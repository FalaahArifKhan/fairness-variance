{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0fd1c5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -r ./requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4fdab9d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T10:55:54.052462Z",
     "start_time": "2024-01-06T10:55:54.038357Z"
    }
   },
   "outputs": [],
   "source": [
    "# !pip uninstall virny -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8eeea999",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T10:56:09.679156Z",
     "start_time": "2024-01-06T10:56:09.668186Z"
    }
   },
   "outputs": [],
   "source": [
    "# Install using an HTTP link\n",
    "# !pip install git+https://github.com/DataResponsibly/Virny.git@feature/prepare_experiments_for_inprocessors\n",
    "\n",
    "# Install using an SSH link\n",
    "# !pip install git+ssh://git@github.com/DataResponsibly/Virny.git@feature/prepare_experiments_for_inprocessors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e16f98dd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T11:15:26.457257Z",
     "start_time": "2024-01-06T11:15:26.114625Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba8251fb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T11:15:26.466361Z",
     "start_time": "2024-01-06T11:15:26.457627Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "os.environ[\"PYTHONWARNINGS\"] = \"ignore\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3d59010",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T11:15:26.478005Z",
     "start_time": "2024-01-06T11:15:26.467253Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current location:  /home/dh3553/projects/fairness-variance\n"
     ]
    }
   ],
   "source": [
    "cur_folder_name = os.getcwd().split('/')[-1]\n",
    "if cur_folder_name != \"fairness-variance\":\n",
    "    os.chdir(\"../../../..\")\n",
    "\n",
    "print('Current location: ', os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a33083",
   "metadata": {},
   "source": [
    "## Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da98cbbb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T11:15:31.734704Z",
     "start_time": "2024-01-06T11:15:28.036691Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:No module named 'tempeh': LawSchoolGPADataset will be unavailable. To install, run:\n",
      "pip install 'aif360[LawSchoolGPA]'\n",
      "WARNING:root:No module named 'fairlearn': ExponentiatedGradientReduction will be unavailable. To install, run:\n",
      "pip install 'aif360[Reductions]'\n",
      "WARNING:root:No module named 'fairlearn': GridSearchReduction will be unavailable. To install, run:\n",
      "pip install 'aif360[Reductions]'\n",
      "WARNING:root:No module named 'fairlearn': GridSearchReduction will be unavailable. To install, run:\n",
      "pip install 'aif360[Reductions]'\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "from virny.utils.custom_initializers import create_config_obj\n",
    "from virny.datasets import ACSPublicCoverageDataset\n",
    "\n",
    "from configs.constants import TEST_SET_FRACTION, EXPERIMENT_SEEDS\n",
    "\n",
    "from source.experiment_interface import run_exp_iter_with_inprocessor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5345d9",
   "metadata": {},
   "source": [
    "## Define Input Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef8f7499",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T11:15:31.772286Z",
     "start_time": "2024-01-06T11:15:31.735883Z"
    }
   },
   "outputs": [],
   "source": [
    "ROOT_DIR = os.getcwd()\n",
    "EXPERIMENT_NAME = 'ADB_acs_pubcov'\n",
    "DB_COLLECTION_NAME = 'one_repair_lvl_many_models'\n",
    "FAIRNESS_INTERVENTION_NAME = 'ADB'\n",
    "FAIR_INTERVENTION_PARAMS_LST = ['debiased_classifier']\n",
    "SAVE_RESULTS_DIR_PATH = os.path.join(ROOT_DIR, 'results', 'diff_fairness_interventions_exp',\n",
    "                                     FAIRNESS_INTERVENTION_NAME, EXPERIMENT_NAME)\n",
    "\n",
    "config_yaml_path = os.path.join(ROOT_DIR, 'notebooks', 'diff_fairness_interventions_exp',\n",
    "                                FAIRNESS_INTERVENTION_NAME, EXPERIMENT_NAME, 'folk_CA_2018_config.yaml')\n",
    "metrics_computation_config = create_config_obj(config_yaml_path=config_yaml_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9907a0ca",
   "metadata": {},
   "source": [
    "## Define a db writer and custom fields to insert into your database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "052f6933",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T11:15:31.813421Z",
     "start_time": "2024-01-06T11:15:31.771935Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fairness_variance'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv('./configs/secrets.env')\n",
    "os.getenv(\"DB_NAME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de6f346f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T11:15:32.096974Z",
     "start_time": "2024-01-06T11:15:31.811395Z"
    }
   },
   "outputs": [],
   "source": [
    "from source.utils.db_functions import connect_to_mongodb\n",
    "\n",
    "client, collection_obj, db_writer_func = connect_to_mongodb(DB_COLLECTION_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c79346e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T11:15:32.138747Z",
     "start_time": "2024-01-06T11:15:32.097343Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current session uuid:  bf843ff8-62e9-4aac-83bc-d805e3299fdc\n"
     ]
    }
   ],
   "source": [
    "import uuid\n",
    "\n",
    "custom_table_fields_dct = {\n",
    "#     'session_uuid': str(uuid.uuid4()),\n",
    "    'session_uuid': 'bf843ff8-62e9-4aac-83bc-d805e3299fdc',\n",
    "}\n",
    "print('Current session uuid: ', custom_table_fields_dct['session_uuid'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a419a8",
   "metadata": {},
   "source": [
    "## Initialize custom objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a03daa4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T11:15:33.528732Z",
     "start_time": "2024-01-06T11:15:33.475702Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SCHL</th>\n",
       "      <th>MAR</th>\n",
       "      <th>SEX</th>\n",
       "      <th>DIS</th>\n",
       "      <th>ESP</th>\n",
       "      <th>CIT</th>\n",
       "      <th>MIG</th>\n",
       "      <th>MIL</th>\n",
       "      <th>ANC</th>\n",
       "      <th>NATIVITY</th>\n",
       "      <th>DEAR</th>\n",
       "      <th>DEYE</th>\n",
       "      <th>DREM</th>\n",
       "      <th>ESR</th>\n",
       "      <th>ST</th>\n",
       "      <th>FER</th>\n",
       "      <th>RAC1P</th>\n",
       "      <th>AGEP</th>\n",
       "      <th>PINCP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>3150.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>18</td>\n",
       "      <td>1600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>43</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>54</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  SCHL MAR SEX DIS ESP CIT MIG MIL ANC NATIVITY DEAR DEYE DREM ESR ST FER  \\\n",
       "0   19   5   1   2   0   1   3   4   1        1    2    2    2   6  6   0   \n",
       "1   16   5   1   2   0   3   3   4   4        1    2    2    2   1  6   0   \n",
       "2   13   5   2   2   1   1   1   0   2        1    2    2    2   6  6   2   \n",
       "3   20   1   2   2   0   4   1   4   1        2    2    2    2   6  6   2   \n",
       "4   16   1   2   2   0   4   1   4   1        2    2    2    2   6  6   0   \n",
       "\n",
       "  RAC1P  AGEP   PINCP  \n",
       "0     1    21  3150.0  \n",
       "1     9    18  1600.0  \n",
       "2     1    16     0.0  \n",
       "3     8    43     0.0  \n",
       "4     6    54     0.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_loader = ACSPublicCoverageDataset(state=['CA'], year=2018, with_nulls=False,\n",
    "                                       subsample_size=15_000, subsample_seed=42)\n",
    "data_loader.X_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "431eb128",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T11:15:34.580537Z",
     "start_time": "2024-01-06T11:15:34.538952Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15000, 19)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_loader.X_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eecf9b5",
   "metadata": {},
   "source": [
    "## Run experiment iterations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fcf6fe6",
   "metadata": {},
   "source": [
    "### Experiment iteration 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c1dfdc30",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T11:15:37.135031Z",
     "start_time": "2024-01-06T11:15:37.105079Z"
    }
   },
   "outputs": [],
   "source": [
    "# Configs for an experiment iteration\n",
    "exp_iter_num = 1\n",
    "experiment_seed = EXPERIMENT_SEEDS[exp_iter_num - 1]\n",
    "custom_table_fields_dct['experiment_iteration'] = f'Exp_iter_{exp_iter_num}'\n",
    "exp_iter_data_loader = copy.deepcopy(data_loader)  # Add deepcopy to avoid data leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894e7da0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T11:15:44.618835Z",
     "start_time": "2024-01-06T11:15:43.745040Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-08 14:47:01 experiment_interface.py INFO    : Start an experiment iteration for the following custom params:\n",
      "INFO:root:Start an experiment iteration for the following custom params:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataset_split_seed': 100,\n",
      " 'experiment_iteration': 'Exp_iter_1',\n",
      " 'fair_intervention_params_lst': \"['debiased_classifier']\",\n",
      " 'model_init_seed': 100,\n",
      " 'session_uuid': '84eeb5f0-4ebe-4d9f-94ef-53ae302c2264'}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0774252fc3d84263b3f1952d6646e165",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Multiple alphas:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-08 14:47:01 experiment_interface.py INFO    : The dataset is preprocessed\n",
      "INFO:root:The dataset is preprocessed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intervention_option:  debiased_classifier\n",
      "cur_base_flow_dataset.X_train_val.columns:  Index(['cat__SCHL_1', 'cat__SCHL_10', 'cat__SCHL_11', 'cat__SCHL_12',\n",
      "       'cat__SCHL_13', 'cat__SCHL_14', 'cat__SCHL_15', 'cat__SCHL_16',\n",
      "       'cat__SCHL_17', 'cat__SCHL_18',\n",
      "       ...\n",
      "       'cat__RELP_3', 'cat__RELP_4', 'cat__RELP_5', 'cat__RELP_6',\n",
      "       'cat__RELP_7', 'cat__RELP_8', 'cat__RELP_9', 'num__AGEP', 'num__WKHP',\n",
      "       'SEX&RAC1P_binary'],\n",
      "      dtype='object', length=724)\n",
      "Top indexes of an X_test in the current base flow dataset:  Int64Index([10155, 11689, 12599, 12193,  8678,  8217,  4670, 12087,  5235,\n",
      "             4189,  7278, 10642,  5284,  7002, 14642, 10594,  7701,  8686,\n",
      "             8665,  6253],\n",
      "           dtype='int64')\n",
      "Top indexes of an y_test in the current base flow dataset:  Int64Index([10155, 11689, 12599, 12193,  8678,  8217,  4670, 12087,  5235,\n",
      "             4189,  7278, 10642,  5284,  7002, 14642, 10594,  7701,  8686,\n",
      "             8665,  6253],\n",
      "           dtype='int64')\n",
      "Using AdversarialDebiasing postprocessor\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6afb71fcf4f547769fec45358ef2d8c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyze multiple models:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b81e93a7c9ca4b759124ebae6b6a39d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/denys_herasymuk/Research/NYU/Code/fairness-variance/faact_venv/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:1176: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/denys_herasymuk/Research/NYU/Code/fairness-variance/faact_venv/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:1176: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "2024-01-08 14:47:02.022905: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:375] MLIR V1 optimization pass is not enabled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.706076; batch adversarial loss: 0.692046\n",
      "epoch 1; iter: 0; batch classifier loss: 0.528616; batch adversarial loss: 0.690824\n",
      "epoch 2; iter: 0; batch classifier loss: 0.437058; batch adversarial loss: 0.641205\n",
      "epoch 3; iter: 0; batch classifier loss: 0.374626; batch adversarial loss: 0.591401\n",
      "epoch 4; iter: 0; batch classifier loss: 0.381561; batch adversarial loss: 0.578531\n",
      "epoch 5; iter: 0; batch classifier loss: 0.362062; batch adversarial loss: 0.540871\n",
      "epoch 6; iter: 0; batch classifier loss: 0.253209; batch adversarial loss: 0.536458\n",
      "epoch 7; iter: 0; batch classifier loss: 0.249384; batch adversarial loss: 0.510654\n",
      "epoch 8; iter: 0; batch classifier loss: 0.222574; batch adversarial loss: 0.526174\n",
      "epoch 9; iter: 0; batch classifier loss: 0.231929; batch adversarial loss: 0.544187\n",
      "epoch 10; iter: 0; batch classifier loss: 0.269365; batch adversarial loss: 0.530938\n",
      "epoch 11; iter: 0; batch classifier loss: 0.269131; batch adversarial loss: 0.499622\n",
      "epoch 12; iter: 0; batch classifier loss: 0.209271; batch adversarial loss: 0.500838\n",
      "epoch 13; iter: 0; batch classifier loss: 0.232830; batch adversarial loss: 0.522906\n",
      "epoch 14; iter: 0; batch classifier loss: 0.200820; batch adversarial loss: 0.444583\n",
      "epoch 15; iter: 0; batch classifier loss: 0.175221; batch adversarial loss: 0.468809\n",
      "epoch 16; iter: 0; batch classifier loss: 0.195260; batch adversarial loss: 0.487876\n",
      "epoch 17; iter: 0; batch classifier loss: 0.108377; batch adversarial loss: 0.462686\n",
      "epoch 18; iter: 0; batch classifier loss: 0.154744; batch adversarial loss: 0.465643\n",
      "epoch 19; iter: 0; batch classifier loss: 0.114956; batch adversarial loss: 0.518928\n",
      "epoch 20; iter: 0; batch classifier loss: 0.185771; batch adversarial loss: 0.457848\n",
      "epoch 21; iter: 0; batch classifier loss: 0.114915; batch adversarial loss: 0.514133\n",
      "epoch 22; iter: 0; batch classifier loss: 0.135782; batch adversarial loss: 0.513373\n",
      "epoch 23; iter: 0; batch classifier loss: 0.134654; batch adversarial loss: 0.569677\n",
      "epoch 24; iter: 0; batch classifier loss: 0.175153; batch adversarial loss: 0.454520\n",
      "epoch 25; iter: 0; batch classifier loss: 0.180932; batch adversarial loss: 0.524089\n",
      "epoch 26; iter: 0; batch classifier loss: 0.194350; batch adversarial loss: 0.554577\n",
      "epoch 27; iter: 0; batch classifier loss: 0.175350; batch adversarial loss: 0.572550\n",
      "epoch 28; iter: 0; batch classifier loss: 0.203875; batch adversarial loss: 0.621340\n",
      "epoch 29; iter: 0; batch classifier loss: 0.220782; batch adversarial loss: 0.584977\n",
      "epoch 30; iter: 0; batch classifier loss: 0.192389; batch adversarial loss: 0.494302\n",
      "epoch 31; iter: 0; batch classifier loss: 0.166049; batch adversarial loss: 0.488495\n",
      "epoch 32; iter: 0; batch classifier loss: 0.181273; batch adversarial loss: 0.477612\n",
      "epoch 33; iter: 0; batch classifier loss: 0.197128; batch adversarial loss: 0.508084\n",
      "epoch 34; iter: 0; batch classifier loss: 0.233774; batch adversarial loss: 0.480641\n",
      "epoch 35; iter: 0; batch classifier loss: 0.171880; batch adversarial loss: 0.430034\n",
      "epoch 36; iter: 0; batch classifier loss: 0.272469; batch adversarial loss: 0.529935\n",
      "epoch 37; iter: 0; batch classifier loss: 0.227646; batch adversarial loss: 0.448445\n",
      "epoch 38; iter: 0; batch classifier loss: 0.163945; batch adversarial loss: 0.406804\n",
      "epoch 39; iter: 0; batch classifier loss: 0.079406; batch adversarial loss: 0.448137\n",
      "epoch 40; iter: 0; batch classifier loss: 0.091811; batch adversarial loss: 0.446052\n",
      "epoch 41; iter: 0; batch classifier loss: 0.067578; batch adversarial loss: 0.525227\n",
      "epoch 42; iter: 0; batch classifier loss: 0.059282; batch adversarial loss: 0.496629\n",
      "epoch 43; iter: 0; batch classifier loss: 0.104444; batch adversarial loss: 0.455580\n",
      "epoch 44; iter: 0; batch classifier loss: 0.119299; batch adversarial loss: 0.454710\n",
      "epoch 45; iter: 0; batch classifier loss: 0.076554; batch adversarial loss: 0.489845\n",
      "epoch 46; iter: 0; batch classifier loss: 0.086420; batch adversarial loss: 0.475786\n",
      "epoch 47; iter: 0; batch classifier loss: 0.067454; batch adversarial loss: 0.383989\n",
      "epoch 48; iter: 0; batch classifier loss: 0.099616; batch adversarial loss: 0.504962\n",
      "epoch 49; iter: 0; batch classifier loss: 0.129307; batch adversarial loss: 0.369170\n",
      "epoch 50; iter: 0; batch classifier loss: 0.074693; batch adversarial loss: 0.344991\n",
      "epoch 51; iter: 0; batch classifier loss: 0.073794; batch adversarial loss: 0.533122\n",
      "epoch 52; iter: 0; batch classifier loss: 0.101932; batch adversarial loss: 0.551938\n",
      "epoch 53; iter: 0; batch classifier loss: 0.079983; batch adversarial loss: 0.460136\n",
      "epoch 54; iter: 0; batch classifier loss: 0.074297; batch adversarial loss: 0.473660\n",
      "epoch 55; iter: 0; batch classifier loss: 0.119616; batch adversarial loss: 0.417397\n",
      "epoch 56; iter: 0; batch classifier loss: 0.096468; batch adversarial loss: 0.344682\n",
      "epoch 57; iter: 0; batch classifier loss: 0.112178; batch adversarial loss: 0.483005\n",
      "epoch 58; iter: 0; batch classifier loss: 0.097981; batch adversarial loss: 0.495853\n",
      "epoch 59; iter: 0; batch classifier loss: 0.082937; batch adversarial loss: 0.485810\n",
      "epoch 60; iter: 0; batch classifier loss: 0.061327; batch adversarial loss: 0.522080\n",
      "epoch 61; iter: 0; batch classifier loss: 0.090307; batch adversarial loss: 0.448743\n",
      "epoch 62; iter: 0; batch classifier loss: 0.047843; batch adversarial loss: 0.452977\n",
      "epoch 63; iter: 0; batch classifier loss: 0.065588; batch adversarial loss: 0.387373\n",
      "epoch 64; iter: 0; batch classifier loss: 0.098521; batch adversarial loss: 0.422866\n",
      "epoch 65; iter: 0; batch classifier loss: 0.058718; batch adversarial loss: 0.489143\n",
      "epoch 66; iter: 0; batch classifier loss: 0.089657; batch adversarial loss: 0.364338\n",
      "epoch 67; iter: 0; batch classifier loss: 0.069073; batch adversarial loss: 0.508808\n",
      "epoch 68; iter: 0; batch classifier loss: 0.079268; batch adversarial loss: 0.435710\n",
      "epoch 69; iter: 0; batch classifier loss: 0.075794; batch adversarial loss: 0.451353\n",
      "epoch 70; iter: 0; batch classifier loss: 0.103014; batch adversarial loss: 0.524944\n",
      "epoch 71; iter: 0; batch classifier loss: 0.079265; batch adversarial loss: 0.458990\n",
      "epoch 72; iter: 0; batch classifier loss: 0.054589; batch adversarial loss: 0.416570\n",
      "epoch 73; iter: 0; batch classifier loss: 0.067984; batch adversarial loss: 0.571959\n",
      "epoch 74; iter: 0; batch classifier loss: 0.075297; batch adversarial loss: 0.431452\n",
      "epoch 75; iter: 0; batch classifier loss: 0.071271; batch adversarial loss: 0.468172\n",
      "epoch 76; iter: 0; batch classifier loss: 0.070982; batch adversarial loss: 0.451261\n",
      "epoch 77; iter: 0; batch classifier loss: 0.076285; batch adversarial loss: 0.433854\n",
      "epoch 78; iter: 0; batch classifier loss: 0.062035; batch adversarial loss: 0.504788\n",
      "epoch 79; iter: 0; batch classifier loss: 0.075761; batch adversarial loss: 0.467174\n",
      "epoch 80; iter: 0; batch classifier loss: 0.098143; batch adversarial loss: 0.505237\n",
      "epoch 81; iter: 0; batch classifier loss: 0.084273; batch adversarial loss: 0.357909\n",
      "epoch 82; iter: 0; batch classifier loss: 0.071487; batch adversarial loss: 0.473864\n",
      "epoch 83; iter: 0; batch classifier loss: 0.121158; batch adversarial loss: 0.486395\n",
      "epoch 84; iter: 0; batch classifier loss: 0.045600; batch adversarial loss: 0.409071\n",
      "epoch 85; iter: 0; batch classifier loss: 0.065818; batch adversarial loss: 0.503372\n",
      "epoch 86; iter: 0; batch classifier loss: 0.082517; batch adversarial loss: 0.587905\n",
      "epoch 87; iter: 0; batch classifier loss: 0.111101; batch adversarial loss: 0.466063\n",
      "epoch 88; iter: 0; batch classifier loss: 0.055440; batch adversarial loss: 0.564533\n",
      "epoch 89; iter: 0; batch classifier loss: 0.089993; batch adversarial loss: 0.390280\n",
      "epoch 90; iter: 0; batch classifier loss: 0.082860; batch adversarial loss: 0.463198\n",
      "epoch 91; iter: 0; batch classifier loss: 0.047112; batch adversarial loss: 0.537224\n",
      "epoch 92; iter: 0; batch classifier loss: 0.101391; batch adversarial loss: 0.538014\n",
      "epoch 93; iter: 0; batch classifier loss: 0.131220; batch adversarial loss: 0.459360\n",
      "epoch 94; iter: 0; batch classifier loss: 0.109573; batch adversarial loss: 0.465781\n",
      "epoch 95; iter: 0; batch classifier loss: 0.054340; batch adversarial loss: 0.397680\n",
      "epoch 96; iter: 0; batch classifier loss: 0.046966; batch adversarial loss: 0.495775\n",
      "epoch 97; iter: 0; batch classifier loss: 0.062126; batch adversarial loss: 0.498909\n",
      "epoch 98; iter: 0; batch classifier loss: 0.062363; batch adversarial loss: 0.431311\n",
      "epoch 99; iter: 0; batch classifier loss: 0.102993; batch adversarial loss: 0.376494\n",
      "epoch 100; iter: 0; batch classifier loss: 0.102044; batch adversarial loss: 0.357074\n",
      "epoch 101; iter: 0; batch classifier loss: 0.054333; batch adversarial loss: 0.467210\n",
      "epoch 102; iter: 0; batch classifier loss: 0.054543; batch adversarial loss: 0.427762\n",
      "epoch 103; iter: 0; batch classifier loss: 0.034367; batch adversarial loss: 0.450090\n",
      "epoch 104; iter: 0; batch classifier loss: 0.065666; batch adversarial loss: 0.440686\n",
      "epoch 105; iter: 0; batch classifier loss: 0.081424; batch adversarial loss: 0.314604\n",
      "epoch 106; iter: 0; batch classifier loss: 0.067678; batch adversarial loss: 0.510275\n",
      "epoch 107; iter: 0; batch classifier loss: 0.063083; batch adversarial loss: 0.474941\n",
      "epoch 108; iter: 0; batch classifier loss: 0.019212; batch adversarial loss: 0.407522\n",
      "epoch 109; iter: 0; batch classifier loss: 0.034522; batch adversarial loss: 0.409571\n",
      "epoch 110; iter: 0; batch classifier loss: 0.058404; batch adversarial loss: 0.502819\n",
      "epoch 111; iter: 0; batch classifier loss: 0.040291; batch adversarial loss: 0.444476\n",
      "epoch 112; iter: 0; batch classifier loss: 0.042527; batch adversarial loss: 0.447824\n",
      "epoch 113; iter: 0; batch classifier loss: 0.053517; batch adversarial loss: 0.419865\n",
      "epoch 114; iter: 0; batch classifier loss: 0.054878; batch adversarial loss: 0.463392\n",
      "epoch 115; iter: 0; batch classifier loss: 0.053708; batch adversarial loss: 0.508642\n",
      "epoch 116; iter: 0; batch classifier loss: 0.035963; batch adversarial loss: 0.455745\n",
      "epoch 117; iter: 0; batch classifier loss: 0.072132; batch adversarial loss: 0.499220\n",
      "epoch 118; iter: 0; batch classifier loss: 0.043367; batch adversarial loss: 0.420356\n",
      "epoch 119; iter: 0; batch classifier loss: 0.048310; batch adversarial loss: 0.492525\n",
      "epoch 120; iter: 0; batch classifier loss: 0.074792; batch adversarial loss: 0.405318\n",
      "epoch 121; iter: 0; batch classifier loss: 0.050102; batch adversarial loss: 0.584632\n",
      "epoch 122; iter: 0; batch classifier loss: 0.066402; batch adversarial loss: 0.514826\n",
      "epoch 123; iter: 0; batch classifier loss: 0.048277; batch adversarial loss: 0.436852\n",
      "epoch 124; iter: 0; batch classifier loss: 0.040002; batch adversarial loss: 0.377582\n",
      "epoch 125; iter: 0; batch classifier loss: 0.017416; batch adversarial loss: 0.497774\n",
      "epoch 126; iter: 0; batch classifier loss: 0.071384; batch adversarial loss: 0.499982\n",
      "epoch 127; iter: 0; batch classifier loss: 0.037890; batch adversarial loss: 0.466903\n",
      "epoch 128; iter: 0; batch classifier loss: 0.045670; batch adversarial loss: 0.433337\n",
      "epoch 129; iter: 0; batch classifier loss: 0.043349; batch adversarial loss: 0.491828\n",
      "epoch 130; iter: 0; batch classifier loss: 0.017410; batch adversarial loss: 0.436271\n",
      "epoch 131; iter: 0; batch classifier loss: 0.050517; batch adversarial loss: 0.450991\n",
      "epoch 132; iter: 0; batch classifier loss: 0.047536; batch adversarial loss: 0.512238\n",
      "epoch 133; iter: 0; batch classifier loss: 0.013396; batch adversarial loss: 0.419450\n",
      "epoch 134; iter: 0; batch classifier loss: 0.069495; batch adversarial loss: 0.453873\n",
      "epoch 135; iter: 0; batch classifier loss: 0.049653; batch adversarial loss: 0.442644\n",
      "epoch 136; iter: 0; batch classifier loss: 0.039447; batch adversarial loss: 0.452397\n",
      "epoch 137; iter: 0; batch classifier loss: 0.046000; batch adversarial loss: 0.442586\n",
      "epoch 138; iter: 0; batch classifier loss: 0.029759; batch adversarial loss: 0.361690\n",
      "epoch 139; iter: 0; batch classifier loss: 0.037082; batch adversarial loss: 0.530520\n",
      "epoch 140; iter: 0; batch classifier loss: 0.061619; batch adversarial loss: 0.476281\n",
      "epoch 141; iter: 0; batch classifier loss: 0.027611; batch adversarial loss: 0.463160\n",
      "epoch 142; iter: 0; batch classifier loss: 0.048353; batch adversarial loss: 0.430123\n",
      "epoch 143; iter: 0; batch classifier loss: 0.023072; batch adversarial loss: 0.542561\n",
      "epoch 144; iter: 0; batch classifier loss: 0.014643; batch adversarial loss: 0.402583\n",
      "epoch 145; iter: 0; batch classifier loss: 0.040828; batch adversarial loss: 0.458558\n",
      "epoch 146; iter: 0; batch classifier loss: 0.052981; batch adversarial loss: 0.499904\n",
      "epoch 147; iter: 0; batch classifier loss: 0.052879; batch adversarial loss: 0.468605\n",
      "epoch 148; iter: 0; batch classifier loss: 0.054970; batch adversarial loss: 0.437735\n",
      "epoch 149; iter: 0; batch classifier loss: 0.013094; batch adversarial loss: 0.392392\n",
      "epoch 150; iter: 0; batch classifier loss: 0.054930; batch adversarial loss: 0.392228\n",
      "epoch 151; iter: 0; batch classifier loss: 0.033070; batch adversarial loss: 0.429573\n",
      "epoch 152; iter: 0; batch classifier loss: 0.013686; batch adversarial loss: 0.480302\n",
      "epoch 153; iter: 0; batch classifier loss: 0.025517; batch adversarial loss: 0.474301\n",
      "epoch 154; iter: 0; batch classifier loss: 0.026941; batch adversarial loss: 0.397288\n",
      "epoch 155; iter: 0; batch classifier loss: 0.021937; batch adversarial loss: 0.382238\n",
      "epoch 156; iter: 0; batch classifier loss: 0.024708; batch adversarial loss: 0.386828\n",
      "epoch 157; iter: 0; batch classifier loss: 0.029149; batch adversarial loss: 0.362087\n",
      "epoch 158; iter: 0; batch classifier loss: 0.032100; batch adversarial loss: 0.514566\n",
      "epoch 159; iter: 0; batch classifier loss: 0.026255; batch adversarial loss: 0.514117\n",
      "epoch 160; iter: 0; batch classifier loss: 0.030920; batch adversarial loss: 0.367334\n",
      "epoch 161; iter: 0; batch classifier loss: 0.015507; batch adversarial loss: 0.385345\n",
      "epoch 162; iter: 0; batch classifier loss: 0.041188; batch adversarial loss: 0.557631\n",
      "epoch 163; iter: 0; batch classifier loss: 0.038723; batch adversarial loss: 0.467234\n",
      "epoch 164; iter: 0; batch classifier loss: 0.024678; batch adversarial loss: 0.458803\n",
      "epoch 165; iter: 0; batch classifier loss: 0.020329; batch adversarial loss: 0.389683\n",
      "epoch 166; iter: 0; batch classifier loss: 0.036762; batch adversarial loss: 0.340316\n",
      "epoch 167; iter: 0; batch classifier loss: 0.030933; batch adversarial loss: 0.488713\n",
      "epoch 168; iter: 0; batch classifier loss: 0.017171; batch adversarial loss: 0.493203\n",
      "epoch 169; iter: 0; batch classifier loss: 0.040985; batch adversarial loss: 0.462638\n",
      "epoch 170; iter: 0; batch classifier loss: 0.028517; batch adversarial loss: 0.418939\n",
      "epoch 171; iter: 0; batch classifier loss: 0.026486; batch adversarial loss: 0.536990\n",
      "epoch 172; iter: 0; batch classifier loss: 0.020521; batch adversarial loss: 0.486689\n",
      "epoch 173; iter: 0; batch classifier loss: 0.030953; batch adversarial loss: 0.454736\n",
      "epoch 174; iter: 0; batch classifier loss: 0.006511; batch adversarial loss: 0.437390\n",
      "epoch 175; iter: 0; batch classifier loss: 0.016025; batch adversarial loss: 0.431013\n",
      "epoch 176; iter: 0; batch classifier loss: 0.023440; batch adversarial loss: 0.506947\n",
      "epoch 177; iter: 0; batch classifier loss: 0.049653; batch adversarial loss: 0.402723\n",
      "epoch 178; iter: 0; batch classifier loss: 0.016105; batch adversarial loss: 0.441069\n",
      "epoch 179; iter: 0; batch classifier loss: 0.010429; batch adversarial loss: 0.496293\n",
      "epoch 180; iter: 0; batch classifier loss: 0.021091; batch adversarial loss: 0.415183\n",
      "epoch 181; iter: 0; batch classifier loss: 0.021063; batch adversarial loss: 0.424210\n",
      "epoch 182; iter: 0; batch classifier loss: 0.029554; batch adversarial loss: 0.479177\n",
      "epoch 183; iter: 0; batch classifier loss: 0.011231; batch adversarial loss: 0.444569\n",
      "epoch 184; iter: 0; batch classifier loss: 0.027491; batch adversarial loss: 0.465693\n",
      "epoch 185; iter: 0; batch classifier loss: 0.033915; batch adversarial loss: 0.559489\n",
      "epoch 186; iter: 0; batch classifier loss: 0.023120; batch adversarial loss: 0.453808\n",
      "epoch 187; iter: 0; batch classifier loss: 0.012470; batch adversarial loss: 0.402795\n",
      "epoch 188; iter: 0; batch classifier loss: 0.028664; batch adversarial loss: 0.427348\n",
      "epoch 189; iter: 0; batch classifier loss: 0.041508; batch adversarial loss: 0.460209\n",
      "epoch 190; iter: 0; batch classifier loss: 0.026672; batch adversarial loss: 0.323445\n",
      "epoch 191; iter: 0; batch classifier loss: 0.039655; batch adversarial loss: 0.390811\n",
      "epoch 192; iter: 0; batch classifier loss: 0.015852; batch adversarial loss: 0.466843\n",
      "epoch 193; iter: 0; batch classifier loss: 0.035564; batch adversarial loss: 0.504015\n",
      "epoch 194; iter: 0; batch classifier loss: 0.008910; batch adversarial loss: 0.485968\n",
      "epoch 195; iter: 0; batch classifier loss: 0.056930; batch adversarial loss: 0.580673\n",
      "epoch 196; iter: 0; batch classifier loss: 0.016108; batch adversarial loss: 0.370200\n",
      "epoch 197; iter: 0; batch classifier loss: 0.045960; batch adversarial loss: 0.446720\n",
      "epoch 198; iter: 0; batch classifier loss: 0.041652; batch adversarial loss: 0.417590\n",
      "epoch 199; iter: 0; batch classifier loss: 0.012187; batch adversarial loss: 0.526439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-08 14:47:38.105341: W tensorflow/c/c_api.cc:304] Operation '{name:'04a441b2-ae24-11ee-be98-ef9b34f2853b/04a441b2-ae24-11ee-be98-ef9b34f2853b/adversary_model/b2/Adam_1/Assign' id:784 op device:{requested: '', assigned: ''} def:{{{node 04a441b2-ae24-11ee-be98-ef9b34f2853b/04a441b2-ae24-11ee-be98-ef9b34f2853b/adversary_model/b2/Adam_1/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](04a441b2-ae24-11ee-be98-ef9b34f2853b/04a441b2-ae24-11ee-be98-ef9b34f2853b/adversary_model/b2/Adam_1, 04a441b2-ae24-11ee-be98-ef9b34f2853b/04a441b2-ae24-11ee-be98-ef9b34f2853b/adversary_model/b2/Adam_1/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.706066; batch adversarial loss: 0.736104\n",
      "epoch 1; iter: 0; batch classifier loss: 0.530403; batch adversarial loss: 0.678148\n",
      "epoch 2; iter: 0; batch classifier loss: 0.459406; batch adversarial loss: 0.631632\n",
      "epoch 3; iter: 0; batch classifier loss: 0.410012; batch adversarial loss: 0.603996\n",
      "epoch 4; iter: 0; batch classifier loss: 0.406459; batch adversarial loss: 0.622275\n",
      "epoch 5; iter: 0; batch classifier loss: 0.403324; batch adversarial loss: 0.592824\n",
      "epoch 6; iter: 0; batch classifier loss: 0.326480; batch adversarial loss: 0.557714\n",
      "epoch 7; iter: 0; batch classifier loss: 0.264814; batch adversarial loss: 0.563979\n",
      "epoch 8; iter: 0; batch classifier loss: 0.309007; batch adversarial loss: 0.561000\n",
      "epoch 9; iter: 0; batch classifier loss: 0.337536; batch adversarial loss: 0.511946\n",
      "epoch 10; iter: 0; batch classifier loss: 0.358785; batch adversarial loss: 0.497081\n",
      "epoch 11; iter: 0; batch classifier loss: 0.326900; batch adversarial loss: 0.521918\n",
      "epoch 12; iter: 0; batch classifier loss: 0.282505; batch adversarial loss: 0.507427\n",
      "epoch 13; iter: 0; batch classifier loss: 0.319482; batch adversarial loss: 0.490685\n",
      "epoch 14; iter: 0; batch classifier loss: 0.297245; batch adversarial loss: 0.530186\n",
      "epoch 15; iter: 0; batch classifier loss: 0.348114; batch adversarial loss: 0.492884\n",
      "epoch 16; iter: 0; batch classifier loss: 0.315601; batch adversarial loss: 0.543774\n",
      "epoch 17; iter: 0; batch classifier loss: 0.353514; batch adversarial loss: 0.479612\n",
      "epoch 18; iter: 0; batch classifier loss: 0.284691; batch adversarial loss: 0.557426\n",
      "epoch 19; iter: 0; batch classifier loss: 0.321636; batch adversarial loss: 0.461743\n",
      "epoch 20; iter: 0; batch classifier loss: 0.313884; batch adversarial loss: 0.535758\n",
      "epoch 21; iter: 0; batch classifier loss: 0.354032; batch adversarial loss: 0.452499\n",
      "epoch 22; iter: 0; batch classifier loss: 0.307755; batch adversarial loss: 0.462012\n",
      "epoch 23; iter: 0; batch classifier loss: 0.339093; batch adversarial loss: 0.481600\n",
      "epoch 24; iter: 0; batch classifier loss: 0.280347; batch adversarial loss: 0.487124\n",
      "epoch 25; iter: 0; batch classifier loss: 0.349690; batch adversarial loss: 0.456283\n",
      "epoch 26; iter: 0; batch classifier loss: 0.296061; batch adversarial loss: 0.497201\n",
      "epoch 27; iter: 0; batch classifier loss: 0.333900; batch adversarial loss: 0.465661\n",
      "epoch 28; iter: 0; batch classifier loss: 0.244060; batch adversarial loss: 0.450193\n",
      "epoch 29; iter: 0; batch classifier loss: 0.281684; batch adversarial loss: 0.416492\n",
      "epoch 30; iter: 0; batch classifier loss: 0.234843; batch adversarial loss: 0.482024\n",
      "epoch 31; iter: 0; batch classifier loss: 0.302185; batch adversarial loss: 0.407197\n",
      "epoch 32; iter: 0; batch classifier loss: 0.187466; batch adversarial loss: 0.474231\n",
      "epoch 33; iter: 0; batch classifier loss: 0.230678; batch adversarial loss: 0.523563\n",
      "epoch 34; iter: 0; batch classifier loss: 0.241098; batch adversarial loss: 0.496128\n",
      "epoch 35; iter: 0; batch classifier loss: 0.299920; batch adversarial loss: 0.424774\n",
      "epoch 36; iter: 0; batch classifier loss: 0.261082; batch adversarial loss: 0.428908\n",
      "epoch 37; iter: 0; batch classifier loss: 0.260111; batch adversarial loss: 0.474318\n",
      "epoch 38; iter: 0; batch classifier loss: 0.284937; batch adversarial loss: 0.372036\n",
      "epoch 39; iter: 0; batch classifier loss: 0.288252; batch adversarial loss: 0.389466\n",
      "epoch 40; iter: 0; batch classifier loss: 0.252943; batch adversarial loss: 0.422020\n",
      "epoch 41; iter: 0; batch classifier loss: 0.203067; batch adversarial loss: 0.377419\n",
      "epoch 42; iter: 0; batch classifier loss: 0.247434; batch adversarial loss: 0.503243\n",
      "epoch 43; iter: 0; batch classifier loss: 0.251894; batch adversarial loss: 0.407028\n",
      "epoch 44; iter: 0; batch classifier loss: 0.323468; batch adversarial loss: 0.434153\n",
      "epoch 45; iter: 0; batch classifier loss: 0.277021; batch adversarial loss: 0.421189\n",
      "epoch 46; iter: 0; batch classifier loss: 0.304496; batch adversarial loss: 0.501504\n",
      "epoch 47; iter: 0; batch classifier loss: 0.246984; batch adversarial loss: 0.447492\n",
      "epoch 48; iter: 0; batch classifier loss: 0.231022; batch adversarial loss: 0.519735\n",
      "epoch 49; iter: 0; batch classifier loss: 0.179348; batch adversarial loss: 0.410107\n",
      "epoch 50; iter: 0; batch classifier loss: 0.257322; batch adversarial loss: 0.496071\n",
      "epoch 51; iter: 0; batch classifier loss: 0.267536; batch adversarial loss: 0.423316\n",
      "epoch 52; iter: 0; batch classifier loss: 0.341285; batch adversarial loss: 0.459359\n",
      "epoch 53; iter: 0; batch classifier loss: 0.095520; batch adversarial loss: 0.458750\n",
      "epoch 54; iter: 0; batch classifier loss: 0.116211; batch adversarial loss: 0.434297\n",
      "epoch 55; iter: 0; batch classifier loss: 0.125691; batch adversarial loss: 0.351374\n",
      "epoch 56; iter: 0; batch classifier loss: 0.099187; batch adversarial loss: 0.398515\n",
      "epoch 57; iter: 0; batch classifier loss: 0.078252; batch adversarial loss: 0.323342\n",
      "epoch 58; iter: 0; batch classifier loss: 0.138991; batch adversarial loss: 0.535808\n",
      "epoch 59; iter: 0; batch classifier loss: 0.090362; batch adversarial loss: 0.529794\n",
      "epoch 60; iter: 0; batch classifier loss: 0.081609; batch adversarial loss: 0.375216\n",
      "epoch 61; iter: 0; batch classifier loss: 0.114897; batch adversarial loss: 0.478639\n",
      "epoch 62; iter: 0; batch classifier loss: 0.108687; batch adversarial loss: 0.408623\n",
      "epoch 63; iter: 0; batch classifier loss: 0.104107; batch adversarial loss: 0.481544\n",
      "epoch 64; iter: 0; batch classifier loss: 0.044141; batch adversarial loss: 0.368196\n",
      "epoch 65; iter: 0; batch classifier loss: 0.082003; batch adversarial loss: 0.465862\n",
      "epoch 66; iter: 0; batch classifier loss: 0.105736; batch adversarial loss: 0.443595\n",
      "epoch 67; iter: 0; batch classifier loss: 0.073735; batch adversarial loss: 0.489333\n",
      "epoch 68; iter: 0; batch classifier loss: 0.060975; batch adversarial loss: 0.436080\n",
      "epoch 69; iter: 0; batch classifier loss: 0.073324; batch adversarial loss: 0.429296\n",
      "epoch 70; iter: 0; batch classifier loss: 0.049926; batch adversarial loss: 0.365259\n",
      "epoch 71; iter: 0; batch classifier loss: 0.083830; batch adversarial loss: 0.494927\n",
      "epoch 72; iter: 0; batch classifier loss: 0.074709; batch adversarial loss: 0.461633\n",
      "epoch 73; iter: 0; batch classifier loss: 0.111192; batch adversarial loss: 0.433871\n",
      "epoch 74; iter: 0; batch classifier loss: 0.039334; batch adversarial loss: 0.515788\n",
      "epoch 75; iter: 0; batch classifier loss: 0.071055; batch adversarial loss: 0.406289\n",
      "epoch 76; iter: 0; batch classifier loss: 0.082684; batch adversarial loss: 0.357580\n",
      "epoch 77; iter: 0; batch classifier loss: 0.067315; batch adversarial loss: 0.511623\n",
      "epoch 78; iter: 0; batch classifier loss: 0.069397; batch adversarial loss: 0.385906\n",
      "epoch 79; iter: 0; batch classifier loss: 0.075082; batch adversarial loss: 0.456910\n",
      "epoch 80; iter: 0; batch classifier loss: 0.048823; batch adversarial loss: 0.406157\n",
      "epoch 81; iter: 0; batch classifier loss: 0.081523; batch adversarial loss: 0.411017\n",
      "epoch 82; iter: 0; batch classifier loss: 0.091294; batch adversarial loss: 0.499160\n",
      "epoch 83; iter: 0; batch classifier loss: 0.064026; batch adversarial loss: 0.350682\n",
      "epoch 84; iter: 0; batch classifier loss: 0.042356; batch adversarial loss: 0.517212\n",
      "epoch 85; iter: 0; batch classifier loss: 0.047720; batch adversarial loss: 0.350081\n",
      "epoch 86; iter: 0; batch classifier loss: 0.035308; batch adversarial loss: 0.443477\n",
      "epoch 87; iter: 0; batch classifier loss: 0.076340; batch adversarial loss: 0.374428\n",
      "epoch 88; iter: 0; batch classifier loss: 0.040681; batch adversarial loss: 0.407967\n",
      "epoch 89; iter: 0; batch classifier loss: 0.102669; batch adversarial loss: 0.389595\n",
      "epoch 90; iter: 0; batch classifier loss: 0.099464; batch adversarial loss: 0.437800\n",
      "epoch 91; iter: 0; batch classifier loss: 0.056865; batch adversarial loss: 0.437627\n",
      "epoch 92; iter: 0; batch classifier loss: 0.041417; batch adversarial loss: 0.460328\n",
      "epoch 93; iter: 0; batch classifier loss: 0.036856; batch adversarial loss: 0.436436\n",
      "epoch 94; iter: 0; batch classifier loss: 0.021777; batch adversarial loss: 0.363280\n",
      "epoch 95; iter: 0; batch classifier loss: 0.105770; batch adversarial loss: 0.378147\n",
      "epoch 96; iter: 0; batch classifier loss: 0.056142; batch adversarial loss: 0.399404\n",
      "epoch 97; iter: 0; batch classifier loss: 0.037050; batch adversarial loss: 0.386856\n",
      "epoch 98; iter: 0; batch classifier loss: 0.067514; batch adversarial loss: 0.414906\n",
      "epoch 99; iter: 0; batch classifier loss: 0.097396; batch adversarial loss: 0.436210\n",
      "epoch 100; iter: 0; batch classifier loss: 0.066562; batch adversarial loss: 0.466013\n",
      "epoch 101; iter: 0; batch classifier loss: 0.042754; batch adversarial loss: 0.375284\n",
      "epoch 102; iter: 0; batch classifier loss: 0.046262; batch adversarial loss: 0.387627\n",
      "epoch 103; iter: 0; batch classifier loss: 0.060422; batch adversarial loss: 0.400367\n",
      "epoch 104; iter: 0; batch classifier loss: 0.047418; batch adversarial loss: 0.438297\n",
      "epoch 105; iter: 0; batch classifier loss: 0.084870; batch adversarial loss: 0.451563\n",
      "epoch 106; iter: 0; batch classifier loss: 0.083724; batch adversarial loss: 0.437510\n",
      "epoch 107; iter: 0; batch classifier loss: 0.024412; batch adversarial loss: 0.500079\n",
      "epoch 108; iter: 0; batch classifier loss: 0.077510; batch adversarial loss: 0.362601\n",
      "epoch 109; iter: 0; batch classifier loss: 0.072262; batch adversarial loss: 0.485094\n",
      "epoch 110; iter: 0; batch classifier loss: 0.028390; batch adversarial loss: 0.414303\n",
      "epoch 111; iter: 0; batch classifier loss: 0.066319; batch adversarial loss: 0.512818\n",
      "epoch 112; iter: 0; batch classifier loss: 0.047636; batch adversarial loss: 0.424238\n",
      "epoch 113; iter: 0; batch classifier loss: 0.041746; batch adversarial loss: 0.410702\n",
      "epoch 114; iter: 0; batch classifier loss: 0.032933; batch adversarial loss: 0.448275\n",
      "epoch 115; iter: 0; batch classifier loss: 0.046158; batch adversarial loss: 0.529532\n",
      "epoch 116; iter: 0; batch classifier loss: 0.065540; batch adversarial loss: 0.429329\n",
      "epoch 117; iter: 0; batch classifier loss: 0.055839; batch adversarial loss: 0.436495\n",
      "epoch 118; iter: 0; batch classifier loss: 0.044993; batch adversarial loss: 0.402658\n",
      "epoch 119; iter: 0; batch classifier loss: 0.073519; batch adversarial loss: 0.378357\n",
      "epoch 120; iter: 0; batch classifier loss: 0.068609; batch adversarial loss: 0.464458\n",
      "epoch 121; iter: 0; batch classifier loss: 0.050895; batch adversarial loss: 0.518541\n",
      "epoch 122; iter: 0; batch classifier loss: 0.059184; batch adversarial loss: 0.345951\n",
      "epoch 123; iter: 0; batch classifier loss: 0.057807; batch adversarial loss: 0.421292\n",
      "epoch 124; iter: 0; batch classifier loss: 0.041276; batch adversarial loss: 0.383915\n",
      "epoch 125; iter: 0; batch classifier loss: 0.049520; batch adversarial loss: 0.421313\n",
      "epoch 126; iter: 0; batch classifier loss: 0.027136; batch adversarial loss: 0.363910\n",
      "epoch 127; iter: 0; batch classifier loss: 0.040973; batch adversarial loss: 0.449873\n",
      "epoch 128; iter: 0; batch classifier loss: 0.032641; batch adversarial loss: 0.476491\n",
      "epoch 129; iter: 0; batch classifier loss: 0.039640; batch adversarial loss: 0.436265\n",
      "epoch 130; iter: 0; batch classifier loss: 0.083309; batch adversarial loss: 0.409344\n",
      "epoch 131; iter: 0; batch classifier loss: 0.066746; batch adversarial loss: 0.464579\n",
      "epoch 132; iter: 0; batch classifier loss: 0.066838; batch adversarial loss: 0.375523\n",
      "epoch 133; iter: 0; batch classifier loss: 0.060657; batch adversarial loss: 0.382825\n",
      "epoch 134; iter: 0; batch classifier loss: 0.039980; batch adversarial loss: 0.450408\n",
      "epoch 135; iter: 0; batch classifier loss: 0.059749; batch adversarial loss: 0.403990\n",
      "epoch 136; iter: 0; batch classifier loss: 0.054896; batch adversarial loss: 0.450985\n",
      "epoch 137; iter: 0; batch classifier loss: 0.039119; batch adversarial loss: 0.574739\n",
      "epoch 138; iter: 0; batch classifier loss: 0.065396; batch adversarial loss: 0.398369\n",
      "epoch 139; iter: 0; batch classifier loss: 0.033868; batch adversarial loss: 0.476669\n",
      "epoch 140; iter: 0; batch classifier loss: 0.028837; batch adversarial loss: 0.481624\n",
      "epoch 141; iter: 0; batch classifier loss: 0.049655; batch adversarial loss: 0.499269\n",
      "epoch 142; iter: 0; batch classifier loss: 0.049504; batch adversarial loss: 0.316459\n",
      "epoch 143; iter: 0; batch classifier loss: 0.070289; batch adversarial loss: 0.535042\n",
      "epoch 144; iter: 0; batch classifier loss: 0.039829; batch adversarial loss: 0.366865\n",
      "epoch 145; iter: 0; batch classifier loss: 0.046085; batch adversarial loss: 0.375202\n",
      "epoch 146; iter: 0; batch classifier loss: 0.023581; batch adversarial loss: 0.446702\n",
      "epoch 147; iter: 0; batch classifier loss: 0.044651; batch adversarial loss: 0.384226\n",
      "epoch 148; iter: 0; batch classifier loss: 0.049078; batch adversarial loss: 0.387665\n",
      "epoch 149; iter: 0; batch classifier loss: 0.039845; batch adversarial loss: 0.441024\n",
      "epoch 150; iter: 0; batch classifier loss: 0.040127; batch adversarial loss: 0.414215\n",
      "epoch 151; iter: 0; batch classifier loss: 0.038650; batch adversarial loss: 0.382847\n",
      "epoch 152; iter: 0; batch classifier loss: 0.031766; batch adversarial loss: 0.458061\n",
      "epoch 153; iter: 0; batch classifier loss: 0.022421; batch adversarial loss: 0.437063\n",
      "epoch 154; iter: 0; batch classifier loss: 0.039472; batch adversarial loss: 0.480207\n",
      "epoch 155; iter: 0; batch classifier loss: 0.034906; batch adversarial loss: 0.514492\n",
      "epoch 156; iter: 0; batch classifier loss: 0.027295; batch adversarial loss: 0.377841\n",
      "epoch 157; iter: 0; batch classifier loss: 0.028500; batch adversarial loss: 0.396452\n",
      "epoch 158; iter: 0; batch classifier loss: 0.034823; batch adversarial loss: 0.453429\n",
      "epoch 159; iter: 0; batch classifier loss: 0.033487; batch adversarial loss: 0.445524\n",
      "epoch 160; iter: 0; batch classifier loss: 0.044612; batch adversarial loss: 0.459001\n",
      "epoch 161; iter: 0; batch classifier loss: 0.017963; batch adversarial loss: 0.343711\n",
      "epoch 162; iter: 0; batch classifier loss: 0.052142; batch adversarial loss: 0.403664\n",
      "epoch 163; iter: 0; batch classifier loss: 0.037099; batch adversarial loss: 0.421914\n",
      "epoch 164; iter: 0; batch classifier loss: 0.032402; batch adversarial loss: 0.472692\n",
      "epoch 165; iter: 0; batch classifier loss: 0.029637; batch adversarial loss: 0.418011\n",
      "epoch 166; iter: 0; batch classifier loss: 0.024944; batch adversarial loss: 0.452449\n",
      "epoch 167; iter: 0; batch classifier loss: 0.017184; batch adversarial loss: 0.458858\n",
      "epoch 168; iter: 0; batch classifier loss: 0.027762; batch adversarial loss: 0.402869\n",
      "epoch 169; iter: 0; batch classifier loss: 0.016027; batch adversarial loss: 0.471132\n",
      "epoch 170; iter: 0; batch classifier loss: 0.020083; batch adversarial loss: 0.480702\n",
      "epoch 171; iter: 0; batch classifier loss: 0.014721; batch adversarial loss: 0.471981\n",
      "epoch 172; iter: 0; batch classifier loss: 0.034698; batch adversarial loss: 0.427563\n",
      "epoch 173; iter: 0; batch classifier loss: 0.026398; batch adversarial loss: 0.372757\n",
      "epoch 174; iter: 0; batch classifier loss: 0.016702; batch adversarial loss: 0.371487\n",
      "epoch 175; iter: 0; batch classifier loss: 0.039552; batch adversarial loss: 0.394009\n",
      "epoch 176; iter: 0; batch classifier loss: 0.031724; batch adversarial loss: 0.377999\n",
      "epoch 177; iter: 0; batch classifier loss: 0.029643; batch adversarial loss: 0.450269\n",
      "epoch 178; iter: 0; batch classifier loss: 0.025091; batch adversarial loss: 0.445277\n",
      "epoch 179; iter: 0; batch classifier loss: 0.026109; batch adversarial loss: 0.446072\n",
      "epoch 180; iter: 0; batch classifier loss: 0.049046; batch adversarial loss: 0.375977\n",
      "epoch 181; iter: 0; batch classifier loss: 0.025078; batch adversarial loss: 0.362209\n",
      "epoch 182; iter: 0; batch classifier loss: 0.031550; batch adversarial loss: 0.392815\n",
      "epoch 183; iter: 0; batch classifier loss: 0.027878; batch adversarial loss: 0.382241\n",
      "epoch 184; iter: 0; batch classifier loss: 0.027336; batch adversarial loss: 0.445629\n",
      "epoch 185; iter: 0; batch classifier loss: 0.022268; batch adversarial loss: 0.451700\n",
      "epoch 186; iter: 0; batch classifier loss: 0.025109; batch adversarial loss: 0.451593\n",
      "epoch 187; iter: 0; batch classifier loss: 0.015620; batch adversarial loss: 0.427051\n",
      "epoch 188; iter: 0; batch classifier loss: 0.013901; batch adversarial loss: 0.616939\n",
      "epoch 189; iter: 0; batch classifier loss: 0.016848; batch adversarial loss: 0.451149\n",
      "epoch 190; iter: 0; batch classifier loss: 0.016180; batch adversarial loss: 0.478983\n",
      "epoch 191; iter: 0; batch classifier loss: 0.034234; batch adversarial loss: 0.362182\n",
      "epoch 192; iter: 0; batch classifier loss: 0.039279; batch adversarial loss: 0.432742\n",
      "epoch 193; iter: 0; batch classifier loss: 0.021960; batch adversarial loss: 0.409336\n",
      "epoch 194; iter: 0; batch classifier loss: 0.023780; batch adversarial loss: 0.408788\n",
      "epoch 195; iter: 0; batch classifier loss: 0.013846; batch adversarial loss: 0.398356\n",
      "epoch 196; iter: 0; batch classifier loss: 0.020329; batch adversarial loss: 0.364331\n",
      "epoch 197; iter: 0; batch classifier loss: 0.007561; batch adversarial loss: 0.454264\n",
      "epoch 198; iter: 0; batch classifier loss: 0.007466; batch adversarial loss: 0.421940\n",
      "epoch 199; iter: 0; batch classifier loss: 0.035742; batch adversarial loss: 0.398075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-08 14:48:13.265192: W tensorflow/c/c_api.cc:304] Operation '{name:'04a4468a-ae24-11ee-be98-ef9b34f2853b/04a4468a-ae24-11ee-be98-ef9b34f2853b/adversary_model/b2/Adam_1/Assign' id:1591 op device:{requested: '', assigned: ''} def:{{{node 04a4468a-ae24-11ee-be98-ef9b34f2853b/04a4468a-ae24-11ee-be98-ef9b34f2853b/adversary_model/b2/Adam_1/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](04a4468a-ae24-11ee-be98-ef9b34f2853b/04a4468a-ae24-11ee-be98-ef9b34f2853b/adversary_model/b2/Adam_1, 04a4468a-ae24-11ee-be98-ef9b34f2853b/04a4468a-ae24-11ee-be98-ef9b34f2853b/adversary_model/b2/Adam_1/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.688129; batch adversarial loss: 0.582458\n",
      "epoch 1; iter: 0; batch classifier loss: 0.418286; batch adversarial loss: 0.582047\n",
      "epoch 2; iter: 0; batch classifier loss: 0.525055; batch adversarial loss: 0.583817\n",
      "epoch 3; iter: 0; batch classifier loss: 0.428255; batch adversarial loss: 0.520912\n",
      "epoch 4; iter: 0; batch classifier loss: 0.349640; batch adversarial loss: 0.566984\n",
      "epoch 5; iter: 0; batch classifier loss: 0.340495; batch adversarial loss: 0.611152\n",
      "epoch 6; iter: 0; batch classifier loss: 0.408788; batch adversarial loss: 0.555860\n",
      "epoch 7; iter: 0; batch classifier loss: 0.336668; batch adversarial loss: 0.536746\n",
      "epoch 8; iter: 0; batch classifier loss: 0.377252; batch adversarial loss: 0.547035\n",
      "epoch 9; iter: 0; batch classifier loss: 0.416875; batch adversarial loss: 0.571816\n",
      "epoch 10; iter: 0; batch classifier loss: 0.458405; batch adversarial loss: 0.447826\n",
      "epoch 11; iter: 0; batch classifier loss: 0.361180; batch adversarial loss: 0.517236\n",
      "epoch 12; iter: 0; batch classifier loss: 0.285615; batch adversarial loss: 0.506002\n",
      "epoch 13; iter: 0; batch classifier loss: 0.346196; batch adversarial loss: 0.575380\n",
      "epoch 14; iter: 0; batch classifier loss: 0.283920; batch adversarial loss: 0.515648\n",
      "epoch 15; iter: 0; batch classifier loss: 0.200360; batch adversarial loss: 0.501168\n",
      "epoch 16; iter: 0; batch classifier loss: 0.243708; batch adversarial loss: 0.432575\n",
      "epoch 17; iter: 0; batch classifier loss: 0.178450; batch adversarial loss: 0.420903\n",
      "epoch 18; iter: 0; batch classifier loss: 0.254595; batch adversarial loss: 0.438466\n",
      "epoch 19; iter: 0; batch classifier loss: 0.257026; batch adversarial loss: 0.496501\n",
      "epoch 20; iter: 0; batch classifier loss: 0.178530; batch adversarial loss: 0.502721\n",
      "epoch 21; iter: 0; batch classifier loss: 0.232064; batch adversarial loss: 0.468430\n",
      "epoch 22; iter: 0; batch classifier loss: 0.189602; batch adversarial loss: 0.435759\n",
      "epoch 23; iter: 0; batch classifier loss: 0.213089; batch adversarial loss: 0.513310\n",
      "epoch 24; iter: 0; batch classifier loss: 0.195573; batch adversarial loss: 0.461283\n",
      "epoch 25; iter: 0; batch classifier loss: 0.202941; batch adversarial loss: 0.458565\n",
      "epoch 26; iter: 0; batch classifier loss: 0.216715; batch adversarial loss: 0.509816\n",
      "epoch 27; iter: 0; batch classifier loss: 0.226038; batch adversarial loss: 0.503132\n",
      "epoch 28; iter: 0; batch classifier loss: 0.185449; batch adversarial loss: 0.474548\n",
      "epoch 29; iter: 0; batch classifier loss: 0.197551; batch adversarial loss: 0.513540\n",
      "epoch 30; iter: 0; batch classifier loss: 0.198968; batch adversarial loss: 0.444631\n",
      "epoch 31; iter: 0; batch classifier loss: 0.178431; batch adversarial loss: 0.418701\n",
      "epoch 32; iter: 0; batch classifier loss: 0.165924; batch adversarial loss: 0.471863\n",
      "epoch 33; iter: 0; batch classifier loss: 0.200710; batch adversarial loss: 0.389130\n",
      "epoch 34; iter: 0; batch classifier loss: 0.215499; batch adversarial loss: 0.398050\n",
      "epoch 35; iter: 0; batch classifier loss: 0.148965; batch adversarial loss: 0.436479\n",
      "epoch 36; iter: 0; batch classifier loss: 0.196180; batch adversarial loss: 0.435999\n",
      "epoch 37; iter: 0; batch classifier loss: 0.219984; batch adversarial loss: 0.414746\n",
      "epoch 38; iter: 0; batch classifier loss: 0.253643; batch adversarial loss: 0.502879\n",
      "epoch 39; iter: 0; batch classifier loss: 0.148975; batch adversarial loss: 0.460152\n",
      "epoch 40; iter: 0; batch classifier loss: 0.182249; batch adversarial loss: 0.430215\n",
      "epoch 41; iter: 0; batch classifier loss: 0.212471; batch adversarial loss: 0.516455\n",
      "epoch 42; iter: 0; batch classifier loss: 0.204900; batch adversarial loss: 0.486186\n",
      "epoch 43; iter: 0; batch classifier loss: 0.273834; batch adversarial loss: 0.370007\n",
      "epoch 44; iter: 0; batch classifier loss: 0.184662; batch adversarial loss: 0.446620\n",
      "epoch 45; iter: 0; batch classifier loss: 0.211863; batch adversarial loss: 0.532505\n",
      "epoch 46; iter: 0; batch classifier loss: 0.246754; batch adversarial loss: 0.378046\n",
      "epoch 47; iter: 0; batch classifier loss: 0.207984; batch adversarial loss: 0.432995\n",
      "epoch 48; iter: 0; batch classifier loss: 0.217221; batch adversarial loss: 0.504403\n",
      "epoch 49; iter: 0; batch classifier loss: 0.199260; batch adversarial loss: 0.494291\n",
      "epoch 50; iter: 0; batch classifier loss: 0.225734; batch adversarial loss: 0.469332\n",
      "epoch 51; iter: 0; batch classifier loss: 0.280469; batch adversarial loss: 0.450357\n",
      "epoch 52; iter: 0; batch classifier loss: 0.256328; batch adversarial loss: 0.400179\n",
      "epoch 53; iter: 0; batch classifier loss: 0.235736; batch adversarial loss: 0.472313\n",
      "epoch 54; iter: 0; batch classifier loss: 0.268841; batch adversarial loss: 0.423809\n",
      "epoch 55; iter: 0; batch classifier loss: 0.215488; batch adversarial loss: 0.494381\n",
      "epoch 56; iter: 0; batch classifier loss: 0.156838; batch adversarial loss: 0.493873\n",
      "epoch 57; iter: 0; batch classifier loss: 0.067571; batch adversarial loss: 0.446264\n",
      "epoch 58; iter: 0; batch classifier loss: 0.103650; batch adversarial loss: 0.479958\n",
      "epoch 59; iter: 0; batch classifier loss: 0.080905; batch adversarial loss: 0.476880\n",
      "epoch 60; iter: 0; batch classifier loss: 0.087581; batch adversarial loss: 0.438387\n",
      "epoch 61; iter: 0; batch classifier loss: 0.057121; batch adversarial loss: 0.527533\n",
      "epoch 62; iter: 0; batch classifier loss: 0.069701; batch adversarial loss: 0.451979\n",
      "epoch 63; iter: 0; batch classifier loss: 0.092830; batch adversarial loss: 0.408839\n",
      "epoch 64; iter: 0; batch classifier loss: 0.179970; batch adversarial loss: 0.439693\n",
      "epoch 65; iter: 0; batch classifier loss: 0.190992; batch adversarial loss: 0.491628\n",
      "epoch 66; iter: 0; batch classifier loss: 0.146571; batch adversarial loss: 0.574472\n",
      "epoch 67; iter: 0; batch classifier loss: 0.124498; batch adversarial loss: 0.413266\n",
      "epoch 68; iter: 0; batch classifier loss: 0.170022; batch adversarial loss: 0.442749\n",
      "epoch 69; iter: 0; batch classifier loss: 0.124150; batch adversarial loss: 0.469246\n",
      "epoch 70; iter: 0; batch classifier loss: 0.086658; batch adversarial loss: 0.446183\n",
      "epoch 71; iter: 0; batch classifier loss: 0.097854; batch adversarial loss: 0.510166\n",
      "epoch 72; iter: 0; batch classifier loss: 0.098005; batch adversarial loss: 0.506230\n",
      "epoch 73; iter: 0; batch classifier loss: 0.103036; batch adversarial loss: 0.476823\n",
      "epoch 74; iter: 0; batch classifier loss: 0.119643; batch adversarial loss: 0.513143\n",
      "epoch 75; iter: 0; batch classifier loss: 0.154620; batch adversarial loss: 0.419525\n",
      "epoch 76; iter: 0; batch classifier loss: 0.085910; batch adversarial loss: 0.417197\n",
      "epoch 77; iter: 0; batch classifier loss: 0.090060; batch adversarial loss: 0.433126\n",
      "epoch 78; iter: 0; batch classifier loss: 0.108649; batch adversarial loss: 0.491992\n",
      "epoch 79; iter: 0; batch classifier loss: 0.072665; batch adversarial loss: 0.427414\n",
      "epoch 80; iter: 0; batch classifier loss: 0.078432; batch adversarial loss: 0.416684\n",
      "epoch 81; iter: 0; batch classifier loss: 0.081628; batch adversarial loss: 0.618467\n",
      "epoch 82; iter: 0; batch classifier loss: 0.081460; batch adversarial loss: 0.451962\n",
      "epoch 83; iter: 0; batch classifier loss: 0.083842; batch adversarial loss: 0.409290\n",
      "epoch 84; iter: 0; batch classifier loss: 0.065025; batch adversarial loss: 0.527774\n",
      "epoch 85; iter: 0; batch classifier loss: 0.076811; batch adversarial loss: 0.395808\n",
      "epoch 86; iter: 0; batch classifier loss: 0.080542; batch adversarial loss: 0.426802\n",
      "epoch 87; iter: 0; batch classifier loss: 0.035755; batch adversarial loss: 0.457259\n",
      "epoch 88; iter: 0; batch classifier loss: 0.075089; batch adversarial loss: 0.522649\n",
      "epoch 89; iter: 0; batch classifier loss: 0.073160; batch adversarial loss: 0.524856\n",
      "epoch 90; iter: 0; batch classifier loss: 0.075504; batch adversarial loss: 0.454985\n",
      "epoch 91; iter: 0; batch classifier loss: 0.082712; batch adversarial loss: 0.468551\n",
      "epoch 92; iter: 0; batch classifier loss: 0.081159; batch adversarial loss: 0.424298\n",
      "epoch 93; iter: 0; batch classifier loss: 0.105341; batch adversarial loss: 0.483678\n",
      "epoch 94; iter: 0; batch classifier loss: 0.103236; batch adversarial loss: 0.413750\n",
      "epoch 95; iter: 0; batch classifier loss: 0.056362; batch adversarial loss: 0.477983\n",
      "epoch 96; iter: 0; batch classifier loss: 0.096910; batch adversarial loss: 0.419712\n",
      "epoch 97; iter: 0; batch classifier loss: 0.088785; batch adversarial loss: 0.338753\n",
      "epoch 98; iter: 0; batch classifier loss: 0.056480; batch adversarial loss: 0.493365\n",
      "epoch 99; iter: 0; batch classifier loss: 0.078842; batch adversarial loss: 0.472535\n",
      "epoch 100; iter: 0; batch classifier loss: 0.045361; batch adversarial loss: 0.404357\n",
      "epoch 101; iter: 0; batch classifier loss: 0.062635; batch adversarial loss: 0.445790\n",
      "epoch 102; iter: 0; batch classifier loss: 0.078453; batch adversarial loss: 0.472064\n",
      "epoch 103; iter: 0; batch classifier loss: 0.038869; batch adversarial loss: 0.438187\n",
      "epoch 104; iter: 0; batch classifier loss: 0.047181; batch adversarial loss: 0.479073\n",
      "epoch 105; iter: 0; batch classifier loss: 0.052053; batch adversarial loss: 0.491621\n",
      "epoch 106; iter: 0; batch classifier loss: 0.031616; batch adversarial loss: 0.548412\n",
      "epoch 107; iter: 0; batch classifier loss: 0.058051; batch adversarial loss: 0.448620\n",
      "epoch 108; iter: 0; batch classifier loss: 0.058622; batch adversarial loss: 0.465527\n",
      "epoch 109; iter: 0; batch classifier loss: 0.026510; batch adversarial loss: 0.452133\n",
      "epoch 110; iter: 0; batch classifier loss: 0.038677; batch adversarial loss: 0.402920\n",
      "epoch 111; iter: 0; batch classifier loss: 0.019532; batch adversarial loss: 0.465544\n",
      "epoch 112; iter: 0; batch classifier loss: 0.056462; batch adversarial loss: 0.441909\n",
      "epoch 113; iter: 0; batch classifier loss: 0.072204; batch adversarial loss: 0.602850\n",
      "epoch 114; iter: 0; batch classifier loss: 0.029742; batch adversarial loss: 0.479939\n",
      "epoch 115; iter: 0; batch classifier loss: 0.050471; batch adversarial loss: 0.433319\n",
      "epoch 116; iter: 0; batch classifier loss: 0.060567; batch adversarial loss: 0.398176\n",
      "epoch 117; iter: 0; batch classifier loss: 0.047180; batch adversarial loss: 0.439185\n",
      "epoch 118; iter: 0; batch classifier loss: 0.029035; batch adversarial loss: 0.418488\n",
      "epoch 119; iter: 0; batch classifier loss: 0.033030; batch adversarial loss: 0.450658\n",
      "epoch 120; iter: 0; batch classifier loss: 0.051230; batch adversarial loss: 0.409980\n",
      "epoch 121; iter: 0; batch classifier loss: 0.034502; batch adversarial loss: 0.483479\n",
      "epoch 122; iter: 0; batch classifier loss: 0.066685; batch adversarial loss: 0.415055\n",
      "epoch 123; iter: 0; batch classifier loss: 0.036303; batch adversarial loss: 0.464543\n",
      "epoch 124; iter: 0; batch classifier loss: 0.052519; batch adversarial loss: 0.493312\n",
      "epoch 125; iter: 0; batch classifier loss: 0.030684; batch adversarial loss: 0.400999\n",
      "epoch 126; iter: 0; batch classifier loss: 0.023634; batch adversarial loss: 0.445230\n",
      "epoch 127; iter: 0; batch classifier loss: 0.032854; batch adversarial loss: 0.453296\n",
      "epoch 128; iter: 0; batch classifier loss: 0.026536; batch adversarial loss: 0.507458\n",
      "epoch 129; iter: 0; batch classifier loss: 0.029507; batch adversarial loss: 0.440097\n",
      "epoch 130; iter: 0; batch classifier loss: 0.037143; batch adversarial loss: 0.370093\n",
      "epoch 131; iter: 0; batch classifier loss: 0.036277; batch adversarial loss: 0.417342\n",
      "epoch 132; iter: 0; batch classifier loss: 0.029931; batch adversarial loss: 0.464351\n",
      "epoch 133; iter: 0; batch classifier loss: 0.032374; batch adversarial loss: 0.545062\n",
      "epoch 134; iter: 0; batch classifier loss: 0.015927; batch adversarial loss: 0.349027\n",
      "epoch 135; iter: 0; batch classifier loss: 0.016774; batch adversarial loss: 0.495524\n",
      "epoch 136; iter: 0; batch classifier loss: 0.030935; batch adversarial loss: 0.449530\n",
      "epoch 137; iter: 0; batch classifier loss: 0.038979; batch adversarial loss: 0.456351\n",
      "epoch 138; iter: 0; batch classifier loss: 0.013323; batch adversarial loss: 0.456658\n",
      "epoch 139; iter: 0; batch classifier loss: 0.030194; batch adversarial loss: 0.510743\n",
      "epoch 140; iter: 0; batch classifier loss: 0.021454; batch adversarial loss: 0.356752\n",
      "epoch 141; iter: 0; batch classifier loss: 0.028846; batch adversarial loss: 0.352905\n",
      "epoch 142; iter: 0; batch classifier loss: 0.023706; batch adversarial loss: 0.536787\n",
      "epoch 143; iter: 0; batch classifier loss: 0.019686; batch adversarial loss: 0.470078\n",
      "epoch 144; iter: 0; batch classifier loss: 0.041820; batch adversarial loss: 0.487558\n",
      "epoch 145; iter: 0; batch classifier loss: 0.011119; batch adversarial loss: 0.483874\n",
      "epoch 146; iter: 0; batch classifier loss: 0.030574; batch adversarial loss: 0.457222\n",
      "epoch 147; iter: 0; batch classifier loss: 0.024936; batch adversarial loss: 0.558170\n",
      "epoch 148; iter: 0; batch classifier loss: 0.022186; batch adversarial loss: 0.372945\n",
      "epoch 149; iter: 0; batch classifier loss: 0.027140; batch adversarial loss: 0.432468\n",
      "epoch 150; iter: 0; batch classifier loss: 0.023059; batch adversarial loss: 0.319447\n",
      "epoch 151; iter: 0; batch classifier loss: 0.041326; batch adversarial loss: 0.445123\n",
      "epoch 152; iter: 0; batch classifier loss: 0.013528; batch adversarial loss: 0.437946\n",
      "epoch 153; iter: 0; batch classifier loss: 0.017250; batch adversarial loss: 0.482155\n",
      "epoch 154; iter: 0; batch classifier loss: 0.012327; batch adversarial loss: 0.448138\n",
      "epoch 155; iter: 0; batch classifier loss: 0.026185; batch adversarial loss: 0.413030\n",
      "epoch 156; iter: 0; batch classifier loss: 0.040082; batch adversarial loss: 0.496351\n",
      "epoch 157; iter: 0; batch classifier loss: 0.021876; batch adversarial loss: 0.453756\n",
      "epoch 158; iter: 0; batch classifier loss: 0.029481; batch adversarial loss: 0.465553\n",
      "epoch 159; iter: 0; batch classifier loss: 0.004143; batch adversarial loss: 0.414448\n",
      "epoch 160; iter: 0; batch classifier loss: 0.013102; batch adversarial loss: 0.464395\n",
      "epoch 161; iter: 0; batch classifier loss: 0.008841; batch adversarial loss: 0.449652\n",
      "epoch 162; iter: 0; batch classifier loss: 0.009041; batch adversarial loss: 0.577473\n",
      "epoch 163; iter: 0; batch classifier loss: 0.012078; batch adversarial loss: 0.431391\n",
      "epoch 164; iter: 0; batch classifier loss: 0.005280; batch adversarial loss: 0.348936\n",
      "epoch 165; iter: 0; batch classifier loss: 0.022938; batch adversarial loss: 0.531446\n",
      "epoch 166; iter: 0; batch classifier loss: 0.007558; batch adversarial loss: 0.368732\n",
      "epoch 167; iter: 0; batch classifier loss: 0.007948; batch adversarial loss: 0.418823\n",
      "epoch 168; iter: 0; batch classifier loss: 0.011378; batch adversarial loss: 0.462137\n",
      "epoch 169; iter: 0; batch classifier loss: 0.012475; batch adversarial loss: 0.522107\n",
      "epoch 170; iter: 0; batch classifier loss: 0.089205; batch adversarial loss: 0.425102\n",
      "epoch 171; iter: 0; batch classifier loss: 0.013193; batch adversarial loss: 0.438883\n",
      "epoch 172; iter: 0; batch classifier loss: 0.019147; batch adversarial loss: 0.464129\n",
      "epoch 173; iter: 0; batch classifier loss: 0.016692; batch adversarial loss: 0.464161\n",
      "epoch 174; iter: 0; batch classifier loss: 0.014131; batch adversarial loss: 0.416692\n",
      "epoch 175; iter: 0; batch classifier loss: 0.019746; batch adversarial loss: 0.454887\n",
      "epoch 176; iter: 0; batch classifier loss: 0.003722; batch adversarial loss: 0.416714\n",
      "epoch 177; iter: 0; batch classifier loss: 0.009313; batch adversarial loss: 0.439547\n",
      "epoch 178; iter: 0; batch classifier loss: 0.013868; batch adversarial loss: 0.486130\n",
      "epoch 179; iter: 0; batch classifier loss: 0.022029; batch adversarial loss: 0.498505\n",
      "epoch 180; iter: 0; batch classifier loss: 0.008864; batch adversarial loss: 0.420729\n",
      "epoch 181; iter: 0; batch classifier loss: 0.038184; batch adversarial loss: 0.417415\n",
      "epoch 182; iter: 0; batch classifier loss: 0.031390; batch adversarial loss: 0.408334\n",
      "epoch 183; iter: 0; batch classifier loss: 0.026545; batch adversarial loss: 0.569768\n",
      "epoch 184; iter: 0; batch classifier loss: 0.006229; batch adversarial loss: 0.342425\n",
      "epoch 185; iter: 0; batch classifier loss: 0.011448; batch adversarial loss: 0.482688\n",
      "epoch 186; iter: 0; batch classifier loss: 0.023002; batch adversarial loss: 0.445266\n",
      "epoch 187; iter: 0; batch classifier loss: 0.004066; batch adversarial loss: 0.428464\n",
      "epoch 188; iter: 0; batch classifier loss: 0.003665; batch adversarial loss: 0.430902\n",
      "epoch 189; iter: 0; batch classifier loss: 0.027354; batch adversarial loss: 0.399141\n",
      "epoch 190; iter: 0; batch classifier loss: 0.005157; batch adversarial loss: 0.474395\n",
      "epoch 191; iter: 0; batch classifier loss: 0.018864; batch adversarial loss: 0.400792\n",
      "epoch 192; iter: 0; batch classifier loss: 0.050361; batch adversarial loss: 0.441677\n",
      "epoch 193; iter: 0; batch classifier loss: 0.012426; batch adversarial loss: 0.475218\n",
      "epoch 194; iter: 0; batch classifier loss: 0.006026; batch adversarial loss: 0.468294\n",
      "epoch 195; iter: 0; batch classifier loss: 0.008955; batch adversarial loss: 0.498031\n",
      "epoch 196; iter: 0; batch classifier loss: 0.012578; batch adversarial loss: 0.443660\n",
      "epoch 197; iter: 0; batch classifier loss: 0.005842; batch adversarial loss: 0.529499\n",
      "epoch 198; iter: 0; batch classifier loss: 0.009330; batch adversarial loss: 0.451309\n",
      "epoch 199; iter: 0; batch classifier loss: 0.053960; batch adversarial loss: 0.396820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-08 14:48:49.999533: W tensorflow/c/c_api.cc:304] Operation '{name:'04a44784-ae24-11ee-be98-ef9b34f2853b/04a44784-ae24-11ee-be98-ef9b34f2853b/adversary_model/b2/Adam_1/Assign' id:2398 op device:{requested: '', assigned: ''} def:{{{node 04a44784-ae24-11ee-be98-ef9b34f2853b/04a44784-ae24-11ee-be98-ef9b34f2853b/adversary_model/b2/Adam_1/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](04a44784-ae24-11ee-be98-ef9b34f2853b/04a44784-ae24-11ee-be98-ef9b34f2853b/adversary_model/b2/Adam_1, 04a44784-ae24-11ee-be98-ef9b34f2853b/04a44784-ae24-11ee-be98-ef9b34f2853b/adversary_model/b2/Adam_1/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.709423; batch adversarial loss: 0.826485\n",
      "epoch 1; iter: 0; batch classifier loss: 0.589269; batch adversarial loss: 0.774333\n",
      "epoch 2; iter: 0; batch classifier loss: 0.757826; batch adversarial loss: 0.757554\n",
      "epoch 3; iter: 0; batch classifier loss: 0.651808; batch adversarial loss: 0.683050\n",
      "epoch 4; iter: 0; batch classifier loss: 0.559073; batch adversarial loss: 0.616526\n",
      "epoch 5; iter: 0; batch classifier loss: 0.383718; batch adversarial loss: 0.587390\n",
      "epoch 6; iter: 0; batch classifier loss: 0.361682; batch adversarial loss: 0.608442\n",
      "epoch 7; iter: 0; batch classifier loss: 0.300812; batch adversarial loss: 0.533616\n",
      "epoch 8; iter: 0; batch classifier loss: 0.428041; batch adversarial loss: 0.522132\n",
      "epoch 9; iter: 0; batch classifier loss: 0.334713; batch adversarial loss: 0.554177\n",
      "epoch 10; iter: 0; batch classifier loss: 0.337976; batch adversarial loss: 0.478305\n",
      "epoch 11; iter: 0; batch classifier loss: 0.403465; batch adversarial loss: 0.537060\n",
      "epoch 12; iter: 0; batch classifier loss: 0.316303; batch adversarial loss: 0.511609\n",
      "epoch 13; iter: 0; batch classifier loss: 0.331920; batch adversarial loss: 0.503228\n",
      "epoch 14; iter: 0; batch classifier loss: 0.314666; batch adversarial loss: 0.467400\n",
      "epoch 15; iter: 0; batch classifier loss: 0.338908; batch adversarial loss: 0.471192\n",
      "epoch 16; iter: 0; batch classifier loss: 0.334456; batch adversarial loss: 0.463481\n",
      "epoch 17; iter: 0; batch classifier loss: 0.237582; batch adversarial loss: 0.487386\n",
      "epoch 18; iter: 0; batch classifier loss: 0.243639; batch adversarial loss: 0.559268\n",
      "epoch 19; iter: 0; batch classifier loss: 0.223562; batch adversarial loss: 0.497359\n",
      "epoch 20; iter: 0; batch classifier loss: 0.289271; batch adversarial loss: 0.560765\n",
      "epoch 21; iter: 0; batch classifier loss: 0.308990; batch adversarial loss: 0.482442\n",
      "epoch 22; iter: 0; batch classifier loss: 0.294239; batch adversarial loss: 0.508942\n",
      "epoch 23; iter: 0; batch classifier loss: 0.245820; batch adversarial loss: 0.469365\n",
      "epoch 24; iter: 0; batch classifier loss: 0.199940; batch adversarial loss: 0.491858\n",
      "epoch 25; iter: 0; batch classifier loss: 0.237852; batch adversarial loss: 0.483418\n",
      "epoch 26; iter: 0; batch classifier loss: 0.248950; batch adversarial loss: 0.494269\n",
      "epoch 27; iter: 0; batch classifier loss: 0.215890; batch adversarial loss: 0.493594\n",
      "epoch 28; iter: 0; batch classifier loss: 0.219729; batch adversarial loss: 0.477457\n",
      "epoch 29; iter: 0; batch classifier loss: 0.219291; batch adversarial loss: 0.576004\n",
      "epoch 30; iter: 0; batch classifier loss: 0.205509; batch adversarial loss: 0.407661\n",
      "epoch 31; iter: 0; batch classifier loss: 0.229055; batch adversarial loss: 0.420588\n",
      "epoch 32; iter: 0; batch classifier loss: 0.231041; batch adversarial loss: 0.436854\n",
      "epoch 33; iter: 0; batch classifier loss: 0.188074; batch adversarial loss: 0.454388\n",
      "epoch 34; iter: 0; batch classifier loss: 0.252571; batch adversarial loss: 0.415374\n",
      "epoch 35; iter: 0; batch classifier loss: 0.175120; batch adversarial loss: 0.415148\n",
      "epoch 36; iter: 0; batch classifier loss: 0.156770; batch adversarial loss: 0.482264\n",
      "epoch 37; iter: 0; batch classifier loss: 0.153350; batch adversarial loss: 0.431682\n",
      "epoch 38; iter: 0; batch classifier loss: 0.211564; batch adversarial loss: 0.467146\n",
      "epoch 39; iter: 0; batch classifier loss: 0.260667; batch adversarial loss: 0.425384\n",
      "epoch 40; iter: 0; batch classifier loss: 0.224133; batch adversarial loss: 0.424066\n",
      "epoch 41; iter: 0; batch classifier loss: 0.186538; batch adversarial loss: 0.481687\n",
      "epoch 42; iter: 0; batch classifier loss: 0.217674; batch adversarial loss: 0.570059\n",
      "epoch 43; iter: 0; batch classifier loss: 0.204773; batch adversarial loss: 0.480069\n",
      "epoch 44; iter: 0; batch classifier loss: 0.287237; batch adversarial loss: 0.476578\n",
      "epoch 45; iter: 0; batch classifier loss: 0.318581; batch adversarial loss: 0.362229\n",
      "epoch 46; iter: 0; batch classifier loss: 0.227443; batch adversarial loss: 0.465089\n",
      "epoch 47; iter: 0; batch classifier loss: 0.194799; batch adversarial loss: 0.446107\n",
      "epoch 48; iter: 0; batch classifier loss: 0.306833; batch adversarial loss: 0.507393\n",
      "epoch 49; iter: 0; batch classifier loss: 0.202465; batch adversarial loss: 0.537706\n",
      "epoch 50; iter: 0; batch classifier loss: 0.223188; batch adversarial loss: 0.423028\n",
      "epoch 51; iter: 0; batch classifier loss: 0.225845; batch adversarial loss: 0.447576\n",
      "epoch 52; iter: 0; batch classifier loss: 0.155381; batch adversarial loss: 0.486634\n",
      "epoch 53; iter: 0; batch classifier loss: 0.203742; batch adversarial loss: 0.445566\n",
      "epoch 54; iter: 0; batch classifier loss: 0.250815; batch adversarial loss: 0.460954\n",
      "epoch 55; iter: 0; batch classifier loss: 0.182396; batch adversarial loss: 0.564597\n",
      "epoch 56; iter: 0; batch classifier loss: 0.178321; batch adversarial loss: 0.466417\n",
      "epoch 57; iter: 0; batch classifier loss: 0.135660; batch adversarial loss: 0.492085\n",
      "epoch 58; iter: 0; batch classifier loss: 0.227268; batch adversarial loss: 0.379017\n",
      "epoch 59; iter: 0; batch classifier loss: 0.185556; batch adversarial loss: 0.459743\n",
      "epoch 60; iter: 0; batch classifier loss: 0.153740; batch adversarial loss: 0.510053\n",
      "epoch 61; iter: 0; batch classifier loss: 0.155630; batch adversarial loss: 0.541576\n",
      "epoch 62; iter: 0; batch classifier loss: 0.116137; batch adversarial loss: 0.521728\n",
      "epoch 63; iter: 0; batch classifier loss: 0.178817; batch adversarial loss: 0.517786\n",
      "epoch 64; iter: 0; batch classifier loss: 0.213310; batch adversarial loss: 0.396766\n",
      "epoch 65; iter: 0; batch classifier loss: 0.174103; batch adversarial loss: 0.519237\n",
      "epoch 66; iter: 0; batch classifier loss: 0.168989; batch adversarial loss: 0.469374\n",
      "epoch 67; iter: 0; batch classifier loss: 0.171487; batch adversarial loss: 0.438444\n",
      "epoch 68; iter: 0; batch classifier loss: 0.227675; batch adversarial loss: 0.382676\n",
      "epoch 69; iter: 0; batch classifier loss: 0.129285; batch adversarial loss: 0.448061\n",
      "epoch 70; iter: 0; batch classifier loss: 0.153188; batch adversarial loss: 0.513892\n",
      "epoch 71; iter: 0; batch classifier loss: 0.189201; batch adversarial loss: 0.483813\n",
      "epoch 72; iter: 0; batch classifier loss: 0.143782; batch adversarial loss: 0.399117\n",
      "epoch 73; iter: 0; batch classifier loss: 0.194640; batch adversarial loss: 0.492915\n",
      "epoch 74; iter: 0; batch classifier loss: 0.222503; batch adversarial loss: 0.506290\n",
      "epoch 75; iter: 0; batch classifier loss: 0.192905; batch adversarial loss: 0.444399\n",
      "epoch 76; iter: 0; batch classifier loss: 0.185618; batch adversarial loss: 0.465811\n",
      "epoch 77; iter: 0; batch classifier loss: 0.102490; batch adversarial loss: 0.387088\n",
      "epoch 78; iter: 0; batch classifier loss: 0.260674; batch adversarial loss: 0.397151\n",
      "epoch 79; iter: 0; batch classifier loss: 0.162815; batch adversarial loss: 0.474389\n",
      "epoch 80; iter: 0; batch classifier loss: 0.195085; batch adversarial loss: 0.410728\n",
      "epoch 81; iter: 0; batch classifier loss: 0.132135; batch adversarial loss: 0.481101\n",
      "epoch 82; iter: 0; batch classifier loss: 0.157003; batch adversarial loss: 0.405431\n",
      "epoch 83; iter: 0; batch classifier loss: 0.114738; batch adversarial loss: 0.472957\n",
      "epoch 84; iter: 0; batch classifier loss: 0.124425; batch adversarial loss: 0.469340\n",
      "epoch 85; iter: 0; batch classifier loss: 0.133828; batch adversarial loss: 0.459536\n",
      "epoch 86; iter: 0; batch classifier loss: 0.127560; batch adversarial loss: 0.468921\n",
      "epoch 87; iter: 0; batch classifier loss: 0.106405; batch adversarial loss: 0.604421\n",
      "epoch 88; iter: 0; batch classifier loss: 0.144443; batch adversarial loss: 0.520639\n",
      "epoch 89; iter: 0; batch classifier loss: 0.117262; batch adversarial loss: 0.506146\n",
      "epoch 90; iter: 0; batch classifier loss: 0.087750; batch adversarial loss: 0.443731\n",
      "epoch 91; iter: 0; batch classifier loss: 0.113289; batch adversarial loss: 0.463015\n",
      "epoch 92; iter: 0; batch classifier loss: 0.128436; batch adversarial loss: 0.406349\n",
      "epoch 93; iter: 0; batch classifier loss: 0.095744; batch adversarial loss: 0.532681\n",
      "epoch 94; iter: 0; batch classifier loss: 0.072927; batch adversarial loss: 0.510598\n",
      "epoch 95; iter: 0; batch classifier loss: 0.050717; batch adversarial loss: 0.512368\n",
      "epoch 96; iter: 0; batch classifier loss: 0.103528; batch adversarial loss: 0.485659\n",
      "epoch 97; iter: 0; batch classifier loss: 0.055867; batch adversarial loss: 0.489014\n",
      "epoch 98; iter: 0; batch classifier loss: 0.119304; batch adversarial loss: 0.409256\n",
      "epoch 99; iter: 0; batch classifier loss: 0.058918; batch adversarial loss: 0.356944\n",
      "epoch 100; iter: 0; batch classifier loss: 0.078266; batch adversarial loss: 0.489582\n",
      "epoch 101; iter: 0; batch classifier loss: 0.100184; batch adversarial loss: 0.437631\n",
      "epoch 102; iter: 0; batch classifier loss: 0.037179; batch adversarial loss: 0.432486\n",
      "epoch 103; iter: 0; batch classifier loss: 0.076005; batch adversarial loss: 0.420993\n",
      "epoch 104; iter: 0; batch classifier loss: 0.023383; batch adversarial loss: 0.489630\n",
      "epoch 105; iter: 0; batch classifier loss: 0.057989; batch adversarial loss: 0.427848\n",
      "epoch 106; iter: 0; batch classifier loss: 0.057579; batch adversarial loss: 0.446779\n",
      "epoch 107; iter: 0; batch classifier loss: 0.016594; batch adversarial loss: 0.571494\n",
      "epoch 108; iter: 0; batch classifier loss: 0.043061; batch adversarial loss: 0.435629\n",
      "epoch 109; iter: 0; batch classifier loss: 0.041660; batch adversarial loss: 0.449064\n",
      "epoch 110; iter: 0; batch classifier loss: 0.052646; batch adversarial loss: 0.429082\n",
      "epoch 111; iter: 0; batch classifier loss: 0.064466; batch adversarial loss: 0.544246\n",
      "epoch 112; iter: 0; batch classifier loss: 0.019509; batch adversarial loss: 0.414706\n",
      "epoch 113; iter: 0; batch classifier loss: 0.053451; batch adversarial loss: 0.438979\n",
      "epoch 114; iter: 0; batch classifier loss: 0.041520; batch adversarial loss: 0.450136\n",
      "epoch 115; iter: 0; batch classifier loss: 0.039195; batch adversarial loss: 0.526165\n",
      "epoch 116; iter: 0; batch classifier loss: 0.046723; batch adversarial loss: 0.487179\n",
      "epoch 117; iter: 0; batch classifier loss: 0.028024; batch adversarial loss: 0.413543\n",
      "epoch 118; iter: 0; batch classifier loss: 0.043546; batch adversarial loss: 0.430986\n",
      "epoch 119; iter: 0; batch classifier loss: 0.042654; batch adversarial loss: 0.482377\n",
      "epoch 120; iter: 0; batch classifier loss: 0.038959; batch adversarial loss: 0.380076\n",
      "epoch 121; iter: 0; batch classifier loss: 0.046653; batch adversarial loss: 0.495118\n",
      "epoch 122; iter: 0; batch classifier loss: 0.015794; batch adversarial loss: 0.513909\n",
      "epoch 123; iter: 0; batch classifier loss: 0.023094; batch adversarial loss: 0.336286\n",
      "epoch 124; iter: 0; batch classifier loss: 0.063677; batch adversarial loss: 0.488526\n",
      "epoch 125; iter: 0; batch classifier loss: 0.023231; batch adversarial loss: 0.407590\n",
      "epoch 126; iter: 0; batch classifier loss: 0.051555; batch adversarial loss: 0.499945\n",
      "epoch 127; iter: 0; batch classifier loss: 0.025814; batch adversarial loss: 0.477885\n",
      "epoch 128; iter: 0; batch classifier loss: 0.016976; batch adversarial loss: 0.424454\n",
      "epoch 129; iter: 0; batch classifier loss: 0.050417; batch adversarial loss: 0.436375\n",
      "epoch 130; iter: 0; batch classifier loss: 0.017588; batch adversarial loss: 0.497257\n",
      "epoch 131; iter: 0; batch classifier loss: 0.035290; batch adversarial loss: 0.445353\n",
      "epoch 132; iter: 0; batch classifier loss: 0.025357; batch adversarial loss: 0.495507\n",
      "epoch 133; iter: 0; batch classifier loss: 0.023691; batch adversarial loss: 0.398855\n",
      "epoch 134; iter: 0; batch classifier loss: 0.032709; batch adversarial loss: 0.477906\n",
      "epoch 135; iter: 0; batch classifier loss: 0.012807; batch adversarial loss: 0.425623\n",
      "epoch 136; iter: 0; batch classifier loss: 0.030065; batch adversarial loss: 0.464185\n",
      "epoch 137; iter: 0; batch classifier loss: 0.041319; batch adversarial loss: 0.495098\n",
      "epoch 138; iter: 0; batch classifier loss: 0.036601; batch adversarial loss: 0.409268\n",
      "epoch 139; iter: 0; batch classifier loss: 0.009201; batch adversarial loss: 0.415366\n",
      "epoch 140; iter: 0; batch classifier loss: 0.010369; batch adversarial loss: 0.548791\n",
      "epoch 141; iter: 0; batch classifier loss: 0.018108; batch adversarial loss: 0.535071\n",
      "epoch 142; iter: 0; batch classifier loss: 0.036020; batch adversarial loss: 0.589606\n",
      "epoch 143; iter: 0; batch classifier loss: 0.015933; batch adversarial loss: 0.460440\n",
      "epoch 144; iter: 0; batch classifier loss: 0.012548; batch adversarial loss: 0.467244\n",
      "epoch 145; iter: 0; batch classifier loss: 0.013664; batch adversarial loss: 0.545864\n",
      "epoch 146; iter: 0; batch classifier loss: 0.026615; batch adversarial loss: 0.433055\n",
      "epoch 147; iter: 0; batch classifier loss: 0.026677; batch adversarial loss: 0.394158\n",
      "epoch 148; iter: 0; batch classifier loss: 0.015726; batch adversarial loss: 0.499501\n",
      "epoch 149; iter: 0; batch classifier loss: 0.013428; batch adversarial loss: 0.500811\n",
      "epoch 150; iter: 0; batch classifier loss: 0.023914; batch adversarial loss: 0.507878\n",
      "epoch 151; iter: 0; batch classifier loss: 0.023069; batch adversarial loss: 0.444022\n",
      "epoch 152; iter: 0; batch classifier loss: 0.015060; batch adversarial loss: 0.406906\n",
      "epoch 153; iter: 0; batch classifier loss: 0.021294; batch adversarial loss: 0.431451\n",
      "epoch 154; iter: 0; batch classifier loss: 0.029299; batch adversarial loss: 0.384312\n",
      "epoch 155; iter: 0; batch classifier loss: 0.021011; batch adversarial loss: 0.425266\n",
      "epoch 156; iter: 0; batch classifier loss: 0.010244; batch adversarial loss: 0.462371\n",
      "epoch 157; iter: 0; batch classifier loss: 0.013574; batch adversarial loss: 0.496028\n",
      "epoch 158; iter: 0; batch classifier loss: 0.016454; batch adversarial loss: 0.442006\n",
      "epoch 159; iter: 0; batch classifier loss: 0.011610; batch adversarial loss: 0.426134\n",
      "epoch 160; iter: 0; batch classifier loss: 0.005939; batch adversarial loss: 0.502678\n",
      "epoch 161; iter: 0; batch classifier loss: 0.007833; batch adversarial loss: 0.470883\n",
      "epoch 162; iter: 0; batch classifier loss: 0.020268; batch adversarial loss: 0.378876\n",
      "epoch 163; iter: 0; batch classifier loss: 0.024588; batch adversarial loss: 0.436137\n",
      "epoch 164; iter: 0; batch classifier loss: 0.023924; batch adversarial loss: 0.466352\n",
      "epoch 165; iter: 0; batch classifier loss: 0.030063; batch adversarial loss: 0.400956\n",
      "epoch 166; iter: 0; batch classifier loss: 0.022583; batch adversarial loss: 0.604907\n",
      "epoch 167; iter: 0; batch classifier loss: 0.008819; batch adversarial loss: 0.359732\n",
      "epoch 168; iter: 0; batch classifier loss: 0.005808; batch adversarial loss: 0.514479\n",
      "epoch 169; iter: 0; batch classifier loss: 0.026108; batch adversarial loss: 0.435591\n",
      "epoch 170; iter: 0; batch classifier loss: 0.022649; batch adversarial loss: 0.438637\n",
      "epoch 171; iter: 0; batch classifier loss: 0.025742; batch adversarial loss: 0.494849\n",
      "epoch 172; iter: 0; batch classifier loss: 0.024279; batch adversarial loss: 0.371164\n",
      "epoch 173; iter: 0; batch classifier loss: 0.011350; batch adversarial loss: 0.457860\n",
      "epoch 174; iter: 0; batch classifier loss: 0.007689; batch adversarial loss: 0.433103\n",
      "epoch 175; iter: 0; batch classifier loss: 0.013153; batch adversarial loss: 0.531247\n",
      "epoch 176; iter: 0; batch classifier loss: 0.007330; batch adversarial loss: 0.419843\n",
      "epoch 177; iter: 0; batch classifier loss: 0.012984; batch adversarial loss: 0.491824\n",
      "epoch 178; iter: 0; batch classifier loss: 0.013910; batch adversarial loss: 0.441699\n",
      "epoch 179; iter: 0; batch classifier loss: 0.012498; batch adversarial loss: 0.515906\n",
      "epoch 180; iter: 0; batch classifier loss: 0.031273; batch adversarial loss: 0.458018\n",
      "epoch 181; iter: 0; batch classifier loss: 0.039369; batch adversarial loss: 0.432972\n",
      "epoch 182; iter: 0; batch classifier loss: 0.034488; batch adversarial loss: 0.494271\n",
      "epoch 183; iter: 0; batch classifier loss: 0.028760; batch adversarial loss: 0.477630\n",
      "epoch 184; iter: 0; batch classifier loss: 0.003358; batch adversarial loss: 0.410230\n",
      "epoch 185; iter: 0; batch classifier loss: 0.008431; batch adversarial loss: 0.415887\n",
      "epoch 186; iter: 0; batch classifier loss: 0.012250; batch adversarial loss: 0.528063\n",
      "epoch 187; iter: 0; batch classifier loss: 0.018286; batch adversarial loss: 0.525953\n",
      "epoch 188; iter: 0; batch classifier loss: 0.012842; batch adversarial loss: 0.436430\n",
      "epoch 189; iter: 0; batch classifier loss: 0.015511; batch adversarial loss: 0.486868\n",
      "epoch 190; iter: 0; batch classifier loss: 0.016325; batch adversarial loss: 0.362743\n",
      "epoch 191; iter: 0; batch classifier loss: 0.025971; batch adversarial loss: 0.450625\n",
      "epoch 192; iter: 0; batch classifier loss: 0.002842; batch adversarial loss: 0.520413\n",
      "epoch 193; iter: 0; batch classifier loss: 0.014467; batch adversarial loss: 0.450268\n",
      "epoch 194; iter: 0; batch classifier loss: 0.011491; batch adversarial loss: 0.497005\n",
      "epoch 195; iter: 0; batch classifier loss: 0.012869; batch adversarial loss: 0.466075\n",
      "epoch 196; iter: 0; batch classifier loss: 0.046112; batch adversarial loss: 0.474331\n",
      "epoch 197; iter: 0; batch classifier loss: 0.001744; batch adversarial loss: 0.376615\n",
      "epoch 198; iter: 0; batch classifier loss: 0.002974; batch adversarial loss: 0.495768\n",
      "epoch 199; iter: 0; batch classifier loss: 0.006627; batch adversarial loss: 0.450932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-08 14:49:25.594013: W tensorflow/c/c_api.cc:304] Operation '{name:'04a4482e-ae24-11ee-be98-ef9b34f2853b/04a4482e-ae24-11ee-be98-ef9b34f2853b/adversary_model/b2/Adam_1/Assign' id:3205 op device:{requested: '', assigned: ''} def:{{{node 04a4482e-ae24-11ee-be98-ef9b34f2853b/04a4482e-ae24-11ee-be98-ef9b34f2853b/adversary_model/b2/Adam_1/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](04a4482e-ae24-11ee-be98-ef9b34f2853b/04a4482e-ae24-11ee-be98-ef9b34f2853b/adversary_model/b2/Adam_1, 04a4482e-ae24-11ee-be98-ef9b34f2853b/04a4482e-ae24-11ee-be98-ef9b34f2853b/adversary_model/b2/Adam_1/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.683073; batch adversarial loss: 0.620856\n",
      "epoch 1; iter: 0; batch classifier loss: 0.440653; batch adversarial loss: 0.621911\n",
      "epoch 2; iter: 0; batch classifier loss: 0.365344; batch adversarial loss: 0.600834\n",
      "epoch 3; iter: 0; batch classifier loss: 0.300769; batch adversarial loss: 0.601682\n",
      "epoch 4; iter: 0; batch classifier loss: 0.272899; batch adversarial loss: 0.534356\n",
      "epoch 5; iter: 0; batch classifier loss: 0.387933; batch adversarial loss: 0.513569\n",
      "epoch 6; iter: 0; batch classifier loss: 0.376173; batch adversarial loss: 0.530133\n",
      "epoch 7; iter: 0; batch classifier loss: 0.369582; batch adversarial loss: 0.561520\n",
      "epoch 8; iter: 0; batch classifier loss: 0.275634; batch adversarial loss: 0.532561\n",
      "epoch 9; iter: 0; batch classifier loss: 0.282988; batch adversarial loss: 0.506175\n",
      "epoch 10; iter: 0; batch classifier loss: 0.250687; batch adversarial loss: 0.404790\n",
      "epoch 11; iter: 0; batch classifier loss: 0.310366; batch adversarial loss: 0.531628\n",
      "epoch 12; iter: 0; batch classifier loss: 0.267975; batch adversarial loss: 0.560586\n",
      "epoch 13; iter: 0; batch classifier loss: 0.340264; batch adversarial loss: 0.544327\n",
      "epoch 14; iter: 0; batch classifier loss: 0.312451; batch adversarial loss: 0.493957\n",
      "epoch 15; iter: 0; batch classifier loss: 0.489029; batch adversarial loss: 0.491952\n",
      "epoch 16; iter: 0; batch classifier loss: 0.488049; batch adversarial loss: 0.555351\n",
      "epoch 17; iter: 0; batch classifier loss: 0.559185; batch adversarial loss: 0.456053\n",
      "epoch 18; iter: 0; batch classifier loss: 0.281974; batch adversarial loss: 0.509155\n",
      "epoch 19; iter: 0; batch classifier loss: 0.237257; batch adversarial loss: 0.485235\n",
      "epoch 20; iter: 0; batch classifier loss: 0.170045; batch adversarial loss: 0.451948\n",
      "epoch 21; iter: 0; batch classifier loss: 0.208757; batch adversarial loss: 0.488383\n",
      "epoch 22; iter: 0; batch classifier loss: 0.176183; batch adversarial loss: 0.451187\n",
      "epoch 23; iter: 0; batch classifier loss: 0.195614; batch adversarial loss: 0.419134\n",
      "epoch 24; iter: 0; batch classifier loss: 0.246046; batch adversarial loss: 0.445964\n",
      "epoch 25; iter: 0; batch classifier loss: 0.174144; batch adversarial loss: 0.449422\n",
      "epoch 26; iter: 0; batch classifier loss: 0.182457; batch adversarial loss: 0.482860\n",
      "epoch 27; iter: 0; batch classifier loss: 0.198129; batch adversarial loss: 0.478548\n",
      "epoch 28; iter: 0; batch classifier loss: 0.212512; batch adversarial loss: 0.394042\n",
      "epoch 29; iter: 0; batch classifier loss: 0.183227; batch adversarial loss: 0.388321\n",
      "epoch 30; iter: 0; batch classifier loss: 0.174824; batch adversarial loss: 0.420980\n",
      "epoch 31; iter: 0; batch classifier loss: 0.156038; batch adversarial loss: 0.456845\n",
      "epoch 32; iter: 0; batch classifier loss: 0.223948; batch adversarial loss: 0.470265\n",
      "epoch 33; iter: 0; batch classifier loss: 0.105976; batch adversarial loss: 0.556003\n",
      "epoch 34; iter: 0; batch classifier loss: 0.142961; batch adversarial loss: 0.437921\n",
      "epoch 35; iter: 0; batch classifier loss: 0.196068; batch adversarial loss: 0.411923\n",
      "epoch 36; iter: 0; batch classifier loss: 0.141115; batch adversarial loss: 0.470426\n",
      "epoch 37; iter: 0; batch classifier loss: 0.165741; batch adversarial loss: 0.353729\n",
      "epoch 38; iter: 0; batch classifier loss: 0.152037; batch adversarial loss: 0.526223\n",
      "epoch 39; iter: 0; batch classifier loss: 0.099027; batch adversarial loss: 0.464474\n",
      "epoch 40; iter: 0; batch classifier loss: 0.110921; batch adversarial loss: 0.452975\n",
      "epoch 41; iter: 0; batch classifier loss: 0.089708; batch adversarial loss: 0.475388\n",
      "epoch 42; iter: 0; batch classifier loss: 0.117443; batch adversarial loss: 0.463111\n",
      "epoch 43; iter: 0; batch classifier loss: 0.081043; batch adversarial loss: 0.560608\n",
      "epoch 44; iter: 0; batch classifier loss: 0.120436; batch adversarial loss: 0.472981\n",
      "epoch 45; iter: 0; batch classifier loss: 0.098060; batch adversarial loss: 0.487844\n",
      "epoch 46; iter: 0; batch classifier loss: 0.127252; batch adversarial loss: 0.368227\n",
      "epoch 47; iter: 0; batch classifier loss: 0.155660; batch adversarial loss: 0.397125\n",
      "epoch 48; iter: 0; batch classifier loss: 0.104707; batch adversarial loss: 0.495177\n",
      "epoch 49; iter: 0; batch classifier loss: 0.094743; batch adversarial loss: 0.437039\n",
      "epoch 50; iter: 0; batch classifier loss: 0.128758; batch adversarial loss: 0.367638\n",
      "epoch 51; iter: 0; batch classifier loss: 0.070209; batch adversarial loss: 0.419098\n",
      "epoch 52; iter: 0; batch classifier loss: 0.121524; batch adversarial loss: 0.511020\n",
      "epoch 53; iter: 0; batch classifier loss: 0.109622; batch adversarial loss: 0.444450\n",
      "epoch 54; iter: 0; batch classifier loss: 0.133209; batch adversarial loss: 0.376170\n",
      "epoch 55; iter: 0; batch classifier loss: 0.119858; batch adversarial loss: 0.415048\n",
      "epoch 56; iter: 0; batch classifier loss: 0.084955; batch adversarial loss: 0.505013\n",
      "epoch 57; iter: 0; batch classifier loss: 0.079445; batch adversarial loss: 0.437708\n",
      "epoch 58; iter: 0; batch classifier loss: 0.173282; batch adversarial loss: 0.451169\n",
      "epoch 59; iter: 0; batch classifier loss: 0.167735; batch adversarial loss: 0.457671\n",
      "epoch 60; iter: 0; batch classifier loss: 0.118800; batch adversarial loss: 0.457323\n",
      "epoch 61; iter: 0; batch classifier loss: 0.104539; batch adversarial loss: 0.457290\n",
      "epoch 62; iter: 0; batch classifier loss: 0.104589; batch adversarial loss: 0.386224\n",
      "epoch 63; iter: 0; batch classifier loss: 0.178848; batch adversarial loss: 0.489418\n",
      "epoch 64; iter: 0; batch classifier loss: 0.118512; batch adversarial loss: 0.493791\n",
      "epoch 65; iter: 0; batch classifier loss: 0.118857; batch adversarial loss: 0.426787\n",
      "epoch 66; iter: 0; batch classifier loss: 0.088094; batch adversarial loss: 0.422159\n",
      "epoch 67; iter: 0; batch classifier loss: 0.094197; batch adversarial loss: 0.431979\n",
      "epoch 68; iter: 0; batch classifier loss: 0.094664; batch adversarial loss: 0.475427\n",
      "epoch 69; iter: 0; batch classifier loss: 0.085103; batch adversarial loss: 0.465173\n",
      "epoch 70; iter: 0; batch classifier loss: 0.144985; batch adversarial loss: 0.411650\n",
      "epoch 71; iter: 0; batch classifier loss: 0.137528; batch adversarial loss: 0.399713\n",
      "epoch 72; iter: 0; batch classifier loss: 0.100343; batch adversarial loss: 0.345952\n",
      "epoch 73; iter: 0; batch classifier loss: 0.114244; batch adversarial loss: 0.513249\n",
      "epoch 74; iter: 0; batch classifier loss: 0.079822; batch adversarial loss: 0.488730\n",
      "epoch 75; iter: 0; batch classifier loss: 0.163532; batch adversarial loss: 0.430517\n",
      "epoch 76; iter: 0; batch classifier loss: 0.106552; batch adversarial loss: 0.413256\n",
      "epoch 77; iter: 0; batch classifier loss: 0.108928; batch adversarial loss: 0.469671\n",
      "epoch 78; iter: 0; batch classifier loss: 0.072789; batch adversarial loss: 0.419774\n",
      "epoch 79; iter: 0; batch classifier loss: 0.080087; batch adversarial loss: 0.451439\n",
      "epoch 80; iter: 0; batch classifier loss: 0.133886; batch adversarial loss: 0.384145\n",
      "epoch 81; iter: 0; batch classifier loss: 0.108813; batch adversarial loss: 0.489638\n",
      "epoch 82; iter: 0; batch classifier loss: 0.127258; batch adversarial loss: 0.392087\n",
      "epoch 83; iter: 0; batch classifier loss: 0.086930; batch adversarial loss: 0.473320\n",
      "epoch 84; iter: 0; batch classifier loss: 0.052324; batch adversarial loss: 0.472512\n",
      "epoch 85; iter: 0; batch classifier loss: 0.095781; batch adversarial loss: 0.449457\n",
      "epoch 86; iter: 0; batch classifier loss: 0.089477; batch adversarial loss: 0.437829\n",
      "epoch 87; iter: 0; batch classifier loss: 0.079782; batch adversarial loss: 0.453353\n",
      "epoch 88; iter: 0; batch classifier loss: 0.143531; batch adversarial loss: 0.466258\n",
      "epoch 89; iter: 0; batch classifier loss: 0.069261; batch adversarial loss: 0.354200\n",
      "epoch 90; iter: 0; batch classifier loss: 0.052139; batch adversarial loss: 0.470479\n",
      "epoch 91; iter: 0; batch classifier loss: 0.062476; batch adversarial loss: 0.541695\n",
      "epoch 92; iter: 0; batch classifier loss: 0.082710; batch adversarial loss: 0.480140\n",
      "epoch 93; iter: 0; batch classifier loss: 0.041896; batch adversarial loss: 0.473447\n",
      "epoch 94; iter: 0; batch classifier loss: 0.075548; batch adversarial loss: 0.447946\n",
      "epoch 95; iter: 0; batch classifier loss: 0.058477; batch adversarial loss: 0.426762\n",
      "epoch 96; iter: 0; batch classifier loss: 0.065355; batch adversarial loss: 0.453171\n",
      "epoch 97; iter: 0; batch classifier loss: 0.046726; batch adversarial loss: 0.335832\n",
      "epoch 98; iter: 0; batch classifier loss: 0.053453; batch adversarial loss: 0.476380\n",
      "epoch 99; iter: 0; batch classifier loss: 0.073238; batch adversarial loss: 0.586781\n",
      "epoch 100; iter: 0; batch classifier loss: 0.035395; batch adversarial loss: 0.427228\n",
      "epoch 101; iter: 0; batch classifier loss: 0.042540; batch adversarial loss: 0.432745\n",
      "epoch 102; iter: 0; batch classifier loss: 0.071360; batch adversarial loss: 0.362941\n",
      "epoch 103; iter: 0; batch classifier loss: 0.093896; batch adversarial loss: 0.463941\n",
      "epoch 104; iter: 0; batch classifier loss: 0.057524; batch adversarial loss: 0.437521\n",
      "epoch 105; iter: 0; batch classifier loss: 0.051401; batch adversarial loss: 0.405707\n",
      "epoch 106; iter: 0; batch classifier loss: 0.054419; batch adversarial loss: 0.473556\n",
      "epoch 107; iter: 0; batch classifier loss: 0.065696; batch adversarial loss: 0.484608\n",
      "epoch 108; iter: 0; batch classifier loss: 0.038128; batch adversarial loss: 0.450714\n",
      "epoch 109; iter: 0; batch classifier loss: 0.050737; batch adversarial loss: 0.470143\n",
      "epoch 110; iter: 0; batch classifier loss: 0.064994; batch adversarial loss: 0.515462\n",
      "epoch 111; iter: 0; batch classifier loss: 0.064557; batch adversarial loss: 0.451665\n",
      "epoch 112; iter: 0; batch classifier loss: 0.038048; batch adversarial loss: 0.495670\n",
      "epoch 113; iter: 0; batch classifier loss: 0.069824; batch adversarial loss: 0.392696\n",
      "epoch 114; iter: 0; batch classifier loss: 0.035725; batch adversarial loss: 0.484216\n",
      "epoch 115; iter: 0; batch classifier loss: 0.044866; batch adversarial loss: 0.430529\n",
      "epoch 116; iter: 0; batch classifier loss: 0.073175; batch adversarial loss: 0.408202\n",
      "epoch 117; iter: 0; batch classifier loss: 0.107425; batch adversarial loss: 0.540736\n",
      "epoch 118; iter: 0; batch classifier loss: 0.043385; batch adversarial loss: 0.383689\n",
      "epoch 119; iter: 0; batch classifier loss: 0.049156; batch adversarial loss: 0.482229\n",
      "epoch 120; iter: 0; batch classifier loss: 0.043849; batch adversarial loss: 0.469089\n",
      "epoch 121; iter: 0; batch classifier loss: 0.058626; batch adversarial loss: 0.445064\n",
      "epoch 122; iter: 0; batch classifier loss: 0.015754; batch adversarial loss: 0.330612\n",
      "epoch 123; iter: 0; batch classifier loss: 0.045682; batch adversarial loss: 0.485688\n",
      "epoch 124; iter: 0; batch classifier loss: 0.033378; batch adversarial loss: 0.408941\n",
      "epoch 125; iter: 0; batch classifier loss: 0.061630; batch adversarial loss: 0.451863\n",
      "epoch 126; iter: 0; batch classifier loss: 0.019002; batch adversarial loss: 0.464778\n",
      "epoch 127; iter: 0; batch classifier loss: 0.026591; batch adversarial loss: 0.464596\n",
      "epoch 128; iter: 0; batch classifier loss: 0.028328; batch adversarial loss: 0.404924\n",
      "epoch 129; iter: 0; batch classifier loss: 0.041040; batch adversarial loss: 0.422667\n",
      "epoch 130; iter: 0; batch classifier loss: 0.021741; batch adversarial loss: 0.410978\n",
      "epoch 131; iter: 0; batch classifier loss: 0.029504; batch adversarial loss: 0.448252\n",
      "epoch 132; iter: 0; batch classifier loss: 0.026199; batch adversarial loss: 0.412464\n",
      "epoch 133; iter: 0; batch classifier loss: 0.039348; batch adversarial loss: 0.566884\n",
      "epoch 134; iter: 0; batch classifier loss: 0.051199; batch adversarial loss: 0.374595\n",
      "epoch 135; iter: 0; batch classifier loss: 0.029727; batch adversarial loss: 0.502335\n",
      "epoch 136; iter: 0; batch classifier loss: 0.086487; batch adversarial loss: 0.358220\n",
      "epoch 137; iter: 0; batch classifier loss: 0.060143; batch adversarial loss: 0.515063\n",
      "epoch 138; iter: 0; batch classifier loss: 0.053990; batch adversarial loss: 0.432021\n",
      "epoch 139; iter: 0; batch classifier loss: 0.022910; batch adversarial loss: 0.428206\n",
      "epoch 140; iter: 0; batch classifier loss: 0.028811; batch adversarial loss: 0.459213\n",
      "epoch 141; iter: 0; batch classifier loss: 0.052790; batch adversarial loss: 0.467816\n",
      "epoch 142; iter: 0; batch classifier loss: 0.042714; batch adversarial loss: 0.384554\n",
      "epoch 143; iter: 0; batch classifier loss: 0.043146; batch adversarial loss: 0.339316\n",
      "epoch 144; iter: 0; batch classifier loss: 0.024966; batch adversarial loss: 0.508985\n",
      "epoch 145; iter: 0; batch classifier loss: 0.020702; batch adversarial loss: 0.497956\n",
      "epoch 146; iter: 0; batch classifier loss: 0.026609; batch adversarial loss: 0.396169\n",
      "epoch 147; iter: 0; batch classifier loss: 0.042491; batch adversarial loss: 0.516891\n",
      "epoch 148; iter: 0; batch classifier loss: 0.015826; batch adversarial loss: 0.594180\n",
      "epoch 149; iter: 0; batch classifier loss: 0.040416; batch adversarial loss: 0.530106\n",
      "epoch 150; iter: 0; batch classifier loss: 0.020989; batch adversarial loss: 0.460259\n",
      "epoch 151; iter: 0; batch classifier loss: 0.008401; batch adversarial loss: 0.446931\n",
      "epoch 152; iter: 0; batch classifier loss: 0.014468; batch adversarial loss: 0.462676\n",
      "epoch 153; iter: 0; batch classifier loss: 0.028570; batch adversarial loss: 0.427720\n",
      "epoch 154; iter: 0; batch classifier loss: 0.067858; batch adversarial loss: 0.356513\n",
      "epoch 155; iter: 0; batch classifier loss: 0.037252; batch adversarial loss: 0.426754\n",
      "epoch 156; iter: 0; batch classifier loss: 0.058051; batch adversarial loss: 0.408194\n",
      "epoch 157; iter: 0; batch classifier loss: 0.024619; batch adversarial loss: 0.531720\n",
      "epoch 158; iter: 0; batch classifier loss: 0.044226; batch adversarial loss: 0.399916\n",
      "epoch 159; iter: 0; batch classifier loss: 0.024355; batch adversarial loss: 0.398681\n",
      "epoch 160; iter: 0; batch classifier loss: 0.020534; batch adversarial loss: 0.469875\n",
      "epoch 161; iter: 0; batch classifier loss: 0.043514; batch adversarial loss: 0.437727\n",
      "epoch 162; iter: 0; batch classifier loss: 0.016105; batch adversarial loss: 0.424770\n",
      "epoch 163; iter: 0; batch classifier loss: 0.024601; batch adversarial loss: 0.405221\n",
      "epoch 164; iter: 0; batch classifier loss: 0.023990; batch adversarial loss: 0.350152\n",
      "epoch 165; iter: 0; batch classifier loss: 0.040421; batch adversarial loss: 0.382282\n",
      "epoch 166; iter: 0; batch classifier loss: 0.045091; batch adversarial loss: 0.472792\n",
      "epoch 167; iter: 0; batch classifier loss: 0.046813; batch adversarial loss: 0.379816\n",
      "epoch 168; iter: 0; batch classifier loss: 0.026784; batch adversarial loss: 0.394039\n",
      "epoch 169; iter: 0; batch classifier loss: 0.021587; batch adversarial loss: 0.414904\n",
      "epoch 170; iter: 0; batch classifier loss: 0.014293; batch adversarial loss: 0.413440\n",
      "epoch 171; iter: 0; batch classifier loss: 0.013882; batch adversarial loss: 0.478051\n",
      "epoch 172; iter: 0; batch classifier loss: 0.017514; batch adversarial loss: 0.448272\n",
      "epoch 173; iter: 0; batch classifier loss: 0.025829; batch adversarial loss: 0.448238\n",
      "epoch 174; iter: 0; batch classifier loss: 0.065883; batch adversarial loss: 0.425081\n",
      "epoch 175; iter: 0; batch classifier loss: 0.040838; batch adversarial loss: 0.481297\n",
      "epoch 176; iter: 0; batch classifier loss: 0.018787; batch adversarial loss: 0.461707\n",
      "epoch 177; iter: 0; batch classifier loss: 0.051299; batch adversarial loss: 0.391626\n",
      "epoch 178; iter: 0; batch classifier loss: 0.021155; batch adversarial loss: 0.433748\n",
      "epoch 179; iter: 0; batch classifier loss: 0.028798; batch adversarial loss: 0.413467\n",
      "epoch 180; iter: 0; batch classifier loss: 0.019515; batch adversarial loss: 0.445502\n",
      "epoch 181; iter: 0; batch classifier loss: 0.012136; batch adversarial loss: 0.463219\n",
      "epoch 182; iter: 0; batch classifier loss: 0.021031; batch adversarial loss: 0.507201\n",
      "epoch 183; iter: 0; batch classifier loss: 0.012701; batch adversarial loss: 0.405407\n",
      "epoch 184; iter: 0; batch classifier loss: 0.036952; batch adversarial loss: 0.458699\n",
      "epoch 185; iter: 0; batch classifier loss: 0.013958; batch adversarial loss: 0.426156\n",
      "epoch 186; iter: 0; batch classifier loss: 0.022732; batch adversarial loss: 0.356023\n",
      "epoch 187; iter: 0; batch classifier loss: 0.017771; batch adversarial loss: 0.448996\n",
      "epoch 188; iter: 0; batch classifier loss: 0.058177; batch adversarial loss: 0.411220\n",
      "epoch 189; iter: 0; batch classifier loss: 0.014598; batch adversarial loss: 0.374938\n",
      "epoch 190; iter: 0; batch classifier loss: 0.023809; batch adversarial loss: 0.396063\n",
      "epoch 191; iter: 0; batch classifier loss: 0.017848; batch adversarial loss: 0.529327\n",
      "epoch 192; iter: 0; batch classifier loss: 0.005764; batch adversarial loss: 0.395014\n",
      "epoch 193; iter: 0; batch classifier loss: 0.005059; batch adversarial loss: 0.442585\n",
      "epoch 194; iter: 0; batch classifier loss: 0.016724; batch adversarial loss: 0.405878\n",
      "epoch 195; iter: 0; batch classifier loss: 0.024334; batch adversarial loss: 0.359202\n",
      "epoch 196; iter: 0; batch classifier loss: 0.006897; batch adversarial loss: 0.479158\n",
      "epoch 197; iter: 0; batch classifier loss: 0.007722; batch adversarial loss: 0.473242\n",
      "epoch 198; iter: 0; batch classifier loss: 0.028269; batch adversarial loss: 0.322968\n",
      "epoch 199; iter: 0; batch classifier loss: 0.031228; batch adversarial loss: 0.561645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-08 14:50:02.788655: W tensorflow/c/c_api.cc:304] Operation '{name:'04a448ba-ae24-11ee-be98-ef9b34f2853b/04a448ba-ae24-11ee-be98-ef9b34f2853b/adversary_model/b2/Adam_1/Assign' id:4012 op device:{requested: '', assigned: ''} def:{{{node 04a448ba-ae24-11ee-be98-ef9b34f2853b/04a448ba-ae24-11ee-be98-ef9b34f2853b/adversary_model/b2/Adam_1/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](04a448ba-ae24-11ee-be98-ef9b34f2853b/04a448ba-ae24-11ee-be98-ef9b34f2853b/adversary_model/b2/Adam_1, 04a448ba-ae24-11ee-be98-ef9b34f2853b/04a448ba-ae24-11ee-be98-ef9b34f2853b/adversary_model/b2/Adam_1/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.688715; batch adversarial loss: 0.983039\n",
      "epoch 1; iter: 0; batch classifier loss: 0.628121; batch adversarial loss: 1.100539\n",
      "epoch 2; iter: 0; batch classifier loss: 0.900819; batch adversarial loss: 1.126426\n",
      "epoch 3; iter: 0; batch classifier loss: 1.017392; batch adversarial loss: 1.014833\n",
      "epoch 4; iter: 0; batch classifier loss: 0.997079; batch adversarial loss: 0.934127\n",
      "epoch 5; iter: 0; batch classifier loss: 0.972972; batch adversarial loss: 0.840362\n",
      "epoch 6; iter: 0; batch classifier loss: 1.035811; batch adversarial loss: 0.765038\n",
      "epoch 7; iter: 0; batch classifier loss: 0.989932; batch adversarial loss: 0.694059\n",
      "epoch 8; iter: 0; batch classifier loss: 1.016223; batch adversarial loss: 0.648634\n",
      "epoch 9; iter: 0; batch classifier loss: 0.816278; batch adversarial loss: 0.583646\n",
      "epoch 10; iter: 0; batch classifier loss: 0.814806; batch adversarial loss: 0.581283\n",
      "epoch 11; iter: 0; batch classifier loss: 0.388503; batch adversarial loss: 0.534007\n",
      "epoch 12; iter: 0; batch classifier loss: 0.460209; batch adversarial loss: 0.522313\n",
      "epoch 13; iter: 0; batch classifier loss: 0.363631; batch adversarial loss: 0.483172\n",
      "epoch 14; iter: 0; batch classifier loss: 0.334066; batch adversarial loss: 0.538998\n",
      "epoch 15; iter: 0; batch classifier loss: 0.330832; batch adversarial loss: 0.503753\n",
      "epoch 16; iter: 0; batch classifier loss: 0.335103; batch adversarial loss: 0.460181\n",
      "epoch 17; iter: 0; batch classifier loss: 0.217084; batch adversarial loss: 0.449338\n",
      "epoch 18; iter: 0; batch classifier loss: 0.222560; batch adversarial loss: 0.452156\n",
      "epoch 19; iter: 0; batch classifier loss: 0.253071; batch adversarial loss: 0.532440\n",
      "epoch 20; iter: 0; batch classifier loss: 0.192251; batch adversarial loss: 0.515274\n",
      "epoch 21; iter: 0; batch classifier loss: 0.195617; batch adversarial loss: 0.457270\n",
      "epoch 22; iter: 0; batch classifier loss: 0.116874; batch adversarial loss: 0.416551\n",
      "epoch 23; iter: 0; batch classifier loss: 0.110665; batch adversarial loss: 0.418451\n",
      "epoch 24; iter: 0; batch classifier loss: 0.130526; batch adversarial loss: 0.442453\n",
      "epoch 25; iter: 0; batch classifier loss: 0.148387; batch adversarial loss: 0.546933\n",
      "epoch 26; iter: 0; batch classifier loss: 0.121442; batch adversarial loss: 0.433987\n",
      "epoch 27; iter: 0; batch classifier loss: 0.104637; batch adversarial loss: 0.486104\n",
      "epoch 28; iter: 0; batch classifier loss: 0.091559; batch adversarial loss: 0.451715\n",
      "epoch 29; iter: 0; batch classifier loss: 0.084214; batch adversarial loss: 0.447392\n",
      "epoch 30; iter: 0; batch classifier loss: 0.066105; batch adversarial loss: 0.413685\n",
      "epoch 31; iter: 0; batch classifier loss: 0.068282; batch adversarial loss: 0.391311\n",
      "epoch 32; iter: 0; batch classifier loss: 0.114118; batch adversarial loss: 0.363025\n",
      "epoch 33; iter: 0; batch classifier loss: 0.084376; batch adversarial loss: 0.496647\n",
      "epoch 34; iter: 0; batch classifier loss: 0.109469; batch adversarial loss: 0.473723\n",
      "epoch 35; iter: 0; batch classifier loss: 0.130510; batch adversarial loss: 0.433919\n",
      "epoch 36; iter: 0; batch classifier loss: 0.102940; batch adversarial loss: 0.484450\n",
      "epoch 37; iter: 0; batch classifier loss: 0.109572; batch adversarial loss: 0.418393\n",
      "epoch 38; iter: 0; batch classifier loss: 0.059485; batch adversarial loss: 0.538812\n",
      "epoch 39; iter: 0; batch classifier loss: 0.107677; batch adversarial loss: 0.465860\n",
      "epoch 40; iter: 0; batch classifier loss: 0.131476; batch adversarial loss: 0.472353\n",
      "epoch 41; iter: 0; batch classifier loss: 0.057669; batch adversarial loss: 0.450761\n",
      "epoch 42; iter: 0; batch classifier loss: 0.082112; batch adversarial loss: 0.501039\n",
      "epoch 43; iter: 0; batch classifier loss: 0.063107; batch adversarial loss: 0.426068\n",
      "epoch 44; iter: 0; batch classifier loss: 0.101416; batch adversarial loss: 0.474336\n",
      "epoch 45; iter: 0; batch classifier loss: 0.090052; batch adversarial loss: 0.427132\n",
      "epoch 46; iter: 0; batch classifier loss: 0.081061; batch adversarial loss: 0.443573\n",
      "epoch 47; iter: 0; batch classifier loss: 0.100561; batch adversarial loss: 0.462411\n",
      "epoch 48; iter: 0; batch classifier loss: 0.082665; batch adversarial loss: 0.528099\n",
      "epoch 49; iter: 0; batch classifier loss: 0.080586; batch adversarial loss: 0.463851\n",
      "epoch 50; iter: 0; batch classifier loss: 0.074351; batch adversarial loss: 0.467955\n",
      "epoch 51; iter: 0; batch classifier loss: 0.065128; batch adversarial loss: 0.363463\n",
      "epoch 52; iter: 0; batch classifier loss: 0.065074; batch adversarial loss: 0.505935\n",
      "epoch 53; iter: 0; batch classifier loss: 0.062227; batch adversarial loss: 0.450037\n",
      "epoch 54; iter: 0; batch classifier loss: 0.082096; batch adversarial loss: 0.483712\n",
      "epoch 55; iter: 0; batch classifier loss: 0.098301; batch adversarial loss: 0.472368\n",
      "epoch 56; iter: 0; batch classifier loss: 0.066021; batch adversarial loss: 0.470020\n",
      "epoch 57; iter: 0; batch classifier loss: 0.061266; batch adversarial loss: 0.469520\n",
      "epoch 58; iter: 0; batch classifier loss: 0.091018; batch adversarial loss: 0.460826\n",
      "epoch 59; iter: 0; batch classifier loss: 0.088777; batch adversarial loss: 0.368837\n",
      "epoch 60; iter: 0; batch classifier loss: 0.072266; batch adversarial loss: 0.417231\n",
      "epoch 61; iter: 0; batch classifier loss: 0.088821; batch adversarial loss: 0.371266\n",
      "epoch 62; iter: 0; batch classifier loss: 0.084045; batch adversarial loss: 0.388032\n",
      "epoch 63; iter: 0; batch classifier loss: 0.099800; batch adversarial loss: 0.480330\n",
      "epoch 64; iter: 0; batch classifier loss: 0.070695; batch adversarial loss: 0.464629\n",
      "epoch 65; iter: 0; batch classifier loss: 0.050034; batch adversarial loss: 0.461426\n",
      "epoch 66; iter: 0; batch classifier loss: 0.091146; batch adversarial loss: 0.408800\n",
      "epoch 67; iter: 0; batch classifier loss: 0.106377; batch adversarial loss: 0.504875\n",
      "epoch 68; iter: 0; batch classifier loss: 0.043170; batch adversarial loss: 0.464844\n",
      "epoch 69; iter: 0; batch classifier loss: 0.072073; batch adversarial loss: 0.433548\n",
      "epoch 70; iter: 0; batch classifier loss: 0.052125; batch adversarial loss: 0.480371\n",
      "epoch 71; iter: 0; batch classifier loss: 0.057055; batch adversarial loss: 0.423309\n",
      "epoch 72; iter: 0; batch classifier loss: 0.088492; batch adversarial loss: 0.363886\n",
      "epoch 73; iter: 0; batch classifier loss: 0.047265; batch adversarial loss: 0.382111\n",
      "epoch 74; iter: 0; batch classifier loss: 0.040557; batch adversarial loss: 0.378222\n",
      "epoch 75; iter: 0; batch classifier loss: 0.042162; batch adversarial loss: 0.436483\n",
      "epoch 76; iter: 0; batch classifier loss: 0.047782; batch adversarial loss: 0.469712\n",
      "epoch 77; iter: 0; batch classifier loss: 0.045663; batch adversarial loss: 0.431864\n",
      "epoch 78; iter: 0; batch classifier loss: 0.059991; batch adversarial loss: 0.420678\n",
      "epoch 79; iter: 0; batch classifier loss: 0.064905; batch adversarial loss: 0.493314\n",
      "epoch 80; iter: 0; batch classifier loss: 0.045461; batch adversarial loss: 0.376153\n",
      "epoch 81; iter: 0; batch classifier loss: 0.050206; batch adversarial loss: 0.409281\n",
      "epoch 82; iter: 0; batch classifier loss: 0.046113; batch adversarial loss: 0.467115\n",
      "epoch 83; iter: 0; batch classifier loss: 0.035233; batch adversarial loss: 0.469703\n",
      "epoch 84; iter: 0; batch classifier loss: 0.029775; batch adversarial loss: 0.505177\n",
      "epoch 85; iter: 0; batch classifier loss: 0.042924; batch adversarial loss: 0.485360\n",
      "epoch 86; iter: 0; batch classifier loss: 0.021504; batch adversarial loss: 0.443047\n",
      "epoch 87; iter: 0; batch classifier loss: 0.047788; batch adversarial loss: 0.547391\n",
      "epoch 88; iter: 0; batch classifier loss: 0.042897; batch adversarial loss: 0.348584\n",
      "epoch 89; iter: 0; batch classifier loss: 0.030057; batch adversarial loss: 0.445219\n",
      "epoch 90; iter: 0; batch classifier loss: 0.048613; batch adversarial loss: 0.498932\n",
      "epoch 91; iter: 0; batch classifier loss: 0.028670; batch adversarial loss: 0.392131\n",
      "epoch 92; iter: 0; batch classifier loss: 0.024187; batch adversarial loss: 0.528975\n",
      "epoch 93; iter: 0; batch classifier loss: 0.032129; batch adversarial loss: 0.476735\n",
      "epoch 94; iter: 0; batch classifier loss: 0.033969; batch adversarial loss: 0.491378\n",
      "epoch 95; iter: 0; batch classifier loss: 0.033368; batch adversarial loss: 0.406544\n",
      "epoch 96; iter: 0; batch classifier loss: 0.035445; batch adversarial loss: 0.499140\n",
      "epoch 97; iter: 0; batch classifier loss: 0.063905; batch adversarial loss: 0.452456\n",
      "epoch 98; iter: 0; batch classifier loss: 0.056222; batch adversarial loss: 0.370576\n",
      "epoch 99; iter: 0; batch classifier loss: 0.046255; batch adversarial loss: 0.461843\n",
      "epoch 100; iter: 0; batch classifier loss: 0.019374; batch adversarial loss: 0.526640\n",
      "epoch 101; iter: 0; batch classifier loss: 0.037838; batch adversarial loss: 0.428831\n",
      "epoch 102; iter: 0; batch classifier loss: 0.029502; batch adversarial loss: 0.517934\n",
      "epoch 103; iter: 0; batch classifier loss: 0.036693; batch adversarial loss: 0.479803\n",
      "epoch 104; iter: 0; batch classifier loss: 0.033586; batch adversarial loss: 0.462126\n",
      "epoch 105; iter: 0; batch classifier loss: 0.022528; batch adversarial loss: 0.480492\n",
      "epoch 106; iter: 0; batch classifier loss: 0.051269; batch adversarial loss: 0.390230\n",
      "epoch 107; iter: 0; batch classifier loss: 0.025912; batch adversarial loss: 0.428924\n",
      "epoch 108; iter: 0; batch classifier loss: 0.042159; batch adversarial loss: 0.443559\n",
      "epoch 109; iter: 0; batch classifier loss: 0.021290; batch adversarial loss: 0.487578\n",
      "epoch 110; iter: 0; batch classifier loss: 0.023505; batch adversarial loss: 0.492512\n",
      "epoch 111; iter: 0; batch classifier loss: 0.017535; batch adversarial loss: 0.410937\n",
      "epoch 112; iter: 0; batch classifier loss: 0.025621; batch adversarial loss: 0.450347\n",
      "epoch 113; iter: 0; batch classifier loss: 0.038833; batch adversarial loss: 0.396705\n",
      "epoch 114; iter: 0; batch classifier loss: 0.033631; batch adversarial loss: 0.478048\n",
      "epoch 115; iter: 0; batch classifier loss: 0.033618; batch adversarial loss: 0.445996\n",
      "epoch 116; iter: 0; batch classifier loss: 0.021869; batch adversarial loss: 0.450988\n",
      "epoch 117; iter: 0; batch classifier loss: 0.025700; batch adversarial loss: 0.489628\n",
      "epoch 118; iter: 0; batch classifier loss: 0.052874; batch adversarial loss: 0.503270\n",
      "epoch 119; iter: 0; batch classifier loss: 0.044407; batch adversarial loss: 0.487963\n",
      "epoch 120; iter: 0; batch classifier loss: 0.039415; batch adversarial loss: 0.468673\n",
      "epoch 121; iter: 0; batch classifier loss: 0.042812; batch adversarial loss: 0.489505\n",
      "epoch 122; iter: 0; batch classifier loss: 0.038994; batch adversarial loss: 0.412301\n",
      "epoch 123; iter: 0; batch classifier loss: 0.036888; batch adversarial loss: 0.312297\n",
      "epoch 124; iter: 0; batch classifier loss: 0.036261; batch adversarial loss: 0.461313\n",
      "epoch 125; iter: 0; batch classifier loss: 0.038236; batch adversarial loss: 0.519647\n",
      "epoch 126; iter: 0; batch classifier loss: 0.039189; batch adversarial loss: 0.494202\n",
      "epoch 127; iter: 0; batch classifier loss: 0.035679; batch adversarial loss: 0.501105\n",
      "epoch 128; iter: 0; batch classifier loss: 0.010645; batch adversarial loss: 0.499304\n",
      "epoch 129; iter: 0; batch classifier loss: 0.018803; batch adversarial loss: 0.537932\n",
      "epoch 130; iter: 0; batch classifier loss: 0.061528; batch adversarial loss: 0.496497\n",
      "epoch 131; iter: 0; batch classifier loss: 0.009915; batch adversarial loss: 0.458411\n",
      "epoch 132; iter: 0; batch classifier loss: 0.034905; batch adversarial loss: 0.429200\n",
      "epoch 133; iter: 0; batch classifier loss: 0.013308; batch adversarial loss: 0.538931\n",
      "epoch 134; iter: 0; batch classifier loss: 0.020050; batch adversarial loss: 0.378343\n",
      "epoch 135; iter: 0; batch classifier loss: 0.036235; batch adversarial loss: 0.495071\n",
      "epoch 136; iter: 0; batch classifier loss: 0.033578; batch adversarial loss: 0.513097\n",
      "epoch 137; iter: 0; batch classifier loss: 0.042364; batch adversarial loss: 0.465550\n",
      "epoch 138; iter: 0; batch classifier loss: 0.021714; batch adversarial loss: 0.450820\n",
      "epoch 139; iter: 0; batch classifier loss: 0.014111; batch adversarial loss: 0.409608\n",
      "epoch 140; iter: 0; batch classifier loss: 0.017977; batch adversarial loss: 0.388635\n",
      "epoch 141; iter: 0; batch classifier loss: 0.023161; batch adversarial loss: 0.446668\n",
      "epoch 142; iter: 0; batch classifier loss: 0.048083; batch adversarial loss: 0.429200\n",
      "epoch 143; iter: 0; batch classifier loss: 0.025612; batch adversarial loss: 0.396818\n",
      "epoch 144; iter: 0; batch classifier loss: 0.032844; batch adversarial loss: 0.315482\n",
      "epoch 145; iter: 0; batch classifier loss: 0.024941; batch adversarial loss: 0.376494\n",
      "epoch 146; iter: 0; batch classifier loss: 0.041394; batch adversarial loss: 0.386173\n",
      "epoch 147; iter: 0; batch classifier loss: 0.024354; batch adversarial loss: 0.495191\n",
      "epoch 148; iter: 0; batch classifier loss: 0.014848; batch adversarial loss: 0.530843\n",
      "epoch 149; iter: 0; batch classifier loss: 0.033395; batch adversarial loss: 0.405986\n",
      "epoch 150; iter: 0; batch classifier loss: 0.053988; batch adversarial loss: 0.362676\n",
      "epoch 151; iter: 0; batch classifier loss: 0.024418; batch adversarial loss: 0.431975\n",
      "epoch 152; iter: 0; batch classifier loss: 0.030281; batch adversarial loss: 0.427211\n",
      "epoch 153; iter: 0; batch classifier loss: 0.020341; batch adversarial loss: 0.485753\n",
      "epoch 154; iter: 0; batch classifier loss: 0.040641; batch adversarial loss: 0.496311\n",
      "epoch 155; iter: 0; batch classifier loss: 0.024292; batch adversarial loss: 0.391502\n",
      "epoch 156; iter: 0; batch classifier loss: 0.030846; batch adversarial loss: 0.431918\n",
      "epoch 157; iter: 0; batch classifier loss: 0.019141; batch adversarial loss: 0.478216\n",
      "epoch 158; iter: 0; batch classifier loss: 0.012302; batch adversarial loss: 0.474453\n",
      "epoch 159; iter: 0; batch classifier loss: 0.026862; batch adversarial loss: 0.497809\n",
      "epoch 160; iter: 0; batch classifier loss: 0.017936; batch adversarial loss: 0.467878\n",
      "epoch 161; iter: 0; batch classifier loss: 0.010025; batch adversarial loss: 0.482063\n",
      "epoch 162; iter: 0; batch classifier loss: 0.019128; batch adversarial loss: 0.359276\n",
      "epoch 163; iter: 0; batch classifier loss: 0.006330; batch adversarial loss: 0.433474\n",
      "epoch 164; iter: 0; batch classifier loss: 0.029055; batch adversarial loss: 0.578649\n",
      "epoch 165; iter: 0; batch classifier loss: 0.020343; batch adversarial loss: 0.478374\n",
      "epoch 166; iter: 0; batch classifier loss: 0.024393; batch adversarial loss: 0.476705\n",
      "epoch 167; iter: 0; batch classifier loss: 0.022079; batch adversarial loss: 0.578530\n",
      "epoch 168; iter: 0; batch classifier loss: 0.017073; batch adversarial loss: 0.552534\n",
      "epoch 169; iter: 0; batch classifier loss: 0.013898; batch adversarial loss: 0.532417\n",
      "epoch 170; iter: 0; batch classifier loss: 0.012398; batch adversarial loss: 0.422551\n",
      "epoch 171; iter: 0; batch classifier loss: 0.012326; batch adversarial loss: 0.436369\n",
      "epoch 172; iter: 0; batch classifier loss: 0.031451; batch adversarial loss: 0.428115\n",
      "epoch 173; iter: 0; batch classifier loss: 0.020282; batch adversarial loss: 0.416464\n",
      "epoch 174; iter: 0; batch classifier loss: 0.021471; batch adversarial loss: 0.379303\n",
      "epoch 175; iter: 0; batch classifier loss: 0.009096; batch adversarial loss: 0.368390\n",
      "epoch 176; iter: 0; batch classifier loss: 0.041444; batch adversarial loss: 0.411759\n",
      "epoch 177; iter: 0; batch classifier loss: 0.008289; batch adversarial loss: 0.522269\n"
     ]
    }
   ],
   "source": [
    "run_exp_iter_with_inprocessor(data_loader=exp_iter_data_loader,\n",
    "                              experiment_seed=experiment_seed,\n",
    "                              test_set_fraction=TEST_SET_FRACTION,\n",
    "                              db_writer_func=db_writer_func,\n",
    "                              fair_intervention_params_lst=FAIR_INTERVENTION_PARAMS_LST,\n",
    "                              metrics_computation_config=metrics_computation_config,\n",
    "                              custom_table_fields_dct=custom_table_fields_dct,\n",
    "                              dataset_name='ACSPublicCoverageDataset',\n",
    "                              inprocessor_name='AdversarialDebiasing',\n",
    "                              verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce2e32e",
   "metadata": {},
   "source": [
    "### Experiment iteration 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "826896b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configs for an experiment iteration\n",
    "exp_iter_num = 2\n",
    "experiment_seed = EXPERIMENT_SEEDS[exp_iter_num - 1]\n",
    "custom_table_fields_dct['experiment_iteration'] = f'Exp_iter_{exp_iter_num}'\n",
    "exp_iter_data_loader = copy.deepcopy(data_loader)  # Add deepcopy to avoid data leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4afaeb6c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-04T20:53:56.249510Z",
     "start_time": "2024-01-04T20:53:56.233525Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-08 21:56:06 experiment_interface.py INFO    : Start an experiment iteration for the following custom params:\n",
      "INFO:root:Start an experiment iteration for the following custom params:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataset_split_seed': 200,\n",
      " 'experiment_iteration': 'Exp_iter_2',\n",
      " 'fair_intervention_params_lst': \"['debiased_classifier']\",\n",
      " 'model_init_seed': 200,\n",
      " 'session_uuid': 'bf843ff8-62e9-4aac-83bc-d805e3299fdc'}\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb933b4632f547a3ba8301fd5364c345",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Multiple alphas:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-08 21:56:06 experiment_interface.py INFO    : The dataset is preprocessed\n",
      "INFO:root:The dataset is preprocessed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intervention_option:  debiased_classifier\n",
      "cur_base_flow_dataset.X_train_val.columns:  Index(['cat__SCHL_1', 'cat__SCHL_10', 'cat__SCHL_11', 'cat__SCHL_12',\n",
      "       'cat__SCHL_13', 'cat__SCHL_14', 'cat__SCHL_15', 'cat__SCHL_16',\n",
      "       'cat__SCHL_17', 'cat__SCHL_18', 'cat__SCHL_19', 'cat__SCHL_2',\n",
      "       'cat__SCHL_20', 'cat__SCHL_21', 'cat__SCHL_22', 'cat__SCHL_23',\n",
      "       'cat__SCHL_24', 'cat__SCHL_3', 'cat__SCHL_4', 'cat__SCHL_5',\n",
      "       'cat__SCHL_6', 'cat__SCHL_7', 'cat__SCHL_8', 'cat__SCHL_9',\n",
      "       'cat__MAR_1', 'cat__MAR_2', 'cat__MAR_3', 'cat__MAR_4', 'cat__MAR_5',\n",
      "       'cat__DIS_1', 'cat__DIS_2', 'cat__ESP_0', 'cat__ESP_1', 'cat__ESP_2',\n",
      "       'cat__ESP_3', 'cat__ESP_4', 'cat__ESP_5', 'cat__ESP_6', 'cat__ESP_7',\n",
      "       'cat__ESP_8', 'cat__CIT_1', 'cat__CIT_2', 'cat__CIT_3', 'cat__CIT_4',\n",
      "       'cat__CIT_5', 'cat__MIG_1', 'cat__MIG_2', 'cat__MIG_3', 'cat__MIL_0',\n",
      "       'cat__MIL_1', 'cat__MIL_2', 'cat__MIL_3', 'cat__MIL_4', 'cat__ANC_1',\n",
      "       'cat__ANC_2', 'cat__ANC_3', 'cat__ANC_4', 'cat__NATIVITY_1',\n",
      "       'cat__NATIVITY_2', 'cat__DEAR_1', 'cat__DEAR_2', 'cat__DEYE_1',\n",
      "       'cat__DEYE_2', 'cat__DREM_1', 'cat__DREM_2', 'cat__ESR_0', 'cat__ESR_1',\n",
      "       'cat__ESR_2', 'cat__ESR_3', 'cat__ESR_4', 'cat__ESR_6', 'cat__ST_6',\n",
      "       'cat__FER_0', 'cat__FER_1', 'cat__FER_2', 'num__AGEP', 'num__PINCP',\n",
      "       'SEX&RAC1P_binary'],\n",
      "      dtype='object')\n",
      "Top indexes of an X_test in the current base flow dataset:  Int64Index([ 6043,  3745,  5159,  7241,  7820,  3695, 11501, 11432,  1163,\n",
      "             8994,  7972,  2554,  9884,  2008,  6884, 11995,  5200,  4649,\n",
      "            10244, 13775],\n",
      "           dtype='int64')\n",
      "Top indexes of an y_test in the current base flow dataset:  Int64Index([ 6043,  3745,  5159,  7241,  7820,  3695, 11501, 11432,  1163,\n",
      "             8994,  7972,  2554,  9884,  2008,  6884, 11995,  5200,  4649,\n",
      "            10244, 13775],\n",
      "           dtype='int64')\n",
      "Using AdversarialDebiasing postprocessor\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76fe8f8b2384482bacdbfb5f813ffc86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyze multiple models:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dce3377f82a7496e821f1474f8b313b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/dh3553/.local/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:1176: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/dh3553/.local/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:1176: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.792746; batch adversarial loss: 1.005012\n",
      "epoch 1; iter: 0; batch classifier loss: 0.949620; batch adversarial loss: 1.258500\n",
      "epoch 2; iter: 0; batch classifier loss: 1.028043; batch adversarial loss: 1.144422\n",
      "epoch 3; iter: 0; batch classifier loss: 1.045848; batch adversarial loss: 1.075771\n",
      "epoch 4; iter: 0; batch classifier loss: 0.997219; batch adversarial loss: 0.978551\n",
      "epoch 5; iter: 0; batch classifier loss: 0.916257; batch adversarial loss: 0.886703\n",
      "epoch 6; iter: 0; batch classifier loss: 0.807742; batch adversarial loss: 0.777476\n",
      "epoch 7; iter: 0; batch classifier loss: 0.756174; batch adversarial loss: 0.765084\n",
      "epoch 8; iter: 0; batch classifier loss: 0.751323; batch adversarial loss: 0.715508\n",
      "epoch 9; iter: 0; batch classifier loss: 0.661528; batch adversarial loss: 0.746465\n",
      "epoch 10; iter: 0; batch classifier loss: 0.532497; batch adversarial loss: 0.583311\n",
      "epoch 11; iter: 0; batch classifier loss: 0.556063; batch adversarial loss: 0.609865\n",
      "epoch 12; iter: 0; batch classifier loss: 0.509892; batch adversarial loss: 0.630546\n",
      "epoch 13; iter: 0; batch classifier loss: 0.474373; batch adversarial loss: 0.588323\n",
      "epoch 14; iter: 0; batch classifier loss: 0.566039; batch adversarial loss: 0.598633\n",
      "epoch 15; iter: 0; batch classifier loss: 0.544423; batch adversarial loss: 0.595941\n",
      "epoch 16; iter: 0; batch classifier loss: 0.478303; batch adversarial loss: 0.716907\n",
      "epoch 17; iter: 0; batch classifier loss: 0.506884; batch adversarial loss: 0.531912\n",
      "epoch 18; iter: 0; batch classifier loss: 0.484061; batch adversarial loss: 0.641703\n",
      "epoch 19; iter: 0; batch classifier loss: 0.484366; batch adversarial loss: 0.609042\n",
      "epoch 20; iter: 0; batch classifier loss: 0.496752; batch adversarial loss: 0.581835\n",
      "epoch 21; iter: 0; batch classifier loss: 0.515339; batch adversarial loss: 0.610445\n",
      "epoch 22; iter: 0; batch classifier loss: 0.452971; batch adversarial loss: 0.628669\n"
     ]
    }
   ],
   "source": [
    "run_exp_iter_with_inprocessor(data_loader=exp_iter_data_loader,\n",
    "                              experiment_seed=experiment_seed,\n",
    "                              test_set_fraction=TEST_SET_FRACTION,\n",
    "                              db_writer_func=db_writer_func,\n",
    "                              fair_intervention_params_lst=FAIR_INTERVENTION_PARAMS_LST,\n",
    "                              metrics_computation_config=metrics_computation_config,\n",
    "                              custom_table_fields_dct=custom_table_fields_dct,\n",
    "                              dataset_name='ACSPublicCoverageDataset',\n",
    "                              inprocessor_name='AdversarialDebiasing',\n",
    "                              verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223b03d2",
   "metadata": {},
   "source": [
    "### Experiment iteration 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b92bb8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configs for an experiment iteration\n",
    "exp_iter_num = 3\n",
    "experiment_seed = EXPERIMENT_SEEDS[exp_iter_num - 1]\n",
    "custom_table_fields_dct['experiment_iteration'] = f'Exp_iter_{exp_iter_num}'\n",
    "exp_iter_data_loader = copy.deepcopy(data_loader)  # Add deepcopy to avoid data leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d0609ba2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-04T20:53:46.750905Z",
     "start_time": "2024-01-04T20:53:46.744795Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-04 19:29:01 experiment_interface.py INFO    : Start an experiment iteration for the following custom params:\n",
      "INFO:root:Start an experiment iteration for the following custom params:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataset_split_seed': 300,\n",
      " 'experiment_iteration': 'Exp_iter_3',\n",
      " 'fair_intervention_params_lst': '[True]',\n",
      " 'model_init_seed': 300,\n",
      " 'session_uuid': '0626d80f-e288-4f16-b8ab-260eb34d62d3'}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b48b0aa26f024ad1b1089190e134193d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Multiple alphas:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-04 19:29:01 experiment_interface.py INFO    : The dataset is preprocessed\n",
      "INFO:root:The dataset is preprocessed\n",
      "2024-01-04 19:29:01 experiment_interface.py INFO    : Models config is loaded from the input file\n",
      "INFO:root:Models config is loaded from the input file\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intervention_option:  True\n",
      "Using ROC postprocessor\n",
      "cur_base_flow_dataset.X_train_val.columns:  Index(['cat__school_GP', 'cat__school_MS', 'cat__address_R', 'cat__address_U',\n",
      "       'cat__famsize_GT3', 'cat__famsize_LE3', 'cat__Pstatus_A',\n",
      "       'cat__Pstatus_T', 'cat__Mjob_at_home', 'cat__Mjob_health',\n",
      "       'cat__Mjob_other', 'cat__Mjob_services', 'cat__Mjob_teacher',\n",
      "       'cat__Fjob_at_home', 'cat__Fjob_health', 'cat__Fjob_other',\n",
      "       'cat__Fjob_services', 'cat__Fjob_teacher', 'cat__reason_course',\n",
      "       'cat__reason_home', 'cat__reason_other', 'cat__reason_reputation',\n",
      "       'cat__guardian_father', 'cat__guardian_mother', 'cat__guardian_other',\n",
      "       'cat__schoolsup_no', 'cat__schoolsup_yes', 'cat__famsup_no',\n",
      "       'cat__famsup_yes', 'cat__paid_no', 'cat__paid_yes',\n",
      "       'cat__activities_no', 'cat__activities_yes', 'cat__nursery_no',\n",
      "       'cat__nursery_yes', 'cat__higher_no', 'cat__higher_yes',\n",
      "       'cat__internet_no', 'cat__internet_yes', 'cat__romantic_no',\n",
      "       'cat__romantic_yes', 'num__age', 'num__Medu', 'num__Fedu',\n",
      "       'num__traveltime', 'num__studytime', 'num__failures', 'num__famrel',\n",
      "       'num__freetime', 'num__goout', 'num__Dalc', 'num__Walc', 'num__health',\n",
      "       'num__absences', 'num__G1', 'num__G2', 'sex_binary'],\n",
      "      dtype='object')\n",
      "Top indexes of an X_test in the current base flow dataset:  Int64Index([250, 438, 479, 326,  46, 565, 534, 382, 377, 457,  97, 388, 123,\n",
      "            156, 430, 466,  38, 474, 167, 524],\n",
      "           dtype='int64')\n",
      "Top indexes of an y_test in the current base flow dataset:  Int64Index([250, 438, 479, 326,  46, 565, 534, 382, 377, 457,  97, 388, 123,\n",
      "            156, 430, 466,  38, 474, 167, 524],\n",
      "           dtype='int64')\n",
      "Path for tuned params:  /home/dh3553/projects/fairness-variance/results/diff_fairness_interventions_exp/ROC/ROC_student_performance/tuning_results_Student_Performance_Por_20240104__212802.csv\n",
      "LGBMClassifier:  {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': 3, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 20, 'objective': None, 'random_state': 300, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'min_data_in_leaf': 100}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9eddcae8f6fc4651885a3144088ae9d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyze multiple models:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabled a postprocessing mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d43ba8d965cc436a91f10cc39b3d5e5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "Enabled a postprocessing mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e94495e7bec64c9ebf4c05cdd52e605d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabled a postprocessing mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28f7167dd20740a68f8f90158ec19560",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run_exp_iter_with_inprocessor(data_loader=exp_iter_data_loader,\n",
    "                              experiment_seed=experiment_seed,\n",
    "                              test_set_fraction=TEST_SET_FRACTION,\n",
    "                              db_writer_func=db_writer_func,\n",
    "                              fair_intervention_params_lst=FAIR_INTERVENTION_PARAMS_LST,\n",
    "                              metrics_computation_config=metrics_computation_config,\n",
    "                              custom_table_fields_dct=custom_table_fields_dct,\n",
    "                              dataset_name='ACSPublicCoverageDataset',\n",
    "                              inprocessor_name='AdversarialDebiasing',\n",
    "                              verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1767a93f",
   "metadata": {},
   "source": [
    "### Experiment iteration 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fd63d15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configs for an experiment iteration\n",
    "exp_iter_num = 4\n",
    "experiment_seed = EXPERIMENT_SEEDS[exp_iter_num - 1]\n",
    "custom_table_fields_dct['experiment_iteration'] = f'Exp_iter_{exp_iter_num}'\n",
    "exp_iter_data_loader = copy.deepcopy(data_loader)  # Add deepcopy to avoid data leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e3fd4c4d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-04T20:53:37.675129Z",
     "start_time": "2024-01-04T20:53:37.670178Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-04 20:15:17 experiment_interface.py INFO    : Start an experiment iteration for the following custom params:\n",
      "INFO:root:Start an experiment iteration for the following custom params:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataset_split_seed': 400,\n",
      " 'experiment_iteration': 'Exp_iter_4',\n",
      " 'fair_intervention_params_lst': '[True]',\n",
      " 'intervention_param': 'True',\n",
      " 'model_init_seed': 400,\n",
      " 'session_uuid': '0626d80f-e288-4f16-b8ab-260eb34d62d3'}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c5b534568b14897b8686d22a9c79d2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Multiple alphas:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-04 20:15:17 experiment_interface.py INFO    : The dataset is preprocessed\n",
      "INFO:root:The dataset is preprocessed\n",
      "2024-01-04 20:15:17 experiment_interface.py INFO    : Models config is loaded from the input file\n",
      "INFO:root:Models config is loaded from the input file\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intervention_option:  True\n",
      "Using ROC postprocessor\n",
      "cur_base_flow_dataset.X_train_val.columns:  Index(['cat__school_GP', 'cat__school_MS', 'cat__address_R', 'cat__address_U',\n",
      "       'cat__famsize_GT3', 'cat__famsize_LE3', 'cat__Pstatus_A',\n",
      "       'cat__Pstatus_T', 'cat__Mjob_at_home', 'cat__Mjob_health',\n",
      "       'cat__Mjob_other', 'cat__Mjob_services', 'cat__Mjob_teacher',\n",
      "       'cat__Fjob_at_home', 'cat__Fjob_health', 'cat__Fjob_other',\n",
      "       'cat__Fjob_services', 'cat__Fjob_teacher', 'cat__reason_course',\n",
      "       'cat__reason_home', 'cat__reason_other', 'cat__reason_reputation',\n",
      "       'cat__guardian_father', 'cat__guardian_mother', 'cat__guardian_other',\n",
      "       'cat__schoolsup_no', 'cat__schoolsup_yes', 'cat__famsup_no',\n",
      "       'cat__famsup_yes', 'cat__paid_no', 'cat__paid_yes',\n",
      "       'cat__activities_no', 'cat__activities_yes', 'cat__nursery_no',\n",
      "       'cat__nursery_yes', 'cat__higher_no', 'cat__higher_yes',\n",
      "       'cat__internet_no', 'cat__internet_yes', 'cat__romantic_no',\n",
      "       'cat__romantic_yes', 'num__age', 'num__Medu', 'num__Fedu',\n",
      "       'num__traveltime', 'num__studytime', 'num__failures', 'num__famrel',\n",
      "       'num__freetime', 'num__goout', 'num__Dalc', 'num__Walc', 'num__health',\n",
      "       'num__absences', 'num__G1', 'num__G2', 'sex_binary'],\n",
      "      dtype='object')\n",
      "Top indexes of an X_test in the current base flow dataset:  Int64Index([331, 157, 559, 553, 580, 169, 561, 452, 180, 257, 160, 289, 197,\n",
      "             39, 290,  68,  56, 638,  54, 120],\n",
      "           dtype='int64')\n",
      "Top indexes of an y_test in the current base flow dataset:  Int64Index([331, 157, 559, 553, 580, 169, 561, 452, 180, 257, 160, 289, 197,\n",
      "             39, 290,  68,  56, 638,  54, 120],\n",
      "           dtype='int64')\n",
      "Path for tuned params:  /home/dh3553/projects/fairness-variance/results/diff_fairness_interventions_exp/ROC/ROC_student_performance/tuning_results_Student_Performance_Por_20240104__212802.csv\n",
      "LGBMClassifier:  {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': 3, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 20, 'objective': None, 'random_state': 400, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'min_data_in_leaf': 100}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42164aebf0d74a5992f0ca8075639200",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyze multiple models:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabled a postprocessing mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0a128a0a62f40fb9bd0b88e41d55103",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "Enabled a postprocessing mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6300cf6db9cc4bcf95389b1f6e9b8108",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabled a postprocessing mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24e75feb8b5c4e00a1fc551544462dcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run_exp_iter_with_inprocessor(data_loader=exp_iter_data_loader,\n",
    "                              experiment_seed=experiment_seed,\n",
    "                              test_set_fraction=TEST_SET_FRACTION,\n",
    "                              db_writer_func=db_writer_func,\n",
    "                              fair_intervention_params_lst=FAIR_INTERVENTION_PARAMS_LST,\n",
    "                              metrics_computation_config=metrics_computation_config,\n",
    "                              custom_table_fields_dct=custom_table_fields_dct,\n",
    "                              dataset_name='ACSPublicCoverageDataset',\n",
    "                              inprocessor_name='AdversarialDebiasing',\n",
    "                              verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45ed1b9",
   "metadata": {},
   "source": [
    "### Experiment iteration 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2be104a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configs for an experiment iteration\n",
    "exp_iter_num = 5\n",
    "experiment_seed = EXPERIMENT_SEEDS[exp_iter_num - 1]\n",
    "custom_table_fields_dct['experiment_iteration'] = f'Exp_iter_{exp_iter_num}'\n",
    "exp_iter_data_loader = copy.deepcopy(data_loader)  # Add deepcopy to avoid data leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9e1f2bb2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-04T20:53:27.080554Z",
     "start_time": "2024-01-04T20:53:27.072313Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-05 03:55:49 experiment_interface.py INFO    : Start an experiment iteration for the following custom params:\n",
      "INFO:root:Start an experiment iteration for the following custom params:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataset_split_seed': 500,\n",
      " 'experiment_iteration': 'Exp_iter_5',\n",
      " 'fair_intervention_params_lst': '[True]',\n",
      " 'model_init_seed': 500,\n",
      " 'session_uuid': '0626d80f-e288-4f16-b8ab-260eb34d62d3'}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc8257cfd4f743e8887bbc74613694af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Multiple alphas:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-05 03:55:49 experiment_interface.py INFO    : The dataset is preprocessed\n",
      "INFO:root:The dataset is preprocessed\n",
      "2024-01-05 03:55:49 experiment_interface.py INFO    : Models config is loaded from the input file\n",
      "INFO:root:Models config is loaded from the input file\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intervention_option:  True\n",
      "Using ROC postprocessor\n",
      "cur_base_flow_dataset.X_train_val.columns:  Index(['cat__school_GP', 'cat__school_MS', 'cat__address_R', 'cat__address_U',\n",
      "       'cat__famsize_GT3', 'cat__famsize_LE3', 'cat__Pstatus_A',\n",
      "       'cat__Pstatus_T', 'cat__Mjob_at_home', 'cat__Mjob_health',\n",
      "       'cat__Mjob_other', 'cat__Mjob_services', 'cat__Mjob_teacher',\n",
      "       'cat__Fjob_at_home', 'cat__Fjob_health', 'cat__Fjob_other',\n",
      "       'cat__Fjob_services', 'cat__Fjob_teacher', 'cat__reason_course',\n",
      "       'cat__reason_home', 'cat__reason_other', 'cat__reason_reputation',\n",
      "       'cat__guardian_father', 'cat__guardian_mother', 'cat__guardian_other',\n",
      "       'cat__schoolsup_no', 'cat__schoolsup_yes', 'cat__famsup_no',\n",
      "       'cat__famsup_yes', 'cat__paid_no', 'cat__paid_yes',\n",
      "       'cat__activities_no', 'cat__activities_yes', 'cat__nursery_no',\n",
      "       'cat__nursery_yes', 'cat__higher_no', 'cat__higher_yes',\n",
      "       'cat__internet_no', 'cat__internet_yes', 'cat__romantic_no',\n",
      "       'cat__romantic_yes', 'num__age', 'num__Medu', 'num__Fedu',\n",
      "       'num__traveltime', 'num__studytime', 'num__failures', 'num__famrel',\n",
      "       'num__freetime', 'num__goout', 'num__Dalc', 'num__Walc', 'num__health',\n",
      "       'num__absences', 'num__G1', 'num__G2', 'sex_binary'],\n",
      "      dtype='object')\n",
      "Top indexes of an X_test in the current base flow dataset:  Int64Index([ 92, 640, 589, 519, 377, 478, 298, 336, 149, 278, 343, 573, 365,\n",
      "            174, 171, 219, 469, 162, 567, 203],\n",
      "           dtype='int64')\n",
      "Top indexes of an y_test in the current base flow dataset:  Int64Index([ 92, 640, 589, 519, 377, 478, 298, 336, 149, 278, 343, 573, 365,\n",
      "            174, 171, 219, 469, 162, 567, 203],\n",
      "           dtype='int64')\n",
      "Path for tuned params:  /home/dh3553/projects/fairness-variance/results/diff_fairness_interventions_exp/ROC/ROC_student_performance/tuning_results_Student_Performance_Por_20240104__212802.csv\n",
      "LGBMClassifier:  {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': 3, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 20, 'objective': None, 'random_state': 500, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'min_data_in_leaf': 100}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b2d40e5f54c4d67bf9f1e66289ae23a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyze multiple models:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabled a postprocessing mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63535df3c576469e9e855b70194bc572",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "Enabled a postprocessing mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15688b8597f74cdaadb60cc93599720c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabled a postprocessing mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3165f4884fae4f29829de3acc475dac4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run_exp_iter_with_inprocessor(data_loader=exp_iter_data_loader,\n",
    "                              experiment_seed=experiment_seed,\n",
    "                              test_set_fraction=TEST_SET_FRACTION,\n",
    "                              db_writer_func=db_writer_func,\n",
    "                              fair_intervention_params_lst=FAIR_INTERVENTION_PARAMS_LST,\n",
    "                              metrics_computation_config=metrics_computation_config,\n",
    "                              custom_table_fields_dct=custom_table_fields_dct,\n",
    "                              dataset_name='ACSPublicCoverageDataset',\n",
    "                              inprocessor_name='AdversarialDebiasing',\n",
    "                              verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ac40d2",
   "metadata": {},
   "source": [
    "### Experiment iteration 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1ab64f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configs for an experiment iteration\n",
    "exp_iter_num = 6\n",
    "experiment_seed = EXPERIMENT_SEEDS[exp_iter_num - 1]\n",
    "custom_table_fields_dct['experiment_iteration'] = f'Exp_iter_{exp_iter_num}'\n",
    "exp_iter_data_loader = copy.deepcopy(data_loader)  # Add deepcopy to avoid data leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fdc5c9d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-04T20:53:16.632770Z",
     "start_time": "2024-01-04T20:53:16.629083Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-08 21:58:14 experiment_interface.py INFO    : Start an experiment iteration for the following custom params:\n",
      "INFO:root:Start an experiment iteration for the following custom params:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataset_split_seed': 600,\n",
      " 'experiment_iteration': 'Exp_iter_6',\n",
      " 'fair_intervention_params_lst': \"['debiased_classifier']\",\n",
      " 'model_init_seed': 600,\n",
      " 'session_uuid': 'bf843ff8-62e9-4aac-83bc-d805e3299fdc'}\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dea47921807e43cea3f06c178041a84c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Multiple alphas:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-08 21:58:14 experiment_interface.py INFO    : The dataset is preprocessed\n",
      "INFO:root:The dataset is preprocessed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intervention_option:  debiased_classifier\n",
      "cur_base_flow_dataset.X_train_val.columns:  Index(['cat__SCHL_1', 'cat__SCHL_10', 'cat__SCHL_11', 'cat__SCHL_12',\n",
      "       'cat__SCHL_13', 'cat__SCHL_14', 'cat__SCHL_15', 'cat__SCHL_16',\n",
      "       'cat__SCHL_17', 'cat__SCHL_18', 'cat__SCHL_19', 'cat__SCHL_2',\n",
      "       'cat__SCHL_20', 'cat__SCHL_21', 'cat__SCHL_22', 'cat__SCHL_23',\n",
      "       'cat__SCHL_24', 'cat__SCHL_3', 'cat__SCHL_4', 'cat__SCHL_5',\n",
      "       'cat__SCHL_6', 'cat__SCHL_7', 'cat__SCHL_8', 'cat__SCHL_9',\n",
      "       'cat__MAR_1', 'cat__MAR_2', 'cat__MAR_3', 'cat__MAR_4', 'cat__MAR_5',\n",
      "       'cat__DIS_1', 'cat__DIS_2', 'cat__ESP_0', 'cat__ESP_1', 'cat__ESP_2',\n",
      "       'cat__ESP_3', 'cat__ESP_4', 'cat__ESP_5', 'cat__ESP_6', 'cat__ESP_7',\n",
      "       'cat__ESP_8', 'cat__CIT_1', 'cat__CIT_2', 'cat__CIT_3', 'cat__CIT_4',\n",
      "       'cat__CIT_5', 'cat__MIG_1', 'cat__MIG_2', 'cat__MIG_3', 'cat__MIL_0',\n",
      "       'cat__MIL_1', 'cat__MIL_2', 'cat__MIL_3', 'cat__MIL_4', 'cat__ANC_1',\n",
      "       'cat__ANC_2', 'cat__ANC_3', 'cat__ANC_4', 'cat__NATIVITY_1',\n",
      "       'cat__NATIVITY_2', 'cat__DEAR_1', 'cat__DEAR_2', 'cat__DEYE_1',\n",
      "       'cat__DEYE_2', 'cat__DREM_1', 'cat__DREM_2', 'cat__ESR_0', 'cat__ESR_1',\n",
      "       'cat__ESR_2', 'cat__ESR_3', 'cat__ESR_4', 'cat__ESR_6', 'cat__ST_6',\n",
      "       'cat__FER_0', 'cat__FER_1', 'cat__FER_2', 'num__AGEP', 'num__PINCP',\n",
      "       'SEX&RAC1P_binary'],\n",
      "      dtype='object')\n",
      "Top indexes of an X_test in the current base flow dataset:  Int64Index([ 2649,  1964, 14464,  4377, 14152,  5747,  1529, 10243, 12578,\n",
      "             9794,  7142, 14347,  6387,  2917,   317,  9085,  5821, 11007,\n",
      "             8142,  3719],\n",
      "           dtype='int64')\n",
      "Top indexes of an y_test in the current base flow dataset:  Int64Index([ 2649,  1964, 14464,  4377, 14152,  5747,  1529, 10243, 12578,\n",
      "             9794,  7142, 14347,  6387,  2917,   317,  9085,  5821, 11007,\n",
      "             8142,  3719],\n",
      "           dtype='int64')\n",
      "Using AdversarialDebiasing postprocessor\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f40673206e746a098312a4fa3e23096",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyze multiple models:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cdffc8964a44ef18a83702c6de0fbf1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/dh3553/.local/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:1176: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/dh3553/.local/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:1176: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.743791; batch adversarial loss: 0.585783\n",
      "epoch 1; iter: 0; batch classifier loss: 0.619866; batch adversarial loss: 0.673092\n",
      "epoch 2; iter: 0; batch classifier loss: 0.569888; batch adversarial loss: 0.648727\n",
      "epoch 3; iter: 0; batch classifier loss: 0.537374; batch adversarial loss: 0.682055\n",
      "epoch 4; iter: 0; batch classifier loss: 0.566032; batch adversarial loss: 0.683686\n",
      "epoch 5; iter: 0; batch classifier loss: 0.613524; batch adversarial loss: 0.549116\n",
      "epoch 6; iter: 0; batch classifier loss: 0.591349; batch adversarial loss: 0.578852\n",
      "epoch 7; iter: 0; batch classifier loss: 0.533006; batch adversarial loss: 0.579092\n",
      "epoch 8; iter: 0; batch classifier loss: 0.578611; batch adversarial loss: 0.586115\n",
      "epoch 9; iter: 0; batch classifier loss: 0.470616; batch adversarial loss: 0.592565\n",
      "epoch 10; iter: 0; batch classifier loss: 0.519969; batch adversarial loss: 0.582356\n",
      "epoch 11; iter: 0; batch classifier loss: 0.480384; batch adversarial loss: 0.560966\n",
      "epoch 12; iter: 0; batch classifier loss: 0.512319; batch adversarial loss: 0.604491\n",
      "epoch 13; iter: 0; batch classifier loss: 0.521245; batch adversarial loss: 0.608929\n",
      "epoch 14; iter: 0; batch classifier loss: 0.543935; batch adversarial loss: 0.612351\n",
      "epoch 15; iter: 0; batch classifier loss: 0.428902; batch adversarial loss: 0.607320\n",
      "epoch 16; iter: 0; batch classifier loss: 0.578667; batch adversarial loss: 0.506694\n",
      "epoch 17; iter: 0; batch classifier loss: 0.465730; batch adversarial loss: 0.547055\n",
      "epoch 18; iter: 0; batch classifier loss: 0.460382; batch adversarial loss: 0.578516\n",
      "epoch 19; iter: 0; batch classifier loss: 0.542658; batch adversarial loss: 0.513202\n",
      "epoch 20; iter: 0; batch classifier loss: 0.539594; batch adversarial loss: 0.547689\n",
      "epoch 21; iter: 0; batch classifier loss: 0.469782; batch adversarial loss: 0.601697\n",
      "epoch 22; iter: 0; batch classifier loss: 0.510363; batch adversarial loss: 0.469505\n",
      "epoch 23; iter: 0; batch classifier loss: 0.422137; batch adversarial loss: 0.588444\n",
      "epoch 24; iter: 0; batch classifier loss: 0.499501; batch adversarial loss: 0.614083\n",
      "epoch 25; iter: 0; batch classifier loss: 0.456277; batch adversarial loss: 0.543647\n",
      "epoch 26; iter: 0; batch classifier loss: 0.484654; batch adversarial loss: 0.526847\n",
      "epoch 27; iter: 0; batch classifier loss: 0.393566; batch adversarial loss: 0.587766\n",
      "epoch 28; iter: 0; batch classifier loss: 0.497976; batch adversarial loss: 0.594803\n",
      "epoch 29; iter: 0; batch classifier loss: 0.443569; batch adversarial loss: 0.596772\n",
      "epoch 30; iter: 0; batch classifier loss: 0.436488; batch adversarial loss: 0.632437\n",
      "epoch 31; iter: 0; batch classifier loss: 0.470954; batch adversarial loss: 0.579674\n",
      "epoch 32; iter: 0; batch classifier loss: 0.438682; batch adversarial loss: 0.511228\n",
      "epoch 33; iter: 0; batch classifier loss: 0.431260; batch adversarial loss: 0.535844\n",
      "epoch 34; iter: 0; batch classifier loss: 0.371744; batch adversarial loss: 0.535630\n",
      "epoch 35; iter: 0; batch classifier loss: 0.395653; batch adversarial loss: 0.588205\n",
      "epoch 36; iter: 0; batch classifier loss: 0.375873; batch adversarial loss: 0.510397\n",
      "epoch 37; iter: 0; batch classifier loss: 0.442849; batch adversarial loss: 0.605754\n",
      "epoch 38; iter: 0; batch classifier loss: 0.477858; batch adversarial loss: 0.571221\n",
      "epoch 39; iter: 0; batch classifier loss: 0.429505; batch adversarial loss: 0.483264\n",
      "epoch 40; iter: 0; batch classifier loss: 0.465448; batch adversarial loss: 0.518022\n",
      "epoch 41; iter: 0; batch classifier loss: 0.438667; batch adversarial loss: 0.553714\n",
      "epoch 42; iter: 0; batch classifier loss: 0.502986; batch adversarial loss: 0.604098\n",
      "epoch 43; iter: 0; batch classifier loss: 0.393021; batch adversarial loss: 0.607293\n",
      "epoch 44; iter: 0; batch classifier loss: 0.478533; batch adversarial loss: 0.615481\n",
      "epoch 45; iter: 0; batch classifier loss: 0.420826; batch adversarial loss: 0.570921\n",
      "epoch 46; iter: 0; batch classifier loss: 0.426349; batch adversarial loss: 0.609599\n",
      "epoch 47; iter: 0; batch classifier loss: 0.475564; batch adversarial loss: 0.573622\n",
      "epoch 48; iter: 0; batch classifier loss: 0.453361; batch adversarial loss: 0.583690\n",
      "epoch 49; iter: 0; batch classifier loss: 0.466501; batch adversarial loss: 0.575320\n",
      "epoch 50; iter: 0; batch classifier loss: 0.479162; batch adversarial loss: 0.517235\n",
      "epoch 51; iter: 0; batch classifier loss: 0.458562; batch adversarial loss: 0.562298\n",
      "epoch 52; iter: 0; batch classifier loss: 0.354458; batch adversarial loss: 0.583749\n",
      "epoch 53; iter: 0; batch classifier loss: 0.445479; batch adversarial loss: 0.529694\n",
      "epoch 54; iter: 0; batch classifier loss: 0.447125; batch adversarial loss: 0.551569\n",
      "epoch 55; iter: 0; batch classifier loss: 0.426533; batch adversarial loss: 0.554822\n",
      "epoch 56; iter: 0; batch classifier loss: 0.411761; batch adversarial loss: 0.505619\n",
      "epoch 57; iter: 0; batch classifier loss: 0.450896; batch adversarial loss: 0.472321\n",
      "epoch 58; iter: 0; batch classifier loss: 0.413493; batch adversarial loss: 0.592221\n",
      "epoch 59; iter: 0; batch classifier loss: 0.385466; batch adversarial loss: 0.513130\n",
      "epoch 60; iter: 0; batch classifier loss: 0.407161; batch adversarial loss: 0.598804\n",
      "epoch 61; iter: 0; batch classifier loss: 0.385357; batch adversarial loss: 0.542882\n",
      "epoch 62; iter: 0; batch classifier loss: 0.379052; batch adversarial loss: 0.514820\n",
      "epoch 63; iter: 0; batch classifier loss: 0.446164; batch adversarial loss: 0.565454\n",
      "epoch 64; iter: 0; batch classifier loss: 0.421768; batch adversarial loss: 0.580927\n",
      "epoch 65; iter: 0; batch classifier loss: 0.445080; batch adversarial loss: 0.496494\n",
      "epoch 66; iter: 0; batch classifier loss: 0.383247; batch adversarial loss: 0.574136\n",
      "epoch 67; iter: 0; batch classifier loss: 0.441681; batch adversarial loss: 0.558389\n",
      "epoch 68; iter: 0; batch classifier loss: 0.430416; batch adversarial loss: 0.530591\n",
      "epoch 69; iter: 0; batch classifier loss: 0.430553; batch adversarial loss: 0.539904\n",
      "epoch 70; iter: 0; batch classifier loss: 0.455499; batch adversarial loss: 0.590282\n",
      "epoch 71; iter: 0; batch classifier loss: 0.487117; batch adversarial loss: 0.474444\n",
      "epoch 72; iter: 0; batch classifier loss: 0.367580; batch adversarial loss: 0.580673\n",
      "epoch 73; iter: 0; batch classifier loss: 0.356847; batch adversarial loss: 0.519546\n",
      "epoch 74; iter: 0; batch classifier loss: 0.458295; batch adversarial loss: 0.573749\n",
      "epoch 75; iter: 0; batch classifier loss: 0.357358; batch adversarial loss: 0.563756\n",
      "epoch 76; iter: 0; batch classifier loss: 0.430487; batch adversarial loss: 0.556350\n",
      "epoch 77; iter: 0; batch classifier loss: 0.363871; batch adversarial loss: 0.629608\n",
      "epoch 78; iter: 0; batch classifier loss: 0.498015; batch adversarial loss: 0.582835\n",
      "epoch 79; iter: 0; batch classifier loss: 0.380698; batch adversarial loss: 0.564166\n",
      "epoch 80; iter: 0; batch classifier loss: 0.454585; batch adversarial loss: 0.581017\n",
      "epoch 81; iter: 0; batch classifier loss: 0.370053; batch adversarial loss: 0.536007\n",
      "epoch 82; iter: 0; batch classifier loss: 0.350346; batch adversarial loss: 0.507281\n",
      "epoch 83; iter: 0; batch classifier loss: 0.376290; batch adversarial loss: 0.636418\n",
      "epoch 84; iter: 0; batch classifier loss: 0.469597; batch adversarial loss: 0.554932\n",
      "epoch 85; iter: 0; batch classifier loss: 0.367192; batch adversarial loss: 0.526913\n",
      "epoch 86; iter: 0; batch classifier loss: 0.349315; batch adversarial loss: 0.499507\n",
      "epoch 87; iter: 0; batch classifier loss: 0.402838; batch adversarial loss: 0.498422\n",
      "epoch 88; iter: 0; batch classifier loss: 0.480383; batch adversarial loss: 0.500550\n",
      "epoch 89; iter: 0; batch classifier loss: 0.326159; batch adversarial loss: 0.471786\n",
      "epoch 90; iter: 0; batch classifier loss: 0.312246; batch adversarial loss: 0.490448\n",
      "epoch 91; iter: 0; batch classifier loss: 0.356562; batch adversarial loss: 0.570372\n",
      "epoch 92; iter: 0; batch classifier loss: 0.365519; batch adversarial loss: 0.608317\n",
      "epoch 93; iter: 0; batch classifier loss: 0.410602; batch adversarial loss: 0.562950\n",
      "epoch 94; iter: 0; batch classifier loss: 0.388513; batch adversarial loss: 0.533720\n",
      "epoch 95; iter: 0; batch classifier loss: 0.365622; batch adversarial loss: 0.588377\n",
      "epoch 96; iter: 0; batch classifier loss: 0.349876; batch adversarial loss: 0.580987\n",
      "epoch 97; iter: 0; batch classifier loss: 0.328114; batch adversarial loss: 0.517140\n",
      "epoch 98; iter: 0; batch classifier loss: 0.357988; batch adversarial loss: 0.554646\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 99; iter: 0; batch classifier loss: 0.476689; batch adversarial loss: 0.480737\n",
      "epoch 100; iter: 0; batch classifier loss: 0.551566; batch adversarial loss: 0.489233\n",
      "epoch 101; iter: 0; batch classifier loss: 0.379301; batch adversarial loss: 0.581177\n",
      "epoch 102; iter: 0; batch classifier loss: 0.350115; batch adversarial loss: 0.534847\n",
      "epoch 103; iter: 0; batch classifier loss: 0.345105; batch adversarial loss: 0.574102\n",
      "epoch 104; iter: 0; batch classifier loss: 0.401866; batch adversarial loss: 0.617754\n",
      "epoch 105; iter: 0; batch classifier loss: 0.383639; batch adversarial loss: 0.631867\n",
      "epoch 106; iter: 0; batch classifier loss: 0.385943; batch adversarial loss: 0.525392\n",
      "epoch 107; iter: 0; batch classifier loss: 0.303950; batch adversarial loss: 0.526119\n",
      "epoch 108; iter: 0; batch classifier loss: 0.393963; batch adversarial loss: 0.527557\n",
      "epoch 109; iter: 0; batch classifier loss: 0.318282; batch adversarial loss: 0.598996\n",
      "epoch 110; iter: 0; batch classifier loss: 0.355563; batch adversarial loss: 0.625896\n",
      "epoch 111; iter: 0; batch classifier loss: 0.372730; batch adversarial loss: 0.519367\n",
      "epoch 112; iter: 0; batch classifier loss: 0.356366; batch adversarial loss: 0.616018\n",
      "epoch 113; iter: 0; batch classifier loss: 0.395447; batch adversarial loss: 0.572442\n",
      "epoch 114; iter: 0; batch classifier loss: 0.408473; batch adversarial loss: 0.581115\n",
      "epoch 115; iter: 0; batch classifier loss: 0.357365; batch adversarial loss: 0.506660\n",
      "epoch 116; iter: 0; batch classifier loss: 0.348600; batch adversarial loss: 0.563316\n",
      "epoch 117; iter: 0; batch classifier loss: 0.294799; batch adversarial loss: 0.544522\n",
      "epoch 118; iter: 0; batch classifier loss: 0.335616; batch adversarial loss: 0.515758\n",
      "epoch 119; iter: 0; batch classifier loss: 0.377308; batch adversarial loss: 0.435098\n",
      "epoch 120; iter: 0; batch classifier loss: 0.364694; batch adversarial loss: 0.555039\n",
      "epoch 121; iter: 0; batch classifier loss: 0.338905; batch adversarial loss: 0.509425\n",
      "epoch 122; iter: 0; batch classifier loss: 0.379332; batch adversarial loss: 0.571166\n",
      "epoch 123; iter: 0; batch classifier loss: 0.328209; batch adversarial loss: 0.572044\n",
      "epoch 124; iter: 0; batch classifier loss: 0.418708; batch adversarial loss: 0.536064\n",
      "epoch 125; iter: 0; batch classifier loss: 0.316798; batch adversarial loss: 0.569347\n",
      "epoch 126; iter: 0; batch classifier loss: 0.384952; batch adversarial loss: 0.571185\n",
      "epoch 127; iter: 0; batch classifier loss: 0.330899; batch adversarial loss: 0.534815\n",
      "epoch 128; iter: 0; batch classifier loss: 0.463488; batch adversarial loss: 0.562981\n",
      "epoch 129; iter: 0; batch classifier loss: 0.406024; batch adversarial loss: 0.545118\n",
      "epoch 130; iter: 0; batch classifier loss: 0.348022; batch adversarial loss: 0.562484\n",
      "epoch 131; iter: 0; batch classifier loss: 0.347025; batch adversarial loss: 0.554302\n",
      "epoch 132; iter: 0; batch classifier loss: 0.432649; batch adversarial loss: 0.533033\n",
      "epoch 133; iter: 0; batch classifier loss: 0.378668; batch adversarial loss: 0.516706\n",
      "epoch 134; iter: 0; batch classifier loss: 0.368468; batch adversarial loss: 0.570168\n",
      "epoch 135; iter: 0; batch classifier loss: 0.380296; batch adversarial loss: 0.598426\n",
      "epoch 136; iter: 0; batch classifier loss: 0.421261; batch adversarial loss: 0.562339\n",
      "epoch 137; iter: 0; batch classifier loss: 0.347157; batch adversarial loss: 0.498195\n",
      "epoch 138; iter: 0; batch classifier loss: 0.334128; batch adversarial loss: 0.534836\n",
      "epoch 139; iter: 0; batch classifier loss: 0.341519; batch adversarial loss: 0.498732\n",
      "epoch 140; iter: 0; batch classifier loss: 0.356726; batch adversarial loss: 0.535850\n",
      "epoch 141; iter: 0; batch classifier loss: 0.390322; batch adversarial loss: 0.462804\n",
      "epoch 142; iter: 0; batch classifier loss: 0.330846; batch adversarial loss: 0.534848\n",
      "epoch 143; iter: 0; batch classifier loss: 0.308248; batch adversarial loss: 0.562337\n",
      "epoch 144; iter: 0; batch classifier loss: 0.395149; batch adversarial loss: 0.535583\n",
      "epoch 145; iter: 0; batch classifier loss: 0.422675; batch adversarial loss: 0.706314\n",
      "epoch 146; iter: 0; batch classifier loss: 0.379848; batch adversarial loss: 0.590420\n",
      "epoch 147; iter: 0; batch classifier loss: 0.355604; batch adversarial loss: 0.527551\n",
      "epoch 148; iter: 0; batch classifier loss: 0.299941; batch adversarial loss: 0.571043\n",
      "epoch 149; iter: 0; batch classifier loss: 0.426479; batch adversarial loss: 0.527006\n",
      "epoch 150; iter: 0; batch classifier loss: 0.364972; batch adversarial loss: 0.519409\n",
      "epoch 151; iter: 0; batch classifier loss: 0.337643; batch adversarial loss: 0.589575\n",
      "epoch 152; iter: 0; batch classifier loss: 0.321444; batch adversarial loss: 0.523608\n",
      "epoch 153; iter: 0; batch classifier loss: 0.350581; batch adversarial loss: 0.536147\n",
      "epoch 154; iter: 0; batch classifier loss: 0.348320; batch adversarial loss: 0.625697\n",
      "epoch 155; iter: 0; batch classifier loss: 0.373278; batch adversarial loss: 0.581635\n",
      "epoch 156; iter: 0; batch classifier loss: 0.425738; batch adversarial loss: 0.525767\n",
      "epoch 157; iter: 0; batch classifier loss: 0.370744; batch adversarial loss: 0.600437\n",
      "epoch 158; iter: 0; batch classifier loss: 0.429173; batch adversarial loss: 0.562250\n",
      "epoch 159; iter: 0; batch classifier loss: 0.287771; batch adversarial loss: 0.543771\n",
      "epoch 160; iter: 0; batch classifier loss: 0.380145; batch adversarial loss: 0.598805\n",
      "epoch 161; iter: 0; batch classifier loss: 0.342757; batch adversarial loss: 0.580588\n",
      "epoch 162; iter: 0; batch classifier loss: 0.364028; batch adversarial loss: 0.480806\n",
      "epoch 163; iter: 0; batch classifier loss: 0.306418; batch adversarial loss: 0.552205\n",
      "epoch 164; iter: 0; batch classifier loss: 0.352090; batch adversarial loss: 0.489807\n",
      "epoch 165; iter: 0; batch classifier loss: 0.431381; batch adversarial loss: 0.491589\n",
      "epoch 166; iter: 0; batch classifier loss: 0.377363; batch adversarial loss: 0.569173\n",
      "epoch 167; iter: 0; batch classifier loss: 0.313038; batch adversarial loss: 0.527014\n",
      "epoch 168; iter: 0; batch classifier loss: 0.326834; batch adversarial loss: 0.525796\n",
      "epoch 169; iter: 0; batch classifier loss: 0.278730; batch adversarial loss: 0.555767\n",
      "epoch 170; iter: 0; batch classifier loss: 0.298246; batch adversarial loss: 0.551534\n",
      "epoch 171; iter: 0; batch classifier loss: 0.380121; batch adversarial loss: 0.624194\n",
      "epoch 172; iter: 0; batch classifier loss: 0.353481; batch adversarial loss: 0.481000\n",
      "epoch 173; iter: 0; batch classifier loss: 0.404390; batch adversarial loss: 0.571886\n",
      "epoch 174; iter: 0; batch classifier loss: 0.356508; batch adversarial loss: 0.480937\n",
      "epoch 175; iter: 0; batch classifier loss: 0.313074; batch adversarial loss: 0.534973\n",
      "epoch 176; iter: 0; batch classifier loss: 0.333257; batch adversarial loss: 0.573108\n",
      "epoch 177; iter: 0; batch classifier loss: 0.364398; batch adversarial loss: 0.563267\n",
      "epoch 178; iter: 0; batch classifier loss: 0.361108; batch adversarial loss: 0.517857\n",
      "epoch 179; iter: 0; batch classifier loss: 0.341315; batch adversarial loss: 0.518744\n",
      "epoch 180; iter: 0; batch classifier loss: 0.400836; batch adversarial loss: 0.498187\n",
      "epoch 181; iter: 0; batch classifier loss: 0.330130; batch adversarial loss: 0.563570\n",
      "epoch 182; iter: 0; batch classifier loss: 0.349820; batch adversarial loss: 0.517711\n",
      "epoch 183; iter: 0; batch classifier loss: 0.313900; batch adversarial loss: 0.589771\n",
      "epoch 184; iter: 0; batch classifier loss: 0.371389; batch adversarial loss: 0.523869\n",
      "epoch 185; iter: 0; batch classifier loss: 0.344039; batch adversarial loss: 0.578649\n",
      "epoch 186; iter: 0; batch classifier loss: 0.349560; batch adversarial loss: 0.481394\n",
      "epoch 187; iter: 0; batch classifier loss: 0.362894; batch adversarial loss: 0.507419\n",
      "epoch 188; iter: 0; batch classifier loss: 0.305915; batch adversarial loss: 0.551433\n",
      "epoch 189; iter: 0; batch classifier loss: 0.323328; batch adversarial loss: 0.527748\n",
      "epoch 190; iter: 0; batch classifier loss: 0.386269; batch adversarial loss: 0.625422\n",
      "epoch 191; iter: 0; batch classifier loss: 0.360929; batch adversarial loss: 0.544217\n",
      "epoch 192; iter: 0; batch classifier loss: 0.363570; batch adversarial loss: 0.492184\n",
      "epoch 193; iter: 0; batch classifier loss: 0.319263; batch adversarial loss: 0.618338\n",
      "epoch 194; iter: 0; batch classifier loss: 0.289289; batch adversarial loss: 0.481701\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 195; iter: 0; batch classifier loss: 0.438026; batch adversarial loss: 0.517658\n",
      "epoch 196; iter: 0; batch classifier loss: 0.357203; batch adversarial loss: 0.526593\n",
      "epoch 197; iter: 0; batch classifier loss: 0.365358; batch adversarial loss: 0.498282\n",
      "epoch 198; iter: 0; batch classifier loss: 0.390214; batch adversarial loss: 0.554625\n",
      "epoch 199; iter: 0; batch classifier loss: 0.400879; batch adversarial loss: 0.516953\n",
      "epoch 0; iter: 0; batch classifier loss: 0.673122; batch adversarial loss: 0.638534\n",
      "epoch 1; iter: 0; batch classifier loss: 0.584176; batch adversarial loss: 0.643302\n",
      "epoch 2; iter: 0; batch classifier loss: 0.571098; batch adversarial loss: 0.667758\n",
      "epoch 3; iter: 0; batch classifier loss: 0.551985; batch adversarial loss: 0.663453\n",
      "epoch 4; iter: 0; batch classifier loss: 0.566097; batch adversarial loss: 0.697117\n",
      "epoch 5; iter: 0; batch classifier loss: 0.547858; batch adversarial loss: 0.641848\n",
      "epoch 6; iter: 0; batch classifier loss: 0.516335; batch adversarial loss: 0.601031\n",
      "epoch 7; iter: 0; batch classifier loss: 0.606528; batch adversarial loss: 0.621157\n",
      "epoch 8; iter: 0; batch classifier loss: 0.488184; batch adversarial loss: 0.631404\n",
      "epoch 9; iter: 0; batch classifier loss: 0.541425; batch adversarial loss: 0.582147\n",
      "epoch 10; iter: 0; batch classifier loss: 0.612712; batch adversarial loss: 0.634127\n",
      "epoch 11; iter: 0; batch classifier loss: 0.560021; batch adversarial loss: 0.598787\n",
      "epoch 12; iter: 0; batch classifier loss: 0.590865; batch adversarial loss: 0.525293\n",
      "epoch 13; iter: 0; batch classifier loss: 0.542370; batch adversarial loss: 0.519258\n",
      "epoch 14; iter: 0; batch classifier loss: 0.513026; batch adversarial loss: 0.555171\n",
      "epoch 15; iter: 0; batch classifier loss: 0.535167; batch adversarial loss: 0.498371\n",
      "epoch 16; iter: 0; batch classifier loss: 0.484793; batch adversarial loss: 0.520722\n",
      "epoch 17; iter: 0; batch classifier loss: 0.490347; batch adversarial loss: 0.582662\n",
      "epoch 18; iter: 0; batch classifier loss: 0.538412; batch adversarial loss: 0.532368\n",
      "epoch 19; iter: 0; batch classifier loss: 0.548115; batch adversarial loss: 0.535105\n",
      "epoch 20; iter: 0; batch classifier loss: 0.454906; batch adversarial loss: 0.541814\n",
      "epoch 21; iter: 0; batch classifier loss: 0.519634; batch adversarial loss: 0.525103\n",
      "epoch 22; iter: 0; batch classifier loss: 0.456814; batch adversarial loss: 0.556905\n",
      "epoch 23; iter: 0; batch classifier loss: 0.452505; batch adversarial loss: 0.620848\n",
      "epoch 24; iter: 0; batch classifier loss: 0.387321; batch adversarial loss: 0.602627\n",
      "epoch 25; iter: 0; batch classifier loss: 0.486216; batch adversarial loss: 0.521126\n",
      "epoch 26; iter: 0; batch classifier loss: 0.479185; batch adversarial loss: 0.538152\n",
      "epoch 27; iter: 0; batch classifier loss: 0.432879; batch adversarial loss: 0.528365\n",
      "epoch 28; iter: 0; batch classifier loss: 0.572810; batch adversarial loss: 0.630518\n",
      "epoch 29; iter: 0; batch classifier loss: 0.502548; batch adversarial loss: 0.545416\n",
      "epoch 30; iter: 0; batch classifier loss: 0.392342; batch adversarial loss: 0.571108\n",
      "epoch 31; iter: 0; batch classifier loss: 0.468531; batch adversarial loss: 0.545328\n",
      "epoch 32; iter: 0; batch classifier loss: 0.431708; batch adversarial loss: 0.501654\n",
      "epoch 33; iter: 0; batch classifier loss: 0.521852; batch adversarial loss: 0.518755\n",
      "epoch 34; iter: 0; batch classifier loss: 0.465675; batch adversarial loss: 0.544657\n",
      "epoch 35; iter: 0; batch classifier loss: 0.393795; batch adversarial loss: 0.597336\n",
      "epoch 36; iter: 0; batch classifier loss: 0.470937; batch adversarial loss: 0.597216\n",
      "epoch 37; iter: 0; batch classifier loss: 0.438510; batch adversarial loss: 0.605794\n",
      "epoch 38; iter: 0; batch classifier loss: 0.398066; batch adversarial loss: 0.651090\n",
      "epoch 39; iter: 0; batch classifier loss: 0.402318; batch adversarial loss: 0.509242\n",
      "epoch 40; iter: 0; batch classifier loss: 0.388306; batch adversarial loss: 0.659831\n",
      "epoch 41; iter: 0; batch classifier loss: 0.424737; batch adversarial loss: 0.553921\n",
      "epoch 42; iter: 0; batch classifier loss: 0.446075; batch adversarial loss: 0.517958\n",
      "epoch 43; iter: 0; batch classifier loss: 0.523080; batch adversarial loss: 0.535751\n",
      "epoch 44; iter: 0; batch classifier loss: 0.523281; batch adversarial loss: 0.545910\n",
      "epoch 45; iter: 0; batch classifier loss: 0.398621; batch adversarial loss: 0.518134\n",
      "epoch 46; iter: 0; batch classifier loss: 0.487181; batch adversarial loss: 0.544583\n",
      "epoch 47; iter: 0; batch classifier loss: 0.513322; batch adversarial loss: 0.518476\n",
      "epoch 48; iter: 0; batch classifier loss: 0.428418; batch adversarial loss: 0.594313\n",
      "epoch 49; iter: 0; batch classifier loss: 0.402835; batch adversarial loss: 0.554500\n",
      "epoch 50; iter: 0; batch classifier loss: 0.388108; batch adversarial loss: 0.544747\n",
      "epoch 51; iter: 0; batch classifier loss: 0.393257; batch adversarial loss: 0.544173\n",
      "epoch 52; iter: 0; batch classifier loss: 0.367929; batch adversarial loss: 0.526373\n",
      "epoch 53; iter: 0; batch classifier loss: 0.472108; batch adversarial loss: 0.518402\n",
      "epoch 54; iter: 0; batch classifier loss: 0.476151; batch adversarial loss: 0.631934\n",
      "epoch 55; iter: 0; batch classifier loss: 0.417087; batch adversarial loss: 0.473707\n",
      "epoch 56; iter: 0; batch classifier loss: 0.420176; batch adversarial loss: 0.573553\n",
      "epoch 57; iter: 0; batch classifier loss: 0.359672; batch adversarial loss: 0.561651\n",
      "epoch 58; iter: 0; batch classifier loss: 0.433843; batch adversarial loss: 0.473439\n",
      "epoch 59; iter: 0; batch classifier loss: 0.391720; batch adversarial loss: 0.544343\n",
      "epoch 60; iter: 0; batch classifier loss: 0.421777; batch adversarial loss: 0.581771\n",
      "epoch 61; iter: 0; batch classifier loss: 0.454982; batch adversarial loss: 0.489723\n",
      "epoch 62; iter: 0; batch classifier loss: 0.416313; batch adversarial loss: 0.581178\n",
      "epoch 63; iter: 0; batch classifier loss: 0.390151; batch adversarial loss: 0.517031\n",
      "epoch 64; iter: 0; batch classifier loss: 0.398821; batch adversarial loss: 0.481551\n",
      "epoch 65; iter: 0; batch classifier loss: 0.434028; batch adversarial loss: 0.571000\n",
      "epoch 66; iter: 0; batch classifier loss: 0.506353; batch adversarial loss: 0.634817\n",
      "epoch 67; iter: 0; batch classifier loss: 0.377479; batch adversarial loss: 0.490974\n",
      "epoch 68; iter: 0; batch classifier loss: 0.426278; batch adversarial loss: 0.544277\n",
      "epoch 69; iter: 0; batch classifier loss: 0.495257; batch adversarial loss: 0.607762\n",
      "epoch 70; iter: 0; batch classifier loss: 0.374638; batch adversarial loss: 0.554388\n",
      "epoch 71; iter: 0; batch classifier loss: 0.465213; batch adversarial loss: 0.445329\n",
      "epoch 72; iter: 0; batch classifier loss: 0.447998; batch adversarial loss: 0.544003\n",
      "epoch 73; iter: 0; batch classifier loss: 0.409207; batch adversarial loss: 0.546068\n",
      "epoch 74; iter: 0; batch classifier loss: 0.411228; batch adversarial loss: 0.608265\n",
      "epoch 75; iter: 0; batch classifier loss: 0.431078; batch adversarial loss: 0.649200\n",
      "epoch 76; iter: 0; batch classifier loss: 0.340066; batch adversarial loss: 0.446399\n",
      "epoch 77; iter: 0; batch classifier loss: 0.418578; batch adversarial loss: 0.615148\n",
      "epoch 78; iter: 0; batch classifier loss: 0.402080; batch adversarial loss: 0.552980\n",
      "epoch 79; iter: 0; batch classifier loss: 0.357162; batch adversarial loss: 0.562097\n",
      "epoch 80; iter: 0; batch classifier loss: 0.302405; batch adversarial loss: 0.517548\n",
      "epoch 81; iter: 0; batch classifier loss: 0.300111; batch adversarial loss: 0.536406\n",
      "epoch 82; iter: 0; batch classifier loss: 0.431823; batch adversarial loss: 0.616288\n",
      "epoch 83; iter: 0; batch classifier loss: 0.382195; batch adversarial loss: 0.481452\n",
      "epoch 84; iter: 0; batch classifier loss: 0.348193; batch adversarial loss: 0.526142\n",
      "epoch 85; iter: 0; batch classifier loss: 0.291907; batch adversarial loss: 0.598052\n",
      "epoch 86; iter: 0; batch classifier loss: 0.369509; batch adversarial loss: 0.473040\n",
      "epoch 87; iter: 0; batch classifier loss: 0.340183; batch adversarial loss: 0.526671\n",
      "epoch 88; iter: 0; batch classifier loss: 0.391848; batch adversarial loss: 0.580383\n",
      "epoch 89; iter: 0; batch classifier loss: 0.428405; batch adversarial loss: 0.499831\n",
      "epoch 90; iter: 0; batch classifier loss: 0.361527; batch adversarial loss: 0.535895\n",
      "epoch 91; iter: 0; batch classifier loss: 0.374044; batch adversarial loss: 0.545609\n",
      "epoch 92; iter: 0; batch classifier loss: 0.411666; batch adversarial loss: 0.562302\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 93; iter: 0; batch classifier loss: 0.416307; batch adversarial loss: 0.615330\n",
      "epoch 94; iter: 0; batch classifier loss: 0.458508; batch adversarial loss: 0.633522\n",
      "epoch 95; iter: 0; batch classifier loss: 0.324230; batch adversarial loss: 0.526093\n",
      "epoch 96; iter: 0; batch classifier loss: 0.446591; batch adversarial loss: 0.617781\n",
      "epoch 97; iter: 0; batch classifier loss: 0.325362; batch adversarial loss: 0.571442\n",
      "epoch 98; iter: 0; batch classifier loss: 0.392113; batch adversarial loss: 0.545631\n",
      "epoch 99; iter: 0; batch classifier loss: 0.397684; batch adversarial loss: 0.536000\n",
      "epoch 100; iter: 0; batch classifier loss: 0.369537; batch adversarial loss: 0.676365\n",
      "epoch 101; iter: 0; batch classifier loss: 0.417615; batch adversarial loss: 0.472829\n",
      "epoch 102; iter: 0; batch classifier loss: 0.339950; batch adversarial loss: 0.640028\n",
      "epoch 103; iter: 0; batch classifier loss: 0.410169; batch adversarial loss: 0.525889\n",
      "epoch 104; iter: 0; batch classifier loss: 0.374219; batch adversarial loss: 0.536135\n",
      "epoch 105; iter: 0; batch classifier loss: 0.358258; batch adversarial loss: 0.516578\n",
      "epoch 106; iter: 0; batch classifier loss: 0.385564; batch adversarial loss: 0.637116\n",
      "epoch 107; iter: 0; batch classifier loss: 0.398185; batch adversarial loss: 0.613567\n",
      "epoch 108; iter: 0; batch classifier loss: 0.362302; batch adversarial loss: 0.543908\n",
      "epoch 109; iter: 0; batch classifier loss: 0.385912; batch adversarial loss: 0.544873\n",
      "epoch 110; iter: 0; batch classifier loss: 0.314986; batch adversarial loss: 0.519407\n",
      "epoch 111; iter: 0; batch classifier loss: 0.408125; batch adversarial loss: 0.624776\n",
      "epoch 112; iter: 0; batch classifier loss: 0.390458; batch adversarial loss: 0.626511\n",
      "epoch 113; iter: 0; batch classifier loss: 0.398043; batch adversarial loss: 0.561646\n",
      "epoch 114; iter: 0; batch classifier loss: 0.328324; batch adversarial loss: 0.529524\n",
      "epoch 115; iter: 0; batch classifier loss: 0.350549; batch adversarial loss: 0.483323\n",
      "epoch 116; iter: 0; batch classifier loss: 0.402973; batch adversarial loss: 0.517527\n",
      "epoch 117; iter: 0; batch classifier loss: 0.330153; batch adversarial loss: 0.586961\n",
      "epoch 118; iter: 0; batch classifier loss: 0.385235; batch adversarial loss: 0.552463\n",
      "epoch 119; iter: 0; batch classifier loss: 0.368921; batch adversarial loss: 0.550875\n",
      "epoch 120; iter: 0; batch classifier loss: 0.363954; batch adversarial loss: 0.579529\n",
      "epoch 121; iter: 0; batch classifier loss: 0.441604; batch adversarial loss: 0.579006\n",
      "epoch 122; iter: 0; batch classifier loss: 0.345680; batch adversarial loss: 0.475358\n",
      "epoch 123; iter: 0; batch classifier loss: 0.375075; batch adversarial loss: 0.570896\n",
      "epoch 124; iter: 0; batch classifier loss: 0.374973; batch adversarial loss: 0.630600\n",
      "epoch 125; iter: 0; batch classifier loss: 0.385568; batch adversarial loss: 0.439035\n",
      "epoch 126; iter: 0; batch classifier loss: 0.443950; batch adversarial loss: 0.508535\n",
      "epoch 127; iter: 0; batch classifier loss: 0.295864; batch adversarial loss: 0.471704\n",
      "epoch 128; iter: 0; batch classifier loss: 0.372530; batch adversarial loss: 0.581242\n",
      "epoch 129; iter: 0; batch classifier loss: 0.420345; batch adversarial loss: 0.517189\n",
      "epoch 130; iter: 0; batch classifier loss: 0.438027; batch adversarial loss: 0.670028\n",
      "epoch 131; iter: 0; batch classifier loss: 0.347660; batch adversarial loss: 0.508430\n",
      "epoch 132; iter: 0; batch classifier loss: 0.407105; batch adversarial loss: 0.571040\n",
      "epoch 133; iter: 0; batch classifier loss: 0.421068; batch adversarial loss: 0.551351\n",
      "epoch 134; iter: 0; batch classifier loss: 0.342460; batch adversarial loss: 0.572383\n",
      "epoch 135; iter: 0; batch classifier loss: 0.352390; batch adversarial loss: 0.543954\n",
      "epoch 136; iter: 0; batch classifier loss: 0.428685; batch adversarial loss: 0.625242\n",
      "epoch 137; iter: 0; batch classifier loss: 0.310502; batch adversarial loss: 0.490554\n",
      "epoch 138; iter: 0; batch classifier loss: 0.439236; batch adversarial loss: 0.591082\n",
      "epoch 139; iter: 0; batch classifier loss: 0.291525; batch adversarial loss: 0.578918\n",
      "epoch 140; iter: 0; batch classifier loss: 0.455350; batch adversarial loss: 0.633651\n",
      "epoch 141; iter: 0; batch classifier loss: 0.391320; batch adversarial loss: 0.588439\n",
      "epoch 142; iter: 0; batch classifier loss: 0.375977; batch adversarial loss: 0.552585\n",
      "epoch 143; iter: 0; batch classifier loss: 0.401879; batch adversarial loss: 0.498760\n",
      "epoch 144; iter: 0; batch classifier loss: 0.322092; batch adversarial loss: 0.570946\n",
      "epoch 145; iter: 0; batch classifier loss: 0.326786; batch adversarial loss: 0.570736\n",
      "epoch 146; iter: 0; batch classifier loss: 0.396574; batch adversarial loss: 0.578599\n",
      "epoch 147; iter: 0; batch classifier loss: 0.402271; batch adversarial loss: 0.531359\n",
      "epoch 148; iter: 0; batch classifier loss: 0.347390; batch adversarial loss: 0.528600\n",
      "epoch 149; iter: 0; batch classifier loss: 0.355731; batch adversarial loss: 0.558241\n",
      "epoch 150; iter: 0; batch classifier loss: 0.391955; batch adversarial loss: 0.579794\n",
      "epoch 151; iter: 0; batch classifier loss: 0.370998; batch adversarial loss: 0.490237\n",
      "epoch 152; iter: 0; batch classifier loss: 0.257196; batch adversarial loss: 0.644587\n",
      "epoch 153; iter: 0; batch classifier loss: 0.441894; batch adversarial loss: 0.552626\n",
      "epoch 154; iter: 0; batch classifier loss: 0.393293; batch adversarial loss: 0.572381\n",
      "epoch 155; iter: 0; batch classifier loss: 0.398811; batch adversarial loss: 0.535648\n",
      "epoch 156; iter: 0; batch classifier loss: 0.314722; batch adversarial loss: 0.615879\n",
      "epoch 157; iter: 0; batch classifier loss: 0.298528; batch adversarial loss: 0.500548\n",
      "epoch 158; iter: 0; batch classifier loss: 0.299999; batch adversarial loss: 0.536439\n",
      "epoch 159; iter: 0; batch classifier loss: 0.333671; batch adversarial loss: 0.590257\n",
      "epoch 160; iter: 0; batch classifier loss: 0.365500; batch adversarial loss: 0.472862\n",
      "epoch 161; iter: 0; batch classifier loss: 0.393001; batch adversarial loss: 0.553209\n",
      "epoch 162; iter: 0; batch classifier loss: 0.366900; batch adversarial loss: 0.579235\n",
      "epoch 163; iter: 0; batch classifier loss: 0.317062; batch adversarial loss: 0.562506\n",
      "epoch 164; iter: 0; batch classifier loss: 0.322792; batch adversarial loss: 0.509545\n",
      "epoch 165; iter: 0; batch classifier loss: 0.436332; batch adversarial loss: 0.662466\n",
      "epoch 166; iter: 0; batch classifier loss: 0.318175; batch adversarial loss: 0.453656\n",
      "epoch 167; iter: 0; batch classifier loss: 0.390321; batch adversarial loss: 0.590875\n",
      "epoch 168; iter: 0; batch classifier loss: 0.377546; batch adversarial loss: 0.571670\n",
      "epoch 169; iter: 0; batch classifier loss: 0.323015; batch adversarial loss: 0.567832\n",
      "epoch 170; iter: 0; batch classifier loss: 0.398662; batch adversarial loss: 0.569649\n",
      "epoch 171; iter: 0; batch classifier loss: 0.374331; batch adversarial loss: 0.589232\n",
      "epoch 172; iter: 0; batch classifier loss: 0.363552; batch adversarial loss: 0.552186\n",
      "epoch 173; iter: 0; batch classifier loss: 0.448183; batch adversarial loss: 0.578355\n",
      "epoch 174; iter: 0; batch classifier loss: 0.283400; batch adversarial loss: 0.524873\n",
      "epoch 175; iter: 0; batch classifier loss: 0.337379; batch adversarial loss: 0.552164\n",
      "epoch 176; iter: 0; batch classifier loss: 0.351571; batch adversarial loss: 0.597088\n",
      "epoch 177; iter: 0; batch classifier loss: 0.360298; batch adversarial loss: 0.579578\n",
      "epoch 178; iter: 0; batch classifier loss: 0.291792; batch adversarial loss: 0.615190\n",
      "epoch 179; iter: 0; batch classifier loss: 0.341999; batch adversarial loss: 0.517607\n",
      "epoch 180; iter: 0; batch classifier loss: 0.337345; batch adversarial loss: 0.562260\n",
      "epoch 181; iter: 0; batch classifier loss: 0.376980; batch adversarial loss: 0.582190\n",
      "epoch 182; iter: 0; batch classifier loss: 0.307481; batch adversarial loss: 0.536286\n",
      "epoch 183; iter: 0; batch classifier loss: 0.376022; batch adversarial loss: 0.569624\n",
      "epoch 184; iter: 0; batch classifier loss: 0.322872; batch adversarial loss: 0.587572\n",
      "epoch 185; iter: 0; batch classifier loss: 0.378612; batch adversarial loss: 0.535764\n",
      "epoch 186; iter: 0; batch classifier loss: 0.266414; batch adversarial loss: 0.590169\n",
      "epoch 187; iter: 0; batch classifier loss: 0.251317; batch adversarial loss: 0.608994\n",
      "epoch 188; iter: 0; batch classifier loss: 0.314878; batch adversarial loss: 0.632264\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 189; iter: 0; batch classifier loss: 0.373182; batch adversarial loss: 0.517480\n",
      "epoch 190; iter: 0; batch classifier loss: 0.354277; batch adversarial loss: 0.585229\n",
      "epoch 191; iter: 0; batch classifier loss: 0.367879; batch adversarial loss: 0.527344\n",
      "epoch 192; iter: 0; batch classifier loss: 0.394444; batch adversarial loss: 0.603056\n",
      "epoch 193; iter: 0; batch classifier loss: 0.299830; batch adversarial loss: 0.525123\n",
      "epoch 194; iter: 0; batch classifier loss: 0.358479; batch adversarial loss: 0.596562\n",
      "epoch 195; iter: 0; batch classifier loss: 0.391075; batch adversarial loss: 0.555675\n",
      "epoch 196; iter: 0; batch classifier loss: 0.343499; batch adversarial loss: 0.545969\n",
      "epoch 197; iter: 0; batch classifier loss: 0.373549; batch adversarial loss: 0.499919\n",
      "epoch 198; iter: 0; batch classifier loss: 0.324513; batch adversarial loss: 0.510483\n",
      "epoch 199; iter: 0; batch classifier loss: 0.381710; batch adversarial loss: 0.600552\n",
      "epoch 0; iter: 0; batch classifier loss: 0.757984; batch adversarial loss: 0.739672\n",
      "epoch 1; iter: 0; batch classifier loss: 0.662655; batch adversarial loss: 0.714978\n",
      "epoch 2; iter: 0; batch classifier loss: 0.626957; batch adversarial loss: 0.672977\n",
      "epoch 3; iter: 0; batch classifier loss: 0.598419; batch adversarial loss: 0.663339\n",
      "epoch 4; iter: 0; batch classifier loss: 0.560604; batch adversarial loss: 0.624100\n",
      "epoch 5; iter: 0; batch classifier loss: 0.536415; batch adversarial loss: 0.634161\n",
      "epoch 6; iter: 0; batch classifier loss: 0.606444; batch adversarial loss: 0.598995\n",
      "epoch 7; iter: 0; batch classifier loss: 0.526422; batch adversarial loss: 0.599747\n",
      "epoch 8; iter: 0; batch classifier loss: 0.506076; batch adversarial loss: 0.552291\n",
      "epoch 9; iter: 0; batch classifier loss: 0.608816; batch adversarial loss: 0.557381\n",
      "epoch 10; iter: 0; batch classifier loss: 0.590302; batch adversarial loss: 0.617308\n",
      "epoch 11; iter: 0; batch classifier loss: 0.549235; batch adversarial loss: 0.579534\n",
      "epoch 12; iter: 0; batch classifier loss: 0.497375; batch adversarial loss: 0.595374\n",
      "epoch 13; iter: 0; batch classifier loss: 0.523519; batch adversarial loss: 0.551294\n",
      "epoch 14; iter: 0; batch classifier loss: 0.492298; batch adversarial loss: 0.607776\n",
      "epoch 15; iter: 0; batch classifier loss: 0.491688; batch adversarial loss: 0.530123\n",
      "epoch 16; iter: 0; batch classifier loss: 0.507762; batch adversarial loss: 0.586419\n",
      "epoch 17; iter: 0; batch classifier loss: 0.577261; batch adversarial loss: 0.513075\n",
      "epoch 18; iter: 0; batch classifier loss: 0.557026; batch adversarial loss: 0.536578\n",
      "epoch 19; iter: 0; batch classifier loss: 0.586284; batch adversarial loss: 0.625693\n",
      "epoch 20; iter: 0; batch classifier loss: 0.506261; batch adversarial loss: 0.540692\n",
      "epoch 21; iter: 0; batch classifier loss: 0.525554; batch adversarial loss: 0.573469\n",
      "epoch 22; iter: 0; batch classifier loss: 0.479034; batch adversarial loss: 0.543661\n",
      "epoch 23; iter: 0; batch classifier loss: 0.556719; batch adversarial loss: 0.562268\n",
      "epoch 24; iter: 0; batch classifier loss: 0.525778; batch adversarial loss: 0.569774\n",
      "epoch 25; iter: 0; batch classifier loss: 0.480016; batch adversarial loss: 0.565831\n",
      "epoch 26; iter: 0; batch classifier loss: 0.425657; batch adversarial loss: 0.573747\n",
      "epoch 27; iter: 0; batch classifier loss: 0.486382; batch adversarial loss: 0.564414\n",
      "epoch 28; iter: 0; batch classifier loss: 0.486043; batch adversarial loss: 0.571394\n",
      "epoch 29; iter: 0; batch classifier loss: 0.471128; batch adversarial loss: 0.500222\n",
      "epoch 30; iter: 0; batch classifier loss: 0.440481; batch adversarial loss: 0.554944\n",
      "epoch 31; iter: 0; batch classifier loss: 0.484292; batch adversarial loss: 0.505674\n",
      "epoch 32; iter: 0; batch classifier loss: 0.509908; batch adversarial loss: 0.620249\n",
      "epoch 33; iter: 0; batch classifier loss: 0.465272; batch adversarial loss: 0.595997\n",
      "epoch 34; iter: 0; batch classifier loss: 0.468090; batch adversarial loss: 0.654809\n",
      "epoch 35; iter: 0; batch classifier loss: 0.514754; batch adversarial loss: 0.570622\n",
      "epoch 36; iter: 0; batch classifier loss: 0.456379; batch adversarial loss: 0.552619\n",
      "epoch 37; iter: 0; batch classifier loss: 0.543851; batch adversarial loss: 0.569872\n",
      "epoch 38; iter: 0; batch classifier loss: 0.467014; batch adversarial loss: 0.524220\n",
      "epoch 39; iter: 0; batch classifier loss: 0.462912; batch adversarial loss: 0.597549\n",
      "epoch 40; iter: 0; batch classifier loss: 0.567429; batch adversarial loss: 0.577781\n",
      "epoch 41; iter: 0; batch classifier loss: 0.477220; batch adversarial loss: 0.509453\n",
      "epoch 42; iter: 0; batch classifier loss: 0.459900; batch adversarial loss: 0.490737\n",
      "epoch 43; iter: 0; batch classifier loss: 0.458888; batch adversarial loss: 0.528512\n",
      "epoch 44; iter: 0; batch classifier loss: 0.556590; batch adversarial loss: 0.570779\n",
      "epoch 45; iter: 0; batch classifier loss: 0.382682; batch adversarial loss: 0.605218\n",
      "epoch 46; iter: 0; batch classifier loss: 0.398038; batch adversarial loss: 0.474985\n",
      "epoch 47; iter: 0; batch classifier loss: 0.454317; batch adversarial loss: 0.578661\n",
      "epoch 48; iter: 0; batch classifier loss: 0.430779; batch adversarial loss: 0.519030\n",
      "epoch 49; iter: 0; batch classifier loss: 0.508550; batch adversarial loss: 0.641153\n",
      "epoch 50; iter: 0; batch classifier loss: 0.354348; batch adversarial loss: 0.597018\n",
      "epoch 51; iter: 0; batch classifier loss: 0.397310; batch adversarial loss: 0.553442\n",
      "epoch 52; iter: 0; batch classifier loss: 0.435278; batch adversarial loss: 0.537090\n",
      "epoch 53; iter: 0; batch classifier loss: 0.469792; batch adversarial loss: 0.614339\n",
      "epoch 54; iter: 0; batch classifier loss: 0.437494; batch adversarial loss: 0.510903\n",
      "epoch 55; iter: 0; batch classifier loss: 0.436270; batch adversarial loss: 0.465873\n",
      "epoch 56; iter: 0; batch classifier loss: 0.447295; batch adversarial loss: 0.596417\n",
      "epoch 57; iter: 0; batch classifier loss: 0.453625; batch adversarial loss: 0.500536\n",
      "epoch 58; iter: 0; batch classifier loss: 0.389233; batch adversarial loss: 0.536910\n",
      "epoch 59; iter: 0; batch classifier loss: 0.398411; batch adversarial loss: 0.535798\n",
      "epoch 60; iter: 0; batch classifier loss: 0.444139; batch adversarial loss: 0.597448\n",
      "epoch 61; iter: 0; batch classifier loss: 0.468073; batch adversarial loss: 0.545620\n",
      "epoch 62; iter: 0; batch classifier loss: 0.395397; batch adversarial loss: 0.491304\n",
      "epoch 63; iter: 0; batch classifier loss: 0.397198; batch adversarial loss: 0.536615\n",
      "epoch 64; iter: 0; batch classifier loss: 0.378829; batch adversarial loss: 0.589507\n",
      "epoch 65; iter: 0; batch classifier loss: 0.385678; batch adversarial loss: 0.545953\n",
      "epoch 66; iter: 0; batch classifier loss: 0.499797; batch adversarial loss: 0.481948\n",
      "epoch 67; iter: 0; batch classifier loss: 0.359919; batch adversarial loss: 0.508276\n",
      "epoch 68; iter: 0; batch classifier loss: 0.451624; batch adversarial loss: 0.520636\n",
      "epoch 69; iter: 0; batch classifier loss: 0.447711; batch adversarial loss: 0.599842\n",
      "epoch 70; iter: 0; batch classifier loss: 0.462135; batch adversarial loss: 0.507523\n",
      "epoch 71; iter: 0; batch classifier loss: 0.405163; batch adversarial loss: 0.526977\n",
      "epoch 72; iter: 0; batch classifier loss: 0.381983; batch adversarial loss: 0.473891\n",
      "epoch 73; iter: 0; batch classifier loss: 0.414982; batch adversarial loss: 0.556186\n",
      "epoch 74; iter: 0; batch classifier loss: 0.448724; batch adversarial loss: 0.561447\n",
      "epoch 75; iter: 0; batch classifier loss: 0.442212; batch adversarial loss: 0.596730\n",
      "epoch 76; iter: 0; batch classifier loss: 0.400168; batch adversarial loss: 0.666590\n",
      "epoch 77; iter: 0; batch classifier loss: 0.409119; batch adversarial loss: 0.551446\n",
      "epoch 78; iter: 0; batch classifier loss: 0.409903; batch adversarial loss: 0.590537\n",
      "epoch 79; iter: 0; batch classifier loss: 0.403723; batch adversarial loss: 0.535954\n",
      "epoch 80; iter: 0; batch classifier loss: 0.360207; batch adversarial loss: 0.526784\n",
      "epoch 81; iter: 0; batch classifier loss: 0.383647; batch adversarial loss: 0.569752\n",
      "epoch 82; iter: 0; batch classifier loss: 0.374872; batch adversarial loss: 0.565834\n",
      "epoch 83; iter: 0; batch classifier loss: 0.419667; batch adversarial loss: 0.566780\n",
      "epoch 84; iter: 0; batch classifier loss: 0.443549; batch adversarial loss: 0.591350\n",
      "epoch 85; iter: 0; batch classifier loss: 0.406381; batch adversarial loss: 0.561860\n",
      "epoch 86; iter: 0; batch classifier loss: 0.339959; batch adversarial loss: 0.516971\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 87; iter: 0; batch classifier loss: 0.432144; batch adversarial loss: 0.579596\n",
      "epoch 88; iter: 0; batch classifier loss: 0.474539; batch adversarial loss: 0.507385\n",
      "epoch 89; iter: 0; batch classifier loss: 0.420689; batch adversarial loss: 0.527382\n",
      "epoch 90; iter: 0; batch classifier loss: 0.321239; batch adversarial loss: 0.542925\n",
      "epoch 91; iter: 0; batch classifier loss: 0.383645; batch adversarial loss: 0.585432\n",
      "epoch 92; iter: 0; batch classifier loss: 0.391853; batch adversarial loss: 0.518518\n",
      "epoch 93; iter: 0; batch classifier loss: 0.417838; batch adversarial loss: 0.545296\n",
      "epoch 94; iter: 0; batch classifier loss: 0.431657; batch adversarial loss: 0.475233\n",
      "epoch 95; iter: 0; batch classifier loss: 0.320746; batch adversarial loss: 0.640033\n",
      "epoch 96; iter: 0; batch classifier loss: 0.425914; batch adversarial loss: 0.586592\n",
      "epoch 97; iter: 0; batch classifier loss: 0.370478; batch adversarial loss: 0.535907\n",
      "epoch 98; iter: 0; batch classifier loss: 0.467649; batch adversarial loss: 0.493064\n",
      "epoch 99; iter: 0; batch classifier loss: 0.447693; batch adversarial loss: 0.492070\n",
      "epoch 100; iter: 0; batch classifier loss: 0.442990; batch adversarial loss: 0.589185\n",
      "epoch 101; iter: 0; batch classifier loss: 0.411537; batch adversarial loss: 0.561328\n",
      "epoch 102; iter: 0; batch classifier loss: 0.352936; batch adversarial loss: 0.518973\n",
      "epoch 103; iter: 0; batch classifier loss: 0.444080; batch adversarial loss: 0.474216\n",
      "epoch 104; iter: 0; batch classifier loss: 0.383501; batch adversarial loss: 0.586294\n",
      "epoch 105; iter: 0; batch classifier loss: 0.392055; batch adversarial loss: 0.527498\n",
      "epoch 106; iter: 0; batch classifier loss: 0.316467; batch adversarial loss: 0.539744\n",
      "epoch 107; iter: 0; batch classifier loss: 0.429266; batch adversarial loss: 0.508687\n",
      "epoch 108; iter: 0; batch classifier loss: 0.407544; batch adversarial loss: 0.535497\n",
      "epoch 109; iter: 0; batch classifier loss: 0.381459; batch adversarial loss: 0.515474\n",
      "epoch 110; iter: 0; batch classifier loss: 0.366730; batch adversarial loss: 0.553545\n",
      "epoch 111; iter: 0; batch classifier loss: 0.479847; batch adversarial loss: 0.491274\n",
      "epoch 112; iter: 0; batch classifier loss: 0.407961; batch adversarial loss: 0.579366\n",
      "epoch 113; iter: 0; batch classifier loss: 0.375226; batch adversarial loss: 0.571329\n",
      "epoch 114; iter: 0; batch classifier loss: 0.403536; batch adversarial loss: 0.571761\n",
      "epoch 115; iter: 0; batch classifier loss: 0.353655; batch adversarial loss: 0.516603\n",
      "epoch 116; iter: 0; batch classifier loss: 0.356310; batch adversarial loss: 0.606144\n",
      "epoch 117; iter: 0; batch classifier loss: 0.340007; batch adversarial loss: 0.550837\n",
      "epoch 118; iter: 0; batch classifier loss: 0.468395; batch adversarial loss: 0.588681\n",
      "epoch 119; iter: 0; batch classifier loss: 0.433427; batch adversarial loss: 0.598416\n",
      "epoch 120; iter: 0; batch classifier loss: 0.285400; batch adversarial loss: 0.552488\n",
      "epoch 121; iter: 0; batch classifier loss: 0.425532; batch adversarial loss: 0.543783\n",
      "epoch 122; iter: 0; batch classifier loss: 0.314182; batch adversarial loss: 0.527406\n",
      "epoch 123; iter: 0; batch classifier loss: 0.339287; batch adversarial loss: 0.499724\n",
      "epoch 124; iter: 0; batch classifier loss: 0.431543; batch adversarial loss: 0.569878\n",
      "epoch 125; iter: 0; batch classifier loss: 0.420410; batch adversarial loss: 0.490513\n",
      "epoch 126; iter: 0; batch classifier loss: 0.361337; batch adversarial loss: 0.642857\n",
      "epoch 127; iter: 0; batch classifier loss: 0.361612; batch adversarial loss: 0.572242\n",
      "epoch 128; iter: 0; batch classifier loss: 0.402666; batch adversarial loss: 0.554254\n",
      "epoch 129; iter: 0; batch classifier loss: 0.372966; batch adversarial loss: 0.588337\n",
      "epoch 130; iter: 0; batch classifier loss: 0.400344; batch adversarial loss: 0.596904\n",
      "epoch 131; iter: 0; batch classifier loss: 0.390067; batch adversarial loss: 0.583989\n",
      "epoch 132; iter: 0; batch classifier loss: 0.375244; batch adversarial loss: 0.616461\n",
      "epoch 133; iter: 0; batch classifier loss: 0.414856; batch adversarial loss: 0.579621\n",
      "epoch 134; iter: 0; batch classifier loss: 0.294692; batch adversarial loss: 0.536480\n",
      "epoch 135; iter: 0; batch classifier loss: 0.396078; batch adversarial loss: 0.588533\n",
      "epoch 136; iter: 0; batch classifier loss: 0.365623; batch adversarial loss: 0.590647\n",
      "epoch 137; iter: 0; batch classifier loss: 0.389806; batch adversarial loss: 0.564065\n",
      "epoch 138; iter: 0; batch classifier loss: 0.384021; batch adversarial loss: 0.493902\n",
      "epoch 139; iter: 0; batch classifier loss: 0.345975; batch adversarial loss: 0.570193\n",
      "epoch 140; iter: 0; batch classifier loss: 0.425143; batch adversarial loss: 0.571684\n",
      "epoch 141; iter: 0; batch classifier loss: 0.434686; batch adversarial loss: 0.533865\n",
      "epoch 142; iter: 0; batch classifier loss: 0.426656; batch adversarial loss: 0.563159\n",
      "epoch 143; iter: 0; batch classifier loss: 0.364378; batch adversarial loss: 0.546818\n",
      "epoch 144; iter: 0; batch classifier loss: 0.411495; batch adversarial loss: 0.594708\n",
      "epoch 145; iter: 0; batch classifier loss: 0.438566; batch adversarial loss: 0.551954\n",
      "epoch 146; iter: 0; batch classifier loss: 0.413145; batch adversarial loss: 0.572427\n",
      "epoch 147; iter: 0; batch classifier loss: 0.421701; batch adversarial loss: 0.510974\n",
      "epoch 148; iter: 0; batch classifier loss: 0.452447; batch adversarial loss: 0.553015\n",
      "epoch 149; iter: 0; batch classifier loss: 0.313490; batch adversarial loss: 0.586514\n",
      "epoch 150; iter: 0; batch classifier loss: 0.377967; batch adversarial loss: 0.560646\n",
      "epoch 151; iter: 0; batch classifier loss: 0.340671; batch adversarial loss: 0.622151\n",
      "epoch 152; iter: 0; batch classifier loss: 0.380368; batch adversarial loss: 0.560434\n",
      "epoch 153; iter: 0; batch classifier loss: 0.344826; batch adversarial loss: 0.554058\n",
      "epoch 154; iter: 0; batch classifier loss: 0.519736; batch adversarial loss: 0.588618\n",
      "epoch 155; iter: 0; batch classifier loss: 0.377843; batch adversarial loss: 0.560291\n",
      "epoch 156; iter: 0; batch classifier loss: 0.512826; batch adversarial loss: 0.561143\n",
      "epoch 157; iter: 0; batch classifier loss: 0.409848; batch adversarial loss: 0.536918\n",
      "epoch 158; iter: 0; batch classifier loss: 0.268207; batch adversarial loss: 0.554430\n",
      "epoch 159; iter: 0; batch classifier loss: 0.347295; batch adversarial loss: 0.541216\n",
      "epoch 160; iter: 0; batch classifier loss: 0.387312; batch adversarial loss: 0.561522\n",
      "epoch 161; iter: 0; batch classifier loss: 0.361421; batch adversarial loss: 0.507877\n",
      "epoch 162; iter: 0; batch classifier loss: 0.436672; batch adversarial loss: 0.561946\n",
      "epoch 163; iter: 0; batch classifier loss: 0.313481; batch adversarial loss: 0.533820\n",
      "epoch 164; iter: 0; batch classifier loss: 0.363674; batch adversarial loss: 0.560267\n",
      "epoch 165; iter: 0; batch classifier loss: 0.333692; batch adversarial loss: 0.571826\n",
      "epoch 166; iter: 0; batch classifier loss: 0.321800; batch adversarial loss: 0.581682\n",
      "epoch 167; iter: 0; batch classifier loss: 0.330965; batch adversarial loss: 0.552941\n",
      "epoch 168; iter: 0; batch classifier loss: 0.367599; batch adversarial loss: 0.544649\n",
      "epoch 169; iter: 0; batch classifier loss: 0.366538; batch adversarial loss: 0.621923\n",
      "epoch 170; iter: 0; batch classifier loss: 0.370652; batch adversarial loss: 0.525443\n",
      "epoch 171; iter: 0; batch classifier loss: 0.362245; batch adversarial loss: 0.510345\n",
      "epoch 172; iter: 0; batch classifier loss: 0.401398; batch adversarial loss: 0.580096\n",
      "epoch 173; iter: 0; batch classifier loss: 0.350588; batch adversarial loss: 0.468157\n",
      "epoch 174; iter: 0; batch classifier loss: 0.369508; batch adversarial loss: 0.563240\n",
      "epoch 175; iter: 0; batch classifier loss: 0.314834; batch adversarial loss: 0.630418\n",
      "epoch 176; iter: 0; batch classifier loss: 0.400319; batch adversarial loss: 0.507546\n",
      "epoch 177; iter: 0; batch classifier loss: 0.292330; batch adversarial loss: 0.613498\n",
      "epoch 178; iter: 0; batch classifier loss: 0.379919; batch adversarial loss: 0.473387\n",
      "epoch 179; iter: 0; batch classifier loss: 0.369299; batch adversarial loss: 0.589731\n",
      "epoch 180; iter: 0; batch classifier loss: 0.463416; batch adversarial loss: 0.544928\n",
      "epoch 181; iter: 0; batch classifier loss: 0.357452; batch adversarial loss: 0.562266\n",
      "epoch 182; iter: 0; batch classifier loss: 0.322892; batch adversarial loss: 0.526115\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 183; iter: 0; batch classifier loss: 0.405760; batch adversarial loss: 0.516969\n",
      "epoch 184; iter: 0; batch classifier loss: 0.378334; batch adversarial loss: 0.553820\n",
      "epoch 185; iter: 0; batch classifier loss: 0.318161; batch adversarial loss: 0.510318\n",
      "epoch 186; iter: 0; batch classifier loss: 0.367550; batch adversarial loss: 0.537894\n",
      "epoch 187; iter: 0; batch classifier loss: 0.357389; batch adversarial loss: 0.483830\n",
      "epoch 188; iter: 0; batch classifier loss: 0.392964; batch adversarial loss: 0.507020\n",
      "epoch 189; iter: 0; batch classifier loss: 0.485574; batch adversarial loss: 0.556135\n",
      "epoch 190; iter: 0; batch classifier loss: 0.311129; batch adversarial loss: 0.545136\n",
      "epoch 191; iter: 0; batch classifier loss: 0.461357; batch adversarial loss: 0.518792\n",
      "epoch 192; iter: 0; batch classifier loss: 0.333385; batch adversarial loss: 0.589880\n",
      "epoch 193; iter: 0; batch classifier loss: 0.353127; batch adversarial loss: 0.554099\n",
      "epoch 194; iter: 0; batch classifier loss: 0.457143; batch adversarial loss: 0.533188\n",
      "epoch 195; iter: 0; batch classifier loss: 0.347675; batch adversarial loss: 0.536710\n",
      "epoch 196; iter: 0; batch classifier loss: 0.385110; batch adversarial loss: 0.437247\n",
      "epoch 197; iter: 0; batch classifier loss: 0.442594; batch adversarial loss: 0.582255\n",
      "epoch 198; iter: 0; batch classifier loss: 0.336680; batch adversarial loss: 0.509930\n",
      "epoch 199; iter: 0; batch classifier loss: 0.432051; batch adversarial loss: 0.642035\n",
      "epoch 0; iter: 0; batch classifier loss: 0.706348; batch adversarial loss: 0.788503\n",
      "epoch 1; iter: 0; batch classifier loss: 0.585019; batch adversarial loss: 0.755625\n",
      "epoch 2; iter: 0; batch classifier loss: 0.653793; batch adversarial loss: 0.680719\n",
      "epoch 3; iter: 0; batch classifier loss: 0.553922; batch adversarial loss: 0.661922\n",
      "epoch 4; iter: 0; batch classifier loss: 0.583459; batch adversarial loss: 0.661532\n",
      "epoch 5; iter: 0; batch classifier loss: 0.481651; batch adversarial loss: 0.624229\n",
      "epoch 6; iter: 0; batch classifier loss: 0.557705; batch adversarial loss: 0.602094\n",
      "epoch 7; iter: 0; batch classifier loss: 0.541436; batch adversarial loss: 0.616917\n",
      "epoch 8; iter: 0; batch classifier loss: 0.590004; batch adversarial loss: 0.587515\n",
      "epoch 9; iter: 0; batch classifier loss: 0.517175; batch adversarial loss: 0.603113\n",
      "epoch 10; iter: 0; batch classifier loss: 0.535162; batch adversarial loss: 0.584144\n",
      "epoch 11; iter: 0; batch classifier loss: 0.506543; batch adversarial loss: 0.528950\n",
      "epoch 12; iter: 0; batch classifier loss: 0.547349; batch adversarial loss: 0.541794\n",
      "epoch 13; iter: 0; batch classifier loss: 0.578822; batch adversarial loss: 0.542221\n",
      "epoch 14; iter: 0; batch classifier loss: 0.558200; batch adversarial loss: 0.574354\n",
      "epoch 15; iter: 0; batch classifier loss: 0.528067; batch adversarial loss: 0.510293\n",
      "epoch 16; iter: 0; batch classifier loss: 0.445922; batch adversarial loss: 0.563129\n",
      "epoch 17; iter: 0; batch classifier loss: 0.534721; batch adversarial loss: 0.595551\n",
      "epoch 18; iter: 0; batch classifier loss: 0.482883; batch adversarial loss: 0.585386\n",
      "epoch 19; iter: 0; batch classifier loss: 0.512808; batch adversarial loss: 0.559358\n",
      "epoch 20; iter: 0; batch classifier loss: 0.498086; batch adversarial loss: 0.557018\n",
      "epoch 21; iter: 0; batch classifier loss: 0.420156; batch adversarial loss: 0.531172\n",
      "epoch 22; iter: 0; batch classifier loss: 0.462338; batch adversarial loss: 0.581149\n",
      "epoch 23; iter: 0; batch classifier loss: 0.498616; batch adversarial loss: 0.582984\n",
      "epoch 24; iter: 0; batch classifier loss: 0.523538; batch adversarial loss: 0.630142\n",
      "epoch 25; iter: 0; batch classifier loss: 0.466632; batch adversarial loss: 0.541891\n",
      "epoch 26; iter: 0; batch classifier loss: 0.472832; batch adversarial loss: 0.522162\n",
      "epoch 27; iter: 0; batch classifier loss: 0.537615; batch adversarial loss: 0.643584\n",
      "epoch 28; iter: 0; batch classifier loss: 0.478872; batch adversarial loss: 0.564656\n",
      "epoch 29; iter: 0; batch classifier loss: 0.412938; batch adversarial loss: 0.567139\n",
      "epoch 30; iter: 0; batch classifier loss: 0.511625; batch adversarial loss: 0.547295\n",
      "epoch 31; iter: 0; batch classifier loss: 0.406861; batch adversarial loss: 0.573510\n",
      "epoch 32; iter: 0; batch classifier loss: 0.484286; batch adversarial loss: 0.551203\n",
      "epoch 33; iter: 0; batch classifier loss: 0.407941; batch adversarial loss: 0.538698\n",
      "epoch 34; iter: 0; batch classifier loss: 0.472895; batch adversarial loss: 0.522331\n",
      "epoch 35; iter: 0; batch classifier loss: 0.453639; batch adversarial loss: 0.563255\n",
      "epoch 36; iter: 0; batch classifier loss: 0.396732; batch adversarial loss: 0.503977\n",
      "epoch 37; iter: 0; batch classifier loss: 0.454164; batch adversarial loss: 0.503745\n",
      "epoch 38; iter: 0; batch classifier loss: 0.406527; batch adversarial loss: 0.580587\n",
      "epoch 39; iter: 0; batch classifier loss: 0.428952; batch adversarial loss: 0.553037\n",
      "epoch 40; iter: 0; batch classifier loss: 0.484692; batch adversarial loss: 0.492651\n",
      "epoch 41; iter: 0; batch classifier loss: 0.402223; batch adversarial loss: 0.536563\n",
      "epoch 42; iter: 0; batch classifier loss: 0.429539; batch adversarial loss: 0.597258\n",
      "epoch 43; iter: 0; batch classifier loss: 0.456931; batch adversarial loss: 0.528530\n",
      "epoch 44; iter: 0; batch classifier loss: 0.449831; batch adversarial loss: 0.607820\n",
      "epoch 45; iter: 0; batch classifier loss: 0.385380; batch adversarial loss: 0.535831\n",
      "epoch 46; iter: 0; batch classifier loss: 0.376855; batch adversarial loss: 0.608420\n",
      "epoch 47; iter: 0; batch classifier loss: 0.450818; batch adversarial loss: 0.545732\n",
      "epoch 48; iter: 0; batch classifier loss: 0.452883; batch adversarial loss: 0.489703\n",
      "epoch 49; iter: 0; batch classifier loss: 0.446492; batch adversarial loss: 0.515864\n",
      "epoch 50; iter: 0; batch classifier loss: 0.390121; batch adversarial loss: 0.569738\n",
      "epoch 51; iter: 0; batch classifier loss: 0.376300; batch adversarial loss: 0.563206\n",
      "epoch 52; iter: 0; batch classifier loss: 0.420941; batch adversarial loss: 0.592970\n",
      "epoch 53; iter: 0; batch classifier loss: 0.414980; batch adversarial loss: 0.561542\n",
      "epoch 54; iter: 0; batch classifier loss: 0.379224; batch adversarial loss: 0.634869\n",
      "epoch 55; iter: 0; batch classifier loss: 0.431947; batch adversarial loss: 0.488340\n",
      "epoch 56; iter: 0; batch classifier loss: 0.515687; batch adversarial loss: 0.588547\n",
      "epoch 57; iter: 0; batch classifier loss: 0.379489; batch adversarial loss: 0.609043\n",
      "epoch 58; iter: 0; batch classifier loss: 0.459360; batch adversarial loss: 0.543670\n",
      "epoch 59; iter: 0; batch classifier loss: 0.330865; batch adversarial loss: 0.526003\n",
      "epoch 60; iter: 0; batch classifier loss: 0.465368; batch adversarial loss: 0.509236\n",
      "epoch 61; iter: 0; batch classifier loss: 0.381750; batch adversarial loss: 0.634606\n",
      "epoch 62; iter: 0; batch classifier loss: 0.377754; batch adversarial loss: 0.582008\n",
      "epoch 63; iter: 0; batch classifier loss: 0.395416; batch adversarial loss: 0.633814\n",
      "epoch 64; iter: 0; batch classifier loss: 0.336051; batch adversarial loss: 0.554020\n",
      "epoch 65; iter: 0; batch classifier loss: 0.414022; batch adversarial loss: 0.551475\n",
      "epoch 66; iter: 0; batch classifier loss: 0.361799; batch adversarial loss: 0.528137\n",
      "epoch 67; iter: 0; batch classifier loss: 0.445309; batch adversarial loss: 0.460813\n",
      "epoch 68; iter: 0; batch classifier loss: 0.406599; batch adversarial loss: 0.543384\n",
      "epoch 69; iter: 0; batch classifier loss: 0.437192; batch adversarial loss: 0.617205\n",
      "epoch 70; iter: 0; batch classifier loss: 0.460658; batch adversarial loss: 0.562238\n",
      "epoch 71; iter: 0; batch classifier loss: 0.384388; batch adversarial loss: 0.500171\n",
      "epoch 72; iter: 0; batch classifier loss: 0.437452; batch adversarial loss: 0.609117\n",
      "epoch 73; iter: 0; batch classifier loss: 0.387910; batch adversarial loss: 0.577500\n",
      "epoch 74; iter: 0; batch classifier loss: 0.368677; batch adversarial loss: 0.537777\n",
      "epoch 75; iter: 0; batch classifier loss: 0.369499; batch adversarial loss: 0.623873\n",
      "epoch 76; iter: 0; batch classifier loss: 0.462758; batch adversarial loss: 0.563543\n",
      "epoch 77; iter: 0; batch classifier loss: 0.385866; batch adversarial loss: 0.534772\n",
      "epoch 78; iter: 0; batch classifier loss: 0.344690; batch adversarial loss: 0.533733\n",
      "epoch 79; iter: 0; batch classifier loss: 0.420978; batch adversarial loss: 0.598074\n",
      "epoch 80; iter: 0; batch classifier loss: 0.460204; batch adversarial loss: 0.545798\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 81; iter: 0; batch classifier loss: 0.319689; batch adversarial loss: 0.554592\n",
      "epoch 82; iter: 0; batch classifier loss: 0.519687; batch adversarial loss: 0.534096\n",
      "epoch 83; iter: 0; batch classifier loss: 0.400240; batch adversarial loss: 0.498842\n",
      "epoch 84; iter: 0; batch classifier loss: 0.424535; batch adversarial loss: 0.506473\n",
      "epoch 85; iter: 0; batch classifier loss: 0.376336; batch adversarial loss: 0.534974\n",
      "epoch 86; iter: 0; batch classifier loss: 0.445581; batch adversarial loss: 0.598449\n",
      "epoch 87; iter: 0; batch classifier loss: 0.359483; batch adversarial loss: 0.516449\n",
      "epoch 88; iter: 0; batch classifier loss: 0.425591; batch adversarial loss: 0.580184\n",
      "epoch 89; iter: 0; batch classifier loss: 0.361017; batch adversarial loss: 0.517502\n",
      "epoch 90; iter: 0; batch classifier loss: 0.363133; batch adversarial loss: 0.519639\n",
      "epoch 91; iter: 0; batch classifier loss: 0.411858; batch adversarial loss: 0.591242\n",
      "epoch 92; iter: 0; batch classifier loss: 0.289778; batch adversarial loss: 0.527002\n",
      "epoch 93; iter: 0; batch classifier loss: 0.405927; batch adversarial loss: 0.510026\n",
      "epoch 94; iter: 0; batch classifier loss: 0.404945; batch adversarial loss: 0.545415\n",
      "epoch 95; iter: 0; batch classifier loss: 0.372806; batch adversarial loss: 0.527296\n",
      "epoch 96; iter: 0; batch classifier loss: 0.373379; batch adversarial loss: 0.553790\n",
      "epoch 97; iter: 0; batch classifier loss: 0.365635; batch adversarial loss: 0.554269\n",
      "epoch 98; iter: 0; batch classifier loss: 0.376091; batch adversarial loss: 0.544827\n",
      "epoch 99; iter: 0; batch classifier loss: 0.441253; batch adversarial loss: 0.516112\n",
      "epoch 100; iter: 0; batch classifier loss: 0.388959; batch adversarial loss: 0.572320\n",
      "epoch 101; iter: 0; batch classifier loss: 0.418481; batch adversarial loss: 0.692163\n",
      "epoch 102; iter: 0; batch classifier loss: 0.372519; batch adversarial loss: 0.479892\n",
      "epoch 103; iter: 0; batch classifier loss: 0.400257; batch adversarial loss: 0.585486\n",
      "epoch 104; iter: 0; batch classifier loss: 0.321899; batch adversarial loss: 0.464539\n",
      "epoch 105; iter: 0; batch classifier loss: 0.359303; batch adversarial loss: 0.500566\n",
      "epoch 106; iter: 0; batch classifier loss: 0.391269; batch adversarial loss: 0.508209\n",
      "epoch 107; iter: 0; batch classifier loss: 0.436759; batch adversarial loss: 0.518362\n",
      "epoch 108; iter: 0; batch classifier loss: 0.391858; batch adversarial loss: 0.562987\n",
      "epoch 109; iter: 0; batch classifier loss: 0.337857; batch adversarial loss: 0.518375\n",
      "epoch 110; iter: 0; batch classifier loss: 0.382836; batch adversarial loss: 0.527374\n",
      "epoch 111; iter: 0; batch classifier loss: 0.416465; batch adversarial loss: 0.500867\n",
      "epoch 112; iter: 0; batch classifier loss: 0.361503; batch adversarial loss: 0.541734\n",
      "epoch 113; iter: 0; batch classifier loss: 0.340105; batch adversarial loss: 0.572094\n",
      "epoch 114; iter: 0; batch classifier loss: 0.498180; batch adversarial loss: 0.496727\n",
      "epoch 115; iter: 0; batch classifier loss: 0.414333; batch adversarial loss: 0.597662\n",
      "epoch 116; iter: 0; batch classifier loss: 0.437622; batch adversarial loss: 0.526666\n",
      "epoch 117; iter: 0; batch classifier loss: 0.372115; batch adversarial loss: 0.544600\n",
      "epoch 118; iter: 0; batch classifier loss: 0.443143; batch adversarial loss: 0.489593\n",
      "epoch 119; iter: 0; batch classifier loss: 0.323569; batch adversarial loss: 0.524216\n",
      "epoch 120; iter: 0; batch classifier loss: 0.364828; batch adversarial loss: 0.580772\n",
      "epoch 121; iter: 0; batch classifier loss: 0.352551; batch adversarial loss: 0.597515\n",
      "epoch 122; iter: 0; batch classifier loss: 0.335443; batch adversarial loss: 0.525175\n",
      "epoch 123; iter: 0; batch classifier loss: 0.303359; batch adversarial loss: 0.510320\n",
      "epoch 124; iter: 0; batch classifier loss: 0.373450; batch adversarial loss: 0.551995\n",
      "epoch 125; iter: 0; batch classifier loss: 0.375339; batch adversarial loss: 0.546742\n",
      "epoch 126; iter: 0; batch classifier loss: 0.291185; batch adversarial loss: 0.507233\n",
      "epoch 127; iter: 0; batch classifier loss: 0.392791; batch adversarial loss: 0.454336\n",
      "epoch 128; iter: 0; batch classifier loss: 0.405561; batch adversarial loss: 0.535953\n",
      "epoch 129; iter: 0; batch classifier loss: 0.439278; batch adversarial loss: 0.606199\n",
      "epoch 130; iter: 0; batch classifier loss: 0.318049; batch adversarial loss: 0.607316\n",
      "epoch 131; iter: 0; batch classifier loss: 0.432383; batch adversarial loss: 0.505200\n",
      "epoch 132; iter: 0; batch classifier loss: 0.364464; batch adversarial loss: 0.564862\n",
      "epoch 133; iter: 0; batch classifier loss: 0.398044; batch adversarial loss: 0.571762\n",
      "epoch 134; iter: 0; batch classifier loss: 0.352927; batch adversarial loss: 0.581623\n",
      "epoch 135; iter: 0; batch classifier loss: 0.387734; batch adversarial loss: 0.528170\n",
      "epoch 136; iter: 0; batch classifier loss: 0.303676; batch adversarial loss: 0.462782\n",
      "epoch 137; iter: 0; batch classifier loss: 0.374301; batch adversarial loss: 0.518524\n",
      "epoch 138; iter: 0; batch classifier loss: 0.460703; batch adversarial loss: 0.525046\n",
      "epoch 139; iter: 0; batch classifier loss: 0.276746; batch adversarial loss: 0.543835\n",
      "epoch 140; iter: 0; batch classifier loss: 0.320053; batch adversarial loss: 0.557618\n",
      "epoch 141; iter: 0; batch classifier loss: 0.327453; batch adversarial loss: 0.582448\n",
      "epoch 142; iter: 0; batch classifier loss: 0.421490; batch adversarial loss: 0.555116\n",
      "epoch 143; iter: 0; batch classifier loss: 0.389241; batch adversarial loss: 0.510557\n",
      "epoch 144; iter: 0; batch classifier loss: 0.386244; batch adversarial loss: 0.551669\n",
      "epoch 145; iter: 0; batch classifier loss: 0.451130; batch adversarial loss: 0.562080\n",
      "epoch 146; iter: 0; batch classifier loss: 0.274856; batch adversarial loss: 0.552503\n",
      "epoch 147; iter: 0; batch classifier loss: 0.421121; batch adversarial loss: 0.553730\n",
      "epoch 148; iter: 0; batch classifier loss: 0.426670; batch adversarial loss: 0.552346\n",
      "epoch 149; iter: 0; batch classifier loss: 0.319285; batch adversarial loss: 0.590726\n",
      "epoch 150; iter: 0; batch classifier loss: 0.397638; batch adversarial loss: 0.583508\n",
      "epoch 151; iter: 0; batch classifier loss: 0.338634; batch adversarial loss: 0.592132\n",
      "epoch 152; iter: 0; batch classifier loss: 0.342384; batch adversarial loss: 0.516507\n",
      "epoch 153; iter: 0; batch classifier loss: 0.345876; batch adversarial loss: 0.545272\n",
      "epoch 154; iter: 0; batch classifier loss: 0.324692; batch adversarial loss: 0.510441\n",
      "epoch 155; iter: 0; batch classifier loss: 0.503748; batch adversarial loss: 0.525888\n",
      "epoch 156; iter: 0; batch classifier loss: 0.350550; batch adversarial loss: 0.508346\n",
      "epoch 157; iter: 0; batch classifier loss: 0.482740; batch adversarial loss: 0.582131\n",
      "epoch 158; iter: 0; batch classifier loss: 0.310610; batch adversarial loss: 0.633016\n",
      "epoch 159; iter: 0; batch classifier loss: 0.352144; batch adversarial loss: 0.612770\n",
      "epoch 160; iter: 0; batch classifier loss: 0.345984; batch adversarial loss: 0.602423\n",
      "epoch 161; iter: 0; batch classifier loss: 0.331541; batch adversarial loss: 0.516987\n",
      "epoch 162; iter: 0; batch classifier loss: 0.358701; batch adversarial loss: 0.523438\n",
      "epoch 163; iter: 0; batch classifier loss: 0.374153; batch adversarial loss: 0.480974\n",
      "epoch 164; iter: 0; batch classifier loss: 0.363006; batch adversarial loss: 0.538340\n",
      "epoch 165; iter: 0; batch classifier loss: 0.425765; batch adversarial loss: 0.498488\n",
      "epoch 166; iter: 0; batch classifier loss: 0.328108; batch adversarial loss: 0.582702\n",
      "epoch 167; iter: 0; batch classifier loss: 0.332279; batch adversarial loss: 0.533478\n",
      "epoch 168; iter: 0; batch classifier loss: 0.373127; batch adversarial loss: 0.454335\n",
      "epoch 169; iter: 0; batch classifier loss: 0.342908; batch adversarial loss: 0.598440\n",
      "epoch 170; iter: 0; batch classifier loss: 0.367049; batch adversarial loss: 0.562364\n",
      "epoch 171; iter: 0; batch classifier loss: 0.329782; batch adversarial loss: 0.507585\n",
      "epoch 172; iter: 0; batch classifier loss: 0.341399; batch adversarial loss: 0.599523\n",
      "epoch 173; iter: 0; batch classifier loss: 0.358719; batch adversarial loss: 0.543657\n",
      "epoch 174; iter: 0; batch classifier loss: 0.379752; batch adversarial loss: 0.554287\n",
      "epoch 175; iter: 0; batch classifier loss: 0.444345; batch adversarial loss: 0.589816\n",
      "epoch 176; iter: 0; batch classifier loss: 0.423772; batch adversarial loss: 0.517692\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 177; iter: 0; batch classifier loss: 0.339917; batch adversarial loss: 0.509710\n",
      "epoch 178; iter: 0; batch classifier loss: 0.511718; batch adversarial loss: 0.542047\n",
      "epoch 179; iter: 0; batch classifier loss: 0.307339; batch adversarial loss: 0.578393\n",
      "epoch 180; iter: 0; batch classifier loss: 0.376136; batch adversarial loss: 0.508848\n",
      "epoch 181; iter: 0; batch classifier loss: 0.346725; batch adversarial loss: 0.606744\n",
      "epoch 182; iter: 0; batch classifier loss: 0.311918; batch adversarial loss: 0.536990\n",
      "epoch 183; iter: 0; batch classifier loss: 0.432333; batch adversarial loss: 0.600062\n",
      "epoch 184; iter: 0; batch classifier loss: 0.387528; batch adversarial loss: 0.507047\n",
      "epoch 185; iter: 0; batch classifier loss: 0.370183; batch adversarial loss: 0.527831\n",
      "epoch 186; iter: 0; batch classifier loss: 0.377812; batch adversarial loss: 0.518639\n",
      "epoch 187; iter: 0; batch classifier loss: 0.349989; batch adversarial loss: 0.523797\n",
      "epoch 188; iter: 0; batch classifier loss: 0.271049; batch adversarial loss: 0.580665\n",
      "epoch 189; iter: 0; batch classifier loss: 0.282833; batch adversarial loss: 0.482755\n",
      "epoch 190; iter: 0; batch classifier loss: 0.408690; batch adversarial loss: 0.488079\n",
      "epoch 191; iter: 0; batch classifier loss: 0.316289; batch adversarial loss: 0.536812\n",
      "epoch 192; iter: 0; batch classifier loss: 0.293387; batch adversarial loss: 0.552393\n",
      "epoch 193; iter: 0; batch classifier loss: 0.327030; batch adversarial loss: 0.445157\n",
      "epoch 194; iter: 0; batch classifier loss: 0.422748; batch adversarial loss: 0.614309\n",
      "epoch 195; iter: 0; batch classifier loss: 0.324917; batch adversarial loss: 0.479477\n",
      "epoch 196; iter: 0; batch classifier loss: 0.297755; batch adversarial loss: 0.487032\n",
      "epoch 197; iter: 0; batch classifier loss: 0.333332; batch adversarial loss: 0.588880\n",
      "epoch 198; iter: 0; batch classifier loss: 0.307559; batch adversarial loss: 0.515104\n",
      "epoch 199; iter: 0; batch classifier loss: 0.363200; batch adversarial loss: 0.563146\n",
      "epoch 0; iter: 0; batch classifier loss: 0.739460; batch adversarial loss: 0.826968\n",
      "epoch 1; iter: 0; batch classifier loss: 0.807748; batch adversarial loss: 0.871274\n",
      "epoch 2; iter: 0; batch classifier loss: 0.939310; batch adversarial loss: 0.827600\n",
      "epoch 3; iter: 0; batch classifier loss: 0.953792; batch adversarial loss: 0.748060\n",
      "epoch 4; iter: 0; batch classifier loss: 0.817656; batch adversarial loss: 0.686516\n",
      "epoch 5; iter: 0; batch classifier loss: 0.702602; batch adversarial loss: 0.634160\n",
      "epoch 6; iter: 0; batch classifier loss: 0.520996; batch adversarial loss: 0.630206\n",
      "epoch 7; iter: 0; batch classifier loss: 0.554787; batch adversarial loss: 0.632871\n",
      "epoch 8; iter: 0; batch classifier loss: 0.547555; batch adversarial loss: 0.588214\n",
      "epoch 9; iter: 0; batch classifier loss: 0.568540; batch adversarial loss: 0.625933\n",
      "epoch 10; iter: 0; batch classifier loss: 0.604469; batch adversarial loss: 0.590769\n",
      "epoch 11; iter: 0; batch classifier loss: 0.534481; batch adversarial loss: 0.595612\n",
      "epoch 12; iter: 0; batch classifier loss: 0.558925; batch adversarial loss: 0.574483\n",
      "epoch 13; iter: 0; batch classifier loss: 0.502458; batch adversarial loss: 0.567389\n",
      "epoch 14; iter: 0; batch classifier loss: 0.487438; batch adversarial loss: 0.577772\n",
      "epoch 15; iter: 0; batch classifier loss: 0.546689; batch adversarial loss: 0.614663\n",
      "epoch 16; iter: 0; batch classifier loss: 0.472469; batch adversarial loss: 0.635613\n",
      "epoch 17; iter: 0; batch classifier loss: 0.496428; batch adversarial loss: 0.611235\n",
      "epoch 18; iter: 0; batch classifier loss: 0.502113; batch adversarial loss: 0.594680\n",
      "epoch 19; iter: 0; batch classifier loss: 0.502046; batch adversarial loss: 0.560624\n",
      "epoch 20; iter: 0; batch classifier loss: 0.519503; batch adversarial loss: 0.554280\n",
      "epoch 21; iter: 0; batch classifier loss: 0.474540; batch adversarial loss: 0.566906\n",
      "epoch 22; iter: 0; batch classifier loss: 0.467268; batch adversarial loss: 0.540741\n",
      "epoch 23; iter: 0; batch classifier loss: 0.486436; batch adversarial loss: 0.559301\n",
      "epoch 24; iter: 0; batch classifier loss: 0.523065; batch adversarial loss: 0.508963\n",
      "epoch 25; iter: 0; batch classifier loss: 0.507429; batch adversarial loss: 0.602134\n",
      "epoch 26; iter: 0; batch classifier loss: 0.449550; batch adversarial loss: 0.577755\n",
      "epoch 27; iter: 0; batch classifier loss: 0.442338; batch adversarial loss: 0.501903\n",
      "epoch 28; iter: 0; batch classifier loss: 0.529898; batch adversarial loss: 0.570722\n",
      "epoch 29; iter: 0; batch classifier loss: 0.489040; batch adversarial loss: 0.550752\n",
      "epoch 30; iter: 0; batch classifier loss: 0.481563; batch adversarial loss: 0.545907\n",
      "epoch 31; iter: 0; batch classifier loss: 0.497941; batch adversarial loss: 0.598873\n",
      "epoch 32; iter: 0; batch classifier loss: 0.472237; batch adversarial loss: 0.570302\n",
      "epoch 33; iter: 0; batch classifier loss: 0.465233; batch adversarial loss: 0.546299\n",
      "epoch 34; iter: 0; batch classifier loss: 0.476560; batch adversarial loss: 0.552127\n",
      "epoch 35; iter: 0; batch classifier loss: 0.438698; batch adversarial loss: 0.580553\n",
      "epoch 36; iter: 0; batch classifier loss: 0.472842; batch adversarial loss: 0.574465\n",
      "epoch 37; iter: 0; batch classifier loss: 0.449232; batch adversarial loss: 0.503438\n",
      "epoch 38; iter: 0; batch classifier loss: 0.469161; batch adversarial loss: 0.505197\n",
      "epoch 39; iter: 0; batch classifier loss: 0.467689; batch adversarial loss: 0.586564\n",
      "epoch 40; iter: 0; batch classifier loss: 0.468048; batch adversarial loss: 0.494355\n",
      "epoch 41; iter: 0; batch classifier loss: 0.521539; batch adversarial loss: 0.502149\n",
      "epoch 42; iter: 0; batch classifier loss: 0.412087; batch adversarial loss: 0.596534\n",
      "epoch 43; iter: 0; batch classifier loss: 0.444835; batch adversarial loss: 0.552435\n",
      "epoch 44; iter: 0; batch classifier loss: 0.462595; batch adversarial loss: 0.579065\n",
      "epoch 45; iter: 0; batch classifier loss: 0.446328; batch adversarial loss: 0.580941\n",
      "epoch 46; iter: 0; batch classifier loss: 0.434610; batch adversarial loss: 0.570872\n",
      "epoch 47; iter: 0; batch classifier loss: 0.459951; batch adversarial loss: 0.528868\n",
      "epoch 48; iter: 0; batch classifier loss: 0.415926; batch adversarial loss: 0.467990\n",
      "epoch 49; iter: 0; batch classifier loss: 0.420418; batch adversarial loss: 0.563600\n",
      "epoch 50; iter: 0; batch classifier loss: 0.421551; batch adversarial loss: 0.562991\n",
      "epoch 51; iter: 0; batch classifier loss: 0.428296; batch adversarial loss: 0.545823\n",
      "epoch 52; iter: 0; batch classifier loss: 0.428021; batch adversarial loss: 0.544552\n",
      "epoch 53; iter: 0; batch classifier loss: 0.472900; batch adversarial loss: 0.580698\n",
      "epoch 54; iter: 0; batch classifier loss: 0.540693; batch adversarial loss: 0.596642\n",
      "epoch 55; iter: 0; batch classifier loss: 0.451123; batch adversarial loss: 0.543836\n",
      "epoch 56; iter: 0; batch classifier loss: 0.403230; batch adversarial loss: 0.603998\n",
      "epoch 57; iter: 0; batch classifier loss: 0.370229; batch adversarial loss: 0.525450\n",
      "epoch 58; iter: 0; batch classifier loss: 0.395090; batch adversarial loss: 0.536682\n",
      "epoch 59; iter: 0; batch classifier loss: 0.348891; batch adversarial loss: 0.493674\n",
      "epoch 60; iter: 0; batch classifier loss: 0.442071; batch adversarial loss: 0.561081\n",
      "epoch 61; iter: 0; batch classifier loss: 0.482163; batch adversarial loss: 0.544960\n",
      "epoch 62; iter: 0; batch classifier loss: 0.369054; batch adversarial loss: 0.576694\n",
      "epoch 63; iter: 0; batch classifier loss: 0.434725; batch adversarial loss: 0.553454\n",
      "epoch 64; iter: 0; batch classifier loss: 0.404308; batch adversarial loss: 0.561226\n",
      "epoch 65; iter: 0; batch classifier loss: 0.407284; batch adversarial loss: 0.546473\n",
      "epoch 66; iter: 0; batch classifier loss: 0.421434; batch adversarial loss: 0.495527\n",
      "epoch 67; iter: 0; batch classifier loss: 0.337729; batch adversarial loss: 0.542866\n",
      "epoch 68; iter: 0; batch classifier loss: 0.481890; batch adversarial loss: 0.474441\n",
      "epoch 69; iter: 0; batch classifier loss: 0.429832; batch adversarial loss: 0.511441\n",
      "epoch 70; iter: 0; batch classifier loss: 0.396429; batch adversarial loss: 0.519387\n",
      "epoch 71; iter: 0; batch classifier loss: 0.373595; batch adversarial loss: 0.544292\n",
      "epoch 72; iter: 0; batch classifier loss: 0.337081; batch adversarial loss: 0.587845\n",
      "epoch 73; iter: 0; batch classifier loss: 0.300530; batch adversarial loss: 0.542209\n",
      "epoch 74; iter: 0; batch classifier loss: 0.411085; batch adversarial loss: 0.562342\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 75; iter: 0; batch classifier loss: 0.336586; batch adversarial loss: 0.570672\n",
      "epoch 76; iter: 0; batch classifier loss: 0.427012; batch adversarial loss: 0.571254\n",
      "epoch 77; iter: 0; batch classifier loss: 0.413760; batch adversarial loss: 0.569988\n",
      "epoch 78; iter: 0; batch classifier loss: 0.368978; batch adversarial loss: 0.614240\n",
      "epoch 79; iter: 0; batch classifier loss: 0.379715; batch adversarial loss: 0.546325\n",
      "epoch 80; iter: 0; batch classifier loss: 0.410542; batch adversarial loss: 0.562370\n",
      "epoch 81; iter: 0; batch classifier loss: 0.348283; batch adversarial loss: 0.585748\n",
      "epoch 82; iter: 0; batch classifier loss: 0.537374; batch adversarial loss: 0.527086\n",
      "epoch 83; iter: 0; batch classifier loss: 0.366342; batch adversarial loss: 0.588045\n",
      "epoch 84; iter: 0; batch classifier loss: 0.366904; batch adversarial loss: 0.668597\n",
      "epoch 85; iter: 0; batch classifier loss: 0.425584; batch adversarial loss: 0.456387\n",
      "epoch 86; iter: 0; batch classifier loss: 0.418113; batch adversarial loss: 0.507687\n",
      "epoch 87; iter: 0; batch classifier loss: 0.360897; batch adversarial loss: 0.570320\n",
      "epoch 88; iter: 0; batch classifier loss: 0.374648; batch adversarial loss: 0.566224\n",
      "epoch 89; iter: 0; batch classifier loss: 0.345034; batch adversarial loss: 0.606592\n",
      "epoch 90; iter: 0; batch classifier loss: 0.340868; batch adversarial loss: 0.535772\n",
      "epoch 91; iter: 0; batch classifier loss: 0.376235; batch adversarial loss: 0.489311\n",
      "epoch 92; iter: 0; batch classifier loss: 0.403011; batch adversarial loss: 0.597106\n",
      "epoch 93; iter: 0; batch classifier loss: 0.438325; batch adversarial loss: 0.629211\n",
      "epoch 94; iter: 0; batch classifier loss: 0.320504; batch adversarial loss: 0.562626\n",
      "epoch 95; iter: 0; batch classifier loss: 0.379622; batch adversarial loss: 0.549550\n",
      "epoch 96; iter: 0; batch classifier loss: 0.402893; batch adversarial loss: 0.512984\n",
      "epoch 97; iter: 0; batch classifier loss: 0.329858; batch adversarial loss: 0.585305\n",
      "epoch 98; iter: 0; batch classifier loss: 0.413846; batch adversarial loss: 0.527338\n",
      "epoch 99; iter: 0; batch classifier loss: 0.330800; batch adversarial loss: 0.580475\n",
      "epoch 100; iter: 0; batch classifier loss: 0.481913; batch adversarial loss: 0.590565\n",
      "epoch 101; iter: 0; batch classifier loss: 0.302159; batch adversarial loss: 0.563257\n",
      "epoch 102; iter: 0; batch classifier loss: 0.356874; batch adversarial loss: 0.613532\n",
      "epoch 103; iter: 0; batch classifier loss: 0.425641; batch adversarial loss: 0.551240\n",
      "epoch 104; iter: 0; batch classifier loss: 0.292658; batch adversarial loss: 0.593439\n",
      "epoch 105; iter: 0; batch classifier loss: 0.317082; batch adversarial loss: 0.568789\n",
      "epoch 106; iter: 0; batch classifier loss: 0.381818; batch adversarial loss: 0.633134\n",
      "epoch 107; iter: 0; batch classifier loss: 0.350001; batch adversarial loss: 0.625035\n",
      "epoch 108; iter: 0; batch classifier loss: 0.349075; batch adversarial loss: 0.603617\n",
      "epoch 109; iter: 0; batch classifier loss: 0.375316; batch adversarial loss: 0.567379\n",
      "epoch 110; iter: 0; batch classifier loss: 0.301576; batch adversarial loss: 0.536662\n",
      "epoch 111; iter: 0; batch classifier loss: 0.289530; batch adversarial loss: 0.535830\n",
      "epoch 112; iter: 0; batch classifier loss: 0.266070; batch adversarial loss: 0.487396\n",
      "epoch 113; iter: 0; batch classifier loss: 0.343682; batch adversarial loss: 0.581690\n",
      "epoch 114; iter: 0; batch classifier loss: 0.498626; batch adversarial loss: 0.563738\n",
      "epoch 115; iter: 0; batch classifier loss: 0.355177; batch adversarial loss: 0.521921\n",
      "epoch 116; iter: 0; batch classifier loss: 0.350412; batch adversarial loss: 0.586500\n",
      "epoch 117; iter: 0; batch classifier loss: 0.298992; batch adversarial loss: 0.526991\n",
      "epoch 118; iter: 0; batch classifier loss: 0.293300; batch adversarial loss: 0.607040\n",
      "epoch 119; iter: 0; batch classifier loss: 0.419212; batch adversarial loss: 0.578213\n",
      "epoch 120; iter: 0; batch classifier loss: 0.399799; batch adversarial loss: 0.665620\n",
      "epoch 121; iter: 0; batch classifier loss: 0.352310; batch adversarial loss: 0.497550\n",
      "epoch 122; iter: 0; batch classifier loss: 0.337893; batch adversarial loss: 0.590010\n",
      "epoch 123; iter: 0; batch classifier loss: 0.329372; batch adversarial loss: 0.586980\n",
      "epoch 124; iter: 0; batch classifier loss: 0.343259; batch adversarial loss: 0.487890\n",
      "epoch 125; iter: 0; batch classifier loss: 0.382518; batch adversarial loss: 0.579624\n",
      "epoch 126; iter: 0; batch classifier loss: 0.382153; batch adversarial loss: 0.529268\n",
      "epoch 127; iter: 0; batch classifier loss: 0.443327; batch adversarial loss: 0.638528\n",
      "epoch 128; iter: 0; batch classifier loss: 0.401069; batch adversarial loss: 0.575609\n",
      "epoch 129; iter: 0; batch classifier loss: 0.359809; batch adversarial loss: 0.553445\n",
      "epoch 130; iter: 0; batch classifier loss: 0.284961; batch adversarial loss: 0.575948\n",
      "epoch 131; iter: 0; batch classifier loss: 0.267685; batch adversarial loss: 0.559754\n",
      "epoch 132; iter: 0; batch classifier loss: 0.333344; batch adversarial loss: 0.571564\n",
      "epoch 133; iter: 0; batch classifier loss: 0.314937; batch adversarial loss: 0.603598\n",
      "epoch 134; iter: 0; batch classifier loss: 0.275247; batch adversarial loss: 0.572002\n",
      "epoch 135; iter: 0; batch classifier loss: 0.340584; batch adversarial loss: 0.610110\n",
      "epoch 136; iter: 0; batch classifier loss: 0.360901; batch adversarial loss: 0.558439\n",
      "epoch 137; iter: 0; batch classifier loss: 0.337319; batch adversarial loss: 0.537842\n",
      "epoch 138; iter: 0; batch classifier loss: 0.410702; batch adversarial loss: 0.529095\n",
      "epoch 139; iter: 0; batch classifier loss: 0.338566; batch adversarial loss: 0.610567\n",
      "epoch 140; iter: 0; batch classifier loss: 0.332236; batch adversarial loss: 0.554740\n",
      "epoch 141; iter: 0; batch classifier loss: 0.327895; batch adversarial loss: 0.562882\n",
      "epoch 142; iter: 0; batch classifier loss: 0.389897; batch adversarial loss: 0.528579\n",
      "epoch 143; iter: 0; batch classifier loss: 0.338634; batch adversarial loss: 0.551531\n",
      "epoch 144; iter: 0; batch classifier loss: 0.464768; batch adversarial loss: 0.478305\n",
      "epoch 145; iter: 0; batch classifier loss: 0.306728; batch adversarial loss: 0.588060\n",
      "epoch 146; iter: 0; batch classifier loss: 0.316908; batch adversarial loss: 0.474766\n",
      "epoch 147; iter: 0; batch classifier loss: 0.309486; batch adversarial loss: 0.571193\n",
      "epoch 148; iter: 0; batch classifier loss: 0.312899; batch adversarial loss: 0.568989\n",
      "epoch 149; iter: 0; batch classifier loss: 0.418158; batch adversarial loss: 0.554351\n",
      "epoch 150; iter: 0; batch classifier loss: 0.299870; batch adversarial loss: 0.526329\n",
      "epoch 151; iter: 0; batch classifier loss: 0.338480; batch adversarial loss: 0.569489\n",
      "epoch 152; iter: 0; batch classifier loss: 0.450706; batch adversarial loss: 0.547861\n",
      "epoch 153; iter: 0; batch classifier loss: 0.338172; batch adversarial loss: 0.581442\n",
      "epoch 154; iter: 0; batch classifier loss: 0.308474; batch adversarial loss: 0.557497\n",
      "epoch 155; iter: 0; batch classifier loss: 0.337778; batch adversarial loss: 0.669767\n",
      "epoch 156; iter: 0; batch classifier loss: 0.424786; batch adversarial loss: 0.565231\n",
      "epoch 157; iter: 0; batch classifier loss: 0.337651; batch adversarial loss: 0.595923\n",
      "epoch 158; iter: 0; batch classifier loss: 0.358949; batch adversarial loss: 0.614112\n",
      "epoch 159; iter: 0; batch classifier loss: 0.321366; batch adversarial loss: 0.473654\n",
      "epoch 160; iter: 0; batch classifier loss: 0.323087; batch adversarial loss: 0.602134\n",
      "epoch 161; iter: 0; batch classifier loss: 0.324087; batch adversarial loss: 0.574341\n",
      "epoch 162; iter: 0; batch classifier loss: 0.321036; batch adversarial loss: 0.560684\n",
      "epoch 163; iter: 0; batch classifier loss: 0.363485; batch adversarial loss: 0.551705\n",
      "epoch 164; iter: 0; batch classifier loss: 0.287659; batch adversarial loss: 0.523223\n",
      "epoch 165; iter: 0; batch classifier loss: 0.288052; batch adversarial loss: 0.533028\n",
      "epoch 166; iter: 0; batch classifier loss: 0.343345; batch adversarial loss: 0.598006\n",
      "epoch 167; iter: 0; batch classifier loss: 0.302558; batch adversarial loss: 0.554568\n",
      "epoch 168; iter: 0; batch classifier loss: 0.410250; batch adversarial loss: 0.561995\n",
      "epoch 169; iter: 0; batch classifier loss: 0.297157; batch adversarial loss: 0.526805\n",
      "epoch 170; iter: 0; batch classifier loss: 0.329315; batch adversarial loss: 0.590290\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 171; iter: 0; batch classifier loss: 0.293778; batch adversarial loss: 0.566417\n",
      "epoch 172; iter: 0; batch classifier loss: 0.378128; batch adversarial loss: 0.672211\n",
      "epoch 173; iter: 0; batch classifier loss: 0.316626; batch adversarial loss: 0.536197\n",
      "epoch 174; iter: 0; batch classifier loss: 0.285190; batch adversarial loss: 0.528397\n",
      "epoch 175; iter: 0; batch classifier loss: 0.352897; batch adversarial loss: 0.570383\n",
      "epoch 176; iter: 0; batch classifier loss: 0.303073; batch adversarial loss: 0.508669\n",
      "epoch 177; iter: 0; batch classifier loss: 0.416460; batch adversarial loss: 0.564403\n",
      "epoch 178; iter: 0; batch classifier loss: 0.314142; batch adversarial loss: 0.573055\n",
      "epoch 179; iter: 0; batch classifier loss: 0.294191; batch adversarial loss: 0.569821\n",
      "epoch 180; iter: 0; batch classifier loss: 0.323367; batch adversarial loss: 0.612793\n",
      "epoch 181; iter: 0; batch classifier loss: 0.360004; batch adversarial loss: 0.538175\n",
      "epoch 182; iter: 0; batch classifier loss: 0.338589; batch adversarial loss: 0.535723\n",
      "epoch 183; iter: 0; batch classifier loss: 0.391468; batch adversarial loss: 0.486850\n",
      "epoch 184; iter: 0; batch classifier loss: 0.294583; batch adversarial loss: 0.605286\n",
      "epoch 185; iter: 0; batch classifier loss: 0.364414; batch adversarial loss: 0.631027\n",
      "epoch 186; iter: 0; batch classifier loss: 0.391223; batch adversarial loss: 0.581467\n",
      "epoch 187; iter: 0; batch classifier loss: 0.265392; batch adversarial loss: 0.497132\n",
      "epoch 188; iter: 0; batch classifier loss: 0.406386; batch adversarial loss: 0.589209\n",
      "epoch 189; iter: 0; batch classifier loss: 0.306900; batch adversarial loss: 0.576574\n",
      "epoch 190; iter: 0; batch classifier loss: 0.320604; batch adversarial loss: 0.476552\n",
      "epoch 191; iter: 0; batch classifier loss: 0.392750; batch adversarial loss: 0.495986\n",
      "epoch 192; iter: 0; batch classifier loss: 0.335325; batch adversarial loss: 0.611176\n",
      "epoch 193; iter: 0; batch classifier loss: 0.314859; batch adversarial loss: 0.568260\n",
      "epoch 194; iter: 0; batch classifier loss: 0.305272; batch adversarial loss: 0.534573\n",
      "epoch 195; iter: 0; batch classifier loss: 0.363108; batch adversarial loss: 0.535946\n",
      "epoch 196; iter: 0; batch classifier loss: 0.261368; batch adversarial loss: 0.578565\n",
      "epoch 197; iter: 0; batch classifier loss: 0.380765; batch adversarial loss: 0.620518\n",
      "epoch 198; iter: 0; batch classifier loss: 0.363357; batch adversarial loss: 0.556296\n",
      "epoch 199; iter: 0; batch classifier loss: 0.420640; batch adversarial loss: 0.518819\n",
      "epoch 0; iter: 0; batch classifier loss: 0.713213; batch adversarial loss: 0.648750\n",
      "epoch 1; iter: 0; batch classifier loss: 0.603857; batch adversarial loss: 0.639288\n",
      "epoch 2; iter: 0; batch classifier loss: 0.644026; batch adversarial loss: 0.642764\n",
      "epoch 3; iter: 0; batch classifier loss: 0.491819; batch adversarial loss: 0.652268\n",
      "epoch 4; iter: 0; batch classifier loss: 0.573633; batch adversarial loss: 0.573676\n",
      "epoch 5; iter: 0; batch classifier loss: 0.623648; batch adversarial loss: 0.643667\n",
      "epoch 6; iter: 0; batch classifier loss: 0.539068; batch adversarial loss: 0.647802\n",
      "epoch 7; iter: 0; batch classifier loss: 0.588495; batch adversarial loss: 0.570053\n",
      "epoch 8; iter: 0; batch classifier loss: 0.564108; batch adversarial loss: 0.621808\n",
      "epoch 9; iter: 0; batch classifier loss: 0.580071; batch adversarial loss: 0.620328\n",
      "epoch 10; iter: 0; batch classifier loss: 0.540640; batch adversarial loss: 0.630255\n",
      "epoch 11; iter: 0; batch classifier loss: 0.603055; batch adversarial loss: 0.508372\n",
      "epoch 12; iter: 0; batch classifier loss: 0.532065; batch adversarial loss: 0.552545\n",
      "epoch 13; iter: 0; batch classifier loss: 0.546802; batch adversarial loss: 0.517035\n",
      "epoch 14; iter: 0; batch classifier loss: 0.541104; batch adversarial loss: 0.532618\n",
      "epoch 15; iter: 0; batch classifier loss: 0.439700; batch adversarial loss: 0.531291\n",
      "epoch 16; iter: 0; batch classifier loss: 0.510611; batch adversarial loss: 0.542394\n",
      "epoch 17; iter: 0; batch classifier loss: 0.473236; batch adversarial loss: 0.527761\n",
      "epoch 18; iter: 0; batch classifier loss: 0.456209; batch adversarial loss: 0.552446\n",
      "epoch 19; iter: 0; batch classifier loss: 0.477227; batch adversarial loss: 0.551657\n",
      "epoch 20; iter: 0; batch classifier loss: 0.531392; batch adversarial loss: 0.590565\n",
      "epoch 21; iter: 0; batch classifier loss: 0.449345; batch adversarial loss: 0.574844\n",
      "epoch 22; iter: 0; batch classifier loss: 0.420077; batch adversarial loss: 0.545137\n",
      "epoch 23; iter: 0; batch classifier loss: 0.508843; batch adversarial loss: 0.634133\n",
      "epoch 24; iter: 0; batch classifier loss: 0.586565; batch adversarial loss: 0.515128\n",
      "epoch 25; iter: 0; batch classifier loss: 0.488689; batch adversarial loss: 0.575457\n",
      "epoch 26; iter: 0; batch classifier loss: 0.486971; batch adversarial loss: 0.530277\n",
      "epoch 27; iter: 0; batch classifier loss: 0.444426; batch adversarial loss: 0.541989\n",
      "epoch 28; iter: 0; batch classifier loss: 0.468049; batch adversarial loss: 0.487342\n",
      "epoch 29; iter: 0; batch classifier loss: 0.419878; batch adversarial loss: 0.561903\n",
      "epoch 30; iter: 0; batch classifier loss: 0.508450; batch adversarial loss: 0.593240\n",
      "epoch 31; iter: 0; batch classifier loss: 0.417669; batch adversarial loss: 0.519867\n",
      "epoch 32; iter: 0; batch classifier loss: 0.457843; batch adversarial loss: 0.577870\n",
      "epoch 33; iter: 0; batch classifier loss: 0.406824; batch adversarial loss: 0.535512\n",
      "epoch 34; iter: 0; batch classifier loss: 0.484210; batch adversarial loss: 0.617475\n",
      "epoch 35; iter: 0; batch classifier loss: 0.459584; batch adversarial loss: 0.527387\n",
      "epoch 36; iter: 0; batch classifier loss: 0.462304; batch adversarial loss: 0.508868\n",
      "epoch 37; iter: 0; batch classifier loss: 0.479148; batch adversarial loss: 0.543772\n",
      "epoch 38; iter: 0; batch classifier loss: 0.366847; batch adversarial loss: 0.565399\n",
      "epoch 39; iter: 0; batch classifier loss: 0.382851; batch adversarial loss: 0.470496\n",
      "epoch 40; iter: 0; batch classifier loss: 0.438783; batch adversarial loss: 0.536414\n",
      "epoch 41; iter: 0; batch classifier loss: 0.435747; batch adversarial loss: 0.535144\n",
      "epoch 42; iter: 0; batch classifier loss: 0.487653; batch adversarial loss: 0.525107\n",
      "epoch 43; iter: 0; batch classifier loss: 0.401240; batch adversarial loss: 0.543134\n",
      "epoch 44; iter: 0; batch classifier loss: 0.399411; batch adversarial loss: 0.616484\n",
      "epoch 45; iter: 0; batch classifier loss: 0.439670; batch adversarial loss: 0.536362\n",
      "epoch 46; iter: 0; batch classifier loss: 0.487476; batch adversarial loss: 0.598069\n",
      "epoch 47; iter: 0; batch classifier loss: 0.400963; batch adversarial loss: 0.527680\n",
      "epoch 48; iter: 0; batch classifier loss: 0.501443; batch adversarial loss: 0.535348\n",
      "epoch 49; iter: 0; batch classifier loss: 0.377651; batch adversarial loss: 0.517313\n",
      "epoch 50; iter: 0; batch classifier loss: 0.381719; batch adversarial loss: 0.460100\n",
      "epoch 51; iter: 0; batch classifier loss: 0.423387; batch adversarial loss: 0.442146\n",
      "epoch 52; iter: 0; batch classifier loss: 0.420012; batch adversarial loss: 0.518732\n",
      "epoch 53; iter: 0; batch classifier loss: 0.408077; batch adversarial loss: 0.544088\n",
      "epoch 54; iter: 0; batch classifier loss: 0.446881; batch adversarial loss: 0.556226\n",
      "epoch 55; iter: 0; batch classifier loss: 0.468499; batch adversarial loss: 0.517022\n",
      "epoch 56; iter: 0; batch classifier loss: 0.394586; batch adversarial loss: 0.500969\n",
      "epoch 57; iter: 0; batch classifier loss: 0.389906; batch adversarial loss: 0.616983\n",
      "epoch 58; iter: 0; batch classifier loss: 0.444733; batch adversarial loss: 0.480551\n",
      "epoch 59; iter: 0; batch classifier loss: 0.369282; batch adversarial loss: 0.443195\n",
      "epoch 60; iter: 0; batch classifier loss: 0.365266; batch adversarial loss: 0.536321\n",
      "epoch 61; iter: 0; batch classifier loss: 0.355269; batch adversarial loss: 0.526609\n",
      "epoch 62; iter: 0; batch classifier loss: 0.452908; batch adversarial loss: 0.522983\n",
      "epoch 63; iter: 0; batch classifier loss: 0.364433; batch adversarial loss: 0.468143\n",
      "epoch 64; iter: 0; batch classifier loss: 0.416880; batch adversarial loss: 0.599907\n",
      "epoch 65; iter: 0; batch classifier loss: 0.390974; batch adversarial loss: 0.563653\n",
      "epoch 66; iter: 0; batch classifier loss: 0.375889; batch adversarial loss: 0.487158\n",
      "epoch 67; iter: 0; batch classifier loss: 0.360188; batch adversarial loss: 0.598671\n",
      "epoch 68; iter: 0; batch classifier loss: 0.395058; batch adversarial loss: 0.545892\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 69; iter: 0; batch classifier loss: 0.392448; batch adversarial loss: 0.580724\n",
      "epoch 70; iter: 0; batch classifier loss: 0.353429; batch adversarial loss: 0.518784\n",
      "epoch 71; iter: 0; batch classifier loss: 0.386417; batch adversarial loss: 0.598861\n",
      "epoch 72; iter: 0; batch classifier loss: 0.353652; batch adversarial loss: 0.590645\n",
      "epoch 73; iter: 0; batch classifier loss: 0.355199; batch adversarial loss: 0.599775\n",
      "epoch 74; iter: 0; batch classifier loss: 0.359759; batch adversarial loss: 0.533998\n",
      "epoch 75; iter: 0; batch classifier loss: 0.404124; batch adversarial loss: 0.553339\n",
      "epoch 76; iter: 0; batch classifier loss: 0.413784; batch adversarial loss: 0.477613\n",
      "epoch 77; iter: 0; batch classifier loss: 0.398696; batch adversarial loss: 0.515492\n",
      "epoch 78; iter: 0; batch classifier loss: 0.447077; batch adversarial loss: 0.524569\n",
      "epoch 79; iter: 0; batch classifier loss: 0.436547; batch adversarial loss: 0.553745\n",
      "epoch 80; iter: 0; batch classifier loss: 0.365443; batch adversarial loss: 0.490307\n",
      "epoch 81; iter: 0; batch classifier loss: 0.402526; batch adversarial loss: 0.578765\n",
      "epoch 82; iter: 0; batch classifier loss: 0.419904; batch adversarial loss: 0.527424\n",
      "epoch 83; iter: 0; batch classifier loss: 0.317782; batch adversarial loss: 0.564630\n",
      "epoch 84; iter: 0; batch classifier loss: 0.409592; batch adversarial loss: 0.545376\n",
      "epoch 85; iter: 0; batch classifier loss: 0.421087; batch adversarial loss: 0.608815\n",
      "epoch 86; iter: 0; batch classifier loss: 0.369255; batch adversarial loss: 0.618415\n",
      "epoch 87; iter: 0; batch classifier loss: 0.323076; batch adversarial loss: 0.562192\n",
      "epoch 88; iter: 0; batch classifier loss: 0.316750; batch adversarial loss: 0.516058\n",
      "epoch 89; iter: 0; batch classifier loss: 0.427503; batch adversarial loss: 0.608482\n",
      "epoch 90; iter: 0; batch classifier loss: 0.488157; batch adversarial loss: 0.507866\n",
      "epoch 91; iter: 0; batch classifier loss: 0.378255; batch adversarial loss: 0.553495\n",
      "epoch 92; iter: 0; batch classifier loss: 0.477486; batch adversarial loss: 0.524757\n",
      "epoch 93; iter: 0; batch classifier loss: 0.449164; batch adversarial loss: 0.451541\n",
      "epoch 94; iter: 0; batch classifier loss: 0.443270; batch adversarial loss: 0.535336\n",
      "epoch 95; iter: 0; batch classifier loss: 0.338738; batch adversarial loss: 0.563050\n",
      "epoch 96; iter: 0; batch classifier loss: 0.370918; batch adversarial loss: 0.639270\n",
      "epoch 97; iter: 0; batch classifier loss: 0.352444; batch adversarial loss: 0.525378\n",
      "epoch 98; iter: 0; batch classifier loss: 0.426553; batch adversarial loss: 0.490010\n",
      "epoch 99; iter: 0; batch classifier loss: 0.451835; batch adversarial loss: 0.479460\n",
      "epoch 100; iter: 0; batch classifier loss: 0.491264; batch adversarial loss: 0.580303\n",
      "epoch 101; iter: 0; batch classifier loss: 0.409263; batch adversarial loss: 0.572959\n",
      "epoch 102; iter: 0; batch classifier loss: 0.412641; batch adversarial loss: 0.572807\n",
      "epoch 103; iter: 0; batch classifier loss: 0.381468; batch adversarial loss: 0.526932\n",
      "epoch 104; iter: 0; batch classifier loss: 0.313679; batch adversarial loss: 0.507902\n",
      "epoch 105; iter: 0; batch classifier loss: 0.374009; batch adversarial loss: 0.573033\n",
      "epoch 106; iter: 0; batch classifier loss: 0.334136; batch adversarial loss: 0.591164\n",
      "epoch 107; iter: 0; batch classifier loss: 0.310956; batch adversarial loss: 0.616352\n",
      "epoch 108; iter: 0; batch classifier loss: 0.388238; batch adversarial loss: 0.589020\n",
      "epoch 109; iter: 0; batch classifier loss: 0.346398; batch adversarial loss: 0.467691\n",
      "epoch 110; iter: 0; batch classifier loss: 0.350083; batch adversarial loss: 0.522945\n",
      "epoch 111; iter: 0; batch classifier loss: 0.392951; batch adversarial loss: 0.646596\n",
      "epoch 112; iter: 0; batch classifier loss: 0.438667; batch adversarial loss: 0.519346\n",
      "epoch 113; iter: 0; batch classifier loss: 0.361372; batch adversarial loss: 0.553035\n",
      "epoch 114; iter: 0; batch classifier loss: 0.370260; batch adversarial loss: 0.524860\n",
      "epoch 115; iter: 0; batch classifier loss: 0.388163; batch adversarial loss: 0.518807\n",
      "epoch 116; iter: 0; batch classifier loss: 0.422712; batch adversarial loss: 0.509407\n",
      "epoch 117; iter: 0; batch classifier loss: 0.404029; batch adversarial loss: 0.481261\n",
      "epoch 118; iter: 0; batch classifier loss: 0.396305; batch adversarial loss: 0.508532\n",
      "epoch 119; iter: 0; batch classifier loss: 0.505997; batch adversarial loss: 0.562317\n",
      "epoch 120; iter: 0; batch classifier loss: 0.351546; batch adversarial loss: 0.544540\n",
      "epoch 121; iter: 0; batch classifier loss: 0.418445; batch adversarial loss: 0.516822\n",
      "epoch 122; iter: 0; batch classifier loss: 0.377511; batch adversarial loss: 0.506745\n",
      "epoch 123; iter: 0; batch classifier loss: 0.415459; batch adversarial loss: 0.580933\n",
      "epoch 124; iter: 0; batch classifier loss: 0.381831; batch adversarial loss: 0.534265\n",
      "epoch 125; iter: 0; batch classifier loss: 0.430012; batch adversarial loss: 0.487997\n",
      "epoch 126; iter: 0; batch classifier loss: 0.384158; batch adversarial loss: 0.525856\n",
      "epoch 127; iter: 0; batch classifier loss: 0.330619; batch adversarial loss: 0.498569\n",
      "epoch 128; iter: 0; batch classifier loss: 0.348476; batch adversarial loss: 0.553258\n",
      "epoch 129; iter: 0; batch classifier loss: 0.346321; batch adversarial loss: 0.525882\n",
      "epoch 130; iter: 0; batch classifier loss: 0.321733; batch adversarial loss: 0.573463\n",
      "epoch 131; iter: 0; batch classifier loss: 0.286311; batch adversarial loss: 0.554563\n",
      "epoch 132; iter: 0; batch classifier loss: 0.302460; batch adversarial loss: 0.580311\n",
      "epoch 133; iter: 0; batch classifier loss: 0.486949; batch adversarial loss: 0.626201\n",
      "epoch 134; iter: 0; batch classifier loss: 0.369813; batch adversarial loss: 0.508213\n",
      "epoch 135; iter: 0; batch classifier loss: 0.385914; batch adversarial loss: 0.665497\n",
      "epoch 136; iter: 0; batch classifier loss: 0.376157; batch adversarial loss: 0.591617\n",
      "epoch 137; iter: 0; batch classifier loss: 0.396313; batch adversarial loss: 0.618429\n",
      "epoch 138; iter: 0; batch classifier loss: 0.341333; batch adversarial loss: 0.524574\n",
      "epoch 139; iter: 0; batch classifier loss: 0.324778; batch adversarial loss: 0.526816\n",
      "epoch 140; iter: 0; batch classifier loss: 0.341549; batch adversarial loss: 0.609496\n",
      "epoch 141; iter: 0; batch classifier loss: 0.425629; batch adversarial loss: 0.600500\n",
      "epoch 142; iter: 0; batch classifier loss: 0.403557; batch adversarial loss: 0.637671\n",
      "epoch 143; iter: 0; batch classifier loss: 0.380223; batch adversarial loss: 0.599505\n",
      "epoch 144; iter: 0; batch classifier loss: 0.312259; batch adversarial loss: 0.561820\n",
      "epoch 145; iter: 0; batch classifier loss: 0.363215; batch adversarial loss: 0.552668\n",
      "epoch 146; iter: 0; batch classifier loss: 0.316257; batch adversarial loss: 0.656143\n",
      "epoch 147; iter: 0; batch classifier loss: 0.384482; batch adversarial loss: 0.582453\n",
      "epoch 148; iter: 0; batch classifier loss: 0.367470; batch adversarial loss: 0.601360\n",
      "epoch 149; iter: 0; batch classifier loss: 0.352317; batch adversarial loss: 0.442445\n",
      "epoch 150; iter: 0; batch classifier loss: 0.302162; batch adversarial loss: 0.534520\n",
      "epoch 151; iter: 0; batch classifier loss: 0.361580; batch adversarial loss: 0.535845\n",
      "epoch 152; iter: 0; batch classifier loss: 0.309744; batch adversarial loss: 0.507104\n",
      "epoch 153; iter: 0; batch classifier loss: 0.322740; batch adversarial loss: 0.581253\n",
      "epoch 154; iter: 0; batch classifier loss: 0.439803; batch adversarial loss: 0.553634\n",
      "epoch 155; iter: 0; batch classifier loss: 0.314905; batch adversarial loss: 0.452108\n",
      "epoch 156; iter: 0; batch classifier loss: 0.381219; batch adversarial loss: 0.545367\n",
      "epoch 157; iter: 0; batch classifier loss: 0.370731; batch adversarial loss: 0.591460\n",
      "epoch 158; iter: 0; batch classifier loss: 0.325688; batch adversarial loss: 0.581759\n",
      "epoch 159; iter: 0; batch classifier loss: 0.387649; batch adversarial loss: 0.562615\n",
      "epoch 160; iter: 0; batch classifier loss: 0.368121; batch adversarial loss: 0.517005\n",
      "epoch 161; iter: 0; batch classifier loss: 0.344099; batch adversarial loss: 0.580886\n",
      "epoch 162; iter: 0; batch classifier loss: 0.363788; batch adversarial loss: 0.544204\n",
      "epoch 163; iter: 0; batch classifier loss: 0.353122; batch adversarial loss: 0.580118\n",
      "epoch 164; iter: 0; batch classifier loss: 0.368307; batch adversarial loss: 0.525756\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 165; iter: 0; batch classifier loss: 0.365389; batch adversarial loss: 0.507825\n",
      "epoch 166; iter: 0; batch classifier loss: 0.344129; batch adversarial loss: 0.496960\n",
      "epoch 167; iter: 0; batch classifier loss: 0.307774; batch adversarial loss: 0.516279\n",
      "epoch 168; iter: 0; batch classifier loss: 0.389523; batch adversarial loss: 0.581194\n",
      "epoch 169; iter: 0; batch classifier loss: 0.314214; batch adversarial loss: 0.525715\n",
      "epoch 170; iter: 0; batch classifier loss: 0.386561; batch adversarial loss: 0.489972\n",
      "epoch 171; iter: 0; batch classifier loss: 0.399828; batch adversarial loss: 0.552368\n",
      "epoch 172; iter: 0; batch classifier loss: 0.306444; batch adversarial loss: 0.607521\n",
      "epoch 173; iter: 0; batch classifier loss: 0.339728; batch adversarial loss: 0.601283\n",
      "epoch 174; iter: 0; batch classifier loss: 0.288620; batch adversarial loss: 0.562706\n",
      "epoch 175; iter: 0; batch classifier loss: 0.333604; batch adversarial loss: 0.516302\n",
      "epoch 176; iter: 0; batch classifier loss: 0.340519; batch adversarial loss: 0.572642\n",
      "epoch 177; iter: 0; batch classifier loss: 0.279268; batch adversarial loss: 0.498530\n",
      "epoch 178; iter: 0; batch classifier loss: 0.333747; batch adversarial loss: 0.488659\n",
      "epoch 179; iter: 0; batch classifier loss: 0.372144; batch adversarial loss: 0.462223\n",
      "epoch 180; iter: 0; batch classifier loss: 0.289701; batch adversarial loss: 0.525932\n",
      "epoch 181; iter: 0; batch classifier loss: 0.410969; batch adversarial loss: 0.535731\n",
      "epoch 182; iter: 0; batch classifier loss: 0.342088; batch adversarial loss: 0.509045\n",
      "epoch 183; iter: 0; batch classifier loss: 0.311419; batch adversarial loss: 0.460848\n",
      "epoch 184; iter: 0; batch classifier loss: 0.291961; batch adversarial loss: 0.599947\n",
      "epoch 185; iter: 0; batch classifier loss: 0.353262; batch adversarial loss: 0.517104\n",
      "epoch 186; iter: 0; batch classifier loss: 0.334365; batch adversarial loss: 0.563534\n",
      "epoch 187; iter: 0; batch classifier loss: 0.336567; batch adversarial loss: 0.628234\n",
      "epoch 188; iter: 0; batch classifier loss: 0.322763; batch adversarial loss: 0.592488\n",
      "epoch 189; iter: 0; batch classifier loss: 0.328450; batch adversarial loss: 0.535436\n",
      "epoch 190; iter: 0; batch classifier loss: 0.367150; batch adversarial loss: 0.478428\n",
      "epoch 191; iter: 0; batch classifier loss: 0.323392; batch adversarial loss: 0.535416\n",
      "epoch 192; iter: 0; batch classifier loss: 0.251093; batch adversarial loss: 0.507480\n",
      "epoch 193; iter: 0; batch classifier loss: 0.284451; batch adversarial loss: 0.479024\n",
      "epoch 194; iter: 0; batch classifier loss: 0.396866; batch adversarial loss: 0.570962\n",
      "epoch 195; iter: 0; batch classifier loss: 0.397543; batch adversarial loss: 0.600288\n",
      "epoch 196; iter: 0; batch classifier loss: 0.351777; batch adversarial loss: 0.498407\n",
      "epoch 197; iter: 0; batch classifier loss: 0.387536; batch adversarial loss: 0.553391\n",
      "epoch 198; iter: 0; batch classifier loss: 0.272103; batch adversarial loss: 0.544208\n",
      "epoch 199; iter: 0; batch classifier loss: 0.324083; batch adversarial loss: 0.552952\n",
      "epoch 0; iter: 0; batch classifier loss: 0.697329; batch adversarial loss: 0.793440\n",
      "epoch 1; iter: 0; batch classifier loss: 0.567783; batch adversarial loss: 0.808670\n",
      "epoch 2; iter: 0; batch classifier loss: 0.571484; batch adversarial loss: 0.752425\n",
      "epoch 3; iter: 0; batch classifier loss: 0.539434; batch adversarial loss: 0.685756\n",
      "epoch 4; iter: 0; batch classifier loss: 0.600737; batch adversarial loss: 0.670563\n",
      "epoch 5; iter: 0; batch classifier loss: 0.480547; batch adversarial loss: 0.676793\n",
      "epoch 6; iter: 0; batch classifier loss: 0.592175; batch adversarial loss: 0.674922\n",
      "epoch 7; iter: 0; batch classifier loss: 0.540908; batch adversarial loss: 0.638657\n",
      "epoch 8; iter: 0; batch classifier loss: 0.492965; batch adversarial loss: 0.605403\n",
      "epoch 9; iter: 0; batch classifier loss: 0.585806; batch adversarial loss: 0.637725\n",
      "epoch 10; iter: 0; batch classifier loss: 0.527731; batch adversarial loss: 0.619330\n",
      "epoch 11; iter: 0; batch classifier loss: 0.505568; batch adversarial loss: 0.620939\n",
      "epoch 12; iter: 0; batch classifier loss: 0.571768; batch adversarial loss: 0.561578\n",
      "epoch 13; iter: 0; batch classifier loss: 0.417959; batch adversarial loss: 0.594018\n",
      "epoch 14; iter: 0; batch classifier loss: 0.546072; batch adversarial loss: 0.554831\n",
      "epoch 15; iter: 0; batch classifier loss: 0.498013; batch adversarial loss: 0.605570\n",
      "epoch 16; iter: 0; batch classifier loss: 0.445810; batch adversarial loss: 0.598717\n",
      "epoch 17; iter: 0; batch classifier loss: 0.506384; batch adversarial loss: 0.551451\n",
      "epoch 18; iter: 0; batch classifier loss: 0.428528; batch adversarial loss: 0.556583\n",
      "epoch 19; iter: 0; batch classifier loss: 0.498237; batch adversarial loss: 0.571215\n",
      "epoch 20; iter: 0; batch classifier loss: 0.518454; batch adversarial loss: 0.544830\n",
      "epoch 21; iter: 0; batch classifier loss: 0.509954; batch adversarial loss: 0.511823\n",
      "epoch 22; iter: 0; batch classifier loss: 0.412619; batch adversarial loss: 0.523504\n",
      "epoch 23; iter: 0; batch classifier loss: 0.451746; batch adversarial loss: 0.514288\n",
      "epoch 24; iter: 0; batch classifier loss: 0.465602; batch adversarial loss: 0.561651\n",
      "epoch 25; iter: 0; batch classifier loss: 0.482990; batch adversarial loss: 0.582887\n",
      "epoch 26; iter: 0; batch classifier loss: 0.520223; batch adversarial loss: 0.515234\n",
      "epoch 27; iter: 0; batch classifier loss: 0.422906; batch adversarial loss: 0.571687\n",
      "epoch 28; iter: 0; batch classifier loss: 0.460309; batch adversarial loss: 0.523116\n",
      "epoch 29; iter: 0; batch classifier loss: 0.508170; batch adversarial loss: 0.560736\n",
      "epoch 30; iter: 0; batch classifier loss: 0.457460; batch adversarial loss: 0.593867\n",
      "epoch 31; iter: 0; batch classifier loss: 0.463599; batch adversarial loss: 0.560117\n",
      "epoch 32; iter: 0; batch classifier loss: 0.435893; batch adversarial loss: 0.564868\n",
      "epoch 33; iter: 0; batch classifier loss: 0.542707; batch adversarial loss: 0.572278\n",
      "epoch 34; iter: 0; batch classifier loss: 0.420506; batch adversarial loss: 0.553512\n",
      "epoch 35; iter: 0; batch classifier loss: 0.482558; batch adversarial loss: 0.528480\n",
      "epoch 36; iter: 0; batch classifier loss: 0.471102; batch adversarial loss: 0.569624\n",
      "epoch 37; iter: 0; batch classifier loss: 0.451990; batch adversarial loss: 0.570377\n",
      "epoch 38; iter: 0; batch classifier loss: 0.441661; batch adversarial loss: 0.500554\n",
      "epoch 39; iter: 0; batch classifier loss: 0.438359; batch adversarial loss: 0.547507\n",
      "epoch 40; iter: 0; batch classifier loss: 0.447605; batch adversarial loss: 0.552013\n",
      "epoch 41; iter: 0; batch classifier loss: 0.362112; batch adversarial loss: 0.589711\n",
      "epoch 42; iter: 0; batch classifier loss: 0.365238; batch adversarial loss: 0.552805\n",
      "epoch 43; iter: 0; batch classifier loss: 0.335096; batch adversarial loss: 0.537524\n",
      "epoch 44; iter: 0; batch classifier loss: 0.391765; batch adversarial loss: 0.560402\n",
      "epoch 45; iter: 0; batch classifier loss: 0.416392; batch adversarial loss: 0.514960\n",
      "epoch 46; iter: 0; batch classifier loss: 0.447335; batch adversarial loss: 0.527264\n",
      "epoch 47; iter: 0; batch classifier loss: 0.403593; batch adversarial loss: 0.545750\n",
      "epoch 48; iter: 0; batch classifier loss: 0.428169; batch adversarial loss: 0.515518\n",
      "epoch 49; iter: 0; batch classifier loss: 0.419996; batch adversarial loss: 0.572954\n",
      "epoch 50; iter: 0; batch classifier loss: 0.402993; batch adversarial loss: 0.568565\n",
      "epoch 51; iter: 0; batch classifier loss: 0.436264; batch adversarial loss: 0.527934\n",
      "epoch 52; iter: 0; batch classifier loss: 0.381333; batch adversarial loss: 0.536117\n",
      "epoch 53; iter: 0; batch classifier loss: 0.415629; batch adversarial loss: 0.574015\n",
      "epoch 54; iter: 0; batch classifier loss: 0.478767; batch adversarial loss: 0.542574\n",
      "epoch 55; iter: 0; batch classifier loss: 0.497733; batch adversarial loss: 0.626875\n",
      "epoch 56; iter: 0; batch classifier loss: 0.392124; batch adversarial loss: 0.580950\n",
      "epoch 57; iter: 0; batch classifier loss: 0.495605; batch adversarial loss: 0.491102\n",
      "epoch 58; iter: 0; batch classifier loss: 0.364934; batch adversarial loss: 0.563930\n",
      "epoch 59; iter: 0; batch classifier loss: 0.411159; batch adversarial loss: 0.499999\n",
      "epoch 60; iter: 0; batch classifier loss: 0.447753; batch adversarial loss: 0.559425\n",
      "epoch 61; iter: 0; batch classifier loss: 0.429607; batch adversarial loss: 0.615888\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 62; iter: 0; batch classifier loss: 0.431905; batch adversarial loss: 0.516506\n",
      "epoch 63; iter: 0; batch classifier loss: 0.433088; batch adversarial loss: 0.498530\n",
      "epoch 64; iter: 0; batch classifier loss: 0.426483; batch adversarial loss: 0.464414\n",
      "epoch 65; iter: 0; batch classifier loss: 0.398861; batch adversarial loss: 0.564184\n",
      "epoch 66; iter: 0; batch classifier loss: 0.438216; batch adversarial loss: 0.622814\n",
      "epoch 67; iter: 0; batch classifier loss: 0.353254; batch adversarial loss: 0.544948\n",
      "epoch 68; iter: 0; batch classifier loss: 0.468773; batch adversarial loss: 0.573731\n",
      "epoch 69; iter: 0; batch classifier loss: 0.426773; batch adversarial loss: 0.571644\n",
      "epoch 70; iter: 0; batch classifier loss: 0.382389; batch adversarial loss: 0.580031\n",
      "epoch 71; iter: 0; batch classifier loss: 0.422038; batch adversarial loss: 0.543857\n",
      "epoch 72; iter: 0; batch classifier loss: 0.369303; batch adversarial loss: 0.535337\n",
      "epoch 73; iter: 0; batch classifier loss: 0.375940; batch adversarial loss: 0.589938\n",
      "epoch 74; iter: 0; batch classifier loss: 0.386363; batch adversarial loss: 0.531934\n",
      "epoch 75; iter: 0; batch classifier loss: 0.447996; batch adversarial loss: 0.500246\n",
      "epoch 76; iter: 0; batch classifier loss: 0.402164; batch adversarial loss: 0.537629\n",
      "epoch 77; iter: 0; batch classifier loss: 0.464578; batch adversarial loss: 0.571563\n",
      "epoch 78; iter: 0; batch classifier loss: 0.395324; batch adversarial loss: 0.552758\n",
      "epoch 79; iter: 0; batch classifier loss: 0.368115; batch adversarial loss: 0.599677\n",
      "epoch 80; iter: 0; batch classifier loss: 0.398961; batch adversarial loss: 0.526264\n",
      "epoch 81; iter: 0; batch classifier loss: 0.344194; batch adversarial loss: 0.542999\n",
      "epoch 82; iter: 0; batch classifier loss: 0.371561; batch adversarial loss: 0.616752\n",
      "epoch 83; iter: 0; batch classifier loss: 0.420904; batch adversarial loss: 0.596366\n",
      "epoch 84; iter: 0; batch classifier loss: 0.374214; batch adversarial loss: 0.571981\n",
      "epoch 85; iter: 0; batch classifier loss: 0.350828; batch adversarial loss: 0.606314\n",
      "epoch 86; iter: 0; batch classifier loss: 0.348330; batch adversarial loss: 0.554811\n",
      "epoch 87; iter: 0; batch classifier loss: 0.418991; batch adversarial loss: 0.553283\n",
      "epoch 88; iter: 0; batch classifier loss: 0.365307; batch adversarial loss: 0.608723\n",
      "epoch 89; iter: 0; batch classifier loss: 0.456107; batch adversarial loss: 0.507198\n",
      "epoch 90; iter: 0; batch classifier loss: 0.391926; batch adversarial loss: 0.580211\n",
      "epoch 91; iter: 0; batch classifier loss: 0.371300; batch adversarial loss: 0.572415\n",
      "epoch 92; iter: 0; batch classifier loss: 0.412041; batch adversarial loss: 0.554261\n",
      "epoch 93; iter: 0; batch classifier loss: 0.414721; batch adversarial loss: 0.553640\n",
      "epoch 94; iter: 0; batch classifier loss: 0.306972; batch adversarial loss: 0.573121\n",
      "epoch 95; iter: 0; batch classifier loss: 0.436028; batch adversarial loss: 0.572608\n",
      "epoch 96; iter: 0; batch classifier loss: 0.431412; batch adversarial loss: 0.589976\n",
      "epoch 97; iter: 0; batch classifier loss: 0.380896; batch adversarial loss: 0.541715\n",
      "epoch 98; iter: 0; batch classifier loss: 0.461183; batch adversarial loss: 0.526339\n",
      "epoch 99; iter: 0; batch classifier loss: 0.332009; batch adversarial loss: 0.543456\n",
      "epoch 100; iter: 0; batch classifier loss: 0.395719; batch adversarial loss: 0.490669\n",
      "epoch 101; iter: 0; batch classifier loss: 0.406025; batch adversarial loss: 0.490912\n",
      "epoch 102; iter: 0; batch classifier loss: 0.438632; batch adversarial loss: 0.534826\n",
      "epoch 103; iter: 0; batch classifier loss: 0.334976; batch adversarial loss: 0.554346\n",
      "epoch 104; iter: 0; batch classifier loss: 0.385373; batch adversarial loss: 0.580060\n",
      "epoch 105; iter: 0; batch classifier loss: 0.382431; batch adversarial loss: 0.562898\n",
      "epoch 106; iter: 0; batch classifier loss: 0.403625; batch adversarial loss: 0.552510\n",
      "epoch 107; iter: 0; batch classifier loss: 0.323832; batch adversarial loss: 0.604154\n",
      "epoch 108; iter: 0; batch classifier loss: 0.316885; batch adversarial loss: 0.546942\n",
      "epoch 109; iter: 0; batch classifier loss: 0.370339; batch adversarial loss: 0.544240\n",
      "epoch 110; iter: 0; batch classifier loss: 0.289528; batch adversarial loss: 0.543739\n",
      "epoch 111; iter: 0; batch classifier loss: 0.337494; batch adversarial loss: 0.472126\n",
      "epoch 112; iter: 0; batch classifier loss: 0.347610; batch adversarial loss: 0.588016\n",
      "epoch 113; iter: 0; batch classifier loss: 0.374575; batch adversarial loss: 0.587760\n",
      "epoch 114; iter: 0; batch classifier loss: 0.351541; batch adversarial loss: 0.570700\n",
      "epoch 115; iter: 0; batch classifier loss: 0.348840; batch adversarial loss: 0.570287\n",
      "epoch 116; iter: 0; batch classifier loss: 0.431599; batch adversarial loss: 0.554102\n",
      "epoch 117; iter: 0; batch classifier loss: 0.388714; batch adversarial loss: 0.508104\n",
      "epoch 118; iter: 0; batch classifier loss: 0.408972; batch adversarial loss: 0.510153\n",
      "epoch 119; iter: 0; batch classifier loss: 0.340924; batch adversarial loss: 0.489624\n",
      "epoch 120; iter: 0; batch classifier loss: 0.470957; batch adversarial loss: 0.489904\n",
      "epoch 121; iter: 0; batch classifier loss: 0.418797; batch adversarial loss: 0.517374\n",
      "epoch 122; iter: 0; batch classifier loss: 0.365666; batch adversarial loss: 0.526778\n",
      "epoch 123; iter: 0; batch classifier loss: 0.350706; batch adversarial loss: 0.581040\n",
      "epoch 124; iter: 0; batch classifier loss: 0.418531; batch adversarial loss: 0.552838\n",
      "epoch 125; iter: 0; batch classifier loss: 0.360436; batch adversarial loss: 0.481527\n",
      "epoch 126; iter: 0; batch classifier loss: 0.403554; batch adversarial loss: 0.516718\n",
      "epoch 127; iter: 0; batch classifier loss: 0.375032; batch adversarial loss: 0.527006\n",
      "epoch 128; iter: 0; batch classifier loss: 0.409195; batch adversarial loss: 0.589768\n",
      "epoch 129; iter: 0; batch classifier loss: 0.358828; batch adversarial loss: 0.507118\n",
      "epoch 130; iter: 0; batch classifier loss: 0.398778; batch adversarial loss: 0.551888\n",
      "epoch 131; iter: 0; batch classifier loss: 0.353425; batch adversarial loss: 0.562556\n",
      "epoch 132; iter: 0; batch classifier loss: 0.446483; batch adversarial loss: 0.579488\n",
      "epoch 133; iter: 0; batch classifier loss: 0.297255; batch adversarial loss: 0.578928\n",
      "epoch 134; iter: 0; batch classifier loss: 0.413068; batch adversarial loss: 0.597223\n",
      "epoch 135; iter: 0; batch classifier loss: 0.442059; batch adversarial loss: 0.602809\n",
      "epoch 136; iter: 0; batch classifier loss: 0.390561; batch adversarial loss: 0.571438\n",
      "epoch 137; iter: 0; batch classifier loss: 0.373077; batch adversarial loss: 0.568040\n",
      "epoch 138; iter: 0; batch classifier loss: 0.283538; batch adversarial loss: 0.564733\n",
      "epoch 139; iter: 0; batch classifier loss: 0.327132; batch adversarial loss: 0.572063\n",
      "epoch 140; iter: 0; batch classifier loss: 0.350665; batch adversarial loss: 0.572514\n",
      "epoch 141; iter: 0; batch classifier loss: 0.423802; batch adversarial loss: 0.616828\n",
      "epoch 142; iter: 0; batch classifier loss: 0.339034; batch adversarial loss: 0.537125\n",
      "epoch 143; iter: 0; batch classifier loss: 0.289455; batch adversarial loss: 0.553715\n",
      "epoch 144; iter: 0; batch classifier loss: 0.407264; batch adversarial loss: 0.588335\n",
      "epoch 145; iter: 0; batch classifier loss: 0.344784; batch adversarial loss: 0.563930\n",
      "epoch 146; iter: 0; batch classifier loss: 0.317852; batch adversarial loss: 0.570569\n",
      "epoch 147; iter: 0; batch classifier loss: 0.346635; batch adversarial loss: 0.534622\n",
      "epoch 148; iter: 0; batch classifier loss: 0.324331; batch adversarial loss: 0.516181\n",
      "epoch 149; iter: 0; batch classifier loss: 0.437451; batch adversarial loss: 0.562199\n",
      "epoch 150; iter: 0; batch classifier loss: 0.338345; batch adversarial loss: 0.580360\n",
      "epoch 151; iter: 0; batch classifier loss: 0.394716; batch adversarial loss: 0.615603\n",
      "epoch 152; iter: 0; batch classifier loss: 0.307241; batch adversarial loss: 0.572133\n",
      "epoch 153; iter: 0; batch classifier loss: 0.404157; batch adversarial loss: 0.554185\n",
      "epoch 154; iter: 0; batch classifier loss: 0.280001; batch adversarial loss: 0.557200\n",
      "epoch 155; iter: 0; batch classifier loss: 0.374111; batch adversarial loss: 0.495294\n",
      "epoch 156; iter: 0; batch classifier loss: 0.290782; batch adversarial loss: 0.558129\n",
      "epoch 157; iter: 0; batch classifier loss: 0.280218; batch adversarial loss: 0.599681\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 158; iter: 0; batch classifier loss: 0.404895; batch adversarial loss: 0.562125\n",
      "epoch 159; iter: 0; batch classifier loss: 0.353888; batch adversarial loss: 0.642242\n",
      "epoch 160; iter: 0; batch classifier loss: 0.295041; batch adversarial loss: 0.542802\n",
      "epoch 161; iter: 0; batch classifier loss: 0.403718; batch adversarial loss: 0.552942\n",
      "epoch 162; iter: 0; batch classifier loss: 0.407969; batch adversarial loss: 0.544723\n",
      "epoch 163; iter: 0; batch classifier loss: 0.348146; batch adversarial loss: 0.526477\n",
      "epoch 164; iter: 0; batch classifier loss: 0.428384; batch adversarial loss: 0.509851\n",
      "epoch 165; iter: 0; batch classifier loss: 0.366439; batch adversarial loss: 0.634050\n",
      "epoch 166; iter: 0; batch classifier loss: 0.372179; batch adversarial loss: 0.579246\n",
      "epoch 167; iter: 0; batch classifier loss: 0.346514; batch adversarial loss: 0.533759\n",
      "epoch 168; iter: 0; batch classifier loss: 0.322852; batch adversarial loss: 0.543018\n",
      "epoch 169; iter: 0; batch classifier loss: 0.309377; batch adversarial loss: 0.617743\n",
      "epoch 170; iter: 0; batch classifier loss: 0.383919; batch adversarial loss: 0.563420\n",
      "epoch 171; iter: 0; batch classifier loss: 0.346573; batch adversarial loss: 0.623186\n",
      "epoch 172; iter: 0; batch classifier loss: 0.336738; batch adversarial loss: 0.596242\n",
      "epoch 173; iter: 0; batch classifier loss: 0.328585; batch adversarial loss: 0.565858\n",
      "epoch 174; iter: 0; batch classifier loss: 0.393217; batch adversarial loss: 0.556371\n",
      "epoch 175; iter: 0; batch classifier loss: 0.344775; batch adversarial loss: 0.560848\n",
      "epoch 176; iter: 0; batch classifier loss: 0.397774; batch adversarial loss: 0.507766\n",
      "epoch 177; iter: 0; batch classifier loss: 0.385057; batch adversarial loss: 0.519133\n",
      "epoch 178; iter: 0; batch classifier loss: 0.382040; batch adversarial loss: 0.490583\n",
      "epoch 179; iter: 0; batch classifier loss: 0.367157; batch adversarial loss: 0.545128\n",
      "epoch 180; iter: 0; batch classifier loss: 0.381219; batch adversarial loss: 0.552293\n",
      "epoch 181; iter: 0; batch classifier loss: 0.401472; batch adversarial loss: 0.565511\n",
      "epoch 182; iter: 0; batch classifier loss: 0.382444; batch adversarial loss: 0.542419\n",
      "epoch 183; iter: 0; batch classifier loss: 0.405091; batch adversarial loss: 0.554822\n",
      "epoch 184; iter: 0; batch classifier loss: 0.349623; batch adversarial loss: 0.571484\n",
      "epoch 185; iter: 0; batch classifier loss: 0.336960; batch adversarial loss: 0.490299\n",
      "epoch 186; iter: 0; batch classifier loss: 0.307542; batch adversarial loss: 0.534546\n",
      "epoch 187; iter: 0; batch classifier loss: 0.417004; batch adversarial loss: 0.492445\n",
      "epoch 188; iter: 0; batch classifier loss: 0.335083; batch adversarial loss: 0.582520\n",
      "epoch 189; iter: 0; batch classifier loss: 0.294880; batch adversarial loss: 0.487897\n",
      "epoch 190; iter: 0; batch classifier loss: 0.418593; batch adversarial loss: 0.571010\n",
      "epoch 191; iter: 0; batch classifier loss: 0.352305; batch adversarial loss: 0.472961\n",
      "epoch 192; iter: 0; batch classifier loss: 0.314488; batch adversarial loss: 0.535346\n",
      "epoch 193; iter: 0; batch classifier loss: 0.395317; batch adversarial loss: 0.572088\n",
      "epoch 194; iter: 0; batch classifier loss: 0.332218; batch adversarial loss: 0.542592\n",
      "epoch 195; iter: 0; batch classifier loss: 0.341214; batch adversarial loss: 0.547851\n",
      "epoch 196; iter: 0; batch classifier loss: 0.391212; batch adversarial loss: 0.581867\n",
      "epoch 197; iter: 0; batch classifier loss: 0.386349; batch adversarial loss: 0.461301\n",
      "epoch 198; iter: 0; batch classifier loss: 0.358774; batch adversarial loss: 0.625643\n",
      "epoch 199; iter: 0; batch classifier loss: 0.287983; batch adversarial loss: 0.565329\n",
      "epoch 0; iter: 0; batch classifier loss: 0.681413; batch adversarial loss: 0.578983\n",
      "epoch 1; iter: 0; batch classifier loss: 0.571726; batch adversarial loss: 0.662629\n",
      "epoch 2; iter: 0; batch classifier loss: 0.519284; batch adversarial loss: 0.656419\n",
      "epoch 3; iter: 0; batch classifier loss: 0.582130; batch adversarial loss: 0.625841\n",
      "epoch 4; iter: 0; batch classifier loss: 0.581735; batch adversarial loss: 0.653862\n",
      "epoch 5; iter: 0; batch classifier loss: 0.621093; batch adversarial loss: 0.664732\n",
      "epoch 6; iter: 0; batch classifier loss: 0.575732; batch adversarial loss: 0.637141\n",
      "epoch 7; iter: 0; batch classifier loss: 0.554511; batch adversarial loss: 0.666455\n",
      "epoch 8; iter: 0; batch classifier loss: 0.540202; batch adversarial loss: 0.621353\n",
      "epoch 9; iter: 0; batch classifier loss: 0.562443; batch adversarial loss: 0.624714\n",
      "epoch 10; iter: 0; batch classifier loss: 0.565675; batch adversarial loss: 0.591548\n",
      "epoch 11; iter: 0; batch classifier loss: 0.465755; batch adversarial loss: 0.592257\n",
      "epoch 12; iter: 0; batch classifier loss: 0.510395; batch adversarial loss: 0.550663\n",
      "epoch 13; iter: 0; batch classifier loss: 0.633666; batch adversarial loss: 0.563854\n",
      "epoch 14; iter: 0; batch classifier loss: 0.524513; batch adversarial loss: 0.561522\n",
      "epoch 15; iter: 0; batch classifier loss: 0.485116; batch adversarial loss: 0.546235\n",
      "epoch 16; iter: 0; batch classifier loss: 0.517099; batch adversarial loss: 0.584826\n",
      "epoch 17; iter: 0; batch classifier loss: 0.516687; batch adversarial loss: 0.504247\n",
      "epoch 18; iter: 0; batch classifier loss: 0.553220; batch adversarial loss: 0.551189\n",
      "epoch 19; iter: 0; batch classifier loss: 0.424633; batch adversarial loss: 0.519789\n",
      "epoch 20; iter: 0; batch classifier loss: 0.468046; batch adversarial loss: 0.534492\n",
      "epoch 21; iter: 0; batch classifier loss: 0.523898; batch adversarial loss: 0.603626\n",
      "epoch 22; iter: 0; batch classifier loss: 0.436508; batch adversarial loss: 0.587086\n",
      "epoch 23; iter: 0; batch classifier loss: 0.481783; batch adversarial loss: 0.551463\n",
      "epoch 24; iter: 0; batch classifier loss: 0.537661; batch adversarial loss: 0.579301\n",
      "epoch 25; iter: 0; batch classifier loss: 0.480921; batch adversarial loss: 0.554636\n",
      "epoch 26; iter: 0; batch classifier loss: 0.457406; batch adversarial loss: 0.545681\n",
      "epoch 27; iter: 0; batch classifier loss: 0.446188; batch adversarial loss: 0.534197\n",
      "epoch 28; iter: 0; batch classifier loss: 0.485155; batch adversarial loss: 0.526874\n",
      "epoch 29; iter: 0; batch classifier loss: 0.473692; batch adversarial loss: 0.545757\n",
      "epoch 30; iter: 0; batch classifier loss: 0.493588; batch adversarial loss: 0.562842\n",
      "epoch 31; iter: 0; batch classifier loss: 0.485362; batch adversarial loss: 0.665839\n",
      "epoch 32; iter: 0; batch classifier loss: 0.401418; batch adversarial loss: 0.493073\n",
      "epoch 33; iter: 0; batch classifier loss: 0.435044; batch adversarial loss: 0.562091\n",
      "epoch 34; iter: 0; batch classifier loss: 0.452830; batch adversarial loss: 0.607094\n",
      "epoch 35; iter: 0; batch classifier loss: 0.382469; batch adversarial loss: 0.653586\n",
      "epoch 36; iter: 0; batch classifier loss: 0.432685; batch adversarial loss: 0.553928\n",
      "epoch 37; iter: 0; batch classifier loss: 0.444122; batch adversarial loss: 0.509613\n",
      "epoch 38; iter: 0; batch classifier loss: 0.409731; batch adversarial loss: 0.625035\n",
      "epoch 39; iter: 0; batch classifier loss: 0.444184; batch adversarial loss: 0.605729\n",
      "epoch 40; iter: 0; batch classifier loss: 0.459901; batch adversarial loss: 0.491483\n",
      "epoch 41; iter: 0; batch classifier loss: 0.389333; batch adversarial loss: 0.488902\n",
      "epoch 42; iter: 0; batch classifier loss: 0.533303; batch adversarial loss: 0.562391\n",
      "epoch 43; iter: 0; batch classifier loss: 0.508614; batch adversarial loss: 0.517318\n",
      "epoch 44; iter: 0; batch classifier loss: 0.494547; batch adversarial loss: 0.465037\n",
      "epoch 45; iter: 0; batch classifier loss: 0.444582; batch adversarial loss: 0.455317\n",
      "epoch 46; iter: 0; batch classifier loss: 0.433115; batch adversarial loss: 0.578411\n",
      "epoch 47; iter: 0; batch classifier loss: 0.399979; batch adversarial loss: 0.508746\n",
      "epoch 48; iter: 0; batch classifier loss: 0.385381; batch adversarial loss: 0.526589\n",
      "epoch 49; iter: 0; batch classifier loss: 0.385268; batch adversarial loss: 0.606284\n",
      "epoch 50; iter: 0; batch classifier loss: 0.356951; batch adversarial loss: 0.550645\n",
      "epoch 51; iter: 0; batch classifier loss: 0.427984; batch adversarial loss: 0.579980\n",
      "epoch 52; iter: 0; batch classifier loss: 0.404250; batch adversarial loss: 0.517214\n",
      "epoch 53; iter: 0; batch classifier loss: 0.493023; batch adversarial loss: 0.499278\n",
      "epoch 54; iter: 0; batch classifier loss: 0.404078; batch adversarial loss: 0.534983\n",
      "epoch 55; iter: 0; batch classifier loss: 0.421510; batch adversarial loss: 0.536182\n",
      "epoch 56; iter: 0; batch classifier loss: 0.358792; batch adversarial loss: 0.534741\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 57; iter: 0; batch classifier loss: 0.440989; batch adversarial loss: 0.582283\n",
      "epoch 58; iter: 0; batch classifier loss: 0.390815; batch adversarial loss: 0.617655\n",
      "epoch 59; iter: 0; batch classifier loss: 0.466666; batch adversarial loss: 0.554086\n",
      "epoch 60; iter: 0; batch classifier loss: 0.383487; batch adversarial loss: 0.427911\n",
      "epoch 61; iter: 0; batch classifier loss: 0.373240; batch adversarial loss: 0.491106\n",
      "epoch 62; iter: 0; batch classifier loss: 0.467716; batch adversarial loss: 0.572415\n",
      "epoch 63; iter: 0; batch classifier loss: 0.428133; batch adversarial loss: 0.661478\n",
      "epoch 64; iter: 0; batch classifier loss: 0.371232; batch adversarial loss: 0.508541\n",
      "epoch 65; iter: 0; batch classifier loss: 0.367084; batch adversarial loss: 0.554781\n",
      "epoch 66; iter: 0; batch classifier loss: 0.372709; batch adversarial loss: 0.562654\n",
      "epoch 67; iter: 0; batch classifier loss: 0.397316; batch adversarial loss: 0.563200\n",
      "epoch 68; iter: 0; batch classifier loss: 0.514557; batch adversarial loss: 0.563432\n",
      "epoch 69; iter: 0; batch classifier loss: 0.336729; batch adversarial loss: 0.535017\n",
      "epoch 70; iter: 0; batch classifier loss: 0.353509; batch adversarial loss: 0.519585\n",
      "epoch 71; iter: 0; batch classifier loss: 0.380974; batch adversarial loss: 0.553064\n",
      "epoch 72; iter: 0; batch classifier loss: 0.443847; batch adversarial loss: 0.607614\n",
      "epoch 73; iter: 0; batch classifier loss: 0.386311; batch adversarial loss: 0.526998\n",
      "epoch 74; iter: 0; batch classifier loss: 0.426079; batch adversarial loss: 0.526484\n",
      "epoch 75; iter: 0; batch classifier loss: 0.453429; batch adversarial loss: 0.527288\n",
      "epoch 76; iter: 0; batch classifier loss: 0.469609; batch adversarial loss: 0.518034\n",
      "epoch 77; iter: 0; batch classifier loss: 0.369687; batch adversarial loss: 0.591275\n",
      "epoch 78; iter: 0; batch classifier loss: 0.404009; batch adversarial loss: 0.616113\n",
      "epoch 79; iter: 0; batch classifier loss: 0.492464; batch adversarial loss: 0.472872\n",
      "epoch 80; iter: 0; batch classifier loss: 0.381231; batch adversarial loss: 0.608422\n",
      "epoch 81; iter: 0; batch classifier loss: 0.389383; batch adversarial loss: 0.508930\n",
      "epoch 82; iter: 0; batch classifier loss: 0.544640; batch adversarial loss: 0.590097\n",
      "epoch 83; iter: 0; batch classifier loss: 0.470493; batch adversarial loss: 0.544280\n",
      "epoch 84; iter: 0; batch classifier loss: 0.453093; batch adversarial loss: 0.527409\n",
      "epoch 85; iter: 0; batch classifier loss: 0.349523; batch adversarial loss: 0.562831\n",
      "epoch 86; iter: 0; batch classifier loss: 0.380855; batch adversarial loss: 0.561998\n",
      "epoch 87; iter: 0; batch classifier loss: 0.366586; batch adversarial loss: 0.535879\n",
      "epoch 88; iter: 0; batch classifier loss: 0.460921; batch adversarial loss: 0.545649\n",
      "epoch 89; iter: 0; batch classifier loss: 0.448694; batch adversarial loss: 0.500377\n",
      "epoch 90; iter: 0; batch classifier loss: 0.453318; batch adversarial loss: 0.554009\n",
      "epoch 91; iter: 0; batch classifier loss: 0.482632; batch adversarial loss: 0.535746\n",
      "epoch 92; iter: 0; batch classifier loss: 0.461170; batch adversarial loss: 0.589083\n",
      "epoch 93; iter: 0; batch classifier loss: 0.348510; batch adversarial loss: 0.535949\n",
      "epoch 94; iter: 0; batch classifier loss: 0.408115; batch adversarial loss: 0.482406\n",
      "epoch 95; iter: 0; batch classifier loss: 0.437546; batch adversarial loss: 0.545690\n",
      "epoch 96; iter: 0; batch classifier loss: 0.309986; batch adversarial loss: 0.498741\n",
      "epoch 97; iter: 0; batch classifier loss: 0.436339; batch adversarial loss: 0.617018\n",
      "epoch 98; iter: 0; batch classifier loss: 0.380283; batch adversarial loss: 0.517902\n",
      "epoch 99; iter: 0; batch classifier loss: 0.315240; batch adversarial loss: 0.536166\n",
      "epoch 100; iter: 0; batch classifier loss: 0.418882; batch adversarial loss: 0.562672\n",
      "epoch 101; iter: 0; batch classifier loss: 0.395857; batch adversarial loss: 0.526560\n",
      "epoch 102; iter: 0; batch classifier loss: 0.442624; batch adversarial loss: 0.561827\n",
      "epoch 103; iter: 0; batch classifier loss: 0.435095; batch adversarial loss: 0.563753\n",
      "epoch 104; iter: 0; batch classifier loss: 0.399268; batch adversarial loss: 0.544572\n",
      "epoch 105; iter: 0; batch classifier loss: 0.462583; batch adversarial loss: 0.527581\n",
      "epoch 106; iter: 0; batch classifier loss: 0.371943; batch adversarial loss: 0.579458\n",
      "epoch 107; iter: 0; batch classifier loss: 0.369425; batch adversarial loss: 0.517760\n",
      "epoch 108; iter: 0; batch classifier loss: 0.400537; batch adversarial loss: 0.553917\n",
      "epoch 109; iter: 0; batch classifier loss: 0.391132; batch adversarial loss: 0.500473\n",
      "epoch 110; iter: 0; batch classifier loss: 0.413309; batch adversarial loss: 0.571866\n",
      "epoch 111; iter: 0; batch classifier loss: 0.367915; batch adversarial loss: 0.680604\n",
      "epoch 112; iter: 0; batch classifier loss: 0.411543; batch adversarial loss: 0.535976\n",
      "epoch 113; iter: 0; batch classifier loss: 0.394539; batch adversarial loss: 0.564001\n",
      "epoch 114; iter: 0; batch classifier loss: 0.388717; batch adversarial loss: 0.562129\n",
      "epoch 115; iter: 0; batch classifier loss: 0.366867; batch adversarial loss: 0.597191\n",
      "epoch 116; iter: 0; batch classifier loss: 0.324569; batch adversarial loss: 0.518322\n",
      "epoch 117; iter: 0; batch classifier loss: 0.392440; batch adversarial loss: 0.534872\n",
      "epoch 118; iter: 0; batch classifier loss: 0.372848; batch adversarial loss: 0.508465\n",
      "epoch 119; iter: 0; batch classifier loss: 0.323592; batch adversarial loss: 0.509207\n",
      "epoch 120; iter: 0; batch classifier loss: 0.389094; batch adversarial loss: 0.481425\n",
      "epoch 121; iter: 0; batch classifier loss: 0.407051; batch adversarial loss: 0.518136\n",
      "epoch 122; iter: 0; batch classifier loss: 0.347136; batch adversarial loss: 0.508524\n",
      "epoch 123; iter: 0; batch classifier loss: 0.389576; batch adversarial loss: 0.535218\n",
      "epoch 124; iter: 0; batch classifier loss: 0.387317; batch adversarial loss: 0.490535\n",
      "epoch 125; iter: 0; batch classifier loss: 0.370846; batch adversarial loss: 0.561560\n",
      "epoch 126; iter: 0; batch classifier loss: 0.388803; batch adversarial loss: 0.509079\n",
      "epoch 127; iter: 0; batch classifier loss: 0.349316; batch adversarial loss: 0.598043\n",
      "epoch 128; iter: 0; batch classifier loss: 0.332209; batch adversarial loss: 0.561798\n",
      "epoch 129; iter: 0; batch classifier loss: 0.390441; batch adversarial loss: 0.561610\n",
      "epoch 130; iter: 0; batch classifier loss: 0.338383; batch adversarial loss: 0.526438\n",
      "epoch 131; iter: 0; batch classifier loss: 0.411621; batch adversarial loss: 0.572559\n",
      "epoch 132; iter: 0; batch classifier loss: 0.353013; batch adversarial loss: 0.589265\n",
      "epoch 133; iter: 0; batch classifier loss: 0.344839; batch adversarial loss: 0.552426\n",
      "epoch 134; iter: 0; batch classifier loss: 0.384902; batch adversarial loss: 0.499976\n",
      "epoch 135; iter: 0; batch classifier loss: 0.321662; batch adversarial loss: 0.517127\n",
      "epoch 136; iter: 0; batch classifier loss: 0.410062; batch adversarial loss: 0.508253\n",
      "epoch 137; iter: 0; batch classifier loss: 0.376240; batch adversarial loss: 0.553534\n",
      "epoch 138; iter: 0; batch classifier loss: 0.356198; batch adversarial loss: 0.589602\n",
      "epoch 139; iter: 0; batch classifier loss: 0.350244; batch adversarial loss: 0.580915\n",
      "epoch 140; iter: 0; batch classifier loss: 0.417123; batch adversarial loss: 0.642858\n",
      "epoch 141; iter: 0; batch classifier loss: 0.329063; batch adversarial loss: 0.580053\n",
      "epoch 142; iter: 0; batch classifier loss: 0.350410; batch adversarial loss: 0.535005\n",
      "epoch 143; iter: 0; batch classifier loss: 0.358638; batch adversarial loss: 0.535774\n",
      "epoch 144; iter: 0; batch classifier loss: 0.382988; batch adversarial loss: 0.607539\n",
      "epoch 145; iter: 0; batch classifier loss: 0.398965; batch adversarial loss: 0.545089\n",
      "epoch 146; iter: 0; batch classifier loss: 0.379132; batch adversarial loss: 0.589584\n",
      "epoch 147; iter: 0; batch classifier loss: 0.340805; batch adversarial loss: 0.508036\n",
      "epoch 148; iter: 0; batch classifier loss: 0.280991; batch adversarial loss: 0.553188\n",
      "epoch 149; iter: 0; batch classifier loss: 0.336646; batch adversarial loss: 0.616687\n",
      "epoch 150; iter: 0; batch classifier loss: 0.349057; batch adversarial loss: 0.535279\n",
      "epoch 151; iter: 0; batch classifier loss: 0.402040; batch adversarial loss: 0.589654\n",
      "epoch 152; iter: 0; batch classifier loss: 0.384147; batch adversarial loss: 0.481652\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 153; iter: 0; batch classifier loss: 0.377776; batch adversarial loss: 0.472339\n",
      "epoch 154; iter: 0; batch classifier loss: 0.332153; batch adversarial loss: 0.571342\n",
      "epoch 155; iter: 0; batch classifier loss: 0.431576; batch adversarial loss: 0.526328\n",
      "epoch 156; iter: 0; batch classifier loss: 0.362835; batch adversarial loss: 0.463962\n",
      "epoch 157; iter: 0; batch classifier loss: 0.432302; batch adversarial loss: 0.526717\n",
      "epoch 158; iter: 0; batch classifier loss: 0.356574; batch adversarial loss: 0.507843\n",
      "epoch 159; iter: 0; batch classifier loss: 0.382002; batch adversarial loss: 0.527071\n",
      "epoch 160; iter: 0; batch classifier loss: 0.363728; batch adversarial loss: 0.598496\n",
      "epoch 161; iter: 0; batch classifier loss: 0.349630; batch adversarial loss: 0.553122\n",
      "epoch 162; iter: 0; batch classifier loss: 0.317869; batch adversarial loss: 0.553086\n",
      "epoch 163; iter: 0; batch classifier loss: 0.335393; batch adversarial loss: 0.624500\n",
      "epoch 164; iter: 0; batch classifier loss: 0.418573; batch adversarial loss: 0.481681\n",
      "epoch 165; iter: 0; batch classifier loss: 0.349168; batch adversarial loss: 0.527161\n",
      "epoch 166; iter: 0; batch classifier loss: 0.367145; batch adversarial loss: 0.661325\n",
      "epoch 167; iter: 0; batch classifier loss: 0.362981; batch adversarial loss: 0.552737\n",
      "epoch 168; iter: 0; batch classifier loss: 0.377429; batch adversarial loss: 0.561614\n",
      "epoch 169; iter: 0; batch classifier loss: 0.376029; batch adversarial loss: 0.536227\n",
      "epoch 170; iter: 0; batch classifier loss: 0.397039; batch adversarial loss: 0.580581\n",
      "epoch 171; iter: 0; batch classifier loss: 0.362651; batch adversarial loss: 0.490165\n",
      "epoch 172; iter: 0; batch classifier loss: 0.381394; batch adversarial loss: 0.562146\n",
      "epoch 173; iter: 0; batch classifier loss: 0.312112; batch adversarial loss: 0.589474\n",
      "epoch 174; iter: 0; batch classifier loss: 0.390904; batch adversarial loss: 0.589521\n",
      "epoch 175; iter: 0; batch classifier loss: 0.378224; batch adversarial loss: 0.499769\n",
      "epoch 176; iter: 0; batch classifier loss: 0.375660; batch adversarial loss: 0.535254\n",
      "epoch 177; iter: 0; batch classifier loss: 0.361370; batch adversarial loss: 0.490590\n",
      "epoch 178; iter: 0; batch classifier loss: 0.362071; batch adversarial loss: 0.535149\n",
      "epoch 179; iter: 0; batch classifier loss: 0.317079; batch adversarial loss: 0.490634\n",
      "epoch 180; iter: 0; batch classifier loss: 0.302906; batch adversarial loss: 0.544632\n",
      "epoch 181; iter: 0; batch classifier loss: 0.379696; batch adversarial loss: 0.563802\n",
      "epoch 182; iter: 0; batch classifier loss: 0.352018; batch adversarial loss: 0.536295\n",
      "epoch 183; iter: 0; batch classifier loss: 0.343292; batch adversarial loss: 0.490226\n",
      "epoch 184; iter: 0; batch classifier loss: 0.386763; batch adversarial loss: 0.518155\n",
      "epoch 185; iter: 0; batch classifier loss: 0.401458; batch adversarial loss: 0.553507\n",
      "epoch 186; iter: 0; batch classifier loss: 0.331466; batch adversarial loss: 0.508392\n",
      "epoch 187; iter: 0; batch classifier loss: 0.366636; batch adversarial loss: 0.643619\n",
      "epoch 188; iter: 0; batch classifier loss: 0.336820; batch adversarial loss: 0.508284\n",
      "epoch 189; iter: 0; batch classifier loss: 0.483944; batch adversarial loss: 0.445090\n",
      "epoch 190; iter: 0; batch classifier loss: 0.369147; batch adversarial loss: 0.491157\n",
      "epoch 191; iter: 0; batch classifier loss: 0.468043; batch adversarial loss: 0.508521\n",
      "epoch 192; iter: 0; batch classifier loss: 0.292721; batch adversarial loss: 0.516330\n",
      "epoch 193; iter: 0; batch classifier loss: 0.387931; batch adversarial loss: 0.563112\n",
      "epoch 194; iter: 0; batch classifier loss: 0.331763; batch adversarial loss: 0.554346\n",
      "epoch 195; iter: 0; batch classifier loss: 0.408742; batch adversarial loss: 0.544530\n",
      "epoch 196; iter: 0; batch classifier loss: 0.403315; batch adversarial loss: 0.553775\n",
      "epoch 197; iter: 0; batch classifier loss: 0.362423; batch adversarial loss: 0.544762\n",
      "epoch 198; iter: 0; batch classifier loss: 0.301167; batch adversarial loss: 0.499362\n",
      "epoch 199; iter: 0; batch classifier loss: 0.414370; batch adversarial loss: 0.500342\n",
      "epoch 0; iter: 0; batch classifier loss: 0.637064; batch adversarial loss: 0.689821\n",
      "epoch 1; iter: 0; batch classifier loss: 0.582257; batch adversarial loss: 0.684981\n",
      "epoch 2; iter: 0; batch classifier loss: 0.598953; batch adversarial loss: 0.661899\n",
      "epoch 3; iter: 0; batch classifier loss: 0.641958; batch adversarial loss: 0.607897\n",
      "epoch 4; iter: 0; batch classifier loss: 0.557653; batch adversarial loss: 0.649498\n",
      "epoch 5; iter: 0; batch classifier loss: 0.543089; batch adversarial loss: 0.642379\n",
      "epoch 6; iter: 0; batch classifier loss: 0.618911; batch adversarial loss: 0.589662\n",
      "epoch 7; iter: 0; batch classifier loss: 0.556037; batch adversarial loss: 0.588997\n",
      "epoch 8; iter: 0; batch classifier loss: 0.537032; batch adversarial loss: 0.586873\n",
      "epoch 9; iter: 0; batch classifier loss: 0.500084; batch adversarial loss: 0.662867\n",
      "epoch 10; iter: 0; batch classifier loss: 0.493409; batch adversarial loss: 0.608829\n",
      "epoch 11; iter: 0; batch classifier loss: 0.551482; batch adversarial loss: 0.534462\n",
      "epoch 12; iter: 0; batch classifier loss: 0.511156; batch adversarial loss: 0.579924\n",
      "epoch 13; iter: 0; batch classifier loss: 0.541706; batch adversarial loss: 0.556390\n",
      "epoch 14; iter: 0; batch classifier loss: 0.546410; batch adversarial loss: 0.579362\n",
      "epoch 15; iter: 0; batch classifier loss: 0.501819; batch adversarial loss: 0.569092\n",
      "epoch 16; iter: 0; batch classifier loss: 0.561711; batch adversarial loss: 0.550559\n",
      "epoch 17; iter: 0; batch classifier loss: 0.485056; batch adversarial loss: 0.561626\n",
      "epoch 18; iter: 0; batch classifier loss: 0.533906; batch adversarial loss: 0.514174\n",
      "epoch 19; iter: 0; batch classifier loss: 0.490957; batch adversarial loss: 0.530108\n",
      "epoch 20; iter: 0; batch classifier loss: 0.460529; batch adversarial loss: 0.580324\n",
      "epoch 21; iter: 0; batch classifier loss: 0.471791; batch adversarial loss: 0.529666\n",
      "epoch 22; iter: 0; batch classifier loss: 0.457122; batch adversarial loss: 0.536827\n",
      "epoch 23; iter: 0; batch classifier loss: 0.512751; batch adversarial loss: 0.556481\n",
      "epoch 24; iter: 0; batch classifier loss: 0.451800; batch adversarial loss: 0.522154\n",
      "epoch 25; iter: 0; batch classifier loss: 0.467714; batch adversarial loss: 0.602299\n",
      "epoch 26; iter: 0; batch classifier loss: 0.433712; batch adversarial loss: 0.513406\n",
      "epoch 27; iter: 0; batch classifier loss: 0.489950; batch adversarial loss: 0.584728\n",
      "epoch 28; iter: 0; batch classifier loss: 0.433897; batch adversarial loss: 0.515437\n",
      "epoch 29; iter: 0; batch classifier loss: 0.479590; batch adversarial loss: 0.648752\n",
      "epoch 30; iter: 0; batch classifier loss: 0.442398; batch adversarial loss: 0.529848\n",
      "epoch 31; iter: 0; batch classifier loss: 0.460342; batch adversarial loss: 0.560534\n",
      "epoch 32; iter: 0; batch classifier loss: 0.484459; batch adversarial loss: 0.545821\n",
      "epoch 33; iter: 0; batch classifier loss: 0.561354; batch adversarial loss: 0.525366\n",
      "epoch 34; iter: 0; batch classifier loss: 0.496525; batch adversarial loss: 0.577849\n",
      "epoch 35; iter: 0; batch classifier loss: 0.513575; batch adversarial loss: 0.588203\n",
      "epoch 36; iter: 0; batch classifier loss: 0.443086; batch adversarial loss: 0.450907\n",
      "epoch 37; iter: 0; batch classifier loss: 0.486039; batch adversarial loss: 0.579328\n",
      "epoch 38; iter: 0; batch classifier loss: 0.519989; batch adversarial loss: 0.538560\n",
      "epoch 39; iter: 0; batch classifier loss: 0.453679; batch adversarial loss: 0.504996\n",
      "epoch 40; iter: 0; batch classifier loss: 0.526125; batch adversarial loss: 0.536797\n",
      "epoch 41; iter: 0; batch classifier loss: 0.474424; batch adversarial loss: 0.587582\n",
      "epoch 42; iter: 0; batch classifier loss: 0.489815; batch adversarial loss: 0.655552\n",
      "epoch 43; iter: 0; batch classifier loss: 0.432294; batch adversarial loss: 0.536550\n",
      "epoch 44; iter: 0; batch classifier loss: 0.411197; batch adversarial loss: 0.563338\n",
      "epoch 45; iter: 0; batch classifier loss: 0.446262; batch adversarial loss: 0.648824\n",
      "epoch 46; iter: 0; batch classifier loss: 0.432547; batch adversarial loss: 0.544963\n",
      "epoch 47; iter: 0; batch classifier loss: 0.377876; batch adversarial loss: 0.632439\n",
      "epoch 48; iter: 0; batch classifier loss: 0.402504; batch adversarial loss: 0.579839\n",
      "epoch 49; iter: 0; batch classifier loss: 0.464830; batch adversarial loss: 0.536952\n",
      "epoch 50; iter: 0; batch classifier loss: 0.398555; batch adversarial loss: 0.517532\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 51; iter: 0; batch classifier loss: 0.438796; batch adversarial loss: 0.533873\n",
      "epoch 52; iter: 0; batch classifier loss: 0.432587; batch adversarial loss: 0.544452\n",
      "epoch 53; iter: 0; batch classifier loss: 0.447597; batch adversarial loss: 0.570908\n",
      "epoch 54; iter: 0; batch classifier loss: 0.454348; batch adversarial loss: 0.519337\n",
      "epoch 55; iter: 0; batch classifier loss: 0.454298; batch adversarial loss: 0.596542\n",
      "epoch 56; iter: 0; batch classifier loss: 0.482846; batch adversarial loss: 0.626036\n",
      "epoch 57; iter: 0; batch classifier loss: 0.414396; batch adversarial loss: 0.581173\n",
      "epoch 58; iter: 0; batch classifier loss: 0.380183; batch adversarial loss: 0.534512\n",
      "epoch 59; iter: 0; batch classifier loss: 0.410081; batch adversarial loss: 0.526430\n",
      "epoch 60; iter: 0; batch classifier loss: 0.332501; batch adversarial loss: 0.545486\n",
      "epoch 61; iter: 0; batch classifier loss: 0.422322; batch adversarial loss: 0.499519\n",
      "epoch 62; iter: 0; batch classifier loss: 0.386931; batch adversarial loss: 0.563505\n",
      "epoch 63; iter: 0; batch classifier loss: 0.434180; batch adversarial loss: 0.510162\n",
      "epoch 64; iter: 0; batch classifier loss: 0.495338; batch adversarial loss: 0.520706\n",
      "epoch 65; iter: 0; batch classifier loss: 0.413577; batch adversarial loss: 0.488950\n",
      "epoch 66; iter: 0; batch classifier loss: 0.429208; batch adversarial loss: 0.475311\n",
      "epoch 67; iter: 0; batch classifier loss: 0.448486; batch adversarial loss: 0.571946\n",
      "epoch 68; iter: 0; batch classifier loss: 0.455550; batch adversarial loss: 0.587557\n",
      "epoch 69; iter: 0; batch classifier loss: 0.387651; batch adversarial loss: 0.563340\n",
      "epoch 70; iter: 0; batch classifier loss: 0.444829; batch adversarial loss: 0.557693\n",
      "epoch 71; iter: 0; batch classifier loss: 0.461056; batch adversarial loss: 0.526122\n",
      "epoch 72; iter: 0; batch classifier loss: 0.385312; batch adversarial loss: 0.537132\n",
      "epoch 73; iter: 0; batch classifier loss: 0.445203; batch adversarial loss: 0.601029\n",
      "epoch 74; iter: 0; batch classifier loss: 0.523864; batch adversarial loss: 0.603930\n",
      "epoch 75; iter: 0; batch classifier loss: 0.379528; batch adversarial loss: 0.517866\n",
      "epoch 76; iter: 0; batch classifier loss: 0.396621; batch adversarial loss: 0.507957\n",
      "epoch 77; iter: 0; batch classifier loss: 0.393223; batch adversarial loss: 0.556188\n",
      "epoch 78; iter: 0; batch classifier loss: 0.373499; batch adversarial loss: 0.560796\n",
      "epoch 79; iter: 0; batch classifier loss: 0.379720; batch adversarial loss: 0.520180\n",
      "epoch 80; iter: 0; batch classifier loss: 0.458305; batch adversarial loss: 0.608970\n",
      "epoch 81; iter: 0; batch classifier loss: 0.502641; batch adversarial loss: 0.545247\n",
      "epoch 82; iter: 0; batch classifier loss: 0.418542; batch adversarial loss: 0.536939\n",
      "epoch 83; iter: 0; batch classifier loss: 0.342041; batch adversarial loss: 0.526626\n",
      "epoch 84; iter: 0; batch classifier loss: 0.407529; batch adversarial loss: 0.618741\n",
      "epoch 85; iter: 0; batch classifier loss: 0.434465; batch adversarial loss: 0.612573\n",
      "epoch 86; iter: 0; batch classifier loss: 0.438293; batch adversarial loss: 0.612257\n",
      "epoch 87; iter: 0; batch classifier loss: 0.443055; batch adversarial loss: 0.625448\n",
      "epoch 88; iter: 0; batch classifier loss: 0.454326; batch adversarial loss: 0.438482\n",
      "epoch 89; iter: 0; batch classifier loss: 0.504367; batch adversarial loss: 0.539612\n",
      "epoch 90; iter: 0; batch classifier loss: 0.385685; batch adversarial loss: 0.587943\n",
      "epoch 91; iter: 0; batch classifier loss: 0.439017; batch adversarial loss: 0.581482\n",
      "epoch 92; iter: 0; batch classifier loss: 0.362326; batch adversarial loss: 0.482290\n",
      "epoch 93; iter: 0; batch classifier loss: 0.415057; batch adversarial loss: 0.563365\n",
      "epoch 94; iter: 0; batch classifier loss: 0.407557; batch adversarial loss: 0.656250\n",
      "epoch 95; iter: 0; batch classifier loss: 0.443816; batch adversarial loss: 0.518962\n",
      "epoch 96; iter: 0; batch classifier loss: 0.438846; batch adversarial loss: 0.614797\n",
      "epoch 97; iter: 0; batch classifier loss: 0.561200; batch adversarial loss: 0.534544\n",
      "epoch 98; iter: 0; batch classifier loss: 0.415875; batch adversarial loss: 0.604738\n",
      "epoch 99; iter: 0; batch classifier loss: 0.515637; batch adversarial loss: 0.563411\n",
      "epoch 100; iter: 0; batch classifier loss: 0.423888; batch adversarial loss: 0.527036\n",
      "epoch 101; iter: 0; batch classifier loss: 0.339622; batch adversarial loss: 0.536755\n",
      "epoch 102; iter: 0; batch classifier loss: 0.395994; batch adversarial loss: 0.571773\n",
      "epoch 103; iter: 0; batch classifier loss: 0.363578; batch adversarial loss: 0.639851\n",
      "epoch 104; iter: 0; batch classifier loss: 0.315868; batch adversarial loss: 0.618368\n",
      "epoch 105; iter: 0; batch classifier loss: 0.450521; batch adversarial loss: 0.578143\n",
      "epoch 106; iter: 0; batch classifier loss: 0.453470; batch adversarial loss: 0.554433\n",
      "epoch 107; iter: 0; batch classifier loss: 0.391135; batch adversarial loss: 0.597257\n",
      "epoch 108; iter: 0; batch classifier loss: 0.391858; batch adversarial loss: 0.580004\n",
      "epoch 109; iter: 0; batch classifier loss: 0.423672; batch adversarial loss: 0.529076\n",
      "epoch 110; iter: 0; batch classifier loss: 0.330237; batch adversarial loss: 0.562873\n",
      "epoch 111; iter: 0; batch classifier loss: 0.401417; batch adversarial loss: 0.544400\n",
      "epoch 112; iter: 0; batch classifier loss: 0.415649; batch adversarial loss: 0.570382\n",
      "epoch 113; iter: 0; batch classifier loss: 0.370997; batch adversarial loss: 0.625957\n",
      "epoch 114; iter: 0; batch classifier loss: 0.373583; batch adversarial loss: 0.499798\n",
      "epoch 115; iter: 0; batch classifier loss: 0.467444; batch adversarial loss: 0.650190\n",
      "epoch 116; iter: 0; batch classifier loss: 0.366345; batch adversarial loss: 0.581689\n",
      "epoch 117; iter: 0; batch classifier loss: 0.404882; batch adversarial loss: 0.572015\n",
      "epoch 118; iter: 0; batch classifier loss: 0.415156; batch adversarial loss: 0.570467\n",
      "epoch 119; iter: 0; batch classifier loss: 0.383427; batch adversarial loss: 0.538554\n",
      "epoch 120; iter: 0; batch classifier loss: 0.411571; batch adversarial loss: 0.507794\n",
      "epoch 121; iter: 0; batch classifier loss: 0.390703; batch adversarial loss: 0.514651\n",
      "epoch 122; iter: 0; batch classifier loss: 0.400040; batch adversarial loss: 0.559337\n",
      "epoch 123; iter: 0; batch classifier loss: 0.389746; batch adversarial loss: 0.566109\n",
      "epoch 124; iter: 0; batch classifier loss: 0.336618; batch adversarial loss: 0.563711\n",
      "epoch 125; iter: 0; batch classifier loss: 0.411397; batch adversarial loss: 0.490144\n",
      "epoch 126; iter: 0; batch classifier loss: 0.430503; batch adversarial loss: 0.560731\n",
      "epoch 127; iter: 0; batch classifier loss: 0.330128; batch adversarial loss: 0.600165\n",
      "epoch 128; iter: 0; batch classifier loss: 0.404206; batch adversarial loss: 0.553306\n",
      "epoch 129; iter: 0; batch classifier loss: 0.386161; batch adversarial loss: 0.572804\n",
      "epoch 130; iter: 0; batch classifier loss: 0.317804; batch adversarial loss: 0.611793\n",
      "epoch 131; iter: 0; batch classifier loss: 0.359161; batch adversarial loss: 0.556536\n",
      "epoch 132; iter: 0; batch classifier loss: 0.372893; batch adversarial loss: 0.599784\n",
      "epoch 133; iter: 0; batch classifier loss: 0.385155; batch adversarial loss: 0.489044\n",
      "epoch 134; iter: 0; batch classifier loss: 0.381495; batch adversarial loss: 0.481548\n",
      "epoch 135; iter: 0; batch classifier loss: 0.354936; batch adversarial loss: 0.585638\n",
      "epoch 136; iter: 0; batch classifier loss: 0.319923; batch adversarial loss: 0.534899\n",
      "epoch 137; iter: 0; batch classifier loss: 0.388263; batch adversarial loss: 0.588640\n",
      "epoch 138; iter: 0; batch classifier loss: 0.414816; batch adversarial loss: 0.534478\n",
      "epoch 139; iter: 0; batch classifier loss: 0.361384; batch adversarial loss: 0.517672\n",
      "epoch 140; iter: 0; batch classifier loss: 0.365589; batch adversarial loss: 0.552942\n",
      "epoch 141; iter: 0; batch classifier loss: 0.498495; batch adversarial loss: 0.559682\n",
      "epoch 142; iter: 0; batch classifier loss: 0.370957; batch adversarial loss: 0.476590\n",
      "epoch 143; iter: 0; batch classifier loss: 0.414068; batch adversarial loss: 0.508335\n",
      "epoch 144; iter: 0; batch classifier loss: 0.413476; batch adversarial loss: 0.543102\n",
      "epoch 145; iter: 0; batch classifier loss: 0.383928; batch adversarial loss: 0.531145\n",
      "epoch 146; iter: 0; batch classifier loss: 0.321981; batch adversarial loss: 0.530077\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 147; iter: 0; batch classifier loss: 0.405660; batch adversarial loss: 0.466491\n",
      "epoch 148; iter: 0; batch classifier loss: 0.332888; batch adversarial loss: 0.661053\n",
      "epoch 149; iter: 0; batch classifier loss: 0.406290; batch adversarial loss: 0.578856\n",
      "epoch 150; iter: 0; batch classifier loss: 0.369085; batch adversarial loss: 0.618736\n",
      "epoch 151; iter: 0; batch classifier loss: 0.436927; batch adversarial loss: 0.570089\n",
      "epoch 152; iter: 0; batch classifier loss: 0.377261; batch adversarial loss: 0.598261\n",
      "epoch 153; iter: 0; batch classifier loss: 0.314242; batch adversarial loss: 0.640753\n",
      "epoch 154; iter: 0; batch classifier loss: 0.401057; batch adversarial loss: 0.668265\n",
      "epoch 155; iter: 0; batch classifier loss: 0.456885; batch adversarial loss: 0.502350\n",
      "epoch 156; iter: 0; batch classifier loss: 0.390390; batch adversarial loss: 0.524382\n",
      "epoch 157; iter: 0; batch classifier loss: 0.430025; batch adversarial loss: 0.616279\n",
      "epoch 158; iter: 0; batch classifier loss: 0.342774; batch adversarial loss: 0.620140\n",
      "epoch 159; iter: 0; batch classifier loss: 0.403368; batch adversarial loss: 0.565338\n",
      "epoch 160; iter: 0; batch classifier loss: 0.357952; batch adversarial loss: 0.526262\n",
      "epoch 161; iter: 0; batch classifier loss: 0.373714; batch adversarial loss: 0.614993\n",
      "epoch 162; iter: 0; batch classifier loss: 0.365938; batch adversarial loss: 0.519308\n",
      "epoch 163; iter: 0; batch classifier loss: 0.311967; batch adversarial loss: 0.501719\n",
      "epoch 164; iter: 0; batch classifier loss: 0.450629; batch adversarial loss: 0.543336\n",
      "epoch 165; iter: 0; batch classifier loss: 0.387853; batch adversarial loss: 0.618145\n",
      "epoch 166; iter: 0; batch classifier loss: 0.419909; batch adversarial loss: 0.607724\n",
      "epoch 167; iter: 0; batch classifier loss: 0.428625; batch adversarial loss: 0.555963\n",
      "epoch 168; iter: 0; batch classifier loss: 0.380986; batch adversarial loss: 0.563742\n",
      "epoch 169; iter: 0; batch classifier loss: 0.450114; batch adversarial loss: 0.540314\n",
      "epoch 170; iter: 0; batch classifier loss: 0.392770; batch adversarial loss: 0.581631\n",
      "epoch 171; iter: 0; batch classifier loss: 0.355862; batch adversarial loss: 0.589547\n",
      "epoch 172; iter: 0; batch classifier loss: 0.462140; batch adversarial loss: 0.579437\n",
      "epoch 173; iter: 0; batch classifier loss: 0.413451; batch adversarial loss: 0.526048\n",
      "epoch 174; iter: 0; batch classifier loss: 0.278797; batch adversarial loss: 0.524963\n",
      "epoch 175; iter: 0; batch classifier loss: 0.253056; batch adversarial loss: 0.614751\n",
      "epoch 176; iter: 0; batch classifier loss: 0.403568; batch adversarial loss: 0.600616\n",
      "epoch 177; iter: 0; batch classifier loss: 0.367165; batch adversarial loss: 0.589318\n",
      "epoch 178; iter: 0; batch classifier loss: 0.305847; batch adversarial loss: 0.569407\n",
      "epoch 179; iter: 0; batch classifier loss: 0.487834; batch adversarial loss: 0.578884\n",
      "epoch 180; iter: 0; batch classifier loss: 0.441303; batch adversarial loss: 0.506607\n",
      "epoch 181; iter: 0; batch classifier loss: 0.329062; batch adversarial loss: 0.467917\n",
      "epoch 182; iter: 0; batch classifier loss: 0.435658; batch adversarial loss: 0.547005\n",
      "epoch 183; iter: 0; batch classifier loss: 0.412850; batch adversarial loss: 0.534740\n",
      "epoch 184; iter: 0; batch classifier loss: 0.371853; batch adversarial loss: 0.594469\n",
      "epoch 185; iter: 0; batch classifier loss: 0.367204; batch adversarial loss: 0.531025\n",
      "epoch 186; iter: 0; batch classifier loss: 0.395202; batch adversarial loss: 0.547649\n",
      "epoch 187; iter: 0; batch classifier loss: 0.357735; batch adversarial loss: 0.570079\n",
      "epoch 188; iter: 0; batch classifier loss: 0.360468; batch adversarial loss: 0.622371\n",
      "epoch 189; iter: 0; batch classifier loss: 0.414191; batch adversarial loss: 0.597713\n",
      "epoch 190; iter: 0; batch classifier loss: 0.411263; batch adversarial loss: 0.536100\n",
      "epoch 191; iter: 0; batch classifier loss: 0.422499; batch adversarial loss: 0.499922\n",
      "epoch 192; iter: 0; batch classifier loss: 0.319000; batch adversarial loss: 0.483809\n",
      "epoch 193; iter: 0; batch classifier loss: 0.318822; batch adversarial loss: 0.537613\n",
      "epoch 194; iter: 0; batch classifier loss: 0.367510; batch adversarial loss: 0.570183\n",
      "epoch 195; iter: 0; batch classifier loss: 0.350206; batch adversarial loss: 0.562621\n",
      "epoch 196; iter: 0; batch classifier loss: 0.315926; batch adversarial loss: 0.545543\n",
      "epoch 197; iter: 0; batch classifier loss: 0.357638; batch adversarial loss: 0.587898\n",
      "epoch 198; iter: 0; batch classifier loss: 0.411053; batch adversarial loss: 0.574615\n",
      "epoch 199; iter: 0; batch classifier loss: 0.329480; batch adversarial loss: 0.568363\n",
      "epoch 0; iter: 0; batch classifier loss: 0.722442; batch adversarial loss: 0.729503\n",
      "epoch 1; iter: 0; batch classifier loss: 0.635836; batch adversarial loss: 0.683519\n",
      "epoch 2; iter: 0; batch classifier loss: 0.545933; batch adversarial loss: 0.646738\n",
      "epoch 3; iter: 0; batch classifier loss: 0.529574; batch adversarial loss: 0.686625\n",
      "epoch 4; iter: 0; batch classifier loss: 0.538388; batch adversarial loss: 0.615713\n",
      "epoch 5; iter: 0; batch classifier loss: 0.600555; batch adversarial loss: 0.621027\n",
      "epoch 6; iter: 0; batch classifier loss: 0.571199; batch adversarial loss: 0.614562\n",
      "epoch 7; iter: 0; batch classifier loss: 0.498433; batch adversarial loss: 0.629053\n",
      "epoch 8; iter: 0; batch classifier loss: 0.511333; batch adversarial loss: 0.644679\n",
      "epoch 9; iter: 0; batch classifier loss: 0.514741; batch adversarial loss: 0.589590\n",
      "epoch 10; iter: 0; batch classifier loss: 0.636387; batch adversarial loss: 0.602452\n",
      "epoch 11; iter: 0; batch classifier loss: 0.548445; batch adversarial loss: 0.683563\n",
      "epoch 12; iter: 0; batch classifier loss: 0.478291; batch adversarial loss: 0.562930\n",
      "epoch 13; iter: 0; batch classifier loss: 0.515976; batch adversarial loss: 0.568167\n",
      "epoch 14; iter: 0; batch classifier loss: 0.462011; batch adversarial loss: 0.605631\n",
      "epoch 15; iter: 0; batch classifier loss: 0.515299; batch adversarial loss: 0.603253\n",
      "epoch 16; iter: 0; batch classifier loss: 0.499899; batch adversarial loss: 0.500376\n",
      "epoch 17; iter: 0; batch classifier loss: 0.466904; batch adversarial loss: 0.610068\n",
      "epoch 18; iter: 0; batch classifier loss: 0.491098; batch adversarial loss: 0.541279\n",
      "epoch 19; iter: 0; batch classifier loss: 0.501459; batch adversarial loss: 0.489448\n",
      "epoch 20; iter: 0; batch classifier loss: 0.461958; batch adversarial loss: 0.553458\n",
      "epoch 21; iter: 0; batch classifier loss: 0.528800; batch adversarial loss: 0.477569\n",
      "epoch 22; iter: 0; batch classifier loss: 0.432215; batch adversarial loss: 0.570288\n",
      "epoch 23; iter: 0; batch classifier loss: 0.432294; batch adversarial loss: 0.490741\n",
      "epoch 24; iter: 0; batch classifier loss: 0.483106; batch adversarial loss: 0.549222\n",
      "epoch 25; iter: 0; batch classifier loss: 0.525574; batch adversarial loss: 0.567191\n",
      "epoch 26; iter: 0; batch classifier loss: 0.461302; batch adversarial loss: 0.511115\n",
      "epoch 27; iter: 0; batch classifier loss: 0.453566; batch adversarial loss: 0.555094\n",
      "epoch 28; iter: 0; batch classifier loss: 0.479364; batch adversarial loss: 0.515539\n",
      "epoch 29; iter: 0; batch classifier loss: 0.439473; batch adversarial loss: 0.486898\n",
      "epoch 30; iter: 0; batch classifier loss: 0.461396; batch adversarial loss: 0.501234\n",
      "epoch 31; iter: 0; batch classifier loss: 0.400519; batch adversarial loss: 0.569752\n",
      "epoch 32; iter: 0; batch classifier loss: 0.474325; batch adversarial loss: 0.528637\n",
      "epoch 33; iter: 0; batch classifier loss: 0.459988; batch adversarial loss: 0.533266\n",
      "epoch 34; iter: 0; batch classifier loss: 0.451600; batch adversarial loss: 0.502556\n",
      "epoch 35; iter: 0; batch classifier loss: 0.446145; batch adversarial loss: 0.658773\n",
      "epoch 36; iter: 0; batch classifier loss: 0.447924; batch adversarial loss: 0.582675\n",
      "epoch 37; iter: 0; batch classifier loss: 0.493197; batch adversarial loss: 0.579124\n",
      "epoch 38; iter: 0; batch classifier loss: 0.428554; batch adversarial loss: 0.560379\n",
      "epoch 39; iter: 0; batch classifier loss: 0.439559; batch adversarial loss: 0.543934\n",
      "epoch 40; iter: 0; batch classifier loss: 0.461434; batch adversarial loss: 0.580322\n",
      "epoch 41; iter: 0; batch classifier loss: 0.417111; batch adversarial loss: 0.567738\n",
      "epoch 42; iter: 0; batch classifier loss: 0.400343; batch adversarial loss: 0.543886\n",
      "epoch 43; iter: 0; batch classifier loss: 0.452806; batch adversarial loss: 0.554709\n",
      "epoch 44; iter: 0; batch classifier loss: 0.445198; batch adversarial loss: 0.509472\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 45; iter: 0; batch classifier loss: 0.414984; batch adversarial loss: 0.545159\n",
      "epoch 46; iter: 0; batch classifier loss: 0.451822; batch adversarial loss: 0.561870\n",
      "epoch 47; iter: 0; batch classifier loss: 0.504545; batch adversarial loss: 0.535811\n",
      "epoch 48; iter: 0; batch classifier loss: 0.364596; batch adversarial loss: 0.580288\n",
      "epoch 49; iter: 0; batch classifier loss: 0.458687; batch adversarial loss: 0.544675\n",
      "epoch 50; iter: 0; batch classifier loss: 0.560141; batch adversarial loss: 0.562627\n",
      "epoch 51; iter: 0; batch classifier loss: 0.397672; batch adversarial loss: 0.499080\n",
      "epoch 52; iter: 0; batch classifier loss: 0.401743; batch adversarial loss: 0.608267\n",
      "epoch 53; iter: 0; batch classifier loss: 0.481028; batch adversarial loss: 0.498225\n",
      "epoch 54; iter: 0; batch classifier loss: 0.448235; batch adversarial loss: 0.444340\n",
      "epoch 55; iter: 0; batch classifier loss: 0.387253; batch adversarial loss: 0.544647\n",
      "epoch 56; iter: 0; batch classifier loss: 0.371795; batch adversarial loss: 0.525780\n",
      "epoch 57; iter: 0; batch classifier loss: 0.438734; batch adversarial loss: 0.517888\n",
      "epoch 58; iter: 0; batch classifier loss: 0.386373; batch adversarial loss: 0.590713\n",
      "epoch 59; iter: 0; batch classifier loss: 0.386291; batch adversarial loss: 0.525595\n",
      "epoch 60; iter: 0; batch classifier loss: 0.354998; batch adversarial loss: 0.526971\n",
      "epoch 61; iter: 0; batch classifier loss: 0.382436; batch adversarial loss: 0.516463\n",
      "epoch 62; iter: 0; batch classifier loss: 0.460377; batch adversarial loss: 0.572020\n",
      "epoch 63; iter: 0; batch classifier loss: 0.441636; batch adversarial loss: 0.582498\n",
      "epoch 64; iter: 0; batch classifier loss: 0.390766; batch adversarial loss: 0.535722\n",
      "epoch 65; iter: 0; batch classifier loss: 0.422298; batch adversarial loss: 0.497573\n",
      "epoch 66; iter: 0; batch classifier loss: 0.423446; batch adversarial loss: 0.608571\n",
      "epoch 67; iter: 0; batch classifier loss: 0.442613; batch adversarial loss: 0.590971\n",
      "epoch 68; iter: 0; batch classifier loss: 0.313094; batch adversarial loss: 0.490636\n",
      "epoch 69; iter: 0; batch classifier loss: 0.310229; batch adversarial loss: 0.562690\n",
      "epoch 70; iter: 0; batch classifier loss: 0.467893; batch adversarial loss: 0.534755\n",
      "epoch 71; iter: 0; batch classifier loss: 0.406973; batch adversarial loss: 0.480332\n",
      "epoch 72; iter: 0; batch classifier loss: 0.383125; batch adversarial loss: 0.617976\n",
      "epoch 73; iter: 0; batch classifier loss: 0.477524; batch adversarial loss: 0.618308\n",
      "epoch 74; iter: 0; batch classifier loss: 0.298406; batch adversarial loss: 0.545828\n",
      "epoch 75; iter: 0; batch classifier loss: 0.357167; batch adversarial loss: 0.580618\n",
      "epoch 76; iter: 0; batch classifier loss: 0.337281; batch adversarial loss: 0.536045\n",
      "epoch 77; iter: 0; batch classifier loss: 0.504144; batch adversarial loss: 0.544694\n",
      "epoch 78; iter: 0; batch classifier loss: 0.412011; batch adversarial loss: 0.627772\n",
      "epoch 79; iter: 0; batch classifier loss: 0.358015; batch adversarial loss: 0.544841\n",
      "epoch 80; iter: 0; batch classifier loss: 0.390717; batch adversarial loss: 0.535584\n",
      "epoch 81; iter: 0; batch classifier loss: 0.358578; batch adversarial loss: 0.663380\n",
      "epoch 82; iter: 0; batch classifier loss: 0.389144; batch adversarial loss: 0.498690\n",
      "epoch 83; iter: 0; batch classifier loss: 0.376458; batch adversarial loss: 0.526496\n",
      "epoch 84; iter: 0; batch classifier loss: 0.454579; batch adversarial loss: 0.499041\n",
      "epoch 85; iter: 0; batch classifier loss: 0.410655; batch adversarial loss: 0.571183\n",
      "epoch 86; iter: 0; batch classifier loss: 0.461391; batch adversarial loss: 0.489293\n",
      "epoch 87; iter: 0; batch classifier loss: 0.367421; batch adversarial loss: 0.563058\n",
      "epoch 88; iter: 0; batch classifier loss: 0.351634; batch adversarial loss: 0.516625\n",
      "epoch 89; iter: 0; batch classifier loss: 0.396801; batch adversarial loss: 0.581192\n",
      "epoch 90; iter: 0; batch classifier loss: 0.425176; batch adversarial loss: 0.525901\n",
      "epoch 91; iter: 0; batch classifier loss: 0.385412; batch adversarial loss: 0.526218\n",
      "epoch 92; iter: 0; batch classifier loss: 0.422362; batch adversarial loss: 0.461092\n",
      "epoch 93; iter: 0; batch classifier loss: 0.404641; batch adversarial loss: 0.572414\n",
      "epoch 94; iter: 0; batch classifier loss: 0.348240; batch adversarial loss: 0.599011\n",
      "epoch 95; iter: 0; batch classifier loss: 0.400318; batch adversarial loss: 0.498484\n",
      "epoch 96; iter: 0; batch classifier loss: 0.352558; batch adversarial loss: 0.535345\n",
      "epoch 97; iter: 0; batch classifier loss: 0.336122; batch adversarial loss: 0.553334\n",
      "epoch 98; iter: 0; batch classifier loss: 0.334958; batch adversarial loss: 0.609281\n",
      "epoch 99; iter: 0; batch classifier loss: 0.441968; batch adversarial loss: 0.498157\n",
      "epoch 100; iter: 0; batch classifier loss: 0.362587; batch adversarial loss: 0.581523\n",
      "epoch 101; iter: 0; batch classifier loss: 0.313905; batch adversarial loss: 0.470406\n",
      "epoch 102; iter: 0; batch classifier loss: 0.359303; batch adversarial loss: 0.535495\n",
      "epoch 103; iter: 0; batch classifier loss: 0.322281; batch adversarial loss: 0.535132\n",
      "epoch 104; iter: 0; batch classifier loss: 0.436776; batch adversarial loss: 0.489204\n",
      "epoch 105; iter: 0; batch classifier loss: 0.316232; batch adversarial loss: 0.571724\n",
      "epoch 106; iter: 0; batch classifier loss: 0.432256; batch adversarial loss: 0.581612\n",
      "epoch 107; iter: 0; batch classifier loss: 0.402640; batch adversarial loss: 0.581306\n",
      "epoch 108; iter: 0; batch classifier loss: 0.390413; batch adversarial loss: 0.617866\n",
      "epoch 109; iter: 0; batch classifier loss: 0.297267; batch adversarial loss: 0.526433\n",
      "epoch 110; iter: 0; batch classifier loss: 0.364893; batch adversarial loss: 0.544624\n",
      "epoch 111; iter: 0; batch classifier loss: 0.356566; batch adversarial loss: 0.553503\n",
      "epoch 112; iter: 0; batch classifier loss: 0.400498; batch adversarial loss: 0.526492\n",
      "epoch 113; iter: 0; batch classifier loss: 0.391655; batch adversarial loss: 0.599745\n",
      "epoch 114; iter: 0; batch classifier loss: 0.410947; batch adversarial loss: 0.507425\n",
      "epoch 115; iter: 0; batch classifier loss: 0.428678; batch adversarial loss: 0.444241\n",
      "epoch 116; iter: 0; batch classifier loss: 0.448579; batch adversarial loss: 0.608646\n",
      "epoch 117; iter: 0; batch classifier loss: 0.477168; batch adversarial loss: 0.544286\n",
      "epoch 118; iter: 0; batch classifier loss: 0.294404; batch adversarial loss: 0.571585\n",
      "epoch 119; iter: 0; batch classifier loss: 0.354882; batch adversarial loss: 0.525896\n",
      "epoch 120; iter: 0; batch classifier loss: 0.317133; batch adversarial loss: 0.526004\n",
      "epoch 121; iter: 0; batch classifier loss: 0.396600; batch adversarial loss: 0.635965\n",
      "epoch 122; iter: 0; batch classifier loss: 0.309176; batch adversarial loss: 0.526058\n",
      "epoch 123; iter: 0; batch classifier loss: 0.296383; batch adversarial loss: 0.562801\n",
      "epoch 124; iter: 0; batch classifier loss: 0.418104; batch adversarial loss: 0.553658\n",
      "epoch 125; iter: 0; batch classifier loss: 0.342536; batch adversarial loss: 0.544231\n",
      "epoch 126; iter: 0; batch classifier loss: 0.312104; batch adversarial loss: 0.590261\n",
      "epoch 127; iter: 0; batch classifier loss: 0.438174; batch adversarial loss: 0.553811\n",
      "epoch 128; iter: 0; batch classifier loss: 0.388467; batch adversarial loss: 0.544611\n",
      "epoch 129; iter: 0; batch classifier loss: 0.343053; batch adversarial loss: 0.526218\n",
      "epoch 130; iter: 0; batch classifier loss: 0.364000; batch adversarial loss: 0.581233\n",
      "epoch 131; iter: 0; batch classifier loss: 0.336905; batch adversarial loss: 0.590596\n",
      "epoch 132; iter: 0; batch classifier loss: 0.384250; batch adversarial loss: 0.581228\n",
      "epoch 133; iter: 0; batch classifier loss: 0.352384; batch adversarial loss: 0.544201\n",
      "epoch 134; iter: 0; batch classifier loss: 0.306903; batch adversarial loss: 0.562876\n",
      "epoch 135; iter: 0; batch classifier loss: 0.340757; batch adversarial loss: 0.535537\n",
      "epoch 136; iter: 0; batch classifier loss: 0.359193; batch adversarial loss: 0.553686\n",
      "epoch 137; iter: 0; batch classifier loss: 0.361164; batch adversarial loss: 0.525935\n",
      "epoch 138; iter: 0; batch classifier loss: 0.385527; batch adversarial loss: 0.637205\n",
      "epoch 139; iter: 0; batch classifier loss: 0.347841; batch adversarial loss: 0.526355\n",
      "epoch 140; iter: 0; batch classifier loss: 0.348090; batch adversarial loss: 0.572181\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 141; iter: 0; batch classifier loss: 0.364923; batch adversarial loss: 0.645946\n",
      "epoch 142; iter: 0; batch classifier loss: 0.415191; batch adversarial loss: 0.498814\n",
      "epoch 143; iter: 0; batch classifier loss: 0.319547; batch adversarial loss: 0.572429\n",
      "epoch 144; iter: 0; batch classifier loss: 0.380964; batch adversarial loss: 0.507598\n",
      "epoch 145; iter: 0; batch classifier loss: 0.350403; batch adversarial loss: 0.562852\n",
      "epoch 146; iter: 0; batch classifier loss: 0.313019; batch adversarial loss: 0.590246\n",
      "epoch 147; iter: 0; batch classifier loss: 0.267774; batch adversarial loss: 0.589926\n",
      "epoch 148; iter: 0; batch classifier loss: 0.282205; batch adversarial loss: 0.581191\n",
      "epoch 149; iter: 0; batch classifier loss: 0.340956; batch adversarial loss: 0.535146\n",
      "epoch 150; iter: 0; batch classifier loss: 0.363167; batch adversarial loss: 0.544621\n",
      "epoch 151; iter: 0; batch classifier loss: 0.329281; batch adversarial loss: 0.535615\n",
      "epoch 152; iter: 0; batch classifier loss: 0.320259; batch adversarial loss: 0.525663\n",
      "epoch 153; iter: 0; batch classifier loss: 0.353156; batch adversarial loss: 0.498666\n",
      "epoch 154; iter: 0; batch classifier loss: 0.342954; batch adversarial loss: 0.526154\n",
      "epoch 155; iter: 0; batch classifier loss: 0.297960; batch adversarial loss: 0.645595\n",
      "epoch 156; iter: 0; batch classifier loss: 0.374451; batch adversarial loss: 0.553667\n",
      "epoch 157; iter: 0; batch classifier loss: 0.357855; batch adversarial loss: 0.517245\n",
      "epoch 158; iter: 0; batch classifier loss: 0.319618; batch adversarial loss: 0.562921\n",
      "epoch 159; iter: 0; batch classifier loss: 0.328913; batch adversarial loss: 0.535288\n",
      "epoch 160; iter: 0; batch classifier loss: 0.351158; batch adversarial loss: 0.618143\n",
      "epoch 161; iter: 0; batch classifier loss: 0.401764; batch adversarial loss: 0.599728\n",
      "epoch 162; iter: 0; batch classifier loss: 0.354655; batch adversarial loss: 0.562272\n",
      "epoch 163; iter: 0; batch classifier loss: 0.287962; batch adversarial loss: 0.599743\n",
      "epoch 164; iter: 0; batch classifier loss: 0.414073; batch adversarial loss: 0.609150\n",
      "epoch 165; iter: 0; batch classifier loss: 0.355784; batch adversarial loss: 0.526349\n",
      "epoch 166; iter: 0; batch classifier loss: 0.309195; batch adversarial loss: 0.507692\n",
      "epoch 167; iter: 0; batch classifier loss: 0.318054; batch adversarial loss: 0.544724\n",
      "epoch 168; iter: 0; batch classifier loss: 0.403883; batch adversarial loss: 0.535119\n",
      "epoch 169; iter: 0; batch classifier loss: 0.395826; batch adversarial loss: 0.581582\n",
      "epoch 170; iter: 0; batch classifier loss: 0.390191; batch adversarial loss: 0.590674\n",
      "epoch 171; iter: 0; batch classifier loss: 0.348926; batch adversarial loss: 0.544674\n",
      "epoch 172; iter: 0; batch classifier loss: 0.336910; batch adversarial loss: 0.608886\n",
      "epoch 173; iter: 0; batch classifier loss: 0.329905; batch adversarial loss: 0.600001\n",
      "epoch 174; iter: 0; batch classifier loss: 0.372328; batch adversarial loss: 0.553875\n",
      "epoch 175; iter: 0; batch classifier loss: 0.297646; batch adversarial loss: 0.516979\n",
      "epoch 176; iter: 0; batch classifier loss: 0.358380; batch adversarial loss: 0.553771\n",
      "epoch 177; iter: 0; batch classifier loss: 0.366099; batch adversarial loss: 0.498357\n",
      "epoch 178; iter: 0; batch classifier loss: 0.342976; batch adversarial loss: 0.581358\n",
      "epoch 179; iter: 0; batch classifier loss: 0.402181; batch adversarial loss: 0.535636\n",
      "epoch 180; iter: 0; batch classifier loss: 0.379076; batch adversarial loss: 0.581286\n",
      "epoch 181; iter: 0; batch classifier loss: 0.429276; batch adversarial loss: 0.526636\n",
      "epoch 182; iter: 0; batch classifier loss: 0.356011; batch adversarial loss: 0.489445\n",
      "epoch 183; iter: 0; batch classifier loss: 0.373172; batch adversarial loss: 0.563148\n",
      "epoch 184; iter: 0; batch classifier loss: 0.395612; batch adversarial loss: 0.489133\n",
      "epoch 185; iter: 0; batch classifier loss: 0.358280; batch adversarial loss: 0.618062\n",
      "epoch 186; iter: 0; batch classifier loss: 0.334280; batch adversarial loss: 0.526262\n",
      "epoch 187; iter: 0; batch classifier loss: 0.333518; batch adversarial loss: 0.590513\n",
      "epoch 188; iter: 0; batch classifier loss: 0.298491; batch adversarial loss: 0.645251\n",
      "epoch 189; iter: 0; batch classifier loss: 0.315006; batch adversarial loss: 0.544554\n",
      "epoch 190; iter: 0; batch classifier loss: 0.345692; batch adversarial loss: 0.517015\n",
      "epoch 191; iter: 0; batch classifier loss: 0.339794; batch adversarial loss: 0.535460\n",
      "epoch 192; iter: 0; batch classifier loss: 0.373769; batch adversarial loss: 0.553718\n",
      "epoch 193; iter: 0; batch classifier loss: 0.432245; batch adversarial loss: 0.535353\n",
      "epoch 194; iter: 0; batch classifier loss: 0.368264; batch adversarial loss: 0.535381\n",
      "epoch 195; iter: 0; batch classifier loss: 0.286964; batch adversarial loss: 0.507897\n",
      "epoch 196; iter: 0; batch classifier loss: 0.420802; batch adversarial loss: 0.526153\n",
      "epoch 197; iter: 0; batch classifier loss: 0.365771; batch adversarial loss: 0.498911\n",
      "epoch 198; iter: 0; batch classifier loss: 0.303310; batch adversarial loss: 0.606985\n",
      "epoch 199; iter: 0; batch classifier loss: 0.324992; batch adversarial loss: 0.470347\n",
      "epoch 0; iter: 0; batch classifier loss: 0.696190; batch adversarial loss: 0.867346\n",
      "epoch 1; iter: 0; batch classifier loss: 0.811035; batch adversarial loss: 0.937869\n",
      "epoch 2; iter: 0; batch classifier loss: 0.940896; batch adversarial loss: 0.889097\n",
      "epoch 3; iter: 0; batch classifier loss: 0.955387; batch adversarial loss: 0.817478\n",
      "epoch 4; iter: 0; batch classifier loss: 0.891032; batch adversarial loss: 0.756197\n",
      "epoch 5; iter: 0; batch classifier loss: 0.835982; batch adversarial loss: 0.697029\n",
      "epoch 6; iter: 0; batch classifier loss: 0.680564; batch adversarial loss: 0.665237\n",
      "epoch 7; iter: 0; batch classifier loss: 0.576451; batch adversarial loss: 0.611677\n",
      "epoch 8; iter: 0; batch classifier loss: 0.550234; batch adversarial loss: 0.588257\n",
      "epoch 9; iter: 0; batch classifier loss: 0.527583; batch adversarial loss: 0.566047\n",
      "epoch 10; iter: 0; batch classifier loss: 0.548734; batch adversarial loss: 0.581063\n",
      "epoch 11; iter: 0; batch classifier loss: 0.533770; batch adversarial loss: 0.573875\n",
      "epoch 12; iter: 0; batch classifier loss: 0.498620; batch adversarial loss: 0.543086\n",
      "epoch 13; iter: 0; batch classifier loss: 0.548524; batch adversarial loss: 0.564936\n",
      "epoch 14; iter: 0; batch classifier loss: 0.554371; batch adversarial loss: 0.617344\n",
      "epoch 15; iter: 0; batch classifier loss: 0.632759; batch adversarial loss: 0.556698\n",
      "epoch 16; iter: 0; batch classifier loss: 0.554314; batch adversarial loss: 0.592512\n",
      "epoch 17; iter: 0; batch classifier loss: 0.540582; batch adversarial loss: 0.583835\n",
      "epoch 18; iter: 0; batch classifier loss: 0.466097; batch adversarial loss: 0.543249\n",
      "epoch 19; iter: 0; batch classifier loss: 0.489564; batch adversarial loss: 0.512914\n",
      "epoch 20; iter: 0; batch classifier loss: 0.471519; batch adversarial loss: 0.589726\n",
      "epoch 21; iter: 0; batch classifier loss: 0.541641; batch adversarial loss: 0.533503\n",
      "epoch 22; iter: 0; batch classifier loss: 0.586445; batch adversarial loss: 0.579392\n",
      "epoch 23; iter: 0; batch classifier loss: 0.512952; batch adversarial loss: 0.547034\n",
      "epoch 24; iter: 0; batch classifier loss: 0.463890; batch adversarial loss: 0.592957\n",
      "epoch 25; iter: 0; batch classifier loss: 0.452483; batch adversarial loss: 0.518717\n",
      "epoch 26; iter: 0; batch classifier loss: 0.517040; batch adversarial loss: 0.452385\n",
      "epoch 27; iter: 0; batch classifier loss: 0.475880; batch adversarial loss: 0.519271\n",
      "epoch 28; iter: 0; batch classifier loss: 0.415085; batch adversarial loss: 0.568803\n",
      "epoch 29; iter: 0; batch classifier loss: 0.529547; batch adversarial loss: 0.525412\n",
      "epoch 30; iter: 0; batch classifier loss: 0.508789; batch adversarial loss: 0.593082\n",
      "epoch 31; iter: 0; batch classifier loss: 0.486002; batch adversarial loss: 0.526140\n",
      "epoch 32; iter: 0; batch classifier loss: 0.450625; batch adversarial loss: 0.509336\n",
      "epoch 33; iter: 0; batch classifier loss: 0.522665; batch adversarial loss: 0.538260\n",
      "epoch 34; iter: 0; batch classifier loss: 0.449863; batch adversarial loss: 0.518552\n",
      "epoch 35; iter: 0; batch classifier loss: 0.455964; batch adversarial loss: 0.567221\n",
      "epoch 36; iter: 0; batch classifier loss: 0.397368; batch adversarial loss: 0.592538\n",
      "epoch 37; iter: 0; batch classifier loss: 0.419134; batch adversarial loss: 0.543720\n",
      "epoch 38; iter: 0; batch classifier loss: 0.546725; batch adversarial loss: 0.564463\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 39; iter: 0; batch classifier loss: 0.434310; batch adversarial loss: 0.532051\n",
      "epoch 40; iter: 0; batch classifier loss: 0.430959; batch adversarial loss: 0.623587\n",
      "epoch 41; iter: 0; batch classifier loss: 0.455511; batch adversarial loss: 0.546703\n",
      "epoch 42; iter: 0; batch classifier loss: 0.431847; batch adversarial loss: 0.667810\n",
      "epoch 43; iter: 0; batch classifier loss: 0.523537; batch adversarial loss: 0.547005\n",
      "epoch 44; iter: 0; batch classifier loss: 0.501941; batch adversarial loss: 0.561939\n",
      "epoch 45; iter: 0; batch classifier loss: 0.426341; batch adversarial loss: 0.554634\n",
      "epoch 46; iter: 0; batch classifier loss: 0.486961; batch adversarial loss: 0.588058\n",
      "epoch 47; iter: 0; batch classifier loss: 0.408968; batch adversarial loss: 0.493618\n",
      "epoch 48; iter: 0; batch classifier loss: 0.530077; batch adversarial loss: 0.641357\n",
      "epoch 49; iter: 0; batch classifier loss: 0.407381; batch adversarial loss: 0.490894\n",
      "epoch 50; iter: 0; batch classifier loss: 0.409455; batch adversarial loss: 0.550114\n",
      "epoch 51; iter: 0; batch classifier loss: 0.540911; batch adversarial loss: 0.520160\n",
      "epoch 52; iter: 0; batch classifier loss: 0.467765; batch adversarial loss: 0.537062\n",
      "epoch 53; iter: 0; batch classifier loss: 0.375259; batch adversarial loss: 0.591378\n",
      "epoch 54; iter: 0; batch classifier loss: 0.377183; batch adversarial loss: 0.562378\n",
      "epoch 55; iter: 0; batch classifier loss: 0.426107; batch adversarial loss: 0.541839\n",
      "epoch 56; iter: 0; batch classifier loss: 0.442021; batch adversarial loss: 0.597042\n",
      "epoch 57; iter: 0; batch classifier loss: 0.444614; batch adversarial loss: 0.528579\n",
      "epoch 58; iter: 0; batch classifier loss: 0.376180; batch adversarial loss: 0.550776\n",
      "epoch 59; iter: 0; batch classifier loss: 0.453901; batch adversarial loss: 0.644556\n",
      "epoch 60; iter: 0; batch classifier loss: 0.376532; batch adversarial loss: 0.527232\n",
      "epoch 61; iter: 0; batch classifier loss: 0.466566; batch adversarial loss: 0.568204\n",
      "epoch 62; iter: 0; batch classifier loss: 0.474454; batch adversarial loss: 0.514633\n",
      "epoch 63; iter: 0; batch classifier loss: 0.409496; batch adversarial loss: 0.570839\n",
      "epoch 64; iter: 0; batch classifier loss: 0.376326; batch adversarial loss: 0.552699\n",
      "epoch 65; iter: 0; batch classifier loss: 0.475073; batch adversarial loss: 0.575060\n",
      "epoch 66; iter: 0; batch classifier loss: 0.359130; batch adversarial loss: 0.571401\n",
      "epoch 67; iter: 0; batch classifier loss: 0.453110; batch adversarial loss: 0.560737\n",
      "epoch 68; iter: 0; batch classifier loss: 0.393115; batch adversarial loss: 0.533853\n",
      "epoch 69; iter: 0; batch classifier loss: 0.424335; batch adversarial loss: 0.597483\n",
      "epoch 70; iter: 0; batch classifier loss: 0.384824; batch adversarial loss: 0.593296\n",
      "epoch 71; iter: 0; batch classifier loss: 0.374986; batch adversarial loss: 0.579065\n",
      "epoch 72; iter: 0; batch classifier loss: 0.347795; batch adversarial loss: 0.544236\n",
      "epoch 73; iter: 0; batch classifier loss: 0.386015; batch adversarial loss: 0.562508\n",
      "epoch 74; iter: 0; batch classifier loss: 0.372151; batch adversarial loss: 0.559710\n",
      "epoch 75; iter: 0; batch classifier loss: 0.473859; batch adversarial loss: 0.517212\n",
      "epoch 76; iter: 0; batch classifier loss: 0.459519; batch adversarial loss: 0.561471\n",
      "epoch 77; iter: 0; batch classifier loss: 0.398739; batch adversarial loss: 0.552713\n",
      "epoch 78; iter: 0; batch classifier loss: 0.411462; batch adversarial loss: 0.588030\n",
      "epoch 79; iter: 0; batch classifier loss: 0.362790; batch adversarial loss: 0.533722\n",
      "epoch 80; iter: 0; batch classifier loss: 0.394438; batch adversarial loss: 0.476745\n",
      "epoch 81; iter: 0; batch classifier loss: 0.403744; batch adversarial loss: 0.555629\n",
      "epoch 82; iter: 0; batch classifier loss: 0.360574; batch adversarial loss: 0.527218\n",
      "epoch 83; iter: 0; batch classifier loss: 0.330547; batch adversarial loss: 0.544178\n",
      "epoch 84; iter: 0; batch classifier loss: 0.373433; batch adversarial loss: 0.535113\n",
      "epoch 85; iter: 0; batch classifier loss: 0.415826; batch adversarial loss: 0.604780\n",
      "epoch 86; iter: 0; batch classifier loss: 0.394790; batch adversarial loss: 0.581064\n",
      "epoch 87; iter: 0; batch classifier loss: 0.417716; batch adversarial loss: 0.471840\n",
      "epoch 88; iter: 0; batch classifier loss: 0.340289; batch adversarial loss: 0.579092\n",
      "epoch 89; iter: 0; batch classifier loss: 0.431775; batch adversarial loss: 0.614119\n",
      "epoch 90; iter: 0; batch classifier loss: 0.420901; batch adversarial loss: 0.454501\n",
      "epoch 91; iter: 0; batch classifier loss: 0.387389; batch adversarial loss: 0.483026\n",
      "epoch 92; iter: 0; batch classifier loss: 0.419690; batch adversarial loss: 0.562610\n",
      "epoch 93; iter: 0; batch classifier loss: 0.378094; batch adversarial loss: 0.519669\n",
      "epoch 94; iter: 0; batch classifier loss: 0.317047; batch adversarial loss: 0.510552\n",
      "epoch 95; iter: 0; batch classifier loss: 0.309541; batch adversarial loss: 0.562233\n",
      "epoch 96; iter: 0; batch classifier loss: 0.375885; batch adversarial loss: 0.462507\n",
      "epoch 97; iter: 0; batch classifier loss: 0.400802; batch adversarial loss: 0.581962\n",
      "epoch 98; iter: 0; batch classifier loss: 0.456034; batch adversarial loss: 0.535425\n",
      "epoch 99; iter: 0; batch classifier loss: 0.376095; batch adversarial loss: 0.559439\n",
      "epoch 100; iter: 0; batch classifier loss: 0.416216; batch adversarial loss: 0.535420\n",
      "epoch 101; iter: 0; batch classifier loss: 0.374936; batch adversarial loss: 0.507844\n",
      "epoch 102; iter: 0; batch classifier loss: 0.323776; batch adversarial loss: 0.545996\n",
      "epoch 103; iter: 0; batch classifier loss: 0.374037; batch adversarial loss: 0.473110\n",
      "epoch 104; iter: 0; batch classifier loss: 0.371504; batch adversarial loss: 0.589050\n",
      "epoch 105; iter: 0; batch classifier loss: 0.398963; batch adversarial loss: 0.578592\n",
      "epoch 106; iter: 0; batch classifier loss: 0.317487; batch adversarial loss: 0.523953\n",
      "epoch 107; iter: 0; batch classifier loss: 0.372065; batch adversarial loss: 0.547579\n",
      "epoch 108; iter: 0; batch classifier loss: 0.284652; batch adversarial loss: 0.517063\n",
      "epoch 109; iter: 0; batch classifier loss: 0.333843; batch adversarial loss: 0.509043\n",
      "epoch 110; iter: 0; batch classifier loss: 0.366068; batch adversarial loss: 0.543904\n",
      "epoch 111; iter: 0; batch classifier loss: 0.386831; batch adversarial loss: 0.565832\n",
      "epoch 112; iter: 0; batch classifier loss: 0.336558; batch adversarial loss: 0.491542\n",
      "epoch 113; iter: 0; batch classifier loss: 0.387438; batch adversarial loss: 0.525187\n",
      "epoch 114; iter: 0; batch classifier loss: 0.366592; batch adversarial loss: 0.548535\n",
      "epoch 115; iter: 0; batch classifier loss: 0.350988; batch adversarial loss: 0.606902\n",
      "epoch 116; iter: 0; batch classifier loss: 0.278996; batch adversarial loss: 0.603135\n",
      "epoch 117; iter: 0; batch classifier loss: 0.388426; batch adversarial loss: 0.513215\n",
      "epoch 118; iter: 0; batch classifier loss: 0.387259; batch adversarial loss: 0.598361\n",
      "epoch 119; iter: 0; batch classifier loss: 0.341264; batch adversarial loss: 0.511231\n",
      "epoch 120; iter: 0; batch classifier loss: 0.335124; batch adversarial loss: 0.564574\n",
      "epoch 121; iter: 0; batch classifier loss: 0.322078; batch adversarial loss: 0.534169\n",
      "epoch 122; iter: 0; batch classifier loss: 0.400569; batch adversarial loss: 0.572303\n",
      "epoch 123; iter: 0; batch classifier loss: 0.336130; batch adversarial loss: 0.553639\n",
      "epoch 124; iter: 0; batch classifier loss: 0.301864; batch adversarial loss: 0.623688\n",
      "epoch 125; iter: 0; batch classifier loss: 0.409836; batch adversarial loss: 0.581486\n",
      "epoch 126; iter: 0; batch classifier loss: 0.368940; batch adversarial loss: 0.518624\n",
      "epoch 127; iter: 0; batch classifier loss: 0.378266; batch adversarial loss: 0.580240\n",
      "epoch 128; iter: 0; batch classifier loss: 0.374527; batch adversarial loss: 0.481837\n",
      "epoch 129; iter: 0; batch classifier loss: 0.360498; batch adversarial loss: 0.590328\n",
      "epoch 130; iter: 0; batch classifier loss: 0.429359; batch adversarial loss: 0.625004\n",
      "epoch 131; iter: 0; batch classifier loss: 0.380729; batch adversarial loss: 0.519060\n",
      "epoch 132; iter: 0; batch classifier loss: 0.365566; batch adversarial loss: 0.520950\n",
      "epoch 133; iter: 0; batch classifier loss: 0.340828; batch adversarial loss: 0.490428\n",
      "epoch 134; iter: 0; batch classifier loss: 0.319015; batch adversarial loss: 0.572045\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 135; iter: 0; batch classifier loss: 0.399742; batch adversarial loss: 0.579108\n",
      "epoch 136; iter: 0; batch classifier loss: 0.331388; batch adversarial loss: 0.543578\n",
      "epoch 137; iter: 0; batch classifier loss: 0.343038; batch adversarial loss: 0.662797\n",
      "epoch 138; iter: 0; batch classifier loss: 0.425776; batch adversarial loss: 0.543507\n",
      "epoch 139; iter: 0; batch classifier loss: 0.393424; batch adversarial loss: 0.518738\n",
      "epoch 140; iter: 0; batch classifier loss: 0.374354; batch adversarial loss: 0.563863\n",
      "epoch 141; iter: 0; batch classifier loss: 0.349762; batch adversarial loss: 0.651221\n",
      "epoch 142; iter: 0; batch classifier loss: 0.363114; batch adversarial loss: 0.614920\n",
      "epoch 143; iter: 0; batch classifier loss: 0.358828; batch adversarial loss: 0.555589\n",
      "epoch 144; iter: 0; batch classifier loss: 0.358464; batch adversarial loss: 0.482188\n",
      "epoch 145; iter: 0; batch classifier loss: 0.264571; batch adversarial loss: 0.518027\n",
      "epoch 146; iter: 0; batch classifier loss: 0.344608; batch adversarial loss: 0.533949\n",
      "epoch 147; iter: 0; batch classifier loss: 0.339885; batch adversarial loss: 0.498581\n",
      "epoch 148; iter: 0; batch classifier loss: 0.329056; batch adversarial loss: 0.642942\n",
      "epoch 149; iter: 0; batch classifier loss: 0.466418; batch adversarial loss: 0.570523\n",
      "epoch 150; iter: 0; batch classifier loss: 0.290776; batch adversarial loss: 0.562793\n",
      "epoch 151; iter: 0; batch classifier loss: 0.428806; batch adversarial loss: 0.491227\n",
      "epoch 152; iter: 0; batch classifier loss: 0.375646; batch adversarial loss: 0.572528\n",
      "epoch 153; iter: 0; batch classifier loss: 0.409409; batch adversarial loss: 0.542835\n",
      "epoch 154; iter: 0; batch classifier loss: 0.418114; batch adversarial loss: 0.516300\n",
      "epoch 155; iter: 0; batch classifier loss: 0.394449; batch adversarial loss: 0.626205\n",
      "epoch 156; iter: 0; batch classifier loss: 0.339218; batch adversarial loss: 0.561623\n",
      "epoch 157; iter: 0; batch classifier loss: 0.273493; batch adversarial loss: 0.507582\n",
      "epoch 158; iter: 0; batch classifier loss: 0.353379; batch adversarial loss: 0.561604\n",
      "epoch 159; iter: 0; batch classifier loss: 0.332037; batch adversarial loss: 0.536484\n",
      "epoch 160; iter: 0; batch classifier loss: 0.413816; batch adversarial loss: 0.474149\n",
      "epoch 161; iter: 0; batch classifier loss: 0.332257; batch adversarial loss: 0.543486\n",
      "epoch 162; iter: 0; batch classifier loss: 0.363566; batch adversarial loss: 0.544958\n",
      "epoch 163; iter: 0; batch classifier loss: 0.411104; batch adversarial loss: 0.653979\n",
      "epoch 164; iter: 0; batch classifier loss: 0.412665; batch adversarial loss: 0.551767\n",
      "epoch 165; iter: 0; batch classifier loss: 0.345331; batch adversarial loss: 0.545308\n",
      "epoch 166; iter: 0; batch classifier loss: 0.313191; batch adversarial loss: 0.615968\n",
      "epoch 167; iter: 0; batch classifier loss: 0.363330; batch adversarial loss: 0.543973\n",
      "epoch 168; iter: 0; batch classifier loss: 0.384938; batch adversarial loss: 0.534606\n",
      "epoch 169; iter: 0; batch classifier loss: 0.270762; batch adversarial loss: 0.609229\n",
      "epoch 170; iter: 0; batch classifier loss: 0.257727; batch adversarial loss: 0.552786\n",
      "epoch 171; iter: 0; batch classifier loss: 0.245264; batch adversarial loss: 0.599358\n",
      "epoch 172; iter: 0; batch classifier loss: 0.418923; batch adversarial loss: 0.563865\n",
      "epoch 173; iter: 0; batch classifier loss: 0.381838; batch adversarial loss: 0.535275\n",
      "epoch 174; iter: 0; batch classifier loss: 0.375266; batch adversarial loss: 0.573380\n",
      "epoch 175; iter: 0; batch classifier loss: 0.335095; batch adversarial loss: 0.543903\n",
      "epoch 176; iter: 0; batch classifier loss: 0.377722; batch adversarial loss: 0.570961\n",
      "epoch 177; iter: 0; batch classifier loss: 0.247003; batch adversarial loss: 0.614439\n",
      "epoch 178; iter: 0; batch classifier loss: 0.372593; batch adversarial loss: 0.552703\n",
      "epoch 179; iter: 0; batch classifier loss: 0.343191; batch adversarial loss: 0.580072\n",
      "epoch 180; iter: 0; batch classifier loss: 0.260235; batch adversarial loss: 0.562119\n",
      "epoch 181; iter: 0; batch classifier loss: 0.410567; batch adversarial loss: 0.535959\n",
      "epoch 182; iter: 0; batch classifier loss: 0.335692; batch adversarial loss: 0.542852\n",
      "epoch 183; iter: 0; batch classifier loss: 0.423039; batch adversarial loss: 0.554914\n",
      "epoch 184; iter: 0; batch classifier loss: 0.357298; batch adversarial loss: 0.642952\n",
      "epoch 185; iter: 0; batch classifier loss: 0.325406; batch adversarial loss: 0.598154\n",
      "epoch 186; iter: 0; batch classifier loss: 0.457675; batch adversarial loss: 0.489731\n",
      "epoch 187; iter: 0; batch classifier loss: 0.379825; batch adversarial loss: 0.553116\n",
      "epoch 188; iter: 0; batch classifier loss: 0.335183; batch adversarial loss: 0.444013\n",
      "epoch 189; iter: 0; batch classifier loss: 0.301008; batch adversarial loss: 0.562391\n",
      "epoch 190; iter: 0; batch classifier loss: 0.391736; batch adversarial loss: 0.617099\n",
      "epoch 191; iter: 0; batch classifier loss: 0.313504; batch adversarial loss: 0.490900\n",
      "epoch 192; iter: 0; batch classifier loss: 0.330809; batch adversarial loss: 0.525704\n",
      "epoch 193; iter: 0; batch classifier loss: 0.400030; batch adversarial loss: 0.571366\n",
      "epoch 194; iter: 0; batch classifier loss: 0.286325; batch adversarial loss: 0.517456\n",
      "epoch 195; iter: 0; batch classifier loss: 0.343630; batch adversarial loss: 0.562422\n",
      "epoch 196; iter: 0; batch classifier loss: 0.334666; batch adversarial loss: 0.552876\n",
      "epoch 197; iter: 0; batch classifier loss: 0.318311; batch adversarial loss: 0.499945\n",
      "epoch 198; iter: 0; batch classifier loss: 0.372382; batch adversarial loss: 0.588625\n",
      "epoch 199; iter: 0; batch classifier loss: 0.385876; batch adversarial loss: 0.634022\n",
      "epoch 0; iter: 0; batch classifier loss: 0.661467; batch adversarial loss: 1.012712\n",
      "epoch 1; iter: 0; batch classifier loss: 0.876165; batch adversarial loss: 1.403199\n",
      "epoch 2; iter: 0; batch classifier loss: 1.130770; batch adversarial loss: 1.502687\n",
      "epoch 3; iter: 0; batch classifier loss: 1.181510; batch adversarial loss: 1.425873\n",
      "epoch 4; iter: 0; batch classifier loss: 1.013915; batch adversarial loss: 1.259655\n",
      "epoch 5; iter: 0; batch classifier loss: 1.289560; batch adversarial loss: 1.159747\n",
      "epoch 6; iter: 0; batch classifier loss: 1.410909; batch adversarial loss: 1.114571\n",
      "epoch 7; iter: 0; batch classifier loss: 1.271487; batch adversarial loss: 0.998596\n",
      "epoch 8; iter: 0; batch classifier loss: 1.284361; batch adversarial loss: 0.933950\n",
      "epoch 9; iter: 0; batch classifier loss: 1.344803; batch adversarial loss: 0.896127\n",
      "epoch 10; iter: 0; batch classifier loss: 1.016880; batch adversarial loss: 0.779713\n",
      "epoch 11; iter: 0; batch classifier loss: 1.317041; batch adversarial loss: 0.777994\n",
      "epoch 12; iter: 0; batch classifier loss: 1.067842; batch adversarial loss: 0.719261\n",
      "epoch 13; iter: 0; batch classifier loss: 1.005859; batch adversarial loss: 0.706550\n",
      "epoch 14; iter: 0; batch classifier loss: 0.772580; batch adversarial loss: 0.657460\n",
      "epoch 15; iter: 0; batch classifier loss: 0.644276; batch adversarial loss: 0.629611\n",
      "epoch 16; iter: 0; batch classifier loss: 0.565420; batch adversarial loss: 0.647852\n",
      "epoch 17; iter: 0; batch classifier loss: 0.537305; batch adversarial loss: 0.612289\n",
      "epoch 18; iter: 0; batch classifier loss: 0.563456; batch adversarial loss: 0.568812\n",
      "epoch 19; iter: 0; batch classifier loss: 0.538418; batch adversarial loss: 0.614400\n",
      "epoch 20; iter: 0; batch classifier loss: 0.454665; batch adversarial loss: 0.587864\n",
      "epoch 21; iter: 0; batch classifier loss: 0.519061; batch adversarial loss: 0.513639\n",
      "epoch 22; iter: 0; batch classifier loss: 0.496929; batch adversarial loss: 0.541558\n",
      "epoch 23; iter: 0; batch classifier loss: 0.484780; batch adversarial loss: 0.510663\n",
      "epoch 24; iter: 0; batch classifier loss: 0.492141; batch adversarial loss: 0.566003\n",
      "epoch 25; iter: 0; batch classifier loss: 0.409360; batch adversarial loss: 0.579942\n",
      "epoch 26; iter: 0; batch classifier loss: 0.455034; batch adversarial loss: 0.538306\n",
      "epoch 27; iter: 0; batch classifier loss: 0.484464; batch adversarial loss: 0.543484\n",
      "epoch 28; iter: 0; batch classifier loss: 0.463493; batch adversarial loss: 0.576425\n",
      "epoch 29; iter: 0; batch classifier loss: 0.481781; batch adversarial loss: 0.576879\n",
      "epoch 30; iter: 0; batch classifier loss: 0.434418; batch adversarial loss: 0.549723\n",
      "epoch 31; iter: 0; batch classifier loss: 0.401279; batch adversarial loss: 0.557749\n",
      "epoch 32; iter: 0; batch classifier loss: 0.410416; batch adversarial loss: 0.574038\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 33; iter: 0; batch classifier loss: 0.506851; batch adversarial loss: 0.588842\n",
      "epoch 34; iter: 0; batch classifier loss: 0.461275; batch adversarial loss: 0.549520\n",
      "epoch 35; iter: 0; batch classifier loss: 0.379672; batch adversarial loss: 0.618345\n",
      "epoch 36; iter: 0; batch classifier loss: 0.438357; batch adversarial loss: 0.534053\n",
      "epoch 37; iter: 0; batch classifier loss: 0.461106; batch adversarial loss: 0.572784\n",
      "epoch 38; iter: 0; batch classifier loss: 0.460338; batch adversarial loss: 0.506630\n",
      "epoch 39; iter: 0; batch classifier loss: 0.399985; batch adversarial loss: 0.550047\n",
      "epoch 40; iter: 0; batch classifier loss: 0.483512; batch adversarial loss: 0.543230\n",
      "epoch 41; iter: 0; batch classifier loss: 0.458749; batch adversarial loss: 0.622222\n",
      "epoch 42; iter: 0; batch classifier loss: 0.326897; batch adversarial loss: 0.557433\n",
      "epoch 43; iter: 0; batch classifier loss: 0.347504; batch adversarial loss: 0.561351\n",
      "epoch 44; iter: 0; batch classifier loss: 0.399952; batch adversarial loss: 0.554366\n",
      "epoch 45; iter: 0; batch classifier loss: 0.371661; batch adversarial loss: 0.564717\n",
      "epoch 46; iter: 0; batch classifier loss: 0.427402; batch adversarial loss: 0.509583\n",
      "epoch 47; iter: 0; batch classifier loss: 0.376197; batch adversarial loss: 0.503034\n",
      "epoch 48; iter: 0; batch classifier loss: 0.451598; batch adversarial loss: 0.537005\n",
      "epoch 49; iter: 0; batch classifier loss: 0.435634; batch adversarial loss: 0.546204\n",
      "epoch 50; iter: 0; batch classifier loss: 0.413422; batch adversarial loss: 0.503493\n",
      "epoch 51; iter: 0; batch classifier loss: 0.408806; batch adversarial loss: 0.488823\n",
      "epoch 52; iter: 0; batch classifier loss: 0.399375; batch adversarial loss: 0.533754\n",
      "epoch 53; iter: 0; batch classifier loss: 0.416805; batch adversarial loss: 0.527486\n",
      "epoch 54; iter: 0; batch classifier loss: 0.411473; batch adversarial loss: 0.545131\n",
      "epoch 55; iter: 0; batch classifier loss: 0.421055; batch adversarial loss: 0.563712\n",
      "epoch 56; iter: 0; batch classifier loss: 0.412614; batch adversarial loss: 0.590465\n",
      "epoch 57; iter: 0; batch classifier loss: 0.459384; batch adversarial loss: 0.564953\n",
      "epoch 58; iter: 0; batch classifier loss: 0.423241; batch adversarial loss: 0.579284\n",
      "epoch 59; iter: 0; batch classifier loss: 0.379205; batch adversarial loss: 0.528481\n",
      "epoch 60; iter: 0; batch classifier loss: 0.384708; batch adversarial loss: 0.562877\n",
      "epoch 61; iter: 0; batch classifier loss: 0.376096; batch adversarial loss: 0.535743\n",
      "epoch 62; iter: 0; batch classifier loss: 0.391604; batch adversarial loss: 0.561582\n",
      "epoch 63; iter: 0; batch classifier loss: 0.402913; batch adversarial loss: 0.518387\n",
      "epoch 64; iter: 0; batch classifier loss: 0.462176; batch adversarial loss: 0.571689\n",
      "epoch 65; iter: 0; batch classifier loss: 0.409106; batch adversarial loss: 0.543706\n",
      "epoch 66; iter: 0; batch classifier loss: 0.392898; batch adversarial loss: 0.518503\n",
      "epoch 67; iter: 0; batch classifier loss: 0.377178; batch adversarial loss: 0.616959\n",
      "epoch 68; iter: 0; batch classifier loss: 0.354913; batch adversarial loss: 0.536736\n",
      "epoch 69; iter: 0; batch classifier loss: 0.353982; batch adversarial loss: 0.562953\n",
      "epoch 70; iter: 0; batch classifier loss: 0.354196; batch adversarial loss: 0.553986\n",
      "epoch 71; iter: 0; batch classifier loss: 0.436552; batch adversarial loss: 0.544157\n",
      "epoch 72; iter: 0; batch classifier loss: 0.325942; batch adversarial loss: 0.526189\n",
      "epoch 73; iter: 0; batch classifier loss: 0.383395; batch adversarial loss: 0.625242\n",
      "epoch 74; iter: 0; batch classifier loss: 0.449517; batch adversarial loss: 0.570810\n",
      "epoch 75; iter: 0; batch classifier loss: 0.353745; batch adversarial loss: 0.536055\n",
      "epoch 76; iter: 0; batch classifier loss: 0.410922; batch adversarial loss: 0.606679\n",
      "epoch 77; iter: 0; batch classifier loss: 0.371259; batch adversarial loss: 0.552676\n",
      "epoch 78; iter: 0; batch classifier loss: 0.360921; batch adversarial loss: 0.571563\n",
      "epoch 79; iter: 0; batch classifier loss: 0.425037; batch adversarial loss: 0.562504\n",
      "epoch 80; iter: 0; batch classifier loss: 0.363939; batch adversarial loss: 0.526777\n",
      "epoch 81; iter: 0; batch classifier loss: 0.407813; batch adversarial loss: 0.510028\n",
      "epoch 82; iter: 0; batch classifier loss: 0.382381; batch adversarial loss: 0.554416\n",
      "epoch 83; iter: 0; batch classifier loss: 0.395091; batch adversarial loss: 0.501187\n",
      "epoch 84; iter: 0; batch classifier loss: 0.417005; batch adversarial loss: 0.543348\n",
      "epoch 85; iter: 0; batch classifier loss: 0.407351; batch adversarial loss: 0.544928\n",
      "epoch 86; iter: 0; batch classifier loss: 0.406905; batch adversarial loss: 0.579214\n",
      "epoch 87; iter: 0; batch classifier loss: 0.395991; batch adversarial loss: 0.579761\n",
      "epoch 88; iter: 0; batch classifier loss: 0.319153; batch adversarial loss: 0.545558\n",
      "epoch 89; iter: 0; batch classifier loss: 0.339776; batch adversarial loss: 0.526196\n",
      "epoch 90; iter: 0; batch classifier loss: 0.404833; batch adversarial loss: 0.598768\n",
      "epoch 91; iter: 0; batch classifier loss: 0.326084; batch adversarial loss: 0.579091\n",
      "epoch 92; iter: 0; batch classifier loss: 0.368435; batch adversarial loss: 0.533204\n",
      "epoch 93; iter: 0; batch classifier loss: 0.342229; batch adversarial loss: 0.545219\n",
      "epoch 94; iter: 0; batch classifier loss: 0.371570; batch adversarial loss: 0.517943\n",
      "epoch 95; iter: 0; batch classifier loss: 0.382859; batch adversarial loss: 0.589980\n",
      "epoch 96; iter: 0; batch classifier loss: 0.384433; batch adversarial loss: 0.546665\n",
      "epoch 97; iter: 0; batch classifier loss: 0.362750; batch adversarial loss: 0.598195\n",
      "epoch 98; iter: 0; batch classifier loss: 0.281878; batch adversarial loss: 0.649908\n",
      "epoch 99; iter: 0; batch classifier loss: 0.417410; batch adversarial loss: 0.569964\n",
      "epoch 100; iter: 0; batch classifier loss: 0.384263; batch adversarial loss: 0.617612\n",
      "epoch 101; iter: 0; batch classifier loss: 0.324964; batch adversarial loss: 0.526836\n",
      "epoch 102; iter: 0; batch classifier loss: 0.416411; batch adversarial loss: 0.562003\n",
      "epoch 103; iter: 0; batch classifier loss: 0.432781; batch adversarial loss: 0.526970\n",
      "epoch 104; iter: 0; batch classifier loss: 0.392240; batch adversarial loss: 0.617270\n",
      "epoch 105; iter: 0; batch classifier loss: 0.402238; batch adversarial loss: 0.552780\n",
      "epoch 106; iter: 0; batch classifier loss: 0.320109; batch adversarial loss: 0.472962\n",
      "epoch 107; iter: 0; batch classifier loss: 0.430725; batch adversarial loss: 0.536080\n",
      "epoch 108; iter: 0; batch classifier loss: 0.384978; batch adversarial loss: 0.509068\n",
      "epoch 109; iter: 0; batch classifier loss: 0.350576; batch adversarial loss: 0.543642\n",
      "epoch 110; iter: 0; batch classifier loss: 0.352656; batch adversarial loss: 0.516733\n",
      "epoch 111; iter: 0; batch classifier loss: 0.413691; batch adversarial loss: 0.480215\n",
      "epoch 112; iter: 0; batch classifier loss: 0.370068; batch adversarial loss: 0.571010\n",
      "epoch 113; iter: 0; batch classifier loss: 0.377765; batch adversarial loss: 0.534769\n",
      "epoch 114; iter: 0; batch classifier loss: 0.342213; batch adversarial loss: 0.572306\n",
      "epoch 115; iter: 0; batch classifier loss: 0.292646; batch adversarial loss: 0.482731\n",
      "epoch 116; iter: 0; batch classifier loss: 0.295396; batch adversarial loss: 0.579531\n",
      "epoch 117; iter: 0; batch classifier loss: 0.304591; batch adversarial loss: 0.528225\n",
      "epoch 118; iter: 0; batch classifier loss: 0.328730; batch adversarial loss: 0.632325\n",
      "epoch 119; iter: 0; batch classifier loss: 0.352435; batch adversarial loss: 0.579620\n",
      "epoch 120; iter: 0; batch classifier loss: 0.328059; batch adversarial loss: 0.600690\n",
      "epoch 121; iter: 0; batch classifier loss: 0.305545; batch adversarial loss: 0.453715\n",
      "epoch 122; iter: 0; batch classifier loss: 0.352091; batch adversarial loss: 0.535257\n",
      "epoch 123; iter: 0; batch classifier loss: 0.237753; batch adversarial loss: 0.544447\n",
      "epoch 124; iter: 0; batch classifier loss: 0.323104; batch adversarial loss: 0.528129\n",
      "epoch 125; iter: 0; batch classifier loss: 0.344643; batch adversarial loss: 0.598951\n",
      "epoch 126; iter: 0; batch classifier loss: 0.334811; batch adversarial loss: 0.560091\n",
      "epoch 127; iter: 0; batch classifier loss: 0.322911; batch adversarial loss: 0.525573\n",
      "epoch 128; iter: 0; batch classifier loss: 0.234563; batch adversarial loss: 0.661537\n",
      "epoch 129; iter: 0; batch classifier loss: 0.324104; batch adversarial loss: 0.591292\n",
      "epoch 130; iter: 0; batch classifier loss: 0.321164; batch adversarial loss: 0.596880\n",
      "epoch 131; iter: 0; batch classifier loss: 0.328695; batch adversarial loss: 0.533347\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 132; iter: 0; batch classifier loss: 0.369105; batch adversarial loss: 0.555071\n",
      "epoch 133; iter: 0; batch classifier loss: 0.338211; batch adversarial loss: 0.540020\n",
      "epoch 134; iter: 0; batch classifier loss: 0.320246; batch adversarial loss: 0.561309\n",
      "epoch 135; iter: 0; batch classifier loss: 0.352814; batch adversarial loss: 0.598927\n",
      "epoch 136; iter: 0; batch classifier loss: 0.309844; batch adversarial loss: 0.593270\n",
      "epoch 137; iter: 0; batch classifier loss: 0.356357; batch adversarial loss: 0.451016\n",
      "epoch 138; iter: 0; batch classifier loss: 0.379720; batch adversarial loss: 0.572984\n",
      "epoch 139; iter: 0; batch classifier loss: 0.372844; batch adversarial loss: 0.472839\n",
      "epoch 140; iter: 0; batch classifier loss: 0.334598; batch adversarial loss: 0.507636\n",
      "epoch 141; iter: 0; batch classifier loss: 0.348791; batch adversarial loss: 0.591316\n",
      "epoch 142; iter: 0; batch classifier loss: 0.284667; batch adversarial loss: 0.540455\n",
      "epoch 143; iter: 0; batch classifier loss: 0.325894; batch adversarial loss: 0.596180\n",
      "epoch 144; iter: 0; batch classifier loss: 0.346242; batch adversarial loss: 0.496798\n",
      "epoch 145; iter: 0; batch classifier loss: 0.334496; batch adversarial loss: 0.573519\n",
      "epoch 146; iter: 0; batch classifier loss: 0.319511; batch adversarial loss: 0.481691\n",
      "epoch 147; iter: 0; batch classifier loss: 0.289415; batch adversarial loss: 0.654610\n",
      "epoch 148; iter: 0; batch classifier loss: 0.293013; batch adversarial loss: 0.527088\n",
      "epoch 149; iter: 0; batch classifier loss: 0.338590; batch adversarial loss: 0.508990\n",
      "epoch 150; iter: 0; batch classifier loss: 0.307346; batch adversarial loss: 0.553312\n",
      "epoch 151; iter: 0; batch classifier loss: 0.275431; batch adversarial loss: 0.543955\n",
      "epoch 152; iter: 0; batch classifier loss: 0.336122; batch adversarial loss: 0.545878\n",
      "epoch 153; iter: 0; batch classifier loss: 0.321140; batch adversarial loss: 0.691320\n",
      "epoch 154; iter: 0; batch classifier loss: 0.359631; batch adversarial loss: 0.520131\n",
      "epoch 155; iter: 0; batch classifier loss: 0.343442; batch adversarial loss: 0.598341\n",
      "epoch 156; iter: 0; batch classifier loss: 0.305240; batch adversarial loss: 0.479969\n",
      "epoch 157; iter: 0; batch classifier loss: 0.385555; batch adversarial loss: 0.551880\n",
      "epoch 158; iter: 0; batch classifier loss: 0.325991; batch adversarial loss: 0.543340\n",
      "epoch 159; iter: 0; batch classifier loss: 0.274315; batch adversarial loss: 0.525766\n",
      "epoch 160; iter: 0; batch classifier loss: 0.355171; batch adversarial loss: 0.482002\n",
      "epoch 161; iter: 0; batch classifier loss: 0.412749; batch adversarial loss: 0.497412\n",
      "epoch 162; iter: 0; batch classifier loss: 0.349887; batch adversarial loss: 0.482463\n",
      "epoch 163; iter: 0; batch classifier loss: 0.351793; batch adversarial loss: 0.551727\n",
      "epoch 164; iter: 0; batch classifier loss: 0.322956; batch adversarial loss: 0.536191\n",
      "epoch 165; iter: 0; batch classifier loss: 0.417912; batch adversarial loss: 0.506673\n",
      "epoch 166; iter: 0; batch classifier loss: 0.314689; batch adversarial loss: 0.598763\n",
      "epoch 167; iter: 0; batch classifier loss: 0.430116; batch adversarial loss: 0.542308\n",
      "epoch 168; iter: 0; batch classifier loss: 0.330062; batch adversarial loss: 0.566104\n",
      "epoch 169; iter: 0; batch classifier loss: 0.394116; batch adversarial loss: 0.500306\n",
      "epoch 170; iter: 0; batch classifier loss: 0.340349; batch adversarial loss: 0.559722\n",
      "epoch 171; iter: 0; batch classifier loss: 0.382983; batch adversarial loss: 0.570301\n",
      "epoch 172; iter: 0; batch classifier loss: 0.331673; batch adversarial loss: 0.470478\n",
      "epoch 173; iter: 0; batch classifier loss: 0.392308; batch adversarial loss: 0.607091\n",
      "epoch 174; iter: 0; batch classifier loss: 0.322168; batch adversarial loss: 0.526446\n",
      "epoch 175; iter: 0; batch classifier loss: 0.239158; batch adversarial loss: 0.555789\n",
      "epoch 176; iter: 0; batch classifier loss: 0.349698; batch adversarial loss: 0.580700\n",
      "epoch 177; iter: 0; batch classifier loss: 0.329332; batch adversarial loss: 0.521743\n",
      "epoch 178; iter: 0; batch classifier loss: 0.369796; batch adversarial loss: 0.595162\n",
      "epoch 179; iter: 0; batch classifier loss: 0.317720; batch adversarial loss: 0.524640\n",
      "epoch 180; iter: 0; batch classifier loss: 0.262396; batch adversarial loss: 0.500985\n",
      "epoch 181; iter: 0; batch classifier loss: 0.298843; batch adversarial loss: 0.534418\n",
      "epoch 182; iter: 0; batch classifier loss: 0.329589; batch adversarial loss: 0.515038\n",
      "epoch 183; iter: 0; batch classifier loss: 0.337114; batch adversarial loss: 0.516784\n",
      "epoch 184; iter: 0; batch classifier loss: 0.336420; batch adversarial loss: 0.545432\n",
      "epoch 185; iter: 0; batch classifier loss: 0.273443; batch adversarial loss: 0.518029\n",
      "epoch 186; iter: 0; batch classifier loss: 0.362501; batch adversarial loss: 0.607436\n",
      "epoch 187; iter: 0; batch classifier loss: 0.306904; batch adversarial loss: 0.542401\n",
      "epoch 188; iter: 0; batch classifier loss: 0.329703; batch adversarial loss: 0.556618\n",
      "epoch 189; iter: 0; batch classifier loss: 0.339293; batch adversarial loss: 0.544314\n",
      "epoch 190; iter: 0; batch classifier loss: 0.398537; batch adversarial loss: 0.544607\n",
      "epoch 191; iter: 0; batch classifier loss: 0.290694; batch adversarial loss: 0.590146\n",
      "epoch 192; iter: 0; batch classifier loss: 0.304652; batch adversarial loss: 0.645000\n",
      "epoch 193; iter: 0; batch classifier loss: 0.366568; batch adversarial loss: 0.544971\n",
      "epoch 194; iter: 0; batch classifier loss: 0.375659; batch adversarial loss: 0.608938\n",
      "epoch 195; iter: 0; batch classifier loss: 0.284811; batch adversarial loss: 0.535187\n",
      "epoch 196; iter: 0; batch classifier loss: 0.331262; batch adversarial loss: 0.623924\n",
      "epoch 197; iter: 0; batch classifier loss: 0.356105; batch adversarial loss: 0.622216\n",
      "epoch 198; iter: 0; batch classifier loss: 0.311739; batch adversarial loss: 0.490048\n",
      "epoch 199; iter: 0; batch classifier loss: 0.332697; batch adversarial loss: 0.524901\n",
      "epoch 0; iter: 0; batch classifier loss: 0.716544; batch adversarial loss: 0.632806\n",
      "epoch 1; iter: 0; batch classifier loss: 0.556770; batch adversarial loss: 0.655866\n",
      "epoch 2; iter: 0; batch classifier loss: 0.493532; batch adversarial loss: 0.641658\n",
      "epoch 3; iter: 0; batch classifier loss: 0.512008; batch adversarial loss: 0.633265\n",
      "epoch 4; iter: 0; batch classifier loss: 0.517729; batch adversarial loss: 0.641814\n",
      "epoch 5; iter: 0; batch classifier loss: 0.587053; batch adversarial loss: 0.641981\n",
      "epoch 6; iter: 0; batch classifier loss: 0.618097; batch adversarial loss: 0.617207\n",
      "epoch 7; iter: 0; batch classifier loss: 0.674954; batch adversarial loss: 0.590888\n",
      "epoch 8; iter: 0; batch classifier loss: 0.561829; batch adversarial loss: 0.591761\n",
      "epoch 9; iter: 0; batch classifier loss: 0.517802; batch adversarial loss: 0.625833\n",
      "epoch 10; iter: 0; batch classifier loss: 0.580773; batch adversarial loss: 0.592857\n",
      "epoch 11; iter: 0; batch classifier loss: 0.579926; batch adversarial loss: 0.609477\n",
      "epoch 12; iter: 0; batch classifier loss: 0.490855; batch adversarial loss: 0.582505\n",
      "epoch 13; iter: 0; batch classifier loss: 0.575956; batch adversarial loss: 0.558547\n",
      "epoch 14; iter: 0; batch classifier loss: 0.545899; batch adversarial loss: 0.537090\n",
      "epoch 15; iter: 0; batch classifier loss: 0.554419; batch adversarial loss: 0.570731\n",
      "epoch 16; iter: 0; batch classifier loss: 0.520152; batch adversarial loss: 0.565224\n",
      "epoch 17; iter: 0; batch classifier loss: 0.524734; batch adversarial loss: 0.582087\n",
      "epoch 18; iter: 0; batch classifier loss: 0.493211; batch adversarial loss: 0.616128\n",
      "epoch 19; iter: 0; batch classifier loss: 0.487574; batch adversarial loss: 0.565640\n",
      "epoch 20; iter: 0; batch classifier loss: 0.480306; batch adversarial loss: 0.587852\n",
      "epoch 21; iter: 0; batch classifier loss: 0.454750; batch adversarial loss: 0.565398\n",
      "epoch 22; iter: 0; batch classifier loss: 0.500493; batch adversarial loss: 0.533038\n",
      "epoch 23; iter: 0; batch classifier loss: 0.507226; batch adversarial loss: 0.579236\n",
      "epoch 24; iter: 0; batch classifier loss: 0.459055; batch adversarial loss: 0.566226\n",
      "epoch 25; iter: 0; batch classifier loss: 0.474086; batch adversarial loss: 0.596128\n",
      "epoch 26; iter: 0; batch classifier loss: 0.466736; batch adversarial loss: 0.530245\n",
      "epoch 27; iter: 0; batch classifier loss: 0.566487; batch adversarial loss: 0.563217\n",
      "epoch 28; iter: 0; batch classifier loss: 0.490673; batch adversarial loss: 0.595870\n",
      "epoch 29; iter: 0; batch classifier loss: 0.489565; batch adversarial loss: 0.487011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30; iter: 0; batch classifier loss: 0.414175; batch adversarial loss: 0.528303\n",
      "epoch 31; iter: 0; batch classifier loss: 0.397780; batch adversarial loss: 0.528231\n",
      "epoch 32; iter: 0; batch classifier loss: 0.473671; batch adversarial loss: 0.572192\n",
      "epoch 33; iter: 0; batch classifier loss: 0.386234; batch adversarial loss: 0.554573\n",
      "epoch 34; iter: 0; batch classifier loss: 0.470937; batch adversarial loss: 0.554356\n",
      "epoch 35; iter: 0; batch classifier loss: 0.493022; batch adversarial loss: 0.571315\n",
      "epoch 36; iter: 0; batch classifier loss: 0.351026; batch adversarial loss: 0.536087\n",
      "epoch 37; iter: 0; batch classifier loss: 0.511711; batch adversarial loss: 0.552559\n",
      "epoch 38; iter: 0; batch classifier loss: 0.450199; batch adversarial loss: 0.535969\n",
      "epoch 39; iter: 0; batch classifier loss: 0.424053; batch adversarial loss: 0.495206\n",
      "epoch 40; iter: 0; batch classifier loss: 0.492299; batch adversarial loss: 0.526995\n",
      "epoch 41; iter: 0; batch classifier loss: 0.438199; batch adversarial loss: 0.633322\n",
      "epoch 42; iter: 0; batch classifier loss: 0.459171; batch adversarial loss: 0.554735\n",
      "epoch 43; iter: 0; batch classifier loss: 0.517959; batch adversarial loss: 0.529748\n",
      "epoch 44; iter: 0; batch classifier loss: 0.420763; batch adversarial loss: 0.589664\n",
      "epoch 45; iter: 0; batch classifier loss: 0.465822; batch adversarial loss: 0.588524\n",
      "epoch 46; iter: 0; batch classifier loss: 0.456858; batch adversarial loss: 0.579206\n",
      "epoch 47; iter: 0; batch classifier loss: 0.397977; batch adversarial loss: 0.606609\n",
      "epoch 48; iter: 0; batch classifier loss: 0.452616; batch adversarial loss: 0.551376\n",
      "epoch 49; iter: 0; batch classifier loss: 0.445572; batch adversarial loss: 0.554204\n",
      "epoch 50; iter: 0; batch classifier loss: 0.421567; batch adversarial loss: 0.501015\n",
      "epoch 51; iter: 0; batch classifier loss: 0.437669; batch adversarial loss: 0.588928\n",
      "epoch 52; iter: 0; batch classifier loss: 0.464658; batch adversarial loss: 0.562976\n",
      "epoch 53; iter: 0; batch classifier loss: 0.421355; batch adversarial loss: 0.625851\n",
      "epoch 54; iter: 0; batch classifier loss: 0.451247; batch adversarial loss: 0.549725\n",
      "epoch 55; iter: 0; batch classifier loss: 0.392783; batch adversarial loss: 0.554867\n",
      "epoch 56; iter: 0; batch classifier loss: 0.405775; batch adversarial loss: 0.572235\n",
      "epoch 57; iter: 0; batch classifier loss: 0.409428; batch adversarial loss: 0.606297\n",
      "epoch 58; iter: 0; batch classifier loss: 0.445376; batch adversarial loss: 0.571090\n",
      "epoch 59; iter: 0; batch classifier loss: 0.421208; batch adversarial loss: 0.568047\n",
      "epoch 60; iter: 0; batch classifier loss: 0.370169; batch adversarial loss: 0.552522\n",
      "epoch 61; iter: 0; batch classifier loss: 0.342386; batch adversarial loss: 0.546767\n",
      "epoch 62; iter: 0; batch classifier loss: 0.353348; batch adversarial loss: 0.511111\n",
      "epoch 63; iter: 0; batch classifier loss: 0.427919; batch adversarial loss: 0.517765\n",
      "epoch 64; iter: 0; batch classifier loss: 0.435943; batch adversarial loss: 0.497693\n",
      "epoch 65; iter: 0; batch classifier loss: 0.468200; batch adversarial loss: 0.532767\n",
      "epoch 66; iter: 0; batch classifier loss: 0.392972; batch adversarial loss: 0.569157\n",
      "epoch 67; iter: 0; batch classifier loss: 0.376627; batch adversarial loss: 0.556595\n",
      "epoch 68; iter: 0; batch classifier loss: 0.394044; batch adversarial loss: 0.553567\n",
      "epoch 69; iter: 0; batch classifier loss: 0.411558; batch adversarial loss: 0.649255\n",
      "epoch 70; iter: 0; batch classifier loss: 0.406570; batch adversarial loss: 0.588971\n",
      "epoch 71; iter: 0; batch classifier loss: 0.435016; batch adversarial loss: 0.555732\n",
      "epoch 72; iter: 0; batch classifier loss: 0.386979; batch adversarial loss: 0.619488\n",
      "epoch 73; iter: 0; batch classifier loss: 0.415971; batch adversarial loss: 0.554301\n",
      "epoch 74; iter: 0; batch classifier loss: 0.404325; batch adversarial loss: 0.605115\n",
      "epoch 75; iter: 0; batch classifier loss: 0.327724; batch adversarial loss: 0.622182\n",
      "epoch 76; iter: 0; batch classifier loss: 0.428698; batch adversarial loss: 0.560165\n",
      "epoch 77; iter: 0; batch classifier loss: 0.434134; batch adversarial loss: 0.493328\n",
      "epoch 78; iter: 0; batch classifier loss: 0.469765; batch adversarial loss: 0.537357\n",
      "epoch 79; iter: 0; batch classifier loss: 0.362022; batch adversarial loss: 0.570526\n",
      "epoch 80; iter: 0; batch classifier loss: 0.477661; batch adversarial loss: 0.602248\n",
      "epoch 81; iter: 0; batch classifier loss: 0.406444; batch adversarial loss: 0.589816\n",
      "epoch 82; iter: 0; batch classifier loss: 0.374130; batch adversarial loss: 0.571751\n",
      "epoch 83; iter: 0; batch classifier loss: 0.403300; batch adversarial loss: 0.543519\n",
      "epoch 84; iter: 0; batch classifier loss: 0.422424; batch adversarial loss: 0.616620\n",
      "epoch 85; iter: 0; batch classifier loss: 0.415019; batch adversarial loss: 0.518460\n",
      "epoch 86; iter: 0; batch classifier loss: 0.378216; batch adversarial loss: 0.519622\n",
      "epoch 87; iter: 0; batch classifier loss: 0.403599; batch adversarial loss: 0.579514\n",
      "epoch 88; iter: 0; batch classifier loss: 0.334561; batch adversarial loss: 0.569117\n",
      "epoch 89; iter: 0; batch classifier loss: 0.425029; batch adversarial loss: 0.614482\n",
      "epoch 90; iter: 0; batch classifier loss: 0.383279; batch adversarial loss: 0.507686\n",
      "epoch 91; iter: 0; batch classifier loss: 0.302381; batch adversarial loss: 0.564935\n",
      "epoch 92; iter: 0; batch classifier loss: 0.433206; batch adversarial loss: 0.491893\n",
      "epoch 93; iter: 0; batch classifier loss: 0.439973; batch adversarial loss: 0.534354\n",
      "epoch 94; iter: 0; batch classifier loss: 0.403336; batch adversarial loss: 0.604355\n",
      "epoch 95; iter: 0; batch classifier loss: 0.414346; batch adversarial loss: 0.496232\n",
      "epoch 96; iter: 0; batch classifier loss: 0.400182; batch adversarial loss: 0.551983\n",
      "epoch 97; iter: 0; batch classifier loss: 0.467358; batch adversarial loss: 0.553216\n",
      "epoch 98; iter: 0; batch classifier loss: 0.432855; batch adversarial loss: 0.590730\n",
      "epoch 99; iter: 0; batch classifier loss: 0.404753; batch adversarial loss: 0.627422\n",
      "epoch 100; iter: 0; batch classifier loss: 0.322612; batch adversarial loss: 0.517610\n",
      "epoch 101; iter: 0; batch classifier loss: 0.328420; batch adversarial loss: 0.561097\n",
      "epoch 102; iter: 0; batch classifier loss: 0.393618; batch adversarial loss: 0.563435\n",
      "epoch 103; iter: 0; batch classifier loss: 0.404977; batch adversarial loss: 0.571079\n",
      "epoch 104; iter: 0; batch classifier loss: 0.394781; batch adversarial loss: 0.635175\n",
      "epoch 105; iter: 0; batch classifier loss: 0.399371; batch adversarial loss: 0.587700\n",
      "epoch 106; iter: 0; batch classifier loss: 0.399017; batch adversarial loss: 0.509738\n",
      "epoch 107; iter: 0; batch classifier loss: 0.407809; batch adversarial loss: 0.528251\n",
      "epoch 108; iter: 0; batch classifier loss: 0.338082; batch adversarial loss: 0.526451\n",
      "epoch 109; iter: 0; batch classifier loss: 0.425472; batch adversarial loss: 0.580004\n",
      "epoch 110; iter: 0; batch classifier loss: 0.349406; batch adversarial loss: 0.516828\n",
      "epoch 111; iter: 0; batch classifier loss: 0.438556; batch adversarial loss: 0.632477\n",
      "epoch 112; iter: 0; batch classifier loss: 0.325258; batch adversarial loss: 0.677498\n",
      "epoch 113; iter: 0; batch classifier loss: 0.313650; batch adversarial loss: 0.599799\n",
      "epoch 114; iter: 0; batch classifier loss: 0.336814; batch adversarial loss: 0.577145\n",
      "epoch 115; iter: 0; batch classifier loss: 0.462757; batch adversarial loss: 0.597554\n",
      "epoch 116; iter: 0; batch classifier loss: 0.447396; batch adversarial loss: 0.524520\n",
      "epoch 117; iter: 0; batch classifier loss: 0.384260; batch adversarial loss: 0.533294\n",
      "epoch 118; iter: 0; batch classifier loss: 0.301111; batch adversarial loss: 0.616154\n",
      "epoch 119; iter: 0; batch classifier loss: 0.390305; batch adversarial loss: 0.501593\n",
      "epoch 120; iter: 0; batch classifier loss: 0.413882; batch adversarial loss: 0.589153\n",
      "epoch 121; iter: 0; batch classifier loss: 0.379983; batch adversarial loss: 0.634079\n",
      "epoch 122; iter: 0; batch classifier loss: 0.385252; batch adversarial loss: 0.587836\n",
      "epoch 123; iter: 0; batch classifier loss: 0.430987; batch adversarial loss: 0.544471\n",
      "epoch 124; iter: 0; batch classifier loss: 0.366226; batch adversarial loss: 0.573203\n",
      "epoch 125; iter: 0; batch classifier loss: 0.348226; batch adversarial loss: 0.611915\n",
      "epoch 126; iter: 0; batch classifier loss: 0.385749; batch adversarial loss: 0.589255\n",
      "epoch 127; iter: 0; batch classifier loss: 0.385515; batch adversarial loss: 0.517718\n",
      "epoch 128; iter: 0; batch classifier loss: 0.346035; batch adversarial loss: 0.529146\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 129; iter: 0; batch classifier loss: 0.343550; batch adversarial loss: 0.570577\n",
      "epoch 130; iter: 0; batch classifier loss: 0.287205; batch adversarial loss: 0.602958\n",
      "epoch 131; iter: 0; batch classifier loss: 0.357423; batch adversarial loss: 0.544146\n",
      "epoch 132; iter: 0; batch classifier loss: 0.358627; batch adversarial loss: 0.544267\n",
      "epoch 133; iter: 0; batch classifier loss: 0.449783; batch adversarial loss: 0.471273\n",
      "epoch 134; iter: 0; batch classifier loss: 0.384356; batch adversarial loss: 0.657870\n",
      "epoch 135; iter: 0; batch classifier loss: 0.424391; batch adversarial loss: 0.472495\n",
      "epoch 136; iter: 0; batch classifier loss: 0.400106; batch adversarial loss: 0.497782\n",
      "epoch 137; iter: 0; batch classifier loss: 0.343834; batch adversarial loss: 0.569955\n",
      "epoch 138; iter: 0; batch classifier loss: 0.444022; batch adversarial loss: 0.580612\n",
      "epoch 139; iter: 0; batch classifier loss: 0.367157; batch adversarial loss: 0.551884\n",
      "epoch 140; iter: 0; batch classifier loss: 0.337597; batch adversarial loss: 0.575988\n",
      "epoch 141; iter: 0; batch classifier loss: 0.378019; batch adversarial loss: 0.575990\n",
      "epoch 142; iter: 0; batch classifier loss: 0.320395; batch adversarial loss: 0.541034\n",
      "epoch 143; iter: 0; batch classifier loss: 0.404150; batch adversarial loss: 0.634138\n",
      "epoch 144; iter: 0; batch classifier loss: 0.389306; batch adversarial loss: 0.568129\n",
      "epoch 145; iter: 0; batch classifier loss: 0.297516; batch adversarial loss: 0.448052\n",
      "epoch 146; iter: 0; batch classifier loss: 0.382608; batch adversarial loss: 0.473860\n",
      "epoch 147; iter: 0; batch classifier loss: 0.362862; batch adversarial loss: 0.513831\n",
      "epoch 148; iter: 0; batch classifier loss: 0.379573; batch adversarial loss: 0.545502\n",
      "epoch 149; iter: 0; batch classifier loss: 0.407473; batch adversarial loss: 0.508246\n",
      "epoch 150; iter: 0; batch classifier loss: 0.410578; batch adversarial loss: 0.599467\n",
      "epoch 151; iter: 0; batch classifier loss: 0.230244; batch adversarial loss: 0.509328\n",
      "epoch 152; iter: 0; batch classifier loss: 0.352999; batch adversarial loss: 0.544402\n",
      "epoch 153; iter: 0; batch classifier loss: 0.396470; batch adversarial loss: 0.562097\n",
      "epoch 154; iter: 0; batch classifier loss: 0.250894; batch adversarial loss: 0.508291\n",
      "epoch 155; iter: 0; batch classifier loss: 0.347278; batch adversarial loss: 0.499441\n",
      "epoch 156; iter: 0; batch classifier loss: 0.339569; batch adversarial loss: 0.636209\n",
      "epoch 157; iter: 0; batch classifier loss: 0.380824; batch adversarial loss: 0.561415\n",
      "epoch 158; iter: 0; batch classifier loss: 0.397358; batch adversarial loss: 0.559264\n",
      "epoch 159; iter: 0; batch classifier loss: 0.396553; batch adversarial loss: 0.542130\n",
      "epoch 160; iter: 0; batch classifier loss: 0.319177; batch adversarial loss: 0.484058\n",
      "epoch 161; iter: 0; batch classifier loss: 0.363784; batch adversarial loss: 0.542864\n",
      "epoch 162; iter: 0; batch classifier loss: 0.357604; batch adversarial loss: 0.563395\n",
      "epoch 163; iter: 0; batch classifier loss: 0.388598; batch adversarial loss: 0.572133\n",
      "epoch 164; iter: 0; batch classifier loss: 0.360999; batch adversarial loss: 0.612569\n",
      "epoch 165; iter: 0; batch classifier loss: 0.420470; batch adversarial loss: 0.536988\n",
      "epoch 166; iter: 0; batch classifier loss: 0.373090; batch adversarial loss: 0.570187\n",
      "epoch 167; iter: 0; batch classifier loss: 0.335512; batch adversarial loss: 0.570938\n",
      "epoch 168; iter: 0; batch classifier loss: 0.351407; batch adversarial loss: 0.570609\n",
      "epoch 169; iter: 0; batch classifier loss: 0.305898; batch adversarial loss: 0.635002\n",
      "epoch 170; iter: 0; batch classifier loss: 0.266056; batch adversarial loss: 0.582264\n",
      "epoch 171; iter: 0; batch classifier loss: 0.372360; batch adversarial loss: 0.631716\n",
      "epoch 172; iter: 0; batch classifier loss: 0.330688; batch adversarial loss: 0.546411\n",
      "epoch 173; iter: 0; batch classifier loss: 0.414736; batch adversarial loss: 0.554886\n",
      "epoch 174; iter: 0; batch classifier loss: 0.406918; batch adversarial loss: 0.593510\n",
      "epoch 175; iter: 0; batch classifier loss: 0.343708; batch adversarial loss: 0.513022\n",
      "epoch 176; iter: 0; batch classifier loss: 0.458876; batch adversarial loss: 0.527033\n",
      "epoch 177; iter: 0; batch classifier loss: 0.363641; batch adversarial loss: 0.504871\n",
      "epoch 178; iter: 0; batch classifier loss: 0.390191; batch adversarial loss: 0.543405\n",
      "epoch 179; iter: 0; batch classifier loss: 0.369315; batch adversarial loss: 0.560977\n",
      "epoch 180; iter: 0; batch classifier loss: 0.337020; batch adversarial loss: 0.616503\n",
      "epoch 181; iter: 0; batch classifier loss: 0.320261; batch adversarial loss: 0.589381\n",
      "epoch 182; iter: 0; batch classifier loss: 0.297261; batch adversarial loss: 0.501470\n",
      "epoch 183; iter: 0; batch classifier loss: 0.438693; batch adversarial loss: 0.533864\n",
      "epoch 184; iter: 0; batch classifier loss: 0.354984; batch adversarial loss: 0.586590\n",
      "epoch 185; iter: 0; batch classifier loss: 0.356564; batch adversarial loss: 0.562325\n",
      "epoch 186; iter: 0; batch classifier loss: 0.298212; batch adversarial loss: 0.498753\n",
      "epoch 187; iter: 0; batch classifier loss: 0.326048; batch adversarial loss: 0.437989\n",
      "epoch 188; iter: 0; batch classifier loss: 0.360104; batch adversarial loss: 0.557486\n",
      "epoch 189; iter: 0; batch classifier loss: 0.348360; batch adversarial loss: 0.614015\n",
      "epoch 190; iter: 0; batch classifier loss: 0.416376; batch adversarial loss: 0.607727\n",
      "epoch 191; iter: 0; batch classifier loss: 0.334125; batch adversarial loss: 0.455797\n",
      "epoch 192; iter: 0; batch classifier loss: 0.329857; batch adversarial loss: 0.577046\n",
      "epoch 193; iter: 0; batch classifier loss: 0.364971; batch adversarial loss: 0.572147\n",
      "epoch 194; iter: 0; batch classifier loss: 0.288367; batch adversarial loss: 0.577216\n",
      "epoch 195; iter: 0; batch classifier loss: 0.375284; batch adversarial loss: 0.570946\n",
      "epoch 196; iter: 0; batch classifier loss: 0.364934; batch adversarial loss: 0.570817\n",
      "epoch 197; iter: 0; batch classifier loss: 0.405666; batch adversarial loss: 0.545143\n",
      "epoch 198; iter: 0; batch classifier loss: 0.317326; batch adversarial loss: 0.561449\n",
      "epoch 199; iter: 0; batch classifier loss: 0.402026; batch adversarial loss: 0.515344\n",
      "epoch 0; iter: 0; batch classifier loss: 0.721404; batch adversarial loss: 0.779639\n",
      "epoch 1; iter: 0; batch classifier loss: 0.790255; batch adversarial loss: 0.814693\n",
      "epoch 2; iter: 0; batch classifier loss: 0.841897; batch adversarial loss: 0.761819\n",
      "epoch 3; iter: 0; batch classifier loss: 0.847852; batch adversarial loss: 0.698765\n",
      "epoch 4; iter: 0; batch classifier loss: 0.650953; batch adversarial loss: 0.652925\n",
      "epoch 5; iter: 0; batch classifier loss: 0.616795; batch adversarial loss: 0.632824\n",
      "epoch 6; iter: 0; batch classifier loss: 0.564151; batch adversarial loss: 0.615210\n",
      "epoch 7; iter: 0; batch classifier loss: 0.557072; batch adversarial loss: 0.587302\n",
      "epoch 8; iter: 0; batch classifier loss: 0.538631; batch adversarial loss: 0.634885\n",
      "epoch 9; iter: 0; batch classifier loss: 0.581466; batch adversarial loss: 0.590650\n",
      "epoch 10; iter: 0; batch classifier loss: 0.481218; batch adversarial loss: 0.586625\n",
      "epoch 11; iter: 0; batch classifier loss: 0.613769; batch adversarial loss: 0.589865\n",
      "epoch 12; iter: 0; batch classifier loss: 0.560181; batch adversarial loss: 0.562276\n",
      "epoch 13; iter: 0; batch classifier loss: 0.542792; batch adversarial loss: 0.579651\n",
      "epoch 14; iter: 0; batch classifier loss: 0.513507; batch adversarial loss: 0.549486\n",
      "epoch 15; iter: 0; batch classifier loss: 0.521649; batch adversarial loss: 0.559354\n",
      "epoch 16; iter: 0; batch classifier loss: 0.466194; batch adversarial loss: 0.578286\n",
      "epoch 17; iter: 0; batch classifier loss: 0.498415; batch adversarial loss: 0.575148\n",
      "epoch 18; iter: 0; batch classifier loss: 0.479154; batch adversarial loss: 0.594412\n",
      "epoch 19; iter: 0; batch classifier loss: 0.480896; batch adversarial loss: 0.577559\n",
      "epoch 20; iter: 0; batch classifier loss: 0.465188; batch adversarial loss: 0.534623\n",
      "epoch 21; iter: 0; batch classifier loss: 0.513347; batch adversarial loss: 0.535833\n",
      "epoch 22; iter: 0; batch classifier loss: 0.487283; batch adversarial loss: 0.587371\n",
      "epoch 23; iter: 0; batch classifier loss: 0.449542; batch adversarial loss: 0.538983\n",
      "epoch 24; iter: 0; batch classifier loss: 0.405545; batch adversarial loss: 0.554596\n",
      "epoch 25; iter: 0; batch classifier loss: 0.461537; batch adversarial loss: 0.539645\n",
      "epoch 26; iter: 0; batch classifier loss: 0.444641; batch adversarial loss: 0.609047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 27; iter: 0; batch classifier loss: 0.418899; batch adversarial loss: 0.552074\n",
      "epoch 28; iter: 0; batch classifier loss: 0.483347; batch adversarial loss: 0.504284\n",
      "epoch 29; iter: 0; batch classifier loss: 0.375484; batch adversarial loss: 0.509060\n",
      "epoch 30; iter: 0; batch classifier loss: 0.463910; batch adversarial loss: 0.503523\n",
      "epoch 31; iter: 0; batch classifier loss: 0.445906; batch adversarial loss: 0.576382\n",
      "epoch 32; iter: 0; batch classifier loss: 0.414481; batch adversarial loss: 0.488776\n",
      "epoch 33; iter: 0; batch classifier loss: 0.394499; batch adversarial loss: 0.596383\n",
      "epoch 34; iter: 0; batch classifier loss: 0.459816; batch adversarial loss: 0.564997\n",
      "epoch 35; iter: 0; batch classifier loss: 0.420724; batch adversarial loss: 0.611742\n",
      "epoch 36; iter: 0; batch classifier loss: 0.420335; batch adversarial loss: 0.551378\n",
      "epoch 37; iter: 0; batch classifier loss: 0.415536; batch adversarial loss: 0.561067\n",
      "epoch 38; iter: 0; batch classifier loss: 0.520458; batch adversarial loss: 0.552758\n",
      "epoch 39; iter: 0; batch classifier loss: 0.414444; batch adversarial loss: 0.514732\n",
      "epoch 40; iter: 0; batch classifier loss: 0.450665; batch adversarial loss: 0.573637\n",
      "epoch 41; iter: 0; batch classifier loss: 0.443596; batch adversarial loss: 0.535929\n",
      "epoch 42; iter: 0; batch classifier loss: 0.457864; batch adversarial loss: 0.578004\n",
      "epoch 43; iter: 0; batch classifier loss: 0.501570; batch adversarial loss: 0.505852\n",
      "epoch 44; iter: 0; batch classifier loss: 0.458145; batch adversarial loss: 0.521024\n",
      "epoch 45; iter: 0; batch classifier loss: 0.437330; batch adversarial loss: 0.528720\n",
      "epoch 46; iter: 0; batch classifier loss: 0.441939; batch adversarial loss: 0.525703\n",
      "epoch 47; iter: 0; batch classifier loss: 0.440042; batch adversarial loss: 0.501790\n",
      "epoch 48; iter: 0; batch classifier loss: 0.564518; batch adversarial loss: 0.534429\n",
      "epoch 49; iter: 0; batch classifier loss: 0.363490; batch adversarial loss: 0.497526\n",
      "epoch 50; iter: 0; batch classifier loss: 0.392825; batch adversarial loss: 0.499610\n",
      "epoch 51; iter: 0; batch classifier loss: 0.387358; batch adversarial loss: 0.512933\n",
      "epoch 52; iter: 0; batch classifier loss: 0.402591; batch adversarial loss: 0.560710\n",
      "epoch 53; iter: 0; batch classifier loss: 0.381304; batch adversarial loss: 0.468006\n",
      "epoch 54; iter: 0; batch classifier loss: 0.402262; batch adversarial loss: 0.525192\n",
      "epoch 55; iter: 0; batch classifier loss: 0.410281; batch adversarial loss: 0.459256\n",
      "epoch 56; iter: 0; batch classifier loss: 0.446275; batch adversarial loss: 0.536991\n",
      "epoch 57; iter: 0; batch classifier loss: 0.409075; batch adversarial loss: 0.665436\n",
      "epoch 58; iter: 0; batch classifier loss: 0.361362; batch adversarial loss: 0.507508\n",
      "epoch 59; iter: 0; batch classifier loss: 0.335849; batch adversarial loss: 0.447382\n",
      "epoch 60; iter: 0; batch classifier loss: 0.425928; batch adversarial loss: 0.582133\n",
      "epoch 61; iter: 0; batch classifier loss: 0.382354; batch adversarial loss: 0.544496\n",
      "epoch 62; iter: 0; batch classifier loss: 0.362336; batch adversarial loss: 0.499209\n",
      "epoch 63; iter: 0; batch classifier loss: 0.409149; batch adversarial loss: 0.607702\n",
      "epoch 64; iter: 0; batch classifier loss: 0.466701; batch adversarial loss: 0.535918\n",
      "epoch 65; iter: 0; batch classifier loss: 0.403615; batch adversarial loss: 0.516618\n",
      "epoch 66; iter: 0; batch classifier loss: 0.470824; batch adversarial loss: 0.581294\n",
      "epoch 67; iter: 0; batch classifier loss: 0.379132; batch adversarial loss: 0.526103\n",
      "epoch 68; iter: 0; batch classifier loss: 0.459204; batch adversarial loss: 0.526525\n",
      "epoch 69; iter: 0; batch classifier loss: 0.413093; batch adversarial loss: 0.553809\n",
      "epoch 70; iter: 0; batch classifier loss: 0.409596; batch adversarial loss: 0.462246\n",
      "epoch 71; iter: 0; batch classifier loss: 0.370404; batch adversarial loss: 0.498312\n",
      "epoch 72; iter: 0; batch classifier loss: 0.330759; batch adversarial loss: 0.553544\n",
      "epoch 73; iter: 0; batch classifier loss: 0.388308; batch adversarial loss: 0.534900\n",
      "epoch 74; iter: 0; batch classifier loss: 0.391357; batch adversarial loss: 0.499048\n",
      "epoch 75; iter: 0; batch classifier loss: 0.407308; batch adversarial loss: 0.600078\n",
      "epoch 76; iter: 0; batch classifier loss: 0.407485; batch adversarial loss: 0.516859\n",
      "epoch 77; iter: 0; batch classifier loss: 0.387071; batch adversarial loss: 0.590799\n",
      "epoch 78; iter: 0; batch classifier loss: 0.370728; batch adversarial loss: 0.581150\n",
      "epoch 79; iter: 0; batch classifier loss: 0.424664; batch adversarial loss: 0.498483\n",
      "epoch 80; iter: 0; batch classifier loss: 0.374987; batch adversarial loss: 0.590667\n",
      "epoch 81; iter: 0; batch classifier loss: 0.389830; batch adversarial loss: 0.488916\n",
      "epoch 82; iter: 0; batch classifier loss: 0.375004; batch adversarial loss: 0.470942\n",
      "epoch 83; iter: 0; batch classifier loss: 0.403390; batch adversarial loss: 0.480347\n",
      "epoch 84; iter: 0; batch classifier loss: 0.388270; batch adversarial loss: 0.517027\n",
      "epoch 85; iter: 0; batch classifier loss: 0.373772; batch adversarial loss: 0.507432\n",
      "epoch 86; iter: 0; batch classifier loss: 0.356973; batch adversarial loss: 0.543829\n",
      "epoch 87; iter: 0; batch classifier loss: 0.382841; batch adversarial loss: 0.609817\n",
      "epoch 88; iter: 0; batch classifier loss: 0.416784; batch adversarial loss: 0.581841\n",
      "epoch 89; iter: 0; batch classifier loss: 0.355073; batch adversarial loss: 0.498619\n",
      "epoch 90; iter: 0; batch classifier loss: 0.322763; batch adversarial loss: 0.489164\n",
      "epoch 91; iter: 0; batch classifier loss: 0.447934; batch adversarial loss: 0.525854\n",
      "epoch 92; iter: 0; batch classifier loss: 0.342185; batch adversarial loss: 0.507406\n",
      "epoch 93; iter: 0; batch classifier loss: 0.466297; batch adversarial loss: 0.535100\n",
      "epoch 94; iter: 0; batch classifier loss: 0.342353; batch adversarial loss: 0.646975\n",
      "epoch 95; iter: 0; batch classifier loss: 0.357767; batch adversarial loss: 0.534901\n",
      "epoch 96; iter: 0; batch classifier loss: 0.386335; batch adversarial loss: 0.544449\n",
      "epoch 97; iter: 0; batch classifier loss: 0.427474; batch adversarial loss: 0.554141\n",
      "epoch 98; iter: 0; batch classifier loss: 0.335541; batch adversarial loss: 0.590971\n",
      "epoch 99; iter: 0; batch classifier loss: 0.396749; batch adversarial loss: 0.544267\n",
      "epoch 100; iter: 0; batch classifier loss: 0.360973; batch adversarial loss: 0.479892\n",
      "epoch 101; iter: 0; batch classifier loss: 0.344384; batch adversarial loss: 0.525960\n",
      "epoch 102; iter: 0; batch classifier loss: 0.369146; batch adversarial loss: 0.636196\n",
      "epoch 103; iter: 0; batch classifier loss: 0.286742; batch adversarial loss: 0.534847\n",
      "epoch 104; iter: 0; batch classifier loss: 0.272453; batch adversarial loss: 0.553591\n",
      "epoch 105; iter: 0; batch classifier loss: 0.300086; batch adversarial loss: 0.535176\n",
      "epoch 106; iter: 0; batch classifier loss: 0.485290; batch adversarial loss: 0.470351\n",
      "epoch 107; iter: 0; batch classifier loss: 0.359184; batch adversarial loss: 0.608780\n",
      "epoch 108; iter: 0; batch classifier loss: 0.256198; batch adversarial loss: 0.525616\n",
      "epoch 109; iter: 0; batch classifier loss: 0.406614; batch adversarial loss: 0.507285\n",
      "epoch 110; iter: 0; batch classifier loss: 0.412838; batch adversarial loss: 0.544796\n",
      "epoch 111; iter: 0; batch classifier loss: 0.428677; batch adversarial loss: 0.553404\n",
      "epoch 112; iter: 0; batch classifier loss: 0.403718; batch adversarial loss: 0.535309\n",
      "epoch 113; iter: 0; batch classifier loss: 0.351390; batch adversarial loss: 0.498223\n",
      "epoch 114; iter: 0; batch classifier loss: 0.308533; batch adversarial loss: 0.553677\n",
      "epoch 115; iter: 0; batch classifier loss: 0.321019; batch adversarial loss: 0.553983\n",
      "epoch 116; iter: 0; batch classifier loss: 0.431745; batch adversarial loss: 0.544770\n",
      "epoch 117; iter: 0; batch classifier loss: 0.412459; batch adversarial loss: 0.590941\n",
      "epoch 118; iter: 0; batch classifier loss: 0.379973; batch adversarial loss: 0.581558\n",
      "epoch 119; iter: 0; batch classifier loss: 0.490887; batch adversarial loss: 0.498505\n",
      "epoch 120; iter: 0; batch classifier loss: 0.364733; batch adversarial loss: 0.581626\n",
      "epoch 121; iter: 0; batch classifier loss: 0.316545; batch adversarial loss: 0.516881\n",
      "epoch 122; iter: 0; batch classifier loss: 0.308778; batch adversarial loss: 0.563402\n",
      "epoch 123; iter: 0; batch classifier loss: 0.349386; batch adversarial loss: 0.572528\n",
      "epoch 124; iter: 0; batch classifier loss: 0.398019; batch adversarial loss: 0.517049\n",
      "epoch 125; iter: 0; batch classifier loss: 0.402284; batch adversarial loss: 0.516797\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 126; iter: 0; batch classifier loss: 0.427155; batch adversarial loss: 0.488969\n",
      "epoch 127; iter: 0; batch classifier loss: 0.369435; batch adversarial loss: 0.433569\n",
      "epoch 128; iter: 0; batch classifier loss: 0.382423; batch adversarial loss: 0.516650\n",
      "epoch 129; iter: 0; batch classifier loss: 0.339822; batch adversarial loss: 0.497870\n",
      "epoch 130; iter: 0; batch classifier loss: 0.437344; batch adversarial loss: 0.618704\n",
      "epoch 131; iter: 0; batch classifier loss: 0.361144; batch adversarial loss: 0.590628\n",
      "epoch 132; iter: 0; batch classifier loss: 0.307862; batch adversarial loss: 0.535219\n",
      "epoch 133; iter: 0; batch classifier loss: 0.303745; batch adversarial loss: 0.590866\n",
      "epoch 134; iter: 0; batch classifier loss: 0.391051; batch adversarial loss: 0.488481\n",
      "epoch 135; iter: 0; batch classifier loss: 0.354412; batch adversarial loss: 0.470425\n",
      "epoch 136; iter: 0; batch classifier loss: 0.363744; batch adversarial loss: 0.544936\n",
      "epoch 137; iter: 0; batch classifier loss: 0.382532; batch adversarial loss: 0.582515\n",
      "epoch 138; iter: 0; batch classifier loss: 0.407331; batch adversarial loss: 0.553768\n",
      "epoch 139; iter: 0; batch classifier loss: 0.362681; batch adversarial loss: 0.553532\n",
      "epoch 140; iter: 0; batch classifier loss: 0.349498; batch adversarial loss: 0.599938\n",
      "epoch 141; iter: 0; batch classifier loss: 0.387589; batch adversarial loss: 0.544496\n",
      "epoch 142; iter: 0; batch classifier loss: 0.307301; batch adversarial loss: 0.525694\n",
      "epoch 143; iter: 0; batch classifier loss: 0.357854; batch adversarial loss: 0.516481\n",
      "epoch 144; iter: 0; batch classifier loss: 0.319687; batch adversarial loss: 0.499067\n",
      "epoch 145; iter: 0; batch classifier loss: 0.288699; batch adversarial loss: 0.526783\n",
      "epoch 146; iter: 0; batch classifier loss: 0.327323; batch adversarial loss: 0.489183\n",
      "epoch 147; iter: 0; batch classifier loss: 0.326325; batch adversarial loss: 0.581909\n",
      "epoch 148; iter: 0; batch classifier loss: 0.351259; batch adversarial loss: 0.572446\n",
      "epoch 149; iter: 0; batch classifier loss: 0.382690; batch adversarial loss: 0.599441\n",
      "epoch 150; iter: 0; batch classifier loss: 0.345306; batch adversarial loss: 0.497363\n",
      "epoch 151; iter: 0; batch classifier loss: 0.331385; batch adversarial loss: 0.580933\n",
      "epoch 152; iter: 0; batch classifier loss: 0.392693; batch adversarial loss: 0.553492\n",
      "epoch 153; iter: 0; batch classifier loss: 0.397372; batch adversarial loss: 0.497742\n",
      "epoch 154; iter: 0; batch classifier loss: 0.359539; batch adversarial loss: 0.554404\n",
      "epoch 155; iter: 0; batch classifier loss: 0.323987; batch adversarial loss: 0.581417\n",
      "epoch 156; iter: 0; batch classifier loss: 0.363204; batch adversarial loss: 0.507654\n",
      "epoch 157; iter: 0; batch classifier loss: 0.314216; batch adversarial loss: 0.572237\n",
      "epoch 158; iter: 0; batch classifier loss: 0.442846; batch adversarial loss: 0.590873\n",
      "epoch 159; iter: 0; batch classifier loss: 0.439493; batch adversarial loss: 0.581422\n",
      "epoch 160; iter: 0; batch classifier loss: 0.412722; batch adversarial loss: 0.498896\n",
      "epoch 161; iter: 0; batch classifier loss: 0.305446; batch adversarial loss: 0.526073\n",
      "epoch 162; iter: 0; batch classifier loss: 0.384676; batch adversarial loss: 0.479871\n",
      "epoch 163; iter: 0; batch classifier loss: 0.308761; batch adversarial loss: 0.628437\n",
      "epoch 164; iter: 0; batch classifier loss: 0.335908; batch adversarial loss: 0.543978\n",
      "epoch 165; iter: 0; batch classifier loss: 0.301168; batch adversarial loss: 0.627164\n",
      "epoch 166; iter: 0; batch classifier loss: 0.409808; batch adversarial loss: 0.526165\n",
      "epoch 167; iter: 0; batch classifier loss: 0.314819; batch adversarial loss: 0.497687\n",
      "epoch 168; iter: 0; batch classifier loss: 0.373318; batch adversarial loss: 0.498249\n",
      "epoch 169; iter: 0; batch classifier loss: 0.299894; batch adversarial loss: 0.544322\n",
      "epoch 170; iter: 0; batch classifier loss: 0.358778; batch adversarial loss: 0.544276\n",
      "epoch 171; iter: 0; batch classifier loss: 0.258157; batch adversarial loss: 0.525054\n",
      "epoch 172; iter: 0; batch classifier loss: 0.444611; batch adversarial loss: 0.470930\n",
      "epoch 173; iter: 0; batch classifier loss: 0.392691; batch adversarial loss: 0.572159\n",
      "epoch 174; iter: 0; batch classifier loss: 0.301198; batch adversarial loss: 0.544204\n",
      "epoch 175; iter: 0; batch classifier loss: 0.355357; batch adversarial loss: 0.591142\n",
      "epoch 176; iter: 0; batch classifier loss: 0.341975; batch adversarial loss: 0.627745\n",
      "epoch 177; iter: 0; batch classifier loss: 0.348567; batch adversarial loss: 0.553912\n",
      "epoch 178; iter: 0; batch classifier loss: 0.336829; batch adversarial loss: 0.637862\n",
      "epoch 179; iter: 0; batch classifier loss: 0.335535; batch adversarial loss: 0.414242\n",
      "epoch 180; iter: 0; batch classifier loss: 0.321407; batch adversarial loss: 0.655972\n",
      "epoch 181; iter: 0; batch classifier loss: 0.246873; batch adversarial loss: 0.544420\n",
      "epoch 182; iter: 0; batch classifier loss: 0.372151; batch adversarial loss: 0.535776\n",
      "epoch 183; iter: 0; batch classifier loss: 0.368681; batch adversarial loss: 0.590590\n",
      "epoch 184; iter: 0; batch classifier loss: 0.374865; batch adversarial loss: 0.562969\n",
      "epoch 185; iter: 0; batch classifier loss: 0.366824; batch adversarial loss: 0.544040\n",
      "epoch 186; iter: 0; batch classifier loss: 0.327057; batch adversarial loss: 0.572019\n",
      "epoch 187; iter: 0; batch classifier loss: 0.372109; batch adversarial loss: 0.571784\n",
      "epoch 188; iter: 0; batch classifier loss: 0.331211; batch adversarial loss: 0.545087\n",
      "epoch 189; iter: 0; batch classifier loss: 0.364791; batch adversarial loss: 0.571642\n",
      "epoch 190; iter: 0; batch classifier loss: 0.305590; batch adversarial loss: 0.608458\n",
      "epoch 191; iter: 0; batch classifier loss: 0.278544; batch adversarial loss: 0.516496\n",
      "epoch 192; iter: 0; batch classifier loss: 0.329430; batch adversarial loss: 0.553270\n",
      "epoch 193; iter: 0; batch classifier loss: 0.291216; batch adversarial loss: 0.609223\n",
      "epoch 194; iter: 0; batch classifier loss: 0.399113; batch adversarial loss: 0.452304\n",
      "epoch 195; iter: 0; batch classifier loss: 0.332162; batch adversarial loss: 0.544699\n",
      "epoch 196; iter: 0; batch classifier loss: 0.369645; batch adversarial loss: 0.544356\n",
      "epoch 197; iter: 0; batch classifier loss: 0.306515; batch adversarial loss: 0.498566\n",
      "epoch 198; iter: 0; batch classifier loss: 0.390334; batch adversarial loss: 0.544870\n",
      "epoch 199; iter: 0; batch classifier loss: 0.355570; batch adversarial loss: 0.517024\n",
      "epoch 0; iter: 0; batch classifier loss: 0.734118; batch adversarial loss: 0.674622\n",
      "epoch 1; iter: 0; batch classifier loss: 0.579247; batch adversarial loss: 0.650531\n",
      "epoch 2; iter: 0; batch classifier loss: 0.552712; batch adversarial loss: 0.630716\n",
      "epoch 3; iter: 0; batch classifier loss: 0.531635; batch adversarial loss: 0.640684\n",
      "epoch 4; iter: 0; batch classifier loss: 0.582302; batch adversarial loss: 0.632141\n",
      "epoch 5; iter: 0; batch classifier loss: 0.528338; batch adversarial loss: 0.615311\n",
      "epoch 6; iter: 0; batch classifier loss: 0.551648; batch adversarial loss: 0.609291\n",
      "epoch 7; iter: 0; batch classifier loss: 0.564512; batch adversarial loss: 0.629220\n",
      "epoch 8; iter: 0; batch classifier loss: 0.496906; batch adversarial loss: 0.613724\n",
      "epoch 9; iter: 0; batch classifier loss: 0.454831; batch adversarial loss: 0.581503\n",
      "epoch 10; iter: 0; batch classifier loss: 0.486209; batch adversarial loss: 0.630287\n",
      "epoch 11; iter: 0; batch classifier loss: 0.502645; batch adversarial loss: 0.586129\n",
      "epoch 12; iter: 0; batch classifier loss: 0.514184; batch adversarial loss: 0.562599\n",
      "epoch 13; iter: 0; batch classifier loss: 0.575508; batch adversarial loss: 0.559383\n",
      "epoch 14; iter: 0; batch classifier loss: 0.532684; batch adversarial loss: 0.509077\n",
      "epoch 15; iter: 0; batch classifier loss: 0.483145; batch adversarial loss: 0.706869\n",
      "epoch 16; iter: 0; batch classifier loss: 0.470976; batch adversarial loss: 0.519275\n",
      "epoch 17; iter: 0; batch classifier loss: 0.519380; batch adversarial loss: 0.542481\n",
      "epoch 18; iter: 0; batch classifier loss: 0.437366; batch adversarial loss: 0.565150\n",
      "epoch 19; iter: 0; batch classifier loss: 0.526720; batch adversarial loss: 0.592527\n",
      "epoch 20; iter: 0; batch classifier loss: 0.478055; batch adversarial loss: 0.568004\n",
      "epoch 21; iter: 0; batch classifier loss: 0.458062; batch adversarial loss: 0.582483\n",
      "epoch 22; iter: 0; batch classifier loss: 0.433507; batch adversarial loss: 0.557814\n",
      "epoch 23; iter: 0; batch classifier loss: 0.495029; batch adversarial loss: 0.603760\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 24; iter: 0; batch classifier loss: 0.495356; batch adversarial loss: 0.509184\n",
      "epoch 25; iter: 0; batch classifier loss: 0.457159; batch adversarial loss: 0.578697\n",
      "epoch 26; iter: 0; batch classifier loss: 0.543965; batch adversarial loss: 0.577323\n",
      "epoch 27; iter: 0; batch classifier loss: 0.506212; batch adversarial loss: 0.587172\n",
      "epoch 28; iter: 0; batch classifier loss: 0.527102; batch adversarial loss: 0.490208\n",
      "epoch 29; iter: 0; batch classifier loss: 0.405231; batch adversarial loss: 0.587649\n",
      "epoch 30; iter: 0; batch classifier loss: 0.478804; batch adversarial loss: 0.606521\n",
      "epoch 31; iter: 0; batch classifier loss: 0.526485; batch adversarial loss: 0.586277\n",
      "epoch 32; iter: 0; batch classifier loss: 0.372516; batch adversarial loss: 0.557010\n",
      "epoch 33; iter: 0; batch classifier loss: 0.404367; batch adversarial loss: 0.502779\n",
      "epoch 34; iter: 0; batch classifier loss: 0.499705; batch adversarial loss: 0.519296\n",
      "epoch 35; iter: 0; batch classifier loss: 0.431488; batch adversarial loss: 0.574608\n",
      "epoch 36; iter: 0; batch classifier loss: 0.442624; batch adversarial loss: 0.506621\n",
      "epoch 37; iter: 0; batch classifier loss: 0.486187; batch adversarial loss: 0.576842\n",
      "epoch 38; iter: 0; batch classifier loss: 0.442518; batch adversarial loss: 0.500744\n",
      "epoch 39; iter: 0; batch classifier loss: 0.445227; batch adversarial loss: 0.633140\n",
      "epoch 40; iter: 0; batch classifier loss: 0.451310; batch adversarial loss: 0.575890\n",
      "epoch 41; iter: 0; batch classifier loss: 0.395671; batch adversarial loss: 0.578156\n",
      "epoch 42; iter: 0; batch classifier loss: 0.361797; batch adversarial loss: 0.615944\n",
      "epoch 43; iter: 0; batch classifier loss: 0.432549; batch adversarial loss: 0.542916\n",
      "epoch 44; iter: 0; batch classifier loss: 0.463788; batch adversarial loss: 0.569138\n",
      "epoch 45; iter: 0; batch classifier loss: 0.399615; batch adversarial loss: 0.442071\n",
      "epoch 46; iter: 0; batch classifier loss: 0.410314; batch adversarial loss: 0.559106\n",
      "epoch 47; iter: 0; batch classifier loss: 0.429431; batch adversarial loss: 0.570859\n",
      "epoch 48; iter: 0; batch classifier loss: 0.380172; batch adversarial loss: 0.500314\n",
      "epoch 49; iter: 0; batch classifier loss: 0.428974; batch adversarial loss: 0.498874\n",
      "epoch 50; iter: 0; batch classifier loss: 0.363212; batch adversarial loss: 0.552343\n",
      "epoch 51; iter: 0; batch classifier loss: 0.457923; batch adversarial loss: 0.663700\n",
      "epoch 52; iter: 0; batch classifier loss: 0.383530; batch adversarial loss: 0.556951\n",
      "epoch 53; iter: 0; batch classifier loss: 0.354176; batch adversarial loss: 0.575540\n",
      "epoch 54; iter: 0; batch classifier loss: 0.445064; batch adversarial loss: 0.578106\n",
      "epoch 55; iter: 0; batch classifier loss: 0.349331; batch adversarial loss: 0.546054\n",
      "epoch 56; iter: 0; batch classifier loss: 0.493865; batch adversarial loss: 0.600927\n",
      "epoch 57; iter: 0; batch classifier loss: 0.354249; batch adversarial loss: 0.507348\n",
      "epoch 58; iter: 0; batch classifier loss: 0.358602; batch adversarial loss: 0.582754\n",
      "epoch 59; iter: 0; batch classifier loss: 0.356591; batch adversarial loss: 0.598563\n",
      "epoch 60; iter: 0; batch classifier loss: 0.323307; batch adversarial loss: 0.562694\n",
      "epoch 61; iter: 0; batch classifier loss: 0.316028; batch adversarial loss: 0.552876\n",
      "epoch 62; iter: 0; batch classifier loss: 0.427514; batch adversarial loss: 0.594057\n",
      "epoch 63; iter: 0; batch classifier loss: 0.441150; batch adversarial loss: 0.552794\n",
      "epoch 64; iter: 0; batch classifier loss: 0.472495; batch adversarial loss: 0.638288\n",
      "epoch 65; iter: 0; batch classifier loss: 0.559141; batch adversarial loss: 0.554067\n",
      "epoch 66; iter: 0; batch classifier loss: 0.404280; batch adversarial loss: 0.596362\n",
      "epoch 67; iter: 0; batch classifier loss: 0.376178; batch adversarial loss: 0.546732\n",
      "epoch 68; iter: 0; batch classifier loss: 0.422909; batch adversarial loss: 0.568542\n",
      "epoch 69; iter: 0; batch classifier loss: 0.397664; batch adversarial loss: 0.587338\n",
      "epoch 70; iter: 0; batch classifier loss: 0.338856; batch adversarial loss: 0.570874\n",
      "epoch 71; iter: 0; batch classifier loss: 0.418207; batch adversarial loss: 0.541935\n",
      "epoch 72; iter: 0; batch classifier loss: 0.333232; batch adversarial loss: 0.631815\n",
      "epoch 73; iter: 0; batch classifier loss: 0.384221; batch adversarial loss: 0.546650\n",
      "epoch 74; iter: 0; batch classifier loss: 0.382938; batch adversarial loss: 0.461087\n",
      "epoch 75; iter: 0; batch classifier loss: 0.460908; batch adversarial loss: 0.537097\n",
      "epoch 76; iter: 0; batch classifier loss: 0.420616; batch adversarial loss: 0.531742\n",
      "epoch 77; iter: 0; batch classifier loss: 0.423033; batch adversarial loss: 0.591019\n",
      "epoch 78; iter: 0; batch classifier loss: 0.347601; batch adversarial loss: 0.559519\n",
      "epoch 79; iter: 0; batch classifier loss: 0.406547; batch adversarial loss: 0.576216\n",
      "epoch 80; iter: 0; batch classifier loss: 0.371174; batch adversarial loss: 0.530760\n",
      "epoch 81; iter: 0; batch classifier loss: 0.395102; batch adversarial loss: 0.594597\n",
      "epoch 82; iter: 0; batch classifier loss: 0.361833; batch adversarial loss: 0.517015\n",
      "epoch 83; iter: 0; batch classifier loss: 0.386512; batch adversarial loss: 0.540462\n",
      "epoch 84; iter: 0; batch classifier loss: 0.454455; batch adversarial loss: 0.552202\n",
      "epoch 85; iter: 0; batch classifier loss: 0.320486; batch adversarial loss: 0.518596\n",
      "epoch 86; iter: 0; batch classifier loss: 0.349051; batch adversarial loss: 0.557444\n",
      "epoch 87; iter: 0; batch classifier loss: 0.382278; batch adversarial loss: 0.592178\n",
      "epoch 88; iter: 0; batch classifier loss: 0.451541; batch adversarial loss: 0.574288\n",
      "epoch 89; iter: 0; batch classifier loss: 0.424122; batch adversarial loss: 0.593256\n",
      "epoch 90; iter: 0; batch classifier loss: 0.381815; batch adversarial loss: 0.578955\n",
      "epoch 91; iter: 0; batch classifier loss: 0.403698; batch adversarial loss: 0.578358\n",
      "epoch 92; iter: 0; batch classifier loss: 0.404632; batch adversarial loss: 0.615366\n",
      "epoch 93; iter: 0; batch classifier loss: 0.413269; batch adversarial loss: 0.650072\n",
      "epoch 94; iter: 0; batch classifier loss: 0.347507; batch adversarial loss: 0.529084\n",
      "epoch 95; iter: 0; batch classifier loss: 0.416393; batch adversarial loss: 0.505466\n",
      "epoch 96; iter: 0; batch classifier loss: 0.331135; batch adversarial loss: 0.542315\n",
      "epoch 97; iter: 0; batch classifier loss: 0.412625; batch adversarial loss: 0.559409\n",
      "epoch 98; iter: 0; batch classifier loss: 0.324515; batch adversarial loss: 0.579259\n",
      "epoch 99; iter: 0; batch classifier loss: 0.291628; batch adversarial loss: 0.456340\n",
      "epoch 100; iter: 0; batch classifier loss: 0.376220; batch adversarial loss: 0.570164\n",
      "epoch 101; iter: 0; batch classifier loss: 0.364470; batch adversarial loss: 0.612460\n",
      "epoch 102; iter: 0; batch classifier loss: 0.322028; batch adversarial loss: 0.580274\n",
      "epoch 103; iter: 0; batch classifier loss: 0.468543; batch adversarial loss: 0.519676\n",
      "epoch 104; iter: 0; batch classifier loss: 0.373482; batch adversarial loss: 0.541352\n",
      "epoch 105; iter: 0; batch classifier loss: 0.401636; batch adversarial loss: 0.509477\n",
      "epoch 106; iter: 0; batch classifier loss: 0.421364; batch adversarial loss: 0.599907\n",
      "epoch 107; iter: 0; batch classifier loss: 0.362777; batch adversarial loss: 0.583367\n",
      "epoch 108; iter: 0; batch classifier loss: 0.422873; batch adversarial loss: 0.531339\n",
      "epoch 109; iter: 0; batch classifier loss: 0.371705; batch adversarial loss: 0.569332\n",
      "epoch 110; iter: 0; batch classifier loss: 0.323399; batch adversarial loss: 0.568653\n",
      "epoch 111; iter: 0; batch classifier loss: 0.447486; batch adversarial loss: 0.580738\n",
      "epoch 112; iter: 0; batch classifier loss: 0.333384; batch adversarial loss: 0.602429\n",
      "epoch 113; iter: 0; batch classifier loss: 0.324382; batch adversarial loss: 0.533276\n",
      "epoch 114; iter: 0; batch classifier loss: 0.346764; batch adversarial loss: 0.613049\n",
      "epoch 115; iter: 0; batch classifier loss: 0.388545; batch adversarial loss: 0.529533\n",
      "epoch 116; iter: 0; batch classifier loss: 0.353394; batch adversarial loss: 0.513930\n",
      "epoch 117; iter: 0; batch classifier loss: 0.461574; batch adversarial loss: 0.547381\n",
      "epoch 118; iter: 0; batch classifier loss: 0.383058; batch adversarial loss: 0.532513\n",
      "epoch 119; iter: 0; batch classifier loss: 0.416547; batch adversarial loss: 0.581405\n",
      "epoch 120; iter: 0; batch classifier loss: 0.368598; batch adversarial loss: 0.552474\n",
      "epoch 121; iter: 0; batch classifier loss: 0.431759; batch adversarial loss: 0.508743\n",
      "epoch 122; iter: 0; batch classifier loss: 0.333313; batch adversarial loss: 0.596666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 123; iter: 0; batch classifier loss: 0.441501; batch adversarial loss: 0.494384\n",
      "epoch 124; iter: 0; batch classifier loss: 0.338300; batch adversarial loss: 0.519062\n",
      "epoch 125; iter: 0; batch classifier loss: 0.407190; batch adversarial loss: 0.515323\n",
      "epoch 126; iter: 0; batch classifier loss: 0.347772; batch adversarial loss: 0.554154\n",
      "epoch 127; iter: 0; batch classifier loss: 0.390283; batch adversarial loss: 0.544118\n",
      "epoch 128; iter: 0; batch classifier loss: 0.391212; batch adversarial loss: 0.619663\n",
      "epoch 129; iter: 0; batch classifier loss: 0.391283; batch adversarial loss: 0.610525\n",
      "epoch 130; iter: 0; batch classifier loss: 0.412920; batch adversarial loss: 0.572153\n",
      "epoch 131; iter: 0; batch classifier loss: 0.350020; batch adversarial loss: 0.555782\n",
      "epoch 132; iter: 0; batch classifier loss: 0.350714; batch adversarial loss: 0.558984\n",
      "epoch 133; iter: 0; batch classifier loss: 0.408940; batch adversarial loss: 0.567846\n",
      "epoch 134; iter: 0; batch classifier loss: 0.287300; batch adversarial loss: 0.614114\n",
      "epoch 135; iter: 0; batch classifier loss: 0.289019; batch adversarial loss: 0.602862\n",
      "epoch 136; iter: 0; batch classifier loss: 0.430457; batch adversarial loss: 0.635832\n",
      "epoch 137; iter: 0; batch classifier loss: 0.400511; batch adversarial loss: 0.493439\n",
      "epoch 138; iter: 0; batch classifier loss: 0.380287; batch adversarial loss: 0.581720\n",
      "epoch 139; iter: 0; batch classifier loss: 0.391724; batch adversarial loss: 0.595872\n",
      "epoch 140; iter: 0; batch classifier loss: 0.325477; batch adversarial loss: 0.611860\n",
      "epoch 141; iter: 0; batch classifier loss: 0.377513; batch adversarial loss: 0.529557\n",
      "epoch 142; iter: 0; batch classifier loss: 0.383280; batch adversarial loss: 0.688428\n",
      "epoch 143; iter: 0; batch classifier loss: 0.489501; batch adversarial loss: 0.564754\n",
      "epoch 144; iter: 0; batch classifier loss: 0.323415; batch adversarial loss: 0.582912\n",
      "epoch 145; iter: 0; batch classifier loss: 0.382337; batch adversarial loss: 0.490490\n",
      "epoch 146; iter: 0; batch classifier loss: 0.413805; batch adversarial loss: 0.566928\n",
      "epoch 147; iter: 0; batch classifier loss: 0.256229; batch adversarial loss: 0.575623\n",
      "epoch 148; iter: 0; batch classifier loss: 0.340463; batch adversarial loss: 0.488428\n",
      "epoch 149; iter: 0; batch classifier loss: 0.324585; batch adversarial loss: 0.598758\n",
      "epoch 150; iter: 0; batch classifier loss: 0.388791; batch adversarial loss: 0.604714\n",
      "epoch 151; iter: 0; batch classifier loss: 0.350326; batch adversarial loss: 0.558091\n",
      "epoch 152; iter: 0; batch classifier loss: 0.455473; batch adversarial loss: 0.625709\n",
      "epoch 153; iter: 0; batch classifier loss: 0.372076; batch adversarial loss: 0.526747\n",
      "epoch 154; iter: 0; batch classifier loss: 0.349705; batch adversarial loss: 0.594577\n",
      "epoch 155; iter: 0; batch classifier loss: 0.436339; batch adversarial loss: 0.521244\n",
      "epoch 156; iter: 0; batch classifier loss: 0.324998; batch adversarial loss: 0.578234\n",
      "epoch 157; iter: 0; batch classifier loss: 0.349815; batch adversarial loss: 0.575649\n",
      "epoch 158; iter: 0; batch classifier loss: 0.395425; batch adversarial loss: 0.595905\n",
      "epoch 159; iter: 0; batch classifier loss: 0.388613; batch adversarial loss: 0.521434\n",
      "epoch 160; iter: 0; batch classifier loss: 0.423744; batch adversarial loss: 0.573966\n",
      "epoch 161; iter: 0; batch classifier loss: 0.411376; batch adversarial loss: 0.633896\n",
      "epoch 162; iter: 0; batch classifier loss: 0.404176; batch adversarial loss: 0.528994\n",
      "epoch 163; iter: 0; batch classifier loss: 0.364987; batch adversarial loss: 0.580114\n",
      "epoch 164; iter: 0; batch classifier loss: 0.436266; batch adversarial loss: 0.556193\n",
      "epoch 165; iter: 0; batch classifier loss: 0.283529; batch adversarial loss: 0.629344\n",
      "epoch 166; iter: 0; batch classifier loss: 0.385382; batch adversarial loss: 0.591668\n",
      "epoch 167; iter: 0; batch classifier loss: 0.373177; batch adversarial loss: 0.550487\n",
      "epoch 168; iter: 0; batch classifier loss: 0.315557; batch adversarial loss: 0.531033\n",
      "epoch 169; iter: 0; batch classifier loss: 0.405413; batch adversarial loss: 0.608348\n",
      "epoch 170; iter: 0; batch classifier loss: 0.339271; batch adversarial loss: 0.579195\n",
      "epoch 171; iter: 0; batch classifier loss: 0.415764; batch adversarial loss: 0.585389\n",
      "epoch 172; iter: 0; batch classifier loss: 0.317749; batch adversarial loss: 0.534108\n",
      "epoch 173; iter: 0; batch classifier loss: 0.376942; batch adversarial loss: 0.442286\n",
      "epoch 174; iter: 0; batch classifier loss: 0.432890; batch adversarial loss: 0.557935\n",
      "epoch 175; iter: 0; batch classifier loss: 0.336484; batch adversarial loss: 0.583841\n",
      "epoch 176; iter: 0; batch classifier loss: 0.321364; batch adversarial loss: 0.593907\n",
      "epoch 177; iter: 0; batch classifier loss: 0.441529; batch adversarial loss: 0.541780\n",
      "epoch 178; iter: 0; batch classifier loss: 0.323695; batch adversarial loss: 0.541001\n",
      "epoch 179; iter: 0; batch classifier loss: 0.381681; batch adversarial loss: 0.645916\n",
      "epoch 180; iter: 0; batch classifier loss: 0.370668; batch adversarial loss: 0.571667\n",
      "epoch 181; iter: 0; batch classifier loss: 0.368659; batch adversarial loss: 0.632968\n",
      "epoch 182; iter: 0; batch classifier loss: 0.447759; batch adversarial loss: 0.576789\n",
      "epoch 183; iter: 0; batch classifier loss: 0.374205; batch adversarial loss: 0.523629\n",
      "epoch 184; iter: 0; batch classifier loss: 0.359323; batch adversarial loss: 0.545937\n",
      "epoch 185; iter: 0; batch classifier loss: 0.315936; batch adversarial loss: 0.489718\n",
      "epoch 186; iter: 0; batch classifier loss: 0.385285; batch adversarial loss: 0.520117\n",
      "epoch 187; iter: 0; batch classifier loss: 0.353404; batch adversarial loss: 0.522692\n",
      "epoch 188; iter: 0; batch classifier loss: 0.318757; batch adversarial loss: 0.601030\n",
      "epoch 189; iter: 0; batch classifier loss: 0.341397; batch adversarial loss: 0.520398\n",
      "epoch 190; iter: 0; batch classifier loss: 0.343755; batch adversarial loss: 0.558848\n",
      "epoch 191; iter: 0; batch classifier loss: 0.316082; batch adversarial loss: 0.572880\n",
      "epoch 192; iter: 0; batch classifier loss: 0.331148; batch adversarial loss: 0.507894\n",
      "epoch 193; iter: 0; batch classifier loss: 0.331271; batch adversarial loss: 0.610626\n",
      "epoch 194; iter: 0; batch classifier loss: 0.329350; batch adversarial loss: 0.519118\n",
      "epoch 195; iter: 0; batch classifier loss: 0.367494; batch adversarial loss: 0.538923\n",
      "epoch 196; iter: 0; batch classifier loss: 0.362830; batch adversarial loss: 0.559883\n",
      "epoch 197; iter: 0; batch classifier loss: 0.315850; batch adversarial loss: 0.550727\n",
      "epoch 198; iter: 0; batch classifier loss: 0.275126; batch adversarial loss: 0.546214\n",
      "epoch 199; iter: 0; batch classifier loss: 0.449552; batch adversarial loss: 0.470289\n",
      "epoch 0; iter: 0; batch classifier loss: 0.689142; batch adversarial loss: 0.725186\n",
      "epoch 1; iter: 0; batch classifier loss: 0.584723; batch adversarial loss: 0.688017\n",
      "epoch 2; iter: 0; batch classifier loss: 0.540812; batch adversarial loss: 0.669711\n",
      "epoch 3; iter: 0; batch classifier loss: 0.624074; batch adversarial loss: 0.654947\n",
      "epoch 4; iter: 0; batch classifier loss: 0.550972; batch adversarial loss: 0.646644\n",
      "epoch 5; iter: 0; batch classifier loss: 0.549717; batch adversarial loss: 0.578508\n",
      "epoch 6; iter: 0; batch classifier loss: 0.553445; batch adversarial loss: 0.568232\n",
      "epoch 7; iter: 0; batch classifier loss: 0.566553; batch adversarial loss: 0.580289\n",
      "epoch 8; iter: 0; batch classifier loss: 0.533435; batch adversarial loss: 0.592349\n",
      "epoch 9; iter: 0; batch classifier loss: 0.548532; batch adversarial loss: 0.617526\n",
      "epoch 10; iter: 0; batch classifier loss: 0.544296; batch adversarial loss: 0.576743\n",
      "epoch 11; iter: 0; batch classifier loss: 0.465256; batch adversarial loss: 0.498211\n",
      "epoch 12; iter: 0; batch classifier loss: 0.540759; batch adversarial loss: 0.549047\n",
      "epoch 13; iter: 0; batch classifier loss: 0.589553; batch adversarial loss: 0.567990\n",
      "epoch 14; iter: 0; batch classifier loss: 0.491218; batch adversarial loss: 0.561681\n",
      "epoch 15; iter: 0; batch classifier loss: 0.495384; batch adversarial loss: 0.549936\n",
      "epoch 16; iter: 0; batch classifier loss: 0.471518; batch adversarial loss: 0.592958\n",
      "epoch 17; iter: 0; batch classifier loss: 0.504163; batch adversarial loss: 0.524121\n",
      "epoch 18; iter: 0; batch classifier loss: 0.533051; batch adversarial loss: 0.561667\n",
      "epoch 19; iter: 0; batch classifier loss: 0.541901; batch adversarial loss: 0.624572\n",
      "epoch 20; iter: 0; batch classifier loss: 0.511495; batch adversarial loss: 0.599755\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 21; iter: 0; batch classifier loss: 0.559150; batch adversarial loss: 0.622878\n",
      "epoch 22; iter: 0; batch classifier loss: 0.563336; batch adversarial loss: 0.587496\n",
      "epoch 23; iter: 0; batch classifier loss: 0.522249; batch adversarial loss: 0.605101\n",
      "epoch 24; iter: 0; batch classifier loss: 0.531739; batch adversarial loss: 0.582222\n",
      "epoch 25; iter: 0; batch classifier loss: 0.406753; batch adversarial loss: 0.579186\n",
      "epoch 26; iter: 0; batch classifier loss: 0.397726; batch adversarial loss: 0.563720\n",
      "epoch 27; iter: 0; batch classifier loss: 0.396203; batch adversarial loss: 0.548122\n",
      "epoch 28; iter: 0; batch classifier loss: 0.451316; batch adversarial loss: 0.651791\n",
      "epoch 29; iter: 0; batch classifier loss: 0.472469; batch adversarial loss: 0.530722\n",
      "epoch 30; iter: 0; batch classifier loss: 0.475571; batch adversarial loss: 0.546039\n",
      "epoch 31; iter: 0; batch classifier loss: 0.471622; batch adversarial loss: 0.529629\n",
      "epoch 32; iter: 0; batch classifier loss: 0.486278; batch adversarial loss: 0.588280\n",
      "epoch 33; iter: 0; batch classifier loss: 0.421771; batch adversarial loss: 0.475590\n",
      "epoch 34; iter: 0; batch classifier loss: 0.473199; batch adversarial loss: 0.529082\n",
      "epoch 35; iter: 0; batch classifier loss: 0.499967; batch adversarial loss: 0.537092\n",
      "epoch 36; iter: 0; batch classifier loss: 0.476318; batch adversarial loss: 0.527410\n",
      "epoch 37; iter: 0; batch classifier loss: 0.486072; batch adversarial loss: 0.579296\n",
      "epoch 38; iter: 0; batch classifier loss: 0.420779; batch adversarial loss: 0.616001\n",
      "epoch 39; iter: 0; batch classifier loss: 0.412814; batch adversarial loss: 0.589285\n",
      "epoch 40; iter: 0; batch classifier loss: 0.474836; batch adversarial loss: 0.500559\n",
      "epoch 41; iter: 0; batch classifier loss: 0.489467; batch adversarial loss: 0.544342\n",
      "epoch 42; iter: 0; batch classifier loss: 0.420413; batch adversarial loss: 0.642593\n",
      "epoch 43; iter: 0; batch classifier loss: 0.489623; batch adversarial loss: 0.489983\n",
      "epoch 44; iter: 0; batch classifier loss: 0.445952; batch adversarial loss: 0.525357\n",
      "epoch 45; iter: 0; batch classifier loss: 0.364663; batch adversarial loss: 0.470828\n",
      "epoch 46; iter: 0; batch classifier loss: 0.505196; batch adversarial loss: 0.525870\n",
      "epoch 47; iter: 0; batch classifier loss: 0.422206; batch adversarial loss: 0.531699\n",
      "epoch 48; iter: 0; batch classifier loss: 0.401591; batch adversarial loss: 0.570831\n",
      "epoch 49; iter: 0; batch classifier loss: 0.470184; batch adversarial loss: 0.523398\n",
      "epoch 50; iter: 0; batch classifier loss: 0.462568; batch adversarial loss: 0.590749\n",
      "epoch 51; iter: 0; batch classifier loss: 0.421173; batch adversarial loss: 0.492053\n",
      "epoch 52; iter: 0; batch classifier loss: 0.469185; batch adversarial loss: 0.509643\n",
      "epoch 53; iter: 0; batch classifier loss: 0.495113; batch adversarial loss: 0.554417\n",
      "epoch 54; iter: 0; batch classifier loss: 0.387281; batch adversarial loss: 0.589068\n",
      "epoch 55; iter: 0; batch classifier loss: 0.487647; batch adversarial loss: 0.623141\n",
      "epoch 56; iter: 0; batch classifier loss: 0.386354; batch adversarial loss: 0.536033\n",
      "epoch 57; iter: 0; batch classifier loss: 0.510032; batch adversarial loss: 0.552725\n",
      "epoch 58; iter: 0; batch classifier loss: 0.421917; batch adversarial loss: 0.536123\n",
      "epoch 59; iter: 0; batch classifier loss: 0.420270; batch adversarial loss: 0.510172\n",
      "epoch 60; iter: 0; batch classifier loss: 0.401568; batch adversarial loss: 0.554807\n",
      "epoch 61; iter: 0; batch classifier loss: 0.501969; batch adversarial loss: 0.553656\n",
      "epoch 62; iter: 0; batch classifier loss: 0.381912; batch adversarial loss: 0.509289\n",
      "epoch 63; iter: 0; batch classifier loss: 0.279750; batch adversarial loss: 0.572024\n",
      "epoch 64; iter: 0; batch classifier loss: 0.397408; batch adversarial loss: 0.527271\n",
      "epoch 65; iter: 0; batch classifier loss: 0.360802; batch adversarial loss: 0.554085\n",
      "epoch 66; iter: 0; batch classifier loss: 0.474765; batch adversarial loss: 0.571744\n",
      "epoch 67; iter: 0; batch classifier loss: 0.439810; batch adversarial loss: 0.498848\n",
      "epoch 68; iter: 0; batch classifier loss: 0.333399; batch adversarial loss: 0.526662\n",
      "epoch 69; iter: 0; batch classifier loss: 0.359151; batch adversarial loss: 0.527050\n",
      "epoch 70; iter: 0; batch classifier loss: 0.407507; batch adversarial loss: 0.472470\n",
      "epoch 71; iter: 0; batch classifier loss: 0.344163; batch adversarial loss: 0.607331\n",
      "epoch 72; iter: 0; batch classifier loss: 0.398263; batch adversarial loss: 0.570953\n",
      "epoch 73; iter: 0; batch classifier loss: 0.397532; batch adversarial loss: 0.571178\n",
      "epoch 74; iter: 0; batch classifier loss: 0.418579; batch adversarial loss: 0.554287\n",
      "epoch 75; iter: 0; batch classifier loss: 0.433001; batch adversarial loss: 0.526451\n",
      "epoch 76; iter: 0; batch classifier loss: 0.455092; batch adversarial loss: 0.615735\n",
      "epoch 77; iter: 0; batch classifier loss: 0.409704; batch adversarial loss: 0.553844\n",
      "epoch 78; iter: 0; batch classifier loss: 0.424975; batch adversarial loss: 0.545825\n",
      "epoch 79; iter: 0; batch classifier loss: 0.356206; batch adversarial loss: 0.589199\n",
      "epoch 80; iter: 0; batch classifier loss: 0.414217; batch adversarial loss: 0.526403\n",
      "epoch 81; iter: 0; batch classifier loss: 0.346160; batch adversarial loss: 0.534846\n",
      "epoch 82; iter: 0; batch classifier loss: 0.406311; batch adversarial loss: 0.536003\n",
      "epoch 83; iter: 0; batch classifier loss: 0.384694; batch adversarial loss: 0.544453\n",
      "epoch 84; iter: 0; batch classifier loss: 0.413030; batch adversarial loss: 0.499629\n",
      "epoch 85; iter: 0; batch classifier loss: 0.328511; batch adversarial loss: 0.562175\n",
      "epoch 86; iter: 0; batch classifier loss: 0.437280; batch adversarial loss: 0.616165\n",
      "epoch 87; iter: 0; batch classifier loss: 0.414070; batch adversarial loss: 0.491017\n",
      "epoch 88; iter: 0; batch classifier loss: 0.377664; batch adversarial loss: 0.589656\n",
      "epoch 89; iter: 0; batch classifier loss: 0.348484; batch adversarial loss: 0.580791\n",
      "epoch 90; iter: 0; batch classifier loss: 0.369804; batch adversarial loss: 0.562678\n",
      "epoch 91; iter: 0; batch classifier loss: 0.413580; batch adversarial loss: 0.544143\n",
      "epoch 92; iter: 0; batch classifier loss: 0.290530; batch adversarial loss: 0.545212\n",
      "epoch 93; iter: 0; batch classifier loss: 0.366421; batch adversarial loss: 0.580673\n",
      "epoch 94; iter: 0; batch classifier loss: 0.307943; batch adversarial loss: 0.481251\n",
      "epoch 95; iter: 0; batch classifier loss: 0.421965; batch adversarial loss: 0.490946\n",
      "epoch 96; iter: 0; batch classifier loss: 0.386620; batch adversarial loss: 0.508321\n",
      "epoch 97; iter: 0; batch classifier loss: 0.316059; batch adversarial loss: 0.580600\n",
      "epoch 98; iter: 0; batch classifier loss: 0.386220; batch adversarial loss: 0.472376\n",
      "epoch 99; iter: 0; batch classifier loss: 0.385074; batch adversarial loss: 0.499483\n",
      "epoch 100; iter: 0; batch classifier loss: 0.393960; batch adversarial loss: 0.562440\n",
      "epoch 101; iter: 0; batch classifier loss: 0.418641; batch adversarial loss: 0.535799\n",
      "epoch 102; iter: 0; batch classifier loss: 0.370636; batch adversarial loss: 0.516889\n",
      "epoch 103; iter: 0; batch classifier loss: 0.426185; batch adversarial loss: 0.571664\n",
      "epoch 104; iter: 0; batch classifier loss: 0.325016; batch adversarial loss: 0.517407\n",
      "epoch 105; iter: 0; batch classifier loss: 0.368719; batch adversarial loss: 0.499159\n",
      "epoch 106; iter: 0; batch classifier loss: 0.317609; batch adversarial loss: 0.561283\n",
      "epoch 107; iter: 0; batch classifier loss: 0.450310; batch adversarial loss: 0.617261\n",
      "epoch 108; iter: 0; batch classifier loss: 0.326784; batch adversarial loss: 0.563366\n",
      "epoch 109; iter: 0; batch classifier loss: 0.414826; batch adversarial loss: 0.481351\n",
      "epoch 110; iter: 0; batch classifier loss: 0.306588; batch adversarial loss: 0.544875\n",
      "epoch 111; iter: 0; batch classifier loss: 0.445902; batch adversarial loss: 0.499975\n",
      "epoch 112; iter: 0; batch classifier loss: 0.364173; batch adversarial loss: 0.580680\n",
      "epoch 113; iter: 0; batch classifier loss: 0.384494; batch adversarial loss: 0.473523\n",
      "epoch 114; iter: 0; batch classifier loss: 0.380719; batch adversarial loss: 0.517033\n",
      "epoch 115; iter: 0; batch classifier loss: 0.327797; batch adversarial loss: 0.535934\n",
      "epoch 116; iter: 0; batch classifier loss: 0.468629; batch adversarial loss: 0.561388\n",
      "epoch 117; iter: 0; batch classifier loss: 0.503358; batch adversarial loss: 0.534602\n",
      "epoch 118; iter: 0; batch classifier loss: 0.316441; batch adversarial loss: 0.536177\n",
      "epoch 119; iter: 0; batch classifier loss: 0.350813; batch adversarial loss: 0.527116\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 120; iter: 0; batch classifier loss: 0.294244; batch adversarial loss: 0.589770\n",
      "epoch 121; iter: 0; batch classifier loss: 0.325328; batch adversarial loss: 0.562562\n",
      "epoch 122; iter: 0; batch classifier loss: 0.470931; batch adversarial loss: 0.499588\n",
      "epoch 123; iter: 0; batch classifier loss: 0.345345; batch adversarial loss: 0.490672\n",
      "epoch 124; iter: 0; batch classifier loss: 0.345406; batch adversarial loss: 0.588669\n",
      "epoch 125; iter: 0; batch classifier loss: 0.332229; batch adversarial loss: 0.581492\n",
      "epoch 126; iter: 0; batch classifier loss: 0.335270; batch adversarial loss: 0.499086\n",
      "epoch 127; iter: 0; batch classifier loss: 0.375442; batch adversarial loss: 0.509373\n",
      "epoch 128; iter: 0; batch classifier loss: 0.429926; batch adversarial loss: 0.481459\n",
      "epoch 129; iter: 0; batch classifier loss: 0.327062; batch adversarial loss: 0.572711\n",
      "epoch 130; iter: 0; batch classifier loss: 0.362919; batch adversarial loss: 0.544352\n",
      "epoch 131; iter: 0; batch classifier loss: 0.485521; batch adversarial loss: 0.571381\n",
      "epoch 132; iter: 0; batch classifier loss: 0.399529; batch adversarial loss: 0.545242\n",
      "epoch 133; iter: 0; batch classifier loss: 0.297696; batch adversarial loss: 0.462619\n",
      "epoch 134; iter: 0; batch classifier loss: 0.305810; batch adversarial loss: 0.534825\n",
      "epoch 135; iter: 0; batch classifier loss: 0.358029; batch adversarial loss: 0.543636\n",
      "epoch 136; iter: 0; batch classifier loss: 0.404790; batch adversarial loss: 0.625297\n",
      "epoch 137; iter: 0; batch classifier loss: 0.426236; batch adversarial loss: 0.562281\n",
      "epoch 138; iter: 0; batch classifier loss: 0.357938; batch adversarial loss: 0.544135\n",
      "epoch 139; iter: 0; batch classifier loss: 0.395749; batch adversarial loss: 0.580221\n",
      "epoch 140; iter: 0; batch classifier loss: 0.392917; batch adversarial loss: 0.652511\n",
      "epoch 141; iter: 0; batch classifier loss: 0.309590; batch adversarial loss: 0.518111\n",
      "epoch 142; iter: 0; batch classifier loss: 0.338094; batch adversarial loss: 0.499145\n",
      "epoch 143; iter: 0; batch classifier loss: 0.346238; batch adversarial loss: 0.571899\n",
      "epoch 144; iter: 0; batch classifier loss: 0.329436; batch adversarial loss: 0.534934\n",
      "epoch 145; iter: 0; batch classifier loss: 0.301657; batch adversarial loss: 0.526708\n",
      "epoch 146; iter: 0; batch classifier loss: 0.377136; batch adversarial loss: 0.526332\n",
      "epoch 147; iter: 0; batch classifier loss: 0.220574; batch adversarial loss: 0.534735\n",
      "epoch 148; iter: 0; batch classifier loss: 0.427868; batch adversarial loss: 0.571529\n",
      "epoch 149; iter: 0; batch classifier loss: 0.338400; batch adversarial loss: 0.553954\n",
      "epoch 150; iter: 0; batch classifier loss: 0.337556; batch adversarial loss: 0.553162\n",
      "epoch 151; iter: 0; batch classifier loss: 0.313965; batch adversarial loss: 0.526409\n",
      "epoch 152; iter: 0; batch classifier loss: 0.315001; batch adversarial loss: 0.544185\n",
      "epoch 153; iter: 0; batch classifier loss: 0.327636; batch adversarial loss: 0.535512\n",
      "epoch 154; iter: 0; batch classifier loss: 0.357869; batch adversarial loss: 0.580001\n",
      "epoch 155; iter: 0; batch classifier loss: 0.380127; batch adversarial loss: 0.535550\n",
      "epoch 156; iter: 0; batch classifier loss: 0.330606; batch adversarial loss: 0.589799\n",
      "epoch 157; iter: 0; batch classifier loss: 0.404516; batch adversarial loss: 0.535859\n",
      "epoch 158; iter: 0; batch classifier loss: 0.329857; batch adversarial loss: 0.527185\n",
      "epoch 159; iter: 0; batch classifier loss: 0.395095; batch adversarial loss: 0.589321\n",
      "epoch 160; iter: 0; batch classifier loss: 0.292311; batch adversarial loss: 0.570956\n",
      "epoch 161; iter: 0; batch classifier loss: 0.300006; batch adversarial loss: 0.589841\n",
      "epoch 162; iter: 0; batch classifier loss: 0.350465; batch adversarial loss: 0.599437\n",
      "epoch 163; iter: 0; batch classifier loss: 0.367191; batch adversarial loss: 0.544542\n",
      "epoch 164; iter: 0; batch classifier loss: 0.323046; batch adversarial loss: 0.508523\n",
      "epoch 165; iter: 0; batch classifier loss: 0.368331; batch adversarial loss: 0.616383\n",
      "epoch 166; iter: 0; batch classifier loss: 0.380034; batch adversarial loss: 0.508946\n",
      "epoch 167; iter: 0; batch classifier loss: 0.284679; batch adversarial loss: 0.535145\n",
      "epoch 168; iter: 0; batch classifier loss: 0.379690; batch adversarial loss: 0.535797\n",
      "epoch 169; iter: 0; batch classifier loss: 0.260090; batch adversarial loss: 0.526294\n",
      "epoch 170; iter: 0; batch classifier loss: 0.403006; batch adversarial loss: 0.552925\n",
      "epoch 171; iter: 0; batch classifier loss: 0.378812; batch adversarial loss: 0.571377\n",
      "epoch 172; iter: 0; batch classifier loss: 0.407435; batch adversarial loss: 0.544768\n",
      "epoch 173; iter: 0; batch classifier loss: 0.338522; batch adversarial loss: 0.563235\n",
      "epoch 174; iter: 0; batch classifier loss: 0.364379; batch adversarial loss: 0.500361\n",
      "epoch 175; iter: 0; batch classifier loss: 0.416712; batch adversarial loss: 0.598242\n",
      "epoch 176; iter: 0; batch classifier loss: 0.376849; batch adversarial loss: 0.517850\n",
      "epoch 177; iter: 0; batch classifier loss: 0.369774; batch adversarial loss: 0.526085\n",
      "epoch 178; iter: 0; batch classifier loss: 0.427519; batch adversarial loss: 0.571991\n",
      "epoch 179; iter: 0; batch classifier loss: 0.327640; batch adversarial loss: 0.482233\n",
      "epoch 180; iter: 0; batch classifier loss: 0.340620; batch adversarial loss: 0.516754\n",
      "epoch 181; iter: 0; batch classifier loss: 0.360027; batch adversarial loss: 0.526048\n",
      "epoch 182; iter: 0; batch classifier loss: 0.349552; batch adversarial loss: 0.562414\n",
      "epoch 183; iter: 0; batch classifier loss: 0.440870; batch adversarial loss: 0.553870\n",
      "epoch 184; iter: 0; batch classifier loss: 0.331156; batch adversarial loss: 0.544548\n",
      "epoch 185; iter: 0; batch classifier loss: 0.288766; batch adversarial loss: 0.499666\n",
      "epoch 186; iter: 0; batch classifier loss: 0.375594; batch adversarial loss: 0.589635\n",
      "epoch 187; iter: 0; batch classifier loss: 0.325558; batch adversarial loss: 0.516649\n",
      "epoch 188; iter: 0; batch classifier loss: 0.382815; batch adversarial loss: 0.554504\n",
      "epoch 189; iter: 0; batch classifier loss: 0.391016; batch adversarial loss: 0.635240\n",
      "epoch 190; iter: 0; batch classifier loss: 0.333440; batch adversarial loss: 0.589437\n",
      "epoch 191; iter: 0; batch classifier loss: 0.426679; batch adversarial loss: 0.553945\n",
      "epoch 192; iter: 0; batch classifier loss: 0.297911; batch adversarial loss: 0.480895\n",
      "epoch 193; iter: 0; batch classifier loss: 0.369337; batch adversarial loss: 0.535606\n",
      "epoch 194; iter: 0; batch classifier loss: 0.404703; batch adversarial loss: 0.572038\n",
      "epoch 195; iter: 0; batch classifier loss: 0.406293; batch adversarial loss: 0.553554\n",
      "epoch 196; iter: 0; batch classifier loss: 0.374518; batch adversarial loss: 0.498353\n",
      "epoch 197; iter: 0; batch classifier loss: 0.328993; batch adversarial loss: 0.624758\n",
      "epoch 198; iter: 0; batch classifier loss: 0.362916; batch adversarial loss: 0.607750\n",
      "epoch 199; iter: 0; batch classifier loss: 0.343980; batch adversarial loss: 0.562957\n",
      "epoch 0; iter: 0; batch classifier loss: 0.679848; batch adversarial loss: 0.966817\n",
      "epoch 1; iter: 0; batch classifier loss: 0.881392; batch adversarial loss: 1.253822\n",
      "epoch 2; iter: 0; batch classifier loss: 1.008617; batch adversarial loss: 1.162413\n",
      "epoch 3; iter: 0; batch classifier loss: 1.022998; batch adversarial loss: 1.117809\n",
      "epoch 4; iter: 0; batch classifier loss: 1.171972; batch adversarial loss: 1.069081\n",
      "epoch 5; iter: 0; batch classifier loss: 0.979114; batch adversarial loss: 0.928884\n",
      "epoch 6; iter: 0; batch classifier loss: 1.059597; batch adversarial loss: 0.884519\n",
      "epoch 7; iter: 0; batch classifier loss: 1.128344; batch adversarial loss: 0.848635\n",
      "epoch 8; iter: 0; batch classifier loss: 0.960636; batch adversarial loss: 0.730173\n",
      "epoch 9; iter: 0; batch classifier loss: 0.919808; batch adversarial loss: 0.741314\n",
      "epoch 10; iter: 0; batch classifier loss: 0.859108; batch adversarial loss: 0.656811\n",
      "epoch 11; iter: 0; batch classifier loss: 0.650121; batch adversarial loss: 0.617930\n",
      "epoch 12; iter: 0; batch classifier loss: 0.564498; batch adversarial loss: 0.585664\n",
      "epoch 13; iter: 0; batch classifier loss: 0.598882; batch adversarial loss: 0.582649\n",
      "epoch 14; iter: 0; batch classifier loss: 0.552089; batch adversarial loss: 0.589975\n",
      "epoch 15; iter: 0; batch classifier loss: 0.477210; batch adversarial loss: 0.549977\n",
      "epoch 16; iter: 0; batch classifier loss: 0.523926; batch adversarial loss: 0.619156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 17; iter: 0; batch classifier loss: 0.519404; batch adversarial loss: 0.584050\n",
      "epoch 18; iter: 0; batch classifier loss: 0.554474; batch adversarial loss: 0.513084\n",
      "epoch 19; iter: 0; batch classifier loss: 0.612120; batch adversarial loss: 0.557384\n",
      "epoch 20; iter: 0; batch classifier loss: 0.512614; batch adversarial loss: 0.554035\n",
      "epoch 21; iter: 0; batch classifier loss: 0.548176; batch adversarial loss: 0.619683\n",
      "epoch 22; iter: 0; batch classifier loss: 0.533630; batch adversarial loss: 0.630013\n",
      "epoch 23; iter: 0; batch classifier loss: 0.496145; batch adversarial loss: 0.578357\n",
      "epoch 24; iter: 0; batch classifier loss: 0.516976; batch adversarial loss: 0.534980\n",
      "epoch 25; iter: 0; batch classifier loss: 0.467168; batch adversarial loss: 0.547634\n",
      "epoch 26; iter: 0; batch classifier loss: 0.474287; batch adversarial loss: 0.591347\n",
      "epoch 27; iter: 0; batch classifier loss: 0.479041; batch adversarial loss: 0.525869\n",
      "epoch 28; iter: 0; batch classifier loss: 0.480775; batch adversarial loss: 0.524691\n",
      "epoch 29; iter: 0; batch classifier loss: 0.552096; batch adversarial loss: 0.591522\n",
      "epoch 30; iter: 0; batch classifier loss: 0.489348; batch adversarial loss: 0.541537\n",
      "epoch 31; iter: 0; batch classifier loss: 0.588532; batch adversarial loss: 0.517270\n",
      "epoch 32; iter: 0; batch classifier loss: 0.471615; batch adversarial loss: 0.562364\n",
      "epoch 33; iter: 0; batch classifier loss: 0.437251; batch adversarial loss: 0.574378\n",
      "epoch 34; iter: 0; batch classifier loss: 0.406496; batch adversarial loss: 0.532809\n",
      "epoch 35; iter: 0; batch classifier loss: 0.512390; batch adversarial loss: 0.526329\n",
      "epoch 36; iter: 0; batch classifier loss: 0.464097; batch adversarial loss: 0.477747\n",
      "epoch 37; iter: 0; batch classifier loss: 0.410000; batch adversarial loss: 0.559856\n",
      "epoch 38; iter: 0; batch classifier loss: 0.438034; batch adversarial loss: 0.599387\n",
      "epoch 39; iter: 0; batch classifier loss: 0.448900; batch adversarial loss: 0.539311\n",
      "epoch 40; iter: 0; batch classifier loss: 0.488503; batch adversarial loss: 0.591054\n",
      "epoch 41; iter: 0; batch classifier loss: 0.438189; batch adversarial loss: 0.599032\n",
      "epoch 42; iter: 0; batch classifier loss: 0.461566; batch adversarial loss: 0.560258\n",
      "epoch 43; iter: 0; batch classifier loss: 0.392557; batch adversarial loss: 0.442944\n",
      "epoch 44; iter: 0; batch classifier loss: 0.447444; batch adversarial loss: 0.606639\n",
      "epoch 45; iter: 0; batch classifier loss: 0.404628; batch adversarial loss: 0.519337\n",
      "epoch 46; iter: 0; batch classifier loss: 0.538290; batch adversarial loss: 0.537853\n",
      "epoch 47; iter: 0; batch classifier loss: 0.426443; batch adversarial loss: 0.494348\n",
      "epoch 48; iter: 0; batch classifier loss: 0.430670; batch adversarial loss: 0.502570\n",
      "epoch 49; iter: 0; batch classifier loss: 0.460031; batch adversarial loss: 0.503565\n",
      "epoch 50; iter: 0; batch classifier loss: 0.430370; batch adversarial loss: 0.545813\n",
      "epoch 51; iter: 0; batch classifier loss: 0.414082; batch adversarial loss: 0.509816\n",
      "epoch 52; iter: 0; batch classifier loss: 0.469715; batch adversarial loss: 0.608278\n",
      "epoch 53; iter: 0; batch classifier loss: 0.441909; batch adversarial loss: 0.512350\n",
      "epoch 54; iter: 0; batch classifier loss: 0.474399; batch adversarial loss: 0.511745\n",
      "epoch 55; iter: 0; batch classifier loss: 0.431679; batch adversarial loss: 0.571832\n",
      "epoch 56; iter: 0; batch classifier loss: 0.448473; batch adversarial loss: 0.528144\n",
      "epoch 57; iter: 0; batch classifier loss: 0.420125; batch adversarial loss: 0.677392\n",
      "epoch 58; iter: 0; batch classifier loss: 0.429177; batch adversarial loss: 0.464778\n",
      "epoch 59; iter: 0; batch classifier loss: 0.458076; batch adversarial loss: 0.508213\n",
      "epoch 60; iter: 0; batch classifier loss: 0.455631; batch adversarial loss: 0.640288\n",
      "epoch 61; iter: 0; batch classifier loss: 0.430441; batch adversarial loss: 0.544854\n",
      "epoch 62; iter: 0; batch classifier loss: 0.418027; batch adversarial loss: 0.615029\n",
      "epoch 63; iter: 0; batch classifier loss: 0.393766; batch adversarial loss: 0.536968\n",
      "epoch 64; iter: 0; batch classifier loss: 0.406987; batch adversarial loss: 0.518246\n",
      "epoch 65; iter: 0; batch classifier loss: 0.439763; batch adversarial loss: 0.575189\n",
      "epoch 66; iter: 0; batch classifier loss: 0.397654; batch adversarial loss: 0.544830\n",
      "epoch 67; iter: 0; batch classifier loss: 0.406825; batch adversarial loss: 0.591121\n",
      "epoch 68; iter: 0; batch classifier loss: 0.458356; batch adversarial loss: 0.526414\n",
      "epoch 69; iter: 0; batch classifier loss: 0.396610; batch adversarial loss: 0.579831\n",
      "epoch 70; iter: 0; batch classifier loss: 0.379983; batch adversarial loss: 0.562310\n",
      "epoch 71; iter: 0; batch classifier loss: 0.387622; batch adversarial loss: 0.543936\n",
      "epoch 72; iter: 0; batch classifier loss: 0.425716; batch adversarial loss: 0.587826\n",
      "epoch 73; iter: 0; batch classifier loss: 0.407958; batch adversarial loss: 0.572563\n",
      "epoch 74; iter: 0; batch classifier loss: 0.399201; batch adversarial loss: 0.543424\n",
      "epoch 75; iter: 0; batch classifier loss: 0.285301; batch adversarial loss: 0.501506\n",
      "epoch 76; iter: 0; batch classifier loss: 0.344973; batch adversarial loss: 0.645064\n",
      "epoch 77; iter: 0; batch classifier loss: 0.388881; batch adversarial loss: 0.667989\n",
      "epoch 78; iter: 0; batch classifier loss: 0.391820; batch adversarial loss: 0.516027\n",
      "epoch 79; iter: 0; batch classifier loss: 0.314211; batch adversarial loss: 0.505941\n",
      "epoch 80; iter: 0; batch classifier loss: 0.410643; batch adversarial loss: 0.574300\n",
      "epoch 81; iter: 0; batch classifier loss: 0.381511; batch adversarial loss: 0.481052\n",
      "epoch 82; iter: 0; batch classifier loss: 0.364150; batch adversarial loss: 0.634735\n",
      "epoch 83; iter: 0; batch classifier loss: 0.308267; batch adversarial loss: 0.542208\n",
      "epoch 84; iter: 0; batch classifier loss: 0.363879; batch adversarial loss: 0.486908\n",
      "epoch 85; iter: 0; batch classifier loss: 0.335622; batch adversarial loss: 0.534077\n",
      "epoch 86; iter: 0; batch classifier loss: 0.349828; batch adversarial loss: 0.584243\n",
      "epoch 87; iter: 0; batch classifier loss: 0.368842; batch adversarial loss: 0.512322\n",
      "epoch 88; iter: 0; batch classifier loss: 0.387407; batch adversarial loss: 0.580741\n",
      "epoch 89; iter: 0; batch classifier loss: 0.351920; batch adversarial loss: 0.582305\n",
      "epoch 90; iter: 0; batch classifier loss: 0.408803; batch adversarial loss: 0.589880\n",
      "epoch 91; iter: 0; batch classifier loss: 0.375824; batch adversarial loss: 0.499420\n",
      "epoch 92; iter: 0; batch classifier loss: 0.359375; batch adversarial loss: 0.522051\n",
      "epoch 93; iter: 0; batch classifier loss: 0.398319; batch adversarial loss: 0.671721\n",
      "epoch 94; iter: 0; batch classifier loss: 0.387132; batch adversarial loss: 0.600127\n",
      "epoch 95; iter: 0; batch classifier loss: 0.327567; batch adversarial loss: 0.550094\n",
      "epoch 96; iter: 0; batch classifier loss: 0.332415; batch adversarial loss: 0.490232\n",
      "epoch 97; iter: 0; batch classifier loss: 0.315991; batch adversarial loss: 0.492794\n",
      "epoch 98; iter: 0; batch classifier loss: 0.373294; batch adversarial loss: 0.480411\n",
      "epoch 99; iter: 0; batch classifier loss: 0.444114; batch adversarial loss: 0.566468\n",
      "epoch 100; iter: 0; batch classifier loss: 0.397457; batch adversarial loss: 0.566413\n",
      "epoch 101; iter: 0; batch classifier loss: 0.356652; batch adversarial loss: 0.579176\n",
      "epoch 102; iter: 0; batch classifier loss: 0.382355; batch adversarial loss: 0.605862\n",
      "epoch 103; iter: 0; batch classifier loss: 0.364758; batch adversarial loss: 0.590193\n",
      "epoch 104; iter: 0; batch classifier loss: 0.436677; batch adversarial loss: 0.514396\n",
      "epoch 105; iter: 0; batch classifier loss: 0.370553; batch adversarial loss: 0.516504\n",
      "epoch 106; iter: 0; batch classifier loss: 0.408945; batch adversarial loss: 0.586986\n",
      "epoch 107; iter: 0; batch classifier loss: 0.391735; batch adversarial loss: 0.495899\n",
      "epoch 108; iter: 0; batch classifier loss: 0.386693; batch adversarial loss: 0.582920\n",
      "epoch 109; iter: 0; batch classifier loss: 0.386745; batch adversarial loss: 0.550230\n",
      "epoch 110; iter: 0; batch classifier loss: 0.338926; batch adversarial loss: 0.567357\n",
      "epoch 111; iter: 0; batch classifier loss: 0.379907; batch adversarial loss: 0.611430\n",
      "epoch 112; iter: 0; batch classifier loss: 0.374052; batch adversarial loss: 0.543857\n",
      "epoch 113; iter: 0; batch classifier loss: 0.340568; batch adversarial loss: 0.525747\n",
      "epoch 114; iter: 0; batch classifier loss: 0.409600; batch adversarial loss: 0.543139\n",
      "epoch 115; iter: 0; batch classifier loss: 0.420144; batch adversarial loss: 0.463846\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 116; iter: 0; batch classifier loss: 0.450770; batch adversarial loss: 0.541246\n",
      "epoch 117; iter: 0; batch classifier loss: 0.391896; batch adversarial loss: 0.545210\n",
      "epoch 118; iter: 0; batch classifier loss: 0.340009; batch adversarial loss: 0.497058\n",
      "epoch 119; iter: 0; batch classifier loss: 0.340391; batch adversarial loss: 0.492404\n",
      "epoch 120; iter: 0; batch classifier loss: 0.327370; batch adversarial loss: 0.577682\n",
      "epoch 121; iter: 0; batch classifier loss: 0.331573; batch adversarial loss: 0.606853\n",
      "epoch 122; iter: 0; batch classifier loss: 0.361029; batch adversarial loss: 0.580554\n",
      "epoch 123; iter: 0; batch classifier loss: 0.312943; batch adversarial loss: 0.505160\n",
      "epoch 124; iter: 0; batch classifier loss: 0.392932; batch adversarial loss: 0.543548\n",
      "epoch 125; iter: 0; batch classifier loss: 0.418837; batch adversarial loss: 0.473792\n",
      "epoch 126; iter: 0; batch classifier loss: 0.392189; batch adversarial loss: 0.552482\n",
      "epoch 127; iter: 0; batch classifier loss: 0.365747; batch adversarial loss: 0.554074\n",
      "epoch 128; iter: 0; batch classifier loss: 0.372947; batch adversarial loss: 0.534683\n",
      "epoch 129; iter: 0; batch classifier loss: 0.390315; batch adversarial loss: 0.572110\n",
      "epoch 130; iter: 0; batch classifier loss: 0.359833; batch adversarial loss: 0.541248\n",
      "epoch 131; iter: 0; batch classifier loss: 0.312987; batch adversarial loss: 0.544739\n",
      "epoch 132; iter: 0; batch classifier loss: 0.332499; batch adversarial loss: 0.531236\n",
      "epoch 133; iter: 0; batch classifier loss: 0.302778; batch adversarial loss: 0.527886\n",
      "epoch 134; iter: 0; batch classifier loss: 0.349933; batch adversarial loss: 0.559088\n",
      "epoch 135; iter: 0; batch classifier loss: 0.321613; batch adversarial loss: 0.547032\n",
      "epoch 136; iter: 0; batch classifier loss: 0.389713; batch adversarial loss: 0.624914\n",
      "epoch 137; iter: 0; batch classifier loss: 0.446699; batch adversarial loss: 0.513095\n",
      "epoch 138; iter: 0; batch classifier loss: 0.324369; batch adversarial loss: 0.540009\n",
      "epoch 139; iter: 0; batch classifier loss: 0.358430; batch adversarial loss: 0.471660\n",
      "epoch 140; iter: 0; batch classifier loss: 0.386852; batch adversarial loss: 0.528295\n",
      "epoch 141; iter: 0; batch classifier loss: 0.413841; batch adversarial loss: 0.568756\n",
      "epoch 142; iter: 0; batch classifier loss: 0.365963; batch adversarial loss: 0.522272\n",
      "epoch 143; iter: 0; batch classifier loss: 0.336757; batch adversarial loss: 0.536836\n",
      "epoch 144; iter: 0; batch classifier loss: 0.297807; batch adversarial loss: 0.527215\n",
      "epoch 145; iter: 0; batch classifier loss: 0.369011; batch adversarial loss: 0.517581\n",
      "epoch 146; iter: 0; batch classifier loss: 0.393348; batch adversarial loss: 0.539880\n",
      "epoch 147; iter: 0; batch classifier loss: 0.466677; batch adversarial loss: 0.555747\n",
      "epoch 148; iter: 0; batch classifier loss: 0.351491; batch adversarial loss: 0.583045\n",
      "epoch 149; iter: 0; batch classifier loss: 0.314688; batch adversarial loss: 0.548637\n",
      "epoch 150; iter: 0; batch classifier loss: 0.383128; batch adversarial loss: 0.499342\n",
      "epoch 151; iter: 0; batch classifier loss: 0.261657; batch adversarial loss: 0.574295\n",
      "epoch 152; iter: 0; batch classifier loss: 0.312156; batch adversarial loss: 0.511083\n",
      "epoch 153; iter: 0; batch classifier loss: 0.361907; batch adversarial loss: 0.598300\n",
      "epoch 154; iter: 0; batch classifier loss: 0.317674; batch adversarial loss: 0.521300\n",
      "epoch 155; iter: 0; batch classifier loss: 0.300320; batch adversarial loss: 0.494587\n",
      "epoch 156; iter: 0; batch classifier loss: 0.325467; batch adversarial loss: 0.566553\n",
      "epoch 157; iter: 0; batch classifier loss: 0.308818; batch adversarial loss: 0.637865\n",
      "epoch 158; iter: 0; batch classifier loss: 0.404141; batch adversarial loss: 0.551391\n",
      "epoch 159; iter: 0; batch classifier loss: 0.376195; batch adversarial loss: 0.525237\n",
      "epoch 160; iter: 0; batch classifier loss: 0.300281; batch adversarial loss: 0.509173\n",
      "epoch 161; iter: 0; batch classifier loss: 0.333536; batch adversarial loss: 0.617957\n",
      "epoch 162; iter: 0; batch classifier loss: 0.301655; batch adversarial loss: 0.592876\n",
      "epoch 163; iter: 0; batch classifier loss: 0.335162; batch adversarial loss: 0.552266\n",
      "epoch 164; iter: 0; batch classifier loss: 0.366667; batch adversarial loss: 0.552607\n",
      "epoch 165; iter: 0; batch classifier loss: 0.249879; batch adversarial loss: 0.590981\n",
      "epoch 166; iter: 0; batch classifier loss: 0.450631; batch adversarial loss: 0.519329\n",
      "epoch 167; iter: 0; batch classifier loss: 0.290242; batch adversarial loss: 0.484885\n",
      "epoch 168; iter: 0; batch classifier loss: 0.334641; batch adversarial loss: 0.514966\n",
      "epoch 169; iter: 0; batch classifier loss: 0.309392; batch adversarial loss: 0.556887\n",
      "epoch 170; iter: 0; batch classifier loss: 0.322849; batch adversarial loss: 0.530401\n",
      "epoch 171; iter: 0; batch classifier loss: 0.280148; batch adversarial loss: 0.477589\n",
      "epoch 172; iter: 0; batch classifier loss: 0.284408; batch adversarial loss: 0.532392\n",
      "epoch 173; iter: 0; batch classifier loss: 0.274443; batch adversarial loss: 0.477535\n",
      "epoch 174; iter: 0; batch classifier loss: 0.318976; batch adversarial loss: 0.542704\n",
      "epoch 175; iter: 0; batch classifier loss: 0.382480; batch adversarial loss: 0.472727\n",
      "epoch 176; iter: 0; batch classifier loss: 0.357798; batch adversarial loss: 0.600981\n",
      "epoch 177; iter: 0; batch classifier loss: 0.414213; batch adversarial loss: 0.584594\n",
      "epoch 178; iter: 0; batch classifier loss: 0.299454; batch adversarial loss: 0.551892\n",
      "epoch 179; iter: 0; batch classifier loss: 0.321504; batch adversarial loss: 0.564151\n",
      "epoch 180; iter: 0; batch classifier loss: 0.294548; batch adversarial loss: 0.565225\n",
      "epoch 181; iter: 0; batch classifier loss: 0.294561; batch adversarial loss: 0.552183\n",
      "epoch 182; iter: 0; batch classifier loss: 0.437005; batch adversarial loss: 0.520388\n",
      "epoch 183; iter: 0; batch classifier loss: 0.449388; batch adversarial loss: 0.580988\n",
      "epoch 184; iter: 0; batch classifier loss: 0.304265; batch adversarial loss: 0.615271\n",
      "epoch 185; iter: 0; batch classifier loss: 0.393238; batch adversarial loss: 0.568645\n",
      "epoch 186; iter: 0; batch classifier loss: 0.281125; batch adversarial loss: 0.526361\n",
      "epoch 187; iter: 0; batch classifier loss: 0.322668; batch adversarial loss: 0.517287\n",
      "epoch 188; iter: 0; batch classifier loss: 0.269849; batch adversarial loss: 0.596210\n",
      "epoch 189; iter: 0; batch classifier loss: 0.351382; batch adversarial loss: 0.506243\n",
      "epoch 190; iter: 0; batch classifier loss: 0.356216; batch adversarial loss: 0.607398\n",
      "epoch 191; iter: 0; batch classifier loss: 0.340311; batch adversarial loss: 0.511769\n",
      "epoch 192; iter: 0; batch classifier loss: 0.299056; batch adversarial loss: 0.562592\n",
      "epoch 193; iter: 0; batch classifier loss: 0.385040; batch adversarial loss: 0.625778\n",
      "epoch 194; iter: 0; batch classifier loss: 0.258557; batch adversarial loss: 0.570549\n",
      "epoch 195; iter: 0; batch classifier loss: 0.295567; batch adversarial loss: 0.561060\n",
      "epoch 196; iter: 0; batch classifier loss: 0.315161; batch adversarial loss: 0.545234\n",
      "epoch 197; iter: 0; batch classifier loss: 0.350464; batch adversarial loss: 0.656898\n",
      "epoch 198; iter: 0; batch classifier loss: 0.356113; batch adversarial loss: 0.602622\n",
      "epoch 199; iter: 0; batch classifier loss: 0.278449; batch adversarial loss: 0.489820\n",
      "epoch 0; iter: 0; batch classifier loss: 0.672755; batch adversarial loss: 0.788071\n",
      "epoch 1; iter: 0; batch classifier loss: 0.658209; batch adversarial loss: 0.915406\n",
      "epoch 2; iter: 0; batch classifier loss: 0.660509; batch adversarial loss: 0.801999\n",
      "epoch 3; iter: 0; batch classifier loss: 0.647117; batch adversarial loss: 0.757946\n",
      "epoch 4; iter: 0; batch classifier loss: 0.568587; batch adversarial loss: 0.701383\n",
      "epoch 5; iter: 0; batch classifier loss: 0.587793; batch adversarial loss: 0.673425\n",
      "epoch 6; iter: 0; batch classifier loss: 0.598997; batch adversarial loss: 0.655307\n",
      "epoch 7; iter: 0; batch classifier loss: 0.557058; batch adversarial loss: 0.633112\n",
      "epoch 8; iter: 0; batch classifier loss: 0.514398; batch adversarial loss: 0.639452\n",
      "epoch 9; iter: 0; batch classifier loss: 0.542430; batch adversarial loss: 0.614078\n",
      "epoch 10; iter: 0; batch classifier loss: 0.528708; batch adversarial loss: 0.587210\n",
      "epoch 11; iter: 0; batch classifier loss: 0.590803; batch adversarial loss: 0.594759\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12; iter: 0; batch classifier loss: 0.533185; batch adversarial loss: 0.605413\n",
      "epoch 13; iter: 0; batch classifier loss: 0.520303; batch adversarial loss: 0.584387\n",
      "epoch 14; iter: 0; batch classifier loss: 0.526701; batch adversarial loss: 0.556402\n",
      "epoch 15; iter: 0; batch classifier loss: 0.485052; batch adversarial loss: 0.580887\n",
      "epoch 16; iter: 0; batch classifier loss: 0.513452; batch adversarial loss: 0.620964\n",
      "epoch 17; iter: 0; batch classifier loss: 0.523223; batch adversarial loss: 0.518343\n",
      "epoch 18; iter: 0; batch classifier loss: 0.454371; batch adversarial loss: 0.603052\n",
      "epoch 19; iter: 0; batch classifier loss: 0.489966; batch adversarial loss: 0.571634\n",
      "epoch 20; iter: 0; batch classifier loss: 0.455051; batch adversarial loss: 0.550923\n",
      "epoch 21; iter: 0; batch classifier loss: 0.486327; batch adversarial loss: 0.578710\n",
      "epoch 22; iter: 0; batch classifier loss: 0.551478; batch adversarial loss: 0.495578\n",
      "epoch 23; iter: 0; batch classifier loss: 0.504561; batch adversarial loss: 0.606088\n",
      "epoch 24; iter: 0; batch classifier loss: 0.511231; batch adversarial loss: 0.583609\n",
      "epoch 25; iter: 0; batch classifier loss: 0.482499; batch adversarial loss: 0.471132\n",
      "epoch 26; iter: 0; batch classifier loss: 0.512449; batch adversarial loss: 0.564145\n",
      "epoch 27; iter: 0; batch classifier loss: 0.511600; batch adversarial loss: 0.539851\n",
      "epoch 28; iter: 0; batch classifier loss: 0.473754; batch adversarial loss: 0.563254\n",
      "epoch 29; iter: 0; batch classifier loss: 0.482611; batch adversarial loss: 0.552055\n",
      "epoch 30; iter: 0; batch classifier loss: 0.478619; batch adversarial loss: 0.569830\n",
      "epoch 31; iter: 0; batch classifier loss: 0.427420; batch adversarial loss: 0.556185\n",
      "epoch 32; iter: 0; batch classifier loss: 0.390414; batch adversarial loss: 0.551797\n",
      "epoch 33; iter: 0; batch classifier loss: 0.443573; batch adversarial loss: 0.539531\n",
      "epoch 34; iter: 0; batch classifier loss: 0.454500; batch adversarial loss: 0.514522\n",
      "epoch 35; iter: 0; batch classifier loss: 0.472567; batch adversarial loss: 0.606982\n",
      "epoch 36; iter: 0; batch classifier loss: 0.428898; batch adversarial loss: 0.608698\n",
      "epoch 37; iter: 0; batch classifier loss: 0.402516; batch adversarial loss: 0.577260\n",
      "epoch 38; iter: 0; batch classifier loss: 0.509148; batch adversarial loss: 0.531954\n",
      "epoch 39; iter: 0; batch classifier loss: 0.435197; batch adversarial loss: 0.554297\n",
      "epoch 40; iter: 0; batch classifier loss: 0.501257; batch adversarial loss: 0.570572\n",
      "epoch 41; iter: 0; batch classifier loss: 0.505059; batch adversarial loss: 0.524122\n",
      "epoch 42; iter: 0; batch classifier loss: 0.454126; batch adversarial loss: 0.509292\n",
      "epoch 43; iter: 0; batch classifier loss: 0.450726; batch adversarial loss: 0.590351\n",
      "epoch 44; iter: 0; batch classifier loss: 0.468954; batch adversarial loss: 0.554127\n",
      "epoch 45; iter: 0; batch classifier loss: 0.423838; batch adversarial loss: 0.571887\n",
      "epoch 46; iter: 0; batch classifier loss: 0.353204; batch adversarial loss: 0.557085\n",
      "epoch 47; iter: 0; batch classifier loss: 0.464564; batch adversarial loss: 0.509646\n",
      "epoch 48; iter: 0; batch classifier loss: 0.413021; batch adversarial loss: 0.501242\n",
      "epoch 49; iter: 0; batch classifier loss: 0.410397; batch adversarial loss: 0.562833\n",
      "epoch 50; iter: 0; batch classifier loss: 0.382470; batch adversarial loss: 0.487442\n",
      "epoch 51; iter: 0; batch classifier loss: 0.489051; batch adversarial loss: 0.534458\n",
      "epoch 52; iter: 0; batch classifier loss: 0.374601; batch adversarial loss: 0.496044\n",
      "epoch 53; iter: 0; batch classifier loss: 0.380991; batch adversarial loss: 0.516048\n",
      "epoch 54; iter: 0; batch classifier loss: 0.404852; batch adversarial loss: 0.508083\n",
      "epoch 55; iter: 0; batch classifier loss: 0.475812; batch adversarial loss: 0.534353\n",
      "epoch 56; iter: 0; batch classifier loss: 0.453587; batch adversarial loss: 0.578945\n",
      "epoch 57; iter: 0; batch classifier loss: 0.465906; batch adversarial loss: 0.507925\n",
      "epoch 58; iter: 0; batch classifier loss: 0.448214; batch adversarial loss: 0.480536\n",
      "epoch 59; iter: 0; batch classifier loss: 0.376667; batch adversarial loss: 0.498157\n",
      "epoch 60; iter: 0; batch classifier loss: 0.366373; batch adversarial loss: 0.588521\n",
      "epoch 61; iter: 0; batch classifier loss: 0.533557; batch adversarial loss: 0.535043\n",
      "epoch 62; iter: 0; batch classifier loss: 0.396774; batch adversarial loss: 0.527888\n",
      "epoch 63; iter: 0; batch classifier loss: 0.395365; batch adversarial loss: 0.582767\n",
      "epoch 64; iter: 0; batch classifier loss: 0.411071; batch adversarial loss: 0.571817\n",
      "epoch 65; iter: 0; batch classifier loss: 0.407541; batch adversarial loss: 0.479129\n",
      "epoch 66; iter: 0; batch classifier loss: 0.403271; batch adversarial loss: 0.479232\n",
      "epoch 67; iter: 0; batch classifier loss: 0.439322; batch adversarial loss: 0.592112\n",
      "epoch 68; iter: 0; batch classifier loss: 0.383249; batch adversarial loss: 0.526761\n",
      "epoch 69; iter: 0; batch classifier loss: 0.339159; batch adversarial loss: 0.573326\n",
      "epoch 70; iter: 0; batch classifier loss: 0.408891; batch adversarial loss: 0.600204\n",
      "epoch 71; iter: 0; batch classifier loss: 0.541319; batch adversarial loss: 0.525755\n",
      "epoch 72; iter: 0; batch classifier loss: 0.345295; batch adversarial loss: 0.535260\n",
      "epoch 73; iter: 0; batch classifier loss: 0.415914; batch adversarial loss: 0.497257\n",
      "epoch 74; iter: 0; batch classifier loss: 0.380258; batch adversarial loss: 0.554089\n",
      "epoch 75; iter: 0; batch classifier loss: 0.362882; batch adversarial loss: 0.488966\n",
      "epoch 76; iter: 0; batch classifier loss: 0.340051; batch adversarial loss: 0.554867\n",
      "epoch 77; iter: 0; batch classifier loss: 0.378244; batch adversarial loss: 0.507976\n",
      "epoch 78; iter: 0; batch classifier loss: 0.401752; batch adversarial loss: 0.490572\n",
      "epoch 79; iter: 0; batch classifier loss: 0.432944; batch adversarial loss: 0.459893\n",
      "epoch 80; iter: 0; batch classifier loss: 0.414425; batch adversarial loss: 0.526287\n",
      "epoch 81; iter: 0; batch classifier loss: 0.354221; batch adversarial loss: 0.583141\n",
      "epoch 82; iter: 0; batch classifier loss: 0.419661; batch adversarial loss: 0.507404\n",
      "epoch 83; iter: 0; batch classifier loss: 0.474250; batch adversarial loss: 0.542581\n",
      "epoch 84; iter: 0; batch classifier loss: 0.439856; batch adversarial loss: 0.562679\n",
      "epoch 85; iter: 0; batch classifier loss: 0.361087; batch adversarial loss: 0.470000\n",
      "epoch 86; iter: 0; batch classifier loss: 0.377721; batch adversarial loss: 0.527461\n",
      "epoch 87; iter: 0; batch classifier loss: 0.405207; batch adversarial loss: 0.515631\n",
      "epoch 88; iter: 0; batch classifier loss: 0.379845; batch adversarial loss: 0.534298\n",
      "epoch 89; iter: 0; batch classifier loss: 0.446271; batch adversarial loss: 0.590322\n",
      "epoch 90; iter: 0; batch classifier loss: 0.392058; batch adversarial loss: 0.469147\n",
      "epoch 91; iter: 0; batch classifier loss: 0.409824; batch adversarial loss: 0.516020\n",
      "epoch 92; iter: 0; batch classifier loss: 0.386982; batch adversarial loss: 0.578889\n",
      "epoch 93; iter: 0; batch classifier loss: 0.349512; batch adversarial loss: 0.535911\n",
      "epoch 94; iter: 0; batch classifier loss: 0.434775; batch adversarial loss: 0.423824\n",
      "epoch 95; iter: 0; batch classifier loss: 0.373599; batch adversarial loss: 0.534637\n",
      "epoch 96; iter: 0; batch classifier loss: 0.387354; batch adversarial loss: 0.626897\n",
      "epoch 97; iter: 0; batch classifier loss: 0.369440; batch adversarial loss: 0.507840\n",
      "epoch 98; iter: 0; batch classifier loss: 0.348604; batch adversarial loss: 0.562142\n",
      "epoch 99; iter: 0; batch classifier loss: 0.481521; batch adversarial loss: 0.451515\n",
      "epoch 100; iter: 0; batch classifier loss: 0.366073; batch adversarial loss: 0.629414\n",
      "epoch 101; iter: 0; batch classifier loss: 0.358550; batch adversarial loss: 0.562516\n",
      "epoch 102; iter: 0; batch classifier loss: 0.407499; batch adversarial loss: 0.534355\n",
      "epoch 103; iter: 0; batch classifier loss: 0.387325; batch adversarial loss: 0.526556\n",
      "epoch 104; iter: 0; batch classifier loss: 0.314282; batch adversarial loss: 0.571749\n",
      "epoch 105; iter: 0; batch classifier loss: 0.366654; batch adversarial loss: 0.581267\n",
      "epoch 106; iter: 0; batch classifier loss: 0.383482; batch adversarial loss: 0.526398\n",
      "epoch 107; iter: 0; batch classifier loss: 0.402822; batch adversarial loss: 0.626925\n",
      "epoch 108; iter: 0; batch classifier loss: 0.395329; batch adversarial loss: 0.573420\n",
      "epoch 109; iter: 0; batch classifier loss: 0.322009; batch adversarial loss: 0.562405\n",
      "epoch 110; iter: 0; batch classifier loss: 0.395093; batch adversarial loss: 0.545259\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 111; iter: 0; batch classifier loss: 0.478743; batch adversarial loss: 0.477897\n",
      "epoch 112; iter: 0; batch classifier loss: 0.360631; batch adversarial loss: 0.572967\n",
      "epoch 113; iter: 0; batch classifier loss: 0.314453; batch adversarial loss: 0.463014\n",
      "epoch 114; iter: 0; batch classifier loss: 0.458523; batch adversarial loss: 0.488584\n",
      "epoch 115; iter: 0; batch classifier loss: 0.416553; batch adversarial loss: 0.534548\n",
      "epoch 116; iter: 0; batch classifier loss: 0.392859; batch adversarial loss: 0.564405\n",
      "epoch 117; iter: 0; batch classifier loss: 0.351751; batch adversarial loss: 0.581650\n",
      "epoch 118; iter: 0; batch classifier loss: 0.383658; batch adversarial loss: 0.499447\n",
      "epoch 119; iter: 0; batch classifier loss: 0.364061; batch adversarial loss: 0.553185\n",
      "epoch 120; iter: 0; batch classifier loss: 0.312549; batch adversarial loss: 0.504961\n",
      "epoch 121; iter: 0; batch classifier loss: 0.411729; batch adversarial loss: 0.582942\n",
      "epoch 122; iter: 0; batch classifier loss: 0.377721; batch adversarial loss: 0.571816\n",
      "epoch 123; iter: 0; batch classifier loss: 0.378365; batch adversarial loss: 0.489426\n",
      "epoch 124; iter: 0; batch classifier loss: 0.321752; batch adversarial loss: 0.545938\n",
      "epoch 125; iter: 0; batch classifier loss: 0.442970; batch adversarial loss: 0.600518\n",
      "epoch 126; iter: 0; batch classifier loss: 0.428298; batch adversarial loss: 0.582622\n",
      "epoch 127; iter: 0; batch classifier loss: 0.332156; batch adversarial loss: 0.489444\n",
      "epoch 128; iter: 0; batch classifier loss: 0.351273; batch adversarial loss: 0.481077\n",
      "epoch 129; iter: 0; batch classifier loss: 0.393392; batch adversarial loss: 0.506622\n",
      "epoch 130; iter: 0; batch classifier loss: 0.388177; batch adversarial loss: 0.553477\n",
      "epoch 131; iter: 0; batch classifier loss: 0.358697; batch adversarial loss: 0.616366\n",
      "epoch 132; iter: 0; batch classifier loss: 0.425557; batch adversarial loss: 0.535161\n",
      "epoch 133; iter: 0; batch classifier loss: 0.378979; batch adversarial loss: 0.524513\n",
      "epoch 134; iter: 0; batch classifier loss: 0.390843; batch adversarial loss: 0.618257\n",
      "epoch 135; iter: 0; batch classifier loss: 0.334717; batch adversarial loss: 0.543455\n",
      "epoch 136; iter: 0; batch classifier loss: 0.341062; batch adversarial loss: 0.553776\n",
      "epoch 137; iter: 0; batch classifier loss: 0.417880; batch adversarial loss: 0.554274\n",
      "epoch 138; iter: 0; batch classifier loss: 0.403694; batch adversarial loss: 0.476969\n",
      "epoch 139; iter: 0; batch classifier loss: 0.392828; batch adversarial loss: 0.497521\n",
      "epoch 140; iter: 0; batch classifier loss: 0.390658; batch adversarial loss: 0.507720\n",
      "epoch 141; iter: 0; batch classifier loss: 0.367333; batch adversarial loss: 0.554143\n",
      "epoch 142; iter: 0; batch classifier loss: 0.274182; batch adversarial loss: 0.507050\n",
      "epoch 143; iter: 0; batch classifier loss: 0.327607; batch adversarial loss: 0.581488\n",
      "epoch 144; iter: 0; batch classifier loss: 0.469076; batch adversarial loss: 0.517536\n",
      "epoch 145; iter: 0; batch classifier loss: 0.351953; batch adversarial loss: 0.599783\n",
      "epoch 146; iter: 0; batch classifier loss: 0.354456; batch adversarial loss: 0.535276\n",
      "epoch 147; iter: 0; batch classifier loss: 0.433906; batch adversarial loss: 0.598442\n",
      "epoch 148; iter: 0; batch classifier loss: 0.342201; batch adversarial loss: 0.562004\n",
      "epoch 149; iter: 0; batch classifier loss: 0.352992; batch adversarial loss: 0.565028\n",
      "epoch 150; iter: 0; batch classifier loss: 0.368186; batch adversarial loss: 0.572867\n",
      "epoch 151; iter: 0; batch classifier loss: 0.337436; batch adversarial loss: 0.617430\n",
      "epoch 152; iter: 0; batch classifier loss: 0.430513; batch adversarial loss: 0.571560\n",
      "epoch 153; iter: 0; batch classifier loss: 0.348773; batch adversarial loss: 0.563441\n",
      "epoch 154; iter: 0; batch classifier loss: 0.440254; batch adversarial loss: 0.508023\n",
      "epoch 155; iter: 0; batch classifier loss: 0.403853; batch adversarial loss: 0.536308\n",
      "epoch 156; iter: 0; batch classifier loss: 0.366916; batch adversarial loss: 0.602071\n",
      "epoch 157; iter: 0; batch classifier loss: 0.362714; batch adversarial loss: 0.495600\n",
      "epoch 158; iter: 0; batch classifier loss: 0.342266; batch adversarial loss: 0.534882\n",
      "epoch 159; iter: 0; batch classifier loss: 0.356432; batch adversarial loss: 0.570210\n",
      "epoch 160; iter: 0; batch classifier loss: 0.319003; batch adversarial loss: 0.611074\n",
      "epoch 161; iter: 0; batch classifier loss: 0.385874; batch adversarial loss: 0.525911\n",
      "epoch 162; iter: 0; batch classifier loss: 0.361946; batch adversarial loss: 0.552329\n",
      "epoch 163; iter: 0; batch classifier loss: 0.421761; batch adversarial loss: 0.514810\n",
      "epoch 164; iter: 0; batch classifier loss: 0.395673; batch adversarial loss: 0.562360\n",
      "epoch 165; iter: 0; batch classifier loss: 0.341309; batch adversarial loss: 0.602282\n",
      "epoch 166; iter: 0; batch classifier loss: 0.382642; batch adversarial loss: 0.535508\n",
      "epoch 167; iter: 0; batch classifier loss: 0.394059; batch adversarial loss: 0.507484\n",
      "epoch 168; iter: 0; batch classifier loss: 0.390426; batch adversarial loss: 0.607538\n",
      "epoch 169; iter: 0; batch classifier loss: 0.291905; batch adversarial loss: 0.553895\n",
      "epoch 170; iter: 0; batch classifier loss: 0.285790; batch adversarial loss: 0.607509\n",
      "epoch 171; iter: 0; batch classifier loss: 0.315626; batch adversarial loss: 0.497963\n",
      "epoch 172; iter: 0; batch classifier loss: 0.363298; batch adversarial loss: 0.561240\n",
      "epoch 173; iter: 0; batch classifier loss: 0.350995; batch adversarial loss: 0.517460\n",
      "epoch 174; iter: 0; batch classifier loss: 0.447217; batch adversarial loss: 0.497370\n",
      "epoch 175; iter: 0; batch classifier loss: 0.276622; batch adversarial loss: 0.626991\n",
      "epoch 176; iter: 0; batch classifier loss: 0.417729; batch adversarial loss: 0.532671\n",
      "epoch 177; iter: 0; batch classifier loss: 0.396562; batch adversarial loss: 0.591038\n",
      "epoch 178; iter: 0; batch classifier loss: 0.389004; batch adversarial loss: 0.498955\n",
      "epoch 179; iter: 0; batch classifier loss: 0.500857; batch adversarial loss: 0.480150\n",
      "epoch 180; iter: 0; batch classifier loss: 0.376657; batch adversarial loss: 0.505184\n",
      "epoch 181; iter: 0; batch classifier loss: 0.347601; batch adversarial loss: 0.527332\n",
      "epoch 182; iter: 0; batch classifier loss: 0.323473; batch adversarial loss: 0.487455\n",
      "epoch 183; iter: 0; batch classifier loss: 0.326811; batch adversarial loss: 0.550954\n",
      "epoch 184; iter: 0; batch classifier loss: 0.397309; batch adversarial loss: 0.516622\n",
      "epoch 185; iter: 0; batch classifier loss: 0.308274; batch adversarial loss: 0.625211\n",
      "epoch 186; iter: 0; batch classifier loss: 0.365326; batch adversarial loss: 0.563579\n",
      "epoch 187; iter: 0; batch classifier loss: 0.317360; batch adversarial loss: 0.565024\n",
      "epoch 188; iter: 0; batch classifier loss: 0.334227; batch adversarial loss: 0.600349\n",
      "epoch 189; iter: 0; batch classifier loss: 0.411519; batch adversarial loss: 0.470280\n",
      "epoch 190; iter: 0; batch classifier loss: 0.382575; batch adversarial loss: 0.564593\n",
      "epoch 191; iter: 0; batch classifier loss: 0.403813; batch adversarial loss: 0.555827\n",
      "epoch 192; iter: 0; batch classifier loss: 0.305425; batch adversarial loss: 0.507482\n",
      "epoch 193; iter: 0; batch classifier loss: 0.362877; batch adversarial loss: 0.517791\n",
      "epoch 194; iter: 0; batch classifier loss: 0.319981; batch adversarial loss: 0.545341\n",
      "epoch 195; iter: 0; batch classifier loss: 0.371561; batch adversarial loss: 0.516899\n",
      "epoch 196; iter: 0; batch classifier loss: 0.302861; batch adversarial loss: 0.564842\n",
      "epoch 197; iter: 0; batch classifier loss: 0.313013; batch adversarial loss: 0.590167\n",
      "epoch 198; iter: 0; batch classifier loss: 0.290015; batch adversarial loss: 0.533804\n",
      "epoch 199; iter: 0; batch classifier loss: 0.415931; batch adversarial loss: 0.554562\n",
      "epoch 0; iter: 0; batch classifier loss: 0.669182; batch adversarial loss: 0.669114\n",
      "epoch 1; iter: 0; batch classifier loss: 0.607522; batch adversarial loss: 0.645016\n",
      "epoch 2; iter: 0; batch classifier loss: 0.542936; batch adversarial loss: 0.666542\n",
      "epoch 3; iter: 0; batch classifier loss: 0.570907; batch adversarial loss: 0.611494\n",
      "epoch 4; iter: 0; batch classifier loss: 0.572577; batch adversarial loss: 0.619994\n",
      "epoch 5; iter: 0; batch classifier loss: 0.522509; batch adversarial loss: 0.613578\n",
      "epoch 6; iter: 0; batch classifier loss: 0.612502; batch adversarial loss: 0.659623\n",
      "epoch 7; iter: 0; batch classifier loss: 0.558652; batch adversarial loss: 0.651119\n",
      "epoch 8; iter: 0; batch classifier loss: 0.549099; batch adversarial loss: 0.570265\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9; iter: 0; batch classifier loss: 0.579856; batch adversarial loss: 0.602126\n",
      "epoch 10; iter: 0; batch classifier loss: 0.530718; batch adversarial loss: 0.614901\n",
      "epoch 11; iter: 0; batch classifier loss: 0.509266; batch adversarial loss: 0.555438\n",
      "epoch 12; iter: 0; batch classifier loss: 0.577666; batch adversarial loss: 0.612758\n",
      "epoch 13; iter: 0; batch classifier loss: 0.512213; batch adversarial loss: 0.614143\n",
      "epoch 14; iter: 0; batch classifier loss: 0.502995; batch adversarial loss: 0.544261\n",
      "epoch 15; iter: 0; batch classifier loss: 0.490803; batch adversarial loss: 0.583221\n",
      "epoch 16; iter: 0; batch classifier loss: 0.495263; batch adversarial loss: 0.599277\n",
      "epoch 17; iter: 0; batch classifier loss: 0.510081; batch adversarial loss: 0.585093\n",
      "epoch 18; iter: 0; batch classifier loss: 0.635193; batch adversarial loss: 0.511936\n",
      "epoch 19; iter: 0; batch classifier loss: 0.441251; batch adversarial loss: 0.568309\n",
      "epoch 20; iter: 0; batch classifier loss: 0.499281; batch adversarial loss: 0.563375\n",
      "epoch 21; iter: 0; batch classifier loss: 0.460411; batch adversarial loss: 0.641576\n",
      "epoch 22; iter: 0; batch classifier loss: 0.467185; batch adversarial loss: 0.607726\n",
      "epoch 23; iter: 0; batch classifier loss: 0.535520; batch adversarial loss: 0.476321\n",
      "epoch 24; iter: 0; batch classifier loss: 0.462650; batch adversarial loss: 0.568601\n",
      "epoch 25; iter: 0; batch classifier loss: 0.476546; batch adversarial loss: 0.525729\n",
      "epoch 26; iter: 0; batch classifier loss: 0.480146; batch adversarial loss: 0.566158\n",
      "epoch 27; iter: 0; batch classifier loss: 0.508604; batch adversarial loss: 0.552477\n",
      "epoch 28; iter: 0; batch classifier loss: 0.440507; batch adversarial loss: 0.520712\n",
      "epoch 29; iter: 0; batch classifier loss: 0.434901; batch adversarial loss: 0.492832\n",
      "epoch 30; iter: 0; batch classifier loss: 0.438877; batch adversarial loss: 0.468372\n",
      "epoch 31; iter: 0; batch classifier loss: 0.533184; batch adversarial loss: 0.624085\n",
      "epoch 32; iter: 0; batch classifier loss: 0.398552; batch adversarial loss: 0.560186\n",
      "epoch 33; iter: 0; batch classifier loss: 0.443448; batch adversarial loss: 0.591562\n",
      "epoch 34; iter: 0; batch classifier loss: 0.447691; batch adversarial loss: 0.666870\n",
      "epoch 35; iter: 0; batch classifier loss: 0.479493; batch adversarial loss: 0.588641\n",
      "epoch 36; iter: 0; batch classifier loss: 0.492728; batch adversarial loss: 0.508996\n",
      "epoch 37; iter: 0; batch classifier loss: 0.409248; batch adversarial loss: 0.488893\n",
      "epoch 38; iter: 0; batch classifier loss: 0.422153; batch adversarial loss: 0.589239\n",
      "epoch 39; iter: 0; batch classifier loss: 0.437284; batch adversarial loss: 0.570244\n",
      "epoch 40; iter: 0; batch classifier loss: 0.420703; batch adversarial loss: 0.632597\n",
      "epoch 41; iter: 0; batch classifier loss: 0.487809; batch adversarial loss: 0.518295\n",
      "epoch 42; iter: 0; batch classifier loss: 0.531992; batch adversarial loss: 0.652459\n",
      "epoch 43; iter: 0; batch classifier loss: 0.459152; batch adversarial loss: 0.543890\n",
      "epoch 44; iter: 0; batch classifier loss: 0.522440; batch adversarial loss: 0.561821\n",
      "epoch 45; iter: 0; batch classifier loss: 0.470098; batch adversarial loss: 0.563287\n",
      "epoch 46; iter: 0; batch classifier loss: 0.457751; batch adversarial loss: 0.572921\n",
      "epoch 47; iter: 0; batch classifier loss: 0.376081; batch adversarial loss: 0.499556\n",
      "epoch 48; iter: 0; batch classifier loss: 0.447275; batch adversarial loss: 0.472486\n",
      "epoch 49; iter: 0; batch classifier loss: 0.399401; batch adversarial loss: 0.446653\n",
      "epoch 50; iter: 0; batch classifier loss: 0.423697; batch adversarial loss: 0.562752\n",
      "epoch 51; iter: 0; batch classifier loss: 0.486948; batch adversarial loss: 0.516684\n",
      "epoch 52; iter: 0; batch classifier loss: 0.418900; batch adversarial loss: 0.481064\n",
      "epoch 53; iter: 0; batch classifier loss: 0.514229; batch adversarial loss: 0.526848\n",
      "epoch 54; iter: 0; batch classifier loss: 0.462863; batch adversarial loss: 0.526610\n",
      "epoch 55; iter: 0; batch classifier loss: 0.437337; batch adversarial loss: 0.526774\n",
      "epoch 56; iter: 0; batch classifier loss: 0.423288; batch adversarial loss: 0.517954\n",
      "epoch 57; iter: 0; batch classifier loss: 0.444575; batch adversarial loss: 0.499705\n",
      "epoch 58; iter: 0; batch classifier loss: 0.468457; batch adversarial loss: 0.544609\n",
      "epoch 59; iter: 0; batch classifier loss: 0.370545; batch adversarial loss: 0.589036\n",
      "epoch 60; iter: 0; batch classifier loss: 0.443558; batch adversarial loss: 0.526999\n",
      "epoch 61; iter: 0; batch classifier loss: 0.432710; batch adversarial loss: 0.589683\n",
      "epoch 62; iter: 0; batch classifier loss: 0.494104; batch adversarial loss: 0.553378\n",
      "epoch 63; iter: 0; batch classifier loss: 0.385543; batch adversarial loss: 0.553825\n",
      "epoch 64; iter: 0; batch classifier loss: 0.412258; batch adversarial loss: 0.553671\n",
      "epoch 65; iter: 0; batch classifier loss: 0.467967; batch adversarial loss: 0.580304\n",
      "epoch 66; iter: 0; batch classifier loss: 0.439880; batch adversarial loss: 0.481616\n",
      "epoch 67; iter: 0; batch classifier loss: 0.396421; batch adversarial loss: 0.571568\n",
      "epoch 68; iter: 0; batch classifier loss: 0.450590; batch adversarial loss: 0.581112\n",
      "epoch 69; iter: 0; batch classifier loss: 0.470996; batch adversarial loss: 0.544859\n",
      "epoch 70; iter: 0; batch classifier loss: 0.436896; batch adversarial loss: 0.499677\n",
      "epoch 71; iter: 0; batch classifier loss: 0.429242; batch adversarial loss: 0.553805\n",
      "epoch 72; iter: 0; batch classifier loss: 0.457176; batch adversarial loss: 0.517725\n",
      "epoch 73; iter: 0; batch classifier loss: 0.360320; batch adversarial loss: 0.500267\n",
      "epoch 74; iter: 0; batch classifier loss: 0.389139; batch adversarial loss: 0.517562\n",
      "epoch 75; iter: 0; batch classifier loss: 0.417395; batch adversarial loss: 0.562678\n",
      "epoch 76; iter: 0; batch classifier loss: 0.435296; batch adversarial loss: 0.544823\n",
      "epoch 77; iter: 0; batch classifier loss: 0.371331; batch adversarial loss: 0.481422\n",
      "epoch 78; iter: 0; batch classifier loss: 0.455972; batch adversarial loss: 0.607593\n",
      "epoch 79; iter: 0; batch classifier loss: 0.466211; batch adversarial loss: 0.589782\n",
      "epoch 80; iter: 0; batch classifier loss: 0.473888; batch adversarial loss: 0.499817\n",
      "epoch 81; iter: 0; batch classifier loss: 0.454369; batch adversarial loss: 0.535797\n",
      "epoch 82; iter: 0; batch classifier loss: 0.489345; batch adversarial loss: 0.616483\n",
      "epoch 83; iter: 0; batch classifier loss: 0.469941; batch adversarial loss: 0.535746\n",
      "epoch 84; iter: 0; batch classifier loss: 0.389614; batch adversarial loss: 0.598479\n",
      "epoch 85; iter: 0; batch classifier loss: 0.450163; batch adversarial loss: 0.553619\n",
      "epoch 86; iter: 0; batch classifier loss: 0.406678; batch adversarial loss: 0.526673\n",
      "epoch 87; iter: 0; batch classifier loss: 0.350744; batch adversarial loss: 0.562394\n",
      "epoch 88; iter: 0; batch classifier loss: 0.505735; batch adversarial loss: 0.517439\n",
      "epoch 89; iter: 0; batch classifier loss: 0.419146; batch adversarial loss: 0.535530\n",
      "epoch 90; iter: 0; batch classifier loss: 0.336022; batch adversarial loss: 0.445936\n",
      "epoch 91; iter: 0; batch classifier loss: 0.348612; batch adversarial loss: 0.616611\n",
      "epoch 92; iter: 0; batch classifier loss: 0.335757; batch adversarial loss: 0.508541\n",
      "epoch 93; iter: 0; batch classifier loss: 0.433797; batch adversarial loss: 0.508735\n",
      "epoch 94; iter: 0; batch classifier loss: 0.373371; batch adversarial loss: 0.562614\n",
      "epoch 95; iter: 0; batch classifier loss: 0.440993; batch adversarial loss: 0.535765\n",
      "epoch 96; iter: 0; batch classifier loss: 0.393181; batch adversarial loss: 0.553675\n",
      "epoch 97; iter: 0; batch classifier loss: 0.422021; batch adversarial loss: 0.580372\n",
      "epoch 98; iter: 0; batch classifier loss: 0.353545; batch adversarial loss: 0.616704\n",
      "epoch 99; iter: 0; batch classifier loss: 0.367348; batch adversarial loss: 0.617106\n",
      "epoch 100; iter: 0; batch classifier loss: 0.437964; batch adversarial loss: 0.526385\n",
      "epoch 101; iter: 0; batch classifier loss: 0.363256; batch adversarial loss: 0.553701\n",
      "epoch 102; iter: 0; batch classifier loss: 0.415092; batch adversarial loss: 0.535268\n",
      "epoch 103; iter: 0; batch classifier loss: 0.399565; batch adversarial loss: 0.580717\n",
      "epoch 104; iter: 0; batch classifier loss: 0.339201; batch adversarial loss: 0.617883\n",
      "epoch 105; iter: 0; batch classifier loss: 0.445964; batch adversarial loss: 0.581196\n",
      "epoch 106; iter: 0; batch classifier loss: 0.348019; batch adversarial loss: 0.551959\n",
      "epoch 107; iter: 0; batch classifier loss: 0.387826; batch adversarial loss: 0.599437\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 108; iter: 0; batch classifier loss: 0.462173; batch adversarial loss: 0.589486\n",
      "epoch 109; iter: 0; batch classifier loss: 0.412650; batch adversarial loss: 0.473614\n",
      "epoch 110; iter: 0; batch classifier loss: 0.456849; batch adversarial loss: 0.507053\n",
      "epoch 111; iter: 0; batch classifier loss: 0.442895; batch adversarial loss: 0.535593\n",
      "epoch 112; iter: 0; batch classifier loss: 0.422904; batch adversarial loss: 0.545675\n",
      "epoch 113; iter: 0; batch classifier loss: 0.407541; batch adversarial loss: 0.526229\n",
      "epoch 114; iter: 0; batch classifier loss: 0.370092; batch adversarial loss: 0.588736\n",
      "epoch 115; iter: 0; batch classifier loss: 0.367202; batch adversarial loss: 0.580989\n",
      "epoch 116; iter: 0; batch classifier loss: 0.476044; batch adversarial loss: 0.553698\n",
      "epoch 117; iter: 0; batch classifier loss: 0.373606; batch adversarial loss: 0.561211\n",
      "epoch 118; iter: 0; batch classifier loss: 0.448939; batch adversarial loss: 0.564764\n",
      "epoch 119; iter: 0; batch classifier loss: 0.410748; batch adversarial loss: 0.506592\n",
      "epoch 120; iter: 0; batch classifier loss: 0.352207; batch adversarial loss: 0.507999\n",
      "epoch 121; iter: 0; batch classifier loss: 0.423820; batch adversarial loss: 0.488642\n",
      "epoch 122; iter: 0; batch classifier loss: 0.405216; batch adversarial loss: 0.572151\n",
      "epoch 123; iter: 0; batch classifier loss: 0.416233; batch adversarial loss: 0.519189\n",
      "epoch 124; iter: 0; batch classifier loss: 0.375537; batch adversarial loss: 0.581019\n",
      "epoch 125; iter: 0; batch classifier loss: 0.394528; batch adversarial loss: 0.589133\n",
      "epoch 126; iter: 0; batch classifier loss: 0.326749; batch adversarial loss: 0.563782\n",
      "epoch 127; iter: 0; batch classifier loss: 0.386399; batch adversarial loss: 0.530749\n",
      "epoch 128; iter: 0; batch classifier loss: 0.400792; batch adversarial loss: 0.537073\n",
      "epoch 129; iter: 0; batch classifier loss: 0.430250; batch adversarial loss: 0.554110\n",
      "epoch 130; iter: 0; batch classifier loss: 0.459195; batch adversarial loss: 0.545265\n",
      "epoch 131; iter: 0; batch classifier loss: 0.449964; batch adversarial loss: 0.571064\n",
      "epoch 132; iter: 0; batch classifier loss: 0.404498; batch adversarial loss: 0.536051\n",
      "epoch 133; iter: 0; batch classifier loss: 0.441537; batch adversarial loss: 0.553707\n",
      "epoch 134; iter: 0; batch classifier loss: 0.369371; batch adversarial loss: 0.580494\n",
      "epoch 135; iter: 0; batch classifier loss: 0.402304; batch adversarial loss: 0.544714\n",
      "epoch 136; iter: 0; batch classifier loss: 0.433632; batch adversarial loss: 0.535424\n",
      "epoch 137; iter: 0; batch classifier loss: 0.385712; batch adversarial loss: 0.606439\n",
      "epoch 138; iter: 0; batch classifier loss: 0.363074; batch adversarial loss: 0.552276\n",
      "epoch 139; iter: 0; batch classifier loss: 0.433078; batch adversarial loss: 0.518705\n",
      "epoch 140; iter: 0; batch classifier loss: 0.370404; batch adversarial loss: 0.562267\n",
      "epoch 141; iter: 0; batch classifier loss: 0.381424; batch adversarial loss: 0.533850\n",
      "epoch 142; iter: 0; batch classifier loss: 0.419641; batch adversarial loss: 0.515965\n",
      "epoch 143; iter: 0; batch classifier loss: 0.438732; batch adversarial loss: 0.562315\n",
      "epoch 144; iter: 0; batch classifier loss: 0.341117; batch adversarial loss: 0.561506\n",
      "epoch 145; iter: 0; batch classifier loss: 0.405499; batch adversarial loss: 0.446337\n",
      "epoch 146; iter: 0; batch classifier loss: 0.358125; batch adversarial loss: 0.546756\n",
      "epoch 147; iter: 0; batch classifier loss: 0.364132; batch adversarial loss: 0.556112\n",
      "epoch 148; iter: 0; batch classifier loss: 0.375005; batch adversarial loss: 0.617466\n",
      "epoch 149; iter: 0; batch classifier loss: 0.414717; batch adversarial loss: 0.571455\n",
      "epoch 150; iter: 0; batch classifier loss: 0.354556; batch adversarial loss: 0.582176\n",
      "epoch 151; iter: 0; batch classifier loss: 0.367303; batch adversarial loss: 0.509371\n",
      "epoch 152; iter: 0; batch classifier loss: 0.390139; batch adversarial loss: 0.624205\n",
      "epoch 153; iter: 0; batch classifier loss: 0.465094; batch adversarial loss: 0.483349\n",
      "epoch 154; iter: 0; batch classifier loss: 0.406198; batch adversarial loss: 0.537617\n",
      "epoch 155; iter: 0; batch classifier loss: 0.420520; batch adversarial loss: 0.571650\n",
      "epoch 156; iter: 0; batch classifier loss: 0.431006; batch adversarial loss: 0.607453\n",
      "epoch 157; iter: 0; batch classifier loss: 0.331415; batch adversarial loss: 0.536319\n",
      "epoch 158; iter: 0; batch classifier loss: 0.302241; batch adversarial loss: 0.475094\n",
      "epoch 159; iter: 0; batch classifier loss: 0.426791; batch adversarial loss: 0.553464\n",
      "epoch 160; iter: 0; batch classifier loss: 0.380441; batch adversarial loss: 0.562489\n",
      "epoch 161; iter: 0; batch classifier loss: 0.343681; batch adversarial loss: 0.642893\n",
      "epoch 162; iter: 0; batch classifier loss: 0.384591; batch adversarial loss: 0.544746\n",
      "epoch 163; iter: 0; batch classifier loss: 0.337372; batch adversarial loss: 0.589314\n",
      "epoch 164; iter: 0; batch classifier loss: 0.290069; batch adversarial loss: 0.544067\n",
      "epoch 165; iter: 0; batch classifier loss: 0.366240; batch adversarial loss: 0.562244\n",
      "epoch 166; iter: 0; batch classifier loss: 0.465515; batch adversarial loss: 0.526762\n",
      "epoch 167; iter: 0; batch classifier loss: 0.350077; batch adversarial loss: 0.625494\n",
      "epoch 168; iter: 0; batch classifier loss: 0.406946; batch adversarial loss: 0.561768\n",
      "epoch 169; iter: 0; batch classifier loss: 0.322347; batch adversarial loss: 0.535161\n",
      "epoch 170; iter: 0; batch classifier loss: 0.393147; batch adversarial loss: 0.571260\n",
      "epoch 171; iter: 0; batch classifier loss: 0.321575; batch adversarial loss: 0.508363\n",
      "epoch 172; iter: 0; batch classifier loss: 0.313858; batch adversarial loss: 0.534977\n",
      "epoch 173; iter: 0; batch classifier loss: 0.346894; batch adversarial loss: 0.471722\n",
      "epoch 174; iter: 0; batch classifier loss: 0.339883; batch adversarial loss: 0.554654\n",
      "epoch 175; iter: 0; batch classifier loss: 0.326864; batch adversarial loss: 0.578733\n",
      "epoch 176; iter: 0; batch classifier loss: 0.457527; batch adversarial loss: 0.525960\n",
      "epoch 177; iter: 0; batch classifier loss: 0.361667; batch adversarial loss: 0.552513\n",
      "epoch 178; iter: 0; batch classifier loss: 0.373927; batch adversarial loss: 0.561033\n",
      "epoch 179; iter: 0; batch classifier loss: 0.382712; batch adversarial loss: 0.504730\n",
      "epoch 180; iter: 0; batch classifier loss: 0.334534; batch adversarial loss: 0.564759\n",
      "epoch 181; iter: 0; batch classifier loss: 0.411299; batch adversarial loss: 0.489931\n",
      "epoch 182; iter: 0; batch classifier loss: 0.363235; batch adversarial loss: 0.561173\n",
      "epoch 183; iter: 0; batch classifier loss: 0.382128; batch adversarial loss: 0.593423\n",
      "epoch 184; iter: 0; batch classifier loss: 0.454815; batch adversarial loss: 0.599375\n",
      "epoch 185; iter: 0; batch classifier loss: 0.355260; batch adversarial loss: 0.526216\n",
      "epoch 186; iter: 0; batch classifier loss: 0.421487; batch adversarial loss: 0.561694\n",
      "epoch 187; iter: 0; batch classifier loss: 0.409321; batch adversarial loss: 0.605070\n",
      "epoch 188; iter: 0; batch classifier loss: 0.313548; batch adversarial loss: 0.617567\n",
      "epoch 189; iter: 0; batch classifier loss: 0.469243; batch adversarial loss: 0.543974\n",
      "epoch 190; iter: 0; batch classifier loss: 0.383257; batch adversarial loss: 0.474794\n",
      "epoch 191; iter: 0; batch classifier loss: 0.297704; batch adversarial loss: 0.571230\n",
      "epoch 192; iter: 0; batch classifier loss: 0.455796; batch adversarial loss: 0.546220\n",
      "epoch 193; iter: 0; batch classifier loss: 0.364229; batch adversarial loss: 0.564415\n",
      "epoch 194; iter: 0; batch classifier loss: 0.389728; batch adversarial loss: 0.659862\n",
      "epoch 195; iter: 0; batch classifier loss: 0.330590; batch adversarial loss: 0.517248\n",
      "epoch 196; iter: 0; batch classifier loss: 0.363110; batch adversarial loss: 0.491801\n",
      "epoch 197; iter: 0; batch classifier loss: 0.401754; batch adversarial loss: 0.552459\n",
      "epoch 198; iter: 0; batch classifier loss: 0.245024; batch adversarial loss: 0.509727\n",
      "epoch 199; iter: 0; batch classifier loss: 0.338454; batch adversarial loss: 0.544298\n",
      "epoch 0; iter: 0; batch classifier loss: 0.675761; batch adversarial loss: 0.825205\n",
      "epoch 1; iter: 0; batch classifier loss: 0.793118; batch adversarial loss: 0.953217\n",
      "epoch 2; iter: 0; batch classifier loss: 0.883530; batch adversarial loss: 0.907291\n",
      "epoch 3; iter: 0; batch classifier loss: 0.987277; batch adversarial loss: 0.860313\n",
      "epoch 4; iter: 0; batch classifier loss: 0.824358; batch adversarial loss: 0.741979\n",
      "epoch 5; iter: 0; batch classifier loss: 0.759746; batch adversarial loss: 0.696327\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6; iter: 0; batch classifier loss: 0.657501; batch adversarial loss: 0.657142\n",
      "epoch 7; iter: 0; batch classifier loss: 0.564348; batch adversarial loss: 0.584782\n",
      "epoch 8; iter: 0; batch classifier loss: 0.595640; batch adversarial loss: 0.590622\n",
      "epoch 9; iter: 0; batch classifier loss: 0.567012; batch adversarial loss: 0.589066\n",
      "epoch 10; iter: 0; batch classifier loss: 0.575989; batch adversarial loss: 0.591324\n",
      "epoch 11; iter: 0; batch classifier loss: 0.526067; batch adversarial loss: 0.545871\n",
      "epoch 12; iter: 0; batch classifier loss: 0.505648; batch adversarial loss: 0.566742\n",
      "epoch 13; iter: 0; batch classifier loss: 0.486417; batch adversarial loss: 0.609086\n",
      "epoch 14; iter: 0; batch classifier loss: 0.479608; batch adversarial loss: 0.534429\n",
      "epoch 15; iter: 0; batch classifier loss: 0.532496; batch adversarial loss: 0.528750\n",
      "epoch 16; iter: 0; batch classifier loss: 0.556367; batch adversarial loss: 0.528292\n",
      "epoch 17; iter: 0; batch classifier loss: 0.506934; batch adversarial loss: 0.546458\n",
      "epoch 18; iter: 0; batch classifier loss: 0.516997; batch adversarial loss: 0.604005\n",
      "epoch 19; iter: 0; batch classifier loss: 0.462343; batch adversarial loss: 0.573056\n",
      "epoch 20; iter: 0; batch classifier loss: 0.516215; batch adversarial loss: 0.610816\n",
      "epoch 21; iter: 0; batch classifier loss: 0.416617; batch adversarial loss: 0.569068\n",
      "epoch 22; iter: 0; batch classifier loss: 0.462735; batch adversarial loss: 0.568315\n",
      "epoch 23; iter: 0; batch classifier loss: 0.440888; batch adversarial loss: 0.528243\n",
      "epoch 24; iter: 0; batch classifier loss: 0.405203; batch adversarial loss: 0.713172\n",
      "epoch 25; iter: 0; batch classifier loss: 0.493039; batch adversarial loss: 0.560116\n",
      "epoch 26; iter: 0; batch classifier loss: 0.476985; batch adversarial loss: 0.611326\n",
      "epoch 27; iter: 0; batch classifier loss: 0.471899; batch adversarial loss: 0.598002\n",
      "epoch 28; iter: 0; batch classifier loss: 0.472563; batch adversarial loss: 0.574048\n",
      "epoch 29; iter: 0; batch classifier loss: 0.494106; batch adversarial loss: 0.626930\n",
      "epoch 30; iter: 0; batch classifier loss: 0.472550; batch adversarial loss: 0.575008\n",
      "epoch 31; iter: 0; batch classifier loss: 0.438181; batch adversarial loss: 0.567776\n",
      "epoch 32; iter: 0; batch classifier loss: 0.461138; batch adversarial loss: 0.540513\n",
      "epoch 33; iter: 0; batch classifier loss: 0.514194; batch adversarial loss: 0.483599\n",
      "epoch 34; iter: 0; batch classifier loss: 0.453705; batch adversarial loss: 0.593314\n",
      "epoch 35; iter: 0; batch classifier loss: 0.434775; batch adversarial loss: 0.594400\n",
      "epoch 36; iter: 0; batch classifier loss: 0.420498; batch adversarial loss: 0.523223\n",
      "epoch 37; iter: 0; batch classifier loss: 0.350175; batch adversarial loss: 0.577148\n",
      "epoch 38; iter: 0; batch classifier loss: 0.487347; batch adversarial loss: 0.523425\n",
      "epoch 39; iter: 0; batch classifier loss: 0.450843; batch adversarial loss: 0.602076\n",
      "epoch 40; iter: 0; batch classifier loss: 0.385754; batch adversarial loss: 0.517253\n",
      "epoch 41; iter: 0; batch classifier loss: 0.368977; batch adversarial loss: 0.502857\n",
      "epoch 42; iter: 0; batch classifier loss: 0.446478; batch adversarial loss: 0.510101\n",
      "epoch 43; iter: 0; batch classifier loss: 0.447304; batch adversarial loss: 0.484646\n",
      "epoch 44; iter: 0; batch classifier loss: 0.443983; batch adversarial loss: 0.512803\n",
      "epoch 45; iter: 0; batch classifier loss: 0.516021; batch adversarial loss: 0.501998\n",
      "epoch 46; iter: 0; batch classifier loss: 0.453472; batch adversarial loss: 0.492935\n",
      "epoch 47; iter: 0; batch classifier loss: 0.442605; batch adversarial loss: 0.518314\n",
      "epoch 48; iter: 0; batch classifier loss: 0.529365; batch adversarial loss: 0.570307\n",
      "epoch 49; iter: 0; batch classifier loss: 0.375056; batch adversarial loss: 0.510633\n",
      "epoch 50; iter: 0; batch classifier loss: 0.391876; batch adversarial loss: 0.544850\n",
      "epoch 51; iter: 0; batch classifier loss: 0.457794; batch adversarial loss: 0.552414\n",
      "epoch 52; iter: 0; batch classifier loss: 0.411636; batch adversarial loss: 0.580946\n",
      "epoch 53; iter: 0; batch classifier loss: 0.445429; batch adversarial loss: 0.563349\n",
      "epoch 54; iter: 0; batch classifier loss: 0.342187; batch adversarial loss: 0.607628\n",
      "epoch 55; iter: 0; batch classifier loss: 0.410199; batch adversarial loss: 0.508210\n",
      "epoch 56; iter: 0; batch classifier loss: 0.447718; batch adversarial loss: 0.462798\n",
      "epoch 57; iter: 0; batch classifier loss: 0.395298; batch adversarial loss: 0.537026\n",
      "epoch 58; iter: 0; batch classifier loss: 0.466756; batch adversarial loss: 0.517295\n",
      "epoch 59; iter: 0; batch classifier loss: 0.361453; batch adversarial loss: 0.508543\n",
      "epoch 60; iter: 0; batch classifier loss: 0.364766; batch adversarial loss: 0.554258\n",
      "epoch 61; iter: 0; batch classifier loss: 0.408727; batch adversarial loss: 0.652508\n",
      "epoch 62; iter: 0; batch classifier loss: 0.399163; batch adversarial loss: 0.498109\n",
      "epoch 63; iter: 0; batch classifier loss: 0.332219; batch adversarial loss: 0.588881\n",
      "epoch 64; iter: 0; batch classifier loss: 0.499561; batch adversarial loss: 0.581707\n",
      "epoch 65; iter: 0; batch classifier loss: 0.470503; batch adversarial loss: 0.508980\n",
      "epoch 66; iter: 0; batch classifier loss: 0.425643; batch adversarial loss: 0.566782\n",
      "epoch 67; iter: 0; batch classifier loss: 0.308173; batch adversarial loss: 0.572490\n",
      "epoch 68; iter: 0; batch classifier loss: 0.454702; batch adversarial loss: 0.530764\n",
      "epoch 69; iter: 0; batch classifier loss: 0.463785; batch adversarial loss: 0.599747\n",
      "epoch 70; iter: 0; batch classifier loss: 0.401182; batch adversarial loss: 0.500875\n",
      "epoch 71; iter: 0; batch classifier loss: 0.313045; batch adversarial loss: 0.606247\n",
      "epoch 72; iter: 0; batch classifier loss: 0.368910; batch adversarial loss: 0.557614\n",
      "epoch 73; iter: 0; batch classifier loss: 0.414881; batch adversarial loss: 0.515244\n",
      "epoch 74; iter: 0; batch classifier loss: 0.362255; batch adversarial loss: 0.516878\n",
      "epoch 75; iter: 0; batch classifier loss: 0.403059; batch adversarial loss: 0.518623\n",
      "epoch 76; iter: 0; batch classifier loss: 0.357936; batch adversarial loss: 0.542536\n",
      "epoch 77; iter: 0; batch classifier loss: 0.344534; batch adversarial loss: 0.558231\n",
      "epoch 78; iter: 0; batch classifier loss: 0.396323; batch adversarial loss: 0.472417\n",
      "epoch 79; iter: 0; batch classifier loss: 0.352489; batch adversarial loss: 0.577097\n",
      "epoch 80; iter: 0; batch classifier loss: 0.330470; batch adversarial loss: 0.622658\n",
      "epoch 81; iter: 0; batch classifier loss: 0.376079; batch adversarial loss: 0.496206\n",
      "epoch 82; iter: 0; batch classifier loss: 0.397638; batch adversarial loss: 0.563246\n",
      "epoch 83; iter: 0; batch classifier loss: 0.370744; batch adversarial loss: 0.601404\n",
      "epoch 84; iter: 0; batch classifier loss: 0.356295; batch adversarial loss: 0.524405\n",
      "epoch 85; iter: 0; batch classifier loss: 0.337594; batch adversarial loss: 0.565012\n",
      "epoch 86; iter: 0; batch classifier loss: 0.318660; batch adversarial loss: 0.553501\n",
      "epoch 87; iter: 0; batch classifier loss: 0.386959; batch adversarial loss: 0.557558\n",
      "epoch 88; iter: 0; batch classifier loss: 0.395660; batch adversarial loss: 0.508526\n",
      "epoch 89; iter: 0; batch classifier loss: 0.352591; batch adversarial loss: 0.511552\n",
      "epoch 90; iter: 0; batch classifier loss: 0.420010; batch adversarial loss: 0.560826\n",
      "epoch 91; iter: 0; batch classifier loss: 0.378997; batch adversarial loss: 0.499772\n",
      "epoch 92; iter: 0; batch classifier loss: 0.370397; batch adversarial loss: 0.548296\n",
      "epoch 93; iter: 0; batch classifier loss: 0.453177; batch adversarial loss: 0.653247\n",
      "epoch 94; iter: 0; batch classifier loss: 0.336351; batch adversarial loss: 0.576266\n",
      "epoch 95; iter: 0; batch classifier loss: 0.434601; batch adversarial loss: 0.548488\n",
      "epoch 96; iter: 0; batch classifier loss: 0.329343; batch adversarial loss: 0.526681\n",
      "epoch 97; iter: 0; batch classifier loss: 0.442798; batch adversarial loss: 0.594341\n",
      "epoch 98; iter: 0; batch classifier loss: 0.391201; batch adversarial loss: 0.497561\n",
      "epoch 99; iter: 0; batch classifier loss: 0.371871; batch adversarial loss: 0.558917\n",
      "epoch 100; iter: 0; batch classifier loss: 0.373037; batch adversarial loss: 0.599398\n",
      "epoch 101; iter: 0; batch classifier loss: 0.325083; batch adversarial loss: 0.530144\n",
      "epoch 102; iter: 0; batch classifier loss: 0.362215; batch adversarial loss: 0.526132\n",
      "epoch 103; iter: 0; batch classifier loss: 0.369261; batch adversarial loss: 0.570552\n",
      "epoch 104; iter: 0; batch classifier loss: 0.275254; batch adversarial loss: 0.681418\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 105; iter: 0; batch classifier loss: 0.330481; batch adversarial loss: 0.630969\n",
      "epoch 106; iter: 0; batch classifier loss: 0.383834; batch adversarial loss: 0.557334\n",
      "epoch 107; iter: 0; batch classifier loss: 0.436086; batch adversarial loss: 0.555390\n",
      "epoch 108; iter: 0; batch classifier loss: 0.340304; batch adversarial loss: 0.528788\n",
      "epoch 109; iter: 0; batch classifier loss: 0.401215; batch adversarial loss: 0.571486\n",
      "epoch 110; iter: 0; batch classifier loss: 0.432130; batch adversarial loss: 0.615609\n",
      "epoch 111; iter: 0; batch classifier loss: 0.310622; batch adversarial loss: 0.530108\n",
      "epoch 112; iter: 0; batch classifier loss: 0.412823; batch adversarial loss: 0.610795\n",
      "epoch 113; iter: 0; batch classifier loss: 0.362664; batch adversarial loss: 0.528552\n",
      "epoch 114; iter: 0; batch classifier loss: 0.393297; batch adversarial loss: 0.479001\n",
      "epoch 115; iter: 0; batch classifier loss: 0.304446; batch adversarial loss: 0.604686\n",
      "epoch 116; iter: 0; batch classifier loss: 0.320707; batch adversarial loss: 0.552050\n",
      "epoch 117; iter: 0; batch classifier loss: 0.343301; batch adversarial loss: 0.596107\n",
      "epoch 118; iter: 0; batch classifier loss: 0.298457; batch adversarial loss: 0.520735\n",
      "epoch 119; iter: 0; batch classifier loss: 0.416225; batch adversarial loss: 0.506776\n",
      "epoch 120; iter: 0; batch classifier loss: 0.296217; batch adversarial loss: 0.565387\n",
      "epoch 121; iter: 0; batch classifier loss: 0.362899; batch adversarial loss: 0.546453\n",
      "epoch 122; iter: 0; batch classifier loss: 0.413640; batch adversarial loss: 0.559535\n",
      "epoch 123; iter: 0; batch classifier loss: 0.390408; batch adversarial loss: 0.675230\n",
      "epoch 124; iter: 0; batch classifier loss: 0.395409; batch adversarial loss: 0.584873\n",
      "epoch 125; iter: 0; batch classifier loss: 0.334958; batch adversarial loss: 0.570002\n",
      "epoch 126; iter: 0; batch classifier loss: 0.342692; batch adversarial loss: 0.544452\n",
      "epoch 127; iter: 0; batch classifier loss: 0.354594; batch adversarial loss: 0.588565\n",
      "epoch 128; iter: 0; batch classifier loss: 0.360919; batch adversarial loss: 0.615146\n",
      "epoch 129; iter: 0; batch classifier loss: 0.385960; batch adversarial loss: 0.569804\n",
      "epoch 130; iter: 0; batch classifier loss: 0.279073; batch adversarial loss: 0.584098\n",
      "epoch 131; iter: 0; batch classifier loss: 0.290867; batch adversarial loss: 0.560497\n",
      "epoch 132; iter: 0; batch classifier loss: 0.376445; batch adversarial loss: 0.580673\n",
      "epoch 133; iter: 0; batch classifier loss: 0.387412; batch adversarial loss: 0.524713\n",
      "epoch 134; iter: 0; batch classifier loss: 0.401673; batch adversarial loss: 0.550156\n",
      "epoch 135; iter: 0; batch classifier loss: 0.323219; batch adversarial loss: 0.567971\n",
      "epoch 136; iter: 0; batch classifier loss: 0.382313; batch adversarial loss: 0.592315\n",
      "epoch 137; iter: 0; batch classifier loss: 0.337696; batch adversarial loss: 0.498894\n",
      "epoch 138; iter: 0; batch classifier loss: 0.345090; batch adversarial loss: 0.473811\n",
      "epoch 139; iter: 0; batch classifier loss: 0.388507; batch adversarial loss: 0.554692\n",
      "epoch 140; iter: 0; batch classifier loss: 0.417144; batch adversarial loss: 0.559662\n",
      "epoch 141; iter: 0; batch classifier loss: 0.382003; batch adversarial loss: 0.508242\n",
      "epoch 142; iter: 0; batch classifier loss: 0.333793; batch adversarial loss: 0.470123\n",
      "epoch 143; iter: 0; batch classifier loss: 0.366059; batch adversarial loss: 0.545850\n",
      "epoch 144; iter: 0; batch classifier loss: 0.349060; batch adversarial loss: 0.557921\n",
      "epoch 145; iter: 0; batch classifier loss: 0.445694; batch adversarial loss: 0.567893\n",
      "epoch 146; iter: 0; batch classifier loss: 0.420399; batch adversarial loss: 0.563594\n",
      "epoch 147; iter: 0; batch classifier loss: 0.285924; batch adversarial loss: 0.576647\n",
      "epoch 148; iter: 0; batch classifier loss: 0.390598; batch adversarial loss: 0.480696\n",
      "epoch 149; iter: 0; batch classifier loss: 0.370066; batch adversarial loss: 0.648550\n",
      "epoch 150; iter: 0; batch classifier loss: 0.359396; batch adversarial loss: 0.563229\n",
      "epoch 151; iter: 0; batch classifier loss: 0.361232; batch adversarial loss: 0.494077\n",
      "epoch 152; iter: 0; batch classifier loss: 0.357119; batch adversarial loss: 0.517844\n",
      "epoch 153; iter: 0; batch classifier loss: 0.337616; batch adversarial loss: 0.574513\n",
      "epoch 154; iter: 0; batch classifier loss: 0.345268; batch adversarial loss: 0.443848\n",
      "epoch 155; iter: 0; batch classifier loss: 0.328613; batch adversarial loss: 0.504308\n",
      "epoch 156; iter: 0; batch classifier loss: 0.412597; batch adversarial loss: 0.492344\n",
      "epoch 157; iter: 0; batch classifier loss: 0.364495; batch adversarial loss: 0.613568\n",
      "epoch 158; iter: 0; batch classifier loss: 0.393208; batch adversarial loss: 0.537513\n",
      "epoch 159; iter: 0; batch classifier loss: 0.325963; batch adversarial loss: 0.526800\n",
      "epoch 160; iter: 0; batch classifier loss: 0.346454; batch adversarial loss: 0.522140\n",
      "epoch 161; iter: 0; batch classifier loss: 0.404061; batch adversarial loss: 0.516335\n",
      "epoch 162; iter: 0; batch classifier loss: 0.328665; batch adversarial loss: 0.565784\n",
      "epoch 163; iter: 0; batch classifier loss: 0.352207; batch adversarial loss: 0.470123\n",
      "epoch 164; iter: 0; batch classifier loss: 0.310945; batch adversarial loss: 0.573860\n",
      "epoch 165; iter: 0; batch classifier loss: 0.353810; batch adversarial loss: 0.463554\n",
      "epoch 166; iter: 0; batch classifier loss: 0.325495; batch adversarial loss: 0.555035\n",
      "epoch 167; iter: 0; batch classifier loss: 0.324324; batch adversarial loss: 0.544725\n",
      "epoch 168; iter: 0; batch classifier loss: 0.295040; batch adversarial loss: 0.606961\n",
      "epoch 169; iter: 0; batch classifier loss: 0.301751; batch adversarial loss: 0.569681\n",
      "epoch 170; iter: 0; batch classifier loss: 0.337262; batch adversarial loss: 0.545917\n",
      "epoch 171; iter: 0; batch classifier loss: 0.354208; batch adversarial loss: 0.471508\n",
      "epoch 172; iter: 0; batch classifier loss: 0.404419; batch adversarial loss: 0.574962\n",
      "epoch 173; iter: 0; batch classifier loss: 0.265369; batch adversarial loss: 0.493048\n",
      "epoch 174; iter: 0; batch classifier loss: 0.381665; batch adversarial loss: 0.550278\n",
      "epoch 175; iter: 0; batch classifier loss: 0.345442; batch adversarial loss: 0.559469\n",
      "epoch 176; iter: 0; batch classifier loss: 0.392961; batch adversarial loss: 0.528774\n",
      "epoch 177; iter: 0; batch classifier loss: 0.380487; batch adversarial loss: 0.540331\n",
      "epoch 178; iter: 0; batch classifier loss: 0.383404; batch adversarial loss: 0.579139\n",
      "epoch 179; iter: 0; batch classifier loss: 0.275295; batch adversarial loss: 0.510333\n",
      "epoch 180; iter: 0; batch classifier loss: 0.312625; batch adversarial loss: 0.568648\n",
      "epoch 181; iter: 0; batch classifier loss: 0.367151; batch adversarial loss: 0.570599\n",
      "epoch 182; iter: 0; batch classifier loss: 0.299552; batch adversarial loss: 0.434212\n",
      "epoch 183; iter: 0; batch classifier loss: 0.368944; batch adversarial loss: 0.585298\n",
      "epoch 184; iter: 0; batch classifier loss: 0.325410; batch adversarial loss: 0.516684\n",
      "epoch 185; iter: 0; batch classifier loss: 0.316001; batch adversarial loss: 0.514101\n",
      "epoch 186; iter: 0; batch classifier loss: 0.356985; batch adversarial loss: 0.556495\n",
      "epoch 187; iter: 0; batch classifier loss: 0.274981; batch adversarial loss: 0.503471\n",
      "epoch 188; iter: 0; batch classifier loss: 0.334460; batch adversarial loss: 0.486008\n",
      "epoch 189; iter: 0; batch classifier loss: 0.321289; batch adversarial loss: 0.581233\n",
      "epoch 190; iter: 0; batch classifier loss: 0.305082; batch adversarial loss: 0.549003\n",
      "epoch 191; iter: 0; batch classifier loss: 0.339844; batch adversarial loss: 0.544604\n",
      "epoch 192; iter: 0; batch classifier loss: 0.274907; batch adversarial loss: 0.542766\n",
      "epoch 193; iter: 0; batch classifier loss: 0.213903; batch adversarial loss: 0.531546\n",
      "epoch 194; iter: 0; batch classifier loss: 0.398193; batch adversarial loss: 0.567643\n",
      "epoch 195; iter: 0; batch classifier loss: 0.315257; batch adversarial loss: 0.539153\n",
      "epoch 196; iter: 0; batch classifier loss: 0.345152; batch adversarial loss: 0.586635\n",
      "epoch 197; iter: 0; batch classifier loss: 0.330478; batch adversarial loss: 0.554070\n",
      "epoch 198; iter: 0; batch classifier loss: 0.309934; batch adversarial loss: 0.538315\n",
      "epoch 199; iter: 0; batch classifier loss: 0.273160; batch adversarial loss: 0.531817\n",
      "epoch 0; iter: 0; batch classifier loss: 0.722948; batch adversarial loss: 0.785355\n",
      "epoch 1; iter: 0; batch classifier loss: 0.617037; batch adversarial loss: 0.754737\n",
      "epoch 2; iter: 0; batch classifier loss: 0.552720; batch adversarial loss: 0.709369\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3; iter: 0; batch classifier loss: 0.627282; batch adversarial loss: 0.666911\n",
      "epoch 4; iter: 0; batch classifier loss: 0.530819; batch adversarial loss: 0.665819\n",
      "epoch 5; iter: 0; batch classifier loss: 0.544624; batch adversarial loss: 0.632656\n",
      "epoch 6; iter: 0; batch classifier loss: 0.524889; batch adversarial loss: 0.631946\n",
      "epoch 7; iter: 0; batch classifier loss: 0.512714; batch adversarial loss: 0.638067\n",
      "epoch 8; iter: 0; batch classifier loss: 0.486713; batch adversarial loss: 0.611340\n",
      "epoch 9; iter: 0; batch classifier loss: 0.548909; batch adversarial loss: 0.592212\n",
      "epoch 10; iter: 0; batch classifier loss: 0.548274; batch adversarial loss: 0.556489\n",
      "epoch 11; iter: 0; batch classifier loss: 0.536216; batch adversarial loss: 0.640180\n",
      "epoch 12; iter: 0; batch classifier loss: 0.481680; batch adversarial loss: 0.533783\n",
      "epoch 13; iter: 0; batch classifier loss: 0.570567; batch adversarial loss: 0.524593\n",
      "epoch 14; iter: 0; batch classifier loss: 0.503285; batch adversarial loss: 0.562059\n",
      "epoch 15; iter: 0; batch classifier loss: 0.471206; batch adversarial loss: 0.607806\n",
      "epoch 16; iter: 0; batch classifier loss: 0.468901; batch adversarial loss: 0.541561\n",
      "epoch 17; iter: 0; batch classifier loss: 0.492251; batch adversarial loss: 0.552358\n",
      "epoch 18; iter: 0; batch classifier loss: 0.524810; batch adversarial loss: 0.553967\n",
      "epoch 19; iter: 0; batch classifier loss: 0.525508; batch adversarial loss: 0.633955\n",
      "epoch 20; iter: 0; batch classifier loss: 0.566479; batch adversarial loss: 0.573092\n",
      "epoch 21; iter: 0; batch classifier loss: 0.500411; batch adversarial loss: 0.575300\n",
      "epoch 22; iter: 0; batch classifier loss: 0.479642; batch adversarial loss: 0.519840\n",
      "epoch 23; iter: 0; batch classifier loss: 0.456995; batch adversarial loss: 0.555094\n",
      "epoch 24; iter: 0; batch classifier loss: 0.504056; batch adversarial loss: 0.548768\n",
      "epoch 25; iter: 0; batch classifier loss: 0.501385; batch adversarial loss: 0.537261\n",
      "epoch 26; iter: 0; batch classifier loss: 0.482069; batch adversarial loss: 0.642912\n",
      "epoch 27; iter: 0; batch classifier loss: 0.488469; batch adversarial loss: 0.480998\n",
      "epoch 28; iter: 0; batch classifier loss: 0.502457; batch adversarial loss: 0.540259\n",
      "epoch 29; iter: 0; batch classifier loss: 0.462859; batch adversarial loss: 0.571495\n",
      "epoch 30; iter: 0; batch classifier loss: 0.474200; batch adversarial loss: 0.515537\n",
      "epoch 31; iter: 0; batch classifier loss: 0.404757; batch adversarial loss: 0.589208\n",
      "epoch 32; iter: 0; batch classifier loss: 0.453525; batch adversarial loss: 0.563502\n",
      "epoch 33; iter: 0; batch classifier loss: 0.431382; batch adversarial loss: 0.512447\n",
      "epoch 34; iter: 0; batch classifier loss: 0.437209; batch adversarial loss: 0.523620\n",
      "epoch 35; iter: 0; batch classifier loss: 0.502519; batch adversarial loss: 0.588781\n",
      "epoch 36; iter: 0; batch classifier loss: 0.498383; batch adversarial loss: 0.520761\n",
      "epoch 37; iter: 0; batch classifier loss: 0.481743; batch adversarial loss: 0.492148\n",
      "epoch 38; iter: 0; batch classifier loss: 0.455594; batch adversarial loss: 0.590573\n",
      "epoch 39; iter: 0; batch classifier loss: 0.442970; batch adversarial loss: 0.650307\n",
      "epoch 40; iter: 0; batch classifier loss: 0.421674; batch adversarial loss: 0.625825\n",
      "epoch 41; iter: 0; batch classifier loss: 0.469523; batch adversarial loss: 0.509913\n",
      "epoch 42; iter: 0; batch classifier loss: 0.475897; batch adversarial loss: 0.506965\n",
      "epoch 43; iter: 0; batch classifier loss: 0.368519; batch adversarial loss: 0.589290\n",
      "epoch 44; iter: 0; batch classifier loss: 0.398568; batch adversarial loss: 0.509815\n",
      "epoch 45; iter: 0; batch classifier loss: 0.498159; batch adversarial loss: 0.491529\n",
      "epoch 46; iter: 0; batch classifier loss: 0.411587; batch adversarial loss: 0.471804\n",
      "epoch 47; iter: 0; batch classifier loss: 0.478907; batch adversarial loss: 0.615720\n",
      "epoch 48; iter: 0; batch classifier loss: 0.486781; batch adversarial loss: 0.569994\n",
      "epoch 49; iter: 0; batch classifier loss: 0.443341; batch adversarial loss: 0.515318\n",
      "epoch 50; iter: 0; batch classifier loss: 0.418574; batch adversarial loss: 0.590654\n",
      "epoch 51; iter: 0; batch classifier loss: 0.444266; batch adversarial loss: 0.508116\n",
      "epoch 52; iter: 0; batch classifier loss: 0.433534; batch adversarial loss: 0.542112\n",
      "epoch 53; iter: 0; batch classifier loss: 0.408265; batch adversarial loss: 0.486783\n",
      "epoch 54; iter: 0; batch classifier loss: 0.367821; batch adversarial loss: 0.615673\n",
      "epoch 55; iter: 0; batch classifier loss: 0.395837; batch adversarial loss: 0.444875\n",
      "epoch 56; iter: 0; batch classifier loss: 0.469048; batch adversarial loss: 0.565077\n",
      "epoch 57; iter: 0; batch classifier loss: 0.407109; batch adversarial loss: 0.600032\n",
      "epoch 58; iter: 0; batch classifier loss: 0.443142; batch adversarial loss: 0.616801\n",
      "epoch 59; iter: 0; batch classifier loss: 0.462331; batch adversarial loss: 0.496541\n",
      "epoch 60; iter: 0; batch classifier loss: 0.365559; batch adversarial loss: 0.610608\n",
      "epoch 61; iter: 0; batch classifier loss: 0.420293; batch adversarial loss: 0.497151\n",
      "epoch 62; iter: 0; batch classifier loss: 0.410675; batch adversarial loss: 0.546669\n",
      "epoch 63; iter: 0; batch classifier loss: 0.482934; batch adversarial loss: 0.592643\n",
      "epoch 64; iter: 0; batch classifier loss: 0.440321; batch adversarial loss: 0.527263\n",
      "epoch 65; iter: 0; batch classifier loss: 0.344136; batch adversarial loss: 0.480851\n",
      "epoch 66; iter: 0; batch classifier loss: 0.460879; batch adversarial loss: 0.563113\n",
      "epoch 67; iter: 0; batch classifier loss: 0.379392; batch adversarial loss: 0.490148\n",
      "epoch 68; iter: 0; batch classifier loss: 0.386378; batch adversarial loss: 0.536783\n",
      "epoch 69; iter: 0; batch classifier loss: 0.383972; batch adversarial loss: 0.571003\n",
      "epoch 70; iter: 0; batch classifier loss: 0.417949; batch adversarial loss: 0.554883\n",
      "epoch 71; iter: 0; batch classifier loss: 0.462367; batch adversarial loss: 0.505775\n",
      "epoch 72; iter: 0; batch classifier loss: 0.427109; batch adversarial loss: 0.571553\n",
      "epoch 73; iter: 0; batch classifier loss: 0.460960; batch adversarial loss: 0.600531\n",
      "epoch 74; iter: 0; batch classifier loss: 0.363275; batch adversarial loss: 0.470645\n",
      "epoch 75; iter: 0; batch classifier loss: 0.436212; batch adversarial loss: 0.518318\n",
      "epoch 76; iter: 0; batch classifier loss: 0.445480; batch adversarial loss: 0.573194\n",
      "epoch 77; iter: 0; batch classifier loss: 0.426295; batch adversarial loss: 0.544349\n",
      "epoch 78; iter: 0; batch classifier loss: 0.452266; batch adversarial loss: 0.551924\n",
      "epoch 79; iter: 0; batch classifier loss: 0.410491; batch adversarial loss: 0.601771\n",
      "epoch 80; iter: 0; batch classifier loss: 0.509646; batch adversarial loss: 0.544570\n",
      "epoch 81; iter: 0; batch classifier loss: 0.449825; batch adversarial loss: 0.490011\n",
      "epoch 82; iter: 0; batch classifier loss: 0.397748; batch adversarial loss: 0.575275\n",
      "epoch 83; iter: 0; batch classifier loss: 0.333632; batch adversarial loss: 0.608263\n",
      "epoch 84; iter: 0; batch classifier loss: 0.352444; batch adversarial loss: 0.542728\n",
      "epoch 85; iter: 0; batch classifier loss: 0.446430; batch adversarial loss: 0.499125\n",
      "epoch 86; iter: 0; batch classifier loss: 0.348119; batch adversarial loss: 0.561129\n",
      "epoch 87; iter: 0; batch classifier loss: 0.445873; batch adversarial loss: 0.534910\n",
      "epoch 88; iter: 0; batch classifier loss: 0.381579; batch adversarial loss: 0.500160\n",
      "epoch 89; iter: 0; batch classifier loss: 0.376050; batch adversarial loss: 0.537403\n",
      "epoch 90; iter: 0; batch classifier loss: 0.409555; batch adversarial loss: 0.488552\n",
      "epoch 91; iter: 0; batch classifier loss: 0.356029; batch adversarial loss: 0.518215\n",
      "epoch 92; iter: 0; batch classifier loss: 0.382736; batch adversarial loss: 0.553765\n",
      "epoch 93; iter: 0; batch classifier loss: 0.424234; batch adversarial loss: 0.583224\n",
      "epoch 94; iter: 0; batch classifier loss: 0.360276; batch adversarial loss: 0.569698\n",
      "epoch 95; iter: 0; batch classifier loss: 0.384222; batch adversarial loss: 0.477520\n",
      "epoch 96; iter: 0; batch classifier loss: 0.344107; batch adversarial loss: 0.462127\n",
      "epoch 97; iter: 0; batch classifier loss: 0.423719; batch adversarial loss: 0.647752\n",
      "epoch 98; iter: 0; batch classifier loss: 0.423292; batch adversarial loss: 0.518156\n",
      "epoch 99; iter: 0; batch classifier loss: 0.364435; batch adversarial loss: 0.580161\n",
      "epoch 100; iter: 0; batch classifier loss: 0.439540; batch adversarial loss: 0.488735\n",
      "epoch 101; iter: 0; batch classifier loss: 0.384387; batch adversarial loss: 0.477956\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 102; iter: 0; batch classifier loss: 0.292844; batch adversarial loss: 0.554644\n",
      "epoch 103; iter: 0; batch classifier loss: 0.437077; batch adversarial loss: 0.479777\n",
      "epoch 104; iter: 0; batch classifier loss: 0.383554; batch adversarial loss: 0.542729\n",
      "epoch 105; iter: 0; batch classifier loss: 0.395985; batch adversarial loss: 0.514930\n",
      "epoch 106; iter: 0; batch classifier loss: 0.417456; batch adversarial loss: 0.487127\n",
      "epoch 107; iter: 0; batch classifier loss: 0.442681; batch adversarial loss: 0.609186\n",
      "epoch 108; iter: 0; batch classifier loss: 0.452102; batch adversarial loss: 0.500648\n",
      "epoch 109; iter: 0; batch classifier loss: 0.365521; batch adversarial loss: 0.480945\n",
      "epoch 110; iter: 0; batch classifier loss: 0.398716; batch adversarial loss: 0.553254\n",
      "epoch 111; iter: 0; batch classifier loss: 0.316398; batch adversarial loss: 0.527250\n",
      "epoch 112; iter: 0; batch classifier loss: 0.416941; batch adversarial loss: 0.554473\n",
      "epoch 113; iter: 0; batch classifier loss: 0.374026; batch adversarial loss: 0.580874\n",
      "epoch 114; iter: 0; batch classifier loss: 0.368733; batch adversarial loss: 0.610036\n",
      "epoch 115; iter: 0; batch classifier loss: 0.408865; batch adversarial loss: 0.553873\n",
      "epoch 116; iter: 0; batch classifier loss: 0.368648; batch adversarial loss: 0.515499\n",
      "epoch 117; iter: 0; batch classifier loss: 0.439436; batch adversarial loss: 0.600848\n",
      "epoch 118; iter: 0; batch classifier loss: 0.405306; batch adversarial loss: 0.552926\n",
      "epoch 119; iter: 0; batch classifier loss: 0.337991; batch adversarial loss: 0.553443\n",
      "epoch 120; iter: 0; batch classifier loss: 0.378984; batch adversarial loss: 0.600518\n",
      "epoch 121; iter: 0; batch classifier loss: 0.454779; batch adversarial loss: 0.544317\n",
      "epoch 122; iter: 0; batch classifier loss: 0.367375; batch adversarial loss: 0.598979\n",
      "epoch 123; iter: 0; batch classifier loss: 0.331730; batch adversarial loss: 0.488932\n",
      "epoch 124; iter: 0; batch classifier loss: 0.452973; batch adversarial loss: 0.526676\n",
      "epoch 125; iter: 0; batch classifier loss: 0.402939; batch adversarial loss: 0.608662\n",
      "epoch 126; iter: 0; batch classifier loss: 0.443791; batch adversarial loss: 0.524272\n",
      "epoch 127; iter: 0; batch classifier loss: 0.351591; batch adversarial loss: 0.553900\n",
      "epoch 128; iter: 0; batch classifier loss: 0.364436; batch adversarial loss: 0.581225\n",
      "epoch 129; iter: 0; batch classifier loss: 0.349486; batch adversarial loss: 0.543438\n",
      "epoch 130; iter: 0; batch classifier loss: 0.438039; batch adversarial loss: 0.582051\n",
      "epoch 131; iter: 0; batch classifier loss: 0.332508; batch adversarial loss: 0.537999\n",
      "epoch 132; iter: 0; batch classifier loss: 0.393605; batch adversarial loss: 0.544991\n",
      "epoch 133; iter: 0; batch classifier loss: 0.411777; batch adversarial loss: 0.546943\n",
      "epoch 134; iter: 0; batch classifier loss: 0.349777; batch adversarial loss: 0.563389\n",
      "epoch 135; iter: 0; batch classifier loss: 0.376270; batch adversarial loss: 0.578312\n",
      "epoch 136; iter: 0; batch classifier loss: 0.231500; batch adversarial loss: 0.581122\n",
      "epoch 137; iter: 0; batch classifier loss: 0.341197; batch adversarial loss: 0.499152\n",
      "epoch 138; iter: 0; batch classifier loss: 0.355955; batch adversarial loss: 0.528812\n",
      "epoch 139; iter: 0; batch classifier loss: 0.356219; batch adversarial loss: 0.580695\n",
      "epoch 140; iter: 0; batch classifier loss: 0.316085; batch adversarial loss: 0.627202\n",
      "epoch 141; iter: 0; batch classifier loss: 0.363521; batch adversarial loss: 0.585300\n",
      "epoch 142; iter: 0; batch classifier loss: 0.429347; batch adversarial loss: 0.535810\n",
      "epoch 143; iter: 0; batch classifier loss: 0.376046; batch adversarial loss: 0.561063\n",
      "epoch 144; iter: 0; batch classifier loss: 0.359642; batch adversarial loss: 0.516392\n",
      "epoch 145; iter: 0; batch classifier loss: 0.421181; batch adversarial loss: 0.554784\n",
      "epoch 146; iter: 0; batch classifier loss: 0.332723; batch adversarial loss: 0.570006\n",
      "epoch 147; iter: 0; batch classifier loss: 0.362456; batch adversarial loss: 0.598825\n",
      "epoch 148; iter: 0; batch classifier loss: 0.416428; batch adversarial loss: 0.470376\n",
      "epoch 149; iter: 0; batch classifier loss: 0.422391; batch adversarial loss: 0.508519\n",
      "epoch 150; iter: 0; batch classifier loss: 0.379571; batch adversarial loss: 0.534056\n",
      "epoch 151; iter: 0; batch classifier loss: 0.365609; batch adversarial loss: 0.543756\n",
      "epoch 152; iter: 0; batch classifier loss: 0.291234; batch adversarial loss: 0.554509\n",
      "epoch 153; iter: 0; batch classifier loss: 0.345102; batch adversarial loss: 0.536816\n",
      "epoch 154; iter: 0; batch classifier loss: 0.370811; batch adversarial loss: 0.600425\n",
      "epoch 155; iter: 0; batch classifier loss: 0.411396; batch adversarial loss: 0.533473\n",
      "epoch 156; iter: 0; batch classifier loss: 0.402054; batch adversarial loss: 0.599753\n",
      "epoch 157; iter: 0; batch classifier loss: 0.325220; batch adversarial loss: 0.524579\n",
      "epoch 158; iter: 0; batch classifier loss: 0.318612; batch adversarial loss: 0.517197\n",
      "epoch 159; iter: 0; batch classifier loss: 0.359820; batch adversarial loss: 0.516135\n",
      "epoch 160; iter: 0; batch classifier loss: 0.379149; batch adversarial loss: 0.445012\n",
      "epoch 161; iter: 0; batch classifier loss: 0.424230; batch adversarial loss: 0.545629\n",
      "epoch 162; iter: 0; batch classifier loss: 0.366647; batch adversarial loss: 0.601050\n",
      "epoch 163; iter: 0; batch classifier loss: 0.364026; batch adversarial loss: 0.581976\n",
      "epoch 164; iter: 0; batch classifier loss: 0.387893; batch adversarial loss: 0.542418\n",
      "epoch 165; iter: 0; batch classifier loss: 0.412799; batch adversarial loss: 0.542826\n",
      "epoch 166; iter: 0; batch classifier loss: 0.458575; batch adversarial loss: 0.514941\n",
      "epoch 167; iter: 0; batch classifier loss: 0.349798; batch adversarial loss: 0.575032\n",
      "epoch 168; iter: 0; batch classifier loss: 0.336827; batch adversarial loss: 0.617926\n",
      "epoch 169; iter: 0; batch classifier loss: 0.369710; batch adversarial loss: 0.573458\n",
      "epoch 170; iter: 0; batch classifier loss: 0.357494; batch adversarial loss: 0.554247\n",
      "epoch 171; iter: 0; batch classifier loss: 0.358490; batch adversarial loss: 0.506790\n",
      "epoch 172; iter: 0; batch classifier loss: 0.400022; batch adversarial loss: 0.499364\n",
      "epoch 173; iter: 0; batch classifier loss: 0.353099; batch adversarial loss: 0.505408\n",
      "epoch 174; iter: 0; batch classifier loss: 0.369998; batch adversarial loss: 0.524846\n",
      "epoch 175; iter: 0; batch classifier loss: 0.326499; batch adversarial loss: 0.582765\n",
      "epoch 176; iter: 0; batch classifier loss: 0.397177; batch adversarial loss: 0.517869\n",
      "epoch 177; iter: 0; batch classifier loss: 0.374806; batch adversarial loss: 0.555305\n",
      "epoch 178; iter: 0; batch classifier loss: 0.419565; batch adversarial loss: 0.532894\n",
      "epoch 179; iter: 0; batch classifier loss: 0.429168; batch adversarial loss: 0.609519\n",
      "epoch 180; iter: 0; batch classifier loss: 0.287270; batch adversarial loss: 0.524718\n",
      "epoch 181; iter: 0; batch classifier loss: 0.358908; batch adversarial loss: 0.488229\n",
      "epoch 182; iter: 0; batch classifier loss: 0.346022; batch adversarial loss: 0.492084\n",
      "epoch 183; iter: 0; batch classifier loss: 0.379627; batch adversarial loss: 0.507112\n",
      "epoch 184; iter: 0; batch classifier loss: 0.346083; batch adversarial loss: 0.517811\n",
      "epoch 185; iter: 0; batch classifier loss: 0.347842; batch adversarial loss: 0.524477\n",
      "epoch 186; iter: 0; batch classifier loss: 0.311790; batch adversarial loss: 0.478549\n",
      "epoch 187; iter: 0; batch classifier loss: 0.334861; batch adversarial loss: 0.590976\n",
      "epoch 188; iter: 0; batch classifier loss: 0.312056; batch adversarial loss: 0.452039\n",
      "epoch 189; iter: 0; batch classifier loss: 0.344092; batch adversarial loss: 0.581626\n",
      "epoch 190; iter: 0; batch classifier loss: 0.292487; batch adversarial loss: 0.508684\n",
      "epoch 191; iter: 0; batch classifier loss: 0.359132; batch adversarial loss: 0.544901\n",
      "epoch 192; iter: 0; batch classifier loss: 0.393479; batch adversarial loss: 0.581372\n",
      "epoch 193; iter: 0; batch classifier loss: 0.385052; batch adversarial loss: 0.525988\n",
      "epoch 194; iter: 0; batch classifier loss: 0.374652; batch adversarial loss: 0.571741\n",
      "epoch 195; iter: 0; batch classifier loss: 0.405915; batch adversarial loss: 0.497882\n",
      "epoch 196; iter: 0; batch classifier loss: 0.359300; batch adversarial loss: 0.423707\n",
      "epoch 197; iter: 0; batch classifier loss: 0.377211; batch adversarial loss: 0.527019\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 198; iter: 0; batch classifier loss: 0.270373; batch adversarial loss: 0.497695\n",
      "epoch 199; iter: 0; batch classifier loss: 0.368085; batch adversarial loss: 0.527485\n",
      "epoch 0; iter: 0; batch classifier loss: 0.707748; batch adversarial loss: 0.697818\n",
      "epoch 1; iter: 0; batch classifier loss: 0.590556; batch adversarial loss: 0.669138\n",
      "epoch 2; iter: 0; batch classifier loss: 0.630304; batch adversarial loss: 0.633557\n",
      "epoch 3; iter: 0; batch classifier loss: 0.580189; batch adversarial loss: 0.646975\n",
      "epoch 4; iter: 0; batch classifier loss: 0.582133; batch adversarial loss: 0.633884\n",
      "epoch 5; iter: 0; batch classifier loss: 0.583455; batch adversarial loss: 0.635334\n",
      "epoch 6; iter: 0; batch classifier loss: 0.605821; batch adversarial loss: 0.607314\n",
      "epoch 7; iter: 0; batch classifier loss: 0.642843; batch adversarial loss: 0.565779\n",
      "epoch 8; iter: 0; batch classifier loss: 0.601738; batch adversarial loss: 0.615385\n",
      "epoch 9; iter: 0; batch classifier loss: 0.516722; batch adversarial loss: 0.612145\n",
      "epoch 10; iter: 0; batch classifier loss: 0.544930; batch adversarial loss: 0.615837\n",
      "epoch 11; iter: 0; batch classifier loss: 0.556616; batch adversarial loss: 0.588883\n",
      "epoch 12; iter: 0; batch classifier loss: 0.553002; batch adversarial loss: 0.580406\n",
      "epoch 13; iter: 0; batch classifier loss: 0.472109; batch adversarial loss: 0.597073\n",
      "epoch 14; iter: 0; batch classifier loss: 0.568532; batch adversarial loss: 0.542266\n",
      "epoch 15; iter: 0; batch classifier loss: 0.539494; batch adversarial loss: 0.573658\n",
      "epoch 16; iter: 0; batch classifier loss: 0.472917; batch adversarial loss: 0.646745\n",
      "epoch 17; iter: 0; batch classifier loss: 0.518955; batch adversarial loss: 0.542492\n",
      "epoch 18; iter: 0; batch classifier loss: 0.519940; batch adversarial loss: 0.554640\n",
      "epoch 19; iter: 0; batch classifier loss: 0.437427; batch adversarial loss: 0.563314\n",
      "epoch 20; iter: 0; batch classifier loss: 0.512081; batch adversarial loss: 0.558311\n",
      "epoch 21; iter: 0; batch classifier loss: 0.475440; batch adversarial loss: 0.611358\n",
      "epoch 22; iter: 0; batch classifier loss: 0.428442; batch adversarial loss: 0.554841\n",
      "epoch 23; iter: 0; batch classifier loss: 0.486308; batch adversarial loss: 0.543153\n",
      "epoch 24; iter: 0; batch classifier loss: 0.434724; batch adversarial loss: 0.524689\n",
      "epoch 25; iter: 0; batch classifier loss: 0.417940; batch adversarial loss: 0.525744\n",
      "epoch 26; iter: 0; batch classifier loss: 0.490222; batch adversarial loss: 0.562533\n",
      "epoch 27; iter: 0; batch classifier loss: 0.484469; batch adversarial loss: 0.578377\n",
      "epoch 28; iter: 0; batch classifier loss: 0.475521; batch adversarial loss: 0.513400\n",
      "epoch 29; iter: 0; batch classifier loss: 0.431698; batch adversarial loss: 0.562672\n",
      "epoch 30; iter: 0; batch classifier loss: 0.454928; batch adversarial loss: 0.570737\n",
      "epoch 31; iter: 0; batch classifier loss: 0.563045; batch adversarial loss: 0.579218\n",
      "epoch 32; iter: 0; batch classifier loss: 0.449368; batch adversarial loss: 0.537225\n",
      "epoch 33; iter: 0; batch classifier loss: 0.452955; batch adversarial loss: 0.511360\n",
      "epoch 34; iter: 0; batch classifier loss: 0.434712; batch adversarial loss: 0.545905\n",
      "epoch 35; iter: 0; batch classifier loss: 0.478119; batch adversarial loss: 0.579886\n",
      "epoch 36; iter: 0; batch classifier loss: 0.437697; batch adversarial loss: 0.578377\n",
      "epoch 37; iter: 0; batch classifier loss: 0.457486; batch adversarial loss: 0.527714\n",
      "epoch 38; iter: 0; batch classifier loss: 0.452408; batch adversarial loss: 0.526896\n",
      "epoch 39; iter: 0; batch classifier loss: 0.377405; batch adversarial loss: 0.606040\n",
      "epoch 40; iter: 0; batch classifier loss: 0.413363; batch adversarial loss: 0.604571\n",
      "epoch 41; iter: 0; batch classifier loss: 0.403637; batch adversarial loss: 0.554770\n",
      "epoch 42; iter: 0; batch classifier loss: 0.392560; batch adversarial loss: 0.518039\n",
      "epoch 43; iter: 0; batch classifier loss: 0.434558; batch adversarial loss: 0.528628\n",
      "epoch 44; iter: 0; batch classifier loss: 0.406582; batch adversarial loss: 0.647192\n",
      "epoch 45; iter: 0; batch classifier loss: 0.382854; batch adversarial loss: 0.554701\n",
      "epoch 46; iter: 0; batch classifier loss: 0.364883; batch adversarial loss: 0.615573\n",
      "epoch 47; iter: 0; batch classifier loss: 0.399472; batch adversarial loss: 0.598169\n",
      "epoch 48; iter: 0; batch classifier loss: 0.501823; batch adversarial loss: 0.586147\n",
      "epoch 49; iter: 0; batch classifier loss: 0.457081; batch adversarial loss: 0.554000\n",
      "epoch 50; iter: 0; batch classifier loss: 0.460062; batch adversarial loss: 0.535782\n",
      "epoch 51; iter: 0; batch classifier loss: 0.374877; batch adversarial loss: 0.633606\n",
      "epoch 52; iter: 0; batch classifier loss: 0.420610; batch adversarial loss: 0.507521\n",
      "epoch 53; iter: 0; batch classifier loss: 0.404432; batch adversarial loss: 0.534716\n",
      "epoch 54; iter: 0; batch classifier loss: 0.384091; batch adversarial loss: 0.546192\n",
      "epoch 55; iter: 0; batch classifier loss: 0.455911; batch adversarial loss: 0.518456\n",
      "epoch 56; iter: 0; batch classifier loss: 0.383242; batch adversarial loss: 0.598613\n",
      "epoch 57; iter: 0; batch classifier loss: 0.377627; batch adversarial loss: 0.510808\n",
      "epoch 58; iter: 0; batch classifier loss: 0.403490; batch adversarial loss: 0.689622\n",
      "epoch 59; iter: 0; batch classifier loss: 0.483179; batch adversarial loss: 0.604787\n",
      "epoch 60; iter: 0; batch classifier loss: 0.410213; batch adversarial loss: 0.533469\n",
      "epoch 61; iter: 0; batch classifier loss: 0.414970; batch adversarial loss: 0.511310\n",
      "epoch 62; iter: 0; batch classifier loss: 0.448875; batch adversarial loss: 0.490599\n",
      "epoch 63; iter: 0; batch classifier loss: 0.429643; batch adversarial loss: 0.519108\n",
      "epoch 64; iter: 0; batch classifier loss: 0.374926; batch adversarial loss: 0.553348\n",
      "epoch 65; iter: 0; batch classifier loss: 0.386179; batch adversarial loss: 0.527396\n",
      "epoch 66; iter: 0; batch classifier loss: 0.538657; batch adversarial loss: 0.570223\n",
      "epoch 67; iter: 0; batch classifier loss: 0.390212; batch adversarial loss: 0.611504\n",
      "epoch 68; iter: 0; batch classifier loss: 0.432426; batch adversarial loss: 0.494394\n",
      "epoch 69; iter: 0; batch classifier loss: 0.340088; batch adversarial loss: 0.561772\n",
      "epoch 70; iter: 0; batch classifier loss: 0.443092; batch adversarial loss: 0.537938\n",
      "epoch 71; iter: 0; batch classifier loss: 0.337227; batch adversarial loss: 0.561015\n",
      "epoch 72; iter: 0; batch classifier loss: 0.401685; batch adversarial loss: 0.509717\n",
      "epoch 73; iter: 0; batch classifier loss: 0.436700; batch adversarial loss: 0.569891\n",
      "epoch 74; iter: 0; batch classifier loss: 0.347698; batch adversarial loss: 0.559705\n",
      "epoch 75; iter: 0; batch classifier loss: 0.438125; batch adversarial loss: 0.566925\n",
      "epoch 76; iter: 0; batch classifier loss: 0.464436; batch adversarial loss: 0.553436\n",
      "epoch 77; iter: 0; batch classifier loss: 0.443718; batch adversarial loss: 0.566524\n",
      "epoch 78; iter: 0; batch classifier loss: 0.484533; batch adversarial loss: 0.477854\n",
      "epoch 79; iter: 0; batch classifier loss: 0.396651; batch adversarial loss: 0.556841\n",
      "epoch 80; iter: 0; batch classifier loss: 0.380338; batch adversarial loss: 0.542197\n",
      "epoch 81; iter: 0; batch classifier loss: 0.411253; batch adversarial loss: 0.608775\n",
      "epoch 82; iter: 0; batch classifier loss: 0.370036; batch adversarial loss: 0.587155\n",
      "epoch 83; iter: 0; batch classifier loss: 0.455394; batch adversarial loss: 0.608588\n",
      "epoch 84; iter: 0; batch classifier loss: 0.356040; batch adversarial loss: 0.587513\n",
      "epoch 85; iter: 0; batch classifier loss: 0.350151; batch adversarial loss: 0.591146\n",
      "epoch 86; iter: 0; batch classifier loss: 0.351168; batch adversarial loss: 0.485094\n",
      "epoch 87; iter: 0; batch classifier loss: 0.423543; batch adversarial loss: 0.517669\n",
      "epoch 88; iter: 0; batch classifier loss: 0.390901; batch adversarial loss: 0.524705\n",
      "epoch 89; iter: 0; batch classifier loss: 0.330256; batch adversarial loss: 0.567140\n",
      "epoch 90; iter: 0; batch classifier loss: 0.428770; batch adversarial loss: 0.500195\n",
      "epoch 91; iter: 0; batch classifier loss: 0.297864; batch adversarial loss: 0.549854\n",
      "epoch 92; iter: 0; batch classifier loss: 0.466919; batch adversarial loss: 0.578260\n",
      "epoch 93; iter: 0; batch classifier loss: 0.324908; batch adversarial loss: 0.529578\n",
      "epoch 94; iter: 0; batch classifier loss: 0.362393; batch adversarial loss: 0.511277\n",
      "epoch 95; iter: 0; batch classifier loss: 0.361962; batch adversarial loss: 0.482506\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 96; iter: 0; batch classifier loss: 0.375877; batch adversarial loss: 0.619673\n",
      "epoch 97; iter: 0; batch classifier loss: 0.451654; batch adversarial loss: 0.519788\n",
      "epoch 98; iter: 0; batch classifier loss: 0.320497; batch adversarial loss: 0.591704\n",
      "epoch 99; iter: 0; batch classifier loss: 0.409711; batch adversarial loss: 0.626209\n",
      "epoch 100; iter: 0; batch classifier loss: 0.408642; batch adversarial loss: 0.547282\n",
      "epoch 101; iter: 0; batch classifier loss: 0.301600; batch adversarial loss: 0.556101\n",
      "epoch 102; iter: 0; batch classifier loss: 0.331763; batch adversarial loss: 0.518690\n",
      "epoch 103; iter: 0; batch classifier loss: 0.355088; batch adversarial loss: 0.535716\n",
      "epoch 104; iter: 0; batch classifier loss: 0.430414; batch adversarial loss: 0.560165\n",
      "epoch 105; iter: 0; batch classifier loss: 0.316724; batch adversarial loss: 0.616888\n",
      "epoch 106; iter: 0; batch classifier loss: 0.397210; batch adversarial loss: 0.513095\n",
      "epoch 107; iter: 0; batch classifier loss: 0.377404; batch adversarial loss: 0.574252\n",
      "epoch 108; iter: 0; batch classifier loss: 0.390279; batch adversarial loss: 0.508860\n",
      "epoch 109; iter: 0; batch classifier loss: 0.396407; batch adversarial loss: 0.567800\n",
      "epoch 110; iter: 0; batch classifier loss: 0.436183; batch adversarial loss: 0.633371\n",
      "epoch 111; iter: 0; batch classifier loss: 0.400692; batch adversarial loss: 0.566851\n",
      "epoch 112; iter: 0; batch classifier loss: 0.396087; batch adversarial loss: 0.541827\n",
      "epoch 113; iter: 0; batch classifier loss: 0.382005; batch adversarial loss: 0.555799\n",
      "epoch 114; iter: 0; batch classifier loss: 0.340719; batch adversarial loss: 0.574983\n",
      "epoch 115; iter: 0; batch classifier loss: 0.399545; batch adversarial loss: 0.549881\n",
      "epoch 116; iter: 0; batch classifier loss: 0.312468; batch adversarial loss: 0.540894\n",
      "epoch 117; iter: 0; batch classifier loss: 0.308099; batch adversarial loss: 0.559092\n",
      "epoch 118; iter: 0; batch classifier loss: 0.399103; batch adversarial loss: 0.555634\n",
      "epoch 119; iter: 0; batch classifier loss: 0.414979; batch adversarial loss: 0.549517\n",
      "epoch 120; iter: 0; batch classifier loss: 0.358867; batch adversarial loss: 0.445896\n",
      "epoch 121; iter: 0; batch classifier loss: 0.359913; batch adversarial loss: 0.515312\n",
      "epoch 122; iter: 0; batch classifier loss: 0.307340; batch adversarial loss: 0.545578\n",
      "epoch 123; iter: 0; batch classifier loss: 0.311433; batch adversarial loss: 0.599200\n",
      "epoch 124; iter: 0; batch classifier loss: 0.304390; batch adversarial loss: 0.457364\n",
      "epoch 125; iter: 0; batch classifier loss: 0.322968; batch adversarial loss: 0.554315\n",
      "epoch 126; iter: 0; batch classifier loss: 0.358585; batch adversarial loss: 0.570395\n",
      "epoch 127; iter: 0; batch classifier loss: 0.395908; batch adversarial loss: 0.614576\n",
      "epoch 128; iter: 0; batch classifier loss: 0.299289; batch adversarial loss: 0.553638\n",
      "epoch 129; iter: 0; batch classifier loss: 0.354598; batch adversarial loss: 0.560580\n",
      "epoch 130; iter: 0; batch classifier loss: 0.433865; batch adversarial loss: 0.527648\n",
      "epoch 131; iter: 0; batch classifier loss: 0.369461; batch adversarial loss: 0.493372\n",
      "epoch 132; iter: 0; batch classifier loss: 0.393845; batch adversarial loss: 0.578399\n",
      "epoch 133; iter: 0; batch classifier loss: 0.369007; batch adversarial loss: 0.563273\n",
      "epoch 134; iter: 0; batch classifier loss: 0.377465; batch adversarial loss: 0.577025\n",
      "epoch 135; iter: 0; batch classifier loss: 0.359760; batch adversarial loss: 0.531061\n",
      "epoch 136; iter: 0; batch classifier loss: 0.403697; batch adversarial loss: 0.595022\n",
      "epoch 137; iter: 0; batch classifier loss: 0.352132; batch adversarial loss: 0.526995\n",
      "epoch 138; iter: 0; batch classifier loss: 0.342780; batch adversarial loss: 0.603775\n",
      "epoch 139; iter: 0; batch classifier loss: 0.432492; batch adversarial loss: 0.573058\n",
      "epoch 140; iter: 0; batch classifier loss: 0.349751; batch adversarial loss: 0.567270\n",
      "epoch 141; iter: 0; batch classifier loss: 0.322476; batch adversarial loss: 0.473529\n",
      "epoch 142; iter: 0; batch classifier loss: 0.333356; batch adversarial loss: 0.490217\n",
      "epoch 143; iter: 0; batch classifier loss: 0.344328; batch adversarial loss: 0.591318\n",
      "epoch 144; iter: 0; batch classifier loss: 0.328810; batch adversarial loss: 0.481342\n",
      "epoch 145; iter: 0; batch classifier loss: 0.404963; batch adversarial loss: 0.582227\n",
      "epoch 146; iter: 0; batch classifier loss: 0.313353; batch adversarial loss: 0.605047\n",
      "epoch 147; iter: 0; batch classifier loss: 0.348321; batch adversarial loss: 0.572763\n",
      "epoch 148; iter: 0; batch classifier loss: 0.349830; batch adversarial loss: 0.585968\n",
      "epoch 149; iter: 0; batch classifier loss: 0.392264; batch adversarial loss: 0.550380\n",
      "epoch 150; iter: 0; batch classifier loss: 0.375520; batch adversarial loss: 0.525280\n",
      "epoch 151; iter: 0; batch classifier loss: 0.332287; batch adversarial loss: 0.566717\n",
      "epoch 152; iter: 0; batch classifier loss: 0.325523; batch adversarial loss: 0.628570\n",
      "epoch 153; iter: 0; batch classifier loss: 0.400080; batch adversarial loss: 0.509885\n",
      "epoch 154; iter: 0; batch classifier loss: 0.384690; batch adversarial loss: 0.600283\n",
      "epoch 155; iter: 0; batch classifier loss: 0.413185; batch adversarial loss: 0.541242\n",
      "epoch 156; iter: 0; batch classifier loss: 0.378041; batch adversarial loss: 0.576700\n",
      "epoch 157; iter: 0; batch classifier loss: 0.374861; batch adversarial loss: 0.544630\n",
      "epoch 158; iter: 0; batch classifier loss: 0.382303; batch adversarial loss: 0.535412\n",
      "epoch 159; iter: 0; batch classifier loss: 0.400790; batch adversarial loss: 0.600151\n",
      "epoch 160; iter: 0; batch classifier loss: 0.326524; batch adversarial loss: 0.555452\n",
      "epoch 161; iter: 0; batch classifier loss: 0.387437; batch adversarial loss: 0.498099\n",
      "epoch 162; iter: 0; batch classifier loss: 0.401999; batch adversarial loss: 0.581376\n",
      "epoch 163; iter: 0; batch classifier loss: 0.389058; batch adversarial loss: 0.521249\n",
      "epoch 164; iter: 0; batch classifier loss: 0.340979; batch adversarial loss: 0.542541\n",
      "epoch 165; iter: 0; batch classifier loss: 0.299682; batch adversarial loss: 0.570297\n",
      "epoch 166; iter: 0; batch classifier loss: 0.319970; batch adversarial loss: 0.599831\n",
      "epoch 167; iter: 0; batch classifier loss: 0.394642; batch adversarial loss: 0.546296\n",
      "epoch 168; iter: 0; batch classifier loss: 0.339616; batch adversarial loss: 0.505928\n",
      "epoch 169; iter: 0; batch classifier loss: 0.415875; batch adversarial loss: 0.606051\n",
      "epoch 170; iter: 0; batch classifier loss: 0.395679; batch adversarial loss: 0.579668\n",
      "epoch 171; iter: 0; batch classifier loss: 0.395207; batch adversarial loss: 0.544683\n",
      "epoch 172; iter: 0; batch classifier loss: 0.481056; batch adversarial loss: 0.515283\n",
      "epoch 173; iter: 0; batch classifier loss: 0.377529; batch adversarial loss: 0.517345\n",
      "epoch 174; iter: 0; batch classifier loss: 0.364899; batch adversarial loss: 0.541432\n",
      "epoch 175; iter: 0; batch classifier loss: 0.356342; batch adversarial loss: 0.596282\n",
      "epoch 176; iter: 0; batch classifier loss: 0.351587; batch adversarial loss: 0.588160\n",
      "epoch 177; iter: 0; batch classifier loss: 0.337530; batch adversarial loss: 0.537380\n",
      "epoch 178; iter: 0; batch classifier loss: 0.317399; batch adversarial loss: 0.609154\n",
      "epoch 179; iter: 0; batch classifier loss: 0.436031; batch adversarial loss: 0.576250\n",
      "epoch 180; iter: 0; batch classifier loss: 0.358214; batch adversarial loss: 0.600273\n",
      "epoch 181; iter: 0; batch classifier loss: 0.279652; batch adversarial loss: 0.519034\n",
      "epoch 182; iter: 0; batch classifier loss: 0.348295; batch adversarial loss: 0.621768\n",
      "epoch 183; iter: 0; batch classifier loss: 0.423053; batch adversarial loss: 0.629535\n",
      "epoch 184; iter: 0; batch classifier loss: 0.340252; batch adversarial loss: 0.574736\n",
      "epoch 185; iter: 0; batch classifier loss: 0.327806; batch adversarial loss: 0.526016\n",
      "epoch 186; iter: 0; batch classifier loss: 0.367414; batch adversarial loss: 0.519378\n",
      "epoch 187; iter: 0; batch classifier loss: 0.395715; batch adversarial loss: 0.507543\n",
      "epoch 188; iter: 0; batch classifier loss: 0.376712; batch adversarial loss: 0.587764\n",
      "epoch 189; iter: 0; batch classifier loss: 0.266302; batch adversarial loss: 0.579391\n",
      "epoch 190; iter: 0; batch classifier loss: 0.350239; batch adversarial loss: 0.536470\n",
      "epoch 191; iter: 0; batch classifier loss: 0.334374; batch adversarial loss: 0.549954\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 192; iter: 0; batch classifier loss: 0.351668; batch adversarial loss: 0.548844\n",
      "epoch 193; iter: 0; batch classifier loss: 0.390298; batch adversarial loss: 0.535718\n",
      "epoch 194; iter: 0; batch classifier loss: 0.331975; batch adversarial loss: 0.568151\n",
      "epoch 195; iter: 0; batch classifier loss: 0.422318; batch adversarial loss: 0.505100\n",
      "epoch 196; iter: 0; batch classifier loss: 0.346773; batch adversarial loss: 0.550298\n",
      "epoch 197; iter: 0; batch classifier loss: 0.307632; batch adversarial loss: 0.495206\n",
      "epoch 198; iter: 0; batch classifier loss: 0.415934; batch adversarial loss: 0.596928\n",
      "epoch 199; iter: 0; batch classifier loss: 0.366559; batch adversarial loss: 0.576810\n",
      "epoch 0; iter: 0; batch classifier loss: 0.769819; batch adversarial loss: 0.749928\n",
      "epoch 1; iter: 0; batch classifier loss: 0.725378; batch adversarial loss: 0.713136\n",
      "epoch 2; iter: 0; batch classifier loss: 0.587811; batch adversarial loss: 0.657976\n",
      "epoch 3; iter: 0; batch classifier loss: 0.649582; batch adversarial loss: 0.657310\n",
      "epoch 4; iter: 0; batch classifier loss: 0.535135; batch adversarial loss: 0.642088\n",
      "epoch 5; iter: 0; batch classifier loss: 0.600957; batch adversarial loss: 0.624727\n",
      "epoch 6; iter: 0; batch classifier loss: 0.582690; batch adversarial loss: 0.608623\n",
      "epoch 7; iter: 0; batch classifier loss: 0.544155; batch adversarial loss: 0.611064\n",
      "epoch 8; iter: 0; batch classifier loss: 0.533433; batch adversarial loss: 0.600390\n",
      "epoch 9; iter: 0; batch classifier loss: 0.552992; batch adversarial loss: 0.588079\n",
      "epoch 10; iter: 0; batch classifier loss: 0.543218; batch adversarial loss: 0.596723\n",
      "epoch 11; iter: 0; batch classifier loss: 0.539003; batch adversarial loss: 0.581254\n",
      "epoch 12; iter: 0; batch classifier loss: 0.531936; batch adversarial loss: 0.573395\n",
      "epoch 13; iter: 0; batch classifier loss: 0.481326; batch adversarial loss: 0.544748\n",
      "epoch 14; iter: 0; batch classifier loss: 0.586506; batch adversarial loss: 0.556407\n",
      "epoch 15; iter: 0; batch classifier loss: 0.479917; batch adversarial loss: 0.597283\n",
      "epoch 16; iter: 0; batch classifier loss: 0.583099; batch adversarial loss: 0.533227\n",
      "epoch 17; iter: 0; batch classifier loss: 0.536760; batch adversarial loss: 0.641138\n",
      "epoch 18; iter: 0; batch classifier loss: 0.530198; batch adversarial loss: 0.597834\n",
      "epoch 19; iter: 0; batch classifier loss: 0.526661; batch adversarial loss: 0.535016\n",
      "epoch 20; iter: 0; batch classifier loss: 0.502333; batch adversarial loss: 0.602525\n",
      "epoch 21; iter: 0; batch classifier loss: 0.528934; batch adversarial loss: 0.606122\n",
      "epoch 22; iter: 0; batch classifier loss: 0.393801; batch adversarial loss: 0.617909\n",
      "epoch 23; iter: 0; batch classifier loss: 0.506121; batch adversarial loss: 0.581953\n",
      "epoch 24; iter: 0; batch classifier loss: 0.507392; batch adversarial loss: 0.480769\n",
      "epoch 25; iter: 0; batch classifier loss: 0.484955; batch adversarial loss: 0.556010\n",
      "epoch 26; iter: 0; batch classifier loss: 0.491255; batch adversarial loss: 0.618235\n",
      "epoch 27; iter: 0; batch classifier loss: 0.489304; batch adversarial loss: 0.546976\n",
      "epoch 28; iter: 0; batch classifier loss: 0.544040; batch adversarial loss: 0.579090\n",
      "epoch 29; iter: 0; batch classifier loss: 0.435332; batch adversarial loss: 0.504311\n",
      "epoch 30; iter: 0; batch classifier loss: 0.479466; batch adversarial loss: 0.595857\n",
      "epoch 31; iter: 0; batch classifier loss: 0.455332; batch adversarial loss: 0.604724\n",
      "epoch 32; iter: 0; batch classifier loss: 0.451703; batch adversarial loss: 0.562561\n",
      "epoch 33; iter: 0; batch classifier loss: 0.438032; batch adversarial loss: 0.561288\n",
      "epoch 34; iter: 0; batch classifier loss: 0.453977; batch adversarial loss: 0.571215\n",
      "epoch 35; iter: 0; batch classifier loss: 0.446771; batch adversarial loss: 0.552498\n",
      "epoch 36; iter: 0; batch classifier loss: 0.472230; batch adversarial loss: 0.570678\n",
      "epoch 37; iter: 0; batch classifier loss: 0.422495; batch adversarial loss: 0.571022\n",
      "epoch 38; iter: 0; batch classifier loss: 0.504168; batch adversarial loss: 0.578867\n",
      "epoch 39; iter: 0; batch classifier loss: 0.457139; batch adversarial loss: 0.536839\n",
      "epoch 40; iter: 0; batch classifier loss: 0.454386; batch adversarial loss: 0.510560\n",
      "epoch 41; iter: 0; batch classifier loss: 0.447852; batch adversarial loss: 0.599522\n",
      "epoch 42; iter: 0; batch classifier loss: 0.399972; batch adversarial loss: 0.534050\n",
      "epoch 43; iter: 0; batch classifier loss: 0.418628; batch adversarial loss: 0.549006\n",
      "epoch 44; iter: 0; batch classifier loss: 0.477101; batch adversarial loss: 0.557423\n",
      "epoch 45; iter: 0; batch classifier loss: 0.384333; batch adversarial loss: 0.581370\n",
      "epoch 46; iter: 0; batch classifier loss: 0.427086; batch adversarial loss: 0.608555\n",
      "epoch 47; iter: 0; batch classifier loss: 0.462328; batch adversarial loss: 0.589521\n",
      "epoch 48; iter: 0; batch classifier loss: 0.493850; batch adversarial loss: 0.561958\n",
      "epoch 49; iter: 0; batch classifier loss: 0.493445; batch adversarial loss: 0.497690\n",
      "epoch 50; iter: 0; batch classifier loss: 0.565221; batch adversarial loss: 0.553742\n",
      "epoch 51; iter: 0; batch classifier loss: 0.464489; batch adversarial loss: 0.508265\n",
      "epoch 52; iter: 0; batch classifier loss: 0.438724; batch adversarial loss: 0.558129\n",
      "epoch 53; iter: 0; batch classifier loss: 0.389959; batch adversarial loss: 0.456249\n",
      "epoch 54; iter: 0; batch classifier loss: 0.438153; batch adversarial loss: 0.535888\n",
      "epoch 55; iter: 0; batch classifier loss: 0.377629; batch adversarial loss: 0.612600\n",
      "epoch 56; iter: 0; batch classifier loss: 0.419332; batch adversarial loss: 0.546876\n",
      "epoch 57; iter: 0; batch classifier loss: 0.466629; batch adversarial loss: 0.621990\n",
      "epoch 58; iter: 0; batch classifier loss: 0.487000; batch adversarial loss: 0.518547\n",
      "epoch 59; iter: 0; batch classifier loss: 0.421022; batch adversarial loss: 0.489570\n",
      "epoch 60; iter: 0; batch classifier loss: 0.316335; batch adversarial loss: 0.616354\n",
      "epoch 61; iter: 0; batch classifier loss: 0.366607; batch adversarial loss: 0.490365\n",
      "epoch 62; iter: 0; batch classifier loss: 0.405509; batch adversarial loss: 0.580756\n",
      "epoch 63; iter: 0; batch classifier loss: 0.468804; batch adversarial loss: 0.497884\n",
      "epoch 64; iter: 0; batch classifier loss: 0.459733; batch adversarial loss: 0.526148\n",
      "epoch 65; iter: 0; batch classifier loss: 0.449720; batch adversarial loss: 0.614913\n",
      "epoch 66; iter: 0; batch classifier loss: 0.429465; batch adversarial loss: 0.514442\n",
      "epoch 67; iter: 0; batch classifier loss: 0.366330; batch adversarial loss: 0.627523\n",
      "epoch 68; iter: 0; batch classifier loss: 0.384862; batch adversarial loss: 0.524458\n",
      "epoch 69; iter: 0; batch classifier loss: 0.405325; batch adversarial loss: 0.490242\n",
      "epoch 70; iter: 0; batch classifier loss: 0.375960; batch adversarial loss: 0.550605\n",
      "epoch 71; iter: 0; batch classifier loss: 0.401540; batch adversarial loss: 0.540729\n",
      "epoch 72; iter: 0; batch classifier loss: 0.387993; batch adversarial loss: 0.567940\n",
      "epoch 73; iter: 0; batch classifier loss: 0.392220; batch adversarial loss: 0.607184\n",
      "epoch 74; iter: 0; batch classifier loss: 0.415398; batch adversarial loss: 0.547704\n",
      "epoch 75; iter: 0; batch classifier loss: 0.405039; batch adversarial loss: 0.575276\n",
      "epoch 76; iter: 0; batch classifier loss: 0.458637; batch adversarial loss: 0.552712\n",
      "epoch 77; iter: 0; batch classifier loss: 0.371196; batch adversarial loss: 0.599316\n",
      "epoch 78; iter: 0; batch classifier loss: 0.468299; batch adversarial loss: 0.570923\n",
      "epoch 79; iter: 0; batch classifier loss: 0.425743; batch adversarial loss: 0.555508\n",
      "epoch 80; iter: 0; batch classifier loss: 0.391767; batch adversarial loss: 0.584226\n",
      "epoch 81; iter: 0; batch classifier loss: 0.379223; batch adversarial loss: 0.476504\n",
      "epoch 82; iter: 0; batch classifier loss: 0.350305; batch adversarial loss: 0.517459\n",
      "epoch 83; iter: 0; batch classifier loss: 0.394105; batch adversarial loss: 0.508327\n",
      "epoch 84; iter: 0; batch classifier loss: 0.423703; batch adversarial loss: 0.556484\n",
      "epoch 85; iter: 0; batch classifier loss: 0.328436; batch adversarial loss: 0.587541\n",
      "epoch 86; iter: 0; batch classifier loss: 0.419656; batch adversarial loss: 0.543818\n",
      "epoch 87; iter: 0; batch classifier loss: 0.435720; batch adversarial loss: 0.489340\n",
      "epoch 88; iter: 0; batch classifier loss: 0.419873; batch adversarial loss: 0.541000\n",
      "epoch 89; iter: 0; batch classifier loss: 0.422931; batch adversarial loss: 0.549578\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 90; iter: 0; batch classifier loss: 0.376442; batch adversarial loss: 0.545928\n",
      "epoch 91; iter: 0; batch classifier loss: 0.438761; batch adversarial loss: 0.549078\n",
      "epoch 92; iter: 0; batch classifier loss: 0.439341; batch adversarial loss: 0.481301\n",
      "epoch 93; iter: 0; batch classifier loss: 0.411061; batch adversarial loss: 0.494880\n",
      "epoch 94; iter: 0; batch classifier loss: 0.434980; batch adversarial loss: 0.515118\n",
      "epoch 95; iter: 0; batch classifier loss: 0.366347; batch adversarial loss: 0.567800\n",
      "epoch 96; iter: 0; batch classifier loss: 0.422893; batch adversarial loss: 0.544816\n",
      "epoch 97; iter: 0; batch classifier loss: 0.385955; batch adversarial loss: 0.491561\n",
      "epoch 98; iter: 0; batch classifier loss: 0.411243; batch adversarial loss: 0.568367\n",
      "epoch 99; iter: 0; batch classifier loss: 0.451213; batch adversarial loss: 0.578393\n",
      "epoch 100; iter: 0; batch classifier loss: 0.444722; batch adversarial loss: 0.473502\n",
      "epoch 101; iter: 0; batch classifier loss: 0.249273; batch adversarial loss: 0.507865\n",
      "epoch 102; iter: 0; batch classifier loss: 0.307829; batch adversarial loss: 0.606833\n",
      "epoch 103; iter: 0; batch classifier loss: 0.399287; batch adversarial loss: 0.522490\n",
      "epoch 104; iter: 0; batch classifier loss: 0.422078; batch adversarial loss: 0.602345\n",
      "epoch 105; iter: 0; batch classifier loss: 0.395939; batch adversarial loss: 0.570074\n",
      "epoch 106; iter: 0; batch classifier loss: 0.430099; batch adversarial loss: 0.475278\n",
      "epoch 107; iter: 0; batch classifier loss: 0.428369; batch adversarial loss: 0.490114\n",
      "epoch 108; iter: 0; batch classifier loss: 0.468125; batch adversarial loss: 0.573727\n",
      "epoch 109; iter: 0; batch classifier loss: 0.408395; batch adversarial loss: 0.553223\n",
      "epoch 110; iter: 0; batch classifier loss: 0.352472; batch adversarial loss: 0.511130\n",
      "epoch 111; iter: 0; batch classifier loss: 0.352665; batch adversarial loss: 0.544117\n",
      "epoch 112; iter: 0; batch classifier loss: 0.358108; batch adversarial loss: 0.586584\n",
      "epoch 113; iter: 0; batch classifier loss: 0.405704; batch adversarial loss: 0.534774\n",
      "epoch 114; iter: 0; batch classifier loss: 0.415165; batch adversarial loss: 0.457319\n",
      "epoch 115; iter: 0; batch classifier loss: 0.330004; batch adversarial loss: 0.537958\n",
      "epoch 116; iter: 0; batch classifier loss: 0.422082; batch adversarial loss: 0.475070\n",
      "epoch 117; iter: 0; batch classifier loss: 0.341476; batch adversarial loss: 0.487229\n",
      "epoch 118; iter: 0; batch classifier loss: 0.392250; batch adversarial loss: 0.523856\n",
      "epoch 119; iter: 0; batch classifier loss: 0.394100; batch adversarial loss: 0.558950\n",
      "epoch 120; iter: 0; batch classifier loss: 0.413603; batch adversarial loss: 0.557845\n",
      "epoch 121; iter: 0; batch classifier loss: 0.296179; batch adversarial loss: 0.572676\n",
      "epoch 122; iter: 0; batch classifier loss: 0.424852; batch adversarial loss: 0.554070\n",
      "epoch 123; iter: 0; batch classifier loss: 0.373916; batch adversarial loss: 0.495749\n",
      "epoch 124; iter: 0; batch classifier loss: 0.374645; batch adversarial loss: 0.583871\n",
      "epoch 125; iter: 0; batch classifier loss: 0.399503; batch adversarial loss: 0.556103\n",
      "epoch 126; iter: 0; batch classifier loss: 0.390430; batch adversarial loss: 0.554068\n",
      "epoch 127; iter: 0; batch classifier loss: 0.368461; batch adversarial loss: 0.552507\n",
      "epoch 128; iter: 0; batch classifier loss: 0.448465; batch adversarial loss: 0.558923\n",
      "epoch 129; iter: 0; batch classifier loss: 0.371848; batch adversarial loss: 0.564846\n",
      "epoch 130; iter: 0; batch classifier loss: 0.390906; batch adversarial loss: 0.590360\n",
      "epoch 131; iter: 0; batch classifier loss: 0.348097; batch adversarial loss: 0.507438\n",
      "epoch 132; iter: 0; batch classifier loss: 0.523882; batch adversarial loss: 0.501754\n",
      "epoch 133; iter: 0; batch classifier loss: 0.358148; batch adversarial loss: 0.532087\n",
      "epoch 134; iter: 0; batch classifier loss: 0.336284; batch adversarial loss: 0.585233\n",
      "epoch 135; iter: 0; batch classifier loss: 0.360132; batch adversarial loss: 0.552528\n",
      "epoch 136; iter: 0; batch classifier loss: 0.355282; batch adversarial loss: 0.497270\n",
      "epoch 137; iter: 0; batch classifier loss: 0.393681; batch adversarial loss: 0.661861\n",
      "epoch 138; iter: 0; batch classifier loss: 0.486652; batch adversarial loss: 0.491883\n",
      "epoch 139; iter: 0; batch classifier loss: 0.395899; batch adversarial loss: 0.517487\n",
      "epoch 140; iter: 0; batch classifier loss: 0.383163; batch adversarial loss: 0.575063\n",
      "epoch 141; iter: 0; batch classifier loss: 0.393621; batch adversarial loss: 0.517412\n",
      "epoch 142; iter: 0; batch classifier loss: 0.438195; batch adversarial loss: 0.588975\n",
      "epoch 143; iter: 0; batch classifier loss: 0.369393; batch adversarial loss: 0.523726\n",
      "epoch 144; iter: 0; batch classifier loss: 0.313837; batch adversarial loss: 0.569694\n",
      "epoch 145; iter: 0; batch classifier loss: 0.387841; batch adversarial loss: 0.478475\n",
      "epoch 146; iter: 0; batch classifier loss: 0.368609; batch adversarial loss: 0.576433\n",
      "epoch 147; iter: 0; batch classifier loss: 0.344171; batch adversarial loss: 0.558470\n",
      "epoch 148; iter: 0; batch classifier loss: 0.340804; batch adversarial loss: 0.544849\n",
      "epoch 149; iter: 0; batch classifier loss: 0.418972; batch adversarial loss: 0.549193\n",
      "epoch 150; iter: 0; batch classifier loss: 0.345926; batch adversarial loss: 0.519210\n",
      "epoch 151; iter: 0; batch classifier loss: 0.369990; batch adversarial loss: 0.553342\n",
      "epoch 152; iter: 0; batch classifier loss: 0.325096; batch adversarial loss: 0.536820\n",
      "epoch 153; iter: 0; batch classifier loss: 0.374361; batch adversarial loss: 0.532629\n",
      "epoch 154; iter: 0; batch classifier loss: 0.376963; batch adversarial loss: 0.516498\n",
      "epoch 155; iter: 0; batch classifier loss: 0.347032; batch adversarial loss: 0.565690\n",
      "epoch 156; iter: 0; batch classifier loss: 0.456237; batch adversarial loss: 0.484919\n",
      "epoch 157; iter: 0; batch classifier loss: 0.411123; batch adversarial loss: 0.567442\n",
      "epoch 158; iter: 0; batch classifier loss: 0.318388; batch adversarial loss: 0.590292\n",
      "epoch 159; iter: 0; batch classifier loss: 0.327383; batch adversarial loss: 0.531767\n",
      "epoch 160; iter: 0; batch classifier loss: 0.366912; batch adversarial loss: 0.585624\n",
      "epoch 161; iter: 0; batch classifier loss: 0.418780; batch adversarial loss: 0.523838\n",
      "epoch 162; iter: 0; batch classifier loss: 0.378985; batch adversarial loss: 0.545394\n",
      "epoch 163; iter: 0; batch classifier loss: 0.384132; batch adversarial loss: 0.599896\n",
      "epoch 164; iter: 0; batch classifier loss: 0.329331; batch adversarial loss: 0.542849\n",
      "epoch 165; iter: 0; batch classifier loss: 0.394767; batch adversarial loss: 0.491042\n",
      "epoch 166; iter: 0; batch classifier loss: 0.503311; batch adversarial loss: 0.520863\n",
      "epoch 167; iter: 0; batch classifier loss: 0.259524; batch adversarial loss: 0.568148\n",
      "epoch 168; iter: 0; batch classifier loss: 0.370392; batch adversarial loss: 0.535735\n",
      "epoch 169; iter: 0; batch classifier loss: 0.329196; batch adversarial loss: 0.625202\n",
      "epoch 170; iter: 0; batch classifier loss: 0.327428; batch adversarial loss: 0.563286\n",
      "epoch 171; iter: 0; batch classifier loss: 0.375410; batch adversarial loss: 0.563869\n",
      "epoch 172; iter: 0; batch classifier loss: 0.297431; batch adversarial loss: 0.489927\n",
      "epoch 173; iter: 0; batch classifier loss: 0.272069; batch adversarial loss: 0.505710\n",
      "epoch 174; iter: 0; batch classifier loss: 0.306314; batch adversarial loss: 0.580322\n",
      "epoch 175; iter: 0; batch classifier loss: 0.396185; batch adversarial loss: 0.564535\n",
      "epoch 176; iter: 0; batch classifier loss: 0.431233; batch adversarial loss: 0.535760\n",
      "epoch 177; iter: 0; batch classifier loss: 0.350605; batch adversarial loss: 0.535186\n",
      "epoch 178; iter: 0; batch classifier loss: 0.472765; batch adversarial loss: 0.541433\n",
      "epoch 179; iter: 0; batch classifier loss: 0.323215; batch adversarial loss: 0.554643\n",
      "epoch 180; iter: 0; batch classifier loss: 0.352614; batch adversarial loss: 0.568536\n",
      "epoch 181; iter: 0; batch classifier loss: 0.305626; batch adversarial loss: 0.620516\n",
      "epoch 182; iter: 0; batch classifier loss: 0.306536; batch adversarial loss: 0.563510\n",
      "epoch 183; iter: 0; batch classifier loss: 0.340480; batch adversarial loss: 0.600028\n",
      "epoch 184; iter: 0; batch classifier loss: 0.387016; batch adversarial loss: 0.559929\n",
      "epoch 185; iter: 0; batch classifier loss: 0.373342; batch adversarial loss: 0.546361\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 186; iter: 0; batch classifier loss: 0.318389; batch adversarial loss: 0.599174\n",
      "epoch 187; iter: 0; batch classifier loss: 0.324505; batch adversarial loss: 0.545768\n",
      "epoch 188; iter: 0; batch classifier loss: 0.386475; batch adversarial loss: 0.545010\n",
      "epoch 189; iter: 0; batch classifier loss: 0.334725; batch adversarial loss: 0.488979\n",
      "epoch 190; iter: 0; batch classifier loss: 0.284170; batch adversarial loss: 0.525137\n",
      "epoch 191; iter: 0; batch classifier loss: 0.351364; batch adversarial loss: 0.543176\n",
      "epoch 192; iter: 0; batch classifier loss: 0.351997; batch adversarial loss: 0.535773\n",
      "epoch 193; iter: 0; batch classifier loss: 0.363273; batch adversarial loss: 0.529374\n",
      "epoch 194; iter: 0; batch classifier loss: 0.397954; batch adversarial loss: 0.573349\n",
      "epoch 195; iter: 0; batch classifier loss: 0.344110; batch adversarial loss: 0.524857\n",
      "epoch 196; iter: 0; batch classifier loss: 0.372512; batch adversarial loss: 0.632781\n",
      "epoch 197; iter: 0; batch classifier loss: 0.365962; batch adversarial loss: 0.577112\n",
      "epoch 198; iter: 0; batch classifier loss: 0.342445; batch adversarial loss: 0.549616\n",
      "epoch 199; iter: 0; batch classifier loss: 0.358532; batch adversarial loss: 0.562015\n",
      "epoch 0; iter: 0; batch classifier loss: 0.724585; batch adversarial loss: 1.005959\n",
      "epoch 1; iter: 0; batch classifier loss: 0.850145; batch adversarial loss: 1.202826\n",
      "epoch 2; iter: 0; batch classifier loss: 0.968307; batch adversarial loss: 1.184846\n",
      "epoch 3; iter: 0; batch classifier loss: 1.111543; batch adversarial loss: 1.093612\n",
      "epoch 4; iter: 0; batch classifier loss: 0.996837; batch adversarial loss: 1.014290\n",
      "epoch 5; iter: 0; batch classifier loss: 1.070548; batch adversarial loss: 0.925220\n",
      "epoch 6; iter: 0; batch classifier loss: 0.971984; batch adversarial loss: 0.869832\n",
      "epoch 7; iter: 0; batch classifier loss: 0.900210; batch adversarial loss: 0.803681\n",
      "epoch 8; iter: 0; batch classifier loss: 0.919470; batch adversarial loss: 0.746585\n",
      "epoch 9; iter: 0; batch classifier loss: 0.788765; batch adversarial loss: 0.669443\n",
      "epoch 10; iter: 0; batch classifier loss: 0.770150; batch adversarial loss: 0.660537\n",
      "epoch 11; iter: 0; batch classifier loss: 0.555039; batch adversarial loss: 0.623066\n",
      "epoch 12; iter: 0; batch classifier loss: 0.549532; batch adversarial loss: 0.599205\n",
      "epoch 13; iter: 0; batch classifier loss: 0.589951; batch adversarial loss: 0.577587\n",
      "epoch 14; iter: 0; batch classifier loss: 0.502269; batch adversarial loss: 0.613484\n",
      "epoch 15; iter: 0; batch classifier loss: 0.523560; batch adversarial loss: 0.573023\n",
      "epoch 16; iter: 0; batch classifier loss: 0.487857; batch adversarial loss: 0.607434\n",
      "epoch 17; iter: 0; batch classifier loss: 0.519068; batch adversarial loss: 0.581480\n",
      "epoch 18; iter: 0; batch classifier loss: 0.500113; batch adversarial loss: 0.548768\n",
      "epoch 19; iter: 0; batch classifier loss: 0.490831; batch adversarial loss: 0.602951\n",
      "epoch 20; iter: 0; batch classifier loss: 0.473931; batch adversarial loss: 0.535610\n",
      "epoch 21; iter: 0; batch classifier loss: 0.524525; batch adversarial loss: 0.557645\n",
      "epoch 22; iter: 0; batch classifier loss: 0.469866; batch adversarial loss: 0.598974\n",
      "epoch 23; iter: 0; batch classifier loss: 0.494988; batch adversarial loss: 0.507532\n",
      "epoch 24; iter: 0; batch classifier loss: 0.498688; batch adversarial loss: 0.551214\n",
      "epoch 25; iter: 0; batch classifier loss: 0.569779; batch adversarial loss: 0.578818\n",
      "epoch 26; iter: 0; batch classifier loss: 0.509907; batch adversarial loss: 0.557461\n",
      "epoch 27; iter: 0; batch classifier loss: 0.405810; batch adversarial loss: 0.556708\n",
      "epoch 28; iter: 0; batch classifier loss: 0.523188; batch adversarial loss: 0.562205\n",
      "epoch 29; iter: 0; batch classifier loss: 0.415167; batch adversarial loss: 0.611899\n",
      "epoch 30; iter: 0; batch classifier loss: 0.506302; batch adversarial loss: 0.538113\n",
      "epoch 31; iter: 0; batch classifier loss: 0.524606; batch adversarial loss: 0.475943\n",
      "epoch 32; iter: 0; batch classifier loss: 0.417088; batch adversarial loss: 0.547651\n",
      "epoch 33; iter: 0; batch classifier loss: 0.450398; batch adversarial loss: 0.546006\n",
      "epoch 34; iter: 0; batch classifier loss: 0.462651; batch adversarial loss: 0.538865\n",
      "epoch 35; iter: 0; batch classifier loss: 0.383382; batch adversarial loss: 0.569998\n",
      "epoch 36; iter: 0; batch classifier loss: 0.499150; batch adversarial loss: 0.596978\n",
      "epoch 37; iter: 0; batch classifier loss: 0.357833; batch adversarial loss: 0.510986\n",
      "epoch 38; iter: 0; batch classifier loss: 0.473166; batch adversarial loss: 0.528218\n",
      "epoch 39; iter: 0; batch classifier loss: 0.528670; batch adversarial loss: 0.648912\n",
      "epoch 40; iter: 0; batch classifier loss: 0.406518; batch adversarial loss: 0.491747\n",
      "epoch 41; iter: 0; batch classifier loss: 0.464884; batch adversarial loss: 0.483112\n",
      "epoch 42; iter: 0; batch classifier loss: 0.432591; batch adversarial loss: 0.624791\n",
      "epoch 43; iter: 0; batch classifier loss: 0.391897; batch adversarial loss: 0.544812\n",
      "epoch 44; iter: 0; batch classifier loss: 0.420750; batch adversarial loss: 0.527019\n",
      "epoch 45; iter: 0; batch classifier loss: 0.457690; batch adversarial loss: 0.589472\n",
      "epoch 46; iter: 0; batch classifier loss: 0.417606; batch adversarial loss: 0.598050\n",
      "epoch 47; iter: 0; batch classifier loss: 0.425897; batch adversarial loss: 0.625670\n",
      "epoch 48; iter: 0; batch classifier loss: 0.423019; batch adversarial loss: 0.662102\n",
      "epoch 49; iter: 0; batch classifier loss: 0.419740; batch adversarial loss: 0.580127\n",
      "epoch 50; iter: 0; batch classifier loss: 0.431378; batch adversarial loss: 0.499742\n",
      "epoch 51; iter: 0; batch classifier loss: 0.376157; batch adversarial loss: 0.517670\n",
      "epoch 52; iter: 0; batch classifier loss: 0.469053; batch adversarial loss: 0.536112\n",
      "epoch 53; iter: 0; batch classifier loss: 0.422376; batch adversarial loss: 0.581587\n",
      "epoch 54; iter: 0; batch classifier loss: 0.417528; batch adversarial loss: 0.588971\n",
      "epoch 55; iter: 0; batch classifier loss: 0.466654; batch adversarial loss: 0.562866\n",
      "epoch 56; iter: 0; batch classifier loss: 0.449977; batch adversarial loss: 0.536216\n",
      "epoch 57; iter: 0; batch classifier loss: 0.375057; batch adversarial loss: 0.598953\n",
      "epoch 58; iter: 0; batch classifier loss: 0.408930; batch adversarial loss: 0.501018\n",
      "epoch 59; iter: 0; batch classifier loss: 0.568609; batch adversarial loss: 0.581040\n",
      "epoch 60; iter: 0; batch classifier loss: 0.364754; batch adversarial loss: 0.498774\n",
      "epoch 61; iter: 0; batch classifier loss: 0.459815; batch adversarial loss: 0.535500\n",
      "epoch 62; iter: 0; batch classifier loss: 0.490709; batch adversarial loss: 0.470184\n",
      "epoch 63; iter: 0; batch classifier loss: 0.483604; batch adversarial loss: 0.543600\n",
      "epoch 64; iter: 0; batch classifier loss: 0.423027; batch adversarial loss: 0.608412\n",
      "epoch 65; iter: 0; batch classifier loss: 0.308017; batch adversarial loss: 0.579805\n",
      "epoch 66; iter: 0; batch classifier loss: 0.371445; batch adversarial loss: 0.616096\n",
      "epoch 67; iter: 0; batch classifier loss: 0.422774; batch adversarial loss: 0.662520\n",
      "epoch 68; iter: 0; batch classifier loss: 0.384778; batch adversarial loss: 0.532121\n",
      "epoch 69; iter: 0; batch classifier loss: 0.436786; batch adversarial loss: 0.623572\n",
      "epoch 70; iter: 0; batch classifier loss: 0.374190; batch adversarial loss: 0.514294\n",
      "epoch 71; iter: 0; batch classifier loss: 0.369107; batch adversarial loss: 0.668001\n",
      "epoch 72; iter: 0; batch classifier loss: 0.466579; batch adversarial loss: 0.497600\n",
      "epoch 73; iter: 0; batch classifier loss: 0.380860; batch adversarial loss: 0.552840\n",
      "epoch 74; iter: 0; batch classifier loss: 0.446724; batch adversarial loss: 0.598441\n",
      "epoch 75; iter: 0; batch classifier loss: 0.412499; batch adversarial loss: 0.556630\n",
      "epoch 76; iter: 0; batch classifier loss: 0.398689; batch adversarial loss: 0.586501\n",
      "epoch 77; iter: 0; batch classifier loss: 0.463937; batch adversarial loss: 0.572967\n",
      "epoch 78; iter: 0; batch classifier loss: 0.381135; batch adversarial loss: 0.563167\n",
      "epoch 79; iter: 0; batch classifier loss: 0.347169; batch adversarial loss: 0.501633\n",
      "epoch 80; iter: 0; batch classifier loss: 0.411831; batch adversarial loss: 0.552681\n",
      "epoch 81; iter: 0; batch classifier loss: 0.385918; batch adversarial loss: 0.571636\n",
      "epoch 82; iter: 0; batch classifier loss: 0.387475; batch adversarial loss: 0.590392\n",
      "epoch 83; iter: 0; batch classifier loss: 0.320541; batch adversarial loss: 0.535407\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 84; iter: 0; batch classifier loss: 0.365930; batch adversarial loss: 0.599685\n",
      "epoch 85; iter: 0; batch classifier loss: 0.435212; batch adversarial loss: 0.510773\n",
      "epoch 86; iter: 0; batch classifier loss: 0.379956; batch adversarial loss: 0.535710\n",
      "epoch 87; iter: 0; batch classifier loss: 0.387033; batch adversarial loss: 0.517464\n",
      "epoch 88; iter: 0; batch classifier loss: 0.399910; batch adversarial loss: 0.482486\n",
      "epoch 89; iter: 0; batch classifier loss: 0.355908; batch adversarial loss: 0.580799\n",
      "epoch 90; iter: 0; batch classifier loss: 0.473621; batch adversarial loss: 0.499829\n",
      "epoch 91; iter: 0; batch classifier loss: 0.357378; batch adversarial loss: 0.553447\n",
      "epoch 92; iter: 0; batch classifier loss: 0.408861; batch adversarial loss: 0.553547\n",
      "epoch 93; iter: 0; batch classifier loss: 0.426800; batch adversarial loss: 0.508205\n",
      "epoch 94; iter: 0; batch classifier loss: 0.294936; batch adversarial loss: 0.571717\n",
      "epoch 95; iter: 0; batch classifier loss: 0.450611; batch adversarial loss: 0.535106\n",
      "epoch 96; iter: 0; batch classifier loss: 0.382587; batch adversarial loss: 0.625536\n",
      "epoch 97; iter: 0; batch classifier loss: 0.317096; batch adversarial loss: 0.608196\n",
      "epoch 98; iter: 0; batch classifier loss: 0.391653; batch adversarial loss: 0.534877\n",
      "epoch 99; iter: 0; batch classifier loss: 0.491516; batch adversarial loss: 0.554227\n",
      "epoch 100; iter: 0; batch classifier loss: 0.329886; batch adversarial loss: 0.563169\n",
      "epoch 101; iter: 0; batch classifier loss: 0.400600; batch adversarial loss: 0.598789\n",
      "epoch 102; iter: 0; batch classifier loss: 0.383957; batch adversarial loss: 0.499446\n",
      "epoch 103; iter: 0; batch classifier loss: 0.416258; batch adversarial loss: 0.535469\n",
      "epoch 104; iter: 0; batch classifier loss: 0.369425; batch adversarial loss: 0.526346\n",
      "epoch 105; iter: 0; batch classifier loss: 0.402266; batch adversarial loss: 0.535844\n",
      "epoch 106; iter: 0; batch classifier loss: 0.334172; batch adversarial loss: 0.544489\n",
      "epoch 107; iter: 0; batch classifier loss: 0.371987; batch adversarial loss: 0.598603\n",
      "epoch 108; iter: 0; batch classifier loss: 0.405147; batch adversarial loss: 0.589703\n",
      "epoch 109; iter: 0; batch classifier loss: 0.470570; batch adversarial loss: 0.508140\n",
      "epoch 110; iter: 0; batch classifier loss: 0.389118; batch adversarial loss: 0.535377\n",
      "epoch 111; iter: 0; batch classifier loss: 0.293979; batch adversarial loss: 0.544301\n",
      "epoch 112; iter: 0; batch classifier loss: 0.298391; batch adversarial loss: 0.508231\n",
      "epoch 113; iter: 0; batch classifier loss: 0.438444; batch adversarial loss: 0.517350\n",
      "epoch 114; iter: 0; batch classifier loss: 0.385736; batch adversarial loss: 0.526358\n",
      "epoch 115; iter: 0; batch classifier loss: 0.351692; batch adversarial loss: 0.535684\n",
      "epoch 116; iter: 0; batch classifier loss: 0.451360; batch adversarial loss: 0.426320\n",
      "epoch 117; iter: 0; batch classifier loss: 0.383155; batch adversarial loss: 0.590038\n",
      "epoch 118; iter: 0; batch classifier loss: 0.374833; batch adversarial loss: 0.517480\n",
      "epoch 119; iter: 0; batch classifier loss: 0.305522; batch adversarial loss: 0.562833\n",
      "epoch 120; iter: 0; batch classifier loss: 0.389649; batch adversarial loss: 0.508251\n",
      "epoch 121; iter: 0; batch classifier loss: 0.348972; batch adversarial loss: 0.642256\n",
      "epoch 122; iter: 0; batch classifier loss: 0.363585; batch adversarial loss: 0.562129\n",
      "epoch 123; iter: 0; batch classifier loss: 0.399949; batch adversarial loss: 0.535851\n",
      "epoch 124; iter: 0; batch classifier loss: 0.306247; batch adversarial loss: 0.524461\n",
      "epoch 125; iter: 0; batch classifier loss: 0.298026; batch adversarial loss: 0.543754\n",
      "epoch 126; iter: 0; batch classifier loss: 0.337117; batch adversarial loss: 0.544859\n",
      "epoch 127; iter: 0; batch classifier loss: 0.316750; batch adversarial loss: 0.553949\n",
      "epoch 128; iter: 0; batch classifier loss: 0.302307; batch adversarial loss: 0.544532\n",
      "epoch 129; iter: 0; batch classifier loss: 0.269610; batch adversarial loss: 0.637090\n",
      "epoch 130; iter: 0; batch classifier loss: 0.386231; batch adversarial loss: 0.489163\n",
      "epoch 131; iter: 0; batch classifier loss: 0.347826; batch adversarial loss: 0.526080\n",
      "epoch 132; iter: 0; batch classifier loss: 0.390394; batch adversarial loss: 0.535374\n",
      "epoch 133; iter: 0; batch classifier loss: 0.389789; batch adversarial loss: 0.507792\n",
      "epoch 134; iter: 0; batch classifier loss: 0.329525; batch adversarial loss: 0.526238\n",
      "epoch 135; iter: 0; batch classifier loss: 0.291232; batch adversarial loss: 0.480294\n",
      "epoch 136; iter: 0; batch classifier loss: 0.391294; batch adversarial loss: 0.498904\n",
      "epoch 137; iter: 0; batch classifier loss: 0.356181; batch adversarial loss: 0.581042\n",
      "epoch 138; iter: 0; batch classifier loss: 0.392007; batch adversarial loss: 0.553703\n",
      "epoch 139; iter: 0; batch classifier loss: 0.335449; batch adversarial loss: 0.563040\n",
      "epoch 140; iter: 0; batch classifier loss: 0.400378; batch adversarial loss: 0.480617\n",
      "epoch 141; iter: 0; batch classifier loss: 0.282900; batch adversarial loss: 0.535361\n",
      "epoch 142; iter: 0; batch classifier loss: 0.406317; batch adversarial loss: 0.507731\n",
      "epoch 143; iter: 0; batch classifier loss: 0.259870; batch adversarial loss: 0.517153\n",
      "epoch 144; iter: 0; batch classifier loss: 0.389235; batch adversarial loss: 0.470590\n",
      "epoch 145; iter: 0; batch classifier loss: 0.331572; batch adversarial loss: 0.562238\n",
      "epoch 146; iter: 0; batch classifier loss: 0.372117; batch adversarial loss: 0.535071\n",
      "epoch 147; iter: 0; batch classifier loss: 0.343026; batch adversarial loss: 0.580596\n",
      "epoch 148; iter: 0; batch classifier loss: 0.332559; batch adversarial loss: 0.545146\n",
      "epoch 149; iter: 0; batch classifier loss: 0.394624; batch adversarial loss: 0.563208\n",
      "epoch 150; iter: 0; batch classifier loss: 0.383941; batch adversarial loss: 0.480979\n",
      "epoch 151; iter: 0; batch classifier loss: 0.338473; batch adversarial loss: 0.481077\n",
      "epoch 152; iter: 0; batch classifier loss: 0.300825; batch adversarial loss: 0.544196\n",
      "epoch 153; iter: 0; batch classifier loss: 0.420272; batch adversarial loss: 0.526506\n",
      "epoch 154; iter: 0; batch classifier loss: 0.381161; batch adversarial loss: 0.563596\n",
      "epoch 155; iter: 0; batch classifier loss: 0.330405; batch adversarial loss: 0.517097\n",
      "epoch 156; iter: 0; batch classifier loss: 0.386299; batch adversarial loss: 0.571711\n",
      "epoch 157; iter: 0; batch classifier loss: 0.312143; batch adversarial loss: 0.553522\n",
      "epoch 158; iter: 0; batch classifier loss: 0.395819; batch adversarial loss: 0.490261\n",
      "epoch 159; iter: 0; batch classifier loss: 0.323862; batch adversarial loss: 0.535371\n",
      "epoch 160; iter: 0; batch classifier loss: 0.328881; batch adversarial loss: 0.589410\n",
      "epoch 161; iter: 0; batch classifier loss: 0.311246; batch adversarial loss: 0.580734\n",
      "epoch 162; iter: 0; batch classifier loss: 0.347939; batch adversarial loss: 0.472021\n",
      "epoch 163; iter: 0; batch classifier loss: 0.364683; batch adversarial loss: 0.544456\n",
      "epoch 164; iter: 0; batch classifier loss: 0.372433; batch adversarial loss: 0.535448\n",
      "epoch 165; iter: 0; batch classifier loss: 0.292069; batch adversarial loss: 0.580980\n",
      "epoch 166; iter: 0; batch classifier loss: 0.336198; batch adversarial loss: 0.517256\n",
      "epoch 167; iter: 0; batch classifier loss: 0.414398; batch adversarial loss: 0.481074\n",
      "epoch 168; iter: 0; batch classifier loss: 0.347164; batch adversarial loss: 0.617342\n",
      "epoch 169; iter: 0; batch classifier loss: 0.346498; batch adversarial loss: 0.599236\n",
      "epoch 170; iter: 0; batch classifier loss: 0.359516; batch adversarial loss: 0.498985\n",
      "epoch 171; iter: 0; batch classifier loss: 0.408999; batch adversarial loss: 0.600037\n",
      "epoch 172; iter: 0; batch classifier loss: 0.361700; batch adversarial loss: 0.553189\n",
      "epoch 173; iter: 0; batch classifier loss: 0.394038; batch adversarial loss: 0.480998\n",
      "epoch 174; iter: 0; batch classifier loss: 0.411161; batch adversarial loss: 0.525927\n",
      "epoch 175; iter: 0; batch classifier loss: 0.383276; batch adversarial loss: 0.499489\n",
      "epoch 176; iter: 0; batch classifier loss: 0.344356; batch adversarial loss: 0.571817\n",
      "epoch 177; iter: 0; batch classifier loss: 0.316072; batch adversarial loss: 0.571723\n",
      "epoch 178; iter: 0; batch classifier loss: 0.333029; batch adversarial loss: 0.563079\n",
      "epoch 179; iter: 0; batch classifier loss: 0.345660; batch adversarial loss: 0.517537\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 180; iter: 0; batch classifier loss: 0.300437; batch adversarial loss: 0.616693\n",
      "epoch 181; iter: 0; batch classifier loss: 0.277638; batch adversarial loss: 0.544020\n",
      "epoch 182; iter: 0; batch classifier loss: 0.305250; batch adversarial loss: 0.599377\n",
      "epoch 183; iter: 0; batch classifier loss: 0.346157; batch adversarial loss: 0.544806\n",
      "epoch 184; iter: 0; batch classifier loss: 0.348096; batch adversarial loss: 0.562485\n",
      "epoch 185; iter: 0; batch classifier loss: 0.319221; batch adversarial loss: 0.499648\n",
      "epoch 186; iter: 0; batch classifier loss: 0.335186; batch adversarial loss: 0.526908\n",
      "epoch 187; iter: 0; batch classifier loss: 0.300345; batch adversarial loss: 0.517642\n",
      "epoch 188; iter: 0; batch classifier loss: 0.299069; batch adversarial loss: 0.574006\n",
      "epoch 189; iter: 0; batch classifier loss: 0.303480; batch adversarial loss: 0.535227\n",
      "epoch 190; iter: 0; batch classifier loss: 0.321732; batch adversarial loss: 0.619002\n",
      "epoch 191; iter: 0; batch classifier loss: 0.345255; batch adversarial loss: 0.535934\n",
      "epoch 192; iter: 0; batch classifier loss: 0.325583; batch adversarial loss: 0.554228\n",
      "epoch 193; iter: 0; batch classifier loss: 0.338981; batch adversarial loss: 0.535740\n",
      "epoch 194; iter: 0; batch classifier loss: 0.307042; batch adversarial loss: 0.517839\n",
      "epoch 195; iter: 0; batch classifier loss: 0.382871; batch adversarial loss: 0.424687\n",
      "epoch 196; iter: 0; batch classifier loss: 0.327634; batch adversarial loss: 0.544545\n",
      "epoch 197; iter: 0; batch classifier loss: 0.381116; batch adversarial loss: 0.526518\n",
      "epoch 198; iter: 0; batch classifier loss: 0.335716; batch adversarial loss: 0.580998\n",
      "epoch 199; iter: 0; batch classifier loss: 0.318441; batch adversarial loss: 0.453146\n",
      "epoch 0; iter: 0; batch classifier loss: 0.711137; batch adversarial loss: 0.597363\n",
      "epoch 1; iter: 0; batch classifier loss: 0.554741; batch adversarial loss: 0.645833\n",
      "epoch 2; iter: 0; batch classifier loss: 0.566499; batch adversarial loss: 0.626540\n",
      "epoch 3; iter: 0; batch classifier loss: 0.613317; batch adversarial loss: 0.671437\n",
      "epoch 4; iter: 0; batch classifier loss: 0.505151; batch adversarial loss: 0.616749\n",
      "epoch 5; iter: 0; batch classifier loss: 0.575032; batch adversarial loss: 0.646467\n",
      "epoch 6; iter: 0; batch classifier loss: 0.525412; batch adversarial loss: 0.622496\n",
      "epoch 7; iter: 0; batch classifier loss: 0.569777; batch adversarial loss: 0.665800\n",
      "epoch 8; iter: 0; batch classifier loss: 0.465860; batch adversarial loss: 0.626045\n",
      "epoch 9; iter: 0; batch classifier loss: 0.455345; batch adversarial loss: 0.553545\n",
      "epoch 10; iter: 0; batch classifier loss: 0.595160; batch adversarial loss: 0.657092\n",
      "epoch 11; iter: 0; batch classifier loss: 0.493314; batch adversarial loss: 0.606027\n",
      "epoch 12; iter: 0; batch classifier loss: 0.543131; batch adversarial loss: 0.606011\n",
      "epoch 13; iter: 0; batch classifier loss: 0.472709; batch adversarial loss: 0.563766\n",
      "epoch 14; iter: 0; batch classifier loss: 0.470879; batch adversarial loss: 0.514608\n",
      "epoch 15; iter: 0; batch classifier loss: 0.472806; batch adversarial loss: 0.561487\n",
      "epoch 16; iter: 0; batch classifier loss: 0.519641; batch adversarial loss: 0.534018\n",
      "epoch 17; iter: 0; batch classifier loss: 0.481845; batch adversarial loss: 0.585940\n",
      "epoch 18; iter: 0; batch classifier loss: 0.519727; batch adversarial loss: 0.564894\n",
      "epoch 19; iter: 0; batch classifier loss: 0.476495; batch adversarial loss: 0.549898\n",
      "epoch 20; iter: 0; batch classifier loss: 0.456425; batch adversarial loss: 0.558330\n",
      "epoch 21; iter: 0; batch classifier loss: 0.543333; batch adversarial loss: 0.553109\n",
      "epoch 22; iter: 0; batch classifier loss: 0.390702; batch adversarial loss: 0.486652\n",
      "epoch 23; iter: 0; batch classifier loss: 0.452927; batch adversarial loss: 0.572854\n",
      "epoch 24; iter: 0; batch classifier loss: 0.389502; batch adversarial loss: 0.564286\n",
      "epoch 25; iter: 0; batch classifier loss: 0.469236; batch adversarial loss: 0.539687\n",
      "epoch 26; iter: 0; batch classifier loss: 0.459451; batch adversarial loss: 0.561695\n",
      "epoch 27; iter: 0; batch classifier loss: 0.536399; batch adversarial loss: 0.573523\n",
      "epoch 28; iter: 0; batch classifier loss: 0.426794; batch adversarial loss: 0.477904\n",
      "epoch 29; iter: 0; batch classifier loss: 0.531943; batch adversarial loss: 0.485429\n",
      "epoch 30; iter: 0; batch classifier loss: 0.449891; batch adversarial loss: 0.571026\n",
      "epoch 31; iter: 0; batch classifier loss: 0.441422; batch adversarial loss: 0.507590\n",
      "epoch 32; iter: 0; batch classifier loss: 0.465109; batch adversarial loss: 0.517853\n",
      "epoch 33; iter: 0; batch classifier loss: 0.375157; batch adversarial loss: 0.490818\n",
      "epoch 34; iter: 0; batch classifier loss: 0.412299; batch adversarial loss: 0.517280\n",
      "epoch 35; iter: 0; batch classifier loss: 0.404953; batch adversarial loss: 0.525860\n",
      "epoch 36; iter: 0; batch classifier loss: 0.403687; batch adversarial loss: 0.553418\n",
      "epoch 37; iter: 0; batch classifier loss: 0.462861; batch adversarial loss: 0.589806\n",
      "epoch 38; iter: 0; batch classifier loss: 0.482957; batch adversarial loss: 0.543502\n",
      "epoch 39; iter: 0; batch classifier loss: 0.455075; batch adversarial loss: 0.543774\n",
      "epoch 40; iter: 0; batch classifier loss: 0.523412; batch adversarial loss: 0.470157\n",
      "epoch 41; iter: 0; batch classifier loss: 0.449842; batch adversarial loss: 0.543696\n",
      "epoch 42; iter: 0; batch classifier loss: 0.449372; batch adversarial loss: 0.562791\n",
      "epoch 43; iter: 0; batch classifier loss: 0.471990; batch adversarial loss: 0.460114\n",
      "epoch 44; iter: 0; batch classifier loss: 0.441653; batch adversarial loss: 0.544118\n",
      "epoch 45; iter: 0; batch classifier loss: 0.342840; batch adversarial loss: 0.478641\n",
      "epoch 46; iter: 0; batch classifier loss: 0.447637; batch adversarial loss: 0.573139\n",
      "epoch 47; iter: 0; batch classifier loss: 0.454115; batch adversarial loss: 0.580400\n",
      "epoch 48; iter: 0; batch classifier loss: 0.469442; batch adversarial loss: 0.526399\n",
      "epoch 49; iter: 0; batch classifier loss: 0.413885; batch adversarial loss: 0.506947\n",
      "epoch 50; iter: 0; batch classifier loss: 0.570545; batch adversarial loss: 0.518387\n",
      "epoch 51; iter: 0; batch classifier loss: 0.504954; batch adversarial loss: 0.536248\n",
      "epoch 52; iter: 0; batch classifier loss: 0.429363; batch adversarial loss: 0.459607\n",
      "epoch 53; iter: 0; batch classifier loss: 0.390758; batch adversarial loss: 0.507308\n",
      "epoch 54; iter: 0; batch classifier loss: 0.446338; batch adversarial loss: 0.610565\n",
      "epoch 55; iter: 0; batch classifier loss: 0.408947; batch adversarial loss: 0.592665\n",
      "epoch 56; iter: 0; batch classifier loss: 0.393543; batch adversarial loss: 0.506254\n",
      "epoch 57; iter: 0; batch classifier loss: 0.411913; batch adversarial loss: 0.514928\n",
      "epoch 58; iter: 0; batch classifier loss: 0.426048; batch adversarial loss: 0.535389\n",
      "epoch 59; iter: 0; batch classifier loss: 0.428330; batch adversarial loss: 0.621320\n",
      "epoch 60; iter: 0; batch classifier loss: 0.416941; batch adversarial loss: 0.487450\n",
      "epoch 61; iter: 0; batch classifier loss: 0.391034; batch adversarial loss: 0.507084\n",
      "epoch 62; iter: 0; batch classifier loss: 0.382735; batch adversarial loss: 0.545857\n",
      "epoch 63; iter: 0; batch classifier loss: 0.467213; batch adversarial loss: 0.518431\n",
      "epoch 64; iter: 0; batch classifier loss: 0.342931; batch adversarial loss: 0.506510\n",
      "epoch 65; iter: 0; batch classifier loss: 0.390867; batch adversarial loss: 0.537444\n",
      "epoch 66; iter: 0; batch classifier loss: 0.403607; batch adversarial loss: 0.524482\n",
      "epoch 67; iter: 0; batch classifier loss: 0.446216; batch adversarial loss: 0.526052\n",
      "epoch 68; iter: 0; batch classifier loss: 0.405275; batch adversarial loss: 0.545322\n",
      "epoch 69; iter: 0; batch classifier loss: 0.425718; batch adversarial loss: 0.525617\n",
      "epoch 70; iter: 0; batch classifier loss: 0.404836; batch adversarial loss: 0.601281\n",
      "epoch 71; iter: 0; batch classifier loss: 0.386600; batch adversarial loss: 0.525575\n",
      "epoch 72; iter: 0; batch classifier loss: 0.404884; batch adversarial loss: 0.561249\n",
      "epoch 73; iter: 0; batch classifier loss: 0.392331; batch adversarial loss: 0.543909\n",
      "epoch 74; iter: 0; batch classifier loss: 0.380597; batch adversarial loss: 0.571922\n",
      "epoch 75; iter: 0; batch classifier loss: 0.389883; batch adversarial loss: 0.552188\n",
      "epoch 76; iter: 0; batch classifier loss: 0.368692; batch adversarial loss: 0.505849\n",
      "epoch 77; iter: 0; batch classifier loss: 0.383386; batch adversarial loss: 0.574182\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 78; iter: 0; batch classifier loss: 0.407805; batch adversarial loss: 0.564998\n",
      "epoch 79; iter: 0; batch classifier loss: 0.388549; batch adversarial loss: 0.544690\n",
      "epoch 80; iter: 0; batch classifier loss: 0.442242; batch adversarial loss: 0.578001\n",
      "epoch 81; iter: 0; batch classifier loss: 0.491002; batch adversarial loss: 0.507953\n",
      "epoch 82; iter: 0; batch classifier loss: 0.435688; batch adversarial loss: 0.516309\n",
      "epoch 83; iter: 0; batch classifier loss: 0.419973; batch adversarial loss: 0.581687\n",
      "epoch 84; iter: 0; batch classifier loss: 0.400533; batch adversarial loss: 0.563931\n",
      "epoch 85; iter: 0; batch classifier loss: 0.327929; batch adversarial loss: 0.498939\n",
      "epoch 86; iter: 0; batch classifier loss: 0.319691; batch adversarial loss: 0.499108\n",
      "epoch 87; iter: 0; batch classifier loss: 0.414640; batch adversarial loss: 0.514578\n",
      "epoch 88; iter: 0; batch classifier loss: 0.379855; batch adversarial loss: 0.574438\n",
      "epoch 89; iter: 0; batch classifier loss: 0.417946; batch adversarial loss: 0.628833\n",
      "epoch 90; iter: 0; batch classifier loss: 0.383930; batch adversarial loss: 0.431293\n",
      "epoch 91; iter: 0; batch classifier loss: 0.430475; batch adversarial loss: 0.544124\n",
      "epoch 92; iter: 0; batch classifier loss: 0.340121; batch adversarial loss: 0.507190\n",
      "epoch 93; iter: 0; batch classifier loss: 0.367805; batch adversarial loss: 0.526150\n",
      "epoch 94; iter: 0; batch classifier loss: 0.404934; batch adversarial loss: 0.508032\n",
      "epoch 95; iter: 0; batch classifier loss: 0.429957; batch adversarial loss: 0.496997\n",
      "epoch 96; iter: 0; batch classifier loss: 0.451423; batch adversarial loss: 0.544571\n",
      "epoch 97; iter: 0; batch classifier loss: 0.366789; batch adversarial loss: 0.480540\n",
      "epoch 98; iter: 0; batch classifier loss: 0.341589; batch adversarial loss: 0.451839\n",
      "epoch 99; iter: 0; batch classifier loss: 0.395794; batch adversarial loss: 0.495484\n",
      "epoch 100; iter: 0; batch classifier loss: 0.466404; batch adversarial loss: 0.622985\n",
      "epoch 101; iter: 0; batch classifier loss: 0.392385; batch adversarial loss: 0.563366\n",
      "epoch 102; iter: 0; batch classifier loss: 0.432701; batch adversarial loss: 0.566258\n",
      "epoch 103; iter: 0; batch classifier loss: 0.342624; batch adversarial loss: 0.481945\n",
      "epoch 104; iter: 0; batch classifier loss: 0.344475; batch adversarial loss: 0.543921\n",
      "epoch 105; iter: 0; batch classifier loss: 0.399632; batch adversarial loss: 0.506717\n",
      "epoch 106; iter: 0; batch classifier loss: 0.357431; batch adversarial loss: 0.627390\n",
      "epoch 107; iter: 0; batch classifier loss: 0.375168; batch adversarial loss: 0.496231\n",
      "epoch 108; iter: 0; batch classifier loss: 0.377916; batch adversarial loss: 0.618844\n",
      "epoch 109; iter: 0; batch classifier loss: 0.362344; batch adversarial loss: 0.488134\n",
      "epoch 110; iter: 0; batch classifier loss: 0.358359; batch adversarial loss: 0.559631\n",
      "epoch 111; iter: 0; batch classifier loss: 0.331930; batch adversarial loss: 0.488576\n",
      "epoch 112; iter: 0; batch classifier loss: 0.347917; batch adversarial loss: 0.527639\n",
      "epoch 113; iter: 0; batch classifier loss: 0.337003; batch adversarial loss: 0.555063\n",
      "epoch 114; iter: 0; batch classifier loss: 0.267250; batch adversarial loss: 0.599770\n",
      "epoch 115; iter: 0; batch classifier loss: 0.396577; batch adversarial loss: 0.552097\n",
      "epoch 116; iter: 0; batch classifier loss: 0.387035; batch adversarial loss: 0.561872\n",
      "epoch 117; iter: 0; batch classifier loss: 0.399839; batch adversarial loss: 0.498694\n",
      "epoch 118; iter: 0; batch classifier loss: 0.381963; batch adversarial loss: 0.450253\n",
      "epoch 119; iter: 0; batch classifier loss: 0.455870; batch adversarial loss: 0.560357\n",
      "epoch 120; iter: 0; batch classifier loss: 0.358084; batch adversarial loss: 0.497433\n",
      "epoch 121; iter: 0; batch classifier loss: 0.387432; batch adversarial loss: 0.591995\n",
      "epoch 122; iter: 0; batch classifier loss: 0.337755; batch adversarial loss: 0.479722\n",
      "epoch 123; iter: 0; batch classifier loss: 0.363988; batch adversarial loss: 0.514229\n",
      "epoch 124; iter: 0; batch classifier loss: 0.394670; batch adversarial loss: 0.544752\n",
      "epoch 125; iter: 0; batch classifier loss: 0.420852; batch adversarial loss: 0.496121\n",
      "epoch 126; iter: 0; batch classifier loss: 0.398198; batch adversarial loss: 0.543707\n",
      "epoch 127; iter: 0; batch classifier loss: 0.360279; batch adversarial loss: 0.489205\n",
      "epoch 128; iter: 0; batch classifier loss: 0.395022; batch adversarial loss: 0.572764\n",
      "epoch 129; iter: 0; batch classifier loss: 0.465490; batch adversarial loss: 0.515152\n",
      "epoch 130; iter: 0; batch classifier loss: 0.461826; batch adversarial loss: 0.525773\n",
      "epoch 131; iter: 0; batch classifier loss: 0.320996; batch adversarial loss: 0.497886\n",
      "epoch 132; iter: 0; batch classifier loss: 0.376935; batch adversarial loss: 0.516115\n",
      "epoch 133; iter: 0; batch classifier loss: 0.320799; batch adversarial loss: 0.553539\n",
      "epoch 134; iter: 0; batch classifier loss: 0.364903; batch adversarial loss: 0.536011\n",
      "epoch 135; iter: 0; batch classifier loss: 0.317738; batch adversarial loss: 0.590908\n",
      "epoch 136; iter: 0; batch classifier loss: 0.363003; batch adversarial loss: 0.507273\n",
      "epoch 137; iter: 0; batch classifier loss: 0.416480; batch adversarial loss: 0.596451\n",
      "epoch 138; iter: 0; batch classifier loss: 0.384460; batch adversarial loss: 0.583103\n",
      "epoch 139; iter: 0; batch classifier loss: 0.445439; batch adversarial loss: 0.468971\n",
      "epoch 140; iter: 0; batch classifier loss: 0.384541; batch adversarial loss: 0.488803\n",
      "epoch 141; iter: 0; batch classifier loss: 0.380209; batch adversarial loss: 0.467320\n",
      "epoch 142; iter: 0; batch classifier loss: 0.488876; batch adversarial loss: 0.583608\n",
      "epoch 143; iter: 0; batch classifier loss: 0.298920; batch adversarial loss: 0.603606\n",
      "epoch 144; iter: 0; batch classifier loss: 0.412089; batch adversarial loss: 0.523955\n",
      "epoch 145; iter: 0; batch classifier loss: 0.456159; batch adversarial loss: 0.571963\n",
      "epoch 146; iter: 0; batch classifier loss: 0.333969; batch adversarial loss: 0.544102\n",
      "epoch 147; iter: 0; batch classifier loss: 0.332920; batch adversarial loss: 0.569959\n",
      "epoch 148; iter: 0; batch classifier loss: 0.279980; batch adversarial loss: 0.579465\n",
      "epoch 149; iter: 0; batch classifier loss: 0.332812; batch adversarial loss: 0.579549\n",
      "epoch 150; iter: 0; batch classifier loss: 0.353307; batch adversarial loss: 0.537350\n",
      "epoch 151; iter: 0; batch classifier loss: 0.290897; batch adversarial loss: 0.570674\n",
      "epoch 152; iter: 0; batch classifier loss: 0.389263; batch adversarial loss: 0.542204\n",
      "epoch 153; iter: 0; batch classifier loss: 0.384593; batch adversarial loss: 0.563911\n",
      "epoch 154; iter: 0; batch classifier loss: 0.372388; batch adversarial loss: 0.544185\n",
      "epoch 155; iter: 0; batch classifier loss: 0.356328; batch adversarial loss: 0.552451\n",
      "epoch 156; iter: 0; batch classifier loss: 0.375909; batch adversarial loss: 0.526045\n",
      "epoch 157; iter: 0; batch classifier loss: 0.382433; batch adversarial loss: 0.580799\n",
      "epoch 158; iter: 0; batch classifier loss: 0.419660; batch adversarial loss: 0.545688\n",
      "epoch 159; iter: 0; batch classifier loss: 0.412558; batch adversarial loss: 0.515752\n",
      "epoch 160; iter: 0; batch classifier loss: 0.372981; batch adversarial loss: 0.591140\n",
      "epoch 161; iter: 0; batch classifier loss: 0.390376; batch adversarial loss: 0.471282\n",
      "epoch 162; iter: 0; batch classifier loss: 0.383770; batch adversarial loss: 0.627653\n",
      "epoch 163; iter: 0; batch classifier loss: 0.385258; batch adversarial loss: 0.543761\n",
      "epoch 164; iter: 0; batch classifier loss: 0.394806; batch adversarial loss: 0.524381\n",
      "epoch 165; iter: 0; batch classifier loss: 0.318315; batch adversarial loss: 0.574258\n",
      "epoch 166; iter: 0; batch classifier loss: 0.272057; batch adversarial loss: 0.537386\n",
      "epoch 167; iter: 0; batch classifier loss: 0.325218; batch adversarial loss: 0.553878\n",
      "epoch 168; iter: 0; batch classifier loss: 0.354797; batch adversarial loss: 0.560706\n",
      "epoch 169; iter: 0; batch classifier loss: 0.429727; batch adversarial loss: 0.633315\n",
      "epoch 170; iter: 0; batch classifier loss: 0.411143; batch adversarial loss: 0.577125\n",
      "epoch 171; iter: 0; batch classifier loss: 0.443642; batch adversarial loss: 0.649407\n",
      "epoch 172; iter: 0; batch classifier loss: 0.381536; batch adversarial loss: 0.590714\n",
      "epoch 173; iter: 0; batch classifier loss: 0.324562; batch adversarial loss: 0.612298\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 174; iter: 0; batch classifier loss: 0.298162; batch adversarial loss: 0.515200\n",
      "epoch 175; iter: 0; batch classifier loss: 0.441044; batch adversarial loss: 0.527447\n",
      "epoch 176; iter: 0; batch classifier loss: 0.295117; batch adversarial loss: 0.553954\n",
      "epoch 177; iter: 0; batch classifier loss: 0.268254; batch adversarial loss: 0.611252\n",
      "epoch 178; iter: 0; batch classifier loss: 0.427478; batch adversarial loss: 0.488215\n",
      "epoch 179; iter: 0; batch classifier loss: 0.385720; batch adversarial loss: 0.608424\n",
      "epoch 180; iter: 0; batch classifier loss: 0.366188; batch adversarial loss: 0.600285\n",
      "epoch 181; iter: 0; batch classifier loss: 0.437163; batch adversarial loss: 0.517579\n",
      "epoch 182; iter: 0; batch classifier loss: 0.364721; batch adversarial loss: 0.589533\n",
      "epoch 183; iter: 0; batch classifier loss: 0.349761; batch adversarial loss: 0.535275\n",
      "epoch 184; iter: 0; batch classifier loss: 0.326801; batch adversarial loss: 0.556446\n",
      "epoch 185; iter: 0; batch classifier loss: 0.366623; batch adversarial loss: 0.545062\n",
      "epoch 186; iter: 0; batch classifier loss: 0.318186; batch adversarial loss: 0.580789\n",
      "epoch 187; iter: 0; batch classifier loss: 0.325934; batch adversarial loss: 0.527636\n",
      "epoch 188; iter: 0; batch classifier loss: 0.402638; batch adversarial loss: 0.648462\n",
      "epoch 189; iter: 0; batch classifier loss: 0.417838; batch adversarial loss: 0.506320\n",
      "epoch 190; iter: 0; batch classifier loss: 0.416280; batch adversarial loss: 0.619885\n",
      "epoch 191; iter: 0; batch classifier loss: 0.355504; batch adversarial loss: 0.562457\n",
      "epoch 192; iter: 0; batch classifier loss: 0.318822; batch adversarial loss: 0.514443\n",
      "epoch 193; iter: 0; batch classifier loss: 0.369482; batch adversarial loss: 0.486720\n",
      "epoch 194; iter: 0; batch classifier loss: 0.434510; batch adversarial loss: 0.471640\n",
      "epoch 195; iter: 0; batch classifier loss: 0.301448; batch adversarial loss: 0.534586\n",
      "epoch 196; iter: 0; batch classifier loss: 0.370226; batch adversarial loss: 0.471368\n",
      "epoch 197; iter: 0; batch classifier loss: 0.360651; batch adversarial loss: 0.505341\n",
      "epoch 198; iter: 0; batch classifier loss: 0.334112; batch adversarial loss: 0.513366\n",
      "epoch 199; iter: 0; batch classifier loss: 0.338233; batch adversarial loss: 0.479924\n",
      "epoch 0; iter: 0; batch classifier loss: 0.655467; batch adversarial loss: 0.713044\n",
      "epoch 1; iter: 0; batch classifier loss: 0.542921; batch adversarial loss: 0.685197\n",
      "epoch 2; iter: 0; batch classifier loss: 0.581540; batch adversarial loss: 0.652814\n",
      "epoch 3; iter: 0; batch classifier loss: 0.532823; batch adversarial loss: 0.629056\n",
      "epoch 4; iter: 0; batch classifier loss: 0.597303; batch adversarial loss: 0.607246\n",
      "epoch 5; iter: 0; batch classifier loss: 0.556996; batch adversarial loss: 0.605029\n",
      "epoch 6; iter: 0; batch classifier loss: 0.480554; batch adversarial loss: 0.580009\n",
      "epoch 7; iter: 0; batch classifier loss: 0.536718; batch adversarial loss: 0.568163\n",
      "epoch 8; iter: 0; batch classifier loss: 0.513797; batch adversarial loss: 0.597979\n",
      "epoch 9; iter: 0; batch classifier loss: 0.564853; batch adversarial loss: 0.559668\n",
      "epoch 10; iter: 0; batch classifier loss: 0.502952; batch adversarial loss: 0.578959\n",
      "epoch 11; iter: 0; batch classifier loss: 0.528588; batch adversarial loss: 0.583972\n",
      "epoch 12; iter: 0; batch classifier loss: 0.558765; batch adversarial loss: 0.623026\n",
      "epoch 13; iter: 0; batch classifier loss: 0.557505; batch adversarial loss: 0.579173\n",
      "epoch 14; iter: 0; batch classifier loss: 0.543678; batch adversarial loss: 0.511827\n",
      "epoch 15; iter: 0; batch classifier loss: 0.538067; batch adversarial loss: 0.590879\n",
      "epoch 16; iter: 0; batch classifier loss: 0.631363; batch adversarial loss: 0.615672\n",
      "epoch 17; iter: 0; batch classifier loss: 0.567671; batch adversarial loss: 0.566689\n",
      "epoch 18; iter: 0; batch classifier loss: 0.521424; batch adversarial loss: 0.567043\n",
      "epoch 19; iter: 0; batch classifier loss: 0.554832; batch adversarial loss: 0.508721\n",
      "epoch 20; iter: 0; batch classifier loss: 0.548147; batch adversarial loss: 0.535534\n",
      "epoch 21; iter: 0; batch classifier loss: 0.415441; batch adversarial loss: 0.626627\n",
      "epoch 22; iter: 0; batch classifier loss: 0.411537; batch adversarial loss: 0.546468\n",
      "epoch 23; iter: 0; batch classifier loss: 0.439342; batch adversarial loss: 0.594525\n",
      "epoch 24; iter: 0; batch classifier loss: 0.528620; batch adversarial loss: 0.562461\n",
      "epoch 25; iter: 0; batch classifier loss: 0.478990; batch adversarial loss: 0.548543\n",
      "epoch 26; iter: 0; batch classifier loss: 0.510759; batch adversarial loss: 0.500134\n",
      "epoch 27; iter: 0; batch classifier loss: 0.511654; batch adversarial loss: 0.546724\n",
      "epoch 28; iter: 0; batch classifier loss: 0.510171; batch adversarial loss: 0.447710\n",
      "epoch 29; iter: 0; batch classifier loss: 0.432724; batch adversarial loss: 0.518830\n",
      "epoch 30; iter: 0; batch classifier loss: 0.467333; batch adversarial loss: 0.511486\n",
      "epoch 31; iter: 0; batch classifier loss: 0.518758; batch adversarial loss: 0.595705\n",
      "epoch 32; iter: 0; batch classifier loss: 0.453583; batch adversarial loss: 0.573063\n",
      "epoch 33; iter: 0; batch classifier loss: 0.406181; batch adversarial loss: 0.476360\n",
      "epoch 34; iter: 0; batch classifier loss: 0.511947; batch adversarial loss: 0.547080\n",
      "epoch 35; iter: 0; batch classifier loss: 0.405066; batch adversarial loss: 0.599105\n",
      "epoch 36; iter: 0; batch classifier loss: 0.415165; batch adversarial loss: 0.538898\n",
      "epoch 37; iter: 0; batch classifier loss: 0.463527; batch adversarial loss: 0.509973\n",
      "epoch 38; iter: 0; batch classifier loss: 0.424221; batch adversarial loss: 0.561230\n",
      "epoch 39; iter: 0; batch classifier loss: 0.415957; batch adversarial loss: 0.519357\n",
      "epoch 40; iter: 0; batch classifier loss: 0.382396; batch adversarial loss: 0.561453\n",
      "epoch 41; iter: 0; batch classifier loss: 0.419310; batch adversarial loss: 0.482943\n",
      "epoch 42; iter: 0; batch classifier loss: 0.402391; batch adversarial loss: 0.526746\n",
      "epoch 43; iter: 0; batch classifier loss: 0.475744; batch adversarial loss: 0.528015\n",
      "epoch 44; iter: 0; batch classifier loss: 0.436555; batch adversarial loss: 0.543986\n",
      "epoch 45; iter: 0; batch classifier loss: 0.383506; batch adversarial loss: 0.571715\n",
      "epoch 46; iter: 0; batch classifier loss: 0.401786; batch adversarial loss: 0.582390\n",
      "epoch 47; iter: 0; batch classifier loss: 0.418660; batch adversarial loss: 0.553223\n",
      "epoch 48; iter: 0; batch classifier loss: 0.416306; batch adversarial loss: 0.508334\n",
      "epoch 49; iter: 0; batch classifier loss: 0.482027; batch adversarial loss: 0.517825\n",
      "epoch 50; iter: 0; batch classifier loss: 0.458363; batch adversarial loss: 0.536072\n",
      "epoch 51; iter: 0; batch classifier loss: 0.417636; batch adversarial loss: 0.564111\n",
      "epoch 52; iter: 0; batch classifier loss: 0.393246; batch adversarial loss: 0.616781\n",
      "epoch 53; iter: 0; batch classifier loss: 0.427485; batch adversarial loss: 0.517387\n",
      "epoch 54; iter: 0; batch classifier loss: 0.444159; batch adversarial loss: 0.634108\n",
      "epoch 55; iter: 0; batch classifier loss: 0.398507; batch adversarial loss: 0.562397\n",
      "epoch 56; iter: 0; batch classifier loss: 0.420349; batch adversarial loss: 0.562502\n",
      "epoch 57; iter: 0; batch classifier loss: 0.431164; batch adversarial loss: 0.552874\n",
      "epoch 58; iter: 0; batch classifier loss: 0.391314; batch adversarial loss: 0.562875\n",
      "epoch 59; iter: 0; batch classifier loss: 0.441144; batch adversarial loss: 0.490834\n",
      "epoch 60; iter: 0; batch classifier loss: 0.382699; batch adversarial loss: 0.588755\n",
      "epoch 61; iter: 0; batch classifier loss: 0.382056; batch adversarial loss: 0.508859\n",
      "epoch 62; iter: 0; batch classifier loss: 0.446711; batch adversarial loss: 0.517629\n",
      "epoch 63; iter: 0; batch classifier loss: 0.469950; batch adversarial loss: 0.580166\n",
      "epoch 64; iter: 0; batch classifier loss: 0.329697; batch adversarial loss: 0.554052\n",
      "epoch 65; iter: 0; batch classifier loss: 0.388825; batch adversarial loss: 0.553903\n",
      "epoch 66; iter: 0; batch classifier loss: 0.397471; batch adversarial loss: 0.580895\n",
      "epoch 67; iter: 0; batch classifier loss: 0.494524; batch adversarial loss: 0.625816\n",
      "epoch 68; iter: 0; batch classifier loss: 0.385310; batch adversarial loss: 0.580847\n",
      "epoch 69; iter: 0; batch classifier loss: 0.364909; batch adversarial loss: 0.571969\n",
      "epoch 70; iter: 0; batch classifier loss: 0.385063; batch adversarial loss: 0.562274\n",
      "epoch 71; iter: 0; batch classifier loss: 0.465602; batch adversarial loss: 0.571455\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 72; iter: 0; batch classifier loss: 0.381588; batch adversarial loss: 0.481559\n",
      "epoch 73; iter: 0; batch classifier loss: 0.353510; batch adversarial loss: 0.553555\n",
      "epoch 74; iter: 0; batch classifier loss: 0.401881; batch adversarial loss: 0.626081\n",
      "epoch 75; iter: 0; batch classifier loss: 0.427324; batch adversarial loss: 0.517327\n",
      "epoch 76; iter: 0; batch classifier loss: 0.399459; batch adversarial loss: 0.517121\n",
      "epoch 77; iter: 0; batch classifier loss: 0.428960; batch adversarial loss: 0.553154\n",
      "epoch 78; iter: 0; batch classifier loss: 0.370395; batch adversarial loss: 0.517573\n",
      "epoch 79; iter: 0; batch classifier loss: 0.372354; batch adversarial loss: 0.508582\n",
      "epoch 80; iter: 0; batch classifier loss: 0.382416; batch adversarial loss: 0.535797\n",
      "epoch 81; iter: 0; batch classifier loss: 0.387174; batch adversarial loss: 0.589445\n",
      "epoch 82; iter: 0; batch classifier loss: 0.423299; batch adversarial loss: 0.553614\n",
      "epoch 83; iter: 0; batch classifier loss: 0.420105; batch adversarial loss: 0.545551\n",
      "epoch 84; iter: 0; batch classifier loss: 0.355595; batch adversarial loss: 0.535184\n",
      "epoch 85; iter: 0; batch classifier loss: 0.397630; batch adversarial loss: 0.490434\n",
      "epoch 86; iter: 0; batch classifier loss: 0.371922; batch adversarial loss: 0.508846\n",
      "epoch 87; iter: 0; batch classifier loss: 0.399394; batch adversarial loss: 0.553057\n",
      "epoch 88; iter: 0; batch classifier loss: 0.400603; batch adversarial loss: 0.517437\n",
      "epoch 89; iter: 0; batch classifier loss: 0.398514; batch adversarial loss: 0.616872\n",
      "epoch 90; iter: 0; batch classifier loss: 0.435784; batch adversarial loss: 0.661381\n",
      "epoch 91; iter: 0; batch classifier loss: 0.438679; batch adversarial loss: 0.535332\n",
      "epoch 92; iter: 0; batch classifier loss: 0.417169; batch adversarial loss: 0.535936\n",
      "epoch 93; iter: 0; batch classifier loss: 0.398466; batch adversarial loss: 0.500147\n",
      "epoch 94; iter: 0; batch classifier loss: 0.318359; batch adversarial loss: 0.516928\n",
      "epoch 95; iter: 0; batch classifier loss: 0.333827; batch adversarial loss: 0.534680\n",
      "epoch 96; iter: 0; batch classifier loss: 0.334004; batch adversarial loss: 0.535924\n",
      "epoch 97; iter: 0; batch classifier loss: 0.443806; batch adversarial loss: 0.589542\n",
      "epoch 98; iter: 0; batch classifier loss: 0.383379; batch adversarial loss: 0.590243\n",
      "epoch 99; iter: 0; batch classifier loss: 0.379888; batch adversarial loss: 0.580084\n",
      "epoch 100; iter: 0; batch classifier loss: 0.393042; batch adversarial loss: 0.516911\n",
      "epoch 101; iter: 0; batch classifier loss: 0.384486; batch adversarial loss: 0.579784\n",
      "epoch 102; iter: 0; batch classifier loss: 0.381240; batch adversarial loss: 0.590246\n",
      "epoch 103; iter: 0; batch classifier loss: 0.323312; batch adversarial loss: 0.509271\n",
      "epoch 104; iter: 0; batch classifier loss: 0.372691; batch adversarial loss: 0.535258\n",
      "epoch 105; iter: 0; batch classifier loss: 0.401806; batch adversarial loss: 0.507959\n",
      "epoch 106; iter: 0; batch classifier loss: 0.391190; batch adversarial loss: 0.472996\n",
      "epoch 107; iter: 0; batch classifier loss: 0.393379; batch adversarial loss: 0.444730\n",
      "epoch 108; iter: 0; batch classifier loss: 0.391419; batch adversarial loss: 0.509128\n",
      "epoch 109; iter: 0; batch classifier loss: 0.377936; batch adversarial loss: 0.526019\n",
      "epoch 110; iter: 0; batch classifier loss: 0.412294; batch adversarial loss: 0.590495\n",
      "epoch 111; iter: 0; batch classifier loss: 0.374568; batch adversarial loss: 0.599806\n",
      "epoch 112; iter: 0; batch classifier loss: 0.382114; batch adversarial loss: 0.626924\n",
      "epoch 113; iter: 0; batch classifier loss: 0.417276; batch adversarial loss: 0.490087\n",
      "epoch 114; iter: 0; batch classifier loss: 0.315975; batch adversarial loss: 0.553400\n",
      "epoch 115; iter: 0; batch classifier loss: 0.374659; batch adversarial loss: 0.525970\n",
      "epoch 116; iter: 0; batch classifier loss: 0.420220; batch adversarial loss: 0.617405\n",
      "epoch 117; iter: 0; batch classifier loss: 0.476754; batch adversarial loss: 0.544486\n",
      "epoch 118; iter: 0; batch classifier loss: 0.396035; batch adversarial loss: 0.580471\n",
      "epoch 119; iter: 0; batch classifier loss: 0.388772; batch adversarial loss: 0.608655\n",
      "epoch 120; iter: 0; batch classifier loss: 0.375758; batch adversarial loss: 0.508102\n",
      "epoch 121; iter: 0; batch classifier loss: 0.418647; batch adversarial loss: 0.580834\n",
      "epoch 122; iter: 0; batch classifier loss: 0.360727; batch adversarial loss: 0.481949\n",
      "epoch 123; iter: 0; batch classifier loss: 0.350439; batch adversarial loss: 0.625855\n",
      "epoch 124; iter: 0; batch classifier loss: 0.477144; batch adversarial loss: 0.590743\n",
      "epoch 125; iter: 0; batch classifier loss: 0.437464; batch adversarial loss: 0.545052\n",
      "epoch 126; iter: 0; batch classifier loss: 0.317871; batch adversarial loss: 0.599779\n",
      "epoch 127; iter: 0; batch classifier loss: 0.386402; batch adversarial loss: 0.516023\n",
      "epoch 128; iter: 0; batch classifier loss: 0.414994; batch adversarial loss: 0.562751\n",
      "epoch 129; iter: 0; batch classifier loss: 0.340330; batch adversarial loss: 0.598527\n",
      "epoch 130; iter: 0; batch classifier loss: 0.343588; batch adversarial loss: 0.552979\n",
      "epoch 131; iter: 0; batch classifier loss: 0.396930; batch adversarial loss: 0.545018\n",
      "epoch 132; iter: 0; batch classifier loss: 0.299386; batch adversarial loss: 0.571059\n",
      "epoch 133; iter: 0; batch classifier loss: 0.386428; batch adversarial loss: 0.599628\n",
      "epoch 134; iter: 0; batch classifier loss: 0.387377; batch adversarial loss: 0.499663\n",
      "epoch 135; iter: 0; batch classifier loss: 0.338852; batch adversarial loss: 0.534694\n",
      "epoch 136; iter: 0; batch classifier loss: 0.370514; batch adversarial loss: 0.535449\n",
      "epoch 137; iter: 0; batch classifier loss: 0.399763; batch adversarial loss: 0.509009\n",
      "epoch 138; iter: 0; batch classifier loss: 0.387183; batch adversarial loss: 0.480904\n",
      "epoch 139; iter: 0; batch classifier loss: 0.393305; batch adversarial loss: 0.544814\n",
      "epoch 140; iter: 0; batch classifier loss: 0.367824; batch adversarial loss: 0.617047\n",
      "epoch 141; iter: 0; batch classifier loss: 0.308636; batch adversarial loss: 0.571693\n",
      "epoch 142; iter: 0; batch classifier loss: 0.340375; batch adversarial loss: 0.589257\n",
      "epoch 143; iter: 0; batch classifier loss: 0.345079; batch adversarial loss: 0.454320\n",
      "epoch 144; iter: 0; batch classifier loss: 0.393978; batch adversarial loss: 0.570402\n",
      "epoch 145; iter: 0; batch classifier loss: 0.417884; batch adversarial loss: 0.563216\n",
      "epoch 146; iter: 0; batch classifier loss: 0.368098; batch adversarial loss: 0.554114\n",
      "epoch 147; iter: 0; batch classifier loss: 0.453240; batch adversarial loss: 0.553478\n",
      "epoch 148; iter: 0; batch classifier loss: 0.433611; batch adversarial loss: 0.650479\n",
      "epoch 149; iter: 0; batch classifier loss: 0.354423; batch adversarial loss: 0.562648\n",
      "epoch 150; iter: 0; batch classifier loss: 0.398441; batch adversarial loss: 0.489925\n",
      "epoch 151; iter: 0; batch classifier loss: 0.374611; batch adversarial loss: 0.535461\n",
      "epoch 152; iter: 0; batch classifier loss: 0.369549; batch adversarial loss: 0.499937\n",
      "epoch 153; iter: 0; batch classifier loss: 0.339122; batch adversarial loss: 0.480495\n",
      "epoch 154; iter: 0; batch classifier loss: 0.354899; batch adversarial loss: 0.553068\n",
      "epoch 155; iter: 0; batch classifier loss: 0.386809; batch adversarial loss: 0.526148\n",
      "epoch 156; iter: 0; batch classifier loss: 0.341790; batch adversarial loss: 0.499335\n",
      "epoch 157; iter: 0; batch classifier loss: 0.421411; batch adversarial loss: 0.570095\n",
      "epoch 158; iter: 0; batch classifier loss: 0.456407; batch adversarial loss: 0.507501\n",
      "epoch 159; iter: 0; batch classifier loss: 0.321004; batch adversarial loss: 0.498362\n",
      "epoch 160; iter: 0; batch classifier loss: 0.342015; batch adversarial loss: 0.509520\n",
      "epoch 161; iter: 0; batch classifier loss: 0.410909; batch adversarial loss: 0.444075\n",
      "epoch 162; iter: 0; batch classifier loss: 0.444927; batch adversarial loss: 0.580896\n",
      "epoch 163; iter: 0; batch classifier loss: 0.321440; batch adversarial loss: 0.580307\n",
      "epoch 164; iter: 0; batch classifier loss: 0.329489; batch adversarial loss: 0.481160\n",
      "epoch 165; iter: 0; batch classifier loss: 0.388146; batch adversarial loss: 0.562353\n",
      "epoch 166; iter: 0; batch classifier loss: 0.414894; batch adversarial loss: 0.535184\n",
      "epoch 167; iter: 0; batch classifier loss: 0.285442; batch adversarial loss: 0.516378\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 168; iter: 0; batch classifier loss: 0.331076; batch adversarial loss: 0.554056\n",
      "epoch 169; iter: 0; batch classifier loss: 0.364893; batch adversarial loss: 0.499314\n",
      "epoch 170; iter: 0; batch classifier loss: 0.335740; batch adversarial loss: 0.570534\n",
      "epoch 171; iter: 0; batch classifier loss: 0.311839; batch adversarial loss: 0.489837\n",
      "epoch 172; iter: 0; batch classifier loss: 0.366195; batch adversarial loss: 0.490469\n",
      "epoch 173; iter: 0; batch classifier loss: 0.292943; batch adversarial loss: 0.563918\n",
      "epoch 174; iter: 0; batch classifier loss: 0.397547; batch adversarial loss: 0.562706\n",
      "epoch 175; iter: 0; batch classifier loss: 0.319319; batch adversarial loss: 0.571624\n",
      "epoch 176; iter: 0; batch classifier loss: 0.379610; batch adversarial loss: 0.544715\n",
      "epoch 177; iter: 0; batch classifier loss: 0.391002; batch adversarial loss: 0.607963\n",
      "epoch 178; iter: 0; batch classifier loss: 0.304936; batch adversarial loss: 0.516556\n",
      "epoch 179; iter: 0; batch classifier loss: 0.381246; batch adversarial loss: 0.498913\n",
      "epoch 180; iter: 0; batch classifier loss: 0.363040; batch adversarial loss: 0.525245\n",
      "epoch 181; iter: 0; batch classifier loss: 0.321230; batch adversarial loss: 0.500406\n",
      "epoch 182; iter: 0; batch classifier loss: 0.321810; batch adversarial loss: 0.563421\n",
      "epoch 183; iter: 0; batch classifier loss: 0.282478; batch adversarial loss: 0.581668\n",
      "epoch 184; iter: 0; batch classifier loss: 0.312707; batch adversarial loss: 0.562452\n",
      "epoch 185; iter: 0; batch classifier loss: 0.328133; batch adversarial loss: 0.526259\n",
      "epoch 186; iter: 0; batch classifier loss: 0.422177; batch adversarial loss: 0.581208\n",
      "epoch 187; iter: 0; batch classifier loss: 0.360634; batch adversarial loss: 0.571875\n",
      "epoch 188; iter: 0; batch classifier loss: 0.384684; batch adversarial loss: 0.617617\n",
      "epoch 189; iter: 0; batch classifier loss: 0.352375; batch adversarial loss: 0.554205\n",
      "epoch 190; iter: 0; batch classifier loss: 0.368174; batch adversarial loss: 0.472289\n",
      "epoch 191; iter: 0; batch classifier loss: 0.465669; batch adversarial loss: 0.599093\n",
      "epoch 192; iter: 0; batch classifier loss: 0.375758; batch adversarial loss: 0.498281\n",
      "epoch 193; iter: 0; batch classifier loss: 0.384557; batch adversarial loss: 0.535918\n",
      "epoch 194; iter: 0; batch classifier loss: 0.396373; batch adversarial loss: 0.463728\n",
      "epoch 195; iter: 0; batch classifier loss: 0.297468; batch adversarial loss: 0.635622\n",
      "epoch 196; iter: 0; batch classifier loss: 0.334068; batch adversarial loss: 0.535607\n",
      "epoch 197; iter: 0; batch classifier loss: 0.342298; batch adversarial loss: 0.490309\n",
      "epoch 198; iter: 0; batch classifier loss: 0.332692; batch adversarial loss: 0.515894\n",
      "epoch 199; iter: 0; batch classifier loss: 0.286911; batch adversarial loss: 0.517129\n",
      "epoch 0; iter: 0; batch classifier loss: 0.721419; batch adversarial loss: 0.678516\n",
      "epoch 1; iter: 0; batch classifier loss: 0.552444; batch adversarial loss: 0.688895\n",
      "epoch 2; iter: 0; batch classifier loss: 0.594261; batch adversarial loss: 0.661709\n",
      "epoch 3; iter: 0; batch classifier loss: 0.589542; batch adversarial loss: 0.614420\n",
      "epoch 4; iter: 0; batch classifier loss: 0.576907; batch adversarial loss: 0.613905\n",
      "epoch 5; iter: 0; batch classifier loss: 0.635991; batch adversarial loss: 0.638541\n",
      "epoch 6; iter: 0; batch classifier loss: 0.592531; batch adversarial loss: 0.594892\n",
      "epoch 7; iter: 0; batch classifier loss: 0.596400; batch adversarial loss: 0.601340\n",
      "epoch 8; iter: 0; batch classifier loss: 0.573486; batch adversarial loss: 0.551505\n",
      "epoch 9; iter: 0; batch classifier loss: 0.569604; batch adversarial loss: 0.625264\n",
      "epoch 10; iter: 0; batch classifier loss: 0.536467; batch adversarial loss: 0.646364\n",
      "epoch 11; iter: 0; batch classifier loss: 0.533280; batch adversarial loss: 0.564508\n",
      "epoch 12; iter: 0; batch classifier loss: 0.504614; batch adversarial loss: 0.562862\n",
      "epoch 13; iter: 0; batch classifier loss: 0.499909; batch adversarial loss: 0.597281\n",
      "epoch 14; iter: 0; batch classifier loss: 0.547572; batch adversarial loss: 0.576477\n",
      "epoch 15; iter: 0; batch classifier loss: 0.486618; batch adversarial loss: 0.548110\n",
      "epoch 16; iter: 0; batch classifier loss: 0.463619; batch adversarial loss: 0.524585\n",
      "epoch 17; iter: 0; batch classifier loss: 0.540899; batch adversarial loss: 0.584856\n",
      "epoch 18; iter: 0; batch classifier loss: 0.485415; batch adversarial loss: 0.626015\n",
      "epoch 19; iter: 0; batch classifier loss: 0.462138; batch adversarial loss: 0.522221\n",
      "epoch 20; iter: 0; batch classifier loss: 0.470553; batch adversarial loss: 0.575129\n",
      "epoch 21; iter: 0; batch classifier loss: 0.539104; batch adversarial loss: 0.502151\n",
      "epoch 22; iter: 0; batch classifier loss: 0.411241; batch adversarial loss: 0.596864\n",
      "epoch 23; iter: 0; batch classifier loss: 0.464352; batch adversarial loss: 0.525319\n",
      "epoch 24; iter: 0; batch classifier loss: 0.478600; batch adversarial loss: 0.564290\n",
      "epoch 25; iter: 0; batch classifier loss: 0.441453; batch adversarial loss: 0.567711\n",
      "epoch 26; iter: 0; batch classifier loss: 0.488505; batch adversarial loss: 0.545741\n",
      "epoch 27; iter: 0; batch classifier loss: 0.426092; batch adversarial loss: 0.538181\n",
      "epoch 28; iter: 0; batch classifier loss: 0.482232; batch adversarial loss: 0.506490\n",
      "epoch 29; iter: 0; batch classifier loss: 0.448450; batch adversarial loss: 0.617519\n",
      "epoch 30; iter: 0; batch classifier loss: 0.468960; batch adversarial loss: 0.567780\n",
      "epoch 31; iter: 0; batch classifier loss: 0.463355; batch adversarial loss: 0.623924\n",
      "epoch 32; iter: 0; batch classifier loss: 0.371731; batch adversarial loss: 0.498152\n",
      "epoch 33; iter: 0; batch classifier loss: 0.422894; batch adversarial loss: 0.639961\n",
      "epoch 34; iter: 0; batch classifier loss: 0.474459; batch adversarial loss: 0.462960\n",
      "epoch 35; iter: 0; batch classifier loss: 0.412908; batch adversarial loss: 0.591246\n",
      "epoch 36; iter: 0; batch classifier loss: 0.443854; batch adversarial loss: 0.536660\n",
      "epoch 37; iter: 0; batch classifier loss: 0.461486; batch adversarial loss: 0.601818\n",
      "epoch 38; iter: 0; batch classifier loss: 0.413710; batch adversarial loss: 0.505482\n",
      "epoch 39; iter: 0; batch classifier loss: 0.461521; batch adversarial loss: 0.537068\n",
      "epoch 40; iter: 0; batch classifier loss: 0.402946; batch adversarial loss: 0.570364\n",
      "epoch 41; iter: 0; batch classifier loss: 0.496159; batch adversarial loss: 0.559709\n",
      "epoch 42; iter: 0; batch classifier loss: 0.432258; batch adversarial loss: 0.586878\n",
      "epoch 43; iter: 0; batch classifier loss: 0.472919; batch adversarial loss: 0.564392\n",
      "epoch 44; iter: 0; batch classifier loss: 0.537011; batch adversarial loss: 0.512600\n",
      "epoch 45; iter: 0; batch classifier loss: 0.470936; batch adversarial loss: 0.545051\n",
      "epoch 46; iter: 0; batch classifier loss: 0.350163; batch adversarial loss: 0.504367\n",
      "epoch 47; iter: 0; batch classifier loss: 0.439378; batch adversarial loss: 0.562560\n",
      "epoch 48; iter: 0; batch classifier loss: 0.437937; batch adversarial loss: 0.500139\n",
      "epoch 49; iter: 0; batch classifier loss: 0.477504; batch adversarial loss: 0.510653\n",
      "epoch 50; iter: 0; batch classifier loss: 0.430860; batch adversarial loss: 0.552363\n",
      "epoch 51; iter: 0; batch classifier loss: 0.405720; batch adversarial loss: 0.543796\n",
      "epoch 52; iter: 0; batch classifier loss: 0.434322; batch adversarial loss: 0.535731\n",
      "epoch 53; iter: 0; batch classifier loss: 0.381350; batch adversarial loss: 0.535638\n",
      "epoch 54; iter: 0; batch classifier loss: 0.358852; batch adversarial loss: 0.623790\n",
      "epoch 55; iter: 0; batch classifier loss: 0.471488; batch adversarial loss: 0.517634\n",
      "epoch 56; iter: 0; batch classifier loss: 0.423835; batch adversarial loss: 0.554131\n",
      "epoch 57; iter: 0; batch classifier loss: 0.399406; batch adversarial loss: 0.553295\n",
      "epoch 58; iter: 0; batch classifier loss: 0.444266; batch adversarial loss: 0.641315\n",
      "epoch 59; iter: 0; batch classifier loss: 0.446618; batch adversarial loss: 0.510721\n",
      "epoch 60; iter: 0; batch classifier loss: 0.359768; batch adversarial loss: 0.649052\n",
      "epoch 61; iter: 0; batch classifier loss: 0.447594; batch adversarial loss: 0.578766\n",
      "epoch 62; iter: 0; batch classifier loss: 0.370442; batch adversarial loss: 0.518373\n",
      "epoch 63; iter: 0; batch classifier loss: 0.473947; batch adversarial loss: 0.586003\n",
      "epoch 64; iter: 0; batch classifier loss: 0.330368; batch adversarial loss: 0.526112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 65; iter: 0; batch classifier loss: 0.463037; batch adversarial loss: 0.491315\n",
      "epoch 66; iter: 0; batch classifier loss: 0.429415; batch adversarial loss: 0.526324\n",
      "epoch 67; iter: 0; batch classifier loss: 0.418395; batch adversarial loss: 0.545115\n",
      "epoch 68; iter: 0; batch classifier loss: 0.432844; batch adversarial loss: 0.535727\n",
      "epoch 69; iter: 0; batch classifier loss: 0.339145; batch adversarial loss: 0.589878\n",
      "epoch 70; iter: 0; batch classifier loss: 0.370704; batch adversarial loss: 0.500573\n",
      "epoch 71; iter: 0; batch classifier loss: 0.440978; batch adversarial loss: 0.553432\n",
      "epoch 72; iter: 0; batch classifier loss: 0.372026; batch adversarial loss: 0.562347\n",
      "epoch 73; iter: 0; batch classifier loss: 0.387141; batch adversarial loss: 0.599296\n",
      "epoch 74; iter: 0; batch classifier loss: 0.419923; batch adversarial loss: 0.501930\n",
      "epoch 75; iter: 0; batch classifier loss: 0.397951; batch adversarial loss: 0.554690\n",
      "epoch 76; iter: 0; batch classifier loss: 0.461562; batch adversarial loss: 0.524122\n",
      "epoch 77; iter: 0; batch classifier loss: 0.437786; batch adversarial loss: 0.571888\n",
      "epoch 78; iter: 0; batch classifier loss: 0.376234; batch adversarial loss: 0.518556\n",
      "epoch 79; iter: 0; batch classifier loss: 0.370367; batch adversarial loss: 0.579494\n",
      "epoch 80; iter: 0; batch classifier loss: 0.383931; batch adversarial loss: 0.510165\n",
      "epoch 81; iter: 0; batch classifier loss: 0.424330; batch adversarial loss: 0.618104\n",
      "epoch 82; iter: 0; batch classifier loss: 0.356086; batch adversarial loss: 0.579411\n",
      "epoch 83; iter: 0; batch classifier loss: 0.507709; batch adversarial loss: 0.554944\n",
      "epoch 84; iter: 0; batch classifier loss: 0.480080; batch adversarial loss: 0.555611\n",
      "epoch 85; iter: 0; batch classifier loss: 0.475668; batch adversarial loss: 0.526190\n",
      "epoch 86; iter: 0; batch classifier loss: 0.377958; batch adversarial loss: 0.571086\n",
      "epoch 87; iter: 0; batch classifier loss: 0.338186; batch adversarial loss: 0.580283\n",
      "epoch 88; iter: 0; batch classifier loss: 0.401645; batch adversarial loss: 0.536667\n",
      "epoch 89; iter: 0; batch classifier loss: 0.416643; batch adversarial loss: 0.587630\n",
      "epoch 90; iter: 0; batch classifier loss: 0.349940; batch adversarial loss: 0.518159\n",
      "epoch 91; iter: 0; batch classifier loss: 0.343354; batch adversarial loss: 0.517565\n",
      "epoch 92; iter: 0; batch classifier loss: 0.385556; batch adversarial loss: 0.571320\n",
      "epoch 93; iter: 0; batch classifier loss: 0.409168; batch adversarial loss: 0.518118\n",
      "epoch 94; iter: 0; batch classifier loss: 0.328756; batch adversarial loss: 0.589933\n",
      "epoch 95; iter: 0; batch classifier loss: 0.471792; batch adversarial loss: 0.571529\n",
      "epoch 96; iter: 0; batch classifier loss: 0.420463; batch adversarial loss: 0.518217\n",
      "epoch 97; iter: 0; batch classifier loss: 0.479682; batch adversarial loss: 0.526097\n",
      "epoch 98; iter: 0; batch classifier loss: 0.485059; batch adversarial loss: 0.517951\n",
      "epoch 99; iter: 0; batch classifier loss: 0.360241; batch adversarial loss: 0.571343\n",
      "epoch 100; iter: 0; batch classifier loss: 0.409699; batch adversarial loss: 0.606938\n",
      "epoch 101; iter: 0; batch classifier loss: 0.370205; batch adversarial loss: 0.527080\n",
      "epoch 102; iter: 0; batch classifier loss: 0.370314; batch adversarial loss: 0.508643\n",
      "epoch 103; iter: 0; batch classifier loss: 0.367425; batch adversarial loss: 0.518800\n",
      "epoch 104; iter: 0; batch classifier loss: 0.409121; batch adversarial loss: 0.563787\n",
      "epoch 105; iter: 0; batch classifier loss: 0.405427; batch adversarial loss: 0.528446\n",
      "epoch 106; iter: 0; batch classifier loss: 0.346824; batch adversarial loss: 0.596709\n",
      "epoch 107; iter: 0; batch classifier loss: 0.262861; batch adversarial loss: 0.551360\n",
      "epoch 108; iter: 0; batch classifier loss: 0.389690; batch adversarial loss: 0.527258\n",
      "epoch 109; iter: 0; batch classifier loss: 0.429554; batch adversarial loss: 0.527549\n",
      "epoch 110; iter: 0; batch classifier loss: 0.413519; batch adversarial loss: 0.544014\n",
      "epoch 111; iter: 0; batch classifier loss: 0.395179; batch adversarial loss: 0.509786\n",
      "epoch 112; iter: 0; batch classifier loss: 0.363261; batch adversarial loss: 0.572094\n",
      "epoch 113; iter: 0; batch classifier loss: 0.378831; batch adversarial loss: 0.571442\n",
      "epoch 114; iter: 0; batch classifier loss: 0.406981; batch adversarial loss: 0.527986\n",
      "epoch 115; iter: 0; batch classifier loss: 0.473175; batch adversarial loss: 0.616917\n",
      "epoch 116; iter: 0; batch classifier loss: 0.353580; batch adversarial loss: 0.596778\n",
      "epoch 117; iter: 0; batch classifier loss: 0.379064; batch adversarial loss: 0.572046\n",
      "epoch 118; iter: 0; batch classifier loss: 0.447365; batch adversarial loss: 0.510421\n",
      "epoch 119; iter: 0; batch classifier loss: 0.306209; batch adversarial loss: 0.544995\n",
      "epoch 120; iter: 0; batch classifier loss: 0.355795; batch adversarial loss: 0.650736\n",
      "epoch 121; iter: 0; batch classifier loss: 0.413593; batch adversarial loss: 0.535152\n",
      "epoch 122; iter: 0; batch classifier loss: 0.400878; batch adversarial loss: 0.455728\n",
      "epoch 123; iter: 0; batch classifier loss: 0.399596; batch adversarial loss: 0.536247\n",
      "epoch 124; iter: 0; batch classifier loss: 0.342981; batch adversarial loss: 0.599100\n",
      "epoch 125; iter: 0; batch classifier loss: 0.402356; batch adversarial loss: 0.528380\n",
      "epoch 126; iter: 0; batch classifier loss: 0.441880; batch adversarial loss: 0.624884\n",
      "epoch 127; iter: 0; batch classifier loss: 0.427470; batch adversarial loss: 0.569937\n",
      "epoch 128; iter: 0; batch classifier loss: 0.441189; batch adversarial loss: 0.552104\n",
      "epoch 129; iter: 0; batch classifier loss: 0.436414; batch adversarial loss: 0.563543\n",
      "epoch 130; iter: 0; batch classifier loss: 0.375570; batch adversarial loss: 0.606781\n",
      "epoch 131; iter: 0; batch classifier loss: 0.373429; batch adversarial loss: 0.510419\n",
      "epoch 132; iter: 0; batch classifier loss: 0.384110; batch adversarial loss: 0.534644\n",
      "epoch 133; iter: 0; batch classifier loss: 0.316562; batch adversarial loss: 0.570894\n",
      "epoch 134; iter: 0; batch classifier loss: 0.416155; batch adversarial loss: 0.509299\n",
      "epoch 135; iter: 0; batch classifier loss: 0.376656; batch adversarial loss: 0.605713\n",
      "epoch 136; iter: 0; batch classifier loss: 0.369008; batch adversarial loss: 0.509213\n",
      "epoch 137; iter: 0; batch classifier loss: 0.380063; batch adversarial loss: 0.570148\n",
      "epoch 138; iter: 0; batch classifier loss: 0.362406; batch adversarial loss: 0.533908\n",
      "epoch 139; iter: 0; batch classifier loss: 0.392319; batch adversarial loss: 0.552719\n",
      "epoch 140; iter: 0; batch classifier loss: 0.383158; batch adversarial loss: 0.491573\n",
      "epoch 141; iter: 0; batch classifier loss: 0.389668; batch adversarial loss: 0.508826\n",
      "epoch 142; iter: 0; batch classifier loss: 0.333393; batch adversarial loss: 0.535385\n",
      "epoch 143; iter: 0; batch classifier loss: 0.382970; batch adversarial loss: 0.509146\n",
      "epoch 144; iter: 0; batch classifier loss: 0.365462; batch adversarial loss: 0.631908\n",
      "epoch 145; iter: 0; batch classifier loss: 0.379428; batch adversarial loss: 0.527148\n",
      "epoch 146; iter: 0; batch classifier loss: 0.336400; batch adversarial loss: 0.555600\n",
      "epoch 147; iter: 0; batch classifier loss: 0.318306; batch adversarial loss: 0.659057\n",
      "epoch 148; iter: 0; batch classifier loss: 0.330788; batch adversarial loss: 0.545495\n",
      "epoch 149; iter: 0; batch classifier loss: 0.410346; batch adversarial loss: 0.527206\n",
      "epoch 150; iter: 0; batch classifier loss: 0.404416; batch adversarial loss: 0.598549\n",
      "epoch 151; iter: 0; batch classifier loss: 0.297699; batch adversarial loss: 0.597754\n",
      "epoch 152; iter: 0; batch classifier loss: 0.364174; batch adversarial loss: 0.553763\n",
      "epoch 153; iter: 0; batch classifier loss: 0.398033; batch adversarial loss: 0.472964\n",
      "epoch 154; iter: 0; batch classifier loss: 0.359994; batch adversarial loss: 0.562608\n",
      "epoch 155; iter: 0; batch classifier loss: 0.412817; batch adversarial loss: 0.500589\n",
      "epoch 156; iter: 0; batch classifier loss: 0.364269; batch adversarial loss: 0.544747\n",
      "epoch 157; iter: 0; batch classifier loss: 0.344554; batch adversarial loss: 0.561251\n",
      "epoch 158; iter: 0; batch classifier loss: 0.490993; batch adversarial loss: 0.563228\n",
      "epoch 159; iter: 0; batch classifier loss: 0.388910; batch adversarial loss: 0.527184\n",
      "epoch 160; iter: 0; batch classifier loss: 0.334245; batch adversarial loss: 0.624870\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 161; iter: 0; batch classifier loss: 0.434358; batch adversarial loss: 0.659597\n",
      "epoch 162; iter: 0; batch classifier loss: 0.355261; batch adversarial loss: 0.606582\n",
      "epoch 163; iter: 0; batch classifier loss: 0.356269; batch adversarial loss: 0.524801\n",
      "epoch 164; iter: 0; batch classifier loss: 0.387119; batch adversarial loss: 0.615920\n",
      "epoch 165; iter: 0; batch classifier loss: 0.344051; batch adversarial loss: 0.608405\n",
      "epoch 166; iter: 0; batch classifier loss: 0.324685; batch adversarial loss: 0.472478\n",
      "epoch 167; iter: 0; batch classifier loss: 0.346754; batch adversarial loss: 0.546431\n",
      "epoch 168; iter: 0; batch classifier loss: 0.345209; batch adversarial loss: 0.607649\n",
      "epoch 169; iter: 0; batch classifier loss: 0.360600; batch adversarial loss: 0.571338\n",
      "epoch 170; iter: 0; batch classifier loss: 0.478576; batch adversarial loss: 0.509257\n",
      "epoch 171; iter: 0; batch classifier loss: 0.340975; batch adversarial loss: 0.596840\n",
      "epoch 172; iter: 0; batch classifier loss: 0.374147; batch adversarial loss: 0.588322\n",
      "epoch 173; iter: 0; batch classifier loss: 0.364923; batch adversarial loss: 0.571935\n",
      "epoch 174; iter: 0; batch classifier loss: 0.345071; batch adversarial loss: 0.501552\n",
      "epoch 175; iter: 0; batch classifier loss: 0.412628; batch adversarial loss: 0.579201\n",
      "epoch 176; iter: 0; batch classifier loss: 0.410815; batch adversarial loss: 0.509063\n",
      "epoch 177; iter: 0; batch classifier loss: 0.307306; batch adversarial loss: 0.570904\n",
      "epoch 178; iter: 0; batch classifier loss: 0.383915; batch adversarial loss: 0.579777\n",
      "epoch 179; iter: 0; batch classifier loss: 0.418882; batch adversarial loss: 0.588914\n",
      "epoch 180; iter: 0; batch classifier loss: 0.374921; batch adversarial loss: 0.545541\n",
      "epoch 181; iter: 0; batch classifier loss: 0.401377; batch adversarial loss: 0.561398\n",
      "epoch 182; iter: 0; batch classifier loss: 0.381073; batch adversarial loss: 0.546134\n",
      "epoch 183; iter: 0; batch classifier loss: 0.391465; batch adversarial loss: 0.517209\n",
      "epoch 184; iter: 0; batch classifier loss: 0.259771; batch adversarial loss: 0.536117\n",
      "epoch 185; iter: 0; batch classifier loss: 0.322612; batch adversarial loss: 0.508684\n",
      "epoch 186; iter: 0; batch classifier loss: 0.407368; batch adversarial loss: 0.519908\n",
      "epoch 187; iter: 0; batch classifier loss: 0.392785; batch adversarial loss: 0.518220\n",
      "epoch 188; iter: 0; batch classifier loss: 0.373456; batch adversarial loss: 0.500645\n",
      "epoch 189; iter: 0; batch classifier loss: 0.327532; batch adversarial loss: 0.545600\n",
      "epoch 190; iter: 0; batch classifier loss: 0.296258; batch adversarial loss: 0.544429\n",
      "epoch 191; iter: 0; batch classifier loss: 0.324586; batch adversarial loss: 0.536125\n",
      "epoch 192; iter: 0; batch classifier loss: 0.369739; batch adversarial loss: 0.597182\n",
      "epoch 193; iter: 0; batch classifier loss: 0.309641; batch adversarial loss: 0.632894\n",
      "epoch 194; iter: 0; batch classifier loss: 0.353956; batch adversarial loss: 0.536156\n",
      "epoch 195; iter: 0; batch classifier loss: 0.360966; batch adversarial loss: 0.552150\n",
      "epoch 196; iter: 0; batch classifier loss: 0.355409; batch adversarial loss: 0.554020\n",
      "epoch 197; iter: 0; batch classifier loss: 0.400090; batch adversarial loss: 0.511120\n",
      "epoch 198; iter: 0; batch classifier loss: 0.386441; batch adversarial loss: 0.518653\n",
      "epoch 199; iter: 0; batch classifier loss: 0.270753; batch adversarial loss: 0.580983\n",
      "epoch 0; iter: 0; batch classifier loss: 0.702956; batch adversarial loss: 0.580237\n",
      "epoch 1; iter: 0; batch classifier loss: 0.593925; batch adversarial loss: 0.643287\n",
      "epoch 2; iter: 0; batch classifier loss: 0.561813; batch adversarial loss: 0.586614\n",
      "epoch 3; iter: 0; batch classifier loss: 0.615358; batch adversarial loss: 0.665199\n",
      "epoch 4; iter: 0; batch classifier loss: 0.579199; batch adversarial loss: 0.656011\n",
      "epoch 5; iter: 0; batch classifier loss: 0.576887; batch adversarial loss: 0.642530\n",
      "epoch 6; iter: 0; batch classifier loss: 0.626789; batch adversarial loss: 0.615409\n",
      "epoch 7; iter: 0; batch classifier loss: 0.616995; batch adversarial loss: 0.609123\n",
      "epoch 8; iter: 0; batch classifier loss: 0.538971; batch adversarial loss: 0.634153\n",
      "epoch 9; iter: 0; batch classifier loss: 0.531202; batch adversarial loss: 0.561384\n",
      "epoch 10; iter: 0; batch classifier loss: 0.550081; batch adversarial loss: 0.626095\n",
      "epoch 11; iter: 0; batch classifier loss: 0.559085; batch adversarial loss: 0.632455\n",
      "epoch 12; iter: 0; batch classifier loss: 0.530330; batch adversarial loss: 0.557744\n",
      "epoch 13; iter: 0; batch classifier loss: 0.568110; batch adversarial loss: 0.554062\n",
      "epoch 14; iter: 0; batch classifier loss: 0.528558; batch adversarial loss: 0.591193\n",
      "epoch 15; iter: 0; batch classifier loss: 0.574751; batch adversarial loss: 0.519881\n",
      "epoch 16; iter: 0; batch classifier loss: 0.496474; batch adversarial loss: 0.475958\n",
      "epoch 17; iter: 0; batch classifier loss: 0.473747; batch adversarial loss: 0.518961\n",
      "epoch 18; iter: 0; batch classifier loss: 0.515257; batch adversarial loss: 0.600333\n",
      "epoch 19; iter: 0; batch classifier loss: 0.436057; batch adversarial loss: 0.529320\n",
      "epoch 20; iter: 0; batch classifier loss: 0.518949; batch adversarial loss: 0.527191\n",
      "epoch 21; iter: 0; batch classifier loss: 0.439715; batch adversarial loss: 0.518273\n",
      "epoch 22; iter: 0; batch classifier loss: 0.501994; batch adversarial loss: 0.637820\n",
      "epoch 23; iter: 0; batch classifier loss: 0.505499; batch adversarial loss: 0.513911\n",
      "epoch 24; iter: 0; batch classifier loss: 0.496608; batch adversarial loss: 0.588827\n",
      "epoch 25; iter: 0; batch classifier loss: 0.397391; batch adversarial loss: 0.555143\n",
      "epoch 26; iter: 0; batch classifier loss: 0.523918; batch adversarial loss: 0.580208\n",
      "epoch 27; iter: 0; batch classifier loss: 0.491231; batch adversarial loss: 0.544881\n",
      "epoch 28; iter: 0; batch classifier loss: 0.434260; batch adversarial loss: 0.625302\n",
      "epoch 29; iter: 0; batch classifier loss: 0.494497; batch adversarial loss: 0.527742\n",
      "epoch 30; iter: 0; batch classifier loss: 0.417358; batch adversarial loss: 0.562717\n",
      "epoch 31; iter: 0; batch classifier loss: 0.458272; batch adversarial loss: 0.536798\n",
      "epoch 32; iter: 0; batch classifier loss: 0.491700; batch adversarial loss: 0.579629\n",
      "epoch 33; iter: 0; batch classifier loss: 0.484430; batch adversarial loss: 0.604977\n",
      "epoch 34; iter: 0; batch classifier loss: 0.502541; batch adversarial loss: 0.569991\n",
      "epoch 35; iter: 0; batch classifier loss: 0.419294; batch adversarial loss: 0.543786\n",
      "epoch 36; iter: 0; batch classifier loss: 0.466480; batch adversarial loss: 0.603318\n",
      "epoch 37; iter: 0; batch classifier loss: 0.499298; batch adversarial loss: 0.585749\n",
      "epoch 38; iter: 0; batch classifier loss: 0.409321; batch adversarial loss: 0.539226\n",
      "epoch 39; iter: 0; batch classifier loss: 0.409111; batch adversarial loss: 0.574378\n",
      "epoch 40; iter: 0; batch classifier loss: 0.481365; batch adversarial loss: 0.581743\n",
      "epoch 41; iter: 0; batch classifier loss: 0.415923; batch adversarial loss: 0.601007\n",
      "epoch 42; iter: 0; batch classifier loss: 0.472034; batch adversarial loss: 0.526361\n",
      "epoch 43; iter: 0; batch classifier loss: 0.481537; batch adversarial loss: 0.619189\n",
      "epoch 44; iter: 0; batch classifier loss: 0.403196; batch adversarial loss: 0.498386\n",
      "epoch 45; iter: 0; batch classifier loss: 0.362416; batch adversarial loss: 0.609124\n",
      "epoch 46; iter: 0; batch classifier loss: 0.454088; batch adversarial loss: 0.525764\n",
      "epoch 47; iter: 0; batch classifier loss: 0.480738; batch adversarial loss: 0.570316\n",
      "epoch 48; iter: 0; batch classifier loss: 0.447674; batch adversarial loss: 0.534097\n",
      "epoch 49; iter: 0; batch classifier loss: 0.430401; batch adversarial loss: 0.580052\n",
      "epoch 50; iter: 0; batch classifier loss: 0.361937; batch adversarial loss: 0.525010\n",
      "epoch 51; iter: 0; batch classifier loss: 0.416651; batch adversarial loss: 0.477486\n",
      "epoch 52; iter: 0; batch classifier loss: 0.431630; batch adversarial loss: 0.570628\n",
      "epoch 53; iter: 0; batch classifier loss: 0.411736; batch adversarial loss: 0.504185\n",
      "epoch 54; iter: 0; batch classifier loss: 0.385406; batch adversarial loss: 0.596107\n",
      "epoch 55; iter: 0; batch classifier loss: 0.444654; batch adversarial loss: 0.607247\n",
      "epoch 56; iter: 0; batch classifier loss: 0.420478; batch adversarial loss: 0.606137\n",
      "epoch 57; iter: 0; batch classifier loss: 0.496946; batch adversarial loss: 0.556107\n",
      "epoch 58; iter: 0; batch classifier loss: 0.419710; batch adversarial loss: 0.538119\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 59; iter: 0; batch classifier loss: 0.484813; batch adversarial loss: 0.526868\n",
      "epoch 60; iter: 0; batch classifier loss: 0.384196; batch adversarial loss: 0.507499\n",
      "epoch 61; iter: 0; batch classifier loss: 0.369342; batch adversarial loss: 0.563307\n",
      "epoch 62; iter: 0; batch classifier loss: 0.410705; batch adversarial loss: 0.526469\n",
      "epoch 63; iter: 0; batch classifier loss: 0.434619; batch adversarial loss: 0.572947\n",
      "epoch 64; iter: 0; batch classifier loss: 0.393443; batch adversarial loss: 0.553414\n",
      "epoch 65; iter: 0; batch classifier loss: 0.398450; batch adversarial loss: 0.554040\n",
      "epoch 66; iter: 0; batch classifier loss: 0.486469; batch adversarial loss: 0.637295\n",
      "epoch 67; iter: 0; batch classifier loss: 0.520750; batch adversarial loss: 0.561161\n",
      "epoch 68; iter: 0; batch classifier loss: 0.399207; batch adversarial loss: 0.581518\n",
      "epoch 69; iter: 0; batch classifier loss: 0.419459; batch adversarial loss: 0.581131\n",
      "epoch 70; iter: 0; batch classifier loss: 0.386530; batch adversarial loss: 0.599402\n",
      "epoch 71; iter: 0; batch classifier loss: 0.388658; batch adversarial loss: 0.517400\n",
      "epoch 72; iter: 0; batch classifier loss: 0.416786; batch adversarial loss: 0.534013\n",
      "epoch 73; iter: 0; batch classifier loss: 0.318597; batch adversarial loss: 0.526485\n",
      "epoch 74; iter: 0; batch classifier loss: 0.349740; batch adversarial loss: 0.545672\n",
      "epoch 75; iter: 0; batch classifier loss: 0.393812; batch adversarial loss: 0.518698\n",
      "epoch 76; iter: 0; batch classifier loss: 0.337771; batch adversarial loss: 0.611791\n",
      "epoch 77; iter: 0; batch classifier loss: 0.411994; batch adversarial loss: 0.527015\n",
      "epoch 78; iter: 0; batch classifier loss: 0.480053; batch adversarial loss: 0.516765\n",
      "epoch 79; iter: 0; batch classifier loss: 0.440986; batch adversarial loss: 0.591887\n",
      "epoch 80; iter: 0; batch classifier loss: 0.312017; batch adversarial loss: 0.544710\n",
      "epoch 81; iter: 0; batch classifier loss: 0.466169; batch adversarial loss: 0.534168\n",
      "epoch 82; iter: 0; batch classifier loss: 0.424384; batch adversarial loss: 0.552559\n",
      "epoch 83; iter: 0; batch classifier loss: 0.362141; batch adversarial loss: 0.582247\n",
      "epoch 84; iter: 0; batch classifier loss: 0.398692; batch adversarial loss: 0.461441\n",
      "epoch 85; iter: 0; batch classifier loss: 0.495248; batch adversarial loss: 0.562541\n",
      "epoch 86; iter: 0; batch classifier loss: 0.388716; batch adversarial loss: 0.674292\n",
      "epoch 87; iter: 0; batch classifier loss: 0.478910; batch adversarial loss: 0.462664\n",
      "epoch 88; iter: 0; batch classifier loss: 0.441119; batch adversarial loss: 0.552628\n",
      "epoch 89; iter: 0; batch classifier loss: 0.401072; batch adversarial loss: 0.543424\n",
      "epoch 90; iter: 0; batch classifier loss: 0.428300; batch adversarial loss: 0.488745\n",
      "epoch 91; iter: 0; batch classifier loss: 0.345166; batch adversarial loss: 0.488338\n",
      "epoch 92; iter: 0; batch classifier loss: 0.376722; batch adversarial loss: 0.553853\n",
      "epoch 93; iter: 0; batch classifier loss: 0.354564; batch adversarial loss: 0.497929\n",
      "epoch 94; iter: 0; batch classifier loss: 0.379079; batch adversarial loss: 0.571959\n",
      "epoch 95; iter: 0; batch classifier loss: 0.404262; batch adversarial loss: 0.564764\n",
      "epoch 96; iter: 0; batch classifier loss: 0.400140; batch adversarial loss: 0.552770\n",
      "epoch 97; iter: 0; batch classifier loss: 0.410031; batch adversarial loss: 0.562109\n",
      "epoch 98; iter: 0; batch classifier loss: 0.473683; batch adversarial loss: 0.469885\n",
      "epoch 99; iter: 0; batch classifier loss: 0.392053; batch adversarial loss: 0.553503\n",
      "epoch 100; iter: 0; batch classifier loss: 0.463384; batch adversarial loss: 0.526110\n",
      "epoch 101; iter: 0; batch classifier loss: 0.358927; batch adversarial loss: 0.609240\n",
      "epoch 102; iter: 0; batch classifier loss: 0.345078; batch adversarial loss: 0.488468\n",
      "epoch 103; iter: 0; batch classifier loss: 0.379144; batch adversarial loss: 0.542441\n",
      "epoch 104; iter: 0; batch classifier loss: 0.407094; batch adversarial loss: 0.525388\n",
      "epoch 105; iter: 0; batch classifier loss: 0.332995; batch adversarial loss: 0.582082\n",
      "epoch 106; iter: 0; batch classifier loss: 0.381454; batch adversarial loss: 0.618111\n",
      "epoch 107; iter: 0; batch classifier loss: 0.473143; batch adversarial loss: 0.553647\n",
      "epoch 108; iter: 0; batch classifier loss: 0.437831; batch adversarial loss: 0.526041\n",
      "epoch 109; iter: 0; batch classifier loss: 0.437868; batch adversarial loss: 0.442507\n",
      "epoch 110; iter: 0; batch classifier loss: 0.319160; batch adversarial loss: 0.507089\n",
      "epoch 111; iter: 0; batch classifier loss: 0.407712; batch adversarial loss: 0.591465\n",
      "epoch 112; iter: 0; batch classifier loss: 0.455023; batch adversarial loss: 0.544445\n",
      "epoch 113; iter: 0; batch classifier loss: 0.351156; batch adversarial loss: 0.552961\n",
      "epoch 114; iter: 0; batch classifier loss: 0.421483; batch adversarial loss: 0.581347\n",
      "epoch 115; iter: 0; batch classifier loss: 0.403953; batch adversarial loss: 0.619207\n",
      "epoch 116; iter: 0; batch classifier loss: 0.437898; batch adversarial loss: 0.516468\n",
      "epoch 117; iter: 0; batch classifier loss: 0.444949; batch adversarial loss: 0.498440\n",
      "epoch 118; iter: 0; batch classifier loss: 0.361516; batch adversarial loss: 0.460696\n",
      "epoch 119; iter: 0; batch classifier loss: 0.419941; batch adversarial loss: 0.563283\n",
      "epoch 120; iter: 0; batch classifier loss: 0.337086; batch adversarial loss: 0.553674\n",
      "epoch 121; iter: 0; batch classifier loss: 0.379235; batch adversarial loss: 0.479047\n",
      "epoch 122; iter: 0; batch classifier loss: 0.459423; batch adversarial loss: 0.525620\n",
      "epoch 123; iter: 0; batch classifier loss: 0.422450; batch adversarial loss: 0.553129\n",
      "epoch 124; iter: 0; batch classifier loss: 0.370240; batch adversarial loss: 0.534940\n",
      "epoch 125; iter: 0; batch classifier loss: 0.346052; batch adversarial loss: 0.582027\n",
      "epoch 126; iter: 0; batch classifier loss: 0.287094; batch adversarial loss: 0.452378\n",
      "epoch 127; iter: 0; batch classifier loss: 0.389182; batch adversarial loss: 0.479357\n",
      "epoch 128; iter: 0; batch classifier loss: 0.274644; batch adversarial loss: 0.563379\n",
      "epoch 129; iter: 0; batch classifier loss: 0.352262; batch adversarial loss: 0.543931\n",
      "epoch 130; iter: 0; batch classifier loss: 0.454099; batch adversarial loss: 0.443309\n",
      "epoch 131; iter: 0; batch classifier loss: 0.392099; batch adversarial loss: 0.535040\n",
      "epoch 132; iter: 0; batch classifier loss: 0.321229; batch adversarial loss: 0.526450\n",
      "epoch 133; iter: 0; batch classifier loss: 0.391323; batch adversarial loss: 0.517124\n",
      "epoch 134; iter: 0; batch classifier loss: 0.366363; batch adversarial loss: 0.591115\n",
      "epoch 135; iter: 0; batch classifier loss: 0.454621; batch adversarial loss: 0.581300\n",
      "epoch 136; iter: 0; batch classifier loss: 0.315268; batch adversarial loss: 0.542602\n",
      "epoch 137; iter: 0; batch classifier loss: 0.390892; batch adversarial loss: 0.443477\n",
      "epoch 138; iter: 0; batch classifier loss: 0.378302; batch adversarial loss: 0.573125\n",
      "epoch 139; iter: 0; batch classifier loss: 0.409950; batch adversarial loss: 0.498716\n",
      "epoch 140; iter: 0; batch classifier loss: 0.345902; batch adversarial loss: 0.469377\n",
      "epoch 141; iter: 0; batch classifier loss: 0.326095; batch adversarial loss: 0.516187\n",
      "epoch 142; iter: 0; batch classifier loss: 0.383649; batch adversarial loss: 0.655114\n",
      "epoch 143; iter: 0; batch classifier loss: 0.449616; batch adversarial loss: 0.675754\n",
      "epoch 144; iter: 0; batch classifier loss: 0.352292; batch adversarial loss: 0.572259\n",
      "epoch 145; iter: 0; batch classifier loss: 0.383993; batch adversarial loss: 0.434158\n",
      "epoch 146; iter: 0; batch classifier loss: 0.438443; batch adversarial loss: 0.600586\n",
      "epoch 147; iter: 0; batch classifier loss: 0.354309; batch adversarial loss: 0.553740\n",
      "epoch 148; iter: 0; batch classifier loss: 0.298724; batch adversarial loss: 0.535014\n",
      "epoch 149; iter: 0; batch classifier loss: 0.428767; batch adversarial loss: 0.489447\n",
      "epoch 150; iter: 0; batch classifier loss: 0.318177; batch adversarial loss: 0.553248\n",
      "epoch 151; iter: 0; batch classifier loss: 0.419635; batch adversarial loss: 0.581195\n",
      "epoch 152; iter: 0; batch classifier loss: 0.369947; batch adversarial loss: 0.516789\n",
      "epoch 153; iter: 0; batch classifier loss: 0.429854; batch adversarial loss: 0.516763\n",
      "epoch 154; iter: 0; batch classifier loss: 0.361169; batch adversarial loss: 0.525925\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 155; iter: 0; batch classifier loss: 0.343645; batch adversarial loss: 0.525619\n",
      "epoch 156; iter: 0; batch classifier loss: 0.368770; batch adversarial loss: 0.563286\n",
      "epoch 157; iter: 0; batch classifier loss: 0.422028; batch adversarial loss: 0.628341\n",
      "epoch 158; iter: 0; batch classifier loss: 0.318553; batch adversarial loss: 0.535059\n",
      "epoch 159; iter: 0; batch classifier loss: 0.423264; batch adversarial loss: 0.517142\n",
      "epoch 160; iter: 0; batch classifier loss: 0.377811; batch adversarial loss: 0.525778\n",
      "epoch 161; iter: 0; batch classifier loss: 0.455154; batch adversarial loss: 0.525737\n",
      "epoch 162; iter: 0; batch classifier loss: 0.374463; batch adversarial loss: 0.572435\n",
      "epoch 163; iter: 0; batch classifier loss: 0.408562; batch adversarial loss: 0.516372\n",
      "epoch 164; iter: 0; batch classifier loss: 0.433413; batch adversarial loss: 0.526144\n",
      "epoch 165; iter: 0; batch classifier loss: 0.326755; batch adversarial loss: 0.609195\n",
      "epoch 166; iter: 0; batch classifier loss: 0.422160; batch adversarial loss: 0.545065\n",
      "epoch 167; iter: 0; batch classifier loss: 0.370480; batch adversarial loss: 0.516652\n",
      "epoch 168; iter: 0; batch classifier loss: 0.376702; batch adversarial loss: 0.599736\n",
      "epoch 169; iter: 0; batch classifier loss: 0.318123; batch adversarial loss: 0.571740\n",
      "epoch 170; iter: 0; batch classifier loss: 0.419745; batch adversarial loss: 0.461319\n",
      "epoch 171; iter: 0; batch classifier loss: 0.328210; batch adversarial loss: 0.553780\n",
      "epoch 172; iter: 0; batch classifier loss: 0.385874; batch adversarial loss: 0.516496\n",
      "epoch 173; iter: 0; batch classifier loss: 0.439449; batch adversarial loss: 0.516940\n",
      "epoch 174; iter: 0; batch classifier loss: 0.463009; batch adversarial loss: 0.544826\n",
      "epoch 175; iter: 0; batch classifier loss: 0.456112; batch adversarial loss: 0.507242\n",
      "epoch 176; iter: 0; batch classifier loss: 0.314355; batch adversarial loss: 0.571295\n",
      "epoch 177; iter: 0; batch classifier loss: 0.312130; batch adversarial loss: 0.544682\n",
      "epoch 178; iter: 0; batch classifier loss: 0.307237; batch adversarial loss: 0.553910\n",
      "epoch 179; iter: 0; batch classifier loss: 0.306818; batch adversarial loss: 0.535151\n",
      "epoch 180; iter: 0; batch classifier loss: 0.331002; batch adversarial loss: 0.507384\n",
      "epoch 181; iter: 0; batch classifier loss: 0.418514; batch adversarial loss: 0.554319\n",
      "epoch 182; iter: 0; batch classifier loss: 0.431351; batch adversarial loss: 0.608931\n",
      "epoch 183; iter: 0; batch classifier loss: 0.333939; batch adversarial loss: 0.562993\n",
      "epoch 184; iter: 0; batch classifier loss: 0.328312; batch adversarial loss: 0.563187\n",
      "epoch 185; iter: 0; batch classifier loss: 0.367778; batch adversarial loss: 0.589625\n",
      "epoch 186; iter: 0; batch classifier loss: 0.340076; batch adversarial loss: 0.470334\n",
      "epoch 187; iter: 0; batch classifier loss: 0.294551; batch adversarial loss: 0.525783\n",
      "epoch 188; iter: 0; batch classifier loss: 0.337527; batch adversarial loss: 0.563001\n",
      "epoch 189; iter: 0; batch classifier loss: 0.482301; batch adversarial loss: 0.535098\n",
      "epoch 190; iter: 0; batch classifier loss: 0.339769; batch adversarial loss: 0.545178\n",
      "epoch 191; iter: 0; batch classifier loss: 0.358981; batch adversarial loss: 0.582447\n",
      "epoch 192; iter: 0; batch classifier loss: 0.373744; batch adversarial loss: 0.591298\n",
      "epoch 193; iter: 0; batch classifier loss: 0.351982; batch adversarial loss: 0.581946\n",
      "epoch 194; iter: 0; batch classifier loss: 0.443332; batch adversarial loss: 0.506886\n",
      "epoch 195; iter: 0; batch classifier loss: 0.404161; batch adversarial loss: 0.507831\n",
      "epoch 196; iter: 0; batch classifier loss: 0.347033; batch adversarial loss: 0.489423\n",
      "epoch 197; iter: 0; batch classifier loss: 0.327308; batch adversarial loss: 0.534679\n",
      "epoch 198; iter: 0; batch classifier loss: 0.368308; batch adversarial loss: 0.489393\n",
      "epoch 199; iter: 0; batch classifier loss: 0.407647; batch adversarial loss: 0.534577\n",
      "epoch 0; iter: 0; batch classifier loss: 0.689463; batch adversarial loss: 0.714488\n",
      "epoch 1; iter: 0; batch classifier loss: 0.553191; batch adversarial loss: 0.676707\n",
      "epoch 2; iter: 0; batch classifier loss: 0.625920; batch adversarial loss: 0.658637\n",
      "epoch 3; iter: 0; batch classifier loss: 0.521827; batch adversarial loss: 0.635961\n",
      "epoch 4; iter: 0; batch classifier loss: 0.518099; batch adversarial loss: 0.614838\n",
      "epoch 5; iter: 0; batch classifier loss: 0.538817; batch adversarial loss: 0.618422\n",
      "epoch 6; iter: 0; batch classifier loss: 0.555146; batch adversarial loss: 0.583060\n",
      "epoch 7; iter: 0; batch classifier loss: 0.617174; batch adversarial loss: 0.617601\n",
      "epoch 8; iter: 0; batch classifier loss: 0.531654; batch adversarial loss: 0.595367\n",
      "epoch 9; iter: 0; batch classifier loss: 0.552152; batch adversarial loss: 0.636650\n",
      "epoch 10; iter: 0; batch classifier loss: 0.559257; batch adversarial loss: 0.543200\n",
      "epoch 11; iter: 0; batch classifier loss: 0.546834; batch adversarial loss: 0.567046\n",
      "epoch 12; iter: 0; batch classifier loss: 0.613743; batch adversarial loss: 0.599512\n",
      "epoch 13; iter: 0; batch classifier loss: 0.488672; batch adversarial loss: 0.562890\n",
      "epoch 14; iter: 0; batch classifier loss: 0.559503; batch adversarial loss: 0.577336\n",
      "epoch 15; iter: 0; batch classifier loss: 0.541259; batch adversarial loss: 0.540193\n",
      "epoch 16; iter: 0; batch classifier loss: 0.573851; batch adversarial loss: 0.633155\n",
      "epoch 17; iter: 0; batch classifier loss: 0.535834; batch adversarial loss: 0.571012\n",
      "epoch 18; iter: 0; batch classifier loss: 0.526395; batch adversarial loss: 0.598110\n",
      "epoch 19; iter: 0; batch classifier loss: 0.473669; batch adversarial loss: 0.574701\n",
      "epoch 20; iter: 0; batch classifier loss: 0.515297; batch adversarial loss: 0.560260\n",
      "epoch 21; iter: 0; batch classifier loss: 0.498634; batch adversarial loss: 0.570194\n",
      "epoch 22; iter: 0; batch classifier loss: 0.519064; batch adversarial loss: 0.523375\n",
      "epoch 23; iter: 0; batch classifier loss: 0.436389; batch adversarial loss: 0.521445\n",
      "epoch 24; iter: 0; batch classifier loss: 0.466478; batch adversarial loss: 0.593507\n",
      "epoch 25; iter: 0; batch classifier loss: 0.455005; batch adversarial loss: 0.584785\n",
      "epoch 26; iter: 0; batch classifier loss: 0.483611; batch adversarial loss: 0.556088\n",
      "epoch 27; iter: 0; batch classifier loss: 0.510897; batch adversarial loss: 0.586764\n",
      "epoch 28; iter: 0; batch classifier loss: 0.517025; batch adversarial loss: 0.554776\n",
      "epoch 29; iter: 0; batch classifier loss: 0.482064; batch adversarial loss: 0.564726\n",
      "epoch 30; iter: 0; batch classifier loss: 0.479493; batch adversarial loss: 0.569390\n",
      "epoch 31; iter: 0; batch classifier loss: 0.412720; batch adversarial loss: 0.547435\n",
      "epoch 32; iter: 0; batch classifier loss: 0.510558; batch adversarial loss: 0.500818\n",
      "epoch 33; iter: 0; batch classifier loss: 0.381208; batch adversarial loss: 0.539250\n",
      "epoch 34; iter: 0; batch classifier loss: 0.476809; batch adversarial loss: 0.483901\n",
      "epoch 35; iter: 0; batch classifier loss: 0.476443; batch adversarial loss: 0.562694\n",
      "epoch 36; iter: 0; batch classifier loss: 0.436880; batch adversarial loss: 0.553049\n",
      "epoch 37; iter: 0; batch classifier loss: 0.484374; batch adversarial loss: 0.553675\n",
      "epoch 38; iter: 0; batch classifier loss: 0.505534; batch adversarial loss: 0.545065\n",
      "epoch 39; iter: 0; batch classifier loss: 0.517146; batch adversarial loss: 0.562153\n",
      "epoch 40; iter: 0; batch classifier loss: 0.427627; batch adversarial loss: 0.589252\n",
      "epoch 41; iter: 0; batch classifier loss: 0.421787; batch adversarial loss: 0.562065\n",
      "epoch 42; iter: 0; batch classifier loss: 0.471824; batch adversarial loss: 0.580349\n",
      "epoch 43; iter: 0; batch classifier loss: 0.395059; batch adversarial loss: 0.644108\n",
      "epoch 44; iter: 0; batch classifier loss: 0.358615; batch adversarial loss: 0.462909\n",
      "epoch 45; iter: 0; batch classifier loss: 0.437753; batch adversarial loss: 0.499174\n",
      "epoch 46; iter: 0; batch classifier loss: 0.426400; batch adversarial loss: 0.517448\n",
      "epoch 47; iter: 0; batch classifier loss: 0.389697; batch adversarial loss: 0.562434\n",
      "epoch 48; iter: 0; batch classifier loss: 0.406071; batch adversarial loss: 0.571669\n",
      "epoch 49; iter: 0; batch classifier loss: 0.395548; batch adversarial loss: 0.553556\n",
      "epoch 50; iter: 0; batch classifier loss: 0.402403; batch adversarial loss: 0.535078\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 51; iter: 0; batch classifier loss: 0.465952; batch adversarial loss: 0.481960\n",
      "epoch 52; iter: 0; batch classifier loss: 0.389327; batch adversarial loss: 0.604861\n",
      "epoch 53; iter: 0; batch classifier loss: 0.493595; batch adversarial loss: 0.611775\n",
      "epoch 54; iter: 0; batch classifier loss: 0.388033; batch adversarial loss: 0.528078\n",
      "epoch 55; iter: 0; batch classifier loss: 0.500706; batch adversarial loss: 0.517024\n",
      "epoch 56; iter: 0; batch classifier loss: 0.415330; batch adversarial loss: 0.542964\n",
      "epoch 57; iter: 0; batch classifier loss: 0.441707; batch adversarial loss: 0.471678\n",
      "epoch 58; iter: 0; batch classifier loss: 0.431701; batch adversarial loss: 0.450052\n",
      "epoch 59; iter: 0; batch classifier loss: 0.478435; batch adversarial loss: 0.553694\n",
      "epoch 60; iter: 0; batch classifier loss: 0.441724; batch adversarial loss: 0.547195\n",
      "epoch 61; iter: 0; batch classifier loss: 0.490214; batch adversarial loss: 0.629499\n",
      "epoch 62; iter: 0; batch classifier loss: 0.366806; batch adversarial loss: 0.537751\n",
      "epoch 63; iter: 0; batch classifier loss: 0.434978; batch adversarial loss: 0.525757\n",
      "epoch 64; iter: 0; batch classifier loss: 0.454018; batch adversarial loss: 0.517359\n",
      "epoch 65; iter: 0; batch classifier loss: 0.416946; batch adversarial loss: 0.522343\n",
      "epoch 66; iter: 0; batch classifier loss: 0.439699; batch adversarial loss: 0.539940\n",
      "epoch 67; iter: 0; batch classifier loss: 0.446427; batch adversarial loss: 0.512387\n",
      "epoch 68; iter: 0; batch classifier loss: 0.403808; batch adversarial loss: 0.609000\n",
      "epoch 69; iter: 0; batch classifier loss: 0.354123; batch adversarial loss: 0.571050\n",
      "epoch 70; iter: 0; batch classifier loss: 0.356456; batch adversarial loss: 0.434700\n",
      "epoch 71; iter: 0; batch classifier loss: 0.469861; batch adversarial loss: 0.547858\n",
      "epoch 72; iter: 0; batch classifier loss: 0.423511; batch adversarial loss: 0.543522\n",
      "epoch 73; iter: 0; batch classifier loss: 0.332278; batch adversarial loss: 0.516230\n",
      "epoch 74; iter: 0; batch classifier loss: 0.320752; batch adversarial loss: 0.544715\n",
      "epoch 75; iter: 0; batch classifier loss: 0.402030; batch adversarial loss: 0.574900\n",
      "epoch 76; iter: 0; batch classifier loss: 0.373556; batch adversarial loss: 0.555312\n",
      "epoch 77; iter: 0; batch classifier loss: 0.345295; batch adversarial loss: 0.573575\n",
      "epoch 78; iter: 0; batch classifier loss: 0.329552; batch adversarial loss: 0.546128\n",
      "epoch 79; iter: 0; batch classifier loss: 0.391248; batch adversarial loss: 0.610437\n",
      "epoch 80; iter: 0; batch classifier loss: 0.416214; batch adversarial loss: 0.488922\n",
      "epoch 81; iter: 0; batch classifier loss: 0.376424; batch adversarial loss: 0.516921\n",
      "epoch 82; iter: 0; batch classifier loss: 0.462317; batch adversarial loss: 0.609113\n",
      "epoch 83; iter: 0; batch classifier loss: 0.341435; batch adversarial loss: 0.554166\n",
      "epoch 84; iter: 0; batch classifier loss: 0.407779; batch adversarial loss: 0.544479\n",
      "epoch 85; iter: 0; batch classifier loss: 0.365490; batch adversarial loss: 0.572434\n",
      "epoch 86; iter: 0; batch classifier loss: 0.409643; batch adversarial loss: 0.497831\n",
      "epoch 87; iter: 0; batch classifier loss: 0.452077; batch adversarial loss: 0.422248\n",
      "epoch 88; iter: 0; batch classifier loss: 0.352005; batch adversarial loss: 0.543605\n",
      "epoch 89; iter: 0; batch classifier loss: 0.320717; batch adversarial loss: 0.526844\n",
      "epoch 90; iter: 0; batch classifier loss: 0.396699; batch adversarial loss: 0.450954\n",
      "epoch 91; iter: 0; batch classifier loss: 0.422671; batch adversarial loss: 0.508518\n",
      "epoch 92; iter: 0; batch classifier loss: 0.466389; batch adversarial loss: 0.526826\n",
      "epoch 93; iter: 0; batch classifier loss: 0.387944; batch adversarial loss: 0.463012\n",
      "epoch 94; iter: 0; batch classifier loss: 0.330436; batch adversarial loss: 0.498802\n",
      "epoch 95; iter: 0; batch classifier loss: 0.356161; batch adversarial loss: 0.608019\n",
      "epoch 96; iter: 0; batch classifier loss: 0.403045; batch adversarial loss: 0.471783\n",
      "epoch 97; iter: 0; batch classifier loss: 0.371145; batch adversarial loss: 0.517854\n",
      "epoch 98; iter: 0; batch classifier loss: 0.376665; batch adversarial loss: 0.562865\n",
      "epoch 99; iter: 0; batch classifier loss: 0.404980; batch adversarial loss: 0.571886\n",
      "epoch 100; iter: 0; batch classifier loss: 0.502901; batch adversarial loss: 0.489995\n",
      "epoch 101; iter: 0; batch classifier loss: 0.277608; batch adversarial loss: 0.644436\n",
      "epoch 102; iter: 0; batch classifier loss: 0.332767; batch adversarial loss: 0.562245\n",
      "epoch 103; iter: 0; batch classifier loss: 0.430618; batch adversarial loss: 0.517385\n",
      "epoch 104; iter: 0; batch classifier loss: 0.330940; batch adversarial loss: 0.599488\n",
      "epoch 105; iter: 0; batch classifier loss: 0.430846; batch adversarial loss: 0.534878\n",
      "epoch 106; iter: 0; batch classifier loss: 0.305234; batch adversarial loss: 0.581913\n",
      "epoch 107; iter: 0; batch classifier loss: 0.337862; batch adversarial loss: 0.554169\n",
      "epoch 108; iter: 0; batch classifier loss: 0.388250; batch adversarial loss: 0.472076\n",
      "epoch 109; iter: 0; batch classifier loss: 0.438359; batch adversarial loss: 0.553662\n",
      "epoch 110; iter: 0; batch classifier loss: 0.343912; batch adversarial loss: 0.572488\n",
      "epoch 111; iter: 0; batch classifier loss: 0.412895; batch adversarial loss: 0.545352\n",
      "epoch 112; iter: 0; batch classifier loss: 0.378453; batch adversarial loss: 0.644350\n",
      "epoch 113; iter: 0; batch classifier loss: 0.425100; batch adversarial loss: 0.543818\n",
      "epoch 114; iter: 0; batch classifier loss: 0.384496; batch adversarial loss: 0.571349\n",
      "epoch 115; iter: 0; batch classifier loss: 0.365471; batch adversarial loss: 0.535581\n",
      "epoch 116; iter: 0; batch classifier loss: 0.438617; batch adversarial loss: 0.508330\n",
      "epoch 117; iter: 0; batch classifier loss: 0.351330; batch adversarial loss: 0.517285\n",
      "epoch 118; iter: 0; batch classifier loss: 0.355243; batch adversarial loss: 0.535935\n",
      "epoch 119; iter: 0; batch classifier loss: 0.330638; batch adversarial loss: 0.516862\n",
      "epoch 120; iter: 0; batch classifier loss: 0.395368; batch adversarial loss: 0.535707\n",
      "epoch 121; iter: 0; batch classifier loss: 0.394593; batch adversarial loss: 0.536515\n",
      "epoch 122; iter: 0; batch classifier loss: 0.347143; batch adversarial loss: 0.580323\n",
      "epoch 123; iter: 0; batch classifier loss: 0.409294; batch adversarial loss: 0.569717\n",
      "epoch 124; iter: 0; batch classifier loss: 0.440959; batch adversarial loss: 0.488291\n",
      "epoch 125; iter: 0; batch classifier loss: 0.505637; batch adversarial loss: 0.514101\n",
      "epoch 126; iter: 0; batch classifier loss: 0.322636; batch adversarial loss: 0.533077\n",
      "epoch 127; iter: 0; batch classifier loss: 0.414271; batch adversarial loss: 0.554179\n",
      "epoch 128; iter: 0; batch classifier loss: 0.372297; batch adversarial loss: 0.563923\n",
      "epoch 129; iter: 0; batch classifier loss: 0.298986; batch adversarial loss: 0.565409\n",
      "epoch 130; iter: 0; batch classifier loss: 0.393028; batch adversarial loss: 0.624248\n",
      "epoch 131; iter: 0; batch classifier loss: 0.294557; batch adversarial loss: 0.517409\n",
      "epoch 132; iter: 0; batch classifier loss: 0.371094; batch adversarial loss: 0.481711\n",
      "epoch 133; iter: 0; batch classifier loss: 0.316238; batch adversarial loss: 0.534979\n",
      "epoch 134; iter: 0; batch classifier loss: 0.313616; batch adversarial loss: 0.498589\n",
      "epoch 135; iter: 0; batch classifier loss: 0.435244; batch adversarial loss: 0.582724\n",
      "epoch 136; iter: 0; batch classifier loss: 0.396161; batch adversarial loss: 0.544993\n",
      "epoch 137; iter: 0; batch classifier loss: 0.437085; batch adversarial loss: 0.535099\n",
      "epoch 138; iter: 0; batch classifier loss: 0.357223; batch adversarial loss: 0.600427\n",
      "epoch 139; iter: 0; batch classifier loss: 0.312129; batch adversarial loss: 0.525554\n",
      "epoch 140; iter: 0; batch classifier loss: 0.380214; batch adversarial loss: 0.545928\n",
      "epoch 141; iter: 0; batch classifier loss: 0.379214; batch adversarial loss: 0.525603\n",
      "epoch 142; iter: 0; batch classifier loss: 0.294539; batch adversarial loss: 0.545204\n",
      "epoch 143; iter: 0; batch classifier loss: 0.377737; batch adversarial loss: 0.597959\n",
      "epoch 144; iter: 0; batch classifier loss: 0.371933; batch adversarial loss: 0.564293\n",
      "epoch 145; iter: 0; batch classifier loss: 0.407462; batch adversarial loss: 0.580923\n",
      "epoch 146; iter: 0; batch classifier loss: 0.355221; batch adversarial loss: 0.543934\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 147; iter: 0; batch classifier loss: 0.438150; batch adversarial loss: 0.627815\n",
      "epoch 148; iter: 0; batch classifier loss: 0.332503; batch adversarial loss: 0.534317\n",
      "epoch 149; iter: 0; batch classifier loss: 0.376797; batch adversarial loss: 0.552839\n",
      "epoch 150; iter: 0; batch classifier loss: 0.405528; batch adversarial loss: 0.499675\n",
      "epoch 151; iter: 0; batch classifier loss: 0.347762; batch adversarial loss: 0.472397\n",
      "epoch 152; iter: 0; batch classifier loss: 0.377064; batch adversarial loss: 0.527597\n",
      "epoch 153; iter: 0; batch classifier loss: 0.309787; batch adversarial loss: 0.537905\n",
      "epoch 154; iter: 0; batch classifier loss: 0.403977; batch adversarial loss: 0.556261\n",
      "epoch 155; iter: 0; batch classifier loss: 0.362098; batch adversarial loss: 0.533881\n",
      "epoch 156; iter: 0; batch classifier loss: 0.443554; batch adversarial loss: 0.506306\n",
      "epoch 157; iter: 0; batch classifier loss: 0.481943; batch adversarial loss: 0.507099\n",
      "epoch 158; iter: 0; batch classifier loss: 0.426866; batch adversarial loss: 0.509371\n",
      "epoch 159; iter: 0; batch classifier loss: 0.338071; batch adversarial loss: 0.469488\n",
      "epoch 160; iter: 0; batch classifier loss: 0.420211; batch adversarial loss: 0.518044\n",
      "epoch 161; iter: 0; batch classifier loss: 0.407030; batch adversarial loss: 0.526811\n",
      "epoch 162; iter: 0; batch classifier loss: 0.380004; batch adversarial loss: 0.517832\n",
      "epoch 163; iter: 0; batch classifier loss: 0.363740; batch adversarial loss: 0.498867\n",
      "epoch 164; iter: 0; batch classifier loss: 0.458466; batch adversarial loss: 0.580535\n",
      "epoch 165; iter: 0; batch classifier loss: 0.375219; batch adversarial loss: 0.509386\n",
      "epoch 166; iter: 0; batch classifier loss: 0.302528; batch adversarial loss: 0.571896\n",
      "epoch 167; iter: 0; batch classifier loss: 0.356151; batch adversarial loss: 0.507644\n",
      "epoch 168; iter: 0; batch classifier loss: 0.301480; batch adversarial loss: 0.499470\n",
      "epoch 169; iter: 0; batch classifier loss: 0.328613; batch adversarial loss: 0.544044\n",
      "epoch 170; iter: 0; batch classifier loss: 0.349291; batch adversarial loss: 0.525816\n",
      "epoch 171; iter: 0; batch classifier loss: 0.333276; batch adversarial loss: 0.536724\n",
      "epoch 172; iter: 0; batch classifier loss: 0.316221; batch adversarial loss: 0.581634\n",
      "epoch 173; iter: 0; batch classifier loss: 0.356242; batch adversarial loss: 0.443332\n",
      "epoch 174; iter: 0; batch classifier loss: 0.331964; batch adversarial loss: 0.571295\n",
      "epoch 175; iter: 0; batch classifier loss: 0.322088; batch adversarial loss: 0.627727\n",
      "epoch 176; iter: 0; batch classifier loss: 0.427924; batch adversarial loss: 0.507555\n",
      "epoch 177; iter: 0; batch classifier loss: 0.405557; batch adversarial loss: 0.562783\n",
      "epoch 178; iter: 0; batch classifier loss: 0.424384; batch adversarial loss: 0.553456\n",
      "epoch 179; iter: 0; batch classifier loss: 0.358483; batch adversarial loss: 0.488713\n",
      "epoch 180; iter: 0; batch classifier loss: 0.383658; batch adversarial loss: 0.553875\n",
      "epoch 181; iter: 0; batch classifier loss: 0.360780; batch adversarial loss: 0.562557\n",
      "epoch 182; iter: 0; batch classifier loss: 0.423144; batch adversarial loss: 0.571918\n",
      "epoch 183; iter: 0; batch classifier loss: 0.381252; batch adversarial loss: 0.526200\n",
      "epoch 184; iter: 0; batch classifier loss: 0.373629; batch adversarial loss: 0.517151\n",
      "epoch 185; iter: 0; batch classifier loss: 0.392489; batch adversarial loss: 0.544117\n",
      "epoch 186; iter: 0; batch classifier loss: 0.382999; batch adversarial loss: 0.571758\n",
      "epoch 187; iter: 0; batch classifier loss: 0.372963; batch adversarial loss: 0.617989\n",
      "epoch 188; iter: 0; batch classifier loss: 0.423810; batch adversarial loss: 0.534765\n",
      "epoch 189; iter: 0; batch classifier loss: 0.386543; batch adversarial loss: 0.535060\n",
      "epoch 190; iter: 0; batch classifier loss: 0.397881; batch adversarial loss: 0.516962\n",
      "epoch 191; iter: 0; batch classifier loss: 0.274887; batch adversarial loss: 0.545700\n",
      "epoch 192; iter: 0; batch classifier loss: 0.294673; batch adversarial loss: 0.516631\n",
      "epoch 193; iter: 0; batch classifier loss: 0.356100; batch adversarial loss: 0.544954\n",
      "epoch 194; iter: 0; batch classifier loss: 0.288020; batch adversarial loss: 0.581421\n",
      "epoch 195; iter: 0; batch classifier loss: 0.299875; batch adversarial loss: 0.552823\n",
      "epoch 196; iter: 0; batch classifier loss: 0.373658; batch adversarial loss: 0.551435\n",
      "epoch 197; iter: 0; batch classifier loss: 0.365841; batch adversarial loss: 0.691379\n",
      "epoch 198; iter: 0; batch classifier loss: 0.342489; batch adversarial loss: 0.574301\n",
      "epoch 199; iter: 0; batch classifier loss: 0.334719; batch adversarial loss: 0.573013\n",
      "epoch 0; iter: 0; batch classifier loss: 0.802614; batch adversarial loss: 0.678217\n",
      "epoch 1; iter: 0; batch classifier loss: 0.599299; batch adversarial loss: 0.662875\n",
      "epoch 2; iter: 0; batch classifier loss: 0.581463; batch adversarial loss: 0.633370\n",
      "epoch 3; iter: 0; batch classifier loss: 0.602508; batch adversarial loss: 0.632144\n",
      "epoch 4; iter: 0; batch classifier loss: 0.582867; batch adversarial loss: 0.594447\n",
      "epoch 5; iter: 0; batch classifier loss: 0.483260; batch adversarial loss: 0.605625\n",
      "epoch 6; iter: 0; batch classifier loss: 0.526940; batch adversarial loss: 0.598650\n",
      "epoch 7; iter: 0; batch classifier loss: 0.558682; batch adversarial loss: 0.618243\n",
      "epoch 8; iter: 0; batch classifier loss: 0.556263; batch adversarial loss: 0.603637\n",
      "epoch 9; iter: 0; batch classifier loss: 0.596230; batch adversarial loss: 0.592729\n",
      "epoch 10; iter: 0; batch classifier loss: 0.529701; batch adversarial loss: 0.619477\n",
      "epoch 11; iter: 0; batch classifier loss: 0.608693; batch adversarial loss: 0.637787\n",
      "epoch 12; iter: 0; batch classifier loss: 0.544106; batch adversarial loss: 0.609441\n",
      "epoch 13; iter: 0; batch classifier loss: 0.530072; batch adversarial loss: 0.556450\n",
      "epoch 14; iter: 0; batch classifier loss: 0.514780; batch adversarial loss: 0.685511\n",
      "epoch 15; iter: 0; batch classifier loss: 0.431508; batch adversarial loss: 0.559492\n",
      "epoch 16; iter: 0; batch classifier loss: 0.520380; batch adversarial loss: 0.575191\n",
      "epoch 17; iter: 0; batch classifier loss: 0.561235; batch adversarial loss: 0.550548\n",
      "epoch 18; iter: 0; batch classifier loss: 0.536866; batch adversarial loss: 0.511542\n",
      "epoch 19; iter: 0; batch classifier loss: 0.531954; batch adversarial loss: 0.506237\n",
      "epoch 20; iter: 0; batch classifier loss: 0.405971; batch adversarial loss: 0.540756\n",
      "epoch 21; iter: 0; batch classifier loss: 0.459123; batch adversarial loss: 0.524510\n",
      "epoch 22; iter: 0; batch classifier loss: 0.462800; batch adversarial loss: 0.546062\n",
      "epoch 23; iter: 0; batch classifier loss: 0.491773; batch adversarial loss: 0.537473\n",
      "epoch 24; iter: 0; batch classifier loss: 0.452461; batch adversarial loss: 0.518824\n",
      "epoch 25; iter: 0; batch classifier loss: 0.461560; batch adversarial loss: 0.557494\n",
      "epoch 26; iter: 0; batch classifier loss: 0.490445; batch adversarial loss: 0.508973\n",
      "epoch 27; iter: 0; batch classifier loss: 0.415709; batch adversarial loss: 0.546420\n",
      "epoch 28; iter: 0; batch classifier loss: 0.410769; batch adversarial loss: 0.520774\n",
      "epoch 29; iter: 0; batch classifier loss: 0.524244; batch adversarial loss: 0.521432\n",
      "epoch 30; iter: 0; batch classifier loss: 0.449634; batch adversarial loss: 0.530064\n",
      "epoch 31; iter: 0; batch classifier loss: 0.466806; batch adversarial loss: 0.562541\n",
      "epoch 32; iter: 0; batch classifier loss: 0.407266; batch adversarial loss: 0.554852\n",
      "epoch 33; iter: 0; batch classifier loss: 0.415128; batch adversarial loss: 0.485663\n",
      "epoch 34; iter: 0; batch classifier loss: 0.415573; batch adversarial loss: 0.527502\n",
      "epoch 35; iter: 0; batch classifier loss: 0.408256; batch adversarial loss: 0.588029\n",
      "epoch 36; iter: 0; batch classifier loss: 0.518817; batch adversarial loss: 0.535605\n",
      "epoch 37; iter: 0; batch classifier loss: 0.542197; batch adversarial loss: 0.580660\n",
      "epoch 38; iter: 0; batch classifier loss: 0.460043; batch adversarial loss: 0.561326\n",
      "epoch 39; iter: 0; batch classifier loss: 0.409218; batch adversarial loss: 0.525792\n",
      "epoch 40; iter: 0; batch classifier loss: 0.395801; batch adversarial loss: 0.614834\n",
      "epoch 41; iter: 0; batch classifier loss: 0.475391; batch adversarial loss: 0.589533\n",
      "epoch 42; iter: 0; batch classifier loss: 0.417126; batch adversarial loss: 0.588057\n",
      "epoch 43; iter: 0; batch classifier loss: 0.467645; batch adversarial loss: 0.535236\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 44; iter: 0; batch classifier loss: 0.361019; batch adversarial loss: 0.473025\n",
      "epoch 45; iter: 0; batch classifier loss: 0.398179; batch adversarial loss: 0.535818\n",
      "epoch 46; iter: 0; batch classifier loss: 0.441934; batch adversarial loss: 0.570984\n",
      "epoch 47; iter: 0; batch classifier loss: 0.393002; batch adversarial loss: 0.571176\n",
      "epoch 48; iter: 0; batch classifier loss: 0.386282; batch adversarial loss: 0.499020\n",
      "epoch 49; iter: 0; batch classifier loss: 0.481428; batch adversarial loss: 0.580122\n",
      "epoch 50; iter: 0; batch classifier loss: 0.480164; batch adversarial loss: 0.526723\n",
      "epoch 51; iter: 0; batch classifier loss: 0.410778; batch adversarial loss: 0.516997\n",
      "epoch 52; iter: 0; batch classifier loss: 0.370331; batch adversarial loss: 0.609810\n",
      "epoch 53; iter: 0; batch classifier loss: 0.376118; batch adversarial loss: 0.535489\n",
      "epoch 54; iter: 0; batch classifier loss: 0.403909; batch adversarial loss: 0.562636\n",
      "epoch 55; iter: 0; batch classifier loss: 0.416373; batch adversarial loss: 0.526654\n",
      "epoch 56; iter: 0; batch classifier loss: 0.449173; batch adversarial loss: 0.490733\n",
      "epoch 57; iter: 0; batch classifier loss: 0.366865; batch adversarial loss: 0.517746\n",
      "epoch 58; iter: 0; batch classifier loss: 0.472646; batch adversarial loss: 0.562609\n",
      "epoch 59; iter: 0; batch classifier loss: 0.438852; batch adversarial loss: 0.526539\n",
      "epoch 60; iter: 0; batch classifier loss: 0.346576; batch adversarial loss: 0.499121\n",
      "epoch 61; iter: 0; batch classifier loss: 0.328496; batch adversarial loss: 0.526480\n",
      "epoch 62; iter: 0; batch classifier loss: 0.407361; batch adversarial loss: 0.517787\n",
      "epoch 63; iter: 0; batch classifier loss: 0.426605; batch adversarial loss: 0.481635\n",
      "epoch 64; iter: 0; batch classifier loss: 0.458330; batch adversarial loss: 0.553686\n",
      "epoch 65; iter: 0; batch classifier loss: 0.379663; batch adversarial loss: 0.580580\n",
      "epoch 66; iter: 0; batch classifier loss: 0.366607; batch adversarial loss: 0.589914\n",
      "epoch 67; iter: 0; batch classifier loss: 0.375362; batch adversarial loss: 0.489827\n",
      "epoch 68; iter: 0; batch classifier loss: 0.404336; batch adversarial loss: 0.528124\n",
      "epoch 69; iter: 0; batch classifier loss: 0.354533; batch adversarial loss: 0.498880\n",
      "epoch 70; iter: 0; batch classifier loss: 0.436078; batch adversarial loss: 0.606019\n",
      "epoch 71; iter: 0; batch classifier loss: 0.390008; batch adversarial loss: 0.597979\n",
      "epoch 72; iter: 0; batch classifier loss: 0.392369; batch adversarial loss: 0.630981\n",
      "epoch 73; iter: 0; batch classifier loss: 0.382982; batch adversarial loss: 0.543401\n",
      "epoch 74; iter: 0; batch classifier loss: 0.393647; batch adversarial loss: 0.583449\n",
      "epoch 75; iter: 0; batch classifier loss: 0.388274; batch adversarial loss: 0.566063\n",
      "epoch 76; iter: 0; batch classifier loss: 0.334567; batch adversarial loss: 0.473333\n",
      "epoch 77; iter: 0; batch classifier loss: 0.383701; batch adversarial loss: 0.580703\n",
      "epoch 78; iter: 0; batch classifier loss: 0.314773; batch adversarial loss: 0.545087\n",
      "epoch 79; iter: 0; batch classifier loss: 0.463445; batch adversarial loss: 0.599051\n",
      "epoch 80; iter: 0; batch classifier loss: 0.413270; batch adversarial loss: 0.474776\n",
      "epoch 81; iter: 0; batch classifier loss: 0.374202; batch adversarial loss: 0.513962\n",
      "epoch 82; iter: 0; batch classifier loss: 0.387370; batch adversarial loss: 0.526021\n",
      "epoch 83; iter: 0; batch classifier loss: 0.397783; batch adversarial loss: 0.563898\n",
      "epoch 84; iter: 0; batch classifier loss: 0.431679; batch adversarial loss: 0.597995\n",
      "epoch 85; iter: 0; batch classifier loss: 0.396871; batch adversarial loss: 0.544507\n",
      "epoch 86; iter: 0; batch classifier loss: 0.321072; batch adversarial loss: 0.563398\n",
      "epoch 87; iter: 0; batch classifier loss: 0.395353; batch adversarial loss: 0.536574\n",
      "epoch 88; iter: 0; batch classifier loss: 0.383365; batch adversarial loss: 0.634281\n",
      "epoch 89; iter: 0; batch classifier loss: 0.455600; batch adversarial loss: 0.553615\n",
      "epoch 90; iter: 0; batch classifier loss: 0.427729; batch adversarial loss: 0.572505\n",
      "epoch 91; iter: 0; batch classifier loss: 0.294209; batch adversarial loss: 0.490868\n",
      "epoch 92; iter: 0; batch classifier loss: 0.348934; batch adversarial loss: 0.544210\n",
      "epoch 93; iter: 0; batch classifier loss: 0.417520; batch adversarial loss: 0.518215\n",
      "epoch 94; iter: 0; batch classifier loss: 0.347622; batch adversarial loss: 0.544250\n",
      "epoch 95; iter: 0; batch classifier loss: 0.405124; batch adversarial loss: 0.562167\n",
      "epoch 96; iter: 0; batch classifier loss: 0.385416; batch adversarial loss: 0.571787\n",
      "epoch 97; iter: 0; batch classifier loss: 0.413443; batch adversarial loss: 0.489482\n",
      "epoch 98; iter: 0; batch classifier loss: 0.400930; batch adversarial loss: 0.526889\n",
      "epoch 99; iter: 0; batch classifier loss: 0.373430; batch adversarial loss: 0.537529\n",
      "epoch 100; iter: 0; batch classifier loss: 0.359205; batch adversarial loss: 0.507450\n",
      "epoch 101; iter: 0; batch classifier loss: 0.383369; batch adversarial loss: 0.553597\n",
      "epoch 102; iter: 0; batch classifier loss: 0.389192; batch adversarial loss: 0.514892\n",
      "epoch 103; iter: 0; batch classifier loss: 0.370601; batch adversarial loss: 0.560764\n",
      "epoch 104; iter: 0; batch classifier loss: 0.414683; batch adversarial loss: 0.532902\n",
      "epoch 105; iter: 0; batch classifier loss: 0.381758; batch adversarial loss: 0.493604\n",
      "epoch 106; iter: 0; batch classifier loss: 0.420862; batch adversarial loss: 0.508203\n",
      "epoch 107; iter: 0; batch classifier loss: 0.396408; batch adversarial loss: 0.446857\n",
      "epoch 108; iter: 0; batch classifier loss: 0.340386; batch adversarial loss: 0.566511\n",
      "epoch 109; iter: 0; batch classifier loss: 0.347271; batch adversarial loss: 0.526090\n",
      "epoch 110; iter: 0; batch classifier loss: 0.403150; batch adversarial loss: 0.534934\n",
      "epoch 111; iter: 0; batch classifier loss: 0.381769; batch adversarial loss: 0.572279\n",
      "epoch 112; iter: 0; batch classifier loss: 0.360754; batch adversarial loss: 0.590057\n",
      "epoch 113; iter: 0; batch classifier loss: 0.357702; batch adversarial loss: 0.472154\n",
      "epoch 114; iter: 0; batch classifier loss: 0.398980; batch adversarial loss: 0.517754\n",
      "epoch 115; iter: 0; batch classifier loss: 0.418263; batch adversarial loss: 0.481738\n",
      "epoch 116; iter: 0; batch classifier loss: 0.330445; batch adversarial loss: 0.552484\n",
      "epoch 117; iter: 0; batch classifier loss: 0.376253; batch adversarial loss: 0.537498\n",
      "epoch 118; iter: 0; batch classifier loss: 0.380432; batch adversarial loss: 0.446597\n",
      "epoch 119; iter: 0; batch classifier loss: 0.424611; batch adversarial loss: 0.448966\n",
      "epoch 120; iter: 0; batch classifier loss: 0.330796; batch adversarial loss: 0.561794\n",
      "epoch 121; iter: 0; batch classifier loss: 0.450384; batch adversarial loss: 0.511165\n",
      "epoch 122; iter: 0; batch classifier loss: 0.417599; batch adversarial loss: 0.527541\n",
      "epoch 123; iter: 0; batch classifier loss: 0.315976; batch adversarial loss: 0.509707\n",
      "epoch 124; iter: 0; batch classifier loss: 0.286549; batch adversarial loss: 0.481575\n",
      "epoch 125; iter: 0; batch classifier loss: 0.380440; batch adversarial loss: 0.607515\n",
      "epoch 126; iter: 0; batch classifier loss: 0.411718; batch adversarial loss: 0.454942\n",
      "epoch 127; iter: 0; batch classifier loss: 0.335048; batch adversarial loss: 0.552680\n",
      "epoch 128; iter: 0; batch classifier loss: 0.329095; batch adversarial loss: 0.525658\n",
      "epoch 129; iter: 0; batch classifier loss: 0.389976; batch adversarial loss: 0.617868\n",
      "epoch 130; iter: 0; batch classifier loss: 0.349261; batch adversarial loss: 0.588332\n",
      "epoch 131; iter: 0; batch classifier loss: 0.326704; batch adversarial loss: 0.534672\n",
      "epoch 132; iter: 0; batch classifier loss: 0.371307; batch adversarial loss: 0.518437\n",
      "epoch 133; iter: 0; batch classifier loss: 0.353561; batch adversarial loss: 0.561992\n",
      "epoch 134; iter: 0; batch classifier loss: 0.437172; batch adversarial loss: 0.571750\n",
      "epoch 135; iter: 0; batch classifier loss: 0.333658; batch adversarial loss: 0.490901\n",
      "epoch 136; iter: 0; batch classifier loss: 0.393022; batch adversarial loss: 0.454754\n",
      "epoch 137; iter: 0; batch classifier loss: 0.471362; batch adversarial loss: 0.517778\n",
      "epoch 138; iter: 0; batch classifier loss: 0.328853; batch adversarial loss: 0.535366\n",
      "epoch 139; iter: 0; batch classifier loss: 0.325799; batch adversarial loss: 0.598175\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 140; iter: 0; batch classifier loss: 0.383218; batch adversarial loss: 0.472160\n",
      "epoch 141; iter: 0; batch classifier loss: 0.362640; batch adversarial loss: 0.518161\n",
      "epoch 142; iter: 0; batch classifier loss: 0.349565; batch adversarial loss: 0.534489\n",
      "epoch 143; iter: 0; batch classifier loss: 0.328486; batch adversarial loss: 0.499043\n",
      "epoch 144; iter: 0; batch classifier loss: 0.363548; batch adversarial loss: 0.470450\n",
      "epoch 145; iter: 0; batch classifier loss: 0.368346; batch adversarial loss: 0.507664\n",
      "epoch 146; iter: 0; batch classifier loss: 0.313862; batch adversarial loss: 0.562929\n",
      "epoch 147; iter: 0; batch classifier loss: 0.338893; batch adversarial loss: 0.545277\n",
      "epoch 148; iter: 0; batch classifier loss: 0.417888; batch adversarial loss: 0.544285\n",
      "epoch 149; iter: 0; batch classifier loss: 0.378900; batch adversarial loss: 0.508310\n",
      "epoch 150; iter: 0; batch classifier loss: 0.331050; batch adversarial loss: 0.600265\n",
      "epoch 151; iter: 0; batch classifier loss: 0.357120; batch adversarial loss: 0.591627\n",
      "epoch 152; iter: 0; batch classifier loss: 0.353880; batch adversarial loss: 0.527294\n",
      "epoch 153; iter: 0; batch classifier loss: 0.369519; batch adversarial loss: 0.473124\n",
      "epoch 154; iter: 0; batch classifier loss: 0.355494; batch adversarial loss: 0.492246\n",
      "epoch 155; iter: 0; batch classifier loss: 0.347440; batch adversarial loss: 0.641899\n",
      "epoch 156; iter: 0; batch classifier loss: 0.339014; batch adversarial loss: 0.571184\n",
      "epoch 157; iter: 0; batch classifier loss: 0.384822; batch adversarial loss: 0.537013\n",
      "epoch 158; iter: 0; batch classifier loss: 0.447876; batch adversarial loss: 0.545161\n",
      "epoch 159; iter: 0; batch classifier loss: 0.424177; batch adversarial loss: 0.526913\n",
      "epoch 160; iter: 0; batch classifier loss: 0.291070; batch adversarial loss: 0.598639\n",
      "epoch 161; iter: 0; batch classifier loss: 0.299737; batch adversarial loss: 0.526496\n",
      "epoch 162; iter: 0; batch classifier loss: 0.392299; batch adversarial loss: 0.580673\n",
      "epoch 163; iter: 0; batch classifier loss: 0.347216; batch adversarial loss: 0.508260\n",
      "epoch 164; iter: 0; batch classifier loss: 0.368555; batch adversarial loss: 0.616154\n",
      "epoch 165; iter: 0; batch classifier loss: 0.408311; batch adversarial loss: 0.589928\n",
      "epoch 166; iter: 0; batch classifier loss: 0.389728; batch adversarial loss: 0.462582\n",
      "epoch 167; iter: 0; batch classifier loss: 0.353056; batch adversarial loss: 0.481234\n",
      "epoch 168; iter: 0; batch classifier loss: 0.416918; batch adversarial loss: 0.616544\n",
      "epoch 169; iter: 0; batch classifier loss: 0.302224; batch adversarial loss: 0.580309\n",
      "epoch 170; iter: 0; batch classifier loss: 0.333009; batch adversarial loss: 0.544570\n",
      "epoch 171; iter: 0; batch classifier loss: 0.371277; batch adversarial loss: 0.625838\n",
      "epoch 172; iter: 0; batch classifier loss: 0.251473; batch adversarial loss: 0.535474\n",
      "epoch 173; iter: 0; batch classifier loss: 0.264559; batch adversarial loss: 0.455075\n",
      "epoch 174; iter: 0; batch classifier loss: 0.385969; batch adversarial loss: 0.571390\n",
      "epoch 175; iter: 0; batch classifier loss: 0.421975; batch adversarial loss: 0.562339\n",
      "epoch 176; iter: 0; batch classifier loss: 0.316408; batch adversarial loss: 0.571553\n",
      "epoch 177; iter: 0; batch classifier loss: 0.318704; batch adversarial loss: 0.598267\n",
      "epoch 178; iter: 0; batch classifier loss: 0.408995; batch adversarial loss: 0.508063\n",
      "epoch 179; iter: 0; batch classifier loss: 0.383170; batch adversarial loss: 0.553173\n",
      "epoch 180; iter: 0; batch classifier loss: 0.337798; batch adversarial loss: 0.515519\n",
      "epoch 181; iter: 0; batch classifier loss: 0.314530; batch adversarial loss: 0.479409\n",
      "epoch 182; iter: 0; batch classifier loss: 0.309175; batch adversarial loss: 0.580977\n",
      "epoch 183; iter: 0; batch classifier loss: 0.280370; batch adversarial loss: 0.568596\n",
      "epoch 184; iter: 0; batch classifier loss: 0.370922; batch adversarial loss: 0.527829\n",
      "epoch 185; iter: 0; batch classifier loss: 0.351928; batch adversarial loss: 0.506685\n",
      "epoch 186; iter: 0; batch classifier loss: 0.320025; batch adversarial loss: 0.543643\n",
      "epoch 187; iter: 0; batch classifier loss: 0.413726; batch adversarial loss: 0.635077\n",
      "epoch 188; iter: 0; batch classifier loss: 0.452899; batch adversarial loss: 0.561285\n",
      "epoch 189; iter: 0; batch classifier loss: 0.276538; batch adversarial loss: 0.528895\n",
      "epoch 190; iter: 0; batch classifier loss: 0.337564; batch adversarial loss: 0.572683\n",
      "epoch 191; iter: 0; batch classifier loss: 0.319846; batch adversarial loss: 0.546014\n",
      "epoch 192; iter: 0; batch classifier loss: 0.419074; batch adversarial loss: 0.492265\n",
      "epoch 193; iter: 0; batch classifier loss: 0.338240; batch adversarial loss: 0.625288\n",
      "epoch 194; iter: 0; batch classifier loss: 0.310289; batch adversarial loss: 0.635017\n",
      "epoch 195; iter: 0; batch classifier loss: 0.381043; batch adversarial loss: 0.574607\n",
      "epoch 196; iter: 0; batch classifier loss: 0.305696; batch adversarial loss: 0.436956\n",
      "epoch 197; iter: 0; batch classifier loss: 0.468026; batch adversarial loss: 0.506479\n",
      "epoch 198; iter: 0; batch classifier loss: 0.374078; batch adversarial loss: 0.682687\n",
      "epoch 199; iter: 0; batch classifier loss: 0.366189; batch adversarial loss: 0.563652\n",
      "epoch 0; iter: 0; batch classifier loss: 0.683920; batch adversarial loss: 0.770106\n",
      "epoch 1; iter: 0; batch classifier loss: 0.785982; batch adversarial loss: 0.923527\n",
      "epoch 2; iter: 0; batch classifier loss: 0.848135; batch adversarial loss: 0.870393\n",
      "epoch 3; iter: 0; batch classifier loss: 1.092966; batch adversarial loss: 0.815649\n",
      "epoch 4; iter: 0; batch classifier loss: 1.015332; batch adversarial loss: 0.744028\n",
      "epoch 5; iter: 0; batch classifier loss: 0.925147; batch adversarial loss: 0.679177\n",
      "epoch 6; iter: 0; batch classifier loss: 0.857297; batch adversarial loss: 0.647902\n",
      "epoch 7; iter: 0; batch classifier loss: 0.578865; batch adversarial loss: 0.599234\n",
      "epoch 8; iter: 0; batch classifier loss: 0.629592; batch adversarial loss: 0.583219\n",
      "epoch 9; iter: 0; batch classifier loss: 0.586120; batch adversarial loss: 0.611743\n",
      "epoch 10; iter: 0; batch classifier loss: 0.466057; batch adversarial loss: 0.622617\n",
      "epoch 11; iter: 0; batch classifier loss: 0.564780; batch adversarial loss: 0.572679\n",
      "epoch 12; iter: 0; batch classifier loss: 0.518617; batch adversarial loss: 0.581998\n",
      "epoch 13; iter: 0; batch classifier loss: 0.507512; batch adversarial loss: 0.561221\n",
      "epoch 14; iter: 0; batch classifier loss: 0.510087; batch adversarial loss: 0.577756\n",
      "epoch 15; iter: 0; batch classifier loss: 0.581260; batch adversarial loss: 0.624277\n",
      "epoch 16; iter: 0; batch classifier loss: 0.522299; batch adversarial loss: 0.593340\n",
      "epoch 17; iter: 0; batch classifier loss: 0.480197; batch adversarial loss: 0.577171\n",
      "epoch 18; iter: 0; batch classifier loss: 0.577923; batch adversarial loss: 0.616310\n",
      "epoch 19; iter: 0; batch classifier loss: 0.538338; batch adversarial loss: 0.526313\n",
      "epoch 20; iter: 0; batch classifier loss: 0.439286; batch adversarial loss: 0.533272\n",
      "epoch 21; iter: 0; batch classifier loss: 0.525025; batch adversarial loss: 0.556792\n",
      "epoch 22; iter: 0; batch classifier loss: 0.471222; batch adversarial loss: 0.473451\n",
      "epoch 23; iter: 0; batch classifier loss: 0.522039; batch adversarial loss: 0.567905\n",
      "epoch 24; iter: 0; batch classifier loss: 0.461676; batch adversarial loss: 0.546794\n",
      "epoch 25; iter: 0; batch classifier loss: 0.428117; batch adversarial loss: 0.462763\n",
      "epoch 26; iter: 0; batch classifier loss: 0.495670; batch adversarial loss: 0.511163\n",
      "epoch 27; iter: 0; batch classifier loss: 0.539008; batch adversarial loss: 0.525411\n",
      "epoch 28; iter: 0; batch classifier loss: 0.496938; batch adversarial loss: 0.554413\n",
      "epoch 29; iter: 0; batch classifier loss: 0.435349; batch adversarial loss: 0.546390\n",
      "epoch 30; iter: 0; batch classifier loss: 0.521230; batch adversarial loss: 0.531753\n",
      "epoch 31; iter: 0; batch classifier loss: 0.445401; batch adversarial loss: 0.501703\n",
      "epoch 32; iter: 0; batch classifier loss: 0.470947; batch adversarial loss: 0.570260\n",
      "epoch 33; iter: 0; batch classifier loss: 0.505734; batch adversarial loss: 0.448962\n",
      "epoch 34; iter: 0; batch classifier loss: 0.409618; batch adversarial loss: 0.508302\n",
      "epoch 35; iter: 0; batch classifier loss: 0.488155; batch adversarial loss: 0.513086\n",
      "epoch 36; iter: 0; batch classifier loss: 0.468345; batch adversarial loss: 0.609367\n",
      "epoch 37; iter: 0; batch classifier loss: 0.448467; batch adversarial loss: 0.510098\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 38; iter: 0; batch classifier loss: 0.432962; batch adversarial loss: 0.563555\n",
      "epoch 39; iter: 0; batch classifier loss: 0.474335; batch adversarial loss: 0.569730\n",
      "epoch 40; iter: 0; batch classifier loss: 0.409017; batch adversarial loss: 0.610797\n",
      "epoch 41; iter: 0; batch classifier loss: 0.378345; batch adversarial loss: 0.566444\n",
      "epoch 42; iter: 0; batch classifier loss: 0.451663; batch adversarial loss: 0.533174\n",
      "epoch 43; iter: 0; batch classifier loss: 0.464232; batch adversarial loss: 0.510469\n",
      "epoch 44; iter: 0; batch classifier loss: 0.327462; batch adversarial loss: 0.523412\n",
      "epoch 45; iter: 0; batch classifier loss: 0.498166; batch adversarial loss: 0.484718\n",
      "epoch 46; iter: 0; batch classifier loss: 0.432364; batch adversarial loss: 0.533589\n",
      "epoch 47; iter: 0; batch classifier loss: 0.437416; batch adversarial loss: 0.633372\n",
      "epoch 48; iter: 0; batch classifier loss: 0.392565; batch adversarial loss: 0.552535\n",
      "epoch 49; iter: 0; batch classifier loss: 0.436767; batch adversarial loss: 0.459148\n",
      "epoch 50; iter: 0; batch classifier loss: 0.394592; batch adversarial loss: 0.595082\n",
      "epoch 51; iter: 0; batch classifier loss: 0.344779; batch adversarial loss: 0.536105\n",
      "epoch 52; iter: 0; batch classifier loss: 0.403757; batch adversarial loss: 0.542396\n",
      "epoch 53; iter: 0; batch classifier loss: 0.372256; batch adversarial loss: 0.510401\n",
      "epoch 54; iter: 0; batch classifier loss: 0.473988; batch adversarial loss: 0.507658\n",
      "epoch 55; iter: 0; batch classifier loss: 0.343946; batch adversarial loss: 0.499388\n",
      "epoch 56; iter: 0; batch classifier loss: 0.423953; batch adversarial loss: 0.583219\n",
      "epoch 57; iter: 0; batch classifier loss: 0.351555; batch adversarial loss: 0.524152\n",
      "epoch 58; iter: 0; batch classifier loss: 0.416796; batch adversarial loss: 0.565006\n",
      "epoch 59; iter: 0; batch classifier loss: 0.416730; batch adversarial loss: 0.444476\n",
      "epoch 60; iter: 0; batch classifier loss: 0.367221; batch adversarial loss: 0.516996\n",
      "epoch 61; iter: 0; batch classifier loss: 0.396037; batch adversarial loss: 0.510387\n",
      "epoch 62; iter: 0; batch classifier loss: 0.416324; batch adversarial loss: 0.581783\n",
      "epoch 63; iter: 0; batch classifier loss: 0.412347; batch adversarial loss: 0.547068\n",
      "epoch 64; iter: 0; batch classifier loss: 0.391893; batch adversarial loss: 0.505935\n",
      "epoch 65; iter: 0; batch classifier loss: 0.436999; batch adversarial loss: 0.543847\n",
      "epoch 66; iter: 0; batch classifier loss: 0.365843; batch adversarial loss: 0.543308\n",
      "epoch 67; iter: 0; batch classifier loss: 0.372234; batch adversarial loss: 0.552123\n",
      "epoch 68; iter: 0; batch classifier loss: 0.434648; batch adversarial loss: 0.606278\n",
      "epoch 69; iter: 0; batch classifier loss: 0.355095; batch adversarial loss: 0.534596\n",
      "epoch 70; iter: 0; batch classifier loss: 0.414703; batch adversarial loss: 0.607801\n",
      "epoch 71; iter: 0; batch classifier loss: 0.336943; batch adversarial loss: 0.479555\n",
      "epoch 72; iter: 0; batch classifier loss: 0.408852; batch adversarial loss: 0.526321\n",
      "epoch 73; iter: 0; batch classifier loss: 0.452894; batch adversarial loss: 0.545171\n",
      "epoch 74; iter: 0; batch classifier loss: 0.291039; batch adversarial loss: 0.524548\n",
      "epoch 75; iter: 0; batch classifier loss: 0.402116; batch adversarial loss: 0.535767\n",
      "epoch 76; iter: 0; batch classifier loss: 0.464491; batch adversarial loss: 0.515542\n",
      "epoch 77; iter: 0; batch classifier loss: 0.349549; batch adversarial loss: 0.579603\n",
      "epoch 78; iter: 0; batch classifier loss: 0.392791; batch adversarial loss: 0.526094\n",
      "epoch 79; iter: 0; batch classifier loss: 0.313843; batch adversarial loss: 0.646449\n",
      "epoch 80; iter: 0; batch classifier loss: 0.338850; batch adversarial loss: 0.556112\n",
      "epoch 81; iter: 0; batch classifier loss: 0.335563; batch adversarial loss: 0.559213\n",
      "epoch 82; iter: 0; batch classifier loss: 0.383527; batch adversarial loss: 0.488897\n",
      "epoch 83; iter: 0; batch classifier loss: 0.337213; batch adversarial loss: 0.589400\n",
      "epoch 84; iter: 0; batch classifier loss: 0.419823; batch adversarial loss: 0.628235\n",
      "epoch 85; iter: 0; batch classifier loss: 0.423612; batch adversarial loss: 0.546668\n",
      "epoch 86; iter: 0; batch classifier loss: 0.395943; batch adversarial loss: 0.543456\n",
      "epoch 87; iter: 0; batch classifier loss: 0.355252; batch adversarial loss: 0.545756\n",
      "epoch 88; iter: 0; batch classifier loss: 0.374864; batch adversarial loss: 0.583257\n",
      "epoch 89; iter: 0; batch classifier loss: 0.361574; batch adversarial loss: 0.503748\n",
      "epoch 90; iter: 0; batch classifier loss: 0.367976; batch adversarial loss: 0.563306\n",
      "epoch 91; iter: 0; batch classifier loss: 0.349641; batch adversarial loss: 0.586994\n",
      "epoch 92; iter: 0; batch classifier loss: 0.376247; batch adversarial loss: 0.607740\n",
      "epoch 93; iter: 0; batch classifier loss: 0.344781; batch adversarial loss: 0.572430\n",
      "epoch 94; iter: 0; batch classifier loss: 0.312337; batch adversarial loss: 0.526076\n",
      "epoch 95; iter: 0; batch classifier loss: 0.364687; batch adversarial loss: 0.619283\n",
      "epoch 96; iter: 0; batch classifier loss: 0.402233; batch adversarial loss: 0.601746\n",
      "epoch 97; iter: 0; batch classifier loss: 0.358177; batch adversarial loss: 0.599277\n",
      "epoch 98; iter: 0; batch classifier loss: 0.362752; batch adversarial loss: 0.616929\n",
      "epoch 99; iter: 0; batch classifier loss: 0.454979; batch adversarial loss: 0.517916\n",
      "epoch 100; iter: 0; batch classifier loss: 0.315821; batch adversarial loss: 0.544709\n",
      "epoch 101; iter: 0; batch classifier loss: 0.382747; batch adversarial loss: 0.554986\n",
      "epoch 102; iter: 0; batch classifier loss: 0.431722; batch adversarial loss: 0.564257\n",
      "epoch 103; iter: 0; batch classifier loss: 0.304208; batch adversarial loss: 0.522386\n",
      "epoch 104; iter: 0; batch classifier loss: 0.283230; batch adversarial loss: 0.570968\n",
      "epoch 105; iter: 0; batch classifier loss: 0.374539; batch adversarial loss: 0.630379\n",
      "epoch 106; iter: 0; batch classifier loss: 0.375701; batch adversarial loss: 0.567965\n",
      "epoch 107; iter: 0; batch classifier loss: 0.426449; batch adversarial loss: 0.525966\n",
      "epoch 108; iter: 0; batch classifier loss: 0.277954; batch adversarial loss: 0.545662\n",
      "epoch 109; iter: 0; batch classifier loss: 0.360800; batch adversarial loss: 0.510216\n",
      "epoch 110; iter: 0; batch classifier loss: 0.306824; batch adversarial loss: 0.507350\n",
      "epoch 111; iter: 0; batch classifier loss: 0.396913; batch adversarial loss: 0.505005\n",
      "epoch 112; iter: 0; batch classifier loss: 0.316312; batch adversarial loss: 0.551180\n",
      "epoch 113; iter: 0; batch classifier loss: 0.310485; batch adversarial loss: 0.562634\n",
      "epoch 114; iter: 0; batch classifier loss: 0.374712; batch adversarial loss: 0.555274\n",
      "epoch 115; iter: 0; batch classifier loss: 0.357809; batch adversarial loss: 0.623827\n",
      "epoch 116; iter: 0; batch classifier loss: 0.396451; batch adversarial loss: 0.490602\n",
      "epoch 117; iter: 0; batch classifier loss: 0.392210; batch adversarial loss: 0.543970\n",
      "epoch 118; iter: 0; batch classifier loss: 0.441257; batch adversarial loss: 0.535211\n",
      "epoch 119; iter: 0; batch classifier loss: 0.320314; batch adversarial loss: 0.506927\n",
      "epoch 120; iter: 0; batch classifier loss: 0.292936; batch adversarial loss: 0.627201\n",
      "epoch 121; iter: 0; batch classifier loss: 0.340791; batch adversarial loss: 0.541455\n",
      "epoch 122; iter: 0; batch classifier loss: 0.296709; batch adversarial loss: 0.517391\n",
      "epoch 123; iter: 0; batch classifier loss: 0.360120; batch adversarial loss: 0.534732\n",
      "epoch 124; iter: 0; batch classifier loss: 0.340264; batch adversarial loss: 0.554124\n",
      "epoch 125; iter: 0; batch classifier loss: 0.362356; batch adversarial loss: 0.481349\n",
      "epoch 126; iter: 0; batch classifier loss: 0.328199; batch adversarial loss: 0.536593\n",
      "epoch 127; iter: 0; batch classifier loss: 0.337744; batch adversarial loss: 0.529692\n",
      "epoch 128; iter: 0; batch classifier loss: 0.346096; batch adversarial loss: 0.488722\n",
      "epoch 129; iter: 0; batch classifier loss: 0.327666; batch adversarial loss: 0.487377\n",
      "epoch 130; iter: 0; batch classifier loss: 0.354467; batch adversarial loss: 0.478649\n",
      "epoch 131; iter: 0; batch classifier loss: 0.282059; batch adversarial loss: 0.545235\n",
      "epoch 132; iter: 0; batch classifier loss: 0.295562; batch adversarial loss: 0.590067\n",
      "epoch 133; iter: 0; batch classifier loss: 0.343058; batch adversarial loss: 0.580727\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 134; iter: 0; batch classifier loss: 0.431435; batch adversarial loss: 0.561597\n",
      "epoch 135; iter: 0; batch classifier loss: 0.410180; batch adversarial loss: 0.618678\n",
      "epoch 136; iter: 0; batch classifier loss: 0.294093; batch adversarial loss: 0.534665\n",
      "epoch 137; iter: 0; batch classifier loss: 0.312827; batch adversarial loss: 0.571470\n",
      "epoch 138; iter: 0; batch classifier loss: 0.403167; batch adversarial loss: 0.546514\n",
      "epoch 139; iter: 0; batch classifier loss: 0.375931; batch adversarial loss: 0.490148\n",
      "epoch 140; iter: 0; batch classifier loss: 0.386711; batch adversarial loss: 0.535082\n",
      "epoch 141; iter: 0; batch classifier loss: 0.340298; batch adversarial loss: 0.498606\n",
      "epoch 142; iter: 0; batch classifier loss: 0.377545; batch adversarial loss: 0.508030\n",
      "epoch 143; iter: 0; batch classifier loss: 0.313110; batch adversarial loss: 0.592589\n",
      "epoch 144; iter: 0; batch classifier loss: 0.351295; batch adversarial loss: 0.477896\n",
      "epoch 145; iter: 0; batch classifier loss: 0.259959; batch adversarial loss: 0.560750\n",
      "epoch 146; iter: 0; batch classifier loss: 0.360806; batch adversarial loss: 0.528572\n",
      "epoch 147; iter: 0; batch classifier loss: 0.359066; batch adversarial loss: 0.570341\n",
      "epoch 148; iter: 0; batch classifier loss: 0.400531; batch adversarial loss: 0.574584\n",
      "epoch 149; iter: 0; batch classifier loss: 0.334767; batch adversarial loss: 0.581225\n",
      "epoch 150; iter: 0; batch classifier loss: 0.276539; batch adversarial loss: 0.535221\n",
      "epoch 151; iter: 0; batch classifier loss: 0.327788; batch adversarial loss: 0.554939\n",
      "epoch 152; iter: 0; batch classifier loss: 0.390379; batch adversarial loss: 0.551579\n",
      "epoch 153; iter: 0; batch classifier loss: 0.394740; batch adversarial loss: 0.617994\n",
      "epoch 154; iter: 0; batch classifier loss: 0.327015; batch adversarial loss: 0.645313\n",
      "epoch 155; iter: 0; batch classifier loss: 0.247497; batch adversarial loss: 0.543656\n",
      "epoch 156; iter: 0; batch classifier loss: 0.313814; batch adversarial loss: 0.553525\n",
      "epoch 157; iter: 0; batch classifier loss: 0.360091; batch adversarial loss: 0.480993\n",
      "epoch 158; iter: 0; batch classifier loss: 0.311169; batch adversarial loss: 0.500180\n",
      "epoch 159; iter: 0; batch classifier loss: 0.245181; batch adversarial loss: 0.563698\n",
      "epoch 160; iter: 0; batch classifier loss: 0.343802; batch adversarial loss: 0.563621\n",
      "epoch 161; iter: 0; batch classifier loss: 0.373517; batch adversarial loss: 0.601652\n",
      "epoch 162; iter: 0; batch classifier loss: 0.286622; batch adversarial loss: 0.525066\n",
      "epoch 163; iter: 0; batch classifier loss: 0.359960; batch adversarial loss: 0.515285\n",
      "epoch 164; iter: 0; batch classifier loss: 0.324141; batch adversarial loss: 0.579444\n",
      "epoch 165; iter: 0; batch classifier loss: 0.338019; batch adversarial loss: 0.506828\n",
      "epoch 166; iter: 0; batch classifier loss: 0.323290; batch adversarial loss: 0.468663\n",
      "epoch 167; iter: 0; batch classifier loss: 0.265860; batch adversarial loss: 0.515474\n",
      "epoch 168; iter: 0; batch classifier loss: 0.337955; batch adversarial loss: 0.552194\n",
      "epoch 169; iter: 0; batch classifier loss: 0.239670; batch adversarial loss: 0.490344\n",
      "epoch 170; iter: 0; batch classifier loss: 0.330353; batch adversarial loss: 0.524945\n",
      "epoch 171; iter: 0; batch classifier loss: 0.338629; batch adversarial loss: 0.509059\n",
      "epoch 172; iter: 0; batch classifier loss: 0.395545; batch adversarial loss: 0.561971\n",
      "epoch 173; iter: 0; batch classifier loss: 0.288301; batch adversarial loss: 0.499473\n",
      "epoch 174; iter: 0; batch classifier loss: 0.423414; batch adversarial loss: 0.597633\n",
      "epoch 175; iter: 0; batch classifier loss: 0.364313; batch adversarial loss: 0.522759\n",
      "epoch 176; iter: 0; batch classifier loss: 0.358844; batch adversarial loss: 0.579778\n",
      "epoch 177; iter: 0; batch classifier loss: 0.311292; batch adversarial loss: 0.562791\n",
      "epoch 178; iter: 0; batch classifier loss: 0.295645; batch adversarial loss: 0.581061\n",
      "epoch 179; iter: 0; batch classifier loss: 0.278714; batch adversarial loss: 0.542952\n",
      "epoch 180; iter: 0; batch classifier loss: 0.344646; batch adversarial loss: 0.568106\n",
      "epoch 181; iter: 0; batch classifier loss: 0.308126; batch adversarial loss: 0.630245\n",
      "epoch 182; iter: 0; batch classifier loss: 0.329470; batch adversarial loss: 0.526314\n",
      "epoch 183; iter: 0; batch classifier loss: 0.270748; batch adversarial loss: 0.542794\n",
      "epoch 184; iter: 0; batch classifier loss: 0.281409; batch adversarial loss: 0.599053\n",
      "epoch 185; iter: 0; batch classifier loss: 0.336119; batch adversarial loss: 0.442159\n",
      "epoch 186; iter: 0; batch classifier loss: 0.316638; batch adversarial loss: 0.611444\n",
      "epoch 187; iter: 0; batch classifier loss: 0.279177; batch adversarial loss: 0.508574\n",
      "epoch 188; iter: 0; batch classifier loss: 0.256206; batch adversarial loss: 0.591126\n",
      "epoch 189; iter: 0; batch classifier loss: 0.309403; batch adversarial loss: 0.506453\n",
      "epoch 190; iter: 0; batch classifier loss: 0.363636; batch adversarial loss: 0.460235\n",
      "epoch 191; iter: 0; batch classifier loss: 0.356105; batch adversarial loss: 0.589416\n",
      "epoch 192; iter: 0; batch classifier loss: 0.351699; batch adversarial loss: 0.609927\n",
      "epoch 193; iter: 0; batch classifier loss: 0.255168; batch adversarial loss: 0.571396\n",
      "epoch 194; iter: 0; batch classifier loss: 0.368319; batch adversarial loss: 0.589886\n",
      "epoch 195; iter: 0; batch classifier loss: 0.287466; batch adversarial loss: 0.538035\n",
      "epoch 196; iter: 0; batch classifier loss: 0.311700; batch adversarial loss: 0.588700\n",
      "epoch 197; iter: 0; batch classifier loss: 0.322740; batch adversarial loss: 0.555535\n",
      "epoch 198; iter: 0; batch classifier loss: 0.343016; batch adversarial loss: 0.562980\n",
      "epoch 199; iter: 0; batch classifier loss: 0.311044; batch adversarial loss: 0.554142\n",
      "epoch 0; iter: 0; batch classifier loss: 0.688549; batch adversarial loss: 0.646462\n",
      "epoch 1; iter: 0; batch classifier loss: 0.521831; batch adversarial loss: 0.646141\n",
      "epoch 2; iter: 0; batch classifier loss: 0.577541; batch adversarial loss: 0.635456\n",
      "epoch 3; iter: 0; batch classifier loss: 0.575193; batch adversarial loss: 0.654870\n",
      "epoch 4; iter: 0; batch classifier loss: 0.555240; batch adversarial loss: 0.647942\n",
      "epoch 5; iter: 0; batch classifier loss: 0.559870; batch adversarial loss: 0.606051\n",
      "epoch 6; iter: 0; batch classifier loss: 0.591869; batch adversarial loss: 0.636004\n",
      "epoch 7; iter: 0; batch classifier loss: 0.485987; batch adversarial loss: 0.600794\n",
      "epoch 8; iter: 0; batch classifier loss: 0.577537; batch adversarial loss: 0.574501\n",
      "epoch 9; iter: 0; batch classifier loss: 0.501269; batch adversarial loss: 0.662183\n",
      "epoch 10; iter: 0; batch classifier loss: 0.550670; batch adversarial loss: 0.581005\n",
      "epoch 11; iter: 0; batch classifier loss: 0.539588; batch adversarial loss: 0.545819\n",
      "epoch 12; iter: 0; batch classifier loss: 0.521927; batch adversarial loss: 0.612407\n",
      "epoch 13; iter: 0; batch classifier loss: 0.517650; batch adversarial loss: 0.637671\n",
      "epoch 14; iter: 0; batch classifier loss: 0.443896; batch adversarial loss: 0.527040\n",
      "epoch 15; iter: 0; batch classifier loss: 0.569616; batch adversarial loss: 0.540033\n",
      "epoch 16; iter: 0; batch classifier loss: 0.577178; batch adversarial loss: 0.594567\n",
      "epoch 17; iter: 0; batch classifier loss: 0.443975; batch adversarial loss: 0.537877\n",
      "epoch 18; iter: 0; batch classifier loss: 0.506800; batch adversarial loss: 0.502694\n",
      "epoch 19; iter: 0; batch classifier loss: 0.517671; batch adversarial loss: 0.579346\n",
      "epoch 20; iter: 0; batch classifier loss: 0.510339; batch adversarial loss: 0.605713\n",
      "epoch 21; iter: 0; batch classifier loss: 0.479920; batch adversarial loss: 0.587356\n",
      "epoch 22; iter: 0; batch classifier loss: 0.449264; batch adversarial loss: 0.530147\n",
      "epoch 23; iter: 0; batch classifier loss: 0.578523; batch adversarial loss: 0.591373\n",
      "epoch 24; iter: 0; batch classifier loss: 0.477418; batch adversarial loss: 0.546796\n",
      "epoch 25; iter: 0; batch classifier loss: 0.535157; batch adversarial loss: 0.490981\n",
      "epoch 26; iter: 0; batch classifier loss: 0.438278; batch adversarial loss: 0.606783\n",
      "epoch 27; iter: 0; batch classifier loss: 0.494126; batch adversarial loss: 0.555631\n",
      "epoch 28; iter: 0; batch classifier loss: 0.471741; batch adversarial loss: 0.515515\n",
      "epoch 29; iter: 0; batch classifier loss: 0.460912; batch adversarial loss: 0.597059\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30; iter: 0; batch classifier loss: 0.434020; batch adversarial loss: 0.441246\n",
      "epoch 31; iter: 0; batch classifier loss: 0.516891; batch adversarial loss: 0.527085\n",
      "epoch 32; iter: 0; batch classifier loss: 0.416445; batch adversarial loss: 0.474544\n",
      "epoch 33; iter: 0; batch classifier loss: 0.511564; batch adversarial loss: 0.492366\n",
      "epoch 34; iter: 0; batch classifier loss: 0.445961; batch adversarial loss: 0.579079\n",
      "epoch 35; iter: 0; batch classifier loss: 0.437922; batch adversarial loss: 0.545544\n",
      "epoch 36; iter: 0; batch classifier loss: 0.382272; batch adversarial loss: 0.615788\n",
      "epoch 37; iter: 0; batch classifier loss: 0.409360; batch adversarial loss: 0.570421\n",
      "epoch 38; iter: 0; batch classifier loss: 0.497103; batch adversarial loss: 0.570542\n",
      "epoch 39; iter: 0; batch classifier loss: 0.445225; batch adversarial loss: 0.445566\n",
      "epoch 40; iter: 0; batch classifier loss: 0.411661; batch adversarial loss: 0.554014\n",
      "epoch 41; iter: 0; batch classifier loss: 0.454058; batch adversarial loss: 0.534653\n",
      "epoch 42; iter: 0; batch classifier loss: 0.445920; batch adversarial loss: 0.526693\n",
      "epoch 43; iter: 0; batch classifier loss: 0.378265; batch adversarial loss: 0.517913\n",
      "epoch 44; iter: 0; batch classifier loss: 0.560280; batch adversarial loss: 0.517995\n",
      "epoch 45; iter: 0; batch classifier loss: 0.496781; batch adversarial loss: 0.526620\n",
      "epoch 46; iter: 0; batch classifier loss: 0.462372; batch adversarial loss: 0.589862\n",
      "epoch 47; iter: 0; batch classifier loss: 0.366870; batch adversarial loss: 0.572000\n",
      "epoch 48; iter: 0; batch classifier loss: 0.540383; batch adversarial loss: 0.526881\n",
      "epoch 49; iter: 0; batch classifier loss: 0.439208; batch adversarial loss: 0.562252\n",
      "epoch 50; iter: 0; batch classifier loss: 0.471872; batch adversarial loss: 0.553522\n",
      "epoch 51; iter: 0; batch classifier loss: 0.413025; batch adversarial loss: 0.607810\n",
      "epoch 52; iter: 0; batch classifier loss: 0.433851; batch adversarial loss: 0.589715\n",
      "epoch 53; iter: 0; batch classifier loss: 0.435509; batch adversarial loss: 0.553460\n",
      "epoch 54; iter: 0; batch classifier loss: 0.394912; batch adversarial loss: 0.499584\n",
      "epoch 55; iter: 0; batch classifier loss: 0.468887; batch adversarial loss: 0.535729\n",
      "epoch 56; iter: 0; batch classifier loss: 0.414549; batch adversarial loss: 0.517063\n",
      "epoch 57; iter: 0; batch classifier loss: 0.405858; batch adversarial loss: 0.572216\n",
      "epoch 58; iter: 0; batch classifier loss: 0.522359; batch adversarial loss: 0.553670\n",
      "epoch 59; iter: 0; batch classifier loss: 0.440408; batch adversarial loss: 0.508136\n",
      "epoch 60; iter: 0; batch classifier loss: 0.385652; batch adversarial loss: 0.535504\n",
      "epoch 61; iter: 0; batch classifier loss: 0.436738; batch adversarial loss: 0.635292\n",
      "epoch 62; iter: 0; batch classifier loss: 0.403243; batch adversarial loss: 0.544701\n",
      "epoch 63; iter: 0; batch classifier loss: 0.374449; batch adversarial loss: 0.544533\n",
      "epoch 64; iter: 0; batch classifier loss: 0.476678; batch adversarial loss: 0.526783\n",
      "epoch 65; iter: 0; batch classifier loss: 0.422350; batch adversarial loss: 0.580222\n",
      "epoch 66; iter: 0; batch classifier loss: 0.378792; batch adversarial loss: 0.552596\n",
      "epoch 67; iter: 0; batch classifier loss: 0.478906; batch adversarial loss: 0.545290\n",
      "epoch 68; iter: 0; batch classifier loss: 0.308096; batch adversarial loss: 0.588191\n",
      "epoch 69; iter: 0; batch classifier loss: 0.425949; batch adversarial loss: 0.542281\n",
      "epoch 70; iter: 0; batch classifier loss: 0.396515; batch adversarial loss: 0.536056\n",
      "epoch 71; iter: 0; batch classifier loss: 0.311443; batch adversarial loss: 0.471960\n",
      "epoch 72; iter: 0; batch classifier loss: 0.412280; batch adversarial loss: 0.444439\n",
      "epoch 73; iter: 0; batch classifier loss: 0.425612; batch adversarial loss: 0.547474\n",
      "epoch 74; iter: 0; batch classifier loss: 0.452734; batch adversarial loss: 0.521610\n",
      "epoch 75; iter: 0; batch classifier loss: 0.440643; batch adversarial loss: 0.598664\n",
      "epoch 76; iter: 0; batch classifier loss: 0.379553; batch adversarial loss: 0.583639\n",
      "epoch 77; iter: 0; batch classifier loss: 0.351775; batch adversarial loss: 0.508241\n",
      "epoch 78; iter: 0; batch classifier loss: 0.404749; batch adversarial loss: 0.611546\n",
      "epoch 79; iter: 0; batch classifier loss: 0.376184; batch adversarial loss: 0.544232\n",
      "epoch 80; iter: 0; batch classifier loss: 0.451816; batch adversarial loss: 0.647011\n",
      "epoch 81; iter: 0; batch classifier loss: 0.396431; batch adversarial loss: 0.572937\n",
      "epoch 82; iter: 0; batch classifier loss: 0.396456; batch adversarial loss: 0.526334\n",
      "epoch 83; iter: 0; batch classifier loss: 0.468107; batch adversarial loss: 0.507533\n",
      "epoch 84; iter: 0; batch classifier loss: 0.383103; batch adversarial loss: 0.562667\n",
      "epoch 85; iter: 0; batch classifier loss: 0.350436; batch adversarial loss: 0.507800\n",
      "epoch 86; iter: 0; batch classifier loss: 0.337832; batch adversarial loss: 0.553475\n",
      "epoch 87; iter: 0; batch classifier loss: 0.387180; batch adversarial loss: 0.580886\n",
      "epoch 88; iter: 0; batch classifier loss: 0.435480; batch adversarial loss: 0.571651\n",
      "epoch 89; iter: 0; batch classifier loss: 0.374263; batch adversarial loss: 0.554465\n",
      "epoch 90; iter: 0; batch classifier loss: 0.447161; batch adversarial loss: 0.526370\n",
      "epoch 91; iter: 0; batch classifier loss: 0.451480; batch adversarial loss: 0.517179\n",
      "epoch 92; iter: 0; batch classifier loss: 0.451867; batch adversarial loss: 0.499540\n",
      "epoch 93; iter: 0; batch classifier loss: 0.406341; batch adversarial loss: 0.552733\n",
      "epoch 94; iter: 0; batch classifier loss: 0.437411; batch adversarial loss: 0.538219\n",
      "epoch 95; iter: 0; batch classifier loss: 0.446710; batch adversarial loss: 0.555551\n",
      "epoch 96; iter: 0; batch classifier loss: 0.335416; batch adversarial loss: 0.523199\n",
      "epoch 97; iter: 0; batch classifier loss: 0.394938; batch adversarial loss: 0.587075\n",
      "epoch 98; iter: 0; batch classifier loss: 0.406245; batch adversarial loss: 0.451746\n",
      "epoch 99; iter: 0; batch classifier loss: 0.434786; batch adversarial loss: 0.467243\n",
      "epoch 100; iter: 0; batch classifier loss: 0.399230; batch adversarial loss: 0.552964\n",
      "epoch 101; iter: 0; batch classifier loss: 0.422102; batch adversarial loss: 0.537191\n",
      "epoch 102; iter: 0; batch classifier loss: 0.347880; batch adversarial loss: 0.547108\n",
      "epoch 103; iter: 0; batch classifier loss: 0.307066; batch adversarial loss: 0.565818\n",
      "epoch 104; iter: 0; batch classifier loss: 0.382073; batch adversarial loss: 0.461168\n",
      "epoch 105; iter: 0; batch classifier loss: 0.361290; batch adversarial loss: 0.527263\n",
      "epoch 106; iter: 0; batch classifier loss: 0.421691; batch adversarial loss: 0.517881\n",
      "epoch 107; iter: 0; batch classifier loss: 0.401883; batch adversarial loss: 0.536329\n",
      "epoch 108; iter: 0; batch classifier loss: 0.439327; batch adversarial loss: 0.562942\n",
      "epoch 109; iter: 0; batch classifier loss: 0.345152; batch adversarial loss: 0.487670\n",
      "epoch 110; iter: 0; batch classifier loss: 0.391831; batch adversarial loss: 0.637352\n",
      "epoch 111; iter: 0; batch classifier loss: 0.427031; batch adversarial loss: 0.516537\n",
      "epoch 112; iter: 0; batch classifier loss: 0.372038; batch adversarial loss: 0.498139\n",
      "epoch 113; iter: 0; batch classifier loss: 0.396284; batch adversarial loss: 0.516788\n",
      "epoch 114; iter: 0; batch classifier loss: 0.398298; batch adversarial loss: 0.489770\n",
      "epoch 115; iter: 0; batch classifier loss: 0.456245; batch adversarial loss: 0.516669\n",
      "epoch 116; iter: 0; batch classifier loss: 0.386736; batch adversarial loss: 0.608436\n",
      "epoch 117; iter: 0; batch classifier loss: 0.431954; batch adversarial loss: 0.588675\n",
      "epoch 118; iter: 0; batch classifier loss: 0.434234; batch adversarial loss: 0.552618\n",
      "epoch 119; iter: 0; batch classifier loss: 0.424719; batch adversarial loss: 0.555158\n",
      "epoch 120; iter: 0; batch classifier loss: 0.356979; batch adversarial loss: 0.536635\n",
      "epoch 121; iter: 0; batch classifier loss: 0.317012; batch adversarial loss: 0.608218\n",
      "epoch 122; iter: 0; batch classifier loss: 0.417408; batch adversarial loss: 0.552731\n",
      "epoch 123; iter: 0; batch classifier loss: 0.310297; batch adversarial loss: 0.516428\n",
      "epoch 124; iter: 0; batch classifier loss: 0.375558; batch adversarial loss: 0.581088\n",
      "epoch 125; iter: 0; batch classifier loss: 0.392817; batch adversarial loss: 0.570940\n",
      "epoch 126; iter: 0; batch classifier loss: 0.429663; batch adversarial loss: 0.581269\n",
      "epoch 127; iter: 0; batch classifier loss: 0.429436; batch adversarial loss: 0.595832\n",
      "epoch 128; iter: 0; batch classifier loss: 0.332203; batch adversarial loss: 0.536021\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 129; iter: 0; batch classifier loss: 0.355852; batch adversarial loss: 0.545234\n",
      "epoch 130; iter: 0; batch classifier loss: 0.373554; batch adversarial loss: 0.552098\n",
      "epoch 131; iter: 0; batch classifier loss: 0.341279; batch adversarial loss: 0.545116\n",
      "epoch 132; iter: 0; batch classifier loss: 0.376851; batch adversarial loss: 0.510728\n",
      "epoch 133; iter: 0; batch classifier loss: 0.436875; batch adversarial loss: 0.544987\n",
      "epoch 134; iter: 0; batch classifier loss: 0.418618; batch adversarial loss: 0.563538\n",
      "epoch 135; iter: 0; batch classifier loss: 0.438928; batch adversarial loss: 0.498925\n",
      "epoch 136; iter: 0; batch classifier loss: 0.390616; batch adversarial loss: 0.536169\n",
      "epoch 137; iter: 0; batch classifier loss: 0.306592; batch adversarial loss: 0.581008\n",
      "epoch 138; iter: 0; batch classifier loss: 0.408742; batch adversarial loss: 0.544522\n",
      "epoch 139; iter: 0; batch classifier loss: 0.338461; batch adversarial loss: 0.526120\n",
      "epoch 140; iter: 0; batch classifier loss: 0.387333; batch adversarial loss: 0.544618\n",
      "epoch 141; iter: 0; batch classifier loss: 0.311950; batch adversarial loss: 0.572119\n",
      "epoch 142; iter: 0; batch classifier loss: 0.348938; batch adversarial loss: 0.599629\n",
      "epoch 143; iter: 0; batch classifier loss: 0.397149; batch adversarial loss: 0.571995\n",
      "epoch 144; iter: 0; batch classifier loss: 0.342298; batch adversarial loss: 0.544427\n",
      "epoch 145; iter: 0; batch classifier loss: 0.366847; batch adversarial loss: 0.553860\n",
      "epoch 146; iter: 0; batch classifier loss: 0.450435; batch adversarial loss: 0.571617\n",
      "epoch 147; iter: 0; batch classifier loss: 0.400693; batch adversarial loss: 0.517834\n",
      "epoch 148; iter: 0; batch classifier loss: 0.378365; batch adversarial loss: 0.554224\n",
      "epoch 149; iter: 0; batch classifier loss: 0.388441; batch adversarial loss: 0.617498\n",
      "epoch 150; iter: 0; batch classifier loss: 0.389625; batch adversarial loss: 0.489900\n",
      "epoch 151; iter: 0; batch classifier loss: 0.339492; batch adversarial loss: 0.545647\n",
      "epoch 152; iter: 0; batch classifier loss: 0.326802; batch adversarial loss: 0.535581\n",
      "epoch 153; iter: 0; batch classifier loss: 0.360330; batch adversarial loss: 0.590040\n",
      "epoch 154; iter: 0; batch classifier loss: 0.384171; batch adversarial loss: 0.589903\n",
      "epoch 155; iter: 0; batch classifier loss: 0.389414; batch adversarial loss: 0.653697\n",
      "epoch 156; iter: 0; batch classifier loss: 0.344298; batch adversarial loss: 0.535360\n",
      "epoch 157; iter: 0; batch classifier loss: 0.376683; batch adversarial loss: 0.544491\n",
      "epoch 158; iter: 0; batch classifier loss: 0.398596; batch adversarial loss: 0.608029\n",
      "epoch 159; iter: 0; batch classifier loss: 0.334454; batch adversarial loss: 0.554028\n",
      "epoch 160; iter: 0; batch classifier loss: 0.289098; batch adversarial loss: 0.635894\n",
      "epoch 161; iter: 0; batch classifier loss: 0.361370; batch adversarial loss: 0.526507\n",
      "epoch 162; iter: 0; batch classifier loss: 0.339614; batch adversarial loss: 0.536624\n",
      "epoch 163; iter: 0; batch classifier loss: 0.384290; batch adversarial loss: 0.562089\n",
      "epoch 164; iter: 0; batch classifier loss: 0.413936; batch adversarial loss: 0.544761\n",
      "epoch 165; iter: 0; batch classifier loss: 0.358691; batch adversarial loss: 0.552912\n",
      "epoch 166; iter: 0; batch classifier loss: 0.372651; batch adversarial loss: 0.561864\n",
      "epoch 167; iter: 0; batch classifier loss: 0.369449; batch adversarial loss: 0.572448\n",
      "epoch 168; iter: 0; batch classifier loss: 0.335773; batch adversarial loss: 0.581357\n",
      "epoch 169; iter: 0; batch classifier loss: 0.303648; batch adversarial loss: 0.552603\n",
      "epoch 170; iter: 0; batch classifier loss: 0.460137; batch adversarial loss: 0.534951\n",
      "epoch 171; iter: 0; batch classifier loss: 0.315494; batch adversarial loss: 0.580574\n",
      "epoch 172; iter: 0; batch classifier loss: 0.303110; batch adversarial loss: 0.553842\n",
      "epoch 173; iter: 0; batch classifier loss: 0.362012; batch adversarial loss: 0.553776\n",
      "epoch 174; iter: 0; batch classifier loss: 0.392663; batch adversarial loss: 0.571891\n",
      "epoch 175; iter: 0; batch classifier loss: 0.378829; batch adversarial loss: 0.581556\n",
      "epoch 176; iter: 0; batch classifier loss: 0.369403; batch adversarial loss: 0.581448\n",
      "epoch 177; iter: 0; batch classifier loss: 0.327788; batch adversarial loss: 0.545494\n",
      "epoch 178; iter: 0; batch classifier loss: 0.317509; batch adversarial loss: 0.553159\n",
      "epoch 179; iter: 0; batch classifier loss: 0.349369; batch adversarial loss: 0.643211\n",
      "epoch 180; iter: 0; batch classifier loss: 0.356971; batch adversarial loss: 0.580967\n",
      "epoch 181; iter: 0; batch classifier loss: 0.381181; batch adversarial loss: 0.608841\n",
      "epoch 182; iter: 0; batch classifier loss: 0.357074; batch adversarial loss: 0.571520\n",
      "epoch 183; iter: 0; batch classifier loss: 0.288752; batch adversarial loss: 0.572039\n",
      "epoch 184; iter: 0; batch classifier loss: 0.384103; batch adversarial loss: 0.608555\n",
      "epoch 185; iter: 0; batch classifier loss: 0.355763; batch adversarial loss: 0.672564\n",
      "epoch 186; iter: 0; batch classifier loss: 0.403760; batch adversarial loss: 0.544353\n",
      "epoch 187; iter: 0; batch classifier loss: 0.338732; batch adversarial loss: 0.480067\n",
      "epoch 188; iter: 0; batch classifier loss: 0.285386; batch adversarial loss: 0.526576\n",
      "epoch 189; iter: 0; batch classifier loss: 0.261705; batch adversarial loss: 0.517929\n",
      "epoch 190; iter: 0; batch classifier loss: 0.394124; batch adversarial loss: 0.518127\n",
      "epoch 191; iter: 0; batch classifier loss: 0.423388; batch adversarial loss: 0.536205\n",
      "epoch 192; iter: 0; batch classifier loss: 0.358295; batch adversarial loss: 0.471534\n",
      "epoch 193; iter: 0; batch classifier loss: 0.438784; batch adversarial loss: 0.590546\n",
      "epoch 194; iter: 0; batch classifier loss: 0.466162; batch adversarial loss: 0.526010\n",
      "epoch 195; iter: 0; batch classifier loss: 0.350384; batch adversarial loss: 0.490878\n",
      "epoch 196; iter: 0; batch classifier loss: 0.332992; batch adversarial loss: 0.581612\n",
      "epoch 197; iter: 0; batch classifier loss: 0.321624; batch adversarial loss: 0.562187\n",
      "epoch 198; iter: 0; batch classifier loss: 0.348334; batch adversarial loss: 0.553201\n",
      "epoch 199; iter: 0; batch classifier loss: 0.348027; batch adversarial loss: 0.571218\n",
      "epoch 0; iter: 0; batch classifier loss: 0.690092; batch adversarial loss: 0.750304\n",
      "epoch 1; iter: 0; batch classifier loss: 0.777499; batch adversarial loss: 0.753918\n",
      "epoch 2; iter: 0; batch classifier loss: 0.670111; batch adversarial loss: 0.689653\n",
      "epoch 3; iter: 0; batch classifier loss: 0.518185; batch adversarial loss: 0.655846\n",
      "epoch 4; iter: 0; batch classifier loss: 0.532615; batch adversarial loss: 0.639012\n",
      "epoch 5; iter: 0; batch classifier loss: 0.549590; batch adversarial loss: 0.620602\n",
      "epoch 6; iter: 0; batch classifier loss: 0.549513; batch adversarial loss: 0.608388\n",
      "epoch 7; iter: 0; batch classifier loss: 0.566480; batch adversarial loss: 0.580773\n",
      "epoch 8; iter: 0; batch classifier loss: 0.500173; batch adversarial loss: 0.604171\n",
      "epoch 9; iter: 0; batch classifier loss: 0.494401; batch adversarial loss: 0.561313\n",
      "epoch 10; iter: 0; batch classifier loss: 0.563809; batch adversarial loss: 0.575925\n",
      "epoch 11; iter: 0; batch classifier loss: 0.483921; batch adversarial loss: 0.543023\n",
      "epoch 12; iter: 0; batch classifier loss: 0.470269; batch adversarial loss: 0.579844\n",
      "epoch 13; iter: 0; batch classifier loss: 0.586122; batch adversarial loss: 0.527946\n",
      "epoch 14; iter: 0; batch classifier loss: 0.488488; batch adversarial loss: 0.546305\n",
      "epoch 15; iter: 0; batch classifier loss: 0.516857; batch adversarial loss: 0.569008\n",
      "epoch 16; iter: 0; batch classifier loss: 0.463746; batch adversarial loss: 0.595701\n",
      "epoch 17; iter: 0; batch classifier loss: 0.562034; batch adversarial loss: 0.529564\n",
      "epoch 18; iter: 0; batch classifier loss: 0.513110; batch adversarial loss: 0.541330\n",
      "epoch 19; iter: 0; batch classifier loss: 0.481683; batch adversarial loss: 0.586513\n",
      "epoch 20; iter: 0; batch classifier loss: 0.475827; batch adversarial loss: 0.523351\n",
      "epoch 21; iter: 0; batch classifier loss: 0.532655; batch adversarial loss: 0.539669\n",
      "epoch 22; iter: 0; batch classifier loss: 0.521158; batch adversarial loss: 0.534874\n",
      "epoch 23; iter: 0; batch classifier loss: 0.379726; batch adversarial loss: 0.548570\n",
      "epoch 24; iter: 0; batch classifier loss: 0.503832; batch adversarial loss: 0.630414\n",
      "epoch 25; iter: 0; batch classifier loss: 0.491003; batch adversarial loss: 0.522965\n",
      "epoch 26; iter: 0; batch classifier loss: 0.425546; batch adversarial loss: 0.494005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 27; iter: 0; batch classifier loss: 0.486350; batch adversarial loss: 0.593914\n",
      "epoch 28; iter: 0; batch classifier loss: 0.431177; batch adversarial loss: 0.550483\n",
      "epoch 29; iter: 0; batch classifier loss: 0.460197; batch adversarial loss: 0.579580\n",
      "epoch 30; iter: 0; batch classifier loss: 0.401905; batch adversarial loss: 0.566004\n",
      "epoch 31; iter: 0; batch classifier loss: 0.452770; batch adversarial loss: 0.622736\n",
      "epoch 32; iter: 0; batch classifier loss: 0.409911; batch adversarial loss: 0.546982\n",
      "epoch 33; iter: 0; batch classifier loss: 0.397698; batch adversarial loss: 0.548813\n",
      "epoch 34; iter: 0; batch classifier loss: 0.429147; batch adversarial loss: 0.598835\n",
      "epoch 35; iter: 0; batch classifier loss: 0.421939; batch adversarial loss: 0.551061\n",
      "epoch 36; iter: 0; batch classifier loss: 0.490690; batch adversarial loss: 0.469899\n",
      "epoch 37; iter: 0; batch classifier loss: 0.409214; batch adversarial loss: 0.592883\n",
      "epoch 38; iter: 0; batch classifier loss: 0.475357; batch adversarial loss: 0.527386\n",
      "epoch 39; iter: 0; batch classifier loss: 0.419764; batch adversarial loss: 0.528404\n",
      "epoch 40; iter: 0; batch classifier loss: 0.490024; batch adversarial loss: 0.496223\n",
      "epoch 41; iter: 0; batch classifier loss: 0.472238; batch adversarial loss: 0.588197\n",
      "epoch 42; iter: 0; batch classifier loss: 0.412702; batch adversarial loss: 0.525278\n",
      "epoch 43; iter: 0; batch classifier loss: 0.463036; batch adversarial loss: 0.507695\n",
      "epoch 44; iter: 0; batch classifier loss: 0.433340; batch adversarial loss: 0.548982\n",
      "epoch 45; iter: 0; batch classifier loss: 0.364016; batch adversarial loss: 0.551812\n",
      "epoch 46; iter: 0; batch classifier loss: 0.355387; batch adversarial loss: 0.517391\n",
      "epoch 47; iter: 0; batch classifier loss: 0.364249; batch adversarial loss: 0.661787\n",
      "epoch 48; iter: 0; batch classifier loss: 0.338758; batch adversarial loss: 0.498264\n",
      "epoch 49; iter: 0; batch classifier loss: 0.445996; batch adversarial loss: 0.566689\n",
      "epoch 50; iter: 0; batch classifier loss: 0.417452; batch adversarial loss: 0.498857\n",
      "epoch 51; iter: 0; batch classifier loss: 0.433590; batch adversarial loss: 0.635718\n",
      "epoch 52; iter: 0; batch classifier loss: 0.475555; batch adversarial loss: 0.563862\n",
      "epoch 53; iter: 0; batch classifier loss: 0.512183; batch adversarial loss: 0.506358\n",
      "epoch 54; iter: 0; batch classifier loss: 0.432876; batch adversarial loss: 0.534214\n",
      "epoch 55; iter: 0; batch classifier loss: 0.359590; batch adversarial loss: 0.536083\n",
      "epoch 56; iter: 0; batch classifier loss: 0.467616; batch adversarial loss: 0.563147\n",
      "epoch 57; iter: 0; batch classifier loss: 0.483451; batch adversarial loss: 0.564072\n",
      "epoch 58; iter: 0; batch classifier loss: 0.350212; batch adversarial loss: 0.519237\n",
      "epoch 59; iter: 0; batch classifier loss: 0.415225; batch adversarial loss: 0.589043\n",
      "epoch 60; iter: 0; batch classifier loss: 0.376496; batch adversarial loss: 0.527258\n",
      "epoch 61; iter: 0; batch classifier loss: 0.461724; batch adversarial loss: 0.570997\n",
      "epoch 62; iter: 0; batch classifier loss: 0.442489; batch adversarial loss: 0.608152\n",
      "epoch 63; iter: 0; batch classifier loss: 0.419558; batch adversarial loss: 0.580229\n",
      "epoch 64; iter: 0; batch classifier loss: 0.463911; batch adversarial loss: 0.571496\n",
      "epoch 65; iter: 0; batch classifier loss: 0.414485; batch adversarial loss: 0.526059\n",
      "epoch 66; iter: 0; batch classifier loss: 0.377498; batch adversarial loss: 0.516684\n",
      "epoch 67; iter: 0; batch classifier loss: 0.465226; batch adversarial loss: 0.590021\n",
      "epoch 68; iter: 0; batch classifier loss: 0.463450; batch adversarial loss: 0.526305\n",
      "epoch 69; iter: 0; batch classifier loss: 0.353680; batch adversarial loss: 0.497336\n",
      "epoch 70; iter: 0; batch classifier loss: 0.487384; batch adversarial loss: 0.489208\n",
      "epoch 71; iter: 0; batch classifier loss: 0.445762; batch adversarial loss: 0.552955\n",
      "epoch 72; iter: 0; batch classifier loss: 0.392917; batch adversarial loss: 0.544536\n",
      "epoch 73; iter: 0; batch classifier loss: 0.450054; batch adversarial loss: 0.591411\n",
      "epoch 74; iter: 0; batch classifier loss: 0.413426; batch adversarial loss: 0.516747\n",
      "epoch 75; iter: 0; batch classifier loss: 0.418204; batch adversarial loss: 0.508837\n",
      "epoch 76; iter: 0; batch classifier loss: 0.355376; batch adversarial loss: 0.526349\n",
      "epoch 77; iter: 0; batch classifier loss: 0.442162; batch adversarial loss: 0.490358\n",
      "epoch 78; iter: 0; batch classifier loss: 0.452623; batch adversarial loss: 0.598729\n",
      "epoch 79; iter: 0; batch classifier loss: 0.382625; batch adversarial loss: 0.646112\n",
      "epoch 80; iter: 0; batch classifier loss: 0.437862; batch adversarial loss: 0.516934\n",
      "epoch 81; iter: 0; batch classifier loss: 0.419617; batch adversarial loss: 0.480148\n",
      "epoch 82; iter: 0; batch classifier loss: 0.372371; batch adversarial loss: 0.582118\n",
      "epoch 83; iter: 0; batch classifier loss: 0.448274; batch adversarial loss: 0.526432\n",
      "epoch 84; iter: 0; batch classifier loss: 0.402341; batch adversarial loss: 0.553786\n",
      "epoch 85; iter: 0; batch classifier loss: 0.347625; batch adversarial loss: 0.544788\n",
      "epoch 86; iter: 0; batch classifier loss: 0.349079; batch adversarial loss: 0.516582\n",
      "epoch 87; iter: 0; batch classifier loss: 0.477626; batch adversarial loss: 0.572870\n",
      "epoch 88; iter: 0; batch classifier loss: 0.415657; batch adversarial loss: 0.571869\n",
      "epoch 89; iter: 0; batch classifier loss: 0.438288; batch adversarial loss: 0.527297\n",
      "epoch 90; iter: 0; batch classifier loss: 0.439381; batch adversarial loss: 0.626399\n",
      "epoch 91; iter: 0; batch classifier loss: 0.428685; batch adversarial loss: 0.525813\n",
      "epoch 92; iter: 0; batch classifier loss: 0.439240; batch adversarial loss: 0.563385\n",
      "epoch 93; iter: 0; batch classifier loss: 0.381761; batch adversarial loss: 0.535110\n",
      "epoch 94; iter: 0; batch classifier loss: 0.384673; batch adversarial loss: 0.637124\n",
      "epoch 95; iter: 0; batch classifier loss: 0.411236; batch adversarial loss: 0.535437\n",
      "epoch 96; iter: 0; batch classifier loss: 0.405544; batch adversarial loss: 0.544186\n",
      "epoch 97; iter: 0; batch classifier loss: 0.384868; batch adversarial loss: 0.525782\n",
      "epoch 98; iter: 0; batch classifier loss: 0.357331; batch adversarial loss: 0.535309\n",
      "epoch 99; iter: 0; batch classifier loss: 0.428825; batch adversarial loss: 0.655089\n",
      "epoch 100; iter: 0; batch classifier loss: 0.358234; batch adversarial loss: 0.516722\n",
      "epoch 101; iter: 0; batch classifier loss: 0.341329; batch adversarial loss: 0.525621\n",
      "epoch 102; iter: 0; batch classifier loss: 0.380006; batch adversarial loss: 0.526052\n",
      "epoch 103; iter: 0; batch classifier loss: 0.396122; batch adversarial loss: 0.573296\n",
      "epoch 104; iter: 0; batch classifier loss: 0.417610; batch adversarial loss: 0.544695\n",
      "epoch 105; iter: 0; batch classifier loss: 0.327418; batch adversarial loss: 0.498575\n",
      "epoch 106; iter: 0; batch classifier loss: 0.395761; batch adversarial loss: 0.507470\n",
      "epoch 107; iter: 0; batch classifier loss: 0.449286; batch adversarial loss: 0.544976\n",
      "epoch 108; iter: 0; batch classifier loss: 0.336543; batch adversarial loss: 0.497641\n",
      "epoch 109; iter: 0; batch classifier loss: 0.337323; batch adversarial loss: 0.535132\n",
      "epoch 110; iter: 0; batch classifier loss: 0.352196; batch adversarial loss: 0.533796\n",
      "epoch 111; iter: 0; batch classifier loss: 0.368960; batch adversarial loss: 0.551813\n",
      "epoch 112; iter: 0; batch classifier loss: 0.389701; batch adversarial loss: 0.544626\n",
      "epoch 113; iter: 0; batch classifier loss: 0.480128; batch adversarial loss: 0.527244\n",
      "epoch 114; iter: 0; batch classifier loss: 0.354796; batch adversarial loss: 0.526578\n",
      "epoch 115; iter: 0; batch classifier loss: 0.343487; batch adversarial loss: 0.562262\n",
      "epoch 116; iter: 0; batch classifier loss: 0.371071; batch adversarial loss: 0.590021\n",
      "epoch 117; iter: 0; batch classifier loss: 0.368026; batch adversarial loss: 0.517205\n",
      "epoch 118; iter: 0; batch classifier loss: 0.352108; batch adversarial loss: 0.544953\n",
      "epoch 119; iter: 0; batch classifier loss: 0.383332; batch adversarial loss: 0.463407\n",
      "epoch 120; iter: 0; batch classifier loss: 0.331613; batch adversarial loss: 0.507465\n",
      "epoch 121; iter: 0; batch classifier loss: 0.385989; batch adversarial loss: 0.571840\n",
      "epoch 122; iter: 0; batch classifier loss: 0.413361; batch adversarial loss: 0.553312\n",
      "epoch 123; iter: 0; batch classifier loss: 0.408598; batch adversarial loss: 0.526307\n",
      "epoch 124; iter: 0; batch classifier loss: 0.398277; batch adversarial loss: 0.535055\n",
      "epoch 125; iter: 0; batch classifier loss: 0.374351; batch adversarial loss: 0.545208\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 126; iter: 0; batch classifier loss: 0.358263; batch adversarial loss: 0.508043\n",
      "epoch 127; iter: 0; batch classifier loss: 0.485153; batch adversarial loss: 0.543765\n",
      "epoch 128; iter: 0; batch classifier loss: 0.309287; batch adversarial loss: 0.620096\n",
      "epoch 129; iter: 0; batch classifier loss: 0.348476; batch adversarial loss: 0.582713\n",
      "epoch 130; iter: 0; batch classifier loss: 0.304952; batch adversarial loss: 0.534515\n",
      "epoch 131; iter: 0; batch classifier loss: 0.394830; batch adversarial loss: 0.590273\n",
      "epoch 132; iter: 0; batch classifier loss: 0.396206; batch adversarial loss: 0.491173\n",
      "epoch 133; iter: 0; batch classifier loss: 0.339496; batch adversarial loss: 0.654545\n",
      "epoch 134; iter: 0; batch classifier loss: 0.303462; batch adversarial loss: 0.535526\n",
      "epoch 135; iter: 0; batch classifier loss: 0.319115; batch adversarial loss: 0.562630\n",
      "epoch 136; iter: 0; batch classifier loss: 0.410035; batch adversarial loss: 0.518565\n",
      "epoch 137; iter: 0; batch classifier loss: 0.400450; batch adversarial loss: 0.562908\n",
      "epoch 138; iter: 0; batch classifier loss: 0.360964; batch adversarial loss: 0.562314\n",
      "epoch 139; iter: 0; batch classifier loss: 0.365877; batch adversarial loss: 0.544587\n",
      "epoch 140; iter: 0; batch classifier loss: 0.367257; batch adversarial loss: 0.619009\n",
      "epoch 141; iter: 0; batch classifier loss: 0.434840; batch adversarial loss: 0.581289\n",
      "epoch 142; iter: 0; batch classifier loss: 0.413064; batch adversarial loss: 0.563036\n",
      "epoch 143; iter: 0; batch classifier loss: 0.308480; batch adversarial loss: 0.572411\n",
      "epoch 144; iter: 0; batch classifier loss: 0.371852; batch adversarial loss: 0.543504\n",
      "epoch 145; iter: 0; batch classifier loss: 0.353107; batch adversarial loss: 0.579681\n",
      "epoch 146; iter: 0; batch classifier loss: 0.360095; batch adversarial loss: 0.562145\n",
      "epoch 147; iter: 0; batch classifier loss: 0.354747; batch adversarial loss: 0.581095\n",
      "epoch 148; iter: 0; batch classifier loss: 0.365566; batch adversarial loss: 0.573943\n",
      "epoch 149; iter: 0; batch classifier loss: 0.335819; batch adversarial loss: 0.572860\n",
      "epoch 150; iter: 0; batch classifier loss: 0.376970; batch adversarial loss: 0.553577\n",
      "epoch 151; iter: 0; batch classifier loss: 0.316127; batch adversarial loss: 0.508213\n",
      "epoch 152; iter: 0; batch classifier loss: 0.303320; batch adversarial loss: 0.534839\n",
      "epoch 153; iter: 0; batch classifier loss: 0.343140; batch adversarial loss: 0.571886\n",
      "epoch 154; iter: 0; batch classifier loss: 0.425872; batch adversarial loss: 0.608218\n",
      "epoch 155; iter: 0; batch classifier loss: 0.323849; batch adversarial loss: 0.573378\n",
      "epoch 156; iter: 0; batch classifier loss: 0.329240; batch adversarial loss: 0.544572\n",
      "epoch 157; iter: 0; batch classifier loss: 0.346202; batch adversarial loss: 0.472049\n",
      "epoch 158; iter: 0; batch classifier loss: 0.362603; batch adversarial loss: 0.571261\n",
      "epoch 159; iter: 0; batch classifier loss: 0.332770; batch adversarial loss: 0.591245\n",
      "epoch 160; iter: 0; batch classifier loss: 0.360787; batch adversarial loss: 0.563305\n",
      "epoch 161; iter: 0; batch classifier loss: 0.380448; batch adversarial loss: 0.534279\n",
      "epoch 162; iter: 0; batch classifier loss: 0.327657; batch adversarial loss: 0.433236\n",
      "epoch 163; iter: 0; batch classifier loss: 0.380372; batch adversarial loss: 0.562788\n",
      "epoch 164; iter: 0; batch classifier loss: 0.305645; batch adversarial loss: 0.555219\n",
      "epoch 165; iter: 0; batch classifier loss: 0.364488; batch adversarial loss: 0.507895\n",
      "epoch 166; iter: 0; batch classifier loss: 0.323756; batch adversarial loss: 0.507727\n",
      "epoch 167; iter: 0; batch classifier loss: 0.383115; batch adversarial loss: 0.562701\n",
      "epoch 168; iter: 0; batch classifier loss: 0.271640; batch adversarial loss: 0.572273\n",
      "epoch 169; iter: 0; batch classifier loss: 0.384615; batch adversarial loss: 0.590762\n",
      "epoch 170; iter: 0; batch classifier loss: 0.297403; batch adversarial loss: 0.553842\n",
      "epoch 171; iter: 0; batch classifier loss: 0.365168; batch adversarial loss: 0.553578\n",
      "epoch 172; iter: 0; batch classifier loss: 0.335061; batch adversarial loss: 0.471051\n",
      "epoch 173; iter: 0; batch classifier loss: 0.388129; batch adversarial loss: 0.535626\n",
      "epoch 174; iter: 0; batch classifier loss: 0.371781; batch adversarial loss: 0.488719\n",
      "epoch 175; iter: 0; batch classifier loss: 0.322890; batch adversarial loss: 0.515474\n",
      "epoch 176; iter: 0; batch classifier loss: 0.376537; batch adversarial loss: 0.452270\n",
      "epoch 177; iter: 0; batch classifier loss: 0.307072; batch adversarial loss: 0.562758\n",
      "epoch 178; iter: 0; batch classifier loss: 0.354572; batch adversarial loss: 0.534995\n",
      "epoch 179; iter: 0; batch classifier loss: 0.389576; batch adversarial loss: 0.517296\n",
      "epoch 180; iter: 0; batch classifier loss: 0.444952; batch adversarial loss: 0.543456\n",
      "epoch 181; iter: 0; batch classifier loss: 0.374862; batch adversarial loss: 0.562673\n",
      "epoch 182; iter: 0; batch classifier loss: 0.414651; batch adversarial loss: 0.600280\n",
      "epoch 183; iter: 0; batch classifier loss: 0.348061; batch adversarial loss: 0.616705\n",
      "epoch 184; iter: 0; batch classifier loss: 0.366512; batch adversarial loss: 0.507196\n",
      "epoch 185; iter: 0; batch classifier loss: 0.425759; batch adversarial loss: 0.618572\n",
      "epoch 186; iter: 0; batch classifier loss: 0.318046; batch adversarial loss: 0.424172\n",
      "epoch 187; iter: 0; batch classifier loss: 0.281751; batch adversarial loss: 0.535504\n",
      "epoch 188; iter: 0; batch classifier loss: 0.386445; batch adversarial loss: 0.606700\n",
      "epoch 189; iter: 0; batch classifier loss: 0.352491; batch adversarial loss: 0.535425\n",
      "epoch 190; iter: 0; batch classifier loss: 0.332669; batch adversarial loss: 0.508864\n",
      "epoch 191; iter: 0; batch classifier loss: 0.404891; batch adversarial loss: 0.599136\n",
      "epoch 192; iter: 0; batch classifier loss: 0.285926; batch adversarial loss: 0.627063\n",
      "epoch 193; iter: 0; batch classifier loss: 0.309571; batch adversarial loss: 0.579596\n",
      "epoch 194; iter: 0; batch classifier loss: 0.408996; batch adversarial loss: 0.543463\n",
      "epoch 195; iter: 0; batch classifier loss: 0.312799; batch adversarial loss: 0.479233\n",
      "epoch 196; iter: 0; batch classifier loss: 0.427509; batch adversarial loss: 0.563872\n",
      "epoch 197; iter: 0; batch classifier loss: 0.372118; batch adversarial loss: 0.515620\n",
      "epoch 198; iter: 0; batch classifier loss: 0.366698; batch adversarial loss: 0.543004\n",
      "epoch 199; iter: 0; batch classifier loss: 0.380361; batch adversarial loss: 0.424264\n",
      "epoch 0; iter: 0; batch classifier loss: 0.686303; batch adversarial loss: 0.664861\n",
      "epoch 1; iter: 0; batch classifier loss: 0.489658; batch adversarial loss: 0.646946\n",
      "epoch 2; iter: 0; batch classifier loss: 0.475689; batch adversarial loss: 0.659055\n",
      "epoch 3; iter: 0; batch classifier loss: 0.509083; batch adversarial loss: 0.599529\n",
      "epoch 4; iter: 0; batch classifier loss: 0.607240; batch adversarial loss: 0.611547\n",
      "epoch 5; iter: 0; batch classifier loss: 0.514636; batch adversarial loss: 0.608773\n",
      "epoch 6; iter: 0; batch classifier loss: 0.453675; batch adversarial loss: 0.614916\n",
      "epoch 7; iter: 0; batch classifier loss: 0.552764; batch adversarial loss: 0.598325\n",
      "epoch 8; iter: 0; batch classifier loss: 0.534997; batch adversarial loss: 0.604968\n",
      "epoch 9; iter: 0; batch classifier loss: 0.576816; batch adversarial loss: 0.606140\n",
      "epoch 10; iter: 0; batch classifier loss: 0.503585; batch adversarial loss: 0.566950\n",
      "epoch 11; iter: 0; batch classifier loss: 0.557949; batch adversarial loss: 0.599819\n",
      "epoch 12; iter: 0; batch classifier loss: 0.570314; batch adversarial loss: 0.612922\n",
      "epoch 13; iter: 0; batch classifier loss: 0.493426; batch adversarial loss: 0.597115\n",
      "epoch 14; iter: 0; batch classifier loss: 0.504156; batch adversarial loss: 0.571936\n",
      "epoch 15; iter: 0; batch classifier loss: 0.479770; batch adversarial loss: 0.668476\n",
      "epoch 16; iter: 0; batch classifier loss: 0.459703; batch adversarial loss: 0.607505\n",
      "epoch 17; iter: 0; batch classifier loss: 0.524671; batch adversarial loss: 0.535384\n",
      "epoch 18; iter: 0; batch classifier loss: 0.462227; batch adversarial loss: 0.526684\n",
      "epoch 19; iter: 0; batch classifier loss: 0.537904; batch adversarial loss: 0.625286\n",
      "epoch 20; iter: 0; batch classifier loss: 0.478345; batch adversarial loss: 0.517908\n",
      "epoch 21; iter: 0; batch classifier loss: 0.474727; batch adversarial loss: 0.608351\n",
      "epoch 22; iter: 0; batch classifier loss: 0.472352; batch adversarial loss: 0.509390\n",
      "epoch 23; iter: 0; batch classifier loss: 0.566281; batch adversarial loss: 0.526033\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 24; iter: 0; batch classifier loss: 0.450590; batch adversarial loss: 0.559224\n",
      "epoch 25; iter: 0; batch classifier loss: 0.478055; batch adversarial loss: 0.587192\n",
      "epoch 26; iter: 0; batch classifier loss: 0.390107; batch adversarial loss: 0.586158\n",
      "epoch 27; iter: 0; batch classifier loss: 0.441156; batch adversarial loss: 0.596238\n",
      "epoch 28; iter: 0; batch classifier loss: 0.512404; batch adversarial loss: 0.522483\n",
      "epoch 29; iter: 0; batch classifier loss: 0.453729; batch adversarial loss: 0.623932\n",
      "epoch 30; iter: 0; batch classifier loss: 0.456149; batch adversarial loss: 0.580783\n",
      "epoch 31; iter: 0; batch classifier loss: 0.472564; batch adversarial loss: 0.578741\n",
      "epoch 32; iter: 0; batch classifier loss: 0.398157; batch adversarial loss: 0.646813\n",
      "epoch 33; iter: 0; batch classifier loss: 0.473706; batch adversarial loss: 0.605650\n",
      "epoch 34; iter: 0; batch classifier loss: 0.387225; batch adversarial loss: 0.545738\n",
      "epoch 35; iter: 0; batch classifier loss: 0.460176; batch adversarial loss: 0.552687\n",
      "epoch 36; iter: 0; batch classifier loss: 0.441203; batch adversarial loss: 0.518704\n",
      "epoch 37; iter: 0; batch classifier loss: 0.438352; batch adversarial loss: 0.474739\n",
      "epoch 38; iter: 0; batch classifier loss: 0.488445; batch adversarial loss: 0.588890\n",
      "epoch 39; iter: 0; batch classifier loss: 0.404449; batch adversarial loss: 0.580010\n",
      "epoch 40; iter: 0; batch classifier loss: 0.435049; batch adversarial loss: 0.553641\n",
      "epoch 41; iter: 0; batch classifier loss: 0.444242; batch adversarial loss: 0.633768\n",
      "epoch 42; iter: 0; batch classifier loss: 0.422445; batch adversarial loss: 0.562531\n",
      "epoch 43; iter: 0; batch classifier loss: 0.507322; batch adversarial loss: 0.562359\n",
      "epoch 44; iter: 0; batch classifier loss: 0.417104; batch adversarial loss: 0.553657\n",
      "epoch 45; iter: 0; batch classifier loss: 0.488960; batch adversarial loss: 0.517726\n",
      "epoch 46; iter: 0; batch classifier loss: 0.455848; batch adversarial loss: 0.527295\n",
      "epoch 47; iter: 0; batch classifier loss: 0.465978; batch adversarial loss: 0.536530\n",
      "epoch 48; iter: 0; batch classifier loss: 0.410110; batch adversarial loss: 0.553621\n",
      "epoch 49; iter: 0; batch classifier loss: 0.520274; batch adversarial loss: 0.499542\n",
      "epoch 50; iter: 0; batch classifier loss: 0.394411; batch adversarial loss: 0.535829\n",
      "epoch 51; iter: 0; batch classifier loss: 0.471145; batch adversarial loss: 0.606950\n",
      "epoch 52; iter: 0; batch classifier loss: 0.438379; batch adversarial loss: 0.517877\n",
      "epoch 53; iter: 0; batch classifier loss: 0.413409; batch adversarial loss: 0.509367\n",
      "epoch 54; iter: 0; batch classifier loss: 0.449634; batch adversarial loss: 0.544373\n",
      "epoch 55; iter: 0; batch classifier loss: 0.489237; batch adversarial loss: 0.562211\n",
      "epoch 56; iter: 0; batch classifier loss: 0.447807; batch adversarial loss: 0.535751\n",
      "epoch 57; iter: 0; batch classifier loss: 0.428597; batch adversarial loss: 0.598785\n",
      "epoch 58; iter: 0; batch classifier loss: 0.411868; batch adversarial loss: 0.544187\n",
      "epoch 59; iter: 0; batch classifier loss: 0.407841; batch adversarial loss: 0.518044\n",
      "epoch 60; iter: 0; batch classifier loss: 0.424968; batch adversarial loss: 0.571772\n",
      "epoch 61; iter: 0; batch classifier loss: 0.386050; batch adversarial loss: 0.607864\n",
      "epoch 62; iter: 0; batch classifier loss: 0.368336; batch adversarial loss: 0.615087\n",
      "epoch 63; iter: 0; batch classifier loss: 0.395526; batch adversarial loss: 0.597591\n",
      "epoch 64; iter: 0; batch classifier loss: 0.329706; batch adversarial loss: 0.516355\n",
      "epoch 65; iter: 0; batch classifier loss: 0.408665; batch adversarial loss: 0.544294\n",
      "epoch 66; iter: 0; batch classifier loss: 0.459170; batch adversarial loss: 0.571539\n",
      "epoch 67; iter: 0; batch classifier loss: 0.387738; batch adversarial loss: 0.544904\n",
      "epoch 68; iter: 0; batch classifier loss: 0.362413; batch adversarial loss: 0.472571\n",
      "epoch 69; iter: 0; batch classifier loss: 0.386822; batch adversarial loss: 0.542958\n",
      "epoch 70; iter: 0; batch classifier loss: 0.431185; batch adversarial loss: 0.545667\n",
      "epoch 71; iter: 0; batch classifier loss: 0.378387; batch adversarial loss: 0.570553\n",
      "epoch 72; iter: 0; batch classifier loss: 0.427168; batch adversarial loss: 0.482399\n",
      "epoch 73; iter: 0; batch classifier loss: 0.349118; batch adversarial loss: 0.580956\n",
      "epoch 74; iter: 0; batch classifier loss: 0.405267; batch adversarial loss: 0.535844\n",
      "epoch 75; iter: 0; batch classifier loss: 0.387625; batch adversarial loss: 0.526720\n",
      "epoch 76; iter: 0; batch classifier loss: 0.416860; batch adversarial loss: 0.562131\n",
      "epoch 77; iter: 0; batch classifier loss: 0.488905; batch adversarial loss: 0.562373\n",
      "epoch 78; iter: 0; batch classifier loss: 0.263296; batch adversarial loss: 0.544627\n",
      "epoch 79; iter: 0; batch classifier loss: 0.413850; batch adversarial loss: 0.544159\n",
      "epoch 80; iter: 0; batch classifier loss: 0.424020; batch adversarial loss: 0.509427\n",
      "epoch 81; iter: 0; batch classifier loss: 0.392112; batch adversarial loss: 0.535216\n",
      "epoch 82; iter: 0; batch classifier loss: 0.429312; batch adversarial loss: 0.535045\n",
      "epoch 83; iter: 0; batch classifier loss: 0.387246; batch adversarial loss: 0.571600\n",
      "epoch 84; iter: 0; batch classifier loss: 0.430705; batch adversarial loss: 0.580361\n",
      "epoch 85; iter: 0; batch classifier loss: 0.306102; batch adversarial loss: 0.535693\n",
      "epoch 86; iter: 0; batch classifier loss: 0.382826; batch adversarial loss: 0.588429\n",
      "epoch 87; iter: 0; batch classifier loss: 0.426889; batch adversarial loss: 0.544850\n",
      "epoch 88; iter: 0; batch classifier loss: 0.265874; batch adversarial loss: 0.526829\n",
      "epoch 89; iter: 0; batch classifier loss: 0.363558; batch adversarial loss: 0.517148\n",
      "epoch 90; iter: 0; batch classifier loss: 0.435730; batch adversarial loss: 0.500811\n",
      "epoch 91; iter: 0; batch classifier loss: 0.408391; batch adversarial loss: 0.544203\n",
      "epoch 92; iter: 0; batch classifier loss: 0.339473; batch adversarial loss: 0.554058\n",
      "epoch 93; iter: 0; batch classifier loss: 0.361930; batch adversarial loss: 0.490585\n",
      "epoch 94; iter: 0; batch classifier loss: 0.338883; batch adversarial loss: 0.580629\n",
      "epoch 95; iter: 0; batch classifier loss: 0.392032; batch adversarial loss: 0.569954\n",
      "epoch 96; iter: 0; batch classifier loss: 0.384368; batch adversarial loss: 0.508304\n",
      "epoch 97; iter: 0; batch classifier loss: 0.416832; batch adversarial loss: 0.554084\n",
      "epoch 98; iter: 0; batch classifier loss: 0.343905; batch adversarial loss: 0.552367\n",
      "epoch 99; iter: 0; batch classifier loss: 0.363035; batch adversarial loss: 0.536755\n",
      "epoch 100; iter: 0; batch classifier loss: 0.351711; batch adversarial loss: 0.518703\n",
      "epoch 101; iter: 0; batch classifier loss: 0.417733; batch adversarial loss: 0.588496\n",
      "epoch 102; iter: 0; batch classifier loss: 0.485538; batch adversarial loss: 0.624612\n",
      "epoch 103; iter: 0; batch classifier loss: 0.405923; batch adversarial loss: 0.554000\n",
      "epoch 104; iter: 0; batch classifier loss: 0.287411; batch adversarial loss: 0.598160\n",
      "epoch 105; iter: 0; batch classifier loss: 0.332129; batch adversarial loss: 0.516811\n",
      "epoch 106; iter: 0; batch classifier loss: 0.417560; batch adversarial loss: 0.543845\n",
      "epoch 107; iter: 0; batch classifier loss: 0.319257; batch adversarial loss: 0.544921\n",
      "epoch 108; iter: 0; batch classifier loss: 0.404729; batch adversarial loss: 0.544566\n",
      "epoch 109; iter: 0; batch classifier loss: 0.376050; batch adversarial loss: 0.608208\n",
      "epoch 110; iter: 0; batch classifier loss: 0.420458; batch adversarial loss: 0.632584\n",
      "epoch 111; iter: 0; batch classifier loss: 0.463583; batch adversarial loss: 0.526029\n",
      "epoch 112; iter: 0; batch classifier loss: 0.371315; batch adversarial loss: 0.508364\n",
      "epoch 113; iter: 0; batch classifier loss: 0.414653; batch adversarial loss: 0.536138\n",
      "epoch 114; iter: 0; batch classifier loss: 0.424351; batch adversarial loss: 0.615986\n",
      "epoch 115; iter: 0; batch classifier loss: 0.357201; batch adversarial loss: 0.616044\n",
      "epoch 116; iter: 0; batch classifier loss: 0.328681; batch adversarial loss: 0.499835\n",
      "epoch 117; iter: 0; batch classifier loss: 0.317027; batch adversarial loss: 0.509233\n",
      "epoch 118; iter: 0; batch classifier loss: 0.414842; batch adversarial loss: 0.569756\n",
      "epoch 119; iter: 0; batch classifier loss: 0.470809; batch adversarial loss: 0.562194\n",
      "epoch 120; iter: 0; batch classifier loss: 0.361075; batch adversarial loss: 0.491532\n",
      "epoch 121; iter: 0; batch classifier loss: 0.387097; batch adversarial loss: 0.563122\n",
      "epoch 122; iter: 0; batch classifier loss: 0.378972; batch adversarial loss: 0.608372\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 123; iter: 0; batch classifier loss: 0.357619; batch adversarial loss: 0.545553\n",
      "epoch 124; iter: 0; batch classifier loss: 0.340474; batch adversarial loss: 0.553956\n",
      "epoch 125; iter: 0; batch classifier loss: 0.370110; batch adversarial loss: 0.526428\n",
      "epoch 126; iter: 0; batch classifier loss: 0.373576; batch adversarial loss: 0.507503\n",
      "epoch 127; iter: 0; batch classifier loss: 0.346447; batch adversarial loss: 0.642979\n",
      "epoch 128; iter: 0; batch classifier loss: 0.344416; batch adversarial loss: 0.509665\n",
      "epoch 129; iter: 0; batch classifier loss: 0.322846; batch adversarial loss: 0.490942\n",
      "epoch 130; iter: 0; batch classifier loss: 0.402107; batch adversarial loss: 0.527535\n",
      "epoch 131; iter: 0; batch classifier loss: 0.379564; batch adversarial loss: 0.582009\n",
      "epoch 132; iter: 0; batch classifier loss: 0.450696; batch adversarial loss: 0.509867\n",
      "epoch 133; iter: 0; batch classifier loss: 0.396526; batch adversarial loss: 0.463759\n",
      "epoch 134; iter: 0; batch classifier loss: 0.276696; batch adversarial loss: 0.562579\n",
      "epoch 135; iter: 0; batch classifier loss: 0.365248; batch adversarial loss: 0.608002\n",
      "epoch 136; iter: 0; batch classifier loss: 0.295692; batch adversarial loss: 0.517402\n",
      "epoch 137; iter: 0; batch classifier loss: 0.372347; batch adversarial loss: 0.544863\n",
      "epoch 138; iter: 0; batch classifier loss: 0.420510; batch adversarial loss: 0.580131\n",
      "epoch 139; iter: 0; batch classifier loss: 0.381320; batch adversarial loss: 0.597863\n",
      "epoch 140; iter: 0; batch classifier loss: 0.358195; batch adversarial loss: 0.543867\n",
      "epoch 141; iter: 0; batch classifier loss: 0.302972; batch adversarial loss: 0.552964\n",
      "epoch 142; iter: 0; batch classifier loss: 0.344579; batch adversarial loss: 0.625615\n",
      "epoch 143; iter: 0; batch classifier loss: 0.365346; batch adversarial loss: 0.535253\n",
      "epoch 144; iter: 0; batch classifier loss: 0.345310; batch adversarial loss: 0.480849\n",
      "epoch 145; iter: 0; batch classifier loss: 0.282239; batch adversarial loss: 0.598104\n",
      "epoch 146; iter: 0; batch classifier loss: 0.313747; batch adversarial loss: 0.553164\n",
      "epoch 147; iter: 0; batch classifier loss: 0.357547; batch adversarial loss: 0.562384\n",
      "epoch 148; iter: 0; batch classifier loss: 0.345421; batch adversarial loss: 0.553719\n",
      "epoch 149; iter: 0; batch classifier loss: 0.411864; batch adversarial loss: 0.580995\n",
      "epoch 150; iter: 0; batch classifier loss: 0.373657; batch adversarial loss: 0.569404\n",
      "epoch 151; iter: 0; batch classifier loss: 0.404337; batch adversarial loss: 0.596279\n",
      "epoch 152; iter: 0; batch classifier loss: 0.342806; batch adversarial loss: 0.529388\n",
      "epoch 153; iter: 0; batch classifier loss: 0.366015; batch adversarial loss: 0.515568\n",
      "epoch 154; iter: 0; batch classifier loss: 0.320952; batch adversarial loss: 0.633816\n",
      "epoch 155; iter: 0; batch classifier loss: 0.321080; batch adversarial loss: 0.581752\n",
      "epoch 156; iter: 0; batch classifier loss: 0.314646; batch adversarial loss: 0.527988\n",
      "epoch 157; iter: 0; batch classifier loss: 0.298241; batch adversarial loss: 0.489747\n",
      "epoch 158; iter: 0; batch classifier loss: 0.449750; batch adversarial loss: 0.566673\n",
      "epoch 159; iter: 0; batch classifier loss: 0.369290; batch adversarial loss: 0.542959\n",
      "epoch 160; iter: 0; batch classifier loss: 0.400601; batch adversarial loss: 0.491002\n",
      "epoch 161; iter: 0; batch classifier loss: 0.399539; batch adversarial loss: 0.592309\n",
      "epoch 162; iter: 0; batch classifier loss: 0.292511; batch adversarial loss: 0.519504\n",
      "epoch 163; iter: 0; batch classifier loss: 0.478814; batch adversarial loss: 0.492208\n",
      "epoch 164; iter: 0; batch classifier loss: 0.305334; batch adversarial loss: 0.554137\n",
      "epoch 165; iter: 0; batch classifier loss: 0.373430; batch adversarial loss: 0.545183\n",
      "epoch 166; iter: 0; batch classifier loss: 0.302744; batch adversarial loss: 0.535600\n",
      "epoch 167; iter: 0; batch classifier loss: 0.426107; batch adversarial loss: 0.544115\n",
      "epoch 168; iter: 0; batch classifier loss: 0.318666; batch adversarial loss: 0.500678\n",
      "epoch 169; iter: 0; batch classifier loss: 0.322152; batch adversarial loss: 0.589728\n",
      "epoch 170; iter: 0; batch classifier loss: 0.424454; batch adversarial loss: 0.508902\n",
      "epoch 171; iter: 0; batch classifier loss: 0.345178; batch adversarial loss: 0.571516\n",
      "epoch 172; iter: 0; batch classifier loss: 0.382004; batch adversarial loss: 0.625539\n",
      "epoch 173; iter: 0; batch classifier loss: 0.296178; batch adversarial loss: 0.509108\n",
      "epoch 174; iter: 0; batch classifier loss: 0.357662; batch adversarial loss: 0.498515\n",
      "epoch 175; iter: 0; batch classifier loss: 0.339384; batch adversarial loss: 0.500079\n",
      "epoch 176; iter: 0; batch classifier loss: 0.410379; batch adversarial loss: 0.563431\n",
      "epoch 177; iter: 0; batch classifier loss: 0.342604; batch adversarial loss: 0.642905\n",
      "epoch 178; iter: 0; batch classifier loss: 0.307546; batch adversarial loss: 0.590106\n",
      "epoch 179; iter: 0; batch classifier loss: 0.395617; batch adversarial loss: 0.543129\n",
      "epoch 180; iter: 0; batch classifier loss: 0.400299; batch adversarial loss: 0.570718\n",
      "epoch 181; iter: 0; batch classifier loss: 0.325408; batch adversarial loss: 0.571496\n",
      "epoch 182; iter: 0; batch classifier loss: 0.347798; batch adversarial loss: 0.590560\n",
      "epoch 183; iter: 0; batch classifier loss: 0.377758; batch adversarial loss: 0.608333\n",
      "epoch 184; iter: 0; batch classifier loss: 0.254013; batch adversarial loss: 0.564278\n",
      "epoch 185; iter: 0; batch classifier loss: 0.449716; batch adversarial loss: 0.570052\n",
      "epoch 186; iter: 0; batch classifier loss: 0.355021; batch adversarial loss: 0.572423\n",
      "epoch 187; iter: 0; batch classifier loss: 0.417748; batch adversarial loss: 0.634483\n",
      "epoch 188; iter: 0; batch classifier loss: 0.356289; batch adversarial loss: 0.571080\n",
      "epoch 189; iter: 0; batch classifier loss: 0.380775; batch adversarial loss: 0.597275\n",
      "epoch 190; iter: 0; batch classifier loss: 0.359862; batch adversarial loss: 0.644016\n",
      "epoch 191; iter: 0; batch classifier loss: 0.343906; batch adversarial loss: 0.553470\n",
      "epoch 192; iter: 0; batch classifier loss: 0.332000; batch adversarial loss: 0.508850\n",
      "epoch 193; iter: 0; batch classifier loss: 0.282009; batch adversarial loss: 0.455025\n",
      "epoch 194; iter: 0; batch classifier loss: 0.304691; batch adversarial loss: 0.562656\n",
      "epoch 195; iter: 0; batch classifier loss: 0.327082; batch adversarial loss: 0.615977\n",
      "epoch 196; iter: 0; batch classifier loss: 0.399592; batch adversarial loss: 0.597378\n",
      "epoch 197; iter: 0; batch classifier loss: 0.255363; batch adversarial loss: 0.508846\n",
      "epoch 198; iter: 0; batch classifier loss: 0.387722; batch adversarial loss: 0.546656\n",
      "epoch 199; iter: 0; batch classifier loss: 0.431650; batch adversarial loss: 0.588404\n",
      "epoch 0; iter: 0; batch classifier loss: 0.659730; batch adversarial loss: 0.581998\n",
      "epoch 1; iter: 0; batch classifier loss: 0.610410; batch adversarial loss: 0.624892\n",
      "epoch 2; iter: 0; batch classifier loss: 0.580374; batch adversarial loss: 0.675485\n",
      "epoch 3; iter: 0; batch classifier loss: 0.604572; batch adversarial loss: 0.679938\n",
      "epoch 4; iter: 0; batch classifier loss: 0.694696; batch adversarial loss: 0.639789\n",
      "epoch 5; iter: 0; batch classifier loss: 0.560608; batch adversarial loss: 0.638725\n",
      "epoch 6; iter: 0; batch classifier loss: 0.641215; batch adversarial loss: 0.672570\n",
      "epoch 7; iter: 0; batch classifier loss: 0.595994; batch adversarial loss: 0.637883\n",
      "epoch 8; iter: 0; batch classifier loss: 0.624480; batch adversarial loss: 0.589426\n",
      "epoch 9; iter: 0; batch classifier loss: 0.494025; batch adversarial loss: 0.584809\n",
      "epoch 10; iter: 0; batch classifier loss: 0.574509; batch adversarial loss: 0.547364\n",
      "epoch 11; iter: 0; batch classifier loss: 0.559185; batch adversarial loss: 0.527559\n",
      "epoch 12; iter: 0; batch classifier loss: 0.589096; batch adversarial loss: 0.558047\n",
      "epoch 13; iter: 0; batch classifier loss: 0.509726; batch adversarial loss: 0.545474\n",
      "epoch 14; iter: 0; batch classifier loss: 0.510506; batch adversarial loss: 0.574098\n",
      "epoch 15; iter: 0; batch classifier loss: 0.488464; batch adversarial loss: 0.558108\n",
      "epoch 16; iter: 0; batch classifier loss: 0.493672; batch adversarial loss: 0.550101\n",
      "epoch 17; iter: 0; batch classifier loss: 0.512156; batch adversarial loss: 0.591406\n",
      "epoch 18; iter: 0; batch classifier loss: 0.562101; batch adversarial loss: 0.543200\n",
      "epoch 19; iter: 0; batch classifier loss: 0.513074; batch adversarial loss: 0.615645\n",
      "epoch 20; iter: 0; batch classifier loss: 0.480411; batch adversarial loss: 0.549743\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 21; iter: 0; batch classifier loss: 0.494288; batch adversarial loss: 0.585108\n",
      "epoch 22; iter: 0; batch classifier loss: 0.485048; batch adversarial loss: 0.507661\n",
      "epoch 23; iter: 0; batch classifier loss: 0.494691; batch adversarial loss: 0.555076\n",
      "epoch 24; iter: 0; batch classifier loss: 0.439630; batch adversarial loss: 0.563923\n",
      "epoch 25; iter: 0; batch classifier loss: 0.506930; batch adversarial loss: 0.529225\n",
      "epoch 26; iter: 0; batch classifier loss: 0.501697; batch adversarial loss: 0.575765\n",
      "epoch 27; iter: 0; batch classifier loss: 0.488207; batch adversarial loss: 0.560518\n",
      "epoch 28; iter: 0; batch classifier loss: 0.547716; batch adversarial loss: 0.535709\n",
      "epoch 29; iter: 0; batch classifier loss: 0.472342; batch adversarial loss: 0.533362\n",
      "epoch 30; iter: 0; batch classifier loss: 0.469978; batch adversarial loss: 0.605189\n",
      "epoch 31; iter: 0; batch classifier loss: 0.468933; batch adversarial loss: 0.604283\n",
      "epoch 32; iter: 0; batch classifier loss: 0.457825; batch adversarial loss: 0.554557\n",
      "epoch 33; iter: 0; batch classifier loss: 0.405810; batch adversarial loss: 0.562811\n",
      "epoch 34; iter: 0; batch classifier loss: 0.496602; batch adversarial loss: 0.553809\n",
      "epoch 35; iter: 0; batch classifier loss: 0.494771; batch adversarial loss: 0.589576\n",
      "epoch 36; iter: 0; batch classifier loss: 0.460666; batch adversarial loss: 0.588463\n",
      "epoch 37; iter: 0; batch classifier loss: 0.478700; batch adversarial loss: 0.581791\n",
      "epoch 38; iter: 0; batch classifier loss: 0.491203; batch adversarial loss: 0.581147\n",
      "epoch 39; iter: 0; batch classifier loss: 0.453068; batch adversarial loss: 0.581290\n",
      "epoch 40; iter: 0; batch classifier loss: 0.447974; batch adversarial loss: 0.526758\n",
      "epoch 41; iter: 0; batch classifier loss: 0.498767; batch adversarial loss: 0.617844\n",
      "epoch 42; iter: 0; batch classifier loss: 0.519086; batch adversarial loss: 0.527275\n",
      "epoch 43; iter: 0; batch classifier loss: 0.452547; batch adversarial loss: 0.572314\n",
      "epoch 44; iter: 0; batch classifier loss: 0.422789; batch adversarial loss: 0.561985\n",
      "epoch 45; iter: 0; batch classifier loss: 0.435414; batch adversarial loss: 0.544478\n",
      "epoch 46; iter: 0; batch classifier loss: 0.452177; batch adversarial loss: 0.535408\n",
      "epoch 47; iter: 0; batch classifier loss: 0.348535; batch adversarial loss: 0.490246\n",
      "epoch 48; iter: 0; batch classifier loss: 0.434973; batch adversarial loss: 0.489745\n",
      "epoch 49; iter: 0; batch classifier loss: 0.493527; batch adversarial loss: 0.553585\n",
      "epoch 50; iter: 0; batch classifier loss: 0.396704; batch adversarial loss: 0.507955\n",
      "epoch 51; iter: 0; batch classifier loss: 0.393798; batch adversarial loss: 0.525835\n",
      "epoch 52; iter: 0; batch classifier loss: 0.398510; batch adversarial loss: 0.525284\n",
      "epoch 53; iter: 0; batch classifier loss: 0.409201; batch adversarial loss: 0.498176\n",
      "epoch 54; iter: 0; batch classifier loss: 0.414455; batch adversarial loss: 0.553241\n",
      "epoch 55; iter: 0; batch classifier loss: 0.453237; batch adversarial loss: 0.563045\n",
      "epoch 56; iter: 0; batch classifier loss: 0.493495; batch adversarial loss: 0.517187\n",
      "epoch 57; iter: 0; batch classifier loss: 0.467655; batch adversarial loss: 0.516445\n",
      "epoch 58; iter: 0; batch classifier loss: 0.423746; batch adversarial loss: 0.563905\n",
      "epoch 59; iter: 0; batch classifier loss: 0.505661; batch adversarial loss: 0.590096\n",
      "epoch 60; iter: 0; batch classifier loss: 0.362958; batch adversarial loss: 0.627419\n",
      "epoch 61; iter: 0; batch classifier loss: 0.470331; batch adversarial loss: 0.582153\n",
      "epoch 62; iter: 0; batch classifier loss: 0.454615; batch adversarial loss: 0.527541\n",
      "epoch 63; iter: 0; batch classifier loss: 0.436563; batch adversarial loss: 0.552254\n",
      "epoch 64; iter: 0; batch classifier loss: 0.454048; batch adversarial loss: 0.526493\n",
      "epoch 65; iter: 0; batch classifier loss: 0.489530; batch adversarial loss: 0.589222\n",
      "epoch 66; iter: 0; batch classifier loss: 0.433393; batch adversarial loss: 0.497698\n",
      "epoch 67; iter: 0; batch classifier loss: 0.401993; batch adversarial loss: 0.553747\n",
      "epoch 68; iter: 0; batch classifier loss: 0.416576; batch adversarial loss: 0.555533\n",
      "epoch 69; iter: 0; batch classifier loss: 0.373836; batch adversarial loss: 0.543788\n",
      "epoch 70; iter: 0; batch classifier loss: 0.402503; batch adversarial loss: 0.490298\n",
      "epoch 71; iter: 0; batch classifier loss: 0.446393; batch adversarial loss: 0.535795\n",
      "epoch 72; iter: 0; batch classifier loss: 0.458027; batch adversarial loss: 0.553696\n",
      "epoch 73; iter: 0; batch classifier loss: 0.458587; batch adversarial loss: 0.580756\n",
      "epoch 74; iter: 0; batch classifier loss: 0.478192; batch adversarial loss: 0.553278\n",
      "epoch 75; iter: 0; batch classifier loss: 0.417315; batch adversarial loss: 0.544137\n",
      "epoch 76; iter: 0; batch classifier loss: 0.425561; batch adversarial loss: 0.563007\n",
      "epoch 77; iter: 0; batch classifier loss: 0.378086; batch adversarial loss: 0.535797\n",
      "epoch 78; iter: 0; batch classifier loss: 0.391601; batch adversarial loss: 0.618168\n",
      "epoch 79; iter: 0; batch classifier loss: 0.344189; batch adversarial loss: 0.609380\n",
      "epoch 80; iter: 0; batch classifier loss: 0.366540; batch adversarial loss: 0.534590\n",
      "epoch 81; iter: 0; batch classifier loss: 0.387584; batch adversarial loss: 0.618578\n",
      "epoch 82; iter: 0; batch classifier loss: 0.384857; batch adversarial loss: 0.545056\n",
      "epoch 83; iter: 0; batch classifier loss: 0.420435; batch adversarial loss: 0.489534\n",
      "epoch 84; iter: 0; batch classifier loss: 0.426929; batch adversarial loss: 0.489753\n",
      "epoch 85; iter: 0; batch classifier loss: 0.436589; batch adversarial loss: 0.572226\n",
      "epoch 86; iter: 0; batch classifier loss: 0.431740; batch adversarial loss: 0.526227\n",
      "epoch 87; iter: 0; batch classifier loss: 0.390467; batch adversarial loss: 0.553860\n",
      "epoch 88; iter: 0; batch classifier loss: 0.302591; batch adversarial loss: 0.544256\n",
      "epoch 89; iter: 0; batch classifier loss: 0.436919; batch adversarial loss: 0.636933\n",
      "epoch 90; iter: 0; batch classifier loss: 0.359877; batch adversarial loss: 0.636389\n",
      "epoch 91; iter: 0; batch classifier loss: 0.394127; batch adversarial loss: 0.535195\n",
      "epoch 92; iter: 0; batch classifier loss: 0.359300; batch adversarial loss: 0.526080\n",
      "epoch 93; iter: 0; batch classifier loss: 0.344665; batch adversarial loss: 0.517493\n",
      "epoch 94; iter: 0; batch classifier loss: 0.411855; batch adversarial loss: 0.424679\n",
      "epoch 95; iter: 0; batch classifier loss: 0.417952; batch adversarial loss: 0.563259\n",
      "epoch 96; iter: 0; batch classifier loss: 0.329420; batch adversarial loss: 0.636465\n",
      "epoch 97; iter: 0; batch classifier loss: 0.362880; batch adversarial loss: 0.553736\n",
      "epoch 98; iter: 0; batch classifier loss: 0.450083; batch adversarial loss: 0.498601\n",
      "epoch 99; iter: 0; batch classifier loss: 0.391280; batch adversarial loss: 0.544402\n",
      "epoch 100; iter: 0; batch classifier loss: 0.365456; batch adversarial loss: 0.553952\n",
      "epoch 101; iter: 0; batch classifier loss: 0.371509; batch adversarial loss: 0.599744\n",
      "epoch 102; iter: 0; batch classifier loss: 0.409444; batch adversarial loss: 0.554245\n",
      "epoch 103; iter: 0; batch classifier loss: 0.381443; batch adversarial loss: 0.608403\n",
      "epoch 104; iter: 0; batch classifier loss: 0.374917; batch adversarial loss: 0.628906\n",
      "epoch 105; iter: 0; batch classifier loss: 0.369917; batch adversarial loss: 0.573009\n",
      "epoch 106; iter: 0; batch classifier loss: 0.426152; batch adversarial loss: 0.648100\n",
      "epoch 107; iter: 0; batch classifier loss: 0.394623; batch adversarial loss: 0.553696\n",
      "epoch 108; iter: 0; batch classifier loss: 0.397621; batch adversarial loss: 0.571386\n",
      "epoch 109; iter: 0; batch classifier loss: 0.342616; batch adversarial loss: 0.532841\n",
      "epoch 110; iter: 0; batch classifier loss: 0.409628; batch adversarial loss: 0.489922\n",
      "epoch 111; iter: 0; batch classifier loss: 0.342927; batch adversarial loss: 0.580671\n",
      "epoch 112; iter: 0; batch classifier loss: 0.465384; batch adversarial loss: 0.572543\n",
      "epoch 113; iter: 0; batch classifier loss: 0.362612; batch adversarial loss: 0.561537\n",
      "epoch 114; iter: 0; batch classifier loss: 0.374125; batch adversarial loss: 0.542382\n",
      "epoch 115; iter: 0; batch classifier loss: 0.311135; batch adversarial loss: 0.508234\n",
      "epoch 116; iter: 0; batch classifier loss: 0.370290; batch adversarial loss: 0.524276\n",
      "epoch 117; iter: 0; batch classifier loss: 0.430220; batch adversarial loss: 0.461673\n",
      "epoch 118; iter: 0; batch classifier loss: 0.372870; batch adversarial loss: 0.591866\n",
      "epoch 119; iter: 0; batch classifier loss: 0.395826; batch adversarial loss: 0.507355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 120; iter: 0; batch classifier loss: 0.381774; batch adversarial loss: 0.497778\n",
      "epoch 121; iter: 0; batch classifier loss: 0.353756; batch adversarial loss: 0.597946\n",
      "epoch 122; iter: 0; batch classifier loss: 0.373491; batch adversarial loss: 0.627649\n",
      "epoch 123; iter: 0; batch classifier loss: 0.399516; batch adversarial loss: 0.553710\n",
      "epoch 124; iter: 0; batch classifier loss: 0.373000; batch adversarial loss: 0.544080\n",
      "epoch 125; iter: 0; batch classifier loss: 0.365143; batch adversarial loss: 0.607892\n",
      "epoch 126; iter: 0; batch classifier loss: 0.369231; batch adversarial loss: 0.517233\n",
      "epoch 127; iter: 0; batch classifier loss: 0.405249; batch adversarial loss: 0.580537\n",
      "epoch 128; iter: 0; batch classifier loss: 0.332842; batch adversarial loss: 0.526535\n",
      "epoch 129; iter: 0; batch classifier loss: 0.376055; batch adversarial loss: 0.581350\n",
      "epoch 130; iter: 0; batch classifier loss: 0.434563; batch adversarial loss: 0.544764\n",
      "epoch 131; iter: 0; batch classifier loss: 0.332703; batch adversarial loss: 0.544792\n",
      "epoch 132; iter: 0; batch classifier loss: 0.386552; batch adversarial loss: 0.425949\n",
      "epoch 133; iter: 0; batch classifier loss: 0.454792; batch adversarial loss: 0.498642\n",
      "epoch 134; iter: 0; batch classifier loss: 0.437412; batch adversarial loss: 0.507414\n",
      "epoch 135; iter: 0; batch classifier loss: 0.350115; batch adversarial loss: 0.489778\n",
      "epoch 136; iter: 0; batch classifier loss: 0.311819; batch adversarial loss: 0.663976\n",
      "epoch 137; iter: 0; batch classifier loss: 0.446549; batch adversarial loss: 0.590564\n",
      "epoch 138; iter: 0; batch classifier loss: 0.408102; batch adversarial loss: 0.554090\n",
      "epoch 139; iter: 0; batch classifier loss: 0.374042; batch adversarial loss: 0.479832\n",
      "epoch 140; iter: 0; batch classifier loss: 0.448460; batch adversarial loss: 0.516866\n",
      "epoch 141; iter: 0; batch classifier loss: 0.328591; batch adversarial loss: 0.498246\n",
      "epoch 142; iter: 0; batch classifier loss: 0.455449; batch adversarial loss: 0.581677\n",
      "epoch 143; iter: 0; batch classifier loss: 0.329458; batch adversarial loss: 0.609319\n",
      "epoch 144; iter: 0; batch classifier loss: 0.312769; batch adversarial loss: 0.572192\n",
      "epoch 145; iter: 0; batch classifier loss: 0.371194; batch adversarial loss: 0.534863\n",
      "epoch 146; iter: 0; batch classifier loss: 0.348156; batch adversarial loss: 0.589432\n",
      "epoch 147; iter: 0; batch classifier loss: 0.336252; batch adversarial loss: 0.516665\n",
      "epoch 148; iter: 0; batch classifier loss: 0.352296; batch adversarial loss: 0.562550\n",
      "epoch 149; iter: 0; batch classifier loss: 0.365144; batch adversarial loss: 0.498658\n",
      "epoch 150; iter: 0; batch classifier loss: 0.368427; batch adversarial loss: 0.516468\n",
      "epoch 151; iter: 0; batch classifier loss: 0.405095; batch adversarial loss: 0.517238\n",
      "epoch 152; iter: 0; batch classifier loss: 0.319816; batch adversarial loss: 0.498566\n",
      "epoch 153; iter: 0; batch classifier loss: 0.395928; batch adversarial loss: 0.526294\n",
      "epoch 154; iter: 0; batch classifier loss: 0.405410; batch adversarial loss: 0.516938\n",
      "epoch 155; iter: 0; batch classifier loss: 0.430822; batch adversarial loss: 0.553296\n",
      "epoch 156; iter: 0; batch classifier loss: 0.355551; batch adversarial loss: 0.562283\n",
      "epoch 157; iter: 0; batch classifier loss: 0.306911; batch adversarial loss: 0.562657\n",
      "epoch 158; iter: 0; batch classifier loss: 0.400763; batch adversarial loss: 0.526566\n",
      "epoch 159; iter: 0; batch classifier loss: 0.342613; batch adversarial loss: 0.582158\n",
      "epoch 160; iter: 0; batch classifier loss: 0.365090; batch adversarial loss: 0.580720\n",
      "epoch 161; iter: 0; batch classifier loss: 0.336633; batch adversarial loss: 0.516731\n",
      "epoch 162; iter: 0; batch classifier loss: 0.389889; batch adversarial loss: 0.488982\n",
      "epoch 163; iter: 0; batch classifier loss: 0.314086; batch adversarial loss: 0.609378\n",
      "epoch 164; iter: 0; batch classifier loss: 0.348113; batch adversarial loss: 0.590821\n",
      "epoch 165; iter: 0; batch classifier loss: 0.393132; batch adversarial loss: 0.581295\n",
      "epoch 166; iter: 0; batch classifier loss: 0.319709; batch adversarial loss: 0.598989\n",
      "epoch 167; iter: 0; batch classifier loss: 0.328903; batch adversarial loss: 0.581514\n",
      "epoch 168; iter: 0; batch classifier loss: 0.445481; batch adversarial loss: 0.534695\n",
      "epoch 169; iter: 0; batch classifier loss: 0.304802; batch adversarial loss: 0.535308\n",
      "epoch 170; iter: 0; batch classifier loss: 0.353476; batch adversarial loss: 0.517340\n",
      "epoch 171; iter: 0; batch classifier loss: 0.460872; batch adversarial loss: 0.535440\n",
      "epoch 172; iter: 0; batch classifier loss: 0.421714; batch adversarial loss: 0.480157\n",
      "epoch 173; iter: 0; batch classifier loss: 0.402782; batch adversarial loss: 0.544043\n",
      "epoch 174; iter: 0; batch classifier loss: 0.339810; batch adversarial loss: 0.553698\n",
      "epoch 175; iter: 0; batch classifier loss: 0.408458; batch adversarial loss: 0.590735\n",
      "epoch 176; iter: 0; batch classifier loss: 0.423971; batch adversarial loss: 0.563311\n",
      "epoch 177; iter: 0; batch classifier loss: 0.428831; batch adversarial loss: 0.617710\n",
      "epoch 178; iter: 0; batch classifier loss: 0.342327; batch adversarial loss: 0.498369\n",
      "epoch 179; iter: 0; batch classifier loss: 0.399887; batch adversarial loss: 0.516254\n",
      "epoch 180; iter: 0; batch classifier loss: 0.375694; batch adversarial loss: 0.498173\n",
      "epoch 181; iter: 0; batch classifier loss: 0.370330; batch adversarial loss: 0.599521\n",
      "epoch 182; iter: 0; batch classifier loss: 0.313392; batch adversarial loss: 0.543955\n",
      "epoch 183; iter: 0; batch classifier loss: 0.383169; batch adversarial loss: 0.497904\n",
      "epoch 184; iter: 0; batch classifier loss: 0.393867; batch adversarial loss: 0.562774\n",
      "epoch 185; iter: 0; batch classifier loss: 0.387007; batch adversarial loss: 0.600253\n",
      "epoch 186; iter: 0; batch classifier loss: 0.381279; batch adversarial loss: 0.544031\n",
      "epoch 187; iter: 0; batch classifier loss: 0.402631; batch adversarial loss: 0.489380\n",
      "epoch 188; iter: 0; batch classifier loss: 0.358631; batch adversarial loss: 0.618756\n",
      "epoch 189; iter: 0; batch classifier loss: 0.363328; batch adversarial loss: 0.553460\n",
      "epoch 190; iter: 0; batch classifier loss: 0.388610; batch adversarial loss: 0.554020\n",
      "epoch 191; iter: 0; batch classifier loss: 0.318364; batch adversarial loss: 0.571871\n",
      "epoch 192; iter: 0; batch classifier loss: 0.286789; batch adversarial loss: 0.470997\n",
      "epoch 193; iter: 0; batch classifier loss: 0.399867; batch adversarial loss: 0.526586\n",
      "epoch 194; iter: 0; batch classifier loss: 0.356112; batch adversarial loss: 0.563015\n",
      "epoch 195; iter: 0; batch classifier loss: 0.334341; batch adversarial loss: 0.553696\n",
      "epoch 196; iter: 0; batch classifier loss: 0.358083; batch adversarial loss: 0.646053\n",
      "epoch 197; iter: 0; batch classifier loss: 0.384918; batch adversarial loss: 0.517031\n",
      "epoch 198; iter: 0; batch classifier loss: 0.318962; batch adversarial loss: 0.562795\n",
      "epoch 199; iter: 0; batch classifier loss: 0.342236; batch adversarial loss: 0.507861\n",
      "epoch 0; iter: 0; batch classifier loss: 0.726210; batch adversarial loss: 0.646225\n",
      "epoch 1; iter: 0; batch classifier loss: 0.583654; batch adversarial loss: 0.651328\n",
      "epoch 2; iter: 0; batch classifier loss: 0.521949; batch adversarial loss: 0.631570\n",
      "epoch 3; iter: 0; batch classifier loss: 0.560889; batch adversarial loss: 0.641792\n",
      "epoch 4; iter: 0; batch classifier loss: 0.623587; batch adversarial loss: 0.604054\n",
      "epoch 5; iter: 0; batch classifier loss: 0.508114; batch adversarial loss: 0.623232\n",
      "epoch 6; iter: 0; batch classifier loss: 0.594708; batch adversarial loss: 0.597421\n",
      "epoch 7; iter: 0; batch classifier loss: 0.547174; batch adversarial loss: 0.593613\n",
      "epoch 8; iter: 0; batch classifier loss: 0.559145; batch adversarial loss: 0.593526\n",
      "epoch 9; iter: 0; batch classifier loss: 0.537399; batch adversarial loss: 0.544484\n",
      "epoch 10; iter: 0; batch classifier loss: 0.462523; batch adversarial loss: 0.568036\n",
      "epoch 11; iter: 0; batch classifier loss: 0.513302; batch adversarial loss: 0.597280\n",
      "epoch 12; iter: 0; batch classifier loss: 0.536086; batch adversarial loss: 0.630983\n",
      "epoch 13; iter: 0; batch classifier loss: 0.519807; batch adversarial loss: 0.561417\n",
      "epoch 14; iter: 0; batch classifier loss: 0.552593; batch adversarial loss: 0.512774\n",
      "epoch 15; iter: 0; batch classifier loss: 0.511392; batch adversarial loss: 0.581156\n",
      "epoch 16; iter: 0; batch classifier loss: 0.492684; batch adversarial loss: 0.588652\n",
      "epoch 17; iter: 0; batch classifier loss: 0.482385; batch adversarial loss: 0.566571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 18; iter: 0; batch classifier loss: 0.541086; batch adversarial loss: 0.548630\n",
      "epoch 19; iter: 0; batch classifier loss: 0.572742; batch adversarial loss: 0.550105\n",
      "epoch 20; iter: 0; batch classifier loss: 0.450054; batch adversarial loss: 0.587631\n",
      "epoch 21; iter: 0; batch classifier loss: 0.431134; batch adversarial loss: 0.536425\n",
      "epoch 22; iter: 0; batch classifier loss: 0.448388; batch adversarial loss: 0.498569\n",
      "epoch 23; iter: 0; batch classifier loss: 0.549371; batch adversarial loss: 0.574680\n",
      "epoch 24; iter: 0; batch classifier loss: 0.508083; batch adversarial loss: 0.501209\n",
      "epoch 25; iter: 0; batch classifier loss: 0.430988; batch adversarial loss: 0.627612\n",
      "epoch 26; iter: 0; batch classifier loss: 0.405958; batch adversarial loss: 0.569734\n",
      "epoch 27; iter: 0; batch classifier loss: 0.422546; batch adversarial loss: 0.505373\n",
      "epoch 28; iter: 0; batch classifier loss: 0.404004; batch adversarial loss: 0.496710\n",
      "epoch 29; iter: 0; batch classifier loss: 0.411023; batch adversarial loss: 0.588866\n",
      "epoch 30; iter: 0; batch classifier loss: 0.464121; batch adversarial loss: 0.510032\n",
      "epoch 31; iter: 0; batch classifier loss: 0.498788; batch adversarial loss: 0.543773\n",
      "epoch 32; iter: 0; batch classifier loss: 0.498716; batch adversarial loss: 0.518335\n",
      "epoch 33; iter: 0; batch classifier loss: 0.434787; batch adversarial loss: 0.549250\n",
      "epoch 34; iter: 0; batch classifier loss: 0.404901; batch adversarial loss: 0.537374\n",
      "epoch 35; iter: 0; batch classifier loss: 0.457300; batch adversarial loss: 0.580442\n",
      "epoch 36; iter: 0; batch classifier loss: 0.432225; batch adversarial loss: 0.546730\n",
      "epoch 37; iter: 0; batch classifier loss: 0.424737; batch adversarial loss: 0.604874\n",
      "epoch 38; iter: 0; batch classifier loss: 0.468733; batch adversarial loss: 0.562661\n",
      "epoch 39; iter: 0; batch classifier loss: 0.423454; batch adversarial loss: 0.536747\n",
      "epoch 40; iter: 0; batch classifier loss: 0.469280; batch adversarial loss: 0.534606\n",
      "epoch 41; iter: 0; batch classifier loss: 0.444703; batch adversarial loss: 0.509558\n",
      "epoch 42; iter: 0; batch classifier loss: 0.421475; batch adversarial loss: 0.563706\n",
      "epoch 43; iter: 0; batch classifier loss: 0.451909; batch adversarial loss: 0.581288\n",
      "epoch 44; iter: 0; batch classifier loss: 0.417113; batch adversarial loss: 0.526823\n",
      "epoch 45; iter: 0; batch classifier loss: 0.427330; batch adversarial loss: 0.571843\n",
      "epoch 46; iter: 0; batch classifier loss: 0.411264; batch adversarial loss: 0.535863\n",
      "epoch 47; iter: 0; batch classifier loss: 0.433289; batch adversarial loss: 0.581180\n",
      "epoch 48; iter: 0; batch classifier loss: 0.319470; batch adversarial loss: 0.544682\n",
      "epoch 49; iter: 0; batch classifier loss: 0.438560; batch adversarial loss: 0.554058\n",
      "epoch 50; iter: 0; batch classifier loss: 0.410961; batch adversarial loss: 0.535339\n",
      "epoch 51; iter: 0; batch classifier loss: 0.444819; batch adversarial loss: 0.544392\n",
      "epoch 52; iter: 0; batch classifier loss: 0.405499; batch adversarial loss: 0.527100\n",
      "epoch 53; iter: 0; batch classifier loss: 0.457555; batch adversarial loss: 0.490974\n",
      "epoch 54; iter: 0; batch classifier loss: 0.485701; batch adversarial loss: 0.552931\n",
      "epoch 55; iter: 0; batch classifier loss: 0.367003; batch adversarial loss: 0.445445\n",
      "epoch 56; iter: 0; batch classifier loss: 0.361932; batch adversarial loss: 0.572708\n",
      "epoch 57; iter: 0; batch classifier loss: 0.379430; batch adversarial loss: 0.608062\n",
      "epoch 58; iter: 0; batch classifier loss: 0.430884; batch adversarial loss: 0.489908\n",
      "epoch 59; iter: 0; batch classifier loss: 0.393004; batch adversarial loss: 0.582139\n",
      "epoch 60; iter: 0; batch classifier loss: 0.413033; batch adversarial loss: 0.616142\n",
      "epoch 61; iter: 0; batch classifier loss: 0.402398; batch adversarial loss: 0.617897\n",
      "epoch 62; iter: 0; batch classifier loss: 0.452655; batch adversarial loss: 0.535649\n",
      "epoch 63; iter: 0; batch classifier loss: 0.447923; batch adversarial loss: 0.564808\n",
      "epoch 64; iter: 0; batch classifier loss: 0.419692; batch adversarial loss: 0.571223\n",
      "epoch 65; iter: 0; batch classifier loss: 0.361588; batch adversarial loss: 0.596075\n",
      "epoch 66; iter: 0; batch classifier loss: 0.404742; batch adversarial loss: 0.595306\n",
      "epoch 67; iter: 0; batch classifier loss: 0.407561; batch adversarial loss: 0.535649\n",
      "epoch 68; iter: 0; batch classifier loss: 0.420727; batch adversarial loss: 0.605068\n",
      "epoch 69; iter: 0; batch classifier loss: 0.335141; batch adversarial loss: 0.534927\n",
      "epoch 70; iter: 0; batch classifier loss: 0.403154; batch adversarial loss: 0.498358\n",
      "epoch 71; iter: 0; batch classifier loss: 0.504997; batch adversarial loss: 0.456452\n",
      "epoch 72; iter: 0; batch classifier loss: 0.462038; batch adversarial loss: 0.561186\n",
      "epoch 73; iter: 0; batch classifier loss: 0.516048; batch adversarial loss: 0.512896\n",
      "epoch 74; iter: 0; batch classifier loss: 0.440774; batch adversarial loss: 0.508572\n",
      "epoch 75; iter: 0; batch classifier loss: 0.354194; batch adversarial loss: 0.591641\n",
      "epoch 76; iter: 0; batch classifier loss: 0.350734; batch adversarial loss: 0.526798\n",
      "epoch 77; iter: 0; batch classifier loss: 0.377054; batch adversarial loss: 0.572852\n",
      "epoch 78; iter: 0; batch classifier loss: 0.368062; batch adversarial loss: 0.545160\n",
      "epoch 79; iter: 0; batch classifier loss: 0.338824; batch adversarial loss: 0.590746\n",
      "epoch 80; iter: 0; batch classifier loss: 0.299522; batch adversarial loss: 0.554736\n",
      "epoch 81; iter: 0; batch classifier loss: 0.369835; batch adversarial loss: 0.554914\n",
      "epoch 82; iter: 0; batch classifier loss: 0.308501; batch adversarial loss: 0.652437\n",
      "epoch 83; iter: 0; batch classifier loss: 0.413970; batch adversarial loss: 0.453694\n",
      "epoch 84; iter: 0; batch classifier loss: 0.411101; batch adversarial loss: 0.544526\n",
      "epoch 85; iter: 0; batch classifier loss: 0.457570; batch adversarial loss: 0.516219\n",
      "epoch 86; iter: 0; batch classifier loss: 0.368051; batch adversarial loss: 0.554667\n",
      "epoch 87; iter: 0; batch classifier loss: 0.367404; batch adversarial loss: 0.525821\n",
      "epoch 88; iter: 0; batch classifier loss: 0.400851; batch adversarial loss: 0.572269\n",
      "epoch 89; iter: 0; batch classifier loss: 0.409759; batch adversarial loss: 0.570144\n",
      "epoch 90; iter: 0; batch classifier loss: 0.359085; batch adversarial loss: 0.590030\n",
      "epoch 91; iter: 0; batch classifier loss: 0.432670; batch adversarial loss: 0.578968\n",
      "epoch 92; iter: 0; batch classifier loss: 0.349666; batch adversarial loss: 0.527614\n",
      "epoch 93; iter: 0; batch classifier loss: 0.355651; batch adversarial loss: 0.535579\n",
      "epoch 94; iter: 0; batch classifier loss: 0.340856; batch adversarial loss: 0.554063\n",
      "epoch 95; iter: 0; batch classifier loss: 0.360778; batch adversarial loss: 0.553050\n",
      "epoch 96; iter: 0; batch classifier loss: 0.338087; batch adversarial loss: 0.551211\n",
      "epoch 97; iter: 0; batch classifier loss: 0.371492; batch adversarial loss: 0.553401\n",
      "epoch 98; iter: 0; batch classifier loss: 0.328732; batch adversarial loss: 0.598479\n",
      "epoch 99; iter: 0; batch classifier loss: 0.300706; batch adversarial loss: 0.525652\n",
      "epoch 100; iter: 0; batch classifier loss: 0.393628; batch adversarial loss: 0.571829\n",
      "epoch 101; iter: 0; batch classifier loss: 0.390281; batch adversarial loss: 0.471466\n",
      "epoch 102; iter: 0; batch classifier loss: 0.415388; batch adversarial loss: 0.553789\n",
      "epoch 103; iter: 0; batch classifier loss: 0.350434; batch adversarial loss: 0.571439\n",
      "epoch 104; iter: 0; batch classifier loss: 0.386108; batch adversarial loss: 0.516350\n",
      "epoch 105; iter: 0; batch classifier loss: 0.366085; batch adversarial loss: 0.606653\n",
      "epoch 106; iter: 0; batch classifier loss: 0.302928; batch adversarial loss: 0.516881\n",
      "epoch 107; iter: 0; batch classifier loss: 0.365889; batch adversarial loss: 0.563394\n",
      "epoch 108; iter: 0; batch classifier loss: 0.298907; batch adversarial loss: 0.535031\n",
      "epoch 109; iter: 0; batch classifier loss: 0.311307; batch adversarial loss: 0.546075\n",
      "epoch 110; iter: 0; batch classifier loss: 0.362761; batch adversarial loss: 0.554496\n",
      "epoch 111; iter: 0; batch classifier loss: 0.355170; batch adversarial loss: 0.542298\n",
      "epoch 112; iter: 0; batch classifier loss: 0.334960; batch adversarial loss: 0.578449\n",
      "epoch 113; iter: 0; batch classifier loss: 0.332075; batch adversarial loss: 0.653297\n",
      "epoch 114; iter: 0; batch classifier loss: 0.411696; batch adversarial loss: 0.518504\n",
      "epoch 115; iter: 0; batch classifier loss: 0.314282; batch adversarial loss: 0.554057\n",
      "epoch 116; iter: 0; batch classifier loss: 0.333027; batch adversarial loss: 0.581375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 117; iter: 0; batch classifier loss: 0.456048; batch adversarial loss: 0.635394\n",
      "epoch 118; iter: 0; batch classifier loss: 0.410075; batch adversarial loss: 0.553986\n",
      "epoch 119; iter: 0; batch classifier loss: 0.459965; batch adversarial loss: 0.535781\n",
      "epoch 120; iter: 0; batch classifier loss: 0.317191; batch adversarial loss: 0.599859\n",
      "epoch 121; iter: 0; batch classifier loss: 0.361754; batch adversarial loss: 0.588205\n",
      "epoch 122; iter: 0; batch classifier loss: 0.327318; batch adversarial loss: 0.516156\n",
      "epoch 123; iter: 0; batch classifier loss: 0.350172; batch adversarial loss: 0.544979\n",
      "epoch 124; iter: 0; batch classifier loss: 0.371277; batch adversarial loss: 0.508488\n",
      "epoch 125; iter: 0; batch classifier loss: 0.323744; batch adversarial loss: 0.555313\n",
      "epoch 126; iter: 0; batch classifier loss: 0.408607; batch adversarial loss: 0.509675\n",
      "epoch 127; iter: 0; batch classifier loss: 0.288166; batch adversarial loss: 0.545151\n",
      "epoch 128; iter: 0; batch classifier loss: 0.350641; batch adversarial loss: 0.545858\n",
      "epoch 129; iter: 0; batch classifier loss: 0.391410; batch adversarial loss: 0.536274\n",
      "epoch 130; iter: 0; batch classifier loss: 0.364515; batch adversarial loss: 0.571977\n",
      "epoch 131; iter: 0; batch classifier loss: 0.353173; batch adversarial loss: 0.590060\n",
      "epoch 132; iter: 0; batch classifier loss: 0.404151; batch adversarial loss: 0.526182\n",
      "epoch 133; iter: 0; batch classifier loss: 0.358044; batch adversarial loss: 0.607294\n",
      "epoch 134; iter: 0; batch classifier loss: 0.363120; batch adversarial loss: 0.560974\n",
      "epoch 135; iter: 0; batch classifier loss: 0.400804; batch adversarial loss: 0.581728\n",
      "epoch 136; iter: 0; batch classifier loss: 0.321945; batch adversarial loss: 0.517132\n",
      "epoch 137; iter: 0; batch classifier loss: 0.320497; batch adversarial loss: 0.526772\n",
      "epoch 138; iter: 0; batch classifier loss: 0.429818; batch adversarial loss: 0.580125\n",
      "epoch 139; iter: 0; batch classifier loss: 0.373161; batch adversarial loss: 0.655067\n",
      "epoch 140; iter: 0; batch classifier loss: 0.342617; batch adversarial loss: 0.588038\n",
      "epoch 141; iter: 0; batch classifier loss: 0.398250; batch adversarial loss: 0.562405\n",
      "epoch 142; iter: 0; batch classifier loss: 0.361402; batch adversarial loss: 0.527247\n",
      "epoch 143; iter: 0; batch classifier loss: 0.310129; batch adversarial loss: 0.589350\n",
      "epoch 144; iter: 0; batch classifier loss: 0.426731; batch adversarial loss: 0.463715\n",
      "epoch 145; iter: 0; batch classifier loss: 0.289609; batch adversarial loss: 0.555760\n",
      "epoch 146; iter: 0; batch classifier loss: 0.354768; batch adversarial loss: 0.551756\n",
      "epoch 147; iter: 0; batch classifier loss: 0.365171; batch adversarial loss: 0.641764\n",
      "epoch 148; iter: 0; batch classifier loss: 0.375649; batch adversarial loss: 0.500010\n",
      "epoch 149; iter: 0; batch classifier loss: 0.366006; batch adversarial loss: 0.518460\n",
      "epoch 150; iter: 0; batch classifier loss: 0.310776; batch adversarial loss: 0.523738\n",
      "epoch 151; iter: 0; batch classifier loss: 0.352049; batch adversarial loss: 0.542379\n",
      "epoch 152; iter: 0; batch classifier loss: 0.300790; batch adversarial loss: 0.508340\n",
      "epoch 153; iter: 0; batch classifier loss: 0.343050; batch adversarial loss: 0.571160\n",
      "epoch 154; iter: 0; batch classifier loss: 0.399435; batch adversarial loss: 0.479856\n",
      "epoch 155; iter: 0; batch classifier loss: 0.444570; batch adversarial loss: 0.582024\n",
      "epoch 156; iter: 0; batch classifier loss: 0.319305; batch adversarial loss: 0.525669\n",
      "epoch 157; iter: 0; batch classifier loss: 0.383537; batch adversarial loss: 0.543757\n",
      "epoch 158; iter: 0; batch classifier loss: 0.322798; batch adversarial loss: 0.537006\n",
      "epoch 159; iter: 0; batch classifier loss: 0.345443; batch adversarial loss: 0.525555\n",
      "epoch 160; iter: 0; batch classifier loss: 0.318350; batch adversarial loss: 0.587510\n",
      "epoch 161; iter: 0; batch classifier loss: 0.347486; batch adversarial loss: 0.480489\n",
      "epoch 162; iter: 0; batch classifier loss: 0.267816; batch adversarial loss: 0.508955\n",
      "epoch 163; iter: 0; batch classifier loss: 0.378970; batch adversarial loss: 0.581366\n",
      "epoch 164; iter: 0; batch classifier loss: 0.341774; batch adversarial loss: 0.580211\n",
      "epoch 165; iter: 0; batch classifier loss: 0.321042; batch adversarial loss: 0.516729\n",
      "epoch 166; iter: 0; batch classifier loss: 0.356695; batch adversarial loss: 0.482470\n",
      "epoch 167; iter: 0; batch classifier loss: 0.302635; batch adversarial loss: 0.608716\n",
      "epoch 168; iter: 0; batch classifier loss: 0.411881; batch adversarial loss: 0.596063\n",
      "epoch 169; iter: 0; batch classifier loss: 0.285941; batch adversarial loss: 0.545521\n",
      "epoch 170; iter: 0; batch classifier loss: 0.350277; batch adversarial loss: 0.524201\n",
      "epoch 171; iter: 0; batch classifier loss: 0.374745; batch adversarial loss: 0.516671\n",
      "epoch 172; iter: 0; batch classifier loss: 0.326747; batch adversarial loss: 0.536632\n",
      "epoch 173; iter: 0; batch classifier loss: 0.422297; batch adversarial loss: 0.591830\n",
      "epoch 174; iter: 0; batch classifier loss: 0.345917; batch adversarial loss: 0.580404\n",
      "epoch 175; iter: 0; batch classifier loss: 0.323494; batch adversarial loss: 0.584264\n",
      "epoch 176; iter: 0; batch classifier loss: 0.269279; batch adversarial loss: 0.554656\n",
      "epoch 177; iter: 0; batch classifier loss: 0.358055; batch adversarial loss: 0.562807\n",
      "epoch 178; iter: 0; batch classifier loss: 0.275343; batch adversarial loss: 0.597952\n",
      "epoch 179; iter: 0; batch classifier loss: 0.364750; batch adversarial loss: 0.583684\n",
      "epoch 180; iter: 0; batch classifier loss: 0.288780; batch adversarial loss: 0.527093\n",
      "epoch 181; iter: 0; batch classifier loss: 0.279998; batch adversarial loss: 0.507748\n",
      "epoch 182; iter: 0; batch classifier loss: 0.276709; batch adversarial loss: 0.519724\n",
      "epoch 183; iter: 0; batch classifier loss: 0.328640; batch adversarial loss: 0.560381\n",
      "epoch 184; iter: 0; batch classifier loss: 0.395155; batch adversarial loss: 0.561030\n",
      "epoch 185; iter: 0; batch classifier loss: 0.445376; batch adversarial loss: 0.546097\n",
      "epoch 186; iter: 0; batch classifier loss: 0.270382; batch adversarial loss: 0.589871\n",
      "epoch 187; iter: 0; batch classifier loss: 0.293313; batch adversarial loss: 0.525819\n",
      "epoch 188; iter: 0; batch classifier loss: 0.384323; batch adversarial loss: 0.571431\n",
      "epoch 189; iter: 0; batch classifier loss: 0.335454; batch adversarial loss: 0.481406\n",
      "epoch 190; iter: 0; batch classifier loss: 0.352276; batch adversarial loss: 0.551001\n",
      "epoch 191; iter: 0; batch classifier loss: 0.313766; batch adversarial loss: 0.589451\n",
      "epoch 192; iter: 0; batch classifier loss: 0.266573; batch adversarial loss: 0.609097\n",
      "epoch 193; iter: 0; batch classifier loss: 0.359128; batch adversarial loss: 0.490784\n",
      "epoch 194; iter: 0; batch classifier loss: 0.303591; batch adversarial loss: 0.515983\n",
      "epoch 195; iter: 0; batch classifier loss: 0.350269; batch adversarial loss: 0.608442\n",
      "epoch 196; iter: 0; batch classifier loss: 0.354619; batch adversarial loss: 0.535896\n",
      "epoch 197; iter: 0; batch classifier loss: 0.326298; batch adversarial loss: 0.577474\n",
      "epoch 198; iter: 0; batch classifier loss: 0.266693; batch adversarial loss: 0.454241\n",
      "epoch 199; iter: 0; batch classifier loss: 0.342326; batch adversarial loss: 0.600038\n",
      "epoch 0; iter: 0; batch classifier loss: 0.668104; batch adversarial loss: 0.663654\n",
      "epoch 1; iter: 0; batch classifier loss: 0.522207; batch adversarial loss: 0.649382\n",
      "epoch 2; iter: 0; batch classifier loss: 0.606386; batch adversarial loss: 0.630883\n",
      "epoch 3; iter: 0; batch classifier loss: 0.534883; batch adversarial loss: 0.624106\n",
      "epoch 4; iter: 0; batch classifier loss: 0.546384; batch adversarial loss: 0.617442\n",
      "epoch 5; iter: 0; batch classifier loss: 0.577143; batch adversarial loss: 0.626231\n",
      "epoch 6; iter: 0; batch classifier loss: 0.507485; batch adversarial loss: 0.581980\n",
      "epoch 7; iter: 0; batch classifier loss: 0.559281; batch adversarial loss: 0.625379\n",
      "epoch 8; iter: 0; batch classifier loss: 0.548181; batch adversarial loss: 0.652203\n",
      "epoch 9; iter: 0; batch classifier loss: 0.539979; batch adversarial loss: 0.607454\n",
      "epoch 10; iter: 0; batch classifier loss: 0.523560; batch adversarial loss: 0.623766\n",
      "epoch 11; iter: 0; batch classifier loss: 0.490210; batch adversarial loss: 0.540240\n",
      "epoch 12; iter: 0; batch classifier loss: 0.616842; batch adversarial loss: 0.560958\n",
      "epoch 13; iter: 0; batch classifier loss: 0.491162; batch adversarial loss: 0.561137\n",
      "epoch 14; iter: 0; batch classifier loss: 0.558090; batch adversarial loss: 0.577015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 15; iter: 0; batch classifier loss: 0.469647; batch adversarial loss: 0.631066\n",
      "epoch 16; iter: 0; batch classifier loss: 0.553736; batch adversarial loss: 0.569007\n",
      "epoch 17; iter: 0; batch classifier loss: 0.487009; batch adversarial loss: 0.663914\n",
      "epoch 18; iter: 0; batch classifier loss: 0.452655; batch adversarial loss: 0.557566\n",
      "epoch 19; iter: 0; batch classifier loss: 0.495988; batch adversarial loss: 0.547727\n",
      "epoch 20; iter: 0; batch classifier loss: 0.492511; batch adversarial loss: 0.587659\n",
      "epoch 21; iter: 0; batch classifier loss: 0.483490; batch adversarial loss: 0.557531\n",
      "epoch 22; iter: 0; batch classifier loss: 0.590231; batch adversarial loss: 0.563197\n",
      "epoch 23; iter: 0; batch classifier loss: 0.542594; batch adversarial loss: 0.546743\n",
      "epoch 24; iter: 0; batch classifier loss: 0.449257; batch adversarial loss: 0.531590\n",
      "epoch 25; iter: 0; batch classifier loss: 0.468595; batch adversarial loss: 0.579623\n",
      "epoch 26; iter: 0; batch classifier loss: 0.493203; batch adversarial loss: 0.561706\n",
      "epoch 27; iter: 0; batch classifier loss: 0.441938; batch adversarial loss: 0.554191\n",
      "epoch 28; iter: 0; batch classifier loss: 0.408090; batch adversarial loss: 0.570686\n",
      "epoch 29; iter: 0; batch classifier loss: 0.484822; batch adversarial loss: 0.528241\n",
      "epoch 30; iter: 0; batch classifier loss: 0.460123; batch adversarial loss: 0.579248\n",
      "epoch 31; iter: 0; batch classifier loss: 0.410417; batch adversarial loss: 0.605359\n",
      "epoch 32; iter: 0; batch classifier loss: 0.434984; batch adversarial loss: 0.553572\n",
      "epoch 33; iter: 0; batch classifier loss: 0.503748; batch adversarial loss: 0.596598\n",
      "epoch 34; iter: 0; batch classifier loss: 0.408025; batch adversarial loss: 0.527804\n",
      "epoch 35; iter: 0; batch classifier loss: 0.423024; batch adversarial loss: 0.657071\n",
      "epoch 36; iter: 0; batch classifier loss: 0.446483; batch adversarial loss: 0.509916\n",
      "epoch 37; iter: 0; batch classifier loss: 0.467588; batch adversarial loss: 0.536280\n",
      "epoch 38; iter: 0; batch classifier loss: 0.408460; batch adversarial loss: 0.535029\n",
      "epoch 39; iter: 0; batch classifier loss: 0.362633; batch adversarial loss: 0.608386\n",
      "epoch 40; iter: 0; batch classifier loss: 0.430100; batch adversarial loss: 0.601510\n",
      "epoch 41; iter: 0; batch classifier loss: 0.430661; batch adversarial loss: 0.447727\n",
      "epoch 42; iter: 0; batch classifier loss: 0.424961; batch adversarial loss: 0.569393\n",
      "epoch 43; iter: 0; batch classifier loss: 0.376662; batch adversarial loss: 0.541027\n",
      "epoch 44; iter: 0; batch classifier loss: 0.452092; batch adversarial loss: 0.527535\n",
      "epoch 45; iter: 0; batch classifier loss: 0.353230; batch adversarial loss: 0.446127\n",
      "epoch 46; iter: 0; batch classifier loss: 0.414834; batch adversarial loss: 0.480301\n",
      "epoch 47; iter: 0; batch classifier loss: 0.385547; batch adversarial loss: 0.597270\n",
      "epoch 48; iter: 0; batch classifier loss: 0.453242; batch adversarial loss: 0.535568\n",
      "epoch 49; iter: 0; batch classifier loss: 0.397910; batch adversarial loss: 0.597698\n",
      "epoch 50; iter: 0; batch classifier loss: 0.431852; batch adversarial loss: 0.596163\n",
      "epoch 51; iter: 0; batch classifier loss: 0.430698; batch adversarial loss: 0.631112\n",
      "epoch 52; iter: 0; batch classifier loss: 0.483375; batch adversarial loss: 0.561518\n",
      "epoch 53; iter: 0; batch classifier loss: 0.467593; batch adversarial loss: 0.439151\n",
      "epoch 54; iter: 0; batch classifier loss: 0.422876; batch adversarial loss: 0.572878\n",
      "epoch 55; iter: 0; batch classifier loss: 0.415290; batch adversarial loss: 0.533852\n",
      "epoch 56; iter: 0; batch classifier loss: 0.426166; batch adversarial loss: 0.545310\n",
      "epoch 57; iter: 0; batch classifier loss: 0.386455; batch adversarial loss: 0.533909\n",
      "epoch 58; iter: 0; batch classifier loss: 0.440903; batch adversarial loss: 0.573923\n",
      "epoch 59; iter: 0; batch classifier loss: 0.329243; batch adversarial loss: 0.554147\n",
      "epoch 60; iter: 0; batch classifier loss: 0.403405; batch adversarial loss: 0.526083\n",
      "epoch 61; iter: 0; batch classifier loss: 0.406532; batch adversarial loss: 0.572350\n",
      "epoch 62; iter: 0; batch classifier loss: 0.450015; batch adversarial loss: 0.536252\n",
      "epoch 63; iter: 0; batch classifier loss: 0.436223; batch adversarial loss: 0.516085\n",
      "epoch 64; iter: 0; batch classifier loss: 0.400010; batch adversarial loss: 0.490580\n",
      "epoch 65; iter: 0; batch classifier loss: 0.376478; batch adversarial loss: 0.616093\n",
      "epoch 66; iter: 0; batch classifier loss: 0.425172; batch adversarial loss: 0.553343\n",
      "epoch 67; iter: 0; batch classifier loss: 0.460569; batch adversarial loss: 0.582257\n",
      "epoch 68; iter: 0; batch classifier loss: 0.493255; batch adversarial loss: 0.516555\n",
      "epoch 69; iter: 0; batch classifier loss: 0.387977; batch adversarial loss: 0.498483\n",
      "epoch 70; iter: 0; batch classifier loss: 0.360892; batch adversarial loss: 0.519749\n",
      "epoch 71; iter: 0; batch classifier loss: 0.407781; batch adversarial loss: 0.617551\n",
      "epoch 72; iter: 0; batch classifier loss: 0.374949; batch adversarial loss: 0.537296\n",
      "epoch 73; iter: 0; batch classifier loss: 0.400617; batch adversarial loss: 0.479328\n",
      "epoch 74; iter: 0; batch classifier loss: 0.356179; batch adversarial loss: 0.581760\n",
      "epoch 75; iter: 0; batch classifier loss: 0.418554; batch adversarial loss: 0.509706\n",
      "epoch 76; iter: 0; batch classifier loss: 0.318582; batch adversarial loss: 0.572147\n",
      "epoch 77; iter: 0; batch classifier loss: 0.437129; batch adversarial loss: 0.544457\n",
      "epoch 78; iter: 0; batch classifier loss: 0.417040; batch adversarial loss: 0.572037\n",
      "epoch 79; iter: 0; batch classifier loss: 0.445887; batch adversarial loss: 0.537242\n",
      "epoch 80; iter: 0; batch classifier loss: 0.424832; batch adversarial loss: 0.543438\n",
      "epoch 81; iter: 0; batch classifier loss: 0.345145; batch adversarial loss: 0.482681\n",
      "epoch 82; iter: 0; batch classifier loss: 0.358603; batch adversarial loss: 0.614676\n",
      "epoch 83; iter: 0; batch classifier loss: 0.422458; batch adversarial loss: 0.473322\n",
      "epoch 84; iter: 0; batch classifier loss: 0.393474; batch adversarial loss: 0.517574\n",
      "epoch 85; iter: 0; batch classifier loss: 0.432499; batch adversarial loss: 0.552779\n",
      "epoch 86; iter: 0; batch classifier loss: 0.346478; batch adversarial loss: 0.617280\n",
      "epoch 87; iter: 0; batch classifier loss: 0.383606; batch adversarial loss: 0.455152\n",
      "epoch 88; iter: 0; batch classifier loss: 0.391385; batch adversarial loss: 0.532820\n",
      "epoch 89; iter: 0; batch classifier loss: 0.389395; batch adversarial loss: 0.536321\n",
      "epoch 90; iter: 0; batch classifier loss: 0.364125; batch adversarial loss: 0.562354\n",
      "epoch 91; iter: 0; batch classifier loss: 0.383251; batch adversarial loss: 0.589712\n",
      "epoch 92; iter: 0; batch classifier loss: 0.368759; batch adversarial loss: 0.573136\n",
      "epoch 93; iter: 0; batch classifier loss: 0.373071; batch adversarial loss: 0.549225\n",
      "epoch 94; iter: 0; batch classifier loss: 0.425849; batch adversarial loss: 0.554577\n",
      "epoch 95; iter: 0; batch classifier loss: 0.420297; batch adversarial loss: 0.581036\n",
      "epoch 96; iter: 0; batch classifier loss: 0.403497; batch adversarial loss: 0.562747\n",
      "epoch 97; iter: 0; batch classifier loss: 0.512370; batch adversarial loss: 0.554535\n",
      "epoch 98; iter: 0; batch classifier loss: 0.396232; batch adversarial loss: 0.498722\n",
      "epoch 99; iter: 0; batch classifier loss: 0.356652; batch adversarial loss: 0.580676\n",
      "epoch 100; iter: 0; batch classifier loss: 0.422655; batch adversarial loss: 0.582154\n",
      "epoch 101; iter: 0; batch classifier loss: 0.351441; batch adversarial loss: 0.659409\n",
      "epoch 102; iter: 0; batch classifier loss: 0.357157; batch adversarial loss: 0.580549\n",
      "epoch 103; iter: 0; batch classifier loss: 0.407036; batch adversarial loss: 0.526139\n",
      "epoch 104; iter: 0; batch classifier loss: 0.353852; batch adversarial loss: 0.580871\n",
      "epoch 105; iter: 0; batch classifier loss: 0.417331; batch adversarial loss: 0.481731\n",
      "epoch 106; iter: 0; batch classifier loss: 0.390045; batch adversarial loss: 0.599777\n",
      "epoch 107; iter: 0; batch classifier loss: 0.389865; batch adversarial loss: 0.516744\n",
      "epoch 108; iter: 0; batch classifier loss: 0.376947; batch adversarial loss: 0.571523\n",
      "epoch 109; iter: 0; batch classifier loss: 0.397580; batch adversarial loss: 0.497702\n",
      "epoch 110; iter: 0; batch classifier loss: 0.369778; batch adversarial loss: 0.625374\n",
      "epoch 111; iter: 0; batch classifier loss: 0.449367; batch adversarial loss: 0.562900\n",
      "epoch 112; iter: 0; batch classifier loss: 0.447705; batch adversarial loss: 0.525272\n",
      "epoch 113; iter: 0; batch classifier loss: 0.408753; batch adversarial loss: 0.518428\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 114; iter: 0; batch classifier loss: 0.366193; batch adversarial loss: 0.498208\n",
      "epoch 115; iter: 0; batch classifier loss: 0.396332; batch adversarial loss: 0.515361\n",
      "epoch 116; iter: 0; batch classifier loss: 0.399893; batch adversarial loss: 0.633114\n",
      "epoch 117; iter: 0; batch classifier loss: 0.333006; batch adversarial loss: 0.582549\n",
      "epoch 118; iter: 0; batch classifier loss: 0.338472; batch adversarial loss: 0.508112\n",
      "epoch 119; iter: 0; batch classifier loss: 0.314176; batch adversarial loss: 0.518476\n",
      "epoch 120; iter: 0; batch classifier loss: 0.428847; batch adversarial loss: 0.664279\n",
      "epoch 121; iter: 0; batch classifier loss: 0.420036; batch adversarial loss: 0.550627\n",
      "epoch 122; iter: 0; batch classifier loss: 0.355544; batch adversarial loss: 0.509078\n",
      "epoch 123; iter: 0; batch classifier loss: 0.329607; batch adversarial loss: 0.500039\n",
      "epoch 124; iter: 0; batch classifier loss: 0.376967; batch adversarial loss: 0.563165\n",
      "epoch 125; iter: 0; batch classifier loss: 0.330178; batch adversarial loss: 0.578514\n",
      "epoch 126; iter: 0; batch classifier loss: 0.329831; batch adversarial loss: 0.550038\n",
      "epoch 127; iter: 0; batch classifier loss: 0.407184; batch adversarial loss: 0.464622\n",
      "epoch 128; iter: 0; batch classifier loss: 0.375995; batch adversarial loss: 0.573057\n",
      "epoch 129; iter: 0; batch classifier loss: 0.341526; batch adversarial loss: 0.509990\n",
      "epoch 130; iter: 0; batch classifier loss: 0.374448; batch adversarial loss: 0.555783\n",
      "epoch 131; iter: 0; batch classifier loss: 0.338915; batch adversarial loss: 0.525377\n",
      "epoch 132; iter: 0; batch classifier loss: 0.386361; batch adversarial loss: 0.502125\n",
      "epoch 133; iter: 0; batch classifier loss: 0.354670; batch adversarial loss: 0.651226\n",
      "epoch 134; iter: 0; batch classifier loss: 0.303180; batch adversarial loss: 0.586826\n",
      "epoch 135; iter: 0; batch classifier loss: 0.410733; batch adversarial loss: 0.627080\n",
      "epoch 136; iter: 0; batch classifier loss: 0.399240; batch adversarial loss: 0.516058\n",
      "epoch 137; iter: 0; batch classifier loss: 0.379097; batch adversarial loss: 0.502176\n",
      "epoch 138; iter: 0; batch classifier loss: 0.387257; batch adversarial loss: 0.545233\n",
      "epoch 139; iter: 0; batch classifier loss: 0.392476; batch adversarial loss: 0.591183\n",
      "epoch 140; iter: 0; batch classifier loss: 0.391626; batch adversarial loss: 0.591230\n",
      "epoch 141; iter: 0; batch classifier loss: 0.423511; batch adversarial loss: 0.554538\n",
      "epoch 142; iter: 0; batch classifier loss: 0.446621; batch adversarial loss: 0.453180\n",
      "epoch 143; iter: 0; batch classifier loss: 0.344733; batch adversarial loss: 0.541959\n",
      "epoch 144; iter: 0; batch classifier loss: 0.356673; batch adversarial loss: 0.609699\n",
      "epoch 145; iter: 0; batch classifier loss: 0.437101; batch adversarial loss: 0.525588\n",
      "epoch 146; iter: 0; batch classifier loss: 0.357608; batch adversarial loss: 0.552460\n",
      "epoch 147; iter: 0; batch classifier loss: 0.329379; batch adversarial loss: 0.622935\n",
      "epoch 148; iter: 0; batch classifier loss: 0.364096; batch adversarial loss: 0.516551\n",
      "epoch 149; iter: 0; batch classifier loss: 0.368991; batch adversarial loss: 0.490475\n",
      "epoch 150; iter: 0; batch classifier loss: 0.352223; batch adversarial loss: 0.659434\n",
      "epoch 151; iter: 0; batch classifier loss: 0.353285; batch adversarial loss: 0.580864\n",
      "epoch 152; iter: 0; batch classifier loss: 0.380616; batch adversarial loss: 0.527446\n",
      "epoch 153; iter: 0; batch classifier loss: 0.285509; batch adversarial loss: 0.470379\n",
      "epoch 154; iter: 0; batch classifier loss: 0.330697; batch adversarial loss: 0.571694\n",
      "epoch 155; iter: 0; batch classifier loss: 0.303091; batch adversarial loss: 0.545431\n",
      "epoch 156; iter: 0; batch classifier loss: 0.424045; batch adversarial loss: 0.537118\n",
      "epoch 157; iter: 0; batch classifier loss: 0.416651; batch adversarial loss: 0.526646\n",
      "epoch 158; iter: 0; batch classifier loss: 0.426570; batch adversarial loss: 0.538715\n",
      "epoch 159; iter: 0; batch classifier loss: 0.333355; batch adversarial loss: 0.576956\n",
      "epoch 160; iter: 0; batch classifier loss: 0.326842; batch adversarial loss: 0.482724\n",
      "epoch 161; iter: 0; batch classifier loss: 0.308564; batch adversarial loss: 0.586362\n",
      "epoch 162; iter: 0; batch classifier loss: 0.420605; batch adversarial loss: 0.481317\n",
      "epoch 163; iter: 0; batch classifier loss: 0.395654; batch adversarial loss: 0.488113\n",
      "epoch 164; iter: 0; batch classifier loss: 0.312797; batch adversarial loss: 0.599454\n",
      "epoch 165; iter: 0; batch classifier loss: 0.339174; batch adversarial loss: 0.590325\n",
      "epoch 166; iter: 0; batch classifier loss: 0.347794; batch adversarial loss: 0.543978\n",
      "epoch 167; iter: 0; batch classifier loss: 0.390154; batch adversarial loss: 0.607214\n",
      "epoch 168; iter: 0; batch classifier loss: 0.443215; batch adversarial loss: 0.581907\n",
      "epoch 169; iter: 0; batch classifier loss: 0.412622; batch adversarial loss: 0.526485\n",
      "epoch 170; iter: 0; batch classifier loss: 0.412301; batch adversarial loss: 0.500229\n",
      "epoch 171; iter: 0; batch classifier loss: 0.338781; batch adversarial loss: 0.584240\n",
      "epoch 172; iter: 0; batch classifier loss: 0.363370; batch adversarial loss: 0.559135\n",
      "epoch 173; iter: 0; batch classifier loss: 0.410511; batch adversarial loss: 0.552283\n",
      "epoch 174; iter: 0; batch classifier loss: 0.341735; batch adversarial loss: 0.586052\n",
      "epoch 175; iter: 0; batch classifier loss: 0.369510; batch adversarial loss: 0.561966\n",
      "epoch 176; iter: 0; batch classifier loss: 0.313993; batch adversarial loss: 0.552585\n",
      "epoch 177; iter: 0; batch classifier loss: 0.281383; batch adversarial loss: 0.544243\n",
      "epoch 178; iter: 0; batch classifier loss: 0.347959; batch adversarial loss: 0.491910\n",
      "epoch 179; iter: 0; batch classifier loss: 0.294283; batch adversarial loss: 0.544924\n",
      "epoch 180; iter: 0; batch classifier loss: 0.430527; batch adversarial loss: 0.571037\n",
      "epoch 181; iter: 0; batch classifier loss: 0.266926; batch adversarial loss: 0.525684\n",
      "epoch 182; iter: 0; batch classifier loss: 0.385538; batch adversarial loss: 0.577942\n",
      "epoch 183; iter: 0; batch classifier loss: 0.395097; batch adversarial loss: 0.563340\n",
      "epoch 184; iter: 0; batch classifier loss: 0.337618; batch adversarial loss: 0.562322\n",
      "epoch 185; iter: 0; batch classifier loss: 0.346824; batch adversarial loss: 0.598876\n",
      "epoch 186; iter: 0; batch classifier loss: 0.364753; batch adversarial loss: 0.564414\n",
      "epoch 187; iter: 0; batch classifier loss: 0.429804; batch adversarial loss: 0.518493\n",
      "epoch 188; iter: 0; batch classifier loss: 0.407858; batch adversarial loss: 0.580502\n",
      "epoch 189; iter: 0; batch classifier loss: 0.405334; batch adversarial loss: 0.534556\n",
      "epoch 190; iter: 0; batch classifier loss: 0.441988; batch adversarial loss: 0.537121\n",
      "epoch 191; iter: 0; batch classifier loss: 0.355035; batch adversarial loss: 0.501855\n",
      "epoch 192; iter: 0; batch classifier loss: 0.372573; batch adversarial loss: 0.579593\n",
      "epoch 193; iter: 0; batch classifier loss: 0.384689; batch adversarial loss: 0.508175\n",
      "epoch 194; iter: 0; batch classifier loss: 0.364614; batch adversarial loss: 0.556189\n",
      "epoch 195; iter: 0; batch classifier loss: 0.315483; batch adversarial loss: 0.490243\n",
      "epoch 196; iter: 0; batch classifier loss: 0.480439; batch adversarial loss: 0.607986\n",
      "epoch 197; iter: 0; batch classifier loss: 0.335367; batch adversarial loss: 0.562193\n",
      "epoch 198; iter: 0; batch classifier loss: 0.360855; batch adversarial loss: 0.542463\n",
      "epoch 199; iter: 0; batch classifier loss: 0.319993; batch adversarial loss: 0.562683\n",
      "epoch 0; iter: 0; batch classifier loss: 0.891463; batch adversarial loss: 0.645288\n",
      "epoch 1; iter: 0; batch classifier loss: 0.596710; batch adversarial loss: 0.646594\n",
      "epoch 2; iter: 0; batch classifier loss: 0.604834; batch adversarial loss: 0.624877\n",
      "epoch 3; iter: 0; batch classifier loss: 0.578565; batch adversarial loss: 0.649947\n",
      "epoch 4; iter: 0; batch classifier loss: 0.553440; batch adversarial loss: 0.626171\n",
      "epoch 5; iter: 0; batch classifier loss: 0.553308; batch adversarial loss: 0.615571\n",
      "epoch 6; iter: 0; batch classifier loss: 0.573286; batch adversarial loss: 0.597501\n",
      "epoch 7; iter: 0; batch classifier loss: 0.525536; batch adversarial loss: 0.614789\n",
      "epoch 8; iter: 0; batch classifier loss: 0.524101; batch adversarial loss: 0.560805\n",
      "epoch 9; iter: 0; batch classifier loss: 0.537310; batch adversarial loss: 0.622014\n",
      "epoch 10; iter: 0; batch classifier loss: 0.573993; batch adversarial loss: 0.593577\n",
      "epoch 11; iter: 0; batch classifier loss: 0.496331; batch adversarial loss: 0.596263\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12; iter: 0; batch classifier loss: 0.579814; batch adversarial loss: 0.649657\n",
      "epoch 13; iter: 0; batch classifier loss: 0.487932; batch adversarial loss: 0.526881\n",
      "epoch 14; iter: 0; batch classifier loss: 0.540413; batch adversarial loss: 0.583751\n",
      "epoch 15; iter: 0; batch classifier loss: 0.434388; batch adversarial loss: 0.584155\n",
      "epoch 16; iter: 0; batch classifier loss: 0.579515; batch adversarial loss: 0.553802\n",
      "epoch 17; iter: 0; batch classifier loss: 0.488064; batch adversarial loss: 0.557667\n",
      "epoch 18; iter: 0; batch classifier loss: 0.522823; batch adversarial loss: 0.540414\n",
      "epoch 19; iter: 0; batch classifier loss: 0.556016; batch adversarial loss: 0.529234\n",
      "epoch 20; iter: 0; batch classifier loss: 0.438948; batch adversarial loss: 0.520505\n",
      "epoch 21; iter: 0; batch classifier loss: 0.537884; batch adversarial loss: 0.570288\n",
      "epoch 22; iter: 0; batch classifier loss: 0.417595; batch adversarial loss: 0.543853\n",
      "epoch 23; iter: 0; batch classifier loss: 0.459549; batch adversarial loss: 0.609889\n",
      "epoch 24; iter: 0; batch classifier loss: 0.461142; batch adversarial loss: 0.582422\n",
      "epoch 25; iter: 0; batch classifier loss: 0.450355; batch adversarial loss: 0.517874\n",
      "epoch 26; iter: 0; batch classifier loss: 0.500501; batch adversarial loss: 0.471640\n",
      "epoch 27; iter: 0; batch classifier loss: 0.499871; batch adversarial loss: 0.603057\n",
      "epoch 28; iter: 0; batch classifier loss: 0.453116; batch adversarial loss: 0.538362\n",
      "epoch 29; iter: 0; batch classifier loss: 0.444108; batch adversarial loss: 0.515159\n",
      "epoch 30; iter: 0; batch classifier loss: 0.463076; batch adversarial loss: 0.553910\n",
      "epoch 31; iter: 0; batch classifier loss: 0.485456; batch adversarial loss: 0.513945\n",
      "epoch 32; iter: 0; batch classifier loss: 0.378802; batch adversarial loss: 0.537944\n",
      "epoch 33; iter: 0; batch classifier loss: 0.456930; batch adversarial loss: 0.554485\n",
      "epoch 34; iter: 0; batch classifier loss: 0.475123; batch adversarial loss: 0.595930\n",
      "epoch 35; iter: 0; batch classifier loss: 0.415887; batch adversarial loss: 0.604540\n",
      "epoch 36; iter: 0; batch classifier loss: 0.432157; batch adversarial loss: 0.570635\n",
      "epoch 37; iter: 0; batch classifier loss: 0.412111; batch adversarial loss: 0.545194\n",
      "epoch 38; iter: 0; batch classifier loss: 0.393905; batch adversarial loss: 0.543559\n",
      "epoch 39; iter: 0; batch classifier loss: 0.407709; batch adversarial loss: 0.570615\n",
      "epoch 40; iter: 0; batch classifier loss: 0.390017; batch adversarial loss: 0.493522\n",
      "epoch 41; iter: 0; batch classifier loss: 0.418229; batch adversarial loss: 0.536406\n",
      "epoch 42; iter: 0; batch classifier loss: 0.506757; batch adversarial loss: 0.572761\n",
      "epoch 43; iter: 0; batch classifier loss: 0.399209; batch adversarial loss: 0.493366\n",
      "epoch 44; iter: 0; batch classifier loss: 0.485113; batch adversarial loss: 0.650382\n",
      "epoch 45; iter: 0; batch classifier loss: 0.499530; batch adversarial loss: 0.510984\n",
      "epoch 46; iter: 0; batch classifier loss: 0.388193; batch adversarial loss: 0.587598\n",
      "epoch 47; iter: 0; batch classifier loss: 0.407645; batch adversarial loss: 0.570739\n",
      "epoch 48; iter: 0; batch classifier loss: 0.470103; batch adversarial loss: 0.537787\n",
      "epoch 49; iter: 0; batch classifier loss: 0.457667; batch adversarial loss: 0.596532\n",
      "epoch 50; iter: 0; batch classifier loss: 0.395192; batch adversarial loss: 0.536696\n",
      "epoch 51; iter: 0; batch classifier loss: 0.512100; batch adversarial loss: 0.528542\n",
      "epoch 52; iter: 0; batch classifier loss: 0.360139; batch adversarial loss: 0.614586\n",
      "epoch 53; iter: 0; batch classifier loss: 0.400447; batch adversarial loss: 0.553268\n",
      "epoch 54; iter: 0; batch classifier loss: 0.459707; batch adversarial loss: 0.536260\n",
      "epoch 55; iter: 0; batch classifier loss: 0.430728; batch adversarial loss: 0.543588\n",
      "epoch 56; iter: 0; batch classifier loss: 0.390601; batch adversarial loss: 0.483795\n",
      "epoch 57; iter: 0; batch classifier loss: 0.428674; batch adversarial loss: 0.553876\n",
      "epoch 58; iter: 0; batch classifier loss: 0.354382; batch adversarial loss: 0.510231\n",
      "epoch 59; iter: 0; batch classifier loss: 0.392073; batch adversarial loss: 0.528765\n",
      "epoch 60; iter: 0; batch classifier loss: 0.517677; batch adversarial loss: 0.536377\n",
      "epoch 61; iter: 0; batch classifier loss: 0.433777; batch adversarial loss: 0.537106\n",
      "epoch 62; iter: 0; batch classifier loss: 0.408769; batch adversarial loss: 0.536551\n",
      "epoch 63; iter: 0; batch classifier loss: 0.401185; batch adversarial loss: 0.579208\n",
      "epoch 64; iter: 0; batch classifier loss: 0.419276; batch adversarial loss: 0.545576\n",
      "epoch 65; iter: 0; batch classifier loss: 0.334043; batch adversarial loss: 0.605369\n",
      "epoch 66; iter: 0; batch classifier loss: 0.375818; batch adversarial loss: 0.545944\n",
      "epoch 67; iter: 0; batch classifier loss: 0.471092; batch adversarial loss: 0.571672\n",
      "epoch 68; iter: 0; batch classifier loss: 0.423166; batch adversarial loss: 0.518887\n",
      "epoch 69; iter: 0; batch classifier loss: 0.375435; batch adversarial loss: 0.588505\n",
      "epoch 70; iter: 0; batch classifier loss: 0.380244; batch adversarial loss: 0.579400\n",
      "epoch 71; iter: 0; batch classifier loss: 0.455417; batch adversarial loss: 0.578490\n",
      "epoch 72; iter: 0; batch classifier loss: 0.402971; batch adversarial loss: 0.648674\n",
      "epoch 73; iter: 0; batch classifier loss: 0.439647; batch adversarial loss: 0.571086\n",
      "epoch 74; iter: 0; batch classifier loss: 0.410030; batch adversarial loss: 0.562552\n",
      "epoch 75; iter: 0; batch classifier loss: 0.448267; batch adversarial loss: 0.588414\n",
      "epoch 76; iter: 0; batch classifier loss: 0.385164; batch adversarial loss: 0.578809\n",
      "epoch 77; iter: 0; batch classifier loss: 0.341918; batch adversarial loss: 0.535875\n",
      "epoch 78; iter: 0; batch classifier loss: 0.426124; batch adversarial loss: 0.614187\n",
      "epoch 79; iter: 0; batch classifier loss: 0.391433; batch adversarial loss: 0.493453\n",
      "epoch 80; iter: 0; batch classifier loss: 0.463624; batch adversarial loss: 0.605724\n",
      "epoch 81; iter: 0; batch classifier loss: 0.366315; batch adversarial loss: 0.588235\n",
      "epoch 82; iter: 0; batch classifier loss: 0.373172; batch adversarial loss: 0.570913\n",
      "epoch 83; iter: 0; batch classifier loss: 0.349066; batch adversarial loss: 0.648004\n",
      "epoch 84; iter: 0; batch classifier loss: 0.403330; batch adversarial loss: 0.553275\n",
      "epoch 85; iter: 0; batch classifier loss: 0.378287; batch adversarial loss: 0.596023\n",
      "epoch 86; iter: 0; batch classifier loss: 0.367784; batch adversarial loss: 0.511110\n",
      "epoch 87; iter: 0; batch classifier loss: 0.402588; batch adversarial loss: 0.580761\n",
      "epoch 88; iter: 0; batch classifier loss: 0.348415; batch adversarial loss: 0.569235\n",
      "epoch 89; iter: 0; batch classifier loss: 0.392121; batch adversarial loss: 0.535082\n",
      "epoch 90; iter: 0; batch classifier loss: 0.362786; batch adversarial loss: 0.578778\n",
      "epoch 91; iter: 0; batch classifier loss: 0.409270; batch adversarial loss: 0.529491\n",
      "epoch 92; iter: 0; batch classifier loss: 0.490580; batch adversarial loss: 0.578446\n",
      "epoch 93; iter: 0; batch classifier loss: 0.357392; batch adversarial loss: 0.571071\n",
      "epoch 94; iter: 0; batch classifier loss: 0.402700; batch adversarial loss: 0.493714\n",
      "epoch 95; iter: 0; batch classifier loss: 0.426591; batch adversarial loss: 0.562142\n",
      "epoch 96; iter: 0; batch classifier loss: 0.372061; batch adversarial loss: 0.457110\n",
      "epoch 97; iter: 0; batch classifier loss: 0.418205; batch adversarial loss: 0.501811\n",
      "epoch 98; iter: 0; batch classifier loss: 0.403154; batch adversarial loss: 0.606258\n",
      "epoch 99; iter: 0; batch classifier loss: 0.370861; batch adversarial loss: 0.527030\n",
      "epoch 100; iter: 0; batch classifier loss: 0.352388; batch adversarial loss: 0.501146\n",
      "epoch 101; iter: 0; batch classifier loss: 0.395814; batch adversarial loss: 0.614392\n",
      "epoch 102; iter: 0; batch classifier loss: 0.398974; batch adversarial loss: 0.596671\n",
      "epoch 103; iter: 0; batch classifier loss: 0.351588; batch adversarial loss: 0.518508\n",
      "epoch 104; iter: 0; batch classifier loss: 0.346043; batch adversarial loss: 0.597496\n",
      "epoch 105; iter: 0; batch classifier loss: 0.416044; batch adversarial loss: 0.571935\n",
      "epoch 106; iter: 0; batch classifier loss: 0.437101; batch adversarial loss: 0.466495\n",
      "epoch 107; iter: 0; batch classifier loss: 0.345492; batch adversarial loss: 0.510319\n",
      "epoch 108; iter: 0; batch classifier loss: 0.364871; batch adversarial loss: 0.615266\n",
      "epoch 109; iter: 0; batch classifier loss: 0.416699; batch adversarial loss: 0.553027\n",
      "epoch 110; iter: 0; batch classifier loss: 0.430345; batch adversarial loss: 0.528249\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 111; iter: 0; batch classifier loss: 0.403757; batch adversarial loss: 0.571340\n",
      "epoch 112; iter: 0; batch classifier loss: 0.348373; batch adversarial loss: 0.571703\n",
      "epoch 113; iter: 0; batch classifier loss: 0.455534; batch adversarial loss: 0.526874\n",
      "epoch 114; iter: 0; batch classifier loss: 0.363733; batch adversarial loss: 0.527470\n",
      "epoch 115; iter: 0; batch classifier loss: 0.401441; batch adversarial loss: 0.527416\n",
      "epoch 116; iter: 0; batch classifier loss: 0.370764; batch adversarial loss: 0.622940\n",
      "epoch 117; iter: 0; batch classifier loss: 0.393662; batch adversarial loss: 0.571173\n",
      "epoch 118; iter: 0; batch classifier loss: 0.404639; batch adversarial loss: 0.510429\n",
      "epoch 119; iter: 0; batch classifier loss: 0.348818; batch adversarial loss: 0.571163\n",
      "epoch 120; iter: 0; batch classifier loss: 0.421207; batch adversarial loss: 0.570802\n",
      "epoch 121; iter: 0; batch classifier loss: 0.460269; batch adversarial loss: 0.510486\n",
      "epoch 122; iter: 0; batch classifier loss: 0.458700; batch adversarial loss: 0.536601\n",
      "epoch 123; iter: 0; batch classifier loss: 0.346243; batch adversarial loss: 0.536073\n",
      "epoch 124; iter: 0; batch classifier loss: 0.347500; batch adversarial loss: 0.596831\n",
      "epoch 125; iter: 0; batch classifier loss: 0.329518; batch adversarial loss: 0.553874\n",
      "epoch 126; iter: 0; batch classifier loss: 0.396848; batch adversarial loss: 0.632045\n",
      "epoch 127; iter: 0; batch classifier loss: 0.433036; batch adversarial loss: 0.640517\n",
      "epoch 128; iter: 0; batch classifier loss: 0.378245; batch adversarial loss: 0.534869\n",
      "epoch 129; iter: 0; batch classifier loss: 0.481548; batch adversarial loss: 0.605953\n",
      "epoch 130; iter: 0; batch classifier loss: 0.333297; batch adversarial loss: 0.510864\n",
      "epoch 131; iter: 0; batch classifier loss: 0.388423; batch adversarial loss: 0.631850\n",
      "epoch 132; iter: 0; batch classifier loss: 0.409197; batch adversarial loss: 0.579574\n",
      "epoch 133; iter: 0; batch classifier loss: 0.362426; batch adversarial loss: 0.553795\n",
      "epoch 134; iter: 0; batch classifier loss: 0.399453; batch adversarial loss: 0.553732\n",
      "epoch 135; iter: 0; batch classifier loss: 0.322691; batch adversarial loss: 0.553781\n",
      "epoch 136; iter: 0; batch classifier loss: 0.333757; batch adversarial loss: 0.519209\n",
      "epoch 137; iter: 0; batch classifier loss: 0.418417; batch adversarial loss: 0.562646\n",
      "epoch 138; iter: 0; batch classifier loss: 0.363514; batch adversarial loss: 0.640227\n",
      "epoch 139; iter: 0; batch classifier loss: 0.355121; batch adversarial loss: 0.613996\n",
      "epoch 140; iter: 0; batch classifier loss: 0.413380; batch adversarial loss: 0.545002\n",
      "epoch 141; iter: 0; batch classifier loss: 0.341033; batch adversarial loss: 0.501629\n",
      "epoch 142; iter: 0; batch classifier loss: 0.283270; batch adversarial loss: 0.544246\n",
      "epoch 143; iter: 0; batch classifier loss: 0.396832; batch adversarial loss: 0.527199\n",
      "epoch 144; iter: 0; batch classifier loss: 0.427792; batch adversarial loss: 0.561945\n",
      "epoch 145; iter: 0; batch classifier loss: 0.351458; batch adversarial loss: 0.588871\n",
      "epoch 146; iter: 0; batch classifier loss: 0.331902; batch adversarial loss: 0.588351\n",
      "epoch 147; iter: 0; batch classifier loss: 0.412191; batch adversarial loss: 0.588040\n",
      "epoch 148; iter: 0; batch classifier loss: 0.427261; batch adversarial loss: 0.535866\n",
      "epoch 149; iter: 0; batch classifier loss: 0.366293; batch adversarial loss: 0.537114\n",
      "epoch 150; iter: 0; batch classifier loss: 0.314967; batch adversarial loss: 0.484700\n",
      "epoch 151; iter: 0; batch classifier loss: 0.392838; batch adversarial loss: 0.613547\n",
      "epoch 152; iter: 0; batch classifier loss: 0.320813; batch adversarial loss: 0.562503\n",
      "epoch 153; iter: 0; batch classifier loss: 0.361195; batch adversarial loss: 0.622481\n",
      "epoch 154; iter: 0; batch classifier loss: 0.325135; batch adversarial loss: 0.536306\n",
      "epoch 155; iter: 0; batch classifier loss: 0.397659; batch adversarial loss: 0.666478\n",
      "epoch 156; iter: 0; batch classifier loss: 0.423947; batch adversarial loss: 0.605413\n",
      "epoch 157; iter: 0; batch classifier loss: 0.372260; batch adversarial loss: 0.623227\n",
      "epoch 158; iter: 0; batch classifier loss: 0.329041; batch adversarial loss: 0.614218\n",
      "epoch 159; iter: 0; batch classifier loss: 0.393607; batch adversarial loss: 0.639722\n",
      "epoch 160; iter: 0; batch classifier loss: 0.294330; batch adversarial loss: 0.536616\n",
      "epoch 161; iter: 0; batch classifier loss: 0.335455; batch adversarial loss: 0.545241\n",
      "epoch 162; iter: 0; batch classifier loss: 0.464029; batch adversarial loss: 0.562571\n",
      "epoch 163; iter: 0; batch classifier loss: 0.324430; batch adversarial loss: 0.562527\n",
      "epoch 164; iter: 0; batch classifier loss: 0.351588; batch adversarial loss: 0.501688\n",
      "epoch 165; iter: 0; batch classifier loss: 0.306972; batch adversarial loss: 0.613976\n",
      "epoch 166; iter: 0; batch classifier loss: 0.390520; batch adversarial loss: 0.562211\n",
      "epoch 167; iter: 0; batch classifier loss: 0.424364; batch adversarial loss: 0.553866\n",
      "epoch 168; iter: 0; batch classifier loss: 0.416007; batch adversarial loss: 0.588057\n",
      "epoch 169; iter: 0; batch classifier loss: 0.350815; batch adversarial loss: 0.545024\n",
      "epoch 170; iter: 0; batch classifier loss: 0.374100; batch adversarial loss: 0.536447\n",
      "epoch 171; iter: 0; batch classifier loss: 0.398870; batch adversarial loss: 0.553703\n",
      "epoch 172; iter: 0; batch classifier loss: 0.418900; batch adversarial loss: 0.510639\n",
      "epoch 173; iter: 0; batch classifier loss: 0.415173; batch adversarial loss: 0.605534\n",
      "epoch 174; iter: 0; batch classifier loss: 0.376783; batch adversarial loss: 0.501796\n",
      "epoch 175; iter: 0; batch classifier loss: 0.369315; batch adversarial loss: 0.553699\n",
      "epoch 176; iter: 0; batch classifier loss: 0.302804; batch adversarial loss: 0.553572\n",
      "epoch 177; iter: 0; batch classifier loss: 0.315953; batch adversarial loss: 0.544997\n",
      "epoch 178; iter: 0; batch classifier loss: 0.340125; batch adversarial loss: 0.552838\n",
      "epoch 179; iter: 0; batch classifier loss: 0.364840; batch adversarial loss: 0.604320\n",
      "epoch 180; iter: 0; batch classifier loss: 0.402255; batch adversarial loss: 0.545414\n",
      "epoch 181; iter: 0; batch classifier loss: 0.376207; batch adversarial loss: 0.587342\n",
      "epoch 182; iter: 0; batch classifier loss: 0.373609; batch adversarial loss: 0.570193\n",
      "epoch 183; iter: 0; batch classifier loss: 0.381591; batch adversarial loss: 0.554165\n",
      "epoch 184; iter: 0; batch classifier loss: 0.339342; batch adversarial loss: 0.545713\n",
      "epoch 185; iter: 0; batch classifier loss: 0.431261; batch adversarial loss: 0.623841\n",
      "epoch 186; iter: 0; batch classifier loss: 0.436818; batch adversarial loss: 0.571089\n",
      "epoch 187; iter: 0; batch classifier loss: 0.374976; batch adversarial loss: 0.579878\n",
      "epoch 188; iter: 0; batch classifier loss: 0.439553; batch adversarial loss: 0.588411\n",
      "epoch 189; iter: 0; batch classifier loss: 0.313289; batch adversarial loss: 0.544780\n",
      "epoch 190; iter: 0; batch classifier loss: 0.298689; batch adversarial loss: 0.579540\n",
      "epoch 191; iter: 0; batch classifier loss: 0.398107; batch adversarial loss: 0.639576\n",
      "epoch 192; iter: 0; batch classifier loss: 0.430500; batch adversarial loss: 0.587641\n",
      "epoch 193; iter: 0; batch classifier loss: 0.364768; batch adversarial loss: 0.519256\n",
      "epoch 194; iter: 0; batch classifier loss: 0.383129; batch adversarial loss: 0.476070\n",
      "epoch 195; iter: 0; batch classifier loss: 0.376567; batch adversarial loss: 0.492902\n",
      "epoch 196; iter: 0; batch classifier loss: 0.295065; batch adversarial loss: 0.553387\n",
      "epoch 197; iter: 0; batch classifier loss: 0.259768; batch adversarial loss: 0.587625\n",
      "epoch 198; iter: 0; batch classifier loss: 0.339966; batch adversarial loss: 0.536143\n",
      "epoch 199; iter: 0; batch classifier loss: 0.437865; batch adversarial loss: 0.649221\n",
      "epoch 0; iter: 0; batch classifier loss: 0.700406; batch adversarial loss: 0.712923\n",
      "epoch 1; iter: 0; batch classifier loss: 0.634390; batch adversarial loss: 0.677311\n",
      "epoch 2; iter: 0; batch classifier loss: 0.527869; batch adversarial loss: 0.663586\n",
      "epoch 3; iter: 0; batch classifier loss: 0.550726; batch adversarial loss: 0.636283\n",
      "epoch 4; iter: 0; batch classifier loss: 0.615614; batch adversarial loss: 0.623590\n",
      "epoch 5; iter: 0; batch classifier loss: 0.594586; batch adversarial loss: 0.626724\n",
      "epoch 6; iter: 0; batch classifier loss: 0.500899; batch adversarial loss: 0.583019\n",
      "epoch 7; iter: 0; batch classifier loss: 0.650325; batch adversarial loss: 0.595316\n",
      "epoch 8; iter: 0; batch classifier loss: 0.512987; batch adversarial loss: 0.568212\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9; iter: 0; batch classifier loss: 0.590137; batch adversarial loss: 0.632997\n",
      "epoch 10; iter: 0; batch classifier loss: 0.484682; batch adversarial loss: 0.596525\n",
      "epoch 11; iter: 0; batch classifier loss: 0.597343; batch adversarial loss: 0.574650\n",
      "epoch 12; iter: 0; batch classifier loss: 0.456422; batch adversarial loss: 0.604900\n",
      "epoch 13; iter: 0; batch classifier loss: 0.500245; batch adversarial loss: 0.547173\n",
      "epoch 14; iter: 0; batch classifier loss: 0.538667; batch adversarial loss: 0.576781\n",
      "epoch 15; iter: 0; batch classifier loss: 0.505307; batch adversarial loss: 0.596722\n",
      "epoch 16; iter: 0; batch classifier loss: 0.491078; batch adversarial loss: 0.545946\n",
      "epoch 17; iter: 0; batch classifier loss: 0.470254; batch adversarial loss: 0.555531\n",
      "epoch 18; iter: 0; batch classifier loss: 0.572656; batch adversarial loss: 0.515504\n",
      "epoch 19; iter: 0; batch classifier loss: 0.441255; batch adversarial loss: 0.552610\n",
      "epoch 20; iter: 0; batch classifier loss: 0.549741; batch adversarial loss: 0.554859\n",
      "epoch 21; iter: 0; batch classifier loss: 0.451059; batch adversarial loss: 0.543888\n",
      "epoch 22; iter: 0; batch classifier loss: 0.422532; batch adversarial loss: 0.620824\n",
      "epoch 23; iter: 0; batch classifier loss: 0.488940; batch adversarial loss: 0.595777\n",
      "epoch 24; iter: 0; batch classifier loss: 0.479749; batch adversarial loss: 0.541464\n",
      "epoch 25; iter: 0; batch classifier loss: 0.393013; batch adversarial loss: 0.492362\n",
      "epoch 26; iter: 0; batch classifier loss: 0.481789; batch adversarial loss: 0.616302\n",
      "epoch 27; iter: 0; batch classifier loss: 0.448598; batch adversarial loss: 0.520604\n",
      "epoch 28; iter: 0; batch classifier loss: 0.481459; batch adversarial loss: 0.630235\n",
      "epoch 29; iter: 0; batch classifier loss: 0.469063; batch adversarial loss: 0.565708\n",
      "epoch 30; iter: 0; batch classifier loss: 0.473020; batch adversarial loss: 0.616287\n",
      "epoch 31; iter: 0; batch classifier loss: 0.458066; batch adversarial loss: 0.500065\n",
      "epoch 32; iter: 0; batch classifier loss: 0.499233; batch adversarial loss: 0.604353\n",
      "epoch 33; iter: 0; batch classifier loss: 0.386890; batch adversarial loss: 0.537042\n",
      "epoch 34; iter: 0; batch classifier loss: 0.422216; batch adversarial loss: 0.482444\n",
      "epoch 35; iter: 0; batch classifier loss: 0.489919; batch adversarial loss: 0.617072\n",
      "epoch 36; iter: 0; batch classifier loss: 0.474426; batch adversarial loss: 0.588292\n",
      "epoch 37; iter: 0; batch classifier loss: 0.394985; batch adversarial loss: 0.526828\n",
      "epoch 38; iter: 0; batch classifier loss: 0.457334; batch adversarial loss: 0.580461\n",
      "epoch 39; iter: 0; batch classifier loss: 0.474691; batch adversarial loss: 0.553222\n",
      "epoch 40; iter: 0; batch classifier loss: 0.419089; batch adversarial loss: 0.563521\n",
      "epoch 41; iter: 0; batch classifier loss: 0.525346; batch adversarial loss: 0.537969\n",
      "epoch 42; iter: 0; batch classifier loss: 0.464321; batch adversarial loss: 0.633401\n",
      "epoch 43; iter: 0; batch classifier loss: 0.406803; batch adversarial loss: 0.607109\n",
      "epoch 44; iter: 0; batch classifier loss: 0.357014; batch adversarial loss: 0.602785\n",
      "epoch 45; iter: 0; batch classifier loss: 0.417358; batch adversarial loss: 0.546937\n",
      "epoch 46; iter: 0; batch classifier loss: 0.469952; batch adversarial loss: 0.529766\n",
      "epoch 47; iter: 0; batch classifier loss: 0.375873; batch adversarial loss: 0.586676\n",
      "epoch 48; iter: 0; batch classifier loss: 0.400734; batch adversarial loss: 0.562545\n",
      "epoch 49; iter: 0; batch classifier loss: 0.478201; batch adversarial loss: 0.537264\n",
      "epoch 50; iter: 0; batch classifier loss: 0.374070; batch adversarial loss: 0.519553\n",
      "epoch 51; iter: 0; batch classifier loss: 0.382424; batch adversarial loss: 0.553498\n",
      "epoch 52; iter: 0; batch classifier loss: 0.374863; batch adversarial loss: 0.569616\n",
      "epoch 53; iter: 0; batch classifier loss: 0.449317; batch adversarial loss: 0.569684\n",
      "epoch 54; iter: 0; batch classifier loss: 0.432166; batch adversarial loss: 0.568506\n",
      "epoch 55; iter: 0; batch classifier loss: 0.439812; batch adversarial loss: 0.595545\n",
      "epoch 56; iter: 0; batch classifier loss: 0.368863; batch adversarial loss: 0.494808\n",
      "epoch 57; iter: 0; batch classifier loss: 0.381040; batch adversarial loss: 0.509678\n",
      "epoch 58; iter: 0; batch classifier loss: 0.446356; batch adversarial loss: 0.537233\n",
      "epoch 59; iter: 0; batch classifier loss: 0.478248; batch adversarial loss: 0.480362\n",
      "epoch 60; iter: 0; batch classifier loss: 0.333773; batch adversarial loss: 0.608891\n",
      "epoch 61; iter: 0; batch classifier loss: 0.415831; batch adversarial loss: 0.511840\n",
      "epoch 62; iter: 0; batch classifier loss: 0.356307; batch adversarial loss: 0.546038\n",
      "epoch 63; iter: 0; batch classifier loss: 0.392499; batch adversarial loss: 0.571111\n",
      "epoch 64; iter: 0; batch classifier loss: 0.378815; batch adversarial loss: 0.517657\n",
      "epoch 65; iter: 0; batch classifier loss: 0.388420; batch adversarial loss: 0.721629\n",
      "epoch 66; iter: 0; batch classifier loss: 0.460957; batch adversarial loss: 0.535673\n",
      "epoch 67; iter: 0; batch classifier loss: 0.402141; batch adversarial loss: 0.562637\n",
      "epoch 68; iter: 0; batch classifier loss: 0.352937; batch adversarial loss: 0.588481\n",
      "epoch 69; iter: 0; batch classifier loss: 0.355538; batch adversarial loss: 0.605586\n",
      "epoch 70; iter: 0; batch classifier loss: 0.418492; batch adversarial loss: 0.623051\n",
      "epoch 71; iter: 0; batch classifier loss: 0.417773; batch adversarial loss: 0.562443\n",
      "epoch 72; iter: 0; batch classifier loss: 0.338287; batch adversarial loss: 0.562097\n",
      "epoch 73; iter: 0; batch classifier loss: 0.405249; batch adversarial loss: 0.493183\n",
      "epoch 74; iter: 0; batch classifier loss: 0.381196; batch adversarial loss: 0.545331\n",
      "epoch 75; iter: 0; batch classifier loss: 0.404590; batch adversarial loss: 0.562612\n",
      "epoch 76; iter: 0; batch classifier loss: 0.366713; batch adversarial loss: 0.519135\n",
      "epoch 77; iter: 0; batch classifier loss: 0.353935; batch adversarial loss: 0.570405\n",
      "epoch 78; iter: 0; batch classifier loss: 0.439422; batch adversarial loss: 0.614255\n",
      "epoch 79; iter: 0; batch classifier loss: 0.358210; batch adversarial loss: 0.484134\n",
      "epoch 80; iter: 0; batch classifier loss: 0.406503; batch adversarial loss: 0.484371\n",
      "epoch 81; iter: 0; batch classifier loss: 0.393251; batch adversarial loss: 0.579761\n",
      "epoch 82; iter: 0; batch classifier loss: 0.443347; batch adversarial loss: 0.474671\n",
      "epoch 83; iter: 0; batch classifier loss: 0.395899; batch adversarial loss: 0.588709\n",
      "epoch 84; iter: 0; batch classifier loss: 0.411900; batch adversarial loss: 0.614928\n",
      "epoch 85; iter: 0; batch classifier loss: 0.388742; batch adversarial loss: 0.553687\n",
      "epoch 86; iter: 0; batch classifier loss: 0.371544; batch adversarial loss: 0.527422\n",
      "epoch 87; iter: 0; batch classifier loss: 0.459466; batch adversarial loss: 0.588765\n",
      "epoch 88; iter: 0; batch classifier loss: 0.332127; batch adversarial loss: 0.535637\n",
      "epoch 89; iter: 0; batch classifier loss: 0.453741; batch adversarial loss: 0.553138\n",
      "epoch 90; iter: 0; batch classifier loss: 0.339891; batch adversarial loss: 0.605449\n",
      "epoch 91; iter: 0; batch classifier loss: 0.338070; batch adversarial loss: 0.554289\n",
      "epoch 92; iter: 0; batch classifier loss: 0.295765; batch adversarial loss: 0.508851\n",
      "epoch 93; iter: 0; batch classifier loss: 0.429220; batch adversarial loss: 0.563921\n",
      "epoch 94; iter: 0; batch classifier loss: 0.439416; batch adversarial loss: 0.616770\n",
      "epoch 95; iter: 0; batch classifier loss: 0.364167; batch adversarial loss: 0.650920\n",
      "epoch 96; iter: 0; batch classifier loss: 0.425530; batch adversarial loss: 0.553834\n",
      "epoch 97; iter: 0; batch classifier loss: 0.409582; batch adversarial loss: 0.595419\n",
      "epoch 98; iter: 0; batch classifier loss: 0.356709; batch adversarial loss: 0.527609\n",
      "epoch 99; iter: 0; batch classifier loss: 0.348833; batch adversarial loss: 0.544058\n",
      "epoch 100; iter: 0; batch classifier loss: 0.420433; batch adversarial loss: 0.579573\n",
      "epoch 101; iter: 0; batch classifier loss: 0.431771; batch adversarial loss: 0.571895\n",
      "epoch 102; iter: 0; batch classifier loss: 0.363767; batch adversarial loss: 0.621878\n",
      "epoch 103; iter: 0; batch classifier loss: 0.383703; batch adversarial loss: 0.622632\n",
      "epoch 104; iter: 0; batch classifier loss: 0.415160; batch adversarial loss: 0.544562\n",
      "epoch 105; iter: 0; batch classifier loss: 0.339840; batch adversarial loss: 0.562271\n",
      "epoch 106; iter: 0; batch classifier loss: 0.273360; batch adversarial loss: 0.562712\n",
      "epoch 107; iter: 0; batch classifier loss: 0.419880; batch adversarial loss: 0.571358\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 108; iter: 0; batch classifier loss: 0.527626; batch adversarial loss: 0.614203\n",
      "epoch 109; iter: 0; batch classifier loss: 0.428160; batch adversarial loss: 0.519126\n",
      "epoch 110; iter: 0; batch classifier loss: 0.350932; batch adversarial loss: 0.500778\n",
      "epoch 111; iter: 0; batch classifier loss: 0.311221; batch adversarial loss: 0.554025\n",
      "epoch 112; iter: 0; batch classifier loss: 0.377590; batch adversarial loss: 0.500934\n",
      "epoch 113; iter: 0; batch classifier loss: 0.339760; batch adversarial loss: 0.500972\n",
      "epoch 114; iter: 0; batch classifier loss: 0.355831; batch adversarial loss: 0.596876\n",
      "epoch 115; iter: 0; batch classifier loss: 0.341207; batch adversarial loss: 0.545074\n",
      "epoch 116; iter: 0; batch classifier loss: 0.375852; batch adversarial loss: 0.553977\n",
      "epoch 117; iter: 0; batch classifier loss: 0.396274; batch adversarial loss: 0.597150\n",
      "epoch 118; iter: 0; batch classifier loss: 0.347949; batch adversarial loss: 0.562524\n",
      "epoch 119; iter: 0; batch classifier loss: 0.342686; batch adversarial loss: 0.545570\n",
      "epoch 120; iter: 0; batch classifier loss: 0.337880; batch adversarial loss: 0.579830\n",
      "epoch 121; iter: 0; batch classifier loss: 0.397665; batch adversarial loss: 0.544486\n",
      "epoch 122; iter: 0; batch classifier loss: 0.392931; batch adversarial loss: 0.545143\n",
      "epoch 123; iter: 0; batch classifier loss: 0.344626; batch adversarial loss: 0.553124\n",
      "epoch 124; iter: 0; batch classifier loss: 0.390301; batch adversarial loss: 0.518876\n",
      "epoch 125; iter: 0; batch classifier loss: 0.299777; batch adversarial loss: 0.605735\n",
      "epoch 126; iter: 0; batch classifier loss: 0.312702; batch adversarial loss: 0.562402\n",
      "epoch 127; iter: 0; batch classifier loss: 0.301781; batch adversarial loss: 0.536152\n",
      "epoch 128; iter: 0; batch classifier loss: 0.367786; batch adversarial loss: 0.588292\n",
      "epoch 129; iter: 0; batch classifier loss: 0.315516; batch adversarial loss: 0.527530\n",
      "epoch 130; iter: 0; batch classifier loss: 0.332101; batch adversarial loss: 0.614883\n",
      "epoch 131; iter: 0; batch classifier loss: 0.364647; batch adversarial loss: 0.519008\n",
      "epoch 132; iter: 0; batch classifier loss: 0.390747; batch adversarial loss: 0.553474\n",
      "epoch 133; iter: 0; batch classifier loss: 0.295264; batch adversarial loss: 0.588749\n",
      "epoch 134; iter: 0; batch classifier loss: 0.322992; batch adversarial loss: 0.553526\n",
      "epoch 135; iter: 0; batch classifier loss: 0.306002; batch adversarial loss: 0.483952\n",
      "epoch 136; iter: 0; batch classifier loss: 0.377779; batch adversarial loss: 0.614588\n",
      "epoch 137; iter: 0; batch classifier loss: 0.426681; batch adversarial loss: 0.570744\n",
      "epoch 138; iter: 0; batch classifier loss: 0.327080; batch adversarial loss: 0.570799\n",
      "epoch 139; iter: 0; batch classifier loss: 0.377505; batch adversarial loss: 0.545565\n",
      "epoch 140; iter: 0; batch classifier loss: 0.317107; batch adversarial loss: 0.562612\n",
      "epoch 141; iter: 0; batch classifier loss: 0.359405; batch adversarial loss: 0.536432\n",
      "epoch 142; iter: 0; batch classifier loss: 0.425417; batch adversarial loss: 0.630961\n",
      "epoch 143; iter: 0; batch classifier loss: 0.388831; batch adversarial loss: 0.578738\n",
      "epoch 144; iter: 0; batch classifier loss: 0.376300; batch adversarial loss: 0.595606\n",
      "epoch 145; iter: 0; batch classifier loss: 0.404422; batch adversarial loss: 0.493323\n",
      "epoch 146; iter: 0; batch classifier loss: 0.360439; batch adversarial loss: 0.631478\n",
      "epoch 147; iter: 0; batch classifier loss: 0.317681; batch adversarial loss: 0.511950\n",
      "epoch 148; iter: 0; batch classifier loss: 0.345446; batch adversarial loss: 0.494978\n",
      "epoch 149; iter: 0; batch classifier loss: 0.415236; batch adversarial loss: 0.536285\n",
      "epoch 150; iter: 0; batch classifier loss: 0.378603; batch adversarial loss: 0.596149\n",
      "epoch 151; iter: 0; batch classifier loss: 0.474302; batch adversarial loss: 0.536224\n",
      "epoch 152; iter: 0; batch classifier loss: 0.351861; batch adversarial loss: 0.518849\n",
      "epoch 153; iter: 0; batch classifier loss: 0.472074; batch adversarial loss: 0.535101\n",
      "epoch 154; iter: 0; batch classifier loss: 0.343545; batch adversarial loss: 0.527965\n",
      "epoch 155; iter: 0; batch classifier loss: 0.358574; batch adversarial loss: 0.467101\n",
      "epoch 156; iter: 0; batch classifier loss: 0.346833; batch adversarial loss: 0.484622\n",
      "epoch 157; iter: 0; batch classifier loss: 0.368725; batch adversarial loss: 0.614286\n",
      "epoch 158; iter: 0; batch classifier loss: 0.327549; batch adversarial loss: 0.606677\n",
      "epoch 159; iter: 0; batch classifier loss: 0.377047; batch adversarial loss: 0.606298\n",
      "epoch 160; iter: 0; batch classifier loss: 0.342649; batch adversarial loss: 0.501004\n",
      "epoch 161; iter: 0; batch classifier loss: 0.341145; batch adversarial loss: 0.588726\n",
      "epoch 162; iter: 0; batch classifier loss: 0.339185; batch adversarial loss: 0.483470\n",
      "epoch 163; iter: 0; batch classifier loss: 0.384763; batch adversarial loss: 0.465986\n",
      "epoch 164; iter: 0; batch classifier loss: 0.309828; batch adversarial loss: 0.579978\n",
      "epoch 165; iter: 0; batch classifier loss: 0.403916; batch adversarial loss: 0.544866\n",
      "epoch 166; iter: 0; batch classifier loss: 0.336174; batch adversarial loss: 0.527462\n",
      "epoch 167; iter: 0; batch classifier loss: 0.312890; batch adversarial loss: 0.571008\n",
      "epoch 168; iter: 0; batch classifier loss: 0.385063; batch adversarial loss: 0.579424\n",
      "epoch 169; iter: 0; batch classifier loss: 0.349996; batch adversarial loss: 0.519050\n",
      "epoch 170; iter: 0; batch classifier loss: 0.284064; batch adversarial loss: 0.544875\n",
      "epoch 171; iter: 0; batch classifier loss: 0.383789; batch adversarial loss: 0.544320\n",
      "epoch 172; iter: 0; batch classifier loss: 0.323654; batch adversarial loss: 0.484686\n",
      "epoch 173; iter: 0; batch classifier loss: 0.336069; batch adversarial loss: 0.631475\n",
      "epoch 174; iter: 0; batch classifier loss: 0.354544; batch adversarial loss: 0.580191\n",
      "epoch 175; iter: 0; batch classifier loss: 0.401079; batch adversarial loss: 0.501425\n",
      "epoch 176; iter: 0; batch classifier loss: 0.310171; batch adversarial loss: 0.623295\n",
      "epoch 177; iter: 0; batch classifier loss: 0.352122; batch adversarial loss: 0.467256\n",
      "epoch 178; iter: 0; batch classifier loss: 0.340795; batch adversarial loss: 0.544431\n",
      "epoch 179; iter: 0; batch classifier loss: 0.377942; batch adversarial loss: 0.554828\n",
      "epoch 180; iter: 0; batch classifier loss: 0.420548; batch adversarial loss: 0.586546\n",
      "epoch 181; iter: 0; batch classifier loss: 0.350921; batch adversarial loss: 0.612147\n",
      "epoch 182; iter: 0; batch classifier loss: 0.297348; batch adversarial loss: 0.605973\n",
      "epoch 183; iter: 0; batch classifier loss: 0.371374; batch adversarial loss: 0.554698\n",
      "epoch 184; iter: 0; batch classifier loss: 0.333398; batch adversarial loss: 0.580462\n",
      "epoch 185; iter: 0; batch classifier loss: 0.384747; batch adversarial loss: 0.509774\n",
      "epoch 186; iter: 0; batch classifier loss: 0.415488; batch adversarial loss: 0.573694\n",
      "epoch 187; iter: 0; batch classifier loss: 0.266963; batch adversarial loss: 0.597795\n",
      "epoch 188; iter: 0; batch classifier loss: 0.370989; batch adversarial loss: 0.562224\n",
      "epoch 189; iter: 0; batch classifier loss: 0.388861; batch adversarial loss: 0.597209\n",
      "epoch 190; iter: 0; batch classifier loss: 0.334858; batch adversarial loss: 0.615158\n",
      "epoch 191; iter: 0; batch classifier loss: 0.326310; batch adversarial loss: 0.553564\n",
      "epoch 192; iter: 0; batch classifier loss: 0.385488; batch adversarial loss: 0.580137\n",
      "epoch 193; iter: 0; batch classifier loss: 0.342471; batch adversarial loss: 0.562348\n",
      "epoch 194; iter: 0; batch classifier loss: 0.335366; batch adversarial loss: 0.518539\n",
      "epoch 195; iter: 0; batch classifier loss: 0.341436; batch adversarial loss: 0.501518\n",
      "epoch 196; iter: 0; batch classifier loss: 0.346555; batch adversarial loss: 0.562470\n",
      "epoch 197; iter: 0; batch classifier loss: 0.344427; batch adversarial loss: 0.587982\n",
      "epoch 198; iter: 0; batch classifier loss: 0.330277; batch adversarial loss: 0.553930\n",
      "epoch 199; iter: 0; batch classifier loss: 0.346711; batch adversarial loss: 0.579111\n",
      "epoch 0; iter: 0; batch classifier loss: 0.684246; batch adversarial loss: 0.618392\n",
      "epoch 1; iter: 0; batch classifier loss: 0.575127; batch adversarial loss: 0.639871\n",
      "epoch 2; iter: 0; batch classifier loss: 0.610515; batch adversarial loss: 0.640210\n",
      "epoch 3; iter: 0; batch classifier loss: 0.595635; batch adversarial loss: 0.644151\n",
      "epoch 4; iter: 0; batch classifier loss: 0.533354; batch adversarial loss: 0.641569\n",
      "epoch 5; iter: 0; batch classifier loss: 0.534390; batch adversarial loss: 0.648186\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6; iter: 0; batch classifier loss: 0.492777; batch adversarial loss: 0.664650\n",
      "epoch 7; iter: 0; batch classifier loss: 0.519597; batch adversarial loss: 0.644917\n",
      "epoch 8; iter: 0; batch classifier loss: 0.593684; batch adversarial loss: 0.656611\n",
      "epoch 9; iter: 0; batch classifier loss: 0.574617; batch adversarial loss: 0.583506\n",
      "epoch 10; iter: 0; batch classifier loss: 0.517861; batch adversarial loss: 0.606349\n",
      "epoch 11; iter: 0; batch classifier loss: 0.545247; batch adversarial loss: 0.586522\n",
      "epoch 12; iter: 0; batch classifier loss: 0.475206; batch adversarial loss: 0.593850\n",
      "epoch 13; iter: 0; batch classifier loss: 0.521438; batch adversarial loss: 0.579408\n",
      "epoch 14; iter: 0; batch classifier loss: 0.464823; batch adversarial loss: 0.520496\n",
      "epoch 15; iter: 0; batch classifier loss: 0.499503; batch adversarial loss: 0.551584\n",
      "epoch 16; iter: 0; batch classifier loss: 0.585202; batch adversarial loss: 0.558404\n",
      "epoch 17; iter: 0; batch classifier loss: 0.516799; batch adversarial loss: 0.584658\n",
      "epoch 18; iter: 0; batch classifier loss: 0.647908; batch adversarial loss: 0.578466\n",
      "epoch 19; iter: 0; batch classifier loss: 0.459171; batch adversarial loss: 0.584318\n",
      "epoch 20; iter: 0; batch classifier loss: 0.494468; batch adversarial loss: 0.572778\n",
      "epoch 21; iter: 0; batch classifier loss: 0.497623; batch adversarial loss: 0.476606\n",
      "epoch 22; iter: 0; batch classifier loss: 0.447718; batch adversarial loss: 0.545750\n",
      "epoch 23; iter: 0; batch classifier loss: 0.438801; batch adversarial loss: 0.587312\n",
      "epoch 24; iter: 0; batch classifier loss: 0.536506; batch adversarial loss: 0.611397\n",
      "epoch 25; iter: 0; batch classifier loss: 0.494647; batch adversarial loss: 0.502729\n",
      "epoch 26; iter: 0; batch classifier loss: 0.452821; batch adversarial loss: 0.494217\n",
      "epoch 27; iter: 0; batch classifier loss: 0.380298; batch adversarial loss: 0.574450\n",
      "epoch 28; iter: 0; batch classifier loss: 0.424081; batch adversarial loss: 0.535297\n",
      "epoch 29; iter: 0; batch classifier loss: 0.446311; batch adversarial loss: 0.500558\n",
      "epoch 30; iter: 0; batch classifier loss: 0.472487; batch adversarial loss: 0.572989\n",
      "epoch 31; iter: 0; batch classifier loss: 0.452205; batch adversarial loss: 0.550141\n",
      "epoch 32; iter: 0; batch classifier loss: 0.529001; batch adversarial loss: 0.519039\n",
      "epoch 33; iter: 0; batch classifier loss: 0.527893; batch adversarial loss: 0.512686\n",
      "epoch 34; iter: 0; batch classifier loss: 0.420912; batch adversarial loss: 0.615849\n",
      "epoch 35; iter: 0; batch classifier loss: 0.497203; batch adversarial loss: 0.529862\n",
      "epoch 36; iter: 0; batch classifier loss: 0.419171; batch adversarial loss: 0.518888\n",
      "epoch 37; iter: 0; batch classifier loss: 0.421044; batch adversarial loss: 0.542567\n",
      "epoch 38; iter: 0; batch classifier loss: 0.367008; batch adversarial loss: 0.535499\n",
      "epoch 39; iter: 0; batch classifier loss: 0.415017; batch adversarial loss: 0.554029\n",
      "epoch 40; iter: 0; batch classifier loss: 0.509178; batch adversarial loss: 0.544892\n",
      "epoch 41; iter: 0; batch classifier loss: 0.492760; batch adversarial loss: 0.542708\n",
      "epoch 42; iter: 0; batch classifier loss: 0.427927; batch adversarial loss: 0.515977\n",
      "epoch 43; iter: 0; batch classifier loss: 0.387260; batch adversarial loss: 0.525177\n",
      "epoch 44; iter: 0; batch classifier loss: 0.419279; batch adversarial loss: 0.490136\n",
      "epoch 45; iter: 0; batch classifier loss: 0.425695; batch adversarial loss: 0.661842\n",
      "epoch 46; iter: 0; batch classifier loss: 0.464616; batch adversarial loss: 0.455323\n",
      "epoch 47; iter: 0; batch classifier loss: 0.460548; batch adversarial loss: 0.480275\n",
      "epoch 48; iter: 0; batch classifier loss: 0.434966; batch adversarial loss: 0.599592\n",
      "epoch 49; iter: 0; batch classifier loss: 0.419644; batch adversarial loss: 0.562195\n",
      "epoch 50; iter: 0; batch classifier loss: 0.421638; batch adversarial loss: 0.518652\n",
      "epoch 51; iter: 0; batch classifier loss: 0.382306; batch adversarial loss: 0.492344\n",
      "epoch 52; iter: 0; batch classifier loss: 0.441905; batch adversarial loss: 0.571201\n",
      "epoch 53; iter: 0; batch classifier loss: 0.444918; batch adversarial loss: 0.597662\n",
      "epoch 54; iter: 0; batch classifier loss: 0.385651; batch adversarial loss: 0.553570\n",
      "epoch 55; iter: 0; batch classifier loss: 0.377037; batch adversarial loss: 0.499813\n",
      "epoch 56; iter: 0; batch classifier loss: 0.410858; batch adversarial loss: 0.454864\n",
      "epoch 57; iter: 0; batch classifier loss: 0.371987; batch adversarial loss: 0.544424\n",
      "epoch 58; iter: 0; batch classifier loss: 0.349456; batch adversarial loss: 0.571684\n",
      "epoch 59; iter: 0; batch classifier loss: 0.382354; batch adversarial loss: 0.644062\n",
      "epoch 60; iter: 0; batch classifier loss: 0.379343; batch adversarial loss: 0.517864\n",
      "epoch 61; iter: 0; batch classifier loss: 0.468766; batch adversarial loss: 0.517985\n",
      "epoch 62; iter: 0; batch classifier loss: 0.423333; batch adversarial loss: 0.544513\n",
      "epoch 63; iter: 0; batch classifier loss: 0.447135; batch adversarial loss: 0.535597\n",
      "epoch 64; iter: 0; batch classifier loss: 0.280340; batch adversarial loss: 0.589759\n",
      "epoch 65; iter: 0; batch classifier loss: 0.451169; batch adversarial loss: 0.562671\n",
      "epoch 66; iter: 0; batch classifier loss: 0.397118; batch adversarial loss: 0.608216\n",
      "epoch 67; iter: 0; batch classifier loss: 0.451188; batch adversarial loss: 0.544158\n",
      "epoch 68; iter: 0; batch classifier loss: 0.441976; batch adversarial loss: 0.589412\n",
      "epoch 69; iter: 0; batch classifier loss: 0.401435; batch adversarial loss: 0.570907\n",
      "epoch 70; iter: 0; batch classifier loss: 0.411915; batch adversarial loss: 0.515935\n",
      "epoch 71; iter: 0; batch classifier loss: 0.376330; batch adversarial loss: 0.543934\n",
      "epoch 72; iter: 0; batch classifier loss: 0.462494; batch adversarial loss: 0.579887\n",
      "epoch 73; iter: 0; batch classifier loss: 0.474017; batch adversarial loss: 0.571799\n",
      "epoch 74; iter: 0; batch classifier loss: 0.323049; batch adversarial loss: 0.543352\n",
      "epoch 75; iter: 0; batch classifier loss: 0.396816; batch adversarial loss: 0.507328\n",
      "epoch 76; iter: 0; batch classifier loss: 0.427158; batch adversarial loss: 0.579383\n",
      "epoch 77; iter: 0; batch classifier loss: 0.355532; batch adversarial loss: 0.571503\n",
      "epoch 78; iter: 0; batch classifier loss: 0.400861; batch adversarial loss: 0.580185\n",
      "epoch 79; iter: 0; batch classifier loss: 0.446969; batch adversarial loss: 0.543994\n",
      "epoch 80; iter: 0; batch classifier loss: 0.404462; batch adversarial loss: 0.499071\n",
      "epoch 81; iter: 0; batch classifier loss: 0.373452; batch adversarial loss: 0.590734\n",
      "epoch 82; iter: 0; batch classifier loss: 0.334948; batch adversarial loss: 0.569921\n",
      "epoch 83; iter: 0; batch classifier loss: 0.466851; batch adversarial loss: 0.570974\n",
      "epoch 84; iter: 0; batch classifier loss: 0.466321; batch adversarial loss: 0.563825\n",
      "epoch 85; iter: 0; batch classifier loss: 0.409413; batch adversarial loss: 0.600759\n",
      "epoch 86; iter: 0; batch classifier loss: 0.428438; batch adversarial loss: 0.562584\n",
      "epoch 87; iter: 0; batch classifier loss: 0.432314; batch adversarial loss: 0.544260\n",
      "epoch 88; iter: 0; batch classifier loss: 0.420615; batch adversarial loss: 0.561965\n",
      "epoch 89; iter: 0; batch classifier loss: 0.368553; batch adversarial loss: 0.518425\n",
      "epoch 90; iter: 0; batch classifier loss: 0.459325; batch adversarial loss: 0.481855\n",
      "epoch 91; iter: 0; batch classifier loss: 0.403952; batch adversarial loss: 0.544709\n",
      "epoch 92; iter: 0; batch classifier loss: 0.334943; batch adversarial loss: 0.499795\n",
      "epoch 93; iter: 0; batch classifier loss: 0.469248; batch adversarial loss: 0.580305\n",
      "epoch 94; iter: 0; batch classifier loss: 0.384296; batch adversarial loss: 0.526787\n",
      "epoch 95; iter: 0; batch classifier loss: 0.377848; batch adversarial loss: 0.562624\n",
      "epoch 96; iter: 0; batch classifier loss: 0.345092; batch adversarial loss: 0.562141\n",
      "epoch 97; iter: 0; batch classifier loss: 0.367795; batch adversarial loss: 0.589661\n",
      "epoch 98; iter: 0; batch classifier loss: 0.346539; batch adversarial loss: 0.490413\n",
      "epoch 99; iter: 0; batch classifier loss: 0.353264; batch adversarial loss: 0.535589\n",
      "epoch 100; iter: 0; batch classifier loss: 0.371658; batch adversarial loss: 0.571457\n",
      "epoch 101; iter: 0; batch classifier loss: 0.355109; batch adversarial loss: 0.607953\n",
      "epoch 102; iter: 0; batch classifier loss: 0.349923; batch adversarial loss: 0.472423\n",
      "epoch 103; iter: 0; batch classifier loss: 0.381009; batch adversarial loss: 0.508363\n",
      "epoch 104; iter: 0; batch classifier loss: 0.339976; batch adversarial loss: 0.508012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 105; iter: 0; batch classifier loss: 0.362994; batch adversarial loss: 0.535020\n",
      "epoch 106; iter: 0; batch classifier loss: 0.419780; batch adversarial loss: 0.580139\n",
      "epoch 107; iter: 0; batch classifier loss: 0.343302; batch adversarial loss: 0.534758\n",
      "epoch 108; iter: 0; batch classifier loss: 0.461676; batch adversarial loss: 0.518236\n",
      "epoch 109; iter: 0; batch classifier loss: 0.331197; batch adversarial loss: 0.624952\n",
      "epoch 110; iter: 0; batch classifier loss: 0.435708; batch adversarial loss: 0.516732\n",
      "epoch 111; iter: 0; batch classifier loss: 0.375707; batch adversarial loss: 0.508043\n",
      "epoch 112; iter: 0; batch classifier loss: 0.371858; batch adversarial loss: 0.616654\n",
      "epoch 113; iter: 0; batch classifier loss: 0.298658; batch adversarial loss: 0.535870\n",
      "epoch 114; iter: 0; batch classifier loss: 0.453491; batch adversarial loss: 0.589165\n",
      "epoch 115; iter: 0; batch classifier loss: 0.387888; batch adversarial loss: 0.562494\n",
      "epoch 116; iter: 0; batch classifier loss: 0.370789; batch adversarial loss: 0.580017\n",
      "epoch 117; iter: 0; batch classifier loss: 0.407906; batch adversarial loss: 0.526482\n",
      "epoch 118; iter: 0; batch classifier loss: 0.294555; batch adversarial loss: 0.589874\n",
      "epoch 119; iter: 0; batch classifier loss: 0.344383; batch adversarial loss: 0.598204\n",
      "epoch 120; iter: 0; batch classifier loss: 0.434817; batch adversarial loss: 0.490522\n",
      "epoch 121; iter: 0; batch classifier loss: 0.355934; batch adversarial loss: 0.553143\n",
      "epoch 122; iter: 0; batch classifier loss: 0.394251; batch adversarial loss: 0.508575\n",
      "epoch 123; iter: 0; batch classifier loss: 0.376029; batch adversarial loss: 0.481673\n",
      "epoch 124; iter: 0; batch classifier loss: 0.353165; batch adversarial loss: 0.562923\n",
      "epoch 125; iter: 0; batch classifier loss: 0.431238; batch adversarial loss: 0.617524\n",
      "epoch 126; iter: 0; batch classifier loss: 0.413232; batch adversarial loss: 0.526292\n",
      "epoch 127; iter: 0; batch classifier loss: 0.348247; batch adversarial loss: 0.616894\n",
      "epoch 128; iter: 0; batch classifier loss: 0.399469; batch adversarial loss: 0.490340\n",
      "epoch 129; iter: 0; batch classifier loss: 0.403487; batch adversarial loss: 0.598559\n",
      "epoch 130; iter: 0; batch classifier loss: 0.380335; batch adversarial loss: 0.553814\n",
      "epoch 131; iter: 0; batch classifier loss: 0.384812; batch adversarial loss: 0.571651\n",
      "epoch 132; iter: 0; batch classifier loss: 0.348537; batch adversarial loss: 0.571488\n",
      "epoch 133; iter: 0; batch classifier loss: 0.348283; batch adversarial loss: 0.535729\n",
      "epoch 134; iter: 0; batch classifier loss: 0.496632; batch adversarial loss: 0.517575\n",
      "epoch 135; iter: 0; batch classifier loss: 0.289671; batch adversarial loss: 0.526430\n",
      "epoch 136; iter: 0; batch classifier loss: 0.285721; batch adversarial loss: 0.580928\n",
      "epoch 137; iter: 0; batch classifier loss: 0.352611; batch adversarial loss: 0.526591\n",
      "epoch 138; iter: 0; batch classifier loss: 0.424790; batch adversarial loss: 0.481277\n",
      "epoch 139; iter: 0; batch classifier loss: 0.418308; batch adversarial loss: 0.499389\n",
      "epoch 140; iter: 0; batch classifier loss: 0.443813; batch adversarial loss: 0.571665\n",
      "epoch 141; iter: 0; batch classifier loss: 0.325510; batch adversarial loss: 0.499816\n",
      "epoch 142; iter: 0; batch classifier loss: 0.316755; batch adversarial loss: 0.562666\n",
      "epoch 143; iter: 0; batch classifier loss: 0.423792; batch adversarial loss: 0.544955\n",
      "epoch 144; iter: 0; batch classifier loss: 0.405017; batch adversarial loss: 0.535692\n",
      "epoch 145; iter: 0; batch classifier loss: 0.413320; batch adversarial loss: 0.553543\n",
      "epoch 146; iter: 0; batch classifier loss: 0.395595; batch adversarial loss: 0.553856\n",
      "epoch 147; iter: 0; batch classifier loss: 0.359287; batch adversarial loss: 0.544710\n",
      "epoch 148; iter: 0; batch classifier loss: 0.324332; batch adversarial loss: 0.616386\n",
      "epoch 149; iter: 0; batch classifier loss: 0.323273; batch adversarial loss: 0.535339\n",
      "epoch 150; iter: 0; batch classifier loss: 0.326256; batch adversarial loss: 0.589670\n",
      "epoch 151; iter: 0; batch classifier loss: 0.340012; batch adversarial loss: 0.543974\n",
      "epoch 152; iter: 0; batch classifier loss: 0.356014; batch adversarial loss: 0.572370\n",
      "epoch 153; iter: 0; batch classifier loss: 0.393421; batch adversarial loss: 0.572178\n",
      "epoch 154; iter: 0; batch classifier loss: 0.378074; batch adversarial loss: 0.563424\n",
      "epoch 155; iter: 0; batch classifier loss: 0.463147; batch adversarial loss: 0.553573\n",
      "epoch 156; iter: 0; batch classifier loss: 0.391071; batch adversarial loss: 0.544807\n",
      "epoch 157; iter: 0; batch classifier loss: 0.355855; batch adversarial loss: 0.571245\n",
      "epoch 158; iter: 0; batch classifier loss: 0.323959; batch adversarial loss: 0.607345\n",
      "epoch 159; iter: 0; batch classifier loss: 0.410556; batch adversarial loss: 0.517714\n",
      "epoch 160; iter: 0; batch classifier loss: 0.318939; batch adversarial loss: 0.499351\n",
      "epoch 161; iter: 0; batch classifier loss: 0.368435; batch adversarial loss: 0.617151\n",
      "epoch 162; iter: 0; batch classifier loss: 0.412032; batch adversarial loss: 0.590343\n",
      "epoch 163; iter: 0; batch classifier loss: 0.373302; batch adversarial loss: 0.499209\n",
      "epoch 164; iter: 0; batch classifier loss: 0.399297; batch adversarial loss: 0.535677\n",
      "epoch 165; iter: 0; batch classifier loss: 0.375969; batch adversarial loss: 0.517337\n",
      "epoch 166; iter: 0; batch classifier loss: 0.397406; batch adversarial loss: 0.526518\n",
      "epoch 167; iter: 0; batch classifier loss: 0.376044; batch adversarial loss: 0.589936\n",
      "epoch 168; iter: 0; batch classifier loss: 0.342725; batch adversarial loss: 0.472862\n",
      "epoch 169; iter: 0; batch classifier loss: 0.347960; batch adversarial loss: 0.526239\n",
      "epoch 170; iter: 0; batch classifier loss: 0.293461; batch adversarial loss: 0.562070\n",
      "epoch 171; iter: 0; batch classifier loss: 0.426504; batch adversarial loss: 0.562588\n",
      "epoch 172; iter: 0; batch classifier loss: 0.333289; batch adversarial loss: 0.589578\n",
      "epoch 173; iter: 0; batch classifier loss: 0.375404; batch adversarial loss: 0.562633\n",
      "epoch 174; iter: 0; batch classifier loss: 0.351793; batch adversarial loss: 0.617436\n",
      "epoch 175; iter: 0; batch classifier loss: 0.341123; batch adversarial loss: 0.553484\n",
      "epoch 176; iter: 0; batch classifier loss: 0.350038; batch adversarial loss: 0.535811\n",
      "epoch 177; iter: 0; batch classifier loss: 0.369527; batch adversarial loss: 0.580559\n",
      "epoch 178; iter: 0; batch classifier loss: 0.439684; batch adversarial loss: 0.589492\n",
      "epoch 179; iter: 0; batch classifier loss: 0.346821; batch adversarial loss: 0.571756\n",
      "epoch 180; iter: 0; batch classifier loss: 0.340984; batch adversarial loss: 0.481867\n",
      "epoch 181; iter: 0; batch classifier loss: 0.420577; batch adversarial loss: 0.571986\n",
      "epoch 182; iter: 0; batch classifier loss: 0.413827; batch adversarial loss: 0.553542\n",
      "epoch 183; iter: 0; batch classifier loss: 0.402893; batch adversarial loss: 0.562520\n",
      "epoch 184; iter: 0; batch classifier loss: 0.375063; batch adversarial loss: 0.580637\n",
      "epoch 185; iter: 0; batch classifier loss: 0.338122; batch adversarial loss: 0.571896\n",
      "epoch 186; iter: 0; batch classifier loss: 0.420868; batch adversarial loss: 0.580544\n",
      "epoch 187; iter: 0; batch classifier loss: 0.357558; batch adversarial loss: 0.471866\n",
      "epoch 188; iter: 0; batch classifier loss: 0.346992; batch adversarial loss: 0.499394\n",
      "epoch 189; iter: 0; batch classifier loss: 0.399435; batch adversarial loss: 0.526510\n",
      "epoch 190; iter: 0; batch classifier loss: 0.395182; batch adversarial loss: 0.508706\n",
      "epoch 191; iter: 0; batch classifier loss: 0.361099; batch adversarial loss: 0.562416\n",
      "epoch 192; iter: 0; batch classifier loss: 0.305715; batch adversarial loss: 0.617192\n",
      "epoch 193; iter: 0; batch classifier loss: 0.414553; batch adversarial loss: 0.462679\n",
      "epoch 194; iter: 0; batch classifier loss: 0.313112; batch adversarial loss: 0.589946\n",
      "epoch 195; iter: 0; batch classifier loss: 0.337257; batch adversarial loss: 0.571275\n",
      "epoch 196; iter: 0; batch classifier loss: 0.373321; batch adversarial loss: 0.490959\n",
      "epoch 197; iter: 0; batch classifier loss: 0.306116; batch adversarial loss: 0.527196\n",
      "epoch 198; iter: 0; batch classifier loss: 0.299236; batch adversarial loss: 0.562754\n",
      "epoch 199; iter: 0; batch classifier loss: 0.395583; batch adversarial loss: 0.517734\n",
      "epoch 0; iter: 0; batch classifier loss: 0.718150; batch adversarial loss: 0.709391\n",
      "epoch 1; iter: 0; batch classifier loss: 0.580635; batch adversarial loss: 0.701167\n",
      "epoch 2; iter: 0; batch classifier loss: 0.576053; batch adversarial loss: 0.682542\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3; iter: 0; batch classifier loss: 0.531125; batch adversarial loss: 0.631179\n",
      "epoch 4; iter: 0; batch classifier loss: 0.595632; batch adversarial loss: 0.655834\n",
      "epoch 5; iter: 0; batch classifier loss: 0.581115; batch adversarial loss: 0.581702\n",
      "epoch 6; iter: 0; batch classifier loss: 0.568107; batch adversarial loss: 0.568035\n",
      "epoch 7; iter: 0; batch classifier loss: 0.470355; batch adversarial loss: 0.604068\n",
      "epoch 8; iter: 0; batch classifier loss: 0.561815; batch adversarial loss: 0.588856\n",
      "epoch 9; iter: 0; batch classifier loss: 0.501886; batch adversarial loss: 0.615219\n",
      "epoch 10; iter: 0; batch classifier loss: 0.584495; batch adversarial loss: 0.619914\n",
      "epoch 11; iter: 0; batch classifier loss: 0.473440; batch adversarial loss: 0.560871\n",
      "epoch 12; iter: 0; batch classifier loss: 0.519419; batch adversarial loss: 0.586855\n",
      "epoch 13; iter: 0; batch classifier loss: 0.510833; batch adversarial loss: 0.535286\n",
      "epoch 14; iter: 0; batch classifier loss: 0.483225; batch adversarial loss: 0.625364\n",
      "epoch 15; iter: 0; batch classifier loss: 0.555018; batch adversarial loss: 0.585153\n",
      "epoch 16; iter: 0; batch classifier loss: 0.607251; batch adversarial loss: 0.604015\n",
      "epoch 17; iter: 0; batch classifier loss: 0.501024; batch adversarial loss: 0.582173\n",
      "epoch 18; iter: 0; batch classifier loss: 0.506646; batch adversarial loss: 0.563775\n",
      "epoch 19; iter: 0; batch classifier loss: 0.564897; batch adversarial loss: 0.579752\n",
      "epoch 20; iter: 0; batch classifier loss: 0.511941; batch adversarial loss: 0.607921\n",
      "epoch 21; iter: 0; batch classifier loss: 0.423351; batch adversarial loss: 0.551855\n",
      "epoch 22; iter: 0; batch classifier loss: 0.521423; batch adversarial loss: 0.543037\n",
      "epoch 23; iter: 0; batch classifier loss: 0.453383; batch adversarial loss: 0.540717\n",
      "epoch 24; iter: 0; batch classifier loss: 0.426878; batch adversarial loss: 0.529959\n",
      "epoch 25; iter: 0; batch classifier loss: 0.506878; batch adversarial loss: 0.548400\n",
      "epoch 26; iter: 0; batch classifier loss: 0.490814; batch adversarial loss: 0.567757\n",
      "epoch 27; iter: 0; batch classifier loss: 0.438024; batch adversarial loss: 0.575306\n",
      "epoch 28; iter: 0; batch classifier loss: 0.504489; batch adversarial loss: 0.541328\n",
      "epoch 29; iter: 0; batch classifier loss: 0.462415; batch adversarial loss: 0.526020\n",
      "epoch 30; iter: 0; batch classifier loss: 0.512709; batch adversarial loss: 0.556185\n",
      "epoch 31; iter: 0; batch classifier loss: 0.437096; batch adversarial loss: 0.526110\n",
      "epoch 32; iter: 0; batch classifier loss: 0.487412; batch adversarial loss: 0.606964\n",
      "epoch 33; iter: 0; batch classifier loss: 0.421585; batch adversarial loss: 0.588139\n",
      "epoch 34; iter: 0; batch classifier loss: 0.380121; batch adversarial loss: 0.596843\n",
      "epoch 35; iter: 0; batch classifier loss: 0.467001; batch adversarial loss: 0.563071\n",
      "epoch 36; iter: 0; batch classifier loss: 0.428320; batch adversarial loss: 0.546423\n",
      "epoch 37; iter: 0; batch classifier loss: 0.520527; batch adversarial loss: 0.537810\n",
      "epoch 38; iter: 0; batch classifier loss: 0.494257; batch adversarial loss: 0.537858\n",
      "epoch 39; iter: 0; batch classifier loss: 0.407775; batch adversarial loss: 0.561501\n",
      "epoch 40; iter: 0; batch classifier loss: 0.480967; batch adversarial loss: 0.509564\n",
      "epoch 41; iter: 0; batch classifier loss: 0.477289; batch adversarial loss: 0.553877\n",
      "epoch 42; iter: 0; batch classifier loss: 0.376626; batch adversarial loss: 0.554161\n",
      "epoch 43; iter: 0; batch classifier loss: 0.410512; batch adversarial loss: 0.597637\n",
      "epoch 44; iter: 0; batch classifier loss: 0.453836; batch adversarial loss: 0.571558\n",
      "epoch 45; iter: 0; batch classifier loss: 0.420075; batch adversarial loss: 0.624390\n",
      "epoch 46; iter: 0; batch classifier loss: 0.426627; batch adversarial loss: 0.553632\n",
      "epoch 47; iter: 0; batch classifier loss: 0.467609; batch adversarial loss: 0.580149\n",
      "epoch 48; iter: 0; batch classifier loss: 0.357293; batch adversarial loss: 0.607046\n",
      "epoch 49; iter: 0; batch classifier loss: 0.435285; batch adversarial loss: 0.589293\n",
      "epoch 50; iter: 0; batch classifier loss: 0.456550; batch adversarial loss: 0.517929\n",
      "epoch 51; iter: 0; batch classifier loss: 0.367820; batch adversarial loss: 0.500249\n",
      "epoch 52; iter: 0; batch classifier loss: 0.467238; batch adversarial loss: 0.500021\n",
      "epoch 53; iter: 0; batch classifier loss: 0.456894; batch adversarial loss: 0.508795\n",
      "epoch 54; iter: 0; batch classifier loss: 0.469657; batch adversarial loss: 0.490717\n",
      "epoch 55; iter: 0; batch classifier loss: 0.433571; batch adversarial loss: 0.544259\n",
      "epoch 56; iter: 0; batch classifier loss: 0.431713; batch adversarial loss: 0.516807\n",
      "epoch 57; iter: 0; batch classifier loss: 0.410417; batch adversarial loss: 0.507029\n",
      "epoch 58; iter: 0; batch classifier loss: 0.409560; batch adversarial loss: 0.543941\n",
      "epoch 59; iter: 0; batch classifier loss: 0.575373; batch adversarial loss: 0.507247\n",
      "epoch 60; iter: 0; batch classifier loss: 0.431777; batch adversarial loss: 0.517412\n",
      "epoch 61; iter: 0; batch classifier loss: 0.403813; batch adversarial loss: 0.578744\n",
      "epoch 62; iter: 0; batch classifier loss: 0.391471; batch adversarial loss: 0.562057\n",
      "epoch 63; iter: 0; batch classifier loss: 0.465290; batch adversarial loss: 0.537258\n",
      "epoch 64; iter: 0; batch classifier loss: 0.394244; batch adversarial loss: 0.543461\n",
      "epoch 65; iter: 0; batch classifier loss: 0.430198; batch adversarial loss: 0.532364\n",
      "epoch 66; iter: 0; batch classifier loss: 0.439631; batch adversarial loss: 0.591010\n",
      "epoch 67; iter: 0; batch classifier loss: 0.430703; batch adversarial loss: 0.591929\n",
      "epoch 68; iter: 0; batch classifier loss: 0.359155; batch adversarial loss: 0.553187\n",
      "epoch 69; iter: 0; batch classifier loss: 0.420331; batch adversarial loss: 0.607842\n",
      "epoch 70; iter: 0; batch classifier loss: 0.382172; batch adversarial loss: 0.659324\n",
      "epoch 71; iter: 0; batch classifier loss: 0.410862; batch adversarial loss: 0.500392\n",
      "epoch 72; iter: 0; batch classifier loss: 0.422610; batch adversarial loss: 0.571361\n",
      "epoch 73; iter: 0; batch classifier loss: 0.385036; batch adversarial loss: 0.483967\n",
      "epoch 74; iter: 0; batch classifier loss: 0.461093; batch adversarial loss: 0.527730\n",
      "epoch 75; iter: 0; batch classifier loss: 0.391541; batch adversarial loss: 0.492175\n",
      "epoch 76; iter: 0; batch classifier loss: 0.339347; batch adversarial loss: 0.597706\n",
      "epoch 77; iter: 0; batch classifier loss: 0.446528; batch adversarial loss: 0.633709\n",
      "epoch 78; iter: 0; batch classifier loss: 0.344230; batch adversarial loss: 0.561889\n",
      "epoch 79; iter: 0; batch classifier loss: 0.376663; batch adversarial loss: 0.562814\n",
      "epoch 80; iter: 0; batch classifier loss: 0.366607; batch adversarial loss: 0.669505\n",
      "epoch 81; iter: 0; batch classifier loss: 0.428711; batch adversarial loss: 0.535413\n",
      "epoch 82; iter: 0; batch classifier loss: 0.352382; batch adversarial loss: 0.642470\n",
      "epoch 83; iter: 0; batch classifier loss: 0.345804; batch adversarial loss: 0.508950\n",
      "epoch 84; iter: 0; batch classifier loss: 0.403271; batch adversarial loss: 0.526483\n",
      "epoch 85; iter: 0; batch classifier loss: 0.341149; batch adversarial loss: 0.526714\n",
      "epoch 86; iter: 0; batch classifier loss: 0.409878; batch adversarial loss: 0.526575\n",
      "epoch 87; iter: 0; batch classifier loss: 0.499968; batch adversarial loss: 0.526723\n",
      "epoch 88; iter: 0; batch classifier loss: 0.425448; batch adversarial loss: 0.535686\n",
      "epoch 89; iter: 0; batch classifier loss: 0.473749; batch adversarial loss: 0.598523\n",
      "epoch 90; iter: 0; batch classifier loss: 0.392803; batch adversarial loss: 0.526499\n",
      "epoch 91; iter: 0; batch classifier loss: 0.372509; batch adversarial loss: 0.544696\n",
      "epoch 92; iter: 0; batch classifier loss: 0.382633; batch adversarial loss: 0.544576\n",
      "epoch 93; iter: 0; batch classifier loss: 0.391539; batch adversarial loss: 0.553740\n",
      "epoch 94; iter: 0; batch classifier loss: 0.467039; batch adversarial loss: 0.625450\n",
      "epoch 95; iter: 0; batch classifier loss: 0.358521; batch adversarial loss: 0.580301\n",
      "epoch 96; iter: 0; batch classifier loss: 0.417990; batch adversarial loss: 0.580333\n",
      "epoch 97; iter: 0; batch classifier loss: 0.387225; batch adversarial loss: 0.499310\n",
      "epoch 98; iter: 0; batch classifier loss: 0.404648; batch adversarial loss: 0.471541\n",
      "epoch 99; iter: 0; batch classifier loss: 0.363581; batch adversarial loss: 0.563030\n",
      "epoch 100; iter: 0; batch classifier loss: 0.355205; batch adversarial loss: 0.544606\n",
      "epoch 101; iter: 0; batch classifier loss: 0.436194; batch adversarial loss: 0.516401\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 102; iter: 0; batch classifier loss: 0.397829; batch adversarial loss: 0.479328\n",
      "epoch 103; iter: 0; batch classifier loss: 0.360862; batch adversarial loss: 0.536246\n",
      "epoch 104; iter: 0; batch classifier loss: 0.378965; batch adversarial loss: 0.526928\n",
      "epoch 105; iter: 0; batch classifier loss: 0.350230; batch adversarial loss: 0.571938\n",
      "epoch 106; iter: 0; batch classifier loss: 0.328329; batch adversarial loss: 0.544672\n",
      "epoch 107; iter: 0; batch classifier loss: 0.421750; batch adversarial loss: 0.536122\n",
      "epoch 108; iter: 0; batch classifier loss: 0.431520; batch adversarial loss: 0.650999\n",
      "epoch 109; iter: 0; batch classifier loss: 0.357587; batch adversarial loss: 0.519119\n",
      "epoch 110; iter: 0; batch classifier loss: 0.383590; batch adversarial loss: 0.615694\n",
      "epoch 111; iter: 0; batch classifier loss: 0.411824; batch adversarial loss: 0.517840\n",
      "epoch 112; iter: 0; batch classifier loss: 0.457477; batch adversarial loss: 0.472352\n",
      "epoch 113; iter: 0; batch classifier loss: 0.368645; batch adversarial loss: 0.571206\n",
      "epoch 114; iter: 0; batch classifier loss: 0.349327; batch adversarial loss: 0.517971\n",
      "epoch 115; iter: 0; batch classifier loss: 0.440099; batch adversarial loss: 0.606516\n",
      "epoch 116; iter: 0; batch classifier loss: 0.321209; batch adversarial loss: 0.561653\n",
      "epoch 117; iter: 0; batch classifier loss: 0.356621; batch adversarial loss: 0.563143\n",
      "epoch 118; iter: 0; batch classifier loss: 0.379418; batch adversarial loss: 0.626036\n",
      "epoch 119; iter: 0; batch classifier loss: 0.435733; batch adversarial loss: 0.518870\n",
      "epoch 120; iter: 0; batch classifier loss: 0.385820; batch adversarial loss: 0.570132\n",
      "epoch 121; iter: 0; batch classifier loss: 0.400862; batch adversarial loss: 0.517438\n",
      "epoch 122; iter: 0; batch classifier loss: 0.458184; batch adversarial loss: 0.572393\n",
      "epoch 123; iter: 0; batch classifier loss: 0.342352; batch adversarial loss: 0.598418\n",
      "epoch 124; iter: 0; batch classifier loss: 0.377548; batch adversarial loss: 0.626090\n",
      "epoch 125; iter: 0; batch classifier loss: 0.369615; batch adversarial loss: 0.554373\n",
      "epoch 126; iter: 0; batch classifier loss: 0.460794; batch adversarial loss: 0.526767\n",
      "epoch 127; iter: 0; batch classifier loss: 0.482940; batch adversarial loss: 0.518020\n",
      "epoch 128; iter: 0; batch classifier loss: 0.401690; batch adversarial loss: 0.553005\n",
      "epoch 129; iter: 0; batch classifier loss: 0.306363; batch adversarial loss: 0.562343\n",
      "epoch 130; iter: 0; batch classifier loss: 0.382521; batch adversarial loss: 0.527214\n",
      "epoch 131; iter: 0; batch classifier loss: 0.311670; batch adversarial loss: 0.544793\n",
      "epoch 132; iter: 0; batch classifier loss: 0.346811; batch adversarial loss: 0.518664\n",
      "epoch 133; iter: 0; batch classifier loss: 0.330395; batch adversarial loss: 0.607442\n",
      "epoch 134; iter: 0; batch classifier loss: 0.369351; batch adversarial loss: 0.527231\n",
      "epoch 135; iter: 0; batch classifier loss: 0.449234; batch adversarial loss: 0.598465\n",
      "epoch 136; iter: 0; batch classifier loss: 0.373851; batch adversarial loss: 0.535601\n",
      "epoch 137; iter: 0; batch classifier loss: 0.374392; batch adversarial loss: 0.617407\n",
      "epoch 138; iter: 0; batch classifier loss: 0.303963; batch adversarial loss: 0.607162\n",
      "epoch 139; iter: 0; batch classifier loss: 0.363508; batch adversarial loss: 0.499179\n",
      "epoch 140; iter: 0; batch classifier loss: 0.367685; batch adversarial loss: 0.643252\n",
      "epoch 141; iter: 0; batch classifier loss: 0.349865; batch adversarial loss: 0.545924\n",
      "epoch 142; iter: 0; batch classifier loss: 0.337528; batch adversarial loss: 0.562605\n",
      "epoch 143; iter: 0; batch classifier loss: 0.393620; batch adversarial loss: 0.582816\n",
      "epoch 144; iter: 0; batch classifier loss: 0.349103; batch adversarial loss: 0.642734\n",
      "epoch 145; iter: 0; batch classifier loss: 0.332053; batch adversarial loss: 0.562138\n",
      "epoch 146; iter: 0; batch classifier loss: 0.353140; batch adversarial loss: 0.544107\n",
      "epoch 147; iter: 0; batch classifier loss: 0.318299; batch adversarial loss: 0.526291\n",
      "epoch 148; iter: 0; batch classifier loss: 0.308034; batch adversarial loss: 0.544303\n",
      "epoch 149; iter: 0; batch classifier loss: 0.361035; batch adversarial loss: 0.498674\n",
      "epoch 150; iter: 0; batch classifier loss: 0.375680; batch adversarial loss: 0.554085\n",
      "epoch 151; iter: 0; batch classifier loss: 0.386471; batch adversarial loss: 0.491148\n",
      "epoch 152; iter: 0; batch classifier loss: 0.375135; batch adversarial loss: 0.554583\n",
      "epoch 153; iter: 0; batch classifier loss: 0.433541; batch adversarial loss: 0.534971\n",
      "epoch 154; iter: 0; batch classifier loss: 0.370369; batch adversarial loss: 0.536767\n",
      "epoch 155; iter: 0; batch classifier loss: 0.347652; batch adversarial loss: 0.598931\n",
      "epoch 156; iter: 0; batch classifier loss: 0.442282; batch adversarial loss: 0.579291\n",
      "epoch 157; iter: 0; batch classifier loss: 0.327046; batch adversarial loss: 0.570783\n",
      "epoch 158; iter: 0; batch classifier loss: 0.386273; batch adversarial loss: 0.571945\n",
      "epoch 159; iter: 0; batch classifier loss: 0.344678; batch adversarial loss: 0.561609\n",
      "epoch 160; iter: 0; batch classifier loss: 0.250502; batch adversarial loss: 0.526704\n",
      "epoch 161; iter: 0; batch classifier loss: 0.368027; batch adversarial loss: 0.643259\n",
      "epoch 162; iter: 0; batch classifier loss: 0.376257; batch adversarial loss: 0.606120\n",
      "epoch 163; iter: 0; batch classifier loss: 0.352569; batch adversarial loss: 0.562377\n",
      "epoch 164; iter: 0; batch classifier loss: 0.408928; batch adversarial loss: 0.599160\n",
      "epoch 165; iter: 0; batch classifier loss: 0.358183; batch adversarial loss: 0.462918\n",
      "epoch 166; iter: 0; batch classifier loss: 0.365181; batch adversarial loss: 0.596908\n",
      "epoch 167; iter: 0; batch classifier loss: 0.360411; batch adversarial loss: 0.526289\n",
      "epoch 168; iter: 0; batch classifier loss: 0.313276; batch adversarial loss: 0.561793\n",
      "epoch 169; iter: 0; batch classifier loss: 0.400341; batch adversarial loss: 0.517632\n",
      "epoch 170; iter: 0; batch classifier loss: 0.403073; batch adversarial loss: 0.517436\n",
      "epoch 171; iter: 0; batch classifier loss: 0.348800; batch adversarial loss: 0.464396\n",
      "epoch 172; iter: 0; batch classifier loss: 0.339501; batch adversarial loss: 0.571362\n",
      "epoch 173; iter: 0; batch classifier loss: 0.381612; batch adversarial loss: 0.491058\n",
      "epoch 174; iter: 0; batch classifier loss: 0.340447; batch adversarial loss: 0.625076\n",
      "epoch 175; iter: 0; batch classifier loss: 0.403000; batch adversarial loss: 0.571073\n",
      "epoch 176; iter: 0; batch classifier loss: 0.385866; batch adversarial loss: 0.652696\n",
      "epoch 177; iter: 0; batch classifier loss: 0.377957; batch adversarial loss: 0.508662\n",
      "epoch 178; iter: 0; batch classifier loss: 0.419329; batch adversarial loss: 0.482082\n",
      "epoch 179; iter: 0; batch classifier loss: 0.394698; batch adversarial loss: 0.544473\n",
      "epoch 180; iter: 0; batch classifier loss: 0.453767; batch adversarial loss: 0.561094\n",
      "epoch 181; iter: 0; batch classifier loss: 0.355921; batch adversarial loss: 0.571751\n",
      "epoch 182; iter: 0; batch classifier loss: 0.316841; batch adversarial loss: 0.570190\n",
      "epoch 183; iter: 0; batch classifier loss: 0.311317; batch adversarial loss: 0.527212\n",
      "epoch 184; iter: 0; batch classifier loss: 0.372917; batch adversarial loss: 0.599684\n",
      "epoch 185; iter: 0; batch classifier loss: 0.378707; batch adversarial loss: 0.553313\n",
      "epoch 186; iter: 0; batch classifier loss: 0.322599; batch adversarial loss: 0.571083\n",
      "epoch 187; iter: 0; batch classifier loss: 0.346673; batch adversarial loss: 0.526317\n",
      "epoch 188; iter: 0; batch classifier loss: 0.361860; batch adversarial loss: 0.553537\n",
      "epoch 189; iter: 0; batch classifier loss: 0.316959; batch adversarial loss: 0.580458\n",
      "epoch 190; iter: 0; batch classifier loss: 0.362390; batch adversarial loss: 0.526957\n",
      "epoch 191; iter: 0; batch classifier loss: 0.419729; batch adversarial loss: 0.589484\n",
      "epoch 192; iter: 0; batch classifier loss: 0.353684; batch adversarial loss: 0.552021\n",
      "epoch 193; iter: 0; batch classifier loss: 0.353136; batch adversarial loss: 0.607460\n",
      "epoch 194; iter: 0; batch classifier loss: 0.253849; batch adversarial loss: 0.525694\n",
      "epoch 195; iter: 0; batch classifier loss: 0.358205; batch adversarial loss: 0.678781\n",
      "epoch 196; iter: 0; batch classifier loss: 0.377288; batch adversarial loss: 0.516637\n",
      "epoch 197; iter: 0; batch classifier loss: 0.345414; batch adversarial loss: 0.508593\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 198; iter: 0; batch classifier loss: 0.314258; batch adversarial loss: 0.508771\n",
      "epoch 199; iter: 0; batch classifier loss: 0.351513; batch adversarial loss: 0.535564\n",
      "epoch 0; iter: 0; batch classifier loss: 0.678593; batch adversarial loss: 0.768053\n",
      "epoch 1; iter: 0; batch classifier loss: 0.631735; batch adversarial loss: 0.751883\n",
      "epoch 2; iter: 0; batch classifier loss: 0.625309; batch adversarial loss: 0.669173\n",
      "epoch 3; iter: 0; batch classifier loss: 0.562669; batch adversarial loss: 0.692549\n",
      "epoch 4; iter: 0; batch classifier loss: 0.582941; batch adversarial loss: 0.673553\n",
      "epoch 5; iter: 0; batch classifier loss: 0.536296; batch adversarial loss: 0.636174\n",
      "epoch 6; iter: 0; batch classifier loss: 0.517310; batch adversarial loss: 0.604486\n",
      "epoch 7; iter: 0; batch classifier loss: 0.510980; batch adversarial loss: 0.575227\n",
      "epoch 8; iter: 0; batch classifier loss: 0.602967; batch adversarial loss: 0.591384\n",
      "epoch 9; iter: 0; batch classifier loss: 0.517315; batch adversarial loss: 0.608473\n",
      "epoch 10; iter: 0; batch classifier loss: 0.531560; batch adversarial loss: 0.568120\n",
      "epoch 11; iter: 0; batch classifier loss: 0.495462; batch adversarial loss: 0.564430\n",
      "epoch 12; iter: 0; batch classifier loss: 0.503134; batch adversarial loss: 0.581879\n",
      "epoch 13; iter: 0; batch classifier loss: 0.588323; batch adversarial loss: 0.469430\n",
      "epoch 14; iter: 0; batch classifier loss: 0.494575; batch adversarial loss: 0.590785\n",
      "epoch 15; iter: 0; batch classifier loss: 0.546624; batch adversarial loss: 0.632945\n",
      "epoch 16; iter: 0; batch classifier loss: 0.498556; batch adversarial loss: 0.567759\n",
      "epoch 17; iter: 0; batch classifier loss: 0.500967; batch adversarial loss: 0.542249\n",
      "epoch 18; iter: 0; batch classifier loss: 0.529878; batch adversarial loss: 0.569506\n",
      "epoch 19; iter: 0; batch classifier loss: 0.503900; batch adversarial loss: 0.509211\n",
      "epoch 20; iter: 0; batch classifier loss: 0.510073; batch adversarial loss: 0.530017\n",
      "epoch 21; iter: 0; batch classifier loss: 0.463582; batch adversarial loss: 0.578753\n",
      "epoch 22; iter: 0; batch classifier loss: 0.511000; batch adversarial loss: 0.541536\n",
      "epoch 23; iter: 0; batch classifier loss: 0.477872; batch adversarial loss: 0.528216\n",
      "epoch 24; iter: 0; batch classifier loss: 0.486046; batch adversarial loss: 0.492400\n",
      "epoch 25; iter: 0; batch classifier loss: 0.489115; batch adversarial loss: 0.560269\n",
      "epoch 26; iter: 0; batch classifier loss: 0.469051; batch adversarial loss: 0.538536\n",
      "epoch 27; iter: 0; batch classifier loss: 0.461045; batch adversarial loss: 0.572887\n",
      "epoch 28; iter: 0; batch classifier loss: 0.528490; batch adversarial loss: 0.545617\n",
      "epoch 29; iter: 0; batch classifier loss: 0.414015; batch adversarial loss: 0.467236\n",
      "epoch 30; iter: 0; batch classifier loss: 0.402263; batch adversarial loss: 0.611143\n",
      "epoch 31; iter: 0; batch classifier loss: 0.427467; batch adversarial loss: 0.567778\n",
      "epoch 32; iter: 0; batch classifier loss: 0.528476; batch adversarial loss: 0.552830\n",
      "epoch 33; iter: 0; batch classifier loss: 0.404159; batch adversarial loss: 0.566632\n",
      "epoch 34; iter: 0; batch classifier loss: 0.407747; batch adversarial loss: 0.548409\n",
      "epoch 35; iter: 0; batch classifier loss: 0.445267; batch adversarial loss: 0.478305\n",
      "epoch 36; iter: 0; batch classifier loss: 0.422604; batch adversarial loss: 0.591361\n",
      "epoch 37; iter: 0; batch classifier loss: 0.415279; batch adversarial loss: 0.472659\n",
      "epoch 38; iter: 0; batch classifier loss: 0.368993; batch adversarial loss: 0.571392\n",
      "epoch 39; iter: 0; batch classifier loss: 0.478394; batch adversarial loss: 0.490386\n",
      "epoch 40; iter: 0; batch classifier loss: 0.448539; batch adversarial loss: 0.573829\n",
      "epoch 41; iter: 0; batch classifier loss: 0.466077; batch adversarial loss: 0.519935\n",
      "epoch 42; iter: 0; batch classifier loss: 0.424469; batch adversarial loss: 0.570309\n",
      "epoch 43; iter: 0; batch classifier loss: 0.355132; batch adversarial loss: 0.562883\n",
      "epoch 44; iter: 0; batch classifier loss: 0.429244; batch adversarial loss: 0.591978\n",
      "epoch 45; iter: 0; batch classifier loss: 0.457519; batch adversarial loss: 0.590149\n",
      "epoch 46; iter: 0; batch classifier loss: 0.369824; batch adversarial loss: 0.488068\n",
      "epoch 47; iter: 0; batch classifier loss: 0.456244; batch adversarial loss: 0.533959\n",
      "epoch 48; iter: 0; batch classifier loss: 0.416681; batch adversarial loss: 0.575117\n",
      "epoch 49; iter: 0; batch classifier loss: 0.444518; batch adversarial loss: 0.581297\n",
      "epoch 50; iter: 0; batch classifier loss: 0.470729; batch adversarial loss: 0.561969\n",
      "epoch 51; iter: 0; batch classifier loss: 0.485030; batch adversarial loss: 0.591419\n",
      "epoch 52; iter: 0; batch classifier loss: 0.408366; batch adversarial loss: 0.552757\n",
      "epoch 53; iter: 0; batch classifier loss: 0.359452; batch adversarial loss: 0.516878\n",
      "epoch 54; iter: 0; batch classifier loss: 0.407574; batch adversarial loss: 0.478938\n",
      "epoch 55; iter: 0; batch classifier loss: 0.459227; batch adversarial loss: 0.497871\n",
      "epoch 56; iter: 0; batch classifier loss: 0.427285; batch adversarial loss: 0.580544\n",
      "epoch 57; iter: 0; batch classifier loss: 0.424924; batch adversarial loss: 0.556474\n",
      "epoch 58; iter: 0; batch classifier loss: 0.472034; batch adversarial loss: 0.543604\n",
      "epoch 59; iter: 0; batch classifier loss: 0.467542; batch adversarial loss: 0.561158\n",
      "epoch 60; iter: 0; batch classifier loss: 0.384696; batch adversarial loss: 0.545531\n",
      "epoch 61; iter: 0; batch classifier loss: 0.446492; batch adversarial loss: 0.544635\n",
      "epoch 62; iter: 0; batch classifier loss: 0.448773; batch adversarial loss: 0.508540\n",
      "epoch 63; iter: 0; batch classifier loss: 0.436413; batch adversarial loss: 0.542458\n",
      "epoch 64; iter: 0; batch classifier loss: 0.440837; batch adversarial loss: 0.489066\n",
      "epoch 65; iter: 0; batch classifier loss: 0.382176; batch adversarial loss: 0.525298\n",
      "epoch 66; iter: 0; batch classifier loss: 0.381111; batch adversarial loss: 0.515750\n",
      "epoch 67; iter: 0; batch classifier loss: 0.417372; batch adversarial loss: 0.469802\n",
      "epoch 68; iter: 0; batch classifier loss: 0.330993; batch adversarial loss: 0.609590\n",
      "epoch 69; iter: 0; batch classifier loss: 0.417531; batch adversarial loss: 0.498748\n",
      "epoch 70; iter: 0; batch classifier loss: 0.416537; batch adversarial loss: 0.524979\n",
      "epoch 71; iter: 0; batch classifier loss: 0.424344; batch adversarial loss: 0.561730\n",
      "epoch 72; iter: 0; batch classifier loss: 0.394163; batch adversarial loss: 0.477915\n",
      "epoch 73; iter: 0; batch classifier loss: 0.442166; batch adversarial loss: 0.516958\n",
      "epoch 74; iter: 0; batch classifier loss: 0.451160; batch adversarial loss: 0.535563\n",
      "epoch 75; iter: 0; batch classifier loss: 0.406010; batch adversarial loss: 0.499261\n",
      "epoch 76; iter: 0; batch classifier loss: 0.421948; batch adversarial loss: 0.478813\n",
      "epoch 77; iter: 0; batch classifier loss: 0.440657; batch adversarial loss: 0.553744\n",
      "epoch 78; iter: 0; batch classifier loss: 0.372503; batch adversarial loss: 0.506586\n",
      "epoch 79; iter: 0; batch classifier loss: 0.413553; batch adversarial loss: 0.480394\n",
      "epoch 80; iter: 0; batch classifier loss: 0.356166; batch adversarial loss: 0.598335\n",
      "epoch 81; iter: 0; batch classifier loss: 0.403798; batch adversarial loss: 0.533526\n",
      "epoch 82; iter: 0; batch classifier loss: 0.389413; batch adversarial loss: 0.589955\n",
      "epoch 83; iter: 0; batch classifier loss: 0.375413; batch adversarial loss: 0.598100\n",
      "epoch 84; iter: 0; batch classifier loss: 0.379984; batch adversarial loss: 0.544382\n",
      "epoch 85; iter: 0; batch classifier loss: 0.382428; batch adversarial loss: 0.487063\n",
      "epoch 86; iter: 0; batch classifier loss: 0.338520; batch adversarial loss: 0.514878\n",
      "epoch 87; iter: 0; batch classifier loss: 0.339730; batch adversarial loss: 0.617271\n",
      "epoch 88; iter: 0; batch classifier loss: 0.346831; batch adversarial loss: 0.602164\n",
      "epoch 89; iter: 0; batch classifier loss: 0.358205; batch adversarial loss: 0.629028\n",
      "epoch 90; iter: 0; batch classifier loss: 0.416140; batch adversarial loss: 0.508611\n",
      "epoch 91; iter: 0; batch classifier loss: 0.353077; batch adversarial loss: 0.489490\n",
      "epoch 92; iter: 0; batch classifier loss: 0.411667; batch adversarial loss: 0.477443\n",
      "epoch 93; iter: 0; batch classifier loss: 0.354604; batch adversarial loss: 0.581857\n",
      "epoch 94; iter: 0; batch classifier loss: 0.345233; batch adversarial loss: 0.592952\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 95; iter: 0; batch classifier loss: 0.365822; batch adversarial loss: 0.496643\n",
      "epoch 96; iter: 0; batch classifier loss: 0.477977; batch adversarial loss: 0.486938\n",
      "epoch 97; iter: 0; batch classifier loss: 0.367257; batch adversarial loss: 0.620892\n",
      "epoch 98; iter: 0; batch classifier loss: 0.397714; batch adversarial loss: 0.553343\n",
      "epoch 99; iter: 0; batch classifier loss: 0.347917; batch adversarial loss: 0.563405\n",
      "epoch 100; iter: 0; batch classifier loss: 0.463270; batch adversarial loss: 0.621044\n",
      "epoch 101; iter: 0; batch classifier loss: 0.414380; batch adversarial loss: 0.561084\n",
      "epoch 102; iter: 0; batch classifier loss: 0.473125; batch adversarial loss: 0.556117\n",
      "epoch 103; iter: 0; batch classifier loss: 0.388028; batch adversarial loss: 0.574516\n",
      "epoch 104; iter: 0; batch classifier loss: 0.397441; batch adversarial loss: 0.552398\n",
      "epoch 105; iter: 0; batch classifier loss: 0.446794; batch adversarial loss: 0.600125\n",
      "epoch 106; iter: 0; batch classifier loss: 0.342282; batch adversarial loss: 0.516085\n",
      "epoch 107; iter: 0; batch classifier loss: 0.364815; batch adversarial loss: 0.525926\n",
      "epoch 108; iter: 0; batch classifier loss: 0.435402; batch adversarial loss: 0.498395\n",
      "epoch 109; iter: 0; batch classifier loss: 0.421208; batch adversarial loss: 0.516956\n",
      "epoch 110; iter: 0; batch classifier loss: 0.355759; batch adversarial loss: 0.470409\n",
      "epoch 111; iter: 0; batch classifier loss: 0.345185; batch adversarial loss: 0.515575\n",
      "epoch 112; iter: 0; batch classifier loss: 0.431487; batch adversarial loss: 0.536379\n",
      "epoch 113; iter: 0; batch classifier loss: 0.279249; batch adversarial loss: 0.506969\n",
      "epoch 114; iter: 0; batch classifier loss: 0.485999; batch adversarial loss: 0.507206\n",
      "epoch 115; iter: 0; batch classifier loss: 0.355999; batch adversarial loss: 0.506768\n",
      "epoch 116; iter: 0; batch classifier loss: 0.382346; batch adversarial loss: 0.599218\n",
      "epoch 117; iter: 0; batch classifier loss: 0.353345; batch adversarial loss: 0.544468\n",
      "epoch 118; iter: 0; batch classifier loss: 0.417652; batch adversarial loss: 0.534183\n",
      "epoch 119; iter: 0; batch classifier loss: 0.424390; batch adversarial loss: 0.545903\n",
      "epoch 120; iter: 0; batch classifier loss: 0.352335; batch adversarial loss: 0.579073\n",
      "epoch 121; iter: 0; batch classifier loss: 0.349410; batch adversarial loss: 0.574352\n",
      "epoch 122; iter: 0; batch classifier loss: 0.350153; batch adversarial loss: 0.584049\n",
      "epoch 123; iter: 0; batch classifier loss: 0.432625; batch adversarial loss: 0.536853\n",
      "epoch 124; iter: 0; batch classifier loss: 0.359014; batch adversarial loss: 0.563335\n",
      "epoch 125; iter: 0; batch classifier loss: 0.370932; batch adversarial loss: 0.563738\n",
      "epoch 126; iter: 0; batch classifier loss: 0.383995; batch adversarial loss: 0.533682\n",
      "epoch 127; iter: 0; batch classifier loss: 0.402113; batch adversarial loss: 0.552874\n",
      "epoch 128; iter: 0; batch classifier loss: 0.368798; batch adversarial loss: 0.504863\n",
      "epoch 129; iter: 0; batch classifier loss: 0.467204; batch adversarial loss: 0.560620\n",
      "epoch 130; iter: 0; batch classifier loss: 0.316690; batch adversarial loss: 0.516341\n",
      "epoch 131; iter: 0; batch classifier loss: 0.345947; batch adversarial loss: 0.506107\n",
      "epoch 132; iter: 0; batch classifier loss: 0.387910; batch adversarial loss: 0.523466\n",
      "epoch 133; iter: 0; batch classifier loss: 0.434504; batch adversarial loss: 0.632787\n",
      "epoch 134; iter: 0; batch classifier loss: 0.438294; batch adversarial loss: 0.554514\n",
      "epoch 135; iter: 0; batch classifier loss: 0.337847; batch adversarial loss: 0.516624\n",
      "epoch 136; iter: 0; batch classifier loss: 0.338167; batch adversarial loss: 0.564489\n",
      "epoch 137; iter: 0; batch classifier loss: 0.530205; batch adversarial loss: 0.535051\n",
      "epoch 138; iter: 0; batch classifier loss: 0.353956; batch adversarial loss: 0.535500\n",
      "epoch 139; iter: 0; batch classifier loss: 0.328975; batch adversarial loss: 0.564259\n",
      "epoch 140; iter: 0; batch classifier loss: 0.413030; batch adversarial loss: 0.486498\n",
      "epoch 141; iter: 0; batch classifier loss: 0.310598; batch adversarial loss: 0.561102\n",
      "epoch 142; iter: 0; batch classifier loss: 0.335759; batch adversarial loss: 0.590290\n",
      "epoch 143; iter: 0; batch classifier loss: 0.383128; batch adversarial loss: 0.497873\n",
      "epoch 144; iter: 0; batch classifier loss: 0.363750; batch adversarial loss: 0.553651\n",
      "epoch 145; iter: 0; batch classifier loss: 0.300740; batch adversarial loss: 0.620411\n",
      "epoch 146; iter: 0; batch classifier loss: 0.360276; batch adversarial loss: 0.572296\n",
      "epoch 147; iter: 0; batch classifier loss: 0.359369; batch adversarial loss: 0.513865\n",
      "epoch 148; iter: 0; batch classifier loss: 0.404655; batch adversarial loss: 0.582830\n",
      "epoch 149; iter: 0; batch classifier loss: 0.365355; batch adversarial loss: 0.571963\n",
      "epoch 150; iter: 0; batch classifier loss: 0.353972; batch adversarial loss: 0.489360\n",
      "epoch 151; iter: 0; batch classifier loss: 0.345815; batch adversarial loss: 0.628200\n",
      "epoch 152; iter: 0; batch classifier loss: 0.319579; batch adversarial loss: 0.555296\n",
      "epoch 153; iter: 0; batch classifier loss: 0.349547; batch adversarial loss: 0.545568\n",
      "epoch 154; iter: 0; batch classifier loss: 0.470668; batch adversarial loss: 0.487147\n",
      "epoch 155; iter: 0; batch classifier loss: 0.406247; batch adversarial loss: 0.611191\n",
      "epoch 156; iter: 0; batch classifier loss: 0.312742; batch adversarial loss: 0.516749\n",
      "epoch 157; iter: 0; batch classifier loss: 0.442169; batch adversarial loss: 0.591593\n",
      "epoch 158; iter: 0; batch classifier loss: 0.349533; batch adversarial loss: 0.523735\n",
      "epoch 159; iter: 0; batch classifier loss: 0.356715; batch adversarial loss: 0.545342\n",
      "epoch 160; iter: 0; batch classifier loss: 0.371952; batch adversarial loss: 0.620261\n",
      "epoch 161; iter: 0; batch classifier loss: 0.392989; batch adversarial loss: 0.516325\n",
      "epoch 162; iter: 0; batch classifier loss: 0.376778; batch adversarial loss: 0.571793\n",
      "epoch 163; iter: 0; batch classifier loss: 0.353513; batch adversarial loss: 0.552798\n",
      "epoch 164; iter: 0; batch classifier loss: 0.356017; batch adversarial loss: 0.561668\n",
      "epoch 165; iter: 0; batch classifier loss: 0.297505; batch adversarial loss: 0.489913\n",
      "epoch 166; iter: 0; batch classifier loss: 0.344560; batch adversarial loss: 0.586390\n",
      "epoch 167; iter: 0; batch classifier loss: 0.346132; batch adversarial loss: 0.524083\n",
      "epoch 168; iter: 0; batch classifier loss: 0.309294; batch adversarial loss: 0.523780\n",
      "epoch 169; iter: 0; batch classifier loss: 0.390751; batch adversarial loss: 0.627118\n",
      "epoch 170; iter: 0; batch classifier loss: 0.370467; batch adversarial loss: 0.551133\n",
      "epoch 171; iter: 0; batch classifier loss: 0.341151; batch adversarial loss: 0.551739\n",
      "epoch 172; iter: 0; batch classifier loss: 0.357721; batch adversarial loss: 0.582438\n",
      "epoch 173; iter: 0; batch classifier loss: 0.363684; batch adversarial loss: 0.541800\n",
      "epoch 174; iter: 0; batch classifier loss: 0.328623; batch adversarial loss: 0.582783\n",
      "epoch 175; iter: 0; batch classifier loss: 0.419140; batch adversarial loss: 0.483297\n",
      "epoch 176; iter: 0; batch classifier loss: 0.387178; batch adversarial loss: 0.524733\n",
      "epoch 177; iter: 0; batch classifier loss: 0.373207; batch adversarial loss: 0.527481\n",
      "epoch 178; iter: 0; batch classifier loss: 0.385052; batch adversarial loss: 0.536511\n",
      "epoch 179; iter: 0; batch classifier loss: 0.332436; batch adversarial loss: 0.563206\n",
      "epoch 180; iter: 0; batch classifier loss: 0.334648; batch adversarial loss: 0.498366\n",
      "epoch 181; iter: 0; batch classifier loss: 0.376032; batch adversarial loss: 0.545373\n",
      "epoch 182; iter: 0; batch classifier loss: 0.351214; batch adversarial loss: 0.543536\n",
      "epoch 183; iter: 0; batch classifier loss: 0.335009; batch adversarial loss: 0.562449\n",
      "epoch 184; iter: 0; batch classifier loss: 0.305386; batch adversarial loss: 0.609894\n",
      "epoch 185; iter: 0; batch classifier loss: 0.358731; batch adversarial loss: 0.478787\n",
      "epoch 186; iter: 0; batch classifier loss: 0.335652; batch adversarial loss: 0.570798\n",
      "epoch 187; iter: 0; batch classifier loss: 0.371764; batch adversarial loss: 0.545993\n",
      "epoch 188; iter: 0; batch classifier loss: 0.352144; batch adversarial loss: 0.487254\n",
      "epoch 189; iter: 0; batch classifier loss: 0.338848; batch adversarial loss: 0.563638\n",
      "epoch 190; iter: 0; batch classifier loss: 0.359616; batch adversarial loss: 0.581510\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 191; iter: 0; batch classifier loss: 0.369597; batch adversarial loss: 0.507575\n",
      "epoch 192; iter: 0; batch classifier loss: 0.432750; batch adversarial loss: 0.487292\n",
      "epoch 193; iter: 0; batch classifier loss: 0.347890; batch adversarial loss: 0.555520\n",
      "epoch 194; iter: 0; batch classifier loss: 0.364734; batch adversarial loss: 0.535372\n",
      "epoch 195; iter: 0; batch classifier loss: 0.317696; batch adversarial loss: 0.515317\n",
      "epoch 196; iter: 0; batch classifier loss: 0.400729; batch adversarial loss: 0.553086\n",
      "epoch 197; iter: 0; batch classifier loss: 0.304367; batch adversarial loss: 0.527111\n",
      "epoch 198; iter: 0; batch classifier loss: 0.354077; batch adversarial loss: 0.657874\n",
      "epoch 199; iter: 0; batch classifier loss: 0.367795; batch adversarial loss: 0.526989\n",
      "epoch 0; iter: 0; batch classifier loss: 0.684266; batch adversarial loss: 0.596068\n",
      "epoch 1; iter: 0; batch classifier loss: 0.660962; batch adversarial loss: 0.699727\n",
      "epoch 2; iter: 0; batch classifier loss: 0.647572; batch adversarial loss: 0.676839\n",
      "epoch 3; iter: 0; batch classifier loss: 0.545684; batch adversarial loss: 0.721180\n",
      "epoch 4; iter: 0; batch classifier loss: 0.636972; batch adversarial loss: 0.639702\n",
      "epoch 5; iter: 0; batch classifier loss: 0.557497; batch adversarial loss: 0.704761\n",
      "epoch 6; iter: 0; batch classifier loss: 0.599162; batch adversarial loss: 0.684358\n",
      "epoch 7; iter: 0; batch classifier loss: 0.627882; batch adversarial loss: 0.681796\n",
      "epoch 8; iter: 0; batch classifier loss: 0.528629; batch adversarial loss: 0.605363\n",
      "epoch 9; iter: 0; batch classifier loss: 0.652470; batch adversarial loss: 0.619861\n",
      "epoch 10; iter: 0; batch classifier loss: 0.544907; batch adversarial loss: 0.629063\n",
      "epoch 11; iter: 0; batch classifier loss: 0.502979; batch adversarial loss: 0.588040\n",
      "epoch 12; iter: 0; batch classifier loss: 0.526356; batch adversarial loss: 0.542720\n",
      "epoch 13; iter: 0; batch classifier loss: 0.587385; batch adversarial loss: 0.552219\n",
      "epoch 14; iter: 0; batch classifier loss: 0.601850; batch adversarial loss: 0.531699\n",
      "epoch 15; iter: 0; batch classifier loss: 0.550094; batch adversarial loss: 0.580513\n",
      "epoch 16; iter: 0; batch classifier loss: 0.437807; batch adversarial loss: 0.572396\n",
      "epoch 17; iter: 0; batch classifier loss: 0.550258; batch adversarial loss: 0.570086\n",
      "epoch 18; iter: 0; batch classifier loss: 0.547366; batch adversarial loss: 0.574937\n",
      "epoch 19; iter: 0; batch classifier loss: 0.511890; batch adversarial loss: 0.565213\n",
      "epoch 20; iter: 0; batch classifier loss: 0.508229; batch adversarial loss: 0.564322\n",
      "epoch 21; iter: 0; batch classifier loss: 0.546790; batch adversarial loss: 0.553215\n",
      "epoch 22; iter: 0; batch classifier loss: 0.426570; batch adversarial loss: 0.509882\n",
      "epoch 23; iter: 0; batch classifier loss: 0.429174; batch adversarial loss: 0.569760\n",
      "epoch 24; iter: 0; batch classifier loss: 0.404234; batch adversarial loss: 0.554996\n",
      "epoch 25; iter: 0; batch classifier loss: 0.447967; batch adversarial loss: 0.500693\n",
      "epoch 26; iter: 0; batch classifier loss: 0.487844; batch adversarial loss: 0.563750\n",
      "epoch 27; iter: 0; batch classifier loss: 0.537342; batch adversarial loss: 0.497900\n",
      "epoch 28; iter: 0; batch classifier loss: 0.506762; batch adversarial loss: 0.527471\n",
      "epoch 29; iter: 0; batch classifier loss: 0.412690; batch adversarial loss: 0.500845\n",
      "epoch 30; iter: 0; batch classifier loss: 0.463836; batch adversarial loss: 0.444765\n",
      "epoch 31; iter: 0; batch classifier loss: 0.436311; batch adversarial loss: 0.568075\n",
      "epoch 32; iter: 0; batch classifier loss: 0.490123; batch adversarial loss: 0.527024\n",
      "epoch 33; iter: 0; batch classifier loss: 0.523019; batch adversarial loss: 0.601479\n",
      "epoch 34; iter: 0; batch classifier loss: 0.413781; batch adversarial loss: 0.625517\n",
      "epoch 35; iter: 0; batch classifier loss: 0.487835; batch adversarial loss: 0.510934\n",
      "epoch 36; iter: 0; batch classifier loss: 0.554825; batch adversarial loss: 0.540116\n",
      "epoch 37; iter: 0; batch classifier loss: 0.417892; batch adversarial loss: 0.605639\n",
      "epoch 38; iter: 0; batch classifier loss: 0.403894; batch adversarial loss: 0.505761\n",
      "epoch 39; iter: 0; batch classifier loss: 0.424999; batch adversarial loss: 0.500491\n",
      "epoch 40; iter: 0; batch classifier loss: 0.447323; batch adversarial loss: 0.604593\n",
      "epoch 41; iter: 0; batch classifier loss: 0.511867; batch adversarial loss: 0.520632\n",
      "epoch 42; iter: 0; batch classifier loss: 0.419200; batch adversarial loss: 0.583092\n",
      "epoch 43; iter: 0; batch classifier loss: 0.356275; batch adversarial loss: 0.650850\n",
      "epoch 44; iter: 0; batch classifier loss: 0.454922; batch adversarial loss: 0.529737\n",
      "epoch 45; iter: 0; batch classifier loss: 0.490164; batch adversarial loss: 0.520663\n",
      "epoch 46; iter: 0; batch classifier loss: 0.440880; batch adversarial loss: 0.532200\n",
      "epoch 47; iter: 0; batch classifier loss: 0.451054; batch adversarial loss: 0.574749\n",
      "epoch 48; iter: 0; batch classifier loss: 0.426720; batch adversarial loss: 0.567526\n",
      "epoch 49; iter: 0; batch classifier loss: 0.398254; batch adversarial loss: 0.553992\n",
      "epoch 50; iter: 0; batch classifier loss: 0.410135; batch adversarial loss: 0.551690\n",
      "epoch 51; iter: 0; batch classifier loss: 0.392413; batch adversarial loss: 0.536054\n",
      "epoch 52; iter: 0; batch classifier loss: 0.379086; batch adversarial loss: 0.559426\n",
      "epoch 53; iter: 0; batch classifier loss: 0.402985; batch adversarial loss: 0.516180\n",
      "epoch 54; iter: 0; batch classifier loss: 0.426710; batch adversarial loss: 0.538258\n",
      "epoch 55; iter: 0; batch classifier loss: 0.382442; batch adversarial loss: 0.520518\n",
      "epoch 56; iter: 0; batch classifier loss: 0.442564; batch adversarial loss: 0.515999\n",
      "epoch 57; iter: 0; batch classifier loss: 0.389573; batch adversarial loss: 0.640508\n",
      "epoch 58; iter: 0; batch classifier loss: 0.419723; batch adversarial loss: 0.548002\n",
      "epoch 59; iter: 0; batch classifier loss: 0.416457; batch adversarial loss: 0.596360\n",
      "epoch 60; iter: 0; batch classifier loss: 0.491186; batch adversarial loss: 0.545923\n",
      "epoch 61; iter: 0; batch classifier loss: 0.459952; batch adversarial loss: 0.555614\n",
      "epoch 62; iter: 0; batch classifier loss: 0.349475; batch adversarial loss: 0.501636\n",
      "epoch 63; iter: 0; batch classifier loss: 0.407953; batch adversarial loss: 0.571648\n",
      "epoch 64; iter: 0; batch classifier loss: 0.457587; batch adversarial loss: 0.555988\n",
      "epoch 65; iter: 0; batch classifier loss: 0.367208; batch adversarial loss: 0.502106\n",
      "epoch 66; iter: 0; batch classifier loss: 0.409959; batch adversarial loss: 0.518404\n",
      "epoch 67; iter: 0; batch classifier loss: 0.403547; batch adversarial loss: 0.560658\n",
      "epoch 68; iter: 0; batch classifier loss: 0.425067; batch adversarial loss: 0.535908\n",
      "epoch 69; iter: 0; batch classifier loss: 0.416918; batch adversarial loss: 0.552873\n",
      "epoch 70; iter: 0; batch classifier loss: 0.430074; batch adversarial loss: 0.624979\n",
      "epoch 71; iter: 0; batch classifier loss: 0.406936; batch adversarial loss: 0.545069\n",
      "epoch 72; iter: 0; batch classifier loss: 0.415822; batch adversarial loss: 0.481225\n",
      "epoch 73; iter: 0; batch classifier loss: 0.419164; batch adversarial loss: 0.506666\n",
      "epoch 74; iter: 0; batch classifier loss: 0.422632; batch adversarial loss: 0.555199\n",
      "epoch 75; iter: 0; batch classifier loss: 0.372388; batch adversarial loss: 0.526557\n",
      "epoch 76; iter: 0; batch classifier loss: 0.452145; batch adversarial loss: 0.487661\n",
      "epoch 77; iter: 0; batch classifier loss: 0.312354; batch adversarial loss: 0.499676\n",
      "epoch 78; iter: 0; batch classifier loss: 0.453018; batch adversarial loss: 0.505807\n",
      "epoch 79; iter: 0; batch classifier loss: 0.342490; batch adversarial loss: 0.583386\n",
      "epoch 80; iter: 0; batch classifier loss: 0.387945; batch adversarial loss: 0.561635\n",
      "epoch 81; iter: 0; batch classifier loss: 0.356786; batch adversarial loss: 0.505221\n",
      "epoch 82; iter: 0; batch classifier loss: 0.379009; batch adversarial loss: 0.467160\n",
      "epoch 83; iter: 0; batch classifier loss: 0.473035; batch adversarial loss: 0.530712\n",
      "epoch 84; iter: 0; batch classifier loss: 0.403720; batch adversarial loss: 0.444934\n",
      "epoch 85; iter: 0; batch classifier loss: 0.370204; batch adversarial loss: 0.534561\n",
      "epoch 86; iter: 0; batch classifier loss: 0.416275; batch adversarial loss: 0.550449\n",
      "epoch 87; iter: 0; batch classifier loss: 0.459311; batch adversarial loss: 0.483716\n",
      "epoch 88; iter: 0; batch classifier loss: 0.411864; batch adversarial loss: 0.535623\n",
      "epoch 89; iter: 0; batch classifier loss: 0.358042; batch adversarial loss: 0.515128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 90; iter: 0; batch classifier loss: 0.375066; batch adversarial loss: 0.593291\n",
      "epoch 91; iter: 0; batch classifier loss: 0.370871; batch adversarial loss: 0.550296\n",
      "epoch 92; iter: 0; batch classifier loss: 0.360214; batch adversarial loss: 0.569778\n",
      "epoch 93; iter: 0; batch classifier loss: 0.363926; batch adversarial loss: 0.585481\n",
      "epoch 94; iter: 0; batch classifier loss: 0.394954; batch adversarial loss: 0.458489\n",
      "epoch 95; iter: 0; batch classifier loss: 0.418956; batch adversarial loss: 0.549601\n",
      "epoch 96; iter: 0; batch classifier loss: 0.488455; batch adversarial loss: 0.578173\n",
      "epoch 97; iter: 0; batch classifier loss: 0.413065; batch adversarial loss: 0.590966\n",
      "epoch 98; iter: 0; batch classifier loss: 0.377174; batch adversarial loss: 0.583112\n",
      "epoch 99; iter: 0; batch classifier loss: 0.367504; batch adversarial loss: 0.548880\n",
      "epoch 100; iter: 0; batch classifier loss: 0.368044; batch adversarial loss: 0.505890\n",
      "epoch 101; iter: 0; batch classifier loss: 0.418024; batch adversarial loss: 0.473990\n",
      "epoch 102; iter: 0; batch classifier loss: 0.342536; batch adversarial loss: 0.554928\n",
      "epoch 103; iter: 0; batch classifier loss: 0.351144; batch adversarial loss: 0.528508\n",
      "epoch 104; iter: 0; batch classifier loss: 0.354961; batch adversarial loss: 0.571747\n",
      "epoch 105; iter: 0; batch classifier loss: 0.420984; batch adversarial loss: 0.527569\n",
      "epoch 106; iter: 0; batch classifier loss: 0.363284; batch adversarial loss: 0.526824\n",
      "epoch 107; iter: 0; batch classifier loss: 0.331571; batch adversarial loss: 0.582743\n",
      "epoch 108; iter: 0; batch classifier loss: 0.350198; batch adversarial loss: 0.499104\n",
      "epoch 109; iter: 0; batch classifier loss: 0.401247; batch adversarial loss: 0.508151\n",
      "epoch 110; iter: 0; batch classifier loss: 0.319773; batch adversarial loss: 0.590073\n",
      "epoch 111; iter: 0; batch classifier loss: 0.407068; batch adversarial loss: 0.532882\n",
      "epoch 112; iter: 0; batch classifier loss: 0.307151; batch adversarial loss: 0.499870\n",
      "epoch 113; iter: 0; batch classifier loss: 0.398003; batch adversarial loss: 0.518232\n",
      "epoch 114; iter: 0; batch classifier loss: 0.368249; batch adversarial loss: 0.565297\n",
      "epoch 115; iter: 0; batch classifier loss: 0.444431; batch adversarial loss: 0.478532\n",
      "epoch 116; iter: 0; batch classifier loss: 0.319806; batch adversarial loss: 0.625817\n",
      "epoch 117; iter: 0; batch classifier loss: 0.371897; batch adversarial loss: 0.532357\n",
      "epoch 118; iter: 0; batch classifier loss: 0.376229; batch adversarial loss: 0.584863\n",
      "epoch 119; iter: 0; batch classifier loss: 0.366191; batch adversarial loss: 0.576556\n",
      "epoch 120; iter: 0; batch classifier loss: 0.310070; batch adversarial loss: 0.563978\n",
      "epoch 121; iter: 0; batch classifier loss: 0.334872; batch adversarial loss: 0.597196\n",
      "epoch 122; iter: 0; batch classifier loss: 0.403392; batch adversarial loss: 0.524019\n",
      "epoch 123; iter: 0; batch classifier loss: 0.392020; batch adversarial loss: 0.540340\n",
      "epoch 124; iter: 0; batch classifier loss: 0.389910; batch adversarial loss: 0.562534\n",
      "epoch 125; iter: 0; batch classifier loss: 0.406897; batch adversarial loss: 0.541527\n",
      "epoch 126; iter: 0; batch classifier loss: 0.362016; batch adversarial loss: 0.523613\n",
      "epoch 127; iter: 0; batch classifier loss: 0.329610; batch adversarial loss: 0.482817\n",
      "epoch 128; iter: 0; batch classifier loss: 0.404454; batch adversarial loss: 0.515249\n",
      "epoch 129; iter: 0; batch classifier loss: 0.392243; batch adversarial loss: 0.456347\n",
      "epoch 130; iter: 0; batch classifier loss: 0.366100; batch adversarial loss: 0.526179\n",
      "epoch 131; iter: 0; batch classifier loss: 0.420446; batch adversarial loss: 0.644735\n",
      "epoch 132; iter: 0; batch classifier loss: 0.340149; batch adversarial loss: 0.571245\n",
      "epoch 133; iter: 0; batch classifier loss: 0.430876; batch adversarial loss: 0.528498\n",
      "epoch 134; iter: 0; batch classifier loss: 0.280855; batch adversarial loss: 0.508346\n",
      "epoch 135; iter: 0; batch classifier loss: 0.284363; batch adversarial loss: 0.550471\n",
      "epoch 136; iter: 0; batch classifier loss: 0.272146; batch adversarial loss: 0.554122\n",
      "epoch 137; iter: 0; batch classifier loss: 0.383935; batch adversarial loss: 0.563230\n",
      "epoch 138; iter: 0; batch classifier loss: 0.378522; batch adversarial loss: 0.546766\n",
      "epoch 139; iter: 0; batch classifier loss: 0.383865; batch adversarial loss: 0.616571\n",
      "epoch 140; iter: 0; batch classifier loss: 0.419896; batch adversarial loss: 0.471892\n",
      "epoch 141; iter: 0; batch classifier loss: 0.345934; batch adversarial loss: 0.544304\n",
      "epoch 142; iter: 0; batch classifier loss: 0.472420; batch adversarial loss: 0.554620\n",
      "epoch 143; iter: 0; batch classifier loss: 0.311676; batch adversarial loss: 0.543170\n",
      "epoch 144; iter: 0; batch classifier loss: 0.450959; batch adversarial loss: 0.527257\n",
      "epoch 145; iter: 0; batch classifier loss: 0.312509; batch adversarial loss: 0.573036\n",
      "epoch 146; iter: 0; batch classifier loss: 0.334229; batch adversarial loss: 0.616714\n",
      "epoch 147; iter: 0; batch classifier loss: 0.431373; batch adversarial loss: 0.535186\n",
      "epoch 148; iter: 0; batch classifier loss: 0.410162; batch adversarial loss: 0.534646\n",
      "epoch 149; iter: 0; batch classifier loss: 0.410086; batch adversarial loss: 0.454430\n",
      "epoch 150; iter: 0; batch classifier loss: 0.385296; batch adversarial loss: 0.489941\n",
      "epoch 151; iter: 0; batch classifier loss: 0.418734; batch adversarial loss: 0.526078\n",
      "epoch 152; iter: 0; batch classifier loss: 0.334613; batch adversarial loss: 0.488059\n",
      "epoch 153; iter: 0; batch classifier loss: 0.343513; batch adversarial loss: 0.544442\n",
      "epoch 154; iter: 0; batch classifier loss: 0.313304; batch adversarial loss: 0.571328\n",
      "epoch 155; iter: 0; batch classifier loss: 0.373712; batch adversarial loss: 0.609375\n",
      "epoch 156; iter: 0; batch classifier loss: 0.313178; batch adversarial loss: 0.628592\n",
      "epoch 157; iter: 0; batch classifier loss: 0.394637; batch adversarial loss: 0.589808\n",
      "epoch 158; iter: 0; batch classifier loss: 0.384432; batch adversarial loss: 0.488941\n",
      "epoch 159; iter: 0; batch classifier loss: 0.433883; batch adversarial loss: 0.619402\n",
      "epoch 160; iter: 0; batch classifier loss: 0.348646; batch adversarial loss: 0.561908\n",
      "epoch 161; iter: 0; batch classifier loss: 0.310469; batch adversarial loss: 0.477038\n",
      "epoch 162; iter: 0; batch classifier loss: 0.395969; batch adversarial loss: 0.581116\n",
      "epoch 163; iter: 0; batch classifier loss: 0.432951; batch adversarial loss: 0.530632\n",
      "epoch 164; iter: 0; batch classifier loss: 0.334961; batch adversarial loss: 0.582061\n",
      "epoch 165; iter: 0; batch classifier loss: 0.317574; batch adversarial loss: 0.535663\n",
      "epoch 166; iter: 0; batch classifier loss: 0.275666; batch adversarial loss: 0.553692\n",
      "epoch 167; iter: 0; batch classifier loss: 0.399506; batch adversarial loss: 0.608569\n",
      "epoch 168; iter: 0; batch classifier loss: 0.312661; batch adversarial loss: 0.469163\n",
      "epoch 169; iter: 0; batch classifier loss: 0.350154; batch adversarial loss: 0.629025\n",
      "epoch 170; iter: 0; batch classifier loss: 0.409759; batch adversarial loss: 0.534766\n",
      "epoch 171; iter: 0; batch classifier loss: 0.471740; batch adversarial loss: 0.518021\n",
      "epoch 172; iter: 0; batch classifier loss: 0.409140; batch adversarial loss: 0.492172\n",
      "epoch 173; iter: 0; batch classifier loss: 0.458289; batch adversarial loss: 0.520652\n",
      "epoch 174; iter: 0; batch classifier loss: 0.322792; batch adversarial loss: 0.592788\n",
      "epoch 175; iter: 0; batch classifier loss: 0.390828; batch adversarial loss: 0.563557\n",
      "epoch 176; iter: 0; batch classifier loss: 0.382095; batch adversarial loss: 0.563892\n",
      "epoch 177; iter: 0; batch classifier loss: 0.314170; batch adversarial loss: 0.554230\n",
      "epoch 178; iter: 0; batch classifier loss: 0.413110; batch adversarial loss: 0.571812\n",
      "epoch 179; iter: 0; batch classifier loss: 0.295872; batch adversarial loss: 0.544490\n",
      "epoch 180; iter: 0; batch classifier loss: 0.331505; batch adversarial loss: 0.516737\n",
      "epoch 181; iter: 0; batch classifier loss: 0.366306; batch adversarial loss: 0.599193\n",
      "epoch 182; iter: 0; batch classifier loss: 0.319555; batch adversarial loss: 0.509603\n",
      "epoch 183; iter: 0; batch classifier loss: 0.373900; batch adversarial loss: 0.533445\n",
      "epoch 184; iter: 0; batch classifier loss: 0.336135; batch adversarial loss: 0.545267\n",
      "epoch 185; iter: 0; batch classifier loss: 0.365685; batch adversarial loss: 0.544979\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 186; iter: 0; batch classifier loss: 0.284683; batch adversarial loss: 0.527167\n",
      "epoch 187; iter: 0; batch classifier loss: 0.327020; batch adversarial loss: 0.516325\n",
      "epoch 188; iter: 0; batch classifier loss: 0.333161; batch adversarial loss: 0.537685\n",
      "epoch 189; iter: 0; batch classifier loss: 0.341480; batch adversarial loss: 0.591402\n",
      "epoch 190; iter: 0; batch classifier loss: 0.321468; batch adversarial loss: 0.516340\n",
      "epoch 191; iter: 0; batch classifier loss: 0.303844; batch adversarial loss: 0.627213\n",
      "epoch 192; iter: 0; batch classifier loss: 0.323336; batch adversarial loss: 0.489673\n",
      "epoch 193; iter: 0; batch classifier loss: 0.360730; batch adversarial loss: 0.563982\n",
      "epoch 194; iter: 0; batch classifier loss: 0.397900; batch adversarial loss: 0.498569\n",
      "epoch 195; iter: 0; batch classifier loss: 0.335486; batch adversarial loss: 0.562204\n",
      "epoch 196; iter: 0; batch classifier loss: 0.325583; batch adversarial loss: 0.672839\n",
      "epoch 197; iter: 0; batch classifier loss: 0.409622; batch adversarial loss: 0.490616\n",
      "epoch 198; iter: 0; batch classifier loss: 0.365881; batch adversarial loss: 0.535248\n",
      "epoch 199; iter: 0; batch classifier loss: 0.384340; batch adversarial loss: 0.561520\n",
      "epoch 0; iter: 0; batch classifier loss: 0.701278; batch adversarial loss: 0.653253\n",
      "epoch 1; iter: 0; batch classifier loss: 0.528284; batch adversarial loss: 0.671703\n",
      "epoch 2; iter: 0; batch classifier loss: 0.613761; batch adversarial loss: 0.617249\n",
      "epoch 3; iter: 0; batch classifier loss: 0.553413; batch adversarial loss: 0.611123\n",
      "epoch 4; iter: 0; batch classifier loss: 0.536974; batch adversarial loss: 0.571664\n",
      "epoch 5; iter: 0; batch classifier loss: 0.563121; batch adversarial loss: 0.596214\n",
      "epoch 6; iter: 0; batch classifier loss: 0.513638; batch adversarial loss: 0.591090\n",
      "epoch 7; iter: 0; batch classifier loss: 0.546618; batch adversarial loss: 0.608901\n",
      "epoch 8; iter: 0; batch classifier loss: 0.537501; batch adversarial loss: 0.561457\n",
      "epoch 9; iter: 0; batch classifier loss: 0.583727; batch adversarial loss: 0.565326\n",
      "epoch 10; iter: 0; batch classifier loss: 0.609159; batch adversarial loss: 0.580015\n",
      "epoch 11; iter: 0; batch classifier loss: 0.599633; batch adversarial loss: 0.563585\n",
      "epoch 12; iter: 0; batch classifier loss: 0.457525; batch adversarial loss: 0.513795\n",
      "epoch 13; iter: 0; batch classifier loss: 0.513113; batch adversarial loss: 0.541710\n",
      "epoch 14; iter: 0; batch classifier loss: 0.521053; batch adversarial loss: 0.612090\n",
      "epoch 15; iter: 0; batch classifier loss: 0.492847; batch adversarial loss: 0.604530\n",
      "epoch 16; iter: 0; batch classifier loss: 0.491456; batch adversarial loss: 0.579294\n",
      "epoch 17; iter: 0; batch classifier loss: 0.589936; batch adversarial loss: 0.545498\n",
      "epoch 18; iter: 0; batch classifier loss: 0.502668; batch adversarial loss: 0.528369\n",
      "epoch 19; iter: 0; batch classifier loss: 0.538591; batch adversarial loss: 0.608540\n",
      "epoch 20; iter: 0; batch classifier loss: 0.500952; batch adversarial loss: 0.616426\n",
      "epoch 21; iter: 0; batch classifier loss: 0.541794; batch adversarial loss: 0.518176\n",
      "epoch 22; iter: 0; batch classifier loss: 0.513229; batch adversarial loss: 0.604256\n",
      "epoch 23; iter: 0; batch classifier loss: 0.561938; batch adversarial loss: 0.547397\n",
      "epoch 24; iter: 0; batch classifier loss: 0.404530; batch adversarial loss: 0.500398\n",
      "epoch 25; iter: 0; batch classifier loss: 0.452709; batch adversarial loss: 0.573290\n",
      "epoch 26; iter: 0; batch classifier loss: 0.400136; batch adversarial loss: 0.540150\n",
      "epoch 27; iter: 0; batch classifier loss: 0.472371; batch adversarial loss: 0.538052\n",
      "epoch 28; iter: 0; batch classifier loss: 0.462131; batch adversarial loss: 0.554999\n",
      "epoch 29; iter: 0; batch classifier loss: 0.464643; batch adversarial loss: 0.494114\n",
      "epoch 30; iter: 0; batch classifier loss: 0.433875; batch adversarial loss: 0.519343\n",
      "epoch 31; iter: 0; batch classifier loss: 0.473616; batch adversarial loss: 0.588134\n",
      "epoch 32; iter: 0; batch classifier loss: 0.489507; batch adversarial loss: 0.536074\n",
      "epoch 33; iter: 0; batch classifier loss: 0.424505; batch adversarial loss: 0.553446\n",
      "epoch 34; iter: 0; batch classifier loss: 0.448780; batch adversarial loss: 0.518528\n",
      "epoch 35; iter: 0; batch classifier loss: 0.435815; batch adversarial loss: 0.571501\n",
      "epoch 36; iter: 0; batch classifier loss: 0.429583; batch adversarial loss: 0.562679\n",
      "epoch 37; iter: 0; batch classifier loss: 0.474094; batch adversarial loss: 0.588744\n",
      "epoch 38; iter: 0; batch classifier loss: 0.469710; batch adversarial loss: 0.561051\n",
      "epoch 39; iter: 0; batch classifier loss: 0.510455; batch adversarial loss: 0.528029\n",
      "epoch 40; iter: 0; batch classifier loss: 0.344380; batch adversarial loss: 0.580532\n",
      "epoch 41; iter: 0; batch classifier loss: 0.392578; batch adversarial loss: 0.545067\n",
      "epoch 42; iter: 0; batch classifier loss: 0.440872; batch adversarial loss: 0.559739\n",
      "epoch 43; iter: 0; batch classifier loss: 0.429426; batch adversarial loss: 0.563125\n",
      "epoch 44; iter: 0; batch classifier loss: 0.464099; batch adversarial loss: 0.544316\n",
      "epoch 45; iter: 0; batch classifier loss: 0.459994; batch adversarial loss: 0.542302\n",
      "epoch 46; iter: 0; batch classifier loss: 0.468089; batch adversarial loss: 0.598991\n",
      "epoch 47; iter: 0; batch classifier loss: 0.501188; batch adversarial loss: 0.571110\n",
      "epoch 48; iter: 0; batch classifier loss: 0.429966; batch adversarial loss: 0.534828\n",
      "epoch 49; iter: 0; batch classifier loss: 0.374009; batch adversarial loss: 0.555514\n",
      "epoch 50; iter: 0; batch classifier loss: 0.372501; batch adversarial loss: 0.572922\n",
      "epoch 51; iter: 0; batch classifier loss: 0.389722; batch adversarial loss: 0.442515\n",
      "epoch 52; iter: 0; batch classifier loss: 0.393592; batch adversarial loss: 0.536290\n",
      "epoch 53; iter: 0; batch classifier loss: 0.424414; batch adversarial loss: 0.542213\n",
      "epoch 54; iter: 0; batch classifier loss: 0.497998; batch adversarial loss: 0.508758\n",
      "epoch 55; iter: 0; batch classifier loss: 0.430780; batch adversarial loss: 0.628736\n",
      "epoch 56; iter: 0; batch classifier loss: 0.377648; batch adversarial loss: 0.563181\n",
      "epoch 57; iter: 0; batch classifier loss: 0.393904; batch adversarial loss: 0.478975\n",
      "epoch 58; iter: 0; batch classifier loss: 0.406219; batch adversarial loss: 0.544643\n",
      "epoch 59; iter: 0; batch classifier loss: 0.435196; batch adversarial loss: 0.565215\n",
      "epoch 60; iter: 0; batch classifier loss: 0.348767; batch adversarial loss: 0.562883\n",
      "epoch 61; iter: 0; batch classifier loss: 0.387378; batch adversarial loss: 0.489204\n",
      "epoch 62; iter: 0; batch classifier loss: 0.347026; batch adversarial loss: 0.530018\n",
      "epoch 63; iter: 0; batch classifier loss: 0.376916; batch adversarial loss: 0.565577\n",
      "epoch 64; iter: 0; batch classifier loss: 0.325983; batch adversarial loss: 0.516410\n",
      "epoch 65; iter: 0; batch classifier loss: 0.448878; batch adversarial loss: 0.600415\n",
      "epoch 66; iter: 0; batch classifier loss: 0.447197; batch adversarial loss: 0.525558\n",
      "epoch 67; iter: 0; batch classifier loss: 0.460119; batch adversarial loss: 0.525951\n",
      "epoch 68; iter: 0; batch classifier loss: 0.378235; batch adversarial loss: 0.533138\n",
      "epoch 69; iter: 0; batch classifier loss: 0.365409; batch adversarial loss: 0.561050\n",
      "epoch 70; iter: 0; batch classifier loss: 0.432169; batch adversarial loss: 0.544152\n",
      "epoch 71; iter: 0; batch classifier loss: 0.390360; batch adversarial loss: 0.546399\n",
      "epoch 72; iter: 0; batch classifier loss: 0.371131; batch adversarial loss: 0.506546\n",
      "epoch 73; iter: 0; batch classifier loss: 0.379317; batch adversarial loss: 0.536927\n",
      "epoch 74; iter: 0; batch classifier loss: 0.329661; batch adversarial loss: 0.532415\n",
      "epoch 75; iter: 0; batch classifier loss: 0.461830; batch adversarial loss: 0.536356\n",
      "epoch 76; iter: 0; batch classifier loss: 0.412655; batch adversarial loss: 0.561403\n",
      "epoch 77; iter: 0; batch classifier loss: 0.367390; batch adversarial loss: 0.661835\n",
      "epoch 78; iter: 0; batch classifier loss: 0.368049; batch adversarial loss: 0.592108\n",
      "epoch 79; iter: 0; batch classifier loss: 0.443054; batch adversarial loss: 0.496020\n",
      "epoch 80; iter: 0; batch classifier loss: 0.462098; batch adversarial loss: 0.578428\n",
      "epoch 81; iter: 0; batch classifier loss: 0.360677; batch adversarial loss: 0.569440\n",
      "epoch 82; iter: 0; batch classifier loss: 0.352909; batch adversarial loss: 0.606495\n",
      "epoch 83; iter: 0; batch classifier loss: 0.457504; batch adversarial loss: 0.590042\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 84; iter: 0; batch classifier loss: 0.427732; batch adversarial loss: 0.497671\n",
      "epoch 85; iter: 0; batch classifier loss: 0.403436; batch adversarial loss: 0.526013\n",
      "epoch 86; iter: 0; batch classifier loss: 0.399886; batch adversarial loss: 0.562350\n",
      "epoch 87; iter: 0; batch classifier loss: 0.416447; batch adversarial loss: 0.481400\n",
      "epoch 88; iter: 0; batch classifier loss: 0.345359; batch adversarial loss: 0.542120\n",
      "epoch 89; iter: 0; batch classifier loss: 0.478758; batch adversarial loss: 0.522311\n",
      "epoch 90; iter: 0; batch classifier loss: 0.460562; batch adversarial loss: 0.553885\n",
      "epoch 91; iter: 0; batch classifier loss: 0.391706; batch adversarial loss: 0.580135\n",
      "epoch 92; iter: 0; batch classifier loss: 0.394299; batch adversarial loss: 0.570841\n",
      "epoch 93; iter: 0; batch classifier loss: 0.285643; batch adversarial loss: 0.517613\n",
      "epoch 94; iter: 0; batch classifier loss: 0.397824; batch adversarial loss: 0.539973\n",
      "epoch 95; iter: 0; batch classifier loss: 0.454673; batch adversarial loss: 0.585948\n",
      "epoch 96; iter: 0; batch classifier loss: 0.455694; batch adversarial loss: 0.583157\n",
      "epoch 97; iter: 0; batch classifier loss: 0.358435; batch adversarial loss: 0.556735\n",
      "epoch 98; iter: 0; batch classifier loss: 0.432800; batch adversarial loss: 0.529517\n",
      "epoch 99; iter: 0; batch classifier loss: 0.404762; batch adversarial loss: 0.488548\n",
      "epoch 100; iter: 0; batch classifier loss: 0.452100; batch adversarial loss: 0.554907\n",
      "epoch 101; iter: 0; batch classifier loss: 0.341711; batch adversarial loss: 0.584252\n",
      "epoch 102; iter: 0; batch classifier loss: 0.422482; batch adversarial loss: 0.459966\n",
      "epoch 103; iter: 0; batch classifier loss: 0.377864; batch adversarial loss: 0.557356\n",
      "epoch 104; iter: 0; batch classifier loss: 0.434508; batch adversarial loss: 0.506214\n",
      "epoch 105; iter: 0; batch classifier loss: 0.394547; batch adversarial loss: 0.557777\n",
      "epoch 106; iter: 0; batch classifier loss: 0.454526; batch adversarial loss: 0.618761\n",
      "epoch 107; iter: 0; batch classifier loss: 0.346779; batch adversarial loss: 0.584607\n",
      "epoch 108; iter: 0; batch classifier loss: 0.381286; batch adversarial loss: 0.514576\n",
      "epoch 109; iter: 0; batch classifier loss: 0.298224; batch adversarial loss: 0.561402\n",
      "epoch 110; iter: 0; batch classifier loss: 0.320139; batch adversarial loss: 0.550403\n",
      "epoch 111; iter: 0; batch classifier loss: 0.396972; batch adversarial loss: 0.548965\n",
      "epoch 112; iter: 0; batch classifier loss: 0.378683; batch adversarial loss: 0.558865\n",
      "epoch 113; iter: 0; batch classifier loss: 0.337060; batch adversarial loss: 0.667573\n",
      "epoch 114; iter: 0; batch classifier loss: 0.348856; batch adversarial loss: 0.551365\n",
      "epoch 115; iter: 0; batch classifier loss: 0.352014; batch adversarial loss: 0.561054\n",
      "epoch 116; iter: 0; batch classifier loss: 0.405622; batch adversarial loss: 0.542658\n",
      "epoch 117; iter: 0; batch classifier loss: 0.358515; batch adversarial loss: 0.526013\n",
      "epoch 118; iter: 0; batch classifier loss: 0.410141; batch adversarial loss: 0.553745\n",
      "epoch 119; iter: 0; batch classifier loss: 0.356083; batch adversarial loss: 0.479914\n",
      "epoch 120; iter: 0; batch classifier loss: 0.357854; batch adversarial loss: 0.455342\n",
      "epoch 121; iter: 0; batch classifier loss: 0.373257; batch adversarial loss: 0.525208\n",
      "epoch 122; iter: 0; batch classifier loss: 0.385406; batch adversarial loss: 0.533797\n",
      "epoch 123; iter: 0; batch classifier loss: 0.400644; batch adversarial loss: 0.574158\n",
      "epoch 124; iter: 0; batch classifier loss: 0.351284; batch adversarial loss: 0.579017\n",
      "epoch 125; iter: 0; batch classifier loss: 0.350927; batch adversarial loss: 0.588620\n",
      "epoch 126; iter: 0; batch classifier loss: 0.357583; batch adversarial loss: 0.562747\n",
      "epoch 127; iter: 0; batch classifier loss: 0.351037; batch adversarial loss: 0.537752\n",
      "epoch 128; iter: 0; batch classifier loss: 0.370758; batch adversarial loss: 0.592157\n",
      "epoch 129; iter: 0; batch classifier loss: 0.324335; batch adversarial loss: 0.508950\n",
      "epoch 130; iter: 0; batch classifier loss: 0.403039; batch adversarial loss: 0.581127\n",
      "epoch 131; iter: 0; batch classifier loss: 0.392061; batch adversarial loss: 0.479254\n",
      "epoch 132; iter: 0; batch classifier loss: 0.429675; batch adversarial loss: 0.554399\n",
      "epoch 133; iter: 0; batch classifier loss: 0.277969; batch adversarial loss: 0.532554\n",
      "epoch 134; iter: 0; batch classifier loss: 0.320649; batch adversarial loss: 0.555922\n",
      "epoch 135; iter: 0; batch classifier loss: 0.336268; batch adversarial loss: 0.563177\n",
      "epoch 136; iter: 0; batch classifier loss: 0.377201; batch adversarial loss: 0.524934\n",
      "epoch 137; iter: 0; batch classifier loss: 0.340527; batch adversarial loss: 0.590134\n",
      "epoch 138; iter: 0; batch classifier loss: 0.336295; batch adversarial loss: 0.454306\n",
      "epoch 139; iter: 0; batch classifier loss: 0.369725; batch adversarial loss: 0.573558\n",
      "epoch 140; iter: 0; batch classifier loss: 0.310672; batch adversarial loss: 0.471984\n",
      "epoch 141; iter: 0; batch classifier loss: 0.386858; batch adversarial loss: 0.545158\n",
      "epoch 142; iter: 0; batch classifier loss: 0.318645; batch adversarial loss: 0.538848\n",
      "epoch 143; iter: 0; batch classifier loss: 0.349541; batch adversarial loss: 0.569852\n",
      "epoch 144; iter: 0; batch classifier loss: 0.354740; batch adversarial loss: 0.568586\n",
      "epoch 145; iter: 0; batch classifier loss: 0.437168; batch adversarial loss: 0.524739\n",
      "epoch 146; iter: 0; batch classifier loss: 0.375041; batch adversarial loss: 0.609561\n",
      "epoch 147; iter: 0; batch classifier loss: 0.298288; batch adversarial loss: 0.504321\n",
      "epoch 148; iter: 0; batch classifier loss: 0.386198; batch adversarial loss: 0.516300\n",
      "epoch 149; iter: 0; batch classifier loss: 0.363668; batch adversarial loss: 0.539130\n",
      "epoch 150; iter: 0; batch classifier loss: 0.326171; batch adversarial loss: 0.589511\n",
      "epoch 151; iter: 0; batch classifier loss: 0.301664; batch adversarial loss: 0.581098\n",
      "epoch 152; iter: 0; batch classifier loss: 0.343749; batch adversarial loss: 0.524609\n",
      "epoch 153; iter: 0; batch classifier loss: 0.405851; batch adversarial loss: 0.558575\n",
      "epoch 154; iter: 0; batch classifier loss: 0.440821; batch adversarial loss: 0.545212\n",
      "epoch 155; iter: 0; batch classifier loss: 0.380575; batch adversarial loss: 0.557287\n",
      "epoch 156; iter: 0; batch classifier loss: 0.427836; batch adversarial loss: 0.490812\n",
      "epoch 157; iter: 0; batch classifier loss: 0.353419; batch adversarial loss: 0.551216\n",
      "epoch 158; iter: 0; batch classifier loss: 0.344279; batch adversarial loss: 0.515143\n",
      "epoch 159; iter: 0; batch classifier loss: 0.343052; batch adversarial loss: 0.579118\n",
      "epoch 160; iter: 0; batch classifier loss: 0.316174; batch adversarial loss: 0.544455\n",
      "epoch 161; iter: 0; batch classifier loss: 0.418807; batch adversarial loss: 0.562234\n",
      "epoch 162; iter: 0; batch classifier loss: 0.302248; batch adversarial loss: 0.520564\n",
      "epoch 163; iter: 0; batch classifier loss: 0.351095; batch adversarial loss: 0.559808\n",
      "epoch 164; iter: 0; batch classifier loss: 0.317298; batch adversarial loss: 0.536272\n",
      "epoch 165; iter: 0; batch classifier loss: 0.319286; batch adversarial loss: 0.566756\n",
      "epoch 166; iter: 0; batch classifier loss: 0.398638; batch adversarial loss: 0.556446\n",
      "epoch 167; iter: 0; batch classifier loss: 0.324468; batch adversarial loss: 0.526390\n",
      "epoch 168; iter: 0; batch classifier loss: 0.381957; batch adversarial loss: 0.513660\n",
      "epoch 169; iter: 0; batch classifier loss: 0.345390; batch adversarial loss: 0.509030\n",
      "epoch 170; iter: 0; batch classifier loss: 0.354870; batch adversarial loss: 0.600132\n",
      "epoch 171; iter: 0; batch classifier loss: 0.358352; batch adversarial loss: 0.516729\n",
      "epoch 172; iter: 0; batch classifier loss: 0.349944; batch adversarial loss: 0.524528\n",
      "epoch 173; iter: 0; batch classifier loss: 0.356252; batch adversarial loss: 0.536435\n",
      "epoch 174; iter: 0; batch classifier loss: 0.327033; batch adversarial loss: 0.491166\n",
      "epoch 175; iter: 0; batch classifier loss: 0.347438; batch adversarial loss: 0.551542\n",
      "epoch 176; iter: 0; batch classifier loss: 0.366144; batch adversarial loss: 0.478076\n",
      "epoch 177; iter: 0; batch classifier loss: 0.336908; batch adversarial loss: 0.541742\n",
      "epoch 178; iter: 0; batch classifier loss: 0.306522; batch adversarial loss: 0.523032\n",
      "epoch 179; iter: 0; batch classifier loss: 0.344370; batch adversarial loss: 0.490942\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 180; iter: 0; batch classifier loss: 0.326178; batch adversarial loss: 0.519506\n",
      "epoch 181; iter: 0; batch classifier loss: 0.322279; batch adversarial loss: 0.520734\n",
      "epoch 182; iter: 0; batch classifier loss: 0.284232; batch adversarial loss: 0.554067\n",
      "epoch 183; iter: 0; batch classifier loss: 0.429981; batch adversarial loss: 0.527830\n",
      "epoch 184; iter: 0; batch classifier loss: 0.342346; batch adversarial loss: 0.619213\n",
      "epoch 185; iter: 0; batch classifier loss: 0.386466; batch adversarial loss: 0.610015\n",
      "epoch 186; iter: 0; batch classifier loss: 0.367409; batch adversarial loss: 0.555285\n",
      "epoch 187; iter: 0; batch classifier loss: 0.442980; batch adversarial loss: 0.588649\n",
      "epoch 188; iter: 0; batch classifier loss: 0.336211; batch adversarial loss: 0.617252\n",
      "epoch 189; iter: 0; batch classifier loss: 0.377194; batch adversarial loss: 0.575194\n",
      "epoch 190; iter: 0; batch classifier loss: 0.331276; batch adversarial loss: 0.550408\n",
      "epoch 191; iter: 0; batch classifier loss: 0.269118; batch adversarial loss: 0.580422\n",
      "epoch 192; iter: 0; batch classifier loss: 0.426057; batch adversarial loss: 0.588415\n",
      "epoch 193; iter: 0; batch classifier loss: 0.395615; batch adversarial loss: 0.586022\n",
      "epoch 194; iter: 0; batch classifier loss: 0.375243; batch adversarial loss: 0.518597\n",
      "epoch 195; iter: 0; batch classifier loss: 0.435696; batch adversarial loss: 0.519429\n",
      "epoch 196; iter: 0; batch classifier loss: 0.254558; batch adversarial loss: 0.518939\n",
      "epoch 197; iter: 0; batch classifier loss: 0.258808; batch adversarial loss: 0.552458\n",
      "epoch 198; iter: 0; batch classifier loss: 0.424028; batch adversarial loss: 0.600353\n",
      "epoch 199; iter: 0; batch classifier loss: 0.341148; batch adversarial loss: 0.541455\n",
      "epoch 0; iter: 0; batch classifier loss: 0.685518; batch adversarial loss: 0.775695\n",
      "epoch 1; iter: 0; batch classifier loss: 0.718701; batch adversarial loss: 0.813768\n",
      "epoch 2; iter: 0; batch classifier loss: 0.683286; batch adversarial loss: 0.745168\n",
      "epoch 3; iter: 0; batch classifier loss: 0.650064; batch adversarial loss: 0.718108\n",
      "epoch 4; iter: 0; batch classifier loss: 0.559909; batch adversarial loss: 0.660538\n",
      "epoch 5; iter: 0; batch classifier loss: 0.595748; batch adversarial loss: 0.640739\n",
      "epoch 6; iter: 0; batch classifier loss: 0.554167; batch adversarial loss: 0.626955\n",
      "epoch 7; iter: 0; batch classifier loss: 0.578798; batch adversarial loss: 0.634224\n",
      "epoch 8; iter: 0; batch classifier loss: 0.537722; batch adversarial loss: 0.613520\n",
      "epoch 9; iter: 0; batch classifier loss: 0.527395; batch adversarial loss: 0.594674\n",
      "epoch 10; iter: 0; batch classifier loss: 0.504333; batch adversarial loss: 0.601190\n",
      "epoch 11; iter: 0; batch classifier loss: 0.542224; batch adversarial loss: 0.591836\n",
      "epoch 12; iter: 0; batch classifier loss: 0.576488; batch adversarial loss: 0.589429\n",
      "epoch 13; iter: 0; batch classifier loss: 0.587520; batch adversarial loss: 0.598979\n",
      "epoch 14; iter: 0; batch classifier loss: 0.505152; batch adversarial loss: 0.563921\n",
      "epoch 15; iter: 0; batch classifier loss: 0.527230; batch adversarial loss: 0.617085\n",
      "epoch 16; iter: 0; batch classifier loss: 0.521340; batch adversarial loss: 0.580420\n",
      "epoch 17; iter: 0; batch classifier loss: 0.605230; batch adversarial loss: 0.587832\n",
      "epoch 18; iter: 0; batch classifier loss: 0.485424; batch adversarial loss: 0.524242\n",
      "epoch 19; iter: 0; batch classifier loss: 0.495645; batch adversarial loss: 0.554561\n",
      "epoch 20; iter: 0; batch classifier loss: 0.463278; batch adversarial loss: 0.590234\n",
      "epoch 21; iter: 0; batch classifier loss: 0.527962; batch adversarial loss: 0.582907\n",
      "epoch 22; iter: 0; batch classifier loss: 0.421466; batch adversarial loss: 0.511761\n",
      "epoch 23; iter: 0; batch classifier loss: 0.527621; batch adversarial loss: 0.512891\n",
      "epoch 24; iter: 0; batch classifier loss: 0.554039; batch adversarial loss: 0.585231\n",
      "epoch 25; iter: 0; batch classifier loss: 0.507757; batch adversarial loss: 0.536807\n",
      "epoch 26; iter: 0; batch classifier loss: 0.450007; batch adversarial loss: 0.505450\n",
      "epoch 27; iter: 0; batch classifier loss: 0.519855; batch adversarial loss: 0.560735\n",
      "epoch 28; iter: 0; batch classifier loss: 0.502422; batch adversarial loss: 0.538988\n",
      "epoch 29; iter: 0; batch classifier loss: 0.495160; batch adversarial loss: 0.527940\n",
      "epoch 30; iter: 0; batch classifier loss: 0.527437; batch adversarial loss: 0.575070\n",
      "epoch 31; iter: 0; batch classifier loss: 0.477291; batch adversarial loss: 0.531099\n",
      "epoch 32; iter: 0; batch classifier loss: 0.513237; batch adversarial loss: 0.597862\n",
      "epoch 33; iter: 0; batch classifier loss: 0.587977; batch adversarial loss: 0.548551\n",
      "epoch 34; iter: 0; batch classifier loss: 0.458562; batch adversarial loss: 0.554528\n",
      "epoch 35; iter: 0; batch classifier loss: 0.502485; batch adversarial loss: 0.554174\n",
      "epoch 36; iter: 0; batch classifier loss: 0.476977; batch adversarial loss: 0.579375\n",
      "epoch 37; iter: 0; batch classifier loss: 0.450430; batch adversarial loss: 0.579373\n",
      "epoch 38; iter: 0; batch classifier loss: 0.500204; batch adversarial loss: 0.579568\n",
      "epoch 39; iter: 0; batch classifier loss: 0.338876; batch adversarial loss: 0.553750\n",
      "epoch 40; iter: 0; batch classifier loss: 0.436401; batch adversarial loss: 0.571031\n",
      "epoch 41; iter: 0; batch classifier loss: 0.513903; batch adversarial loss: 0.527452\n",
      "epoch 42; iter: 0; batch classifier loss: 0.491917; batch adversarial loss: 0.588677\n",
      "epoch 43; iter: 0; batch classifier loss: 0.471060; batch adversarial loss: 0.580000\n",
      "epoch 44; iter: 0; batch classifier loss: 0.518377; batch adversarial loss: 0.536084\n",
      "epoch 45; iter: 0; batch classifier loss: 0.374509; batch adversarial loss: 0.491458\n",
      "epoch 46; iter: 0; batch classifier loss: 0.486350; batch adversarial loss: 0.473597\n",
      "epoch 47; iter: 0; batch classifier loss: 0.391375; batch adversarial loss: 0.580667\n",
      "epoch 48; iter: 0; batch classifier loss: 0.405516; batch adversarial loss: 0.571509\n",
      "epoch 49; iter: 0; batch classifier loss: 0.477633; batch adversarial loss: 0.606417\n",
      "epoch 50; iter: 0; batch classifier loss: 0.421630; batch adversarial loss: 0.525814\n",
      "epoch 51; iter: 0; batch classifier loss: 0.426144; batch adversarial loss: 0.452176\n",
      "epoch 52; iter: 0; batch classifier loss: 0.510880; batch adversarial loss: 0.534078\n",
      "epoch 53; iter: 0; batch classifier loss: 0.445731; batch adversarial loss: 0.495468\n",
      "epoch 54; iter: 0; batch classifier loss: 0.373200; batch adversarial loss: 0.562765\n",
      "epoch 55; iter: 0; batch classifier loss: 0.406509; batch adversarial loss: 0.555695\n",
      "epoch 56; iter: 0; batch classifier loss: 0.405193; batch adversarial loss: 0.551592\n",
      "epoch 57; iter: 0; batch classifier loss: 0.422396; batch adversarial loss: 0.551928\n",
      "epoch 58; iter: 0; batch classifier loss: 0.392143; batch adversarial loss: 0.445972\n",
      "epoch 59; iter: 0; batch classifier loss: 0.483574; batch adversarial loss: 0.591516\n",
      "epoch 60; iter: 0; batch classifier loss: 0.403152; batch adversarial loss: 0.496170\n",
      "epoch 61; iter: 0; batch classifier loss: 0.452802; batch adversarial loss: 0.529674\n",
      "epoch 62; iter: 0; batch classifier loss: 0.388364; batch adversarial loss: 0.580605\n",
      "epoch 63; iter: 0; batch classifier loss: 0.460101; batch adversarial loss: 0.627705\n",
      "epoch 64; iter: 0; batch classifier loss: 0.484274; batch adversarial loss: 0.573675\n",
      "epoch 65; iter: 0; batch classifier loss: 0.436945; batch adversarial loss: 0.562436\n",
      "epoch 66; iter: 0; batch classifier loss: 0.380683; batch adversarial loss: 0.580114\n",
      "epoch 67; iter: 0; batch classifier loss: 0.381185; batch adversarial loss: 0.510198\n",
      "epoch 68; iter: 0; batch classifier loss: 0.377060; batch adversarial loss: 0.562197\n",
      "epoch 69; iter: 0; batch classifier loss: 0.356074; batch adversarial loss: 0.562621\n",
      "epoch 70; iter: 0; batch classifier loss: 0.343777; batch adversarial loss: 0.580180\n",
      "epoch 71; iter: 0; batch classifier loss: 0.393954; batch adversarial loss: 0.474023\n",
      "epoch 72; iter: 0; batch classifier loss: 0.463640; batch adversarial loss: 0.526948\n",
      "epoch 73; iter: 0; batch classifier loss: 0.411692; batch adversarial loss: 0.562939\n",
      "epoch 74; iter: 0; batch classifier loss: 0.345178; batch adversarial loss: 0.526435\n",
      "epoch 75; iter: 0; batch classifier loss: 0.388782; batch adversarial loss: 0.517676\n",
      "epoch 76; iter: 0; batch classifier loss: 0.379849; batch adversarial loss: 0.616682\n",
      "epoch 77; iter: 0; batch classifier loss: 0.372822; batch adversarial loss: 0.518154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 78; iter: 0; batch classifier loss: 0.415849; batch adversarial loss: 0.437567\n",
      "epoch 79; iter: 0; batch classifier loss: 0.444334; batch adversarial loss: 0.545221\n",
      "epoch 80; iter: 0; batch classifier loss: 0.341303; batch adversarial loss: 0.580946\n",
      "epoch 81; iter: 0; batch classifier loss: 0.419702; batch adversarial loss: 0.562679\n",
      "epoch 82; iter: 0; batch classifier loss: 0.345323; batch adversarial loss: 0.589638\n",
      "epoch 83; iter: 0; batch classifier loss: 0.463399; batch adversarial loss: 0.536227\n",
      "epoch 84; iter: 0; batch classifier loss: 0.328798; batch adversarial loss: 0.634267\n",
      "epoch 85; iter: 0; batch classifier loss: 0.471174; batch adversarial loss: 0.563258\n",
      "epoch 86; iter: 0; batch classifier loss: 0.389601; batch adversarial loss: 0.589812\n",
      "epoch 87; iter: 0; batch classifier loss: 0.424195; batch adversarial loss: 0.499750\n",
      "epoch 88; iter: 0; batch classifier loss: 0.435121; batch adversarial loss: 0.572523\n",
      "epoch 89; iter: 0; batch classifier loss: 0.374022; batch adversarial loss: 0.580452\n",
      "epoch 90; iter: 0; batch classifier loss: 0.363728; batch adversarial loss: 0.598270\n",
      "epoch 91; iter: 0; batch classifier loss: 0.391386; batch adversarial loss: 0.535416\n",
      "epoch 92; iter: 0; batch classifier loss: 0.402364; batch adversarial loss: 0.607120\n",
      "epoch 93; iter: 0; batch classifier loss: 0.475714; batch adversarial loss: 0.481409\n",
      "epoch 94; iter: 0; batch classifier loss: 0.396700; batch adversarial loss: 0.562935\n",
      "epoch 95; iter: 0; batch classifier loss: 0.452835; batch adversarial loss: 0.491001\n",
      "epoch 96; iter: 0; batch classifier loss: 0.361145; batch adversarial loss: 0.535354\n",
      "epoch 97; iter: 0; batch classifier loss: 0.351206; batch adversarial loss: 0.544745\n",
      "epoch 98; iter: 0; batch classifier loss: 0.399829; batch adversarial loss: 0.625858\n",
      "epoch 99; iter: 0; batch classifier loss: 0.318532; batch adversarial loss: 0.499659\n",
      "epoch 100; iter: 0; batch classifier loss: 0.340774; batch adversarial loss: 0.517512\n",
      "epoch 101; iter: 0; batch classifier loss: 0.367134; batch adversarial loss: 0.543893\n",
      "epoch 102; iter: 0; batch classifier loss: 0.398522; batch adversarial loss: 0.544775\n",
      "epoch 103; iter: 0; batch classifier loss: 0.433500; batch adversarial loss: 0.625376\n",
      "epoch 104; iter: 0; batch classifier loss: 0.417406; batch adversarial loss: 0.535994\n",
      "epoch 105; iter: 0; batch classifier loss: 0.463513; batch adversarial loss: 0.599069\n",
      "epoch 106; iter: 0; batch classifier loss: 0.442484; batch adversarial loss: 0.625943\n",
      "epoch 107; iter: 0; batch classifier loss: 0.376228; batch adversarial loss: 0.607994\n",
      "epoch 108; iter: 0; batch classifier loss: 0.351226; batch adversarial loss: 0.617185\n",
      "epoch 109; iter: 0; batch classifier loss: 0.416162; batch adversarial loss: 0.608198\n",
      "epoch 110; iter: 0; batch classifier loss: 0.388789; batch adversarial loss: 0.526753\n",
      "epoch 111; iter: 0; batch classifier loss: 0.464045; batch adversarial loss: 0.535412\n",
      "epoch 112; iter: 0; batch classifier loss: 0.383335; batch adversarial loss: 0.544605\n",
      "epoch 113; iter: 0; batch classifier loss: 0.405099; batch adversarial loss: 0.571557\n",
      "epoch 114; iter: 0; batch classifier loss: 0.372409; batch adversarial loss: 0.571386\n",
      "epoch 115; iter: 0; batch classifier loss: 0.394113; batch adversarial loss: 0.553771\n",
      "epoch 116; iter: 0; batch classifier loss: 0.376377; batch adversarial loss: 0.526541\n",
      "epoch 117; iter: 0; batch classifier loss: 0.408600; batch adversarial loss: 0.589393\n",
      "epoch 118; iter: 0; batch classifier loss: 0.358529; batch adversarial loss: 0.517637\n",
      "epoch 119; iter: 0; batch classifier loss: 0.441244; batch adversarial loss: 0.508402\n",
      "epoch 120; iter: 0; batch classifier loss: 0.271118; batch adversarial loss: 0.589867\n",
      "epoch 121; iter: 0; batch classifier loss: 0.423485; batch adversarial loss: 0.517845\n",
      "epoch 122; iter: 0; batch classifier loss: 0.409588; batch adversarial loss: 0.445269\n",
      "epoch 123; iter: 0; batch classifier loss: 0.369552; batch adversarial loss: 0.516998\n",
      "epoch 124; iter: 0; batch classifier loss: 0.436247; batch adversarial loss: 0.517713\n",
      "epoch 125; iter: 0; batch classifier loss: 0.368320; batch adversarial loss: 0.535866\n",
      "epoch 126; iter: 0; batch classifier loss: 0.402373; batch adversarial loss: 0.607638\n",
      "epoch 127; iter: 0; batch classifier loss: 0.336496; batch adversarial loss: 0.490382\n",
      "epoch 128; iter: 0; batch classifier loss: 0.415431; batch adversarial loss: 0.571529\n",
      "epoch 129; iter: 0; batch classifier loss: 0.325535; batch adversarial loss: 0.562806\n",
      "epoch 130; iter: 0; batch classifier loss: 0.424638; batch adversarial loss: 0.571757\n",
      "epoch 131; iter: 0; batch classifier loss: 0.408773; batch adversarial loss: 0.544705\n",
      "epoch 132; iter: 0; batch classifier loss: 0.389336; batch adversarial loss: 0.535239\n",
      "epoch 133; iter: 0; batch classifier loss: 0.338043; batch adversarial loss: 0.436491\n",
      "epoch 134; iter: 0; batch classifier loss: 0.366936; batch adversarial loss: 0.445704\n",
      "epoch 135; iter: 0; batch classifier loss: 0.331075; batch adversarial loss: 0.535299\n",
      "epoch 136; iter: 0; batch classifier loss: 0.315937; batch adversarial loss: 0.517529\n",
      "epoch 137; iter: 0; batch classifier loss: 0.401692; batch adversarial loss: 0.499663\n",
      "epoch 138; iter: 0; batch classifier loss: 0.453684; batch adversarial loss: 0.526513\n",
      "epoch 139; iter: 0; batch classifier loss: 0.400626; batch adversarial loss: 0.508482\n",
      "epoch 140; iter: 0; batch classifier loss: 0.293001; batch adversarial loss: 0.634695\n",
      "epoch 141; iter: 0; batch classifier loss: 0.437907; batch adversarial loss: 0.553578\n",
      "epoch 142; iter: 0; batch classifier loss: 0.275881; batch adversarial loss: 0.508897\n",
      "epoch 143; iter: 0; batch classifier loss: 0.435123; batch adversarial loss: 0.526645\n",
      "epoch 144; iter: 0; batch classifier loss: 0.402189; batch adversarial loss: 0.643727\n",
      "epoch 145; iter: 0; batch classifier loss: 0.419701; batch adversarial loss: 0.535699\n",
      "epoch 146; iter: 0; batch classifier loss: 0.389120; batch adversarial loss: 0.526379\n",
      "epoch 147; iter: 0; batch classifier loss: 0.295469; batch adversarial loss: 0.535688\n",
      "epoch 148; iter: 0; batch classifier loss: 0.341534; batch adversarial loss: 0.562475\n",
      "epoch 149; iter: 0; batch classifier loss: 0.418281; batch adversarial loss: 0.598686\n",
      "epoch 150; iter: 0; batch classifier loss: 0.427004; batch adversarial loss: 0.553428\n",
      "epoch 151; iter: 0; batch classifier loss: 0.359044; batch adversarial loss: 0.535644\n",
      "epoch 152; iter: 0; batch classifier loss: 0.376593; batch adversarial loss: 0.598583\n",
      "epoch 153; iter: 0; batch classifier loss: 0.318930; batch adversarial loss: 0.625692\n",
      "epoch 154; iter: 0; batch classifier loss: 0.350802; batch adversarial loss: 0.580404\n",
      "epoch 155; iter: 0; batch classifier loss: 0.317691; batch adversarial loss: 0.481877\n",
      "epoch 156; iter: 0; batch classifier loss: 0.407953; batch adversarial loss: 0.580803\n",
      "epoch 157; iter: 0; batch classifier loss: 0.333578; batch adversarial loss: 0.643725\n",
      "epoch 158; iter: 0; batch classifier loss: 0.336645; batch adversarial loss: 0.544558\n",
      "epoch 159; iter: 0; batch classifier loss: 0.349150; batch adversarial loss: 0.553746\n",
      "epoch 160; iter: 0; batch classifier loss: 0.442370; batch adversarial loss: 0.643685\n",
      "epoch 161; iter: 0; batch classifier loss: 0.299490; batch adversarial loss: 0.562733\n",
      "epoch 162; iter: 0; batch classifier loss: 0.397083; batch adversarial loss: 0.499166\n",
      "epoch 163; iter: 0; batch classifier loss: 0.499552; batch adversarial loss: 0.598994\n",
      "epoch 164; iter: 0; batch classifier loss: 0.352123; batch adversarial loss: 0.552701\n",
      "epoch 165; iter: 0; batch classifier loss: 0.295727; batch adversarial loss: 0.644433\n",
      "epoch 166; iter: 0; batch classifier loss: 0.325295; batch adversarial loss: 0.562664\n",
      "epoch 167; iter: 0; batch classifier loss: 0.365971; batch adversarial loss: 0.553594\n",
      "epoch 168; iter: 0; batch classifier loss: 0.378326; batch adversarial loss: 0.553726\n",
      "epoch 169; iter: 0; batch classifier loss: 0.447707; batch adversarial loss: 0.508941\n",
      "epoch 170; iter: 0; batch classifier loss: 0.355013; batch adversarial loss: 0.572091\n",
      "epoch 171; iter: 0; batch classifier loss: 0.388621; batch adversarial loss: 0.544822\n",
      "epoch 172; iter: 0; batch classifier loss: 0.433206; batch adversarial loss: 0.607799\n",
      "epoch 173; iter: 0; batch classifier loss: 0.391315; batch adversarial loss: 0.553910\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 174; iter: 0; batch classifier loss: 0.365301; batch adversarial loss: 0.589390\n",
      "epoch 175; iter: 0; batch classifier loss: 0.335795; batch adversarial loss: 0.571855\n",
      "epoch 176; iter: 0; batch classifier loss: 0.378018; batch adversarial loss: 0.598677\n",
      "epoch 177; iter: 0; batch classifier loss: 0.360830; batch adversarial loss: 0.598612\n",
      "epoch 178; iter: 0; batch classifier loss: 0.288011; batch adversarial loss: 0.508394\n",
      "epoch 179; iter: 0; batch classifier loss: 0.335547; batch adversarial loss: 0.589336\n",
      "epoch 180; iter: 0; batch classifier loss: 0.465071; batch adversarial loss: 0.562286\n",
      "epoch 181; iter: 0; batch classifier loss: 0.343362; batch adversarial loss: 0.571247\n",
      "epoch 182; iter: 0; batch classifier loss: 0.404482; batch adversarial loss: 0.616386\n",
      "epoch 183; iter: 0; batch classifier loss: 0.335842; batch adversarial loss: 0.598032\n",
      "epoch 184; iter: 0; batch classifier loss: 0.353170; batch adversarial loss: 0.544661\n",
      "epoch 185; iter: 0; batch classifier loss: 0.382682; batch adversarial loss: 0.526308\n",
      "epoch 186; iter: 0; batch classifier loss: 0.488643; batch adversarial loss: 0.490061\n",
      "epoch 187; iter: 0; batch classifier loss: 0.447793; batch adversarial loss: 0.463494\n",
      "epoch 188; iter: 0; batch classifier loss: 0.338142; batch adversarial loss: 0.544067\n",
      "epoch 189; iter: 0; batch classifier loss: 0.331214; batch adversarial loss: 0.563118\n",
      "epoch 190; iter: 0; batch classifier loss: 0.393986; batch adversarial loss: 0.562272\n",
      "epoch 191; iter: 0; batch classifier loss: 0.356170; batch adversarial loss: 0.463492\n",
      "epoch 192; iter: 0; batch classifier loss: 0.407266; batch adversarial loss: 0.598553\n",
      "epoch 193; iter: 0; batch classifier loss: 0.339377; batch adversarial loss: 0.517647\n",
      "epoch 194; iter: 0; batch classifier loss: 0.315805; batch adversarial loss: 0.517450\n",
      "epoch 195; iter: 0; batch classifier loss: 0.338126; batch adversarial loss: 0.562573\n",
      "epoch 196; iter: 0; batch classifier loss: 0.363609; batch adversarial loss: 0.590092\n",
      "epoch 197; iter: 0; batch classifier loss: 0.422870; batch adversarial loss: 0.589845\n",
      "epoch 198; iter: 0; batch classifier loss: 0.363778; batch adversarial loss: 0.508640\n",
      "epoch 199; iter: 0; batch classifier loss: 0.306531; batch adversarial loss: 0.625246\n",
      "epoch 0; iter: 0; batch classifier loss: 0.815360; batch adversarial loss: 0.803622\n",
      "epoch 1; iter: 0; batch classifier loss: 0.716546; batch adversarial loss: 0.799848\n",
      "epoch 2; iter: 0; batch classifier loss: 0.723985; batch adversarial loss: 0.751207\n",
      "epoch 3; iter: 0; batch classifier loss: 0.656655; batch adversarial loss: 0.689365\n",
      "epoch 4; iter: 0; batch classifier loss: 0.545137; batch adversarial loss: 0.647858\n",
      "epoch 5; iter: 0; batch classifier loss: 0.560027; batch adversarial loss: 0.624036\n",
      "epoch 6; iter: 0; batch classifier loss: 0.492703; batch adversarial loss: 0.624602\n",
      "epoch 7; iter: 0; batch classifier loss: 0.588068; batch adversarial loss: 0.604714\n",
      "epoch 8; iter: 0; batch classifier loss: 0.553277; batch adversarial loss: 0.581731\n",
      "epoch 9; iter: 0; batch classifier loss: 0.543192; batch adversarial loss: 0.588859\n",
      "epoch 10; iter: 0; batch classifier loss: 0.494352; batch adversarial loss: 0.613266\n",
      "epoch 11; iter: 0; batch classifier loss: 0.565154; batch adversarial loss: 0.562671\n",
      "epoch 12; iter: 0; batch classifier loss: 0.486457; batch adversarial loss: 0.583159\n",
      "epoch 13; iter: 0; batch classifier loss: 0.495803; batch adversarial loss: 0.566060\n",
      "epoch 14; iter: 0; batch classifier loss: 0.394423; batch adversarial loss: 0.564932\n",
      "epoch 15; iter: 0; batch classifier loss: 0.563035; batch adversarial loss: 0.523221\n",
      "epoch 16; iter: 0; batch classifier loss: 0.507454; batch adversarial loss: 0.565362\n",
      "epoch 17; iter: 0; batch classifier loss: 0.497066; batch adversarial loss: 0.600673\n",
      "epoch 18; iter: 0; batch classifier loss: 0.499231; batch adversarial loss: 0.546846\n",
      "epoch 19; iter: 0; batch classifier loss: 0.539198; batch adversarial loss: 0.596461\n",
      "epoch 20; iter: 0; batch classifier loss: 0.436780; batch adversarial loss: 0.523081\n",
      "epoch 21; iter: 0; batch classifier loss: 0.475996; batch adversarial loss: 0.559202\n",
      "epoch 22; iter: 0; batch classifier loss: 0.511513; batch adversarial loss: 0.591968\n",
      "epoch 23; iter: 0; batch classifier loss: 0.471019; batch adversarial loss: 0.560616\n",
      "epoch 24; iter: 0; batch classifier loss: 0.482592; batch adversarial loss: 0.538502\n",
      "epoch 25; iter: 0; batch classifier loss: 0.480959; batch adversarial loss: 0.518983\n",
      "epoch 26; iter: 0; batch classifier loss: 0.430210; batch adversarial loss: 0.550714\n",
      "epoch 27; iter: 0; batch classifier loss: 0.436704; batch adversarial loss: 0.557944\n",
      "epoch 28; iter: 0; batch classifier loss: 0.520468; batch adversarial loss: 0.576669\n",
      "epoch 29; iter: 0; batch classifier loss: 0.387666; batch adversarial loss: 0.543614\n",
      "epoch 30; iter: 0; batch classifier loss: 0.416733; batch adversarial loss: 0.547017\n",
      "epoch 31; iter: 0; batch classifier loss: 0.460984; batch adversarial loss: 0.534284\n",
      "epoch 32; iter: 0; batch classifier loss: 0.454094; batch adversarial loss: 0.550695\n",
      "epoch 33; iter: 0; batch classifier loss: 0.396742; batch adversarial loss: 0.609991\n",
      "epoch 34; iter: 0; batch classifier loss: 0.459719; batch adversarial loss: 0.515384\n",
      "epoch 35; iter: 0; batch classifier loss: 0.402215; batch adversarial loss: 0.521755\n",
      "epoch 36; iter: 0; batch classifier loss: 0.461248; batch adversarial loss: 0.580837\n",
      "epoch 37; iter: 0; batch classifier loss: 0.457637; batch adversarial loss: 0.520094\n",
      "epoch 38; iter: 0; batch classifier loss: 0.418614; batch adversarial loss: 0.545534\n",
      "epoch 39; iter: 0; batch classifier loss: 0.416337; batch adversarial loss: 0.581083\n",
      "epoch 40; iter: 0; batch classifier loss: 0.449971; batch adversarial loss: 0.571843\n",
      "epoch 41; iter: 0; batch classifier loss: 0.459685; batch adversarial loss: 0.545048\n",
      "epoch 42; iter: 0; batch classifier loss: 0.357268; batch adversarial loss: 0.544692\n",
      "epoch 43; iter: 0; batch classifier loss: 0.426057; batch adversarial loss: 0.580243\n",
      "epoch 44; iter: 0; batch classifier loss: 0.433468; batch adversarial loss: 0.526715\n",
      "epoch 45; iter: 0; batch classifier loss: 0.427178; batch adversarial loss: 0.562601\n",
      "epoch 46; iter: 0; batch classifier loss: 0.482682; batch adversarial loss: 0.463155\n",
      "epoch 47; iter: 0; batch classifier loss: 0.428493; batch adversarial loss: 0.590024\n",
      "epoch 48; iter: 0; batch classifier loss: 0.405543; batch adversarial loss: 0.535613\n",
      "epoch 49; iter: 0; batch classifier loss: 0.465151; batch adversarial loss: 0.572182\n",
      "epoch 50; iter: 0; batch classifier loss: 0.353920; batch adversarial loss: 0.517204\n",
      "epoch 51; iter: 0; batch classifier loss: 0.469595; batch adversarial loss: 0.425624\n",
      "epoch 52; iter: 0; batch classifier loss: 0.424146; batch adversarial loss: 0.590610\n",
      "epoch 53; iter: 0; batch classifier loss: 0.419363; batch adversarial loss: 0.544923\n",
      "epoch 54; iter: 0; batch classifier loss: 0.474026; batch adversarial loss: 0.498026\n",
      "epoch 55; iter: 0; batch classifier loss: 0.385983; batch adversarial loss: 0.544281\n",
      "epoch 56; iter: 0; batch classifier loss: 0.392509; batch adversarial loss: 0.562976\n",
      "epoch 57; iter: 0; batch classifier loss: 0.414202; batch adversarial loss: 0.535028\n",
      "epoch 58; iter: 0; batch classifier loss: 0.400541; batch adversarial loss: 0.479411\n",
      "epoch 59; iter: 0; batch classifier loss: 0.379668; batch adversarial loss: 0.563448\n",
      "epoch 60; iter: 0; batch classifier loss: 0.489311; batch adversarial loss: 0.498069\n",
      "epoch 61; iter: 0; batch classifier loss: 0.424943; batch adversarial loss: 0.507660\n",
      "epoch 62; iter: 0; batch classifier loss: 0.363854; batch adversarial loss: 0.535278\n",
      "epoch 63; iter: 0; batch classifier loss: 0.367415; batch adversarial loss: 0.563669\n",
      "epoch 64; iter: 0; batch classifier loss: 0.389861; batch adversarial loss: 0.581822\n",
      "epoch 65; iter: 0; batch classifier loss: 0.410851; batch adversarial loss: 0.525828\n",
      "epoch 66; iter: 0; batch classifier loss: 0.416105; batch adversarial loss: 0.506838\n",
      "epoch 67; iter: 0; batch classifier loss: 0.379758; batch adversarial loss: 0.563404\n",
      "epoch 68; iter: 0; batch classifier loss: 0.373005; batch adversarial loss: 0.636874\n",
      "epoch 69; iter: 0; batch classifier loss: 0.350938; batch adversarial loss: 0.590628\n",
      "epoch 70; iter: 0; batch classifier loss: 0.378305; batch adversarial loss: 0.545219\n",
      "epoch 71; iter: 0; batch classifier loss: 0.376066; batch adversarial loss: 0.526332\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 72; iter: 0; batch classifier loss: 0.434554; batch adversarial loss: 0.581354\n",
      "epoch 73; iter: 0; batch classifier loss: 0.429651; batch adversarial loss: 0.582634\n",
      "epoch 74; iter: 0; batch classifier loss: 0.310619; batch adversarial loss: 0.553576\n",
      "epoch 75; iter: 0; batch classifier loss: 0.362229; batch adversarial loss: 0.433672\n",
      "epoch 76; iter: 0; batch classifier loss: 0.397640; batch adversarial loss: 0.553274\n",
      "epoch 77; iter: 0; batch classifier loss: 0.381005; batch adversarial loss: 0.562560\n",
      "epoch 78; iter: 0; batch classifier loss: 0.410497; batch adversarial loss: 0.572245\n",
      "epoch 79; iter: 0; batch classifier loss: 0.357304; batch adversarial loss: 0.619500\n",
      "epoch 80; iter: 0; batch classifier loss: 0.393673; batch adversarial loss: 0.589492\n",
      "epoch 81; iter: 0; batch classifier loss: 0.407527; batch adversarial loss: 0.488624\n",
      "epoch 82; iter: 0; batch classifier loss: 0.458426; batch adversarial loss: 0.554437\n",
      "epoch 83; iter: 0; batch classifier loss: 0.334738; batch adversarial loss: 0.564547\n",
      "epoch 84; iter: 0; batch classifier loss: 0.372036; batch adversarial loss: 0.544976\n",
      "epoch 85; iter: 0; batch classifier loss: 0.456657; batch adversarial loss: 0.506028\n",
      "epoch 86; iter: 0; batch classifier loss: 0.433024; batch adversarial loss: 0.573044\n",
      "epoch 87; iter: 0; batch classifier loss: 0.405598; batch adversarial loss: 0.506577\n",
      "epoch 88; iter: 0; batch classifier loss: 0.402859; batch adversarial loss: 0.506873\n",
      "epoch 89; iter: 0; batch classifier loss: 0.362125; batch adversarial loss: 0.535747\n",
      "epoch 90; iter: 0; batch classifier loss: 0.377499; batch adversarial loss: 0.535699\n",
      "epoch 91; iter: 0; batch classifier loss: 0.387680; batch adversarial loss: 0.508130\n",
      "epoch 92; iter: 0; batch classifier loss: 0.328791; batch adversarial loss: 0.553469\n",
      "epoch 93; iter: 0; batch classifier loss: 0.385448; batch adversarial loss: 0.589780\n",
      "epoch 94; iter: 0; batch classifier loss: 0.353657; batch adversarial loss: 0.525568\n",
      "epoch 95; iter: 0; batch classifier loss: 0.372344; batch adversarial loss: 0.573184\n",
      "epoch 96; iter: 0; batch classifier loss: 0.312379; batch adversarial loss: 0.433083\n",
      "epoch 97; iter: 0; batch classifier loss: 0.308306; batch adversarial loss: 0.489225\n",
      "epoch 98; iter: 0; batch classifier loss: 0.413660; batch adversarial loss: 0.497927\n",
      "epoch 99; iter: 0; batch classifier loss: 0.327196; batch adversarial loss: 0.533608\n",
      "epoch 100; iter: 0; batch classifier loss: 0.455025; batch adversarial loss: 0.535731\n",
      "epoch 101; iter: 0; batch classifier loss: 0.364151; batch adversarial loss: 0.515882\n",
      "epoch 102; iter: 0; batch classifier loss: 0.306388; batch adversarial loss: 0.637792\n",
      "epoch 103; iter: 0; batch classifier loss: 0.423080; batch adversarial loss: 0.544857\n",
      "epoch 104; iter: 0; batch classifier loss: 0.426588; batch adversarial loss: 0.563270\n",
      "epoch 105; iter: 0; batch classifier loss: 0.337887; batch adversarial loss: 0.514780\n",
      "epoch 106; iter: 0; batch classifier loss: 0.350192; batch adversarial loss: 0.626662\n",
      "epoch 107; iter: 0; batch classifier loss: 0.328683; batch adversarial loss: 0.554794\n",
      "epoch 108; iter: 0; batch classifier loss: 0.385836; batch adversarial loss: 0.554260\n",
      "epoch 109; iter: 0; batch classifier loss: 0.345332; batch adversarial loss: 0.527747\n",
      "epoch 110; iter: 0; batch classifier loss: 0.397034; batch adversarial loss: 0.581930\n",
      "epoch 111; iter: 0; batch classifier loss: 0.446969; batch adversarial loss: 0.517670\n",
      "epoch 112; iter: 0; batch classifier loss: 0.409571; batch adversarial loss: 0.599325\n",
      "epoch 113; iter: 0; batch classifier loss: 0.346070; batch adversarial loss: 0.582727\n",
      "epoch 114; iter: 0; batch classifier loss: 0.367467; batch adversarial loss: 0.581075\n",
      "epoch 115; iter: 0; batch classifier loss: 0.333244; batch adversarial loss: 0.544642\n",
      "epoch 116; iter: 0; batch classifier loss: 0.340369; batch adversarial loss: 0.525360\n",
      "epoch 117; iter: 0; batch classifier loss: 0.476640; batch adversarial loss: 0.627066\n",
      "epoch 118; iter: 0; batch classifier loss: 0.416985; batch adversarial loss: 0.479865\n",
      "epoch 119; iter: 0; batch classifier loss: 0.392818; batch adversarial loss: 0.544541\n",
      "epoch 120; iter: 0; batch classifier loss: 0.448866; batch adversarial loss: 0.581396\n",
      "epoch 121; iter: 0; batch classifier loss: 0.381858; batch adversarial loss: 0.553947\n",
      "epoch 122; iter: 0; batch classifier loss: 0.349304; batch adversarial loss: 0.533957\n",
      "epoch 123; iter: 0; batch classifier loss: 0.347364; batch adversarial loss: 0.496468\n",
      "epoch 124; iter: 0; batch classifier loss: 0.360751; batch adversarial loss: 0.591380\n",
      "epoch 125; iter: 0; batch classifier loss: 0.329533; batch adversarial loss: 0.544832\n",
      "epoch 126; iter: 0; batch classifier loss: 0.391978; batch adversarial loss: 0.490293\n",
      "epoch 127; iter: 0; batch classifier loss: 0.364531; batch adversarial loss: 0.470717\n",
      "epoch 128; iter: 0; batch classifier loss: 0.332898; batch adversarial loss: 0.534829\n",
      "epoch 129; iter: 0; batch classifier loss: 0.464017; batch adversarial loss: 0.478828\n",
      "epoch 130; iter: 0; batch classifier loss: 0.396755; batch adversarial loss: 0.572445\n",
      "epoch 131; iter: 0; batch classifier loss: 0.420781; batch adversarial loss: 0.535663\n",
      "epoch 132; iter: 0; batch classifier loss: 0.414135; batch adversarial loss: 0.563285\n",
      "epoch 133; iter: 0; batch classifier loss: 0.341124; batch adversarial loss: 0.517375\n",
      "epoch 134; iter: 0; batch classifier loss: 0.332353; batch adversarial loss: 0.489491\n",
      "epoch 135; iter: 0; batch classifier loss: 0.314749; batch adversarial loss: 0.590725\n",
      "epoch 136; iter: 0; batch classifier loss: 0.330264; batch adversarial loss: 0.544519\n",
      "epoch 137; iter: 0; batch classifier loss: 0.372286; batch adversarial loss: 0.506797\n",
      "epoch 138; iter: 0; batch classifier loss: 0.375293; batch adversarial loss: 0.506255\n",
      "epoch 139; iter: 0; batch classifier loss: 0.360163; batch adversarial loss: 0.544471\n",
      "epoch 140; iter: 0; batch classifier loss: 0.333361; batch adversarial loss: 0.536697\n",
      "epoch 141; iter: 0; batch classifier loss: 0.397773; batch adversarial loss: 0.561605\n",
      "epoch 142; iter: 0; batch classifier loss: 0.330056; batch adversarial loss: 0.524859\n",
      "epoch 143; iter: 0; batch classifier loss: 0.327576; batch adversarial loss: 0.553960\n",
      "epoch 144; iter: 0; batch classifier loss: 0.324922; batch adversarial loss: 0.563738\n",
      "epoch 145; iter: 0; batch classifier loss: 0.331784; batch adversarial loss: 0.570973\n",
      "epoch 146; iter: 0; batch classifier loss: 0.343717; batch adversarial loss: 0.617506\n",
      "epoch 147; iter: 0; batch classifier loss: 0.382251; batch adversarial loss: 0.480689\n",
      "epoch 148; iter: 0; batch classifier loss: 0.338613; batch adversarial loss: 0.525350\n",
      "epoch 149; iter: 0; batch classifier loss: 0.387273; batch adversarial loss: 0.524980\n",
      "epoch 150; iter: 0; batch classifier loss: 0.446459; batch adversarial loss: 0.561196\n",
      "epoch 151; iter: 0; batch classifier loss: 0.389706; batch adversarial loss: 0.489413\n",
      "epoch 152; iter: 0; batch classifier loss: 0.396516; batch adversarial loss: 0.544387\n",
      "epoch 153; iter: 0; batch classifier loss: 0.306319; batch adversarial loss: 0.471505\n",
      "epoch 154; iter: 0; batch classifier loss: 0.337692; batch adversarial loss: 0.610579\n",
      "epoch 155; iter: 0; batch classifier loss: 0.374376; batch adversarial loss: 0.619961\n",
      "epoch 156; iter: 0; batch classifier loss: 0.341199; batch adversarial loss: 0.562521\n",
      "epoch 157; iter: 0; batch classifier loss: 0.282891; batch adversarial loss: 0.544131\n",
      "epoch 158; iter: 0; batch classifier loss: 0.399775; batch adversarial loss: 0.534483\n",
      "epoch 159; iter: 0; batch classifier loss: 0.371813; batch adversarial loss: 0.561035\n",
      "epoch 160; iter: 0; batch classifier loss: 0.344206; batch adversarial loss: 0.461787\n",
      "epoch 161; iter: 0; batch classifier loss: 0.304392; batch adversarial loss: 0.591617\n",
      "epoch 162; iter: 0; batch classifier loss: 0.410595; batch adversarial loss: 0.515705\n",
      "epoch 163; iter: 0; batch classifier loss: 0.402694; batch adversarial loss: 0.561447\n",
      "epoch 164; iter: 0; batch classifier loss: 0.340335; batch adversarial loss: 0.536189\n",
      "epoch 165; iter: 0; batch classifier loss: 0.446192; batch adversarial loss: 0.505780\n",
      "epoch 166; iter: 0; batch classifier loss: 0.434818; batch adversarial loss: 0.536115\n",
      "epoch 167; iter: 0; batch classifier loss: 0.319489; batch adversarial loss: 0.462766\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 168; iter: 0; batch classifier loss: 0.359463; batch adversarial loss: 0.562643\n",
      "epoch 169; iter: 0; batch classifier loss: 0.307918; batch adversarial loss: 0.451329\n",
      "epoch 170; iter: 0; batch classifier loss: 0.285835; batch adversarial loss: 0.563729\n",
      "epoch 171; iter: 0; batch classifier loss: 0.414064; batch adversarial loss: 0.525216\n",
      "epoch 172; iter: 0; batch classifier loss: 0.356554; batch adversarial loss: 0.497786\n",
      "epoch 173; iter: 0; batch classifier loss: 0.383900; batch adversarial loss: 0.543988\n",
      "epoch 174; iter: 0; batch classifier loss: 0.369770; batch adversarial loss: 0.565567\n",
      "epoch 175; iter: 0; batch classifier loss: 0.327382; batch adversarial loss: 0.469815\n",
      "epoch 176; iter: 0; batch classifier loss: 0.344023; batch adversarial loss: 0.524879\n",
      "epoch 177; iter: 0; batch classifier loss: 0.341849; batch adversarial loss: 0.553963\n",
      "epoch 178; iter: 0; batch classifier loss: 0.340487; batch adversarial loss: 0.507190\n",
      "epoch 179; iter: 0; batch classifier loss: 0.345888; batch adversarial loss: 0.506787\n",
      "epoch 180; iter: 0; batch classifier loss: 0.335333; batch adversarial loss: 0.543920\n",
      "epoch 181; iter: 0; batch classifier loss: 0.394285; batch adversarial loss: 0.536743\n",
      "epoch 182; iter: 0; batch classifier loss: 0.386757; batch adversarial loss: 0.554660\n",
      "epoch 183; iter: 0; batch classifier loss: 0.294040; batch adversarial loss: 0.552929\n",
      "epoch 184; iter: 0; batch classifier loss: 0.332379; batch adversarial loss: 0.553608\n",
      "epoch 185; iter: 0; batch classifier loss: 0.356302; batch adversarial loss: 0.545804\n",
      "epoch 186; iter: 0; batch classifier loss: 0.357151; batch adversarial loss: 0.619147\n",
      "epoch 187; iter: 0; batch classifier loss: 0.286020; batch adversarial loss: 0.543474\n",
      "epoch 188; iter: 0; batch classifier loss: 0.323217; batch adversarial loss: 0.589435\n",
      "epoch 189; iter: 0; batch classifier loss: 0.393114; batch adversarial loss: 0.553828\n",
      "epoch 190; iter: 0; batch classifier loss: 0.273504; batch adversarial loss: 0.534630\n",
      "epoch 191; iter: 0; batch classifier loss: 0.314023; batch adversarial loss: 0.469427\n",
      "epoch 192; iter: 0; batch classifier loss: 0.326802; batch adversarial loss: 0.600422\n",
      "epoch 193; iter: 0; batch classifier loss: 0.375737; batch adversarial loss: 0.536121\n",
      "epoch 194; iter: 0; batch classifier loss: 0.330651; batch adversarial loss: 0.692868\n",
      "epoch 195; iter: 0; batch classifier loss: 0.378151; batch adversarial loss: 0.509192\n",
      "epoch 196; iter: 0; batch classifier loss: 0.496697; batch adversarial loss: 0.563747\n",
      "epoch 197; iter: 0; batch classifier loss: 0.320261; batch adversarial loss: 0.583360\n",
      "epoch 198; iter: 0; batch classifier loss: 0.431365; batch adversarial loss: 0.468357\n",
      "epoch 199; iter: 0; batch classifier loss: 0.431436; batch adversarial loss: 0.507821\n",
      "epoch 0; iter: 0; batch classifier loss: 0.812796; batch adversarial loss: 0.681077\n",
      "epoch 1; iter: 0; batch classifier loss: 0.629623; batch adversarial loss: 0.673129\n",
      "epoch 2; iter: 0; batch classifier loss: 0.609507; batch adversarial loss: 0.650178\n",
      "epoch 3; iter: 0; batch classifier loss: 0.584131; batch adversarial loss: 0.631607\n",
      "epoch 4; iter: 0; batch classifier loss: 0.561807; batch adversarial loss: 0.622315\n",
      "epoch 5; iter: 0; batch classifier loss: 0.522921; batch adversarial loss: 0.633478\n",
      "epoch 6; iter: 0; batch classifier loss: 0.608235; batch adversarial loss: 0.643692\n",
      "epoch 7; iter: 0; batch classifier loss: 0.502137; batch adversarial loss: 0.615485\n",
      "epoch 8; iter: 0; batch classifier loss: 0.539917; batch adversarial loss: 0.612750\n",
      "epoch 9; iter: 0; batch classifier loss: 0.579088; batch adversarial loss: 0.595506\n",
      "epoch 10; iter: 0; batch classifier loss: 0.535424; batch adversarial loss: 0.542576\n",
      "epoch 11; iter: 0; batch classifier loss: 0.486539; batch adversarial loss: 0.592088\n",
      "epoch 12; iter: 0; batch classifier loss: 0.540510; batch adversarial loss: 0.538230\n",
      "epoch 13; iter: 0; batch classifier loss: 0.500370; batch adversarial loss: 0.598884\n",
      "epoch 14; iter: 0; batch classifier loss: 0.485390; batch adversarial loss: 0.630672\n",
      "epoch 15; iter: 0; batch classifier loss: 0.436229; batch adversarial loss: 0.580224\n",
      "epoch 16; iter: 0; batch classifier loss: 0.515866; batch adversarial loss: 0.525175\n",
      "epoch 17; iter: 0; batch classifier loss: 0.577722; batch adversarial loss: 0.563291\n",
      "epoch 18; iter: 0; batch classifier loss: 0.506215; batch adversarial loss: 0.590593\n",
      "epoch 19; iter: 0; batch classifier loss: 0.582952; batch adversarial loss: 0.516352\n",
      "epoch 20; iter: 0; batch classifier loss: 0.488301; batch adversarial loss: 0.566628\n",
      "epoch 21; iter: 0; batch classifier loss: 0.546421; batch adversarial loss: 0.505022\n",
      "epoch 22; iter: 0; batch classifier loss: 0.468412; batch adversarial loss: 0.526258\n",
      "epoch 23; iter: 0; batch classifier loss: 0.420742; batch adversarial loss: 0.593591\n",
      "epoch 24; iter: 0; batch classifier loss: 0.504530; batch adversarial loss: 0.620492\n",
      "epoch 25; iter: 0; batch classifier loss: 0.449553; batch adversarial loss: 0.532778\n",
      "epoch 26; iter: 0; batch classifier loss: 0.472374; batch adversarial loss: 0.579480\n",
      "epoch 27; iter: 0; batch classifier loss: 0.503693; batch adversarial loss: 0.480387\n",
      "epoch 28; iter: 0; batch classifier loss: 0.475155; batch adversarial loss: 0.594436\n",
      "epoch 29; iter: 0; batch classifier loss: 0.409456; batch adversarial loss: 0.556088\n",
      "epoch 30; iter: 0; batch classifier loss: 0.503840; batch adversarial loss: 0.582223\n",
      "epoch 31; iter: 0; batch classifier loss: 0.456059; batch adversarial loss: 0.576844\n",
      "epoch 32; iter: 0; batch classifier loss: 0.520204; batch adversarial loss: 0.507573\n",
      "epoch 33; iter: 0; batch classifier loss: 0.507302; batch adversarial loss: 0.542396\n",
      "epoch 34; iter: 0; batch classifier loss: 0.429114; batch adversarial loss: 0.605569\n",
      "epoch 35; iter: 0; batch classifier loss: 0.421098; batch adversarial loss: 0.530632\n",
      "epoch 36; iter: 0; batch classifier loss: 0.498397; batch adversarial loss: 0.554643\n",
      "epoch 37; iter: 0; batch classifier loss: 0.447097; batch adversarial loss: 0.596159\n",
      "epoch 38; iter: 0; batch classifier loss: 0.424471; batch adversarial loss: 0.536539\n",
      "epoch 39; iter: 0; batch classifier loss: 0.520296; batch adversarial loss: 0.605242\n",
      "epoch 40; iter: 0; batch classifier loss: 0.459975; batch adversarial loss: 0.518642\n",
      "epoch 41; iter: 0; batch classifier loss: 0.427438; batch adversarial loss: 0.623383\n",
      "epoch 42; iter: 0; batch classifier loss: 0.484938; batch adversarial loss: 0.508654\n",
      "epoch 43; iter: 0; batch classifier loss: 0.426847; batch adversarial loss: 0.517673\n",
      "epoch 44; iter: 0; batch classifier loss: 0.440023; batch adversarial loss: 0.500502\n",
      "epoch 45; iter: 0; batch classifier loss: 0.445441; batch adversarial loss: 0.562701\n",
      "epoch 46; iter: 0; batch classifier loss: 0.437393; batch adversarial loss: 0.544499\n",
      "epoch 47; iter: 0; batch classifier loss: 0.456237; batch adversarial loss: 0.535806\n",
      "epoch 48; iter: 0; batch classifier loss: 0.420375; batch adversarial loss: 0.580156\n",
      "epoch 49; iter: 0; batch classifier loss: 0.399399; batch adversarial loss: 0.455805\n",
      "epoch 50; iter: 0; batch classifier loss: 0.460578; batch adversarial loss: 0.639972\n",
      "epoch 51; iter: 0; batch classifier loss: 0.413023; batch adversarial loss: 0.561438\n",
      "epoch 52; iter: 0; batch classifier loss: 0.373054; batch adversarial loss: 0.535093\n",
      "epoch 53; iter: 0; batch classifier loss: 0.438309; batch adversarial loss: 0.543340\n",
      "epoch 54; iter: 0; batch classifier loss: 0.449207; batch adversarial loss: 0.544203\n",
      "epoch 55; iter: 0; batch classifier loss: 0.430504; batch adversarial loss: 0.472180\n",
      "epoch 56; iter: 0; batch classifier loss: 0.411003; batch adversarial loss: 0.517817\n",
      "epoch 57; iter: 0; batch classifier loss: 0.442275; batch adversarial loss: 0.572240\n",
      "epoch 58; iter: 0; batch classifier loss: 0.460577; batch adversarial loss: 0.619241\n",
      "epoch 59; iter: 0; batch classifier loss: 0.427603; batch adversarial loss: 0.498219\n",
      "epoch 60; iter: 0; batch classifier loss: 0.396953; batch adversarial loss: 0.553705\n",
      "epoch 61; iter: 0; batch classifier loss: 0.428811; batch adversarial loss: 0.460620\n",
      "epoch 62; iter: 0; batch classifier loss: 0.411512; batch adversarial loss: 0.535963\n",
      "epoch 63; iter: 0; batch classifier loss: 0.487017; batch adversarial loss: 0.637235\n",
      "epoch 64; iter: 0; batch classifier loss: 0.436113; batch adversarial loss: 0.526370\n",
      "epoch 65; iter: 0; batch classifier loss: 0.453878; batch adversarial loss: 0.535595\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 66; iter: 0; batch classifier loss: 0.467181; batch adversarial loss: 0.526153\n",
      "epoch 67; iter: 0; batch classifier loss: 0.356397; batch adversarial loss: 0.581399\n",
      "epoch 68; iter: 0; batch classifier loss: 0.416730; batch adversarial loss: 0.544462\n",
      "epoch 69; iter: 0; batch classifier loss: 0.450174; batch adversarial loss: 0.525802\n",
      "epoch 70; iter: 0; batch classifier loss: 0.425957; batch adversarial loss: 0.508744\n",
      "epoch 71; iter: 0; batch classifier loss: 0.398771; batch adversarial loss: 0.562682\n",
      "epoch 72; iter: 0; batch classifier loss: 0.424419; batch adversarial loss: 0.572779\n",
      "epoch 73; iter: 0; batch classifier loss: 0.376872; batch adversarial loss: 0.472011\n",
      "epoch 74; iter: 0; batch classifier loss: 0.422772; batch adversarial loss: 0.599653\n",
      "epoch 75; iter: 0; batch classifier loss: 0.445961; batch adversarial loss: 0.545343\n",
      "epoch 76; iter: 0; batch classifier loss: 0.457903; batch adversarial loss: 0.535036\n",
      "epoch 77; iter: 0; batch classifier loss: 0.335128; batch adversarial loss: 0.525803\n",
      "epoch 78; iter: 0; batch classifier loss: 0.431612; batch adversarial loss: 0.573387\n",
      "epoch 79; iter: 0; batch classifier loss: 0.373144; batch adversarial loss: 0.570221\n",
      "epoch 80; iter: 0; batch classifier loss: 0.426556; batch adversarial loss: 0.598928\n",
      "epoch 81; iter: 0; batch classifier loss: 0.383572; batch adversarial loss: 0.571752\n",
      "epoch 82; iter: 0; batch classifier loss: 0.426019; batch adversarial loss: 0.517003\n",
      "epoch 83; iter: 0; batch classifier loss: 0.403256; batch adversarial loss: 0.619491\n",
      "epoch 84; iter: 0; batch classifier loss: 0.384184; batch adversarial loss: 0.544703\n",
      "epoch 85; iter: 0; batch classifier loss: 0.382063; batch adversarial loss: 0.498684\n",
      "epoch 86; iter: 0; batch classifier loss: 0.343615; batch adversarial loss: 0.583109\n",
      "epoch 87; iter: 0; batch classifier loss: 0.410478; batch adversarial loss: 0.525609\n",
      "epoch 88; iter: 0; batch classifier loss: 0.368256; batch adversarial loss: 0.462602\n",
      "epoch 89; iter: 0; batch classifier loss: 0.377191; batch adversarial loss: 0.571450\n",
      "epoch 90; iter: 0; batch classifier loss: 0.444877; batch adversarial loss: 0.598773\n",
      "epoch 91; iter: 0; batch classifier loss: 0.441252; batch adversarial loss: 0.544634\n",
      "epoch 92; iter: 0; batch classifier loss: 0.391295; batch adversarial loss: 0.517181\n",
      "epoch 93; iter: 0; batch classifier loss: 0.392997; batch adversarial loss: 0.534767\n",
      "epoch 94; iter: 0; batch classifier loss: 0.424667; batch adversarial loss: 0.525203\n",
      "epoch 95; iter: 0; batch classifier loss: 0.405169; batch adversarial loss: 0.507261\n",
      "epoch 96; iter: 0; batch classifier loss: 0.396954; batch adversarial loss: 0.563055\n",
      "epoch 97; iter: 0; batch classifier loss: 0.431882; batch adversarial loss: 0.572651\n",
      "epoch 98; iter: 0; batch classifier loss: 0.445225; batch adversarial loss: 0.515657\n",
      "epoch 99; iter: 0; batch classifier loss: 0.363168; batch adversarial loss: 0.598933\n",
      "epoch 100; iter: 0; batch classifier loss: 0.404481; batch adversarial loss: 0.555836\n",
      "epoch 101; iter: 0; batch classifier loss: 0.401078; batch adversarial loss: 0.562573\n",
      "epoch 102; iter: 0; batch classifier loss: 0.396474; batch adversarial loss: 0.527323\n",
      "epoch 103; iter: 0; batch classifier loss: 0.320580; batch adversarial loss: 0.562253\n",
      "epoch 104; iter: 0; batch classifier loss: 0.389769; batch adversarial loss: 0.562176\n",
      "epoch 105; iter: 0; batch classifier loss: 0.435799; batch adversarial loss: 0.499513\n",
      "epoch 106; iter: 0; batch classifier loss: 0.418060; batch adversarial loss: 0.626112\n",
      "epoch 107; iter: 0; batch classifier loss: 0.418656; batch adversarial loss: 0.498860\n",
      "epoch 108; iter: 0; batch classifier loss: 0.337999; batch adversarial loss: 0.608948\n",
      "epoch 109; iter: 0; batch classifier loss: 0.356070; batch adversarial loss: 0.545325\n",
      "epoch 110; iter: 0; batch classifier loss: 0.383268; batch adversarial loss: 0.463232\n",
      "epoch 111; iter: 0; batch classifier loss: 0.378104; batch adversarial loss: 0.590819\n",
      "epoch 112; iter: 0; batch classifier loss: 0.411568; batch adversarial loss: 0.480520\n",
      "epoch 113; iter: 0; batch classifier loss: 0.439850; batch adversarial loss: 0.553782\n",
      "epoch 114; iter: 0; batch classifier loss: 0.315020; batch adversarial loss: 0.507852\n",
      "epoch 115; iter: 0; batch classifier loss: 0.345347; batch adversarial loss: 0.571409\n",
      "epoch 116; iter: 0; batch classifier loss: 0.375855; batch adversarial loss: 0.598408\n",
      "epoch 117; iter: 0; batch classifier loss: 0.354806; batch adversarial loss: 0.571246\n",
      "epoch 118; iter: 0; batch classifier loss: 0.302655; batch adversarial loss: 0.564099\n",
      "epoch 119; iter: 0; batch classifier loss: 0.354967; batch adversarial loss: 0.500059\n",
      "epoch 120; iter: 0; batch classifier loss: 0.364704; batch adversarial loss: 0.498047\n",
      "epoch 121; iter: 0; batch classifier loss: 0.337697; batch adversarial loss: 0.562939\n",
      "epoch 122; iter: 0; batch classifier loss: 0.442236; batch adversarial loss: 0.553990\n",
      "epoch 123; iter: 0; batch classifier loss: 0.362816; batch adversarial loss: 0.491391\n",
      "epoch 124; iter: 0; batch classifier loss: 0.396154; batch adversarial loss: 0.553544\n",
      "epoch 125; iter: 0; batch classifier loss: 0.372059; batch adversarial loss: 0.562930\n",
      "epoch 126; iter: 0; batch classifier loss: 0.375336; batch adversarial loss: 0.471076\n",
      "epoch 127; iter: 0; batch classifier loss: 0.350925; batch adversarial loss: 0.525458\n",
      "epoch 128; iter: 0; batch classifier loss: 0.377497; batch adversarial loss: 0.609306\n",
      "epoch 129; iter: 0; batch classifier loss: 0.318362; batch adversarial loss: 0.544979\n",
      "epoch 130; iter: 0; batch classifier loss: 0.377948; batch adversarial loss: 0.572900\n",
      "epoch 131; iter: 0; batch classifier loss: 0.365478; batch adversarial loss: 0.534679\n",
      "epoch 132; iter: 0; batch classifier loss: 0.381522; batch adversarial loss: 0.544773\n",
      "epoch 133; iter: 0; batch classifier loss: 0.297639; batch adversarial loss: 0.554152\n",
      "epoch 134; iter: 0; batch classifier loss: 0.479573; batch adversarial loss: 0.572610\n",
      "epoch 135; iter: 0; batch classifier loss: 0.418925; batch adversarial loss: 0.590086\n",
      "epoch 136; iter: 0; batch classifier loss: 0.396395; batch adversarial loss: 0.598885\n",
      "epoch 137; iter: 0; batch classifier loss: 0.311709; batch adversarial loss: 0.508767\n",
      "epoch 138; iter: 0; batch classifier loss: 0.341644; batch adversarial loss: 0.626673\n",
      "epoch 139; iter: 0; batch classifier loss: 0.297933; batch adversarial loss: 0.525209\n",
      "epoch 140; iter: 0; batch classifier loss: 0.409867; batch adversarial loss: 0.616070\n",
      "epoch 141; iter: 0; batch classifier loss: 0.333862; batch adversarial loss: 0.607564\n",
      "epoch 142; iter: 0; batch classifier loss: 0.405417; batch adversarial loss: 0.528108\n",
      "epoch 143; iter: 0; batch classifier loss: 0.387774; batch adversarial loss: 0.561475\n",
      "epoch 144; iter: 0; batch classifier loss: 0.394210; batch adversarial loss: 0.507049\n",
      "epoch 145; iter: 0; batch classifier loss: 0.390985; batch adversarial loss: 0.580779\n",
      "epoch 146; iter: 0; batch classifier loss: 0.361934; batch adversarial loss: 0.480856\n",
      "epoch 147; iter: 0; batch classifier loss: 0.396984; batch adversarial loss: 0.571791\n",
      "epoch 148; iter: 0; batch classifier loss: 0.381280; batch adversarial loss: 0.609023\n",
      "epoch 149; iter: 0; batch classifier loss: 0.378038; batch adversarial loss: 0.589198\n",
      "epoch 150; iter: 0; batch classifier loss: 0.390011; batch adversarial loss: 0.608691\n",
      "epoch 151; iter: 0; batch classifier loss: 0.349766; batch adversarial loss: 0.615577\n",
      "epoch 152; iter: 0; batch classifier loss: 0.318391; batch adversarial loss: 0.535299\n",
      "epoch 153; iter: 0; batch classifier loss: 0.374699; batch adversarial loss: 0.516743\n",
      "epoch 154; iter: 0; batch classifier loss: 0.352050; batch adversarial loss: 0.534070\n",
      "epoch 155; iter: 0; batch classifier loss: 0.416711; batch adversarial loss: 0.525300\n",
      "epoch 156; iter: 0; batch classifier loss: 0.426081; batch adversarial loss: 0.591987\n",
      "epoch 157; iter: 0; batch classifier loss: 0.358697; batch adversarial loss: 0.554040\n",
      "epoch 158; iter: 0; batch classifier loss: 0.300658; batch adversarial loss: 0.544819\n",
      "epoch 159; iter: 0; batch classifier loss: 0.344016; batch adversarial loss: 0.545273\n",
      "epoch 160; iter: 0; batch classifier loss: 0.300705; batch adversarial loss: 0.518188\n",
      "epoch 161; iter: 0; batch classifier loss: 0.381272; batch adversarial loss: 0.508438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 162; iter: 0; batch classifier loss: 0.277126; batch adversarial loss: 0.581446\n",
      "epoch 163; iter: 0; batch classifier loss: 0.417897; batch adversarial loss: 0.489547\n",
      "epoch 164; iter: 0; batch classifier loss: 0.420787; batch adversarial loss: 0.570312\n",
      "epoch 165; iter: 0; batch classifier loss: 0.380071; batch adversarial loss: 0.534422\n",
      "epoch 166; iter: 0; batch classifier loss: 0.379005; batch adversarial loss: 0.526583\n",
      "epoch 167; iter: 0; batch classifier loss: 0.321349; batch adversarial loss: 0.581266\n",
      "epoch 168; iter: 0; batch classifier loss: 0.396857; batch adversarial loss: 0.490319\n",
      "epoch 169; iter: 0; batch classifier loss: 0.308912; batch adversarial loss: 0.471430\n",
      "epoch 170; iter: 0; batch classifier loss: 0.391057; batch adversarial loss: 0.527357\n",
      "epoch 171; iter: 0; batch classifier loss: 0.362923; batch adversarial loss: 0.525369\n",
      "epoch 172; iter: 0; batch classifier loss: 0.342862; batch adversarial loss: 0.570756\n",
      "epoch 173; iter: 0; batch classifier loss: 0.449761; batch adversarial loss: 0.483273\n",
      "epoch 174; iter: 0; batch classifier loss: 0.411676; batch adversarial loss: 0.571964\n",
      "epoch 175; iter: 0; batch classifier loss: 0.324292; batch adversarial loss: 0.544420\n",
      "epoch 176; iter: 0; batch classifier loss: 0.381617; batch adversarial loss: 0.571194\n",
      "epoch 177; iter: 0; batch classifier loss: 0.406594; batch adversarial loss: 0.580393\n",
      "epoch 178; iter: 0; batch classifier loss: 0.375781; batch adversarial loss: 0.562348\n",
      "epoch 179; iter: 0; batch classifier loss: 0.344842; batch adversarial loss: 0.555034\n",
      "epoch 180; iter: 0; batch classifier loss: 0.383916; batch adversarial loss: 0.545748\n",
      "epoch 181; iter: 0; batch classifier loss: 0.358084; batch adversarial loss: 0.479767\n",
      "epoch 182; iter: 0; batch classifier loss: 0.408065; batch adversarial loss: 0.563846\n",
      "epoch 183; iter: 0; batch classifier loss: 0.305517; batch adversarial loss: 0.463411\n",
      "epoch 184; iter: 0; batch classifier loss: 0.361203; batch adversarial loss: 0.517839\n",
      "epoch 185; iter: 0; batch classifier loss: 0.342311; batch adversarial loss: 0.492413\n",
      "epoch 186; iter: 0; batch classifier loss: 0.380494; batch adversarial loss: 0.534300\n",
      "epoch 187; iter: 0; batch classifier loss: 0.335540; batch adversarial loss: 0.544757\n",
      "epoch 188; iter: 0; batch classifier loss: 0.350314; batch adversarial loss: 0.625855\n",
      "epoch 189; iter: 0; batch classifier loss: 0.385319; batch adversarial loss: 0.473152\n",
      "epoch 190; iter: 0; batch classifier loss: 0.351026; batch adversarial loss: 0.543240\n",
      "epoch 191; iter: 0; batch classifier loss: 0.425213; batch adversarial loss: 0.516670\n",
      "epoch 192; iter: 0; batch classifier loss: 0.336257; batch adversarial loss: 0.573254\n",
      "epoch 193; iter: 0; batch classifier loss: 0.354004; batch adversarial loss: 0.543264\n",
      "epoch 194; iter: 0; batch classifier loss: 0.352687; batch adversarial loss: 0.544969\n",
      "epoch 195; iter: 0; batch classifier loss: 0.379359; batch adversarial loss: 0.509236\n",
      "epoch 196; iter: 0; batch classifier loss: 0.340474; batch adversarial loss: 0.462465\n",
      "epoch 197; iter: 0; batch classifier loss: 0.429107; batch adversarial loss: 0.481857\n",
      "epoch 198; iter: 0; batch classifier loss: 0.331353; batch adversarial loss: 0.471974\n",
      "epoch 199; iter: 0; batch classifier loss: 0.363699; batch adversarial loss: 0.554583\n",
      "epoch 0; iter: 0; batch classifier loss: 0.714764; batch adversarial loss: 0.757484\n",
      "epoch 1; iter: 0; batch classifier loss: 0.803132; batch adversarial loss: 0.979244\n",
      "epoch 2; iter: 0; batch classifier loss: 0.944972; batch adversarial loss: 0.934102\n",
      "epoch 3; iter: 0; batch classifier loss: 1.116482; batch adversarial loss: 0.871838\n",
      "epoch 4; iter: 0; batch classifier loss: 1.029440; batch adversarial loss: 0.805006\n",
      "epoch 5; iter: 0; batch classifier loss: 0.924072; batch adversarial loss: 0.736012\n",
      "epoch 6; iter: 0; batch classifier loss: 0.799366; batch adversarial loss: 0.680692\n",
      "epoch 7; iter: 0; batch classifier loss: 0.626803; batch adversarial loss: 0.627358\n",
      "epoch 8; iter: 0; batch classifier loss: 0.530416; batch adversarial loss: 0.592219\n",
      "epoch 9; iter: 0; batch classifier loss: 0.578443; batch adversarial loss: 0.562926\n",
      "epoch 10; iter: 0; batch classifier loss: 0.589638; batch adversarial loss: 0.589908\n",
      "epoch 11; iter: 0; batch classifier loss: 0.503266; batch adversarial loss: 0.597816\n",
      "epoch 12; iter: 0; batch classifier loss: 0.565172; batch adversarial loss: 0.548460\n",
      "epoch 13; iter: 0; batch classifier loss: 0.550855; batch adversarial loss: 0.579797\n",
      "epoch 14; iter: 0; batch classifier loss: 0.550903; batch adversarial loss: 0.536751\n",
      "epoch 15; iter: 0; batch classifier loss: 0.560066; batch adversarial loss: 0.612557\n",
      "epoch 16; iter: 0; batch classifier loss: 0.551302; batch adversarial loss: 0.585919\n",
      "epoch 17; iter: 0; batch classifier loss: 0.404403; batch adversarial loss: 0.632760\n",
      "epoch 18; iter: 0; batch classifier loss: 0.536310; batch adversarial loss: 0.555056\n",
      "epoch 19; iter: 0; batch classifier loss: 0.532624; batch adversarial loss: 0.588687\n",
      "epoch 20; iter: 0; batch classifier loss: 0.515841; batch adversarial loss: 0.584075\n",
      "epoch 21; iter: 0; batch classifier loss: 0.523923; batch adversarial loss: 0.553689\n",
      "epoch 22; iter: 0; batch classifier loss: 0.460124; batch adversarial loss: 0.609075\n",
      "epoch 23; iter: 0; batch classifier loss: 0.444333; batch adversarial loss: 0.579311\n",
      "epoch 24; iter: 0; batch classifier loss: 0.446507; batch adversarial loss: 0.541967\n",
      "epoch 25; iter: 0; batch classifier loss: 0.569405; batch adversarial loss: 0.598315\n",
      "epoch 26; iter: 0; batch classifier loss: 0.536769; batch adversarial loss: 0.561008\n",
      "epoch 27; iter: 0; batch classifier loss: 0.477662; batch adversarial loss: 0.533219\n",
      "epoch 28; iter: 0; batch classifier loss: 0.430169; batch adversarial loss: 0.517455\n",
      "epoch 29; iter: 0; batch classifier loss: 0.487691; batch adversarial loss: 0.569900\n",
      "epoch 30; iter: 0; batch classifier loss: 0.465803; batch adversarial loss: 0.551131\n",
      "epoch 31; iter: 0; batch classifier loss: 0.380635; batch adversarial loss: 0.507394\n",
      "epoch 32; iter: 0; batch classifier loss: 0.512323; batch adversarial loss: 0.574812\n",
      "epoch 33; iter: 0; batch classifier loss: 0.483957; batch adversarial loss: 0.578656\n",
      "epoch 34; iter: 0; batch classifier loss: 0.434484; batch adversarial loss: 0.530334\n",
      "epoch 35; iter: 0; batch classifier loss: 0.457613; batch adversarial loss: 0.516897\n",
      "epoch 36; iter: 0; batch classifier loss: 0.530105; batch adversarial loss: 0.521223\n",
      "epoch 37; iter: 0; batch classifier loss: 0.409655; batch adversarial loss: 0.561170\n",
      "epoch 38; iter: 0; batch classifier loss: 0.450432; batch adversarial loss: 0.539323\n",
      "epoch 39; iter: 0; batch classifier loss: 0.513109; batch adversarial loss: 0.539386\n",
      "epoch 40; iter: 0; batch classifier loss: 0.487277; batch adversarial loss: 0.591916\n",
      "epoch 41; iter: 0; batch classifier loss: 0.389387; batch adversarial loss: 0.594831\n",
      "epoch 42; iter: 0; batch classifier loss: 0.391488; batch adversarial loss: 0.562866\n",
      "epoch 43; iter: 0; batch classifier loss: 0.435765; batch adversarial loss: 0.496267\n",
      "epoch 44; iter: 0; batch classifier loss: 0.432180; batch adversarial loss: 0.493305\n",
      "epoch 45; iter: 0; batch classifier loss: 0.451615; batch adversarial loss: 0.581806\n",
      "epoch 46; iter: 0; batch classifier loss: 0.414535; batch adversarial loss: 0.517418\n",
      "epoch 47; iter: 0; batch classifier loss: 0.466964; batch adversarial loss: 0.581338\n",
      "epoch 48; iter: 0; batch classifier loss: 0.401856; batch adversarial loss: 0.525276\n",
      "epoch 49; iter: 0; batch classifier loss: 0.477340; batch adversarial loss: 0.589626\n",
      "epoch 50; iter: 0; batch classifier loss: 0.457607; batch adversarial loss: 0.563738\n",
      "epoch 51; iter: 0; batch classifier loss: 0.440229; batch adversarial loss: 0.569896\n",
      "epoch 52; iter: 0; batch classifier loss: 0.538686; batch adversarial loss: 0.599384\n",
      "epoch 53; iter: 0; batch classifier loss: 0.380684; batch adversarial loss: 0.552246\n",
      "epoch 54; iter: 0; batch classifier loss: 0.454052; batch adversarial loss: 0.562175\n",
      "epoch 55; iter: 0; batch classifier loss: 0.467335; batch adversarial loss: 0.580800\n",
      "epoch 56; iter: 0; batch classifier loss: 0.419979; batch adversarial loss: 0.635216\n",
      "epoch 57; iter: 0; batch classifier loss: 0.431009; batch adversarial loss: 0.508467\n",
      "epoch 58; iter: 0; batch classifier loss: 0.344201; batch adversarial loss: 0.472179\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 59; iter: 0; batch classifier loss: 0.412450; batch adversarial loss: 0.517580\n",
      "epoch 60; iter: 0; batch classifier loss: 0.407530; batch adversarial loss: 0.607789\n",
      "epoch 61; iter: 0; batch classifier loss: 0.470694; batch adversarial loss: 0.499588\n",
      "epoch 62; iter: 0; batch classifier loss: 0.427978; batch adversarial loss: 0.490431\n",
      "epoch 63; iter: 0; batch classifier loss: 0.420472; batch adversarial loss: 0.589740\n",
      "epoch 64; iter: 0; batch classifier loss: 0.445659; batch adversarial loss: 0.599219\n",
      "epoch 65; iter: 0; batch classifier loss: 0.400702; batch adversarial loss: 0.589855\n",
      "epoch 66; iter: 0; batch classifier loss: 0.454418; batch adversarial loss: 0.598983\n",
      "epoch 67; iter: 0; batch classifier loss: 0.355997; batch adversarial loss: 0.517571\n",
      "epoch 68; iter: 0; batch classifier loss: 0.436938; batch adversarial loss: 0.617572\n",
      "epoch 69; iter: 0; batch classifier loss: 0.388221; batch adversarial loss: 0.670310\n",
      "epoch 70; iter: 0; batch classifier loss: 0.404840; batch adversarial loss: 0.580213\n",
      "epoch 71; iter: 0; batch classifier loss: 0.337533; batch adversarial loss: 0.590229\n",
      "epoch 72; iter: 0; batch classifier loss: 0.332719; batch adversarial loss: 0.543318\n",
      "epoch 73; iter: 0; batch classifier loss: 0.375834; batch adversarial loss: 0.544274\n",
      "epoch 74; iter: 0; batch classifier loss: 0.359890; batch adversarial loss: 0.526023\n",
      "epoch 75; iter: 0; batch classifier loss: 0.381189; batch adversarial loss: 0.615780\n",
      "epoch 76; iter: 0; batch classifier loss: 0.414078; batch adversarial loss: 0.562844\n",
      "epoch 77; iter: 0; batch classifier loss: 0.381765; batch adversarial loss: 0.480637\n",
      "epoch 78; iter: 0; batch classifier loss: 0.397115; batch adversarial loss: 0.591192\n",
      "epoch 79; iter: 0; batch classifier loss: 0.291084; batch adversarial loss: 0.562505\n",
      "epoch 80; iter: 0; batch classifier loss: 0.322216; batch adversarial loss: 0.562655\n",
      "epoch 81; iter: 0; batch classifier loss: 0.390560; batch adversarial loss: 0.515959\n",
      "epoch 82; iter: 0; batch classifier loss: 0.358373; batch adversarial loss: 0.517417\n",
      "epoch 83; iter: 0; batch classifier loss: 0.416994; batch adversarial loss: 0.607478\n",
      "epoch 84; iter: 0; batch classifier loss: 0.415478; batch adversarial loss: 0.616463\n",
      "epoch 85; iter: 0; batch classifier loss: 0.358819; batch adversarial loss: 0.624355\n",
      "epoch 86; iter: 0; batch classifier loss: 0.428397; batch adversarial loss: 0.516340\n",
      "epoch 87; iter: 0; batch classifier loss: 0.354840; batch adversarial loss: 0.598779\n",
      "epoch 88; iter: 0; batch classifier loss: 0.370388; batch adversarial loss: 0.609554\n",
      "epoch 89; iter: 0; batch classifier loss: 0.381395; batch adversarial loss: 0.606049\n",
      "epoch 90; iter: 0; batch classifier loss: 0.411873; batch adversarial loss: 0.488856\n",
      "epoch 91; iter: 0; batch classifier loss: 0.421926; batch adversarial loss: 0.553750\n",
      "epoch 92; iter: 0; batch classifier loss: 0.381402; batch adversarial loss: 0.501046\n",
      "epoch 93; iter: 0; batch classifier loss: 0.332815; batch adversarial loss: 0.563287\n",
      "epoch 94; iter: 0; batch classifier loss: 0.308449; batch adversarial loss: 0.462360\n",
      "epoch 95; iter: 0; batch classifier loss: 0.325586; batch adversarial loss: 0.571544\n",
      "epoch 96; iter: 0; batch classifier loss: 0.430812; batch adversarial loss: 0.555440\n",
      "epoch 97; iter: 0; batch classifier loss: 0.348864; batch adversarial loss: 0.525843\n",
      "epoch 98; iter: 0; batch classifier loss: 0.324180; batch adversarial loss: 0.537759\n",
      "epoch 99; iter: 0; batch classifier loss: 0.413389; batch adversarial loss: 0.508649\n",
      "epoch 100; iter: 0; batch classifier loss: 0.371848; batch adversarial loss: 0.516446\n",
      "epoch 101; iter: 0; batch classifier loss: 0.338919; batch adversarial loss: 0.570445\n",
      "epoch 102; iter: 0; batch classifier loss: 0.374428; batch adversarial loss: 0.581042\n",
      "epoch 103; iter: 0; batch classifier loss: 0.413197; batch adversarial loss: 0.517519\n",
      "epoch 104; iter: 0; batch classifier loss: 0.303103; batch adversarial loss: 0.544051\n",
      "epoch 105; iter: 0; batch classifier loss: 0.321370; batch adversarial loss: 0.588211\n",
      "epoch 106; iter: 0; batch classifier loss: 0.348578; batch adversarial loss: 0.516704\n",
      "epoch 107; iter: 0; batch classifier loss: 0.379259; batch adversarial loss: 0.517006\n",
      "epoch 108; iter: 0; batch classifier loss: 0.414468; batch adversarial loss: 0.580038\n",
      "epoch 109; iter: 0; batch classifier loss: 0.385883; batch adversarial loss: 0.627772\n",
      "epoch 110; iter: 0; batch classifier loss: 0.337138; batch adversarial loss: 0.562136\n",
      "epoch 111; iter: 0; batch classifier loss: 0.338058; batch adversarial loss: 0.525221\n",
      "epoch 112; iter: 0; batch classifier loss: 0.388699; batch adversarial loss: 0.542879\n",
      "epoch 113; iter: 0; batch classifier loss: 0.307248; batch adversarial loss: 0.490892\n",
      "epoch 114; iter: 0; batch classifier loss: 0.359500; batch adversarial loss: 0.615966\n",
      "epoch 115; iter: 0; batch classifier loss: 0.416093; batch adversarial loss: 0.480168\n",
      "epoch 116; iter: 0; batch classifier loss: 0.408585; batch adversarial loss: 0.526814\n",
      "epoch 117; iter: 0; batch classifier loss: 0.295770; batch adversarial loss: 0.508269\n",
      "epoch 118; iter: 0; batch classifier loss: 0.333514; batch adversarial loss: 0.564692\n",
      "epoch 119; iter: 0; batch classifier loss: 0.353251; batch adversarial loss: 0.607103\n",
      "epoch 120; iter: 0; batch classifier loss: 0.292572; batch adversarial loss: 0.545719\n",
      "epoch 121; iter: 0; batch classifier loss: 0.381786; batch adversarial loss: 0.609016\n",
      "epoch 122; iter: 0; batch classifier loss: 0.382269; batch adversarial loss: 0.554907\n",
      "epoch 123; iter: 0; batch classifier loss: 0.306787; batch adversarial loss: 0.582932\n",
      "epoch 124; iter: 0; batch classifier loss: 0.305074; batch adversarial loss: 0.481826\n",
      "epoch 125; iter: 0; batch classifier loss: 0.321604; batch adversarial loss: 0.578509\n",
      "epoch 126; iter: 0; batch classifier loss: 0.385469; batch adversarial loss: 0.525255\n",
      "epoch 127; iter: 0; batch classifier loss: 0.335731; batch adversarial loss: 0.480326\n",
      "epoch 128; iter: 0; batch classifier loss: 0.385071; batch adversarial loss: 0.599881\n",
      "epoch 129; iter: 0; batch classifier loss: 0.384774; batch adversarial loss: 0.553908\n",
      "epoch 130; iter: 0; batch classifier loss: 0.324097; batch adversarial loss: 0.442705\n",
      "epoch 131; iter: 0; batch classifier loss: 0.387295; batch adversarial loss: 0.545588\n",
      "epoch 132; iter: 0; batch classifier loss: 0.346770; batch adversarial loss: 0.582006\n",
      "epoch 133; iter: 0; batch classifier loss: 0.383124; batch adversarial loss: 0.495725\n",
      "epoch 134; iter: 0; batch classifier loss: 0.330541; batch adversarial loss: 0.542315\n",
      "epoch 135; iter: 0; batch classifier loss: 0.368943; batch adversarial loss: 0.552508\n",
      "epoch 136; iter: 0; batch classifier loss: 0.361680; batch adversarial loss: 0.561486\n",
      "epoch 137; iter: 0; batch classifier loss: 0.317691; batch adversarial loss: 0.571733\n",
      "epoch 138; iter: 0; batch classifier loss: 0.336629; batch adversarial loss: 0.578226\n",
      "epoch 139; iter: 0; batch classifier loss: 0.367879; batch adversarial loss: 0.516591\n",
      "epoch 140; iter: 0; batch classifier loss: 0.497566; batch adversarial loss: 0.571400\n",
      "epoch 141; iter: 0; batch classifier loss: 0.362902; batch adversarial loss: 0.588578\n",
      "epoch 142; iter: 0; batch classifier loss: 0.319211; batch adversarial loss: 0.525264\n",
      "epoch 143; iter: 0; batch classifier loss: 0.358005; batch adversarial loss: 0.581421\n",
      "epoch 144; iter: 0; batch classifier loss: 0.282967; batch adversarial loss: 0.542888\n",
      "epoch 145; iter: 0; batch classifier loss: 0.301066; batch adversarial loss: 0.491408\n",
      "epoch 146; iter: 0; batch classifier loss: 0.329145; batch adversarial loss: 0.518336\n",
      "epoch 147; iter: 0; batch classifier loss: 0.275627; batch adversarial loss: 0.626423\n",
      "epoch 148; iter: 0; batch classifier loss: 0.327283; batch adversarial loss: 0.553915\n",
      "epoch 149; iter: 0; batch classifier loss: 0.372456; batch adversarial loss: 0.510209\n",
      "epoch 150; iter: 0; batch classifier loss: 0.356051; batch adversarial loss: 0.615364\n",
      "epoch 151; iter: 0; batch classifier loss: 0.374570; batch adversarial loss: 0.588318\n",
      "epoch 152; iter: 0; batch classifier loss: 0.364623; batch adversarial loss: 0.570775\n",
      "epoch 153; iter: 0; batch classifier loss: 0.389911; batch adversarial loss: 0.554360\n",
      "epoch 154; iter: 0; batch classifier loss: 0.383334; batch adversarial loss: 0.501023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 155; iter: 0; batch classifier loss: 0.352957; batch adversarial loss: 0.563823\n",
      "epoch 156; iter: 0; batch classifier loss: 0.367397; batch adversarial loss: 0.615705\n",
      "epoch 157; iter: 0; batch classifier loss: 0.329796; batch adversarial loss: 0.497664\n",
      "epoch 158; iter: 0; batch classifier loss: 0.300820; batch adversarial loss: 0.534889\n",
      "epoch 159; iter: 0; batch classifier loss: 0.286160; batch adversarial loss: 0.581628\n",
      "epoch 160; iter: 0; batch classifier loss: 0.285626; batch adversarial loss: 0.514572\n",
      "epoch 161; iter: 0; batch classifier loss: 0.393525; batch adversarial loss: 0.591713\n",
      "epoch 162; iter: 0; batch classifier loss: 0.356337; batch adversarial loss: 0.528238\n",
      "epoch 163; iter: 0; batch classifier loss: 0.280027; batch adversarial loss: 0.544296\n",
      "epoch 164; iter: 0; batch classifier loss: 0.378873; batch adversarial loss: 0.463232\n",
      "epoch 165; iter: 0; batch classifier loss: 0.258348; batch adversarial loss: 0.561372\n",
      "epoch 166; iter: 0; batch classifier loss: 0.290522; batch adversarial loss: 0.545007\n",
      "epoch 167; iter: 0; batch classifier loss: 0.360647; batch adversarial loss: 0.452626\n",
      "epoch 168; iter: 0; batch classifier loss: 0.351680; batch adversarial loss: 0.525103\n",
      "epoch 169; iter: 0; batch classifier loss: 0.352048; batch adversarial loss: 0.590197\n",
      "epoch 170; iter: 0; batch classifier loss: 0.323877; batch adversarial loss: 0.537134\n",
      "epoch 171; iter: 0; batch classifier loss: 0.393247; batch adversarial loss: 0.526322\n",
      "epoch 172; iter: 0; batch classifier loss: 0.265923; batch adversarial loss: 0.536862\n",
      "epoch 173; iter: 0; batch classifier loss: 0.283217; batch adversarial loss: 0.526478\n",
      "epoch 174; iter: 0; batch classifier loss: 0.331404; batch adversarial loss: 0.536396\n",
      "epoch 175; iter: 0; batch classifier loss: 0.288022; batch adversarial loss: 0.589967\n",
      "epoch 176; iter: 0; batch classifier loss: 0.343746; batch adversarial loss: 0.526738\n",
      "epoch 177; iter: 0; batch classifier loss: 0.311719; batch adversarial loss: 0.562930\n",
      "epoch 178; iter: 0; batch classifier loss: 0.405008; batch adversarial loss: 0.500110\n",
      "epoch 179; iter: 0; batch classifier loss: 0.269627; batch adversarial loss: 0.536166\n",
      "epoch 180; iter: 0; batch classifier loss: 0.368996; batch adversarial loss: 0.453712\n",
      "epoch 181; iter: 0; batch classifier loss: 0.355120; batch adversarial loss: 0.624037\n",
      "epoch 182; iter: 0; batch classifier loss: 0.296923; batch adversarial loss: 0.545030\n",
      "epoch 183; iter: 0; batch classifier loss: 0.310871; batch adversarial loss: 0.580268\n",
      "epoch 184; iter: 0; batch classifier loss: 0.365010; batch adversarial loss: 0.626315\n",
      "epoch 185; iter: 0; batch classifier loss: 0.272255; batch adversarial loss: 0.563859\n",
      "epoch 186; iter: 0; batch classifier loss: 0.383985; batch adversarial loss: 0.533946\n",
      "epoch 187; iter: 0; batch classifier loss: 0.308145; batch adversarial loss: 0.569833\n",
      "epoch 188; iter: 0; batch classifier loss: 0.359884; batch adversarial loss: 0.528429\n",
      "epoch 189; iter: 0; batch classifier loss: 0.274592; batch adversarial loss: 0.600380\n",
      "epoch 190; iter: 0; batch classifier loss: 0.325267; batch adversarial loss: 0.618307\n",
      "epoch 191; iter: 0; batch classifier loss: 0.364680; batch adversarial loss: 0.517748\n",
      "epoch 192; iter: 0; batch classifier loss: 0.342458; batch adversarial loss: 0.563727\n",
      "epoch 193; iter: 0; batch classifier loss: 0.395768; batch adversarial loss: 0.560069\n",
      "epoch 194; iter: 0; batch classifier loss: 0.318907; batch adversarial loss: 0.506678\n",
      "epoch 195; iter: 0; batch classifier loss: 0.338287; batch adversarial loss: 0.526211\n",
      "epoch 196; iter: 0; batch classifier loss: 0.324913; batch adversarial loss: 0.505990\n",
      "epoch 197; iter: 0; batch classifier loss: 0.328992; batch adversarial loss: 0.526572\n",
      "epoch 198; iter: 0; batch classifier loss: 0.332570; batch adversarial loss: 0.598957\n",
      "epoch 199; iter: 0; batch classifier loss: 0.352888; batch adversarial loss: 0.590540\n",
      "epoch 0; iter: 0; batch classifier loss: 0.668696; batch adversarial loss: 0.798227\n",
      "epoch 1; iter: 0; batch classifier loss: 0.798584; batch adversarial loss: 0.895081\n",
      "epoch 2; iter: 0; batch classifier loss: 0.830585; batch adversarial loss: 0.833823\n",
      "epoch 3; iter: 0; batch classifier loss: 0.936318; batch adversarial loss: 0.767597\n",
      "epoch 4; iter: 0; batch classifier loss: 0.854030; batch adversarial loss: 0.706583\n",
      "epoch 5; iter: 0; batch classifier loss: 0.688743; batch adversarial loss: 0.645154\n",
      "epoch 6; iter: 0; batch classifier loss: 0.613770; batch adversarial loss: 0.596466\n",
      "epoch 7; iter: 0; batch classifier loss: 0.584690; batch adversarial loss: 0.606817\n",
      "epoch 8; iter: 0; batch classifier loss: 0.502143; batch adversarial loss: 0.590315\n",
      "epoch 9; iter: 0; batch classifier loss: 0.501835; batch adversarial loss: 0.613354\n",
      "epoch 10; iter: 0; batch classifier loss: 0.565600; batch adversarial loss: 0.568167\n",
      "epoch 11; iter: 0; batch classifier loss: 0.537458; batch adversarial loss: 0.601726\n",
      "epoch 12; iter: 0; batch classifier loss: 0.597487; batch adversarial loss: 0.584177\n",
      "epoch 13; iter: 0; batch classifier loss: 0.529097; batch adversarial loss: 0.572195\n",
      "epoch 14; iter: 0; batch classifier loss: 0.594705; batch adversarial loss: 0.549098\n",
      "epoch 15; iter: 0; batch classifier loss: 0.480679; batch adversarial loss: 0.635338\n",
      "epoch 16; iter: 0; batch classifier loss: 0.463129; batch adversarial loss: 0.563149\n",
      "epoch 17; iter: 0; batch classifier loss: 0.484620; batch adversarial loss: 0.577566\n",
      "epoch 18; iter: 0; batch classifier loss: 0.505731; batch adversarial loss: 0.623037\n",
      "epoch 19; iter: 0; batch classifier loss: 0.483113; batch adversarial loss: 0.612705\n",
      "epoch 20; iter: 0; batch classifier loss: 0.485547; batch adversarial loss: 0.595387\n",
      "epoch 21; iter: 0; batch classifier loss: 0.471834; batch adversarial loss: 0.545043\n",
      "epoch 22; iter: 0; batch classifier loss: 0.443728; batch adversarial loss: 0.603189\n",
      "epoch 23; iter: 0; batch classifier loss: 0.615588; batch adversarial loss: 0.567897\n",
      "epoch 24; iter: 0; batch classifier loss: 0.445602; batch adversarial loss: 0.488112\n",
      "epoch 25; iter: 0; batch classifier loss: 0.564576; batch adversarial loss: 0.565660\n",
      "epoch 26; iter: 0; batch classifier loss: 0.546286; batch adversarial loss: 0.531344\n",
      "epoch 27; iter: 0; batch classifier loss: 0.468928; batch adversarial loss: 0.560293\n",
      "epoch 28; iter: 0; batch classifier loss: 0.453607; batch adversarial loss: 0.582305\n",
      "epoch 29; iter: 0; batch classifier loss: 0.420891; batch adversarial loss: 0.616314\n",
      "epoch 30; iter: 0; batch classifier loss: 0.481414; batch adversarial loss: 0.561978\n",
      "epoch 31; iter: 0; batch classifier loss: 0.440786; batch adversarial loss: 0.574954\n",
      "epoch 32; iter: 0; batch classifier loss: 0.466894; batch adversarial loss: 0.564364\n",
      "epoch 33; iter: 0; batch classifier loss: 0.447579; batch adversarial loss: 0.564633\n",
      "epoch 34; iter: 0; batch classifier loss: 0.469187; batch adversarial loss: 0.607133\n",
      "epoch 35; iter: 0; batch classifier loss: 0.441713; batch adversarial loss: 0.491492\n",
      "epoch 36; iter: 0; batch classifier loss: 0.484806; batch adversarial loss: 0.573788\n",
      "epoch 37; iter: 0; batch classifier loss: 0.475020; batch adversarial loss: 0.553567\n",
      "epoch 38; iter: 0; batch classifier loss: 0.486335; batch adversarial loss: 0.532872\n",
      "epoch 39; iter: 0; batch classifier loss: 0.390891; batch adversarial loss: 0.598928\n",
      "epoch 40; iter: 0; batch classifier loss: 0.470494; batch adversarial loss: 0.552701\n",
      "epoch 41; iter: 0; batch classifier loss: 0.446019; batch adversarial loss: 0.522941\n",
      "epoch 42; iter: 0; batch classifier loss: 0.512901; batch adversarial loss: 0.548549\n",
      "epoch 43; iter: 0; batch classifier loss: 0.401836; batch adversarial loss: 0.542362\n",
      "epoch 44; iter: 0; batch classifier loss: 0.462740; batch adversarial loss: 0.601517\n",
      "epoch 45; iter: 0; batch classifier loss: 0.368051; batch adversarial loss: 0.531489\n",
      "epoch 46; iter: 0; batch classifier loss: 0.403397; batch adversarial loss: 0.535448\n",
      "epoch 47; iter: 0; batch classifier loss: 0.464090; batch adversarial loss: 0.641122\n",
      "epoch 48; iter: 0; batch classifier loss: 0.359040; batch adversarial loss: 0.519433\n",
      "epoch 49; iter: 0; batch classifier loss: 0.382518; batch adversarial loss: 0.547613\n",
      "epoch 50; iter: 0; batch classifier loss: 0.412847; batch adversarial loss: 0.606027\n",
      "epoch 51; iter: 0; batch classifier loss: 0.422301; batch adversarial loss: 0.495030\n",
      "epoch 52; iter: 0; batch classifier loss: 0.421799; batch adversarial loss: 0.577658\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 53; iter: 0; batch classifier loss: 0.381731; batch adversarial loss: 0.542789\n",
      "epoch 54; iter: 0; batch classifier loss: 0.452655; batch adversarial loss: 0.590440\n",
      "epoch 55; iter: 0; batch classifier loss: 0.382004; batch adversarial loss: 0.509458\n",
      "epoch 56; iter: 0; batch classifier loss: 0.401873; batch adversarial loss: 0.481413\n",
      "epoch 57; iter: 0; batch classifier loss: 0.390376; batch adversarial loss: 0.588173\n",
      "epoch 58; iter: 0; batch classifier loss: 0.457137; batch adversarial loss: 0.589439\n",
      "epoch 59; iter: 0; batch classifier loss: 0.406530; batch adversarial loss: 0.508459\n",
      "epoch 60; iter: 0; batch classifier loss: 0.363356; batch adversarial loss: 0.569216\n",
      "epoch 61; iter: 0; batch classifier loss: 0.508155; batch adversarial loss: 0.562905\n",
      "epoch 62; iter: 0; batch classifier loss: 0.368791; batch adversarial loss: 0.581846\n",
      "epoch 63; iter: 0; batch classifier loss: 0.350653; batch adversarial loss: 0.509046\n",
      "epoch 64; iter: 0; batch classifier loss: 0.424053; batch adversarial loss: 0.570988\n",
      "epoch 65; iter: 0; batch classifier loss: 0.379429; batch adversarial loss: 0.544978\n",
      "epoch 66; iter: 0; batch classifier loss: 0.378039; batch adversarial loss: 0.491574\n",
      "epoch 67; iter: 0; batch classifier loss: 0.352196; batch adversarial loss: 0.570781\n",
      "epoch 68; iter: 0; batch classifier loss: 0.331172; batch adversarial loss: 0.536002\n",
      "epoch 69; iter: 0; batch classifier loss: 0.390641; batch adversarial loss: 0.570335\n",
      "epoch 70; iter: 0; batch classifier loss: 0.422299; batch adversarial loss: 0.607533\n",
      "epoch 71; iter: 0; batch classifier loss: 0.428888; batch adversarial loss: 0.490896\n",
      "epoch 72; iter: 0; batch classifier loss: 0.438184; batch adversarial loss: 0.553893\n",
      "epoch 73; iter: 0; batch classifier loss: 0.443454; batch adversarial loss: 0.571130\n",
      "epoch 74; iter: 0; batch classifier loss: 0.395933; batch adversarial loss: 0.454136\n",
      "epoch 75; iter: 0; batch classifier loss: 0.436181; batch adversarial loss: 0.553656\n",
      "epoch 76; iter: 0; batch classifier loss: 0.341310; batch adversarial loss: 0.545071\n",
      "epoch 77; iter: 0; batch classifier loss: 0.372891; batch adversarial loss: 0.526924\n",
      "epoch 78; iter: 0; batch classifier loss: 0.375500; batch adversarial loss: 0.553561\n",
      "epoch 79; iter: 0; batch classifier loss: 0.372449; batch adversarial loss: 0.526748\n",
      "epoch 80; iter: 0; batch classifier loss: 0.336135; batch adversarial loss: 0.597939\n",
      "epoch 81; iter: 0; batch classifier loss: 0.404380; batch adversarial loss: 0.580480\n",
      "epoch 82; iter: 0; batch classifier loss: 0.345274; batch adversarial loss: 0.562941\n",
      "epoch 83; iter: 0; batch classifier loss: 0.404375; batch adversarial loss: 0.553953\n",
      "epoch 84; iter: 0; batch classifier loss: 0.406646; batch adversarial loss: 0.490605\n",
      "epoch 85; iter: 0; batch classifier loss: 0.328628; batch adversarial loss: 0.553431\n",
      "epoch 86; iter: 0; batch classifier loss: 0.324247; batch adversarial loss: 0.581147\n",
      "epoch 87; iter: 0; batch classifier loss: 0.367330; batch adversarial loss: 0.554211\n",
      "epoch 88; iter: 0; batch classifier loss: 0.386654; batch adversarial loss: 0.544986\n",
      "epoch 89; iter: 0; batch classifier loss: 0.419230; batch adversarial loss: 0.553380\n",
      "epoch 90; iter: 0; batch classifier loss: 0.419232; batch adversarial loss: 0.509084\n",
      "epoch 91; iter: 0; batch classifier loss: 0.375732; batch adversarial loss: 0.500348\n",
      "epoch 92; iter: 0; batch classifier loss: 0.368207; batch adversarial loss: 0.544332\n",
      "epoch 93; iter: 0; batch classifier loss: 0.398094; batch adversarial loss: 0.553338\n",
      "epoch 94; iter: 0; batch classifier loss: 0.376829; batch adversarial loss: 0.616701\n",
      "epoch 95; iter: 0; batch classifier loss: 0.359606; batch adversarial loss: 0.598235\n",
      "epoch 96; iter: 0; batch classifier loss: 0.336393; batch adversarial loss: 0.553364\n",
      "epoch 97; iter: 0; batch classifier loss: 0.350751; batch adversarial loss: 0.517462\n",
      "epoch 98; iter: 0; batch classifier loss: 0.369782; batch adversarial loss: 0.508876\n",
      "epoch 99; iter: 0; batch classifier loss: 0.243771; batch adversarial loss: 0.580214\n",
      "epoch 100; iter: 0; batch classifier loss: 0.433741; batch adversarial loss: 0.527091\n",
      "epoch 101; iter: 0; batch classifier loss: 0.355621; batch adversarial loss: 0.535930\n",
      "epoch 102; iter: 0; batch classifier loss: 0.388981; batch adversarial loss: 0.526667\n",
      "epoch 103; iter: 0; batch classifier loss: 0.379409; batch adversarial loss: 0.463960\n",
      "epoch 104; iter: 0; batch classifier loss: 0.339968; batch adversarial loss: 0.535624\n",
      "epoch 105; iter: 0; batch classifier loss: 0.410632; batch adversarial loss: 0.482007\n",
      "epoch 106; iter: 0; batch classifier loss: 0.349606; batch adversarial loss: 0.589591\n",
      "epoch 107; iter: 0; batch classifier loss: 0.322724; batch adversarial loss: 0.526688\n",
      "epoch 108; iter: 0; batch classifier loss: 0.326839; batch adversarial loss: 0.544269\n",
      "epoch 109; iter: 0; batch classifier loss: 0.317820; batch adversarial loss: 0.616201\n",
      "epoch 110; iter: 0; batch classifier loss: 0.396333; batch adversarial loss: 0.517957\n",
      "epoch 111; iter: 0; batch classifier loss: 0.294844; batch adversarial loss: 0.535957\n",
      "epoch 112; iter: 0; batch classifier loss: 0.334159; batch adversarial loss: 0.580329\n",
      "epoch 113; iter: 0; batch classifier loss: 0.379906; batch adversarial loss: 0.553122\n",
      "epoch 114; iter: 0; batch classifier loss: 0.317023; batch adversarial loss: 0.508632\n",
      "epoch 115; iter: 0; batch classifier loss: 0.315363; batch adversarial loss: 0.580856\n",
      "epoch 116; iter: 0; batch classifier loss: 0.395337; batch adversarial loss: 0.500049\n",
      "epoch 117; iter: 0; batch classifier loss: 0.434078; batch adversarial loss: 0.580636\n",
      "epoch 118; iter: 0; batch classifier loss: 0.348722; batch adversarial loss: 0.517612\n",
      "epoch 119; iter: 0; batch classifier loss: 0.370987; batch adversarial loss: 0.562499\n",
      "epoch 120; iter: 0; batch classifier loss: 0.351986; batch adversarial loss: 0.535254\n",
      "epoch 121; iter: 0; batch classifier loss: 0.369456; batch adversarial loss: 0.598036\n",
      "epoch 122; iter: 0; batch classifier loss: 0.361271; batch adversarial loss: 0.473503\n",
      "epoch 123; iter: 0; batch classifier loss: 0.421467; batch adversarial loss: 0.499815\n",
      "epoch 124; iter: 0; batch classifier loss: 0.338114; batch adversarial loss: 0.562270\n",
      "epoch 125; iter: 0; batch classifier loss: 0.375517; batch adversarial loss: 0.589314\n",
      "epoch 126; iter: 0; batch classifier loss: 0.370248; batch adversarial loss: 0.526735\n",
      "epoch 127; iter: 0; batch classifier loss: 0.343049; batch adversarial loss: 0.544408\n",
      "epoch 128; iter: 0; batch classifier loss: 0.263641; batch adversarial loss: 0.589488\n",
      "epoch 129; iter: 0; batch classifier loss: 0.428811; batch adversarial loss: 0.580621\n",
      "epoch 130; iter: 0; batch classifier loss: 0.338032; batch adversarial loss: 0.562588\n",
      "epoch 131; iter: 0; batch classifier loss: 0.327358; batch adversarial loss: 0.526610\n",
      "epoch 132; iter: 0; batch classifier loss: 0.370497; batch adversarial loss: 0.580498\n",
      "epoch 133; iter: 0; batch classifier loss: 0.365652; batch adversarial loss: 0.562396\n",
      "epoch 134; iter: 0; batch classifier loss: 0.340000; batch adversarial loss: 0.509169\n",
      "epoch 135; iter: 0; batch classifier loss: 0.301143; batch adversarial loss: 0.562499\n",
      "epoch 136; iter: 0; batch classifier loss: 0.293090; batch adversarial loss: 0.598295\n",
      "epoch 137; iter: 0; batch classifier loss: 0.385414; batch adversarial loss: 0.598562\n",
      "epoch 138; iter: 0; batch classifier loss: 0.294312; batch adversarial loss: 0.544651\n",
      "epoch 139; iter: 0; batch classifier loss: 0.313327; batch adversarial loss: 0.598228\n",
      "epoch 140; iter: 0; batch classifier loss: 0.360888; batch adversarial loss: 0.580502\n",
      "epoch 141; iter: 0; batch classifier loss: 0.337156; batch adversarial loss: 0.544599\n",
      "epoch 142; iter: 0; batch classifier loss: 0.415706; batch adversarial loss: 0.580448\n",
      "epoch 143; iter: 0; batch classifier loss: 0.358431; batch adversarial loss: 0.544708\n",
      "epoch 144; iter: 0; batch classifier loss: 0.337441; batch adversarial loss: 0.517858\n",
      "epoch 145; iter: 0; batch classifier loss: 0.397110; batch adversarial loss: 0.535842\n",
      "epoch 146; iter: 0; batch classifier loss: 0.347656; batch adversarial loss: 0.553644\n",
      "epoch 147; iter: 0; batch classifier loss: 0.374355; batch adversarial loss: 0.643468\n",
      "epoch 148; iter: 0; batch classifier loss: 0.423395; batch adversarial loss: 0.526831\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 149; iter: 0; batch classifier loss: 0.409261; batch adversarial loss: 0.526684\n",
      "epoch 150; iter: 0; batch classifier loss: 0.314058; batch adversarial loss: 0.553614\n",
      "epoch 151; iter: 0; batch classifier loss: 0.377293; batch adversarial loss: 0.589398\n",
      "epoch 152; iter: 0; batch classifier loss: 0.316629; batch adversarial loss: 0.589677\n",
      "epoch 153; iter: 0; batch classifier loss: 0.355527; batch adversarial loss: 0.526504\n",
      "epoch 154; iter: 0; batch classifier loss: 0.362459; batch adversarial loss: 0.607450\n",
      "epoch 155; iter: 0; batch classifier loss: 0.311439; batch adversarial loss: 0.535680\n",
      "epoch 156; iter: 0; batch classifier loss: 0.381472; batch adversarial loss: 0.607448\n",
      "epoch 157; iter: 0; batch classifier loss: 0.335438; batch adversarial loss: 0.428120\n",
      "epoch 158; iter: 0; batch classifier loss: 0.382667; batch adversarial loss: 0.526976\n",
      "epoch 159; iter: 0; batch classifier loss: 0.373996; batch adversarial loss: 0.589697\n",
      "epoch 160; iter: 0; batch classifier loss: 0.269253; batch adversarial loss: 0.571225\n",
      "epoch 161; iter: 0; batch classifier loss: 0.336175; batch adversarial loss: 0.517599\n",
      "epoch 162; iter: 0; batch classifier loss: 0.335175; batch adversarial loss: 0.490932\n",
      "epoch 163; iter: 0; batch classifier loss: 0.377995; batch adversarial loss: 0.508770\n",
      "epoch 164; iter: 0; batch classifier loss: 0.359893; batch adversarial loss: 0.499818\n",
      "epoch 165; iter: 0; batch classifier loss: 0.318053; batch adversarial loss: 0.625237\n",
      "epoch 166; iter: 0; batch classifier loss: 0.289721; batch adversarial loss: 0.527113\n",
      "epoch 167; iter: 0; batch classifier loss: 0.299177; batch adversarial loss: 0.526622\n",
      "epoch 168; iter: 0; batch classifier loss: 0.401813; batch adversarial loss: 0.545051\n",
      "epoch 169; iter: 0; batch classifier loss: 0.329204; batch adversarial loss: 0.625468\n",
      "epoch 170; iter: 0; batch classifier loss: 0.306403; batch adversarial loss: 0.527192\n",
      "epoch 171; iter: 0; batch classifier loss: 0.441392; batch adversarial loss: 0.544667\n",
      "epoch 172; iter: 0; batch classifier loss: 0.404878; batch adversarial loss: 0.481988\n",
      "epoch 173; iter: 0; batch classifier loss: 0.401908; batch adversarial loss: 0.499876\n",
      "epoch 174; iter: 0; batch classifier loss: 0.289401; batch adversarial loss: 0.535864\n",
      "epoch 175; iter: 0; batch classifier loss: 0.294063; batch adversarial loss: 0.517925\n",
      "epoch 176; iter: 0; batch classifier loss: 0.348436; batch adversarial loss: 0.607179\n",
      "epoch 177; iter: 0; batch classifier loss: 0.313415; batch adversarial loss: 0.553669\n",
      "epoch 178; iter: 0; batch classifier loss: 0.326869; batch adversarial loss: 0.571232\n",
      "epoch 179; iter: 0; batch classifier loss: 0.347873; batch adversarial loss: 0.616285\n",
      "epoch 180; iter: 0; batch classifier loss: 0.413995; batch adversarial loss: 0.517703\n",
      "epoch 181; iter: 0; batch classifier loss: 0.272682; batch adversarial loss: 0.598417\n",
      "epoch 182; iter: 0; batch classifier loss: 0.354976; batch adversarial loss: 0.526747\n",
      "epoch 183; iter: 0; batch classifier loss: 0.410350; batch adversarial loss: 0.624885\n",
      "epoch 184; iter: 0; batch classifier loss: 0.332639; batch adversarial loss: 0.562491\n",
      "epoch 185; iter: 0; batch classifier loss: 0.325137; batch adversarial loss: 0.571568\n",
      "epoch 186; iter: 0; batch classifier loss: 0.345800; batch adversarial loss: 0.517628\n",
      "epoch 187; iter: 0; batch classifier loss: 0.295132; batch adversarial loss: 0.553944\n",
      "epoch 188; iter: 0; batch classifier loss: 0.347176; batch adversarial loss: 0.509166\n",
      "epoch 189; iter: 0; batch classifier loss: 0.350282; batch adversarial loss: 0.553633\n",
      "epoch 190; iter: 0; batch classifier loss: 0.333003; batch adversarial loss: 0.508628\n",
      "epoch 191; iter: 0; batch classifier loss: 0.309402; batch adversarial loss: 0.598328\n",
      "epoch 192; iter: 0; batch classifier loss: 0.348033; batch adversarial loss: 0.544235\n",
      "epoch 193; iter: 0; batch classifier loss: 0.363965; batch adversarial loss: 0.598430\n",
      "epoch 194; iter: 0; batch classifier loss: 0.312960; batch adversarial loss: 0.544867\n",
      "epoch 195; iter: 0; batch classifier loss: 0.354017; batch adversarial loss: 0.571385\n",
      "epoch 196; iter: 0; batch classifier loss: 0.295406; batch adversarial loss: 0.473395\n",
      "epoch 197; iter: 0; batch classifier loss: 0.386323; batch adversarial loss: 0.589413\n",
      "epoch 198; iter: 0; batch classifier loss: 0.324333; batch adversarial loss: 0.580533\n",
      "epoch 199; iter: 0; batch classifier loss: 0.349755; batch adversarial loss: 0.598275\n",
      "epoch 0; iter: 0; batch classifier loss: 0.739778; batch adversarial loss: 0.677133\n",
      "epoch 1; iter: 0; batch classifier loss: 0.567028; batch adversarial loss: 0.664753\n",
      "epoch 2; iter: 0; batch classifier loss: 0.644327; batch adversarial loss: 0.630102\n",
      "epoch 3; iter: 0; batch classifier loss: 0.598925; batch adversarial loss: 0.651471\n",
      "epoch 4; iter: 0; batch classifier loss: 0.583542; batch adversarial loss: 0.612636\n",
      "epoch 5; iter: 0; batch classifier loss: 0.558047; batch adversarial loss: 0.634242\n",
      "epoch 6; iter: 0; batch classifier loss: 0.619784; batch adversarial loss: 0.614526\n",
      "epoch 7; iter: 0; batch classifier loss: 0.603669; batch adversarial loss: 0.599002\n",
      "epoch 8; iter: 0; batch classifier loss: 0.594229; batch adversarial loss: 0.573045\n",
      "epoch 9; iter: 0; batch classifier loss: 0.509324; batch adversarial loss: 0.574164\n",
      "epoch 10; iter: 0; batch classifier loss: 0.544982; batch adversarial loss: 0.578216\n",
      "epoch 11; iter: 0; batch classifier loss: 0.476848; batch adversarial loss: 0.555668\n",
      "epoch 12; iter: 0; batch classifier loss: 0.522859; batch adversarial loss: 0.627185\n",
      "epoch 13; iter: 0; batch classifier loss: 0.530041; batch adversarial loss: 0.506770\n",
      "epoch 14; iter: 0; batch classifier loss: 0.530471; batch adversarial loss: 0.498334\n",
      "epoch 15; iter: 0; batch classifier loss: 0.512382; batch adversarial loss: 0.542085\n",
      "epoch 16; iter: 0; batch classifier loss: 0.580236; batch adversarial loss: 0.561066\n",
      "epoch 17; iter: 0; batch classifier loss: 0.473831; batch adversarial loss: 0.578622\n",
      "epoch 18; iter: 0; batch classifier loss: 0.545995; batch adversarial loss: 0.573725\n",
      "epoch 19; iter: 0; batch classifier loss: 0.521984; batch adversarial loss: 0.533406\n",
      "epoch 20; iter: 0; batch classifier loss: 0.482874; batch adversarial loss: 0.527542\n",
      "epoch 21; iter: 0; batch classifier loss: 0.485003; batch adversarial loss: 0.591933\n",
      "epoch 22; iter: 0; batch classifier loss: 0.554086; batch adversarial loss: 0.546633\n",
      "epoch 23; iter: 0; batch classifier loss: 0.440998; batch adversarial loss: 0.580419\n",
      "epoch 24; iter: 0; batch classifier loss: 0.486508; batch adversarial loss: 0.556041\n",
      "epoch 25; iter: 0; batch classifier loss: 0.509950; batch adversarial loss: 0.582209\n",
      "epoch 26; iter: 0; batch classifier loss: 0.466692; batch adversarial loss: 0.548816\n",
      "epoch 27; iter: 0; batch classifier loss: 0.472141; batch adversarial loss: 0.523177\n",
      "epoch 28; iter: 0; batch classifier loss: 0.469785; batch adversarial loss: 0.629064\n",
      "epoch 29; iter: 0; batch classifier loss: 0.574730; batch adversarial loss: 0.513640\n",
      "epoch 30; iter: 0; batch classifier loss: 0.457564; batch adversarial loss: 0.570749\n",
      "epoch 31; iter: 0; batch classifier loss: 0.454661; batch adversarial loss: 0.604676\n",
      "epoch 32; iter: 0; batch classifier loss: 0.493234; batch adversarial loss: 0.495087\n",
      "epoch 33; iter: 0; batch classifier loss: 0.422031; batch adversarial loss: 0.519579\n",
      "epoch 34; iter: 0; batch classifier loss: 0.442103; batch adversarial loss: 0.579603\n",
      "epoch 35; iter: 0; batch classifier loss: 0.430279; batch adversarial loss: 0.571044\n",
      "epoch 36; iter: 0; batch classifier loss: 0.447159; batch adversarial loss: 0.614493\n",
      "epoch 37; iter: 0; batch classifier loss: 0.468890; batch adversarial loss: 0.544871\n",
      "epoch 38; iter: 0; batch classifier loss: 0.434998; batch adversarial loss: 0.588853\n",
      "epoch 39; iter: 0; batch classifier loss: 0.443016; batch adversarial loss: 0.554037\n",
      "epoch 40; iter: 0; batch classifier loss: 0.458109; batch adversarial loss: 0.499357\n",
      "epoch 41; iter: 0; batch classifier loss: 0.470831; batch adversarial loss: 0.544780\n",
      "epoch 42; iter: 0; batch classifier loss: 0.475048; batch adversarial loss: 0.544375\n",
      "epoch 43; iter: 0; batch classifier loss: 0.495953; batch adversarial loss: 0.482275\n",
      "epoch 44; iter: 0; batch classifier loss: 0.428878; batch adversarial loss: 0.589888\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 45; iter: 0; batch classifier loss: 0.407574; batch adversarial loss: 0.535784\n",
      "epoch 46; iter: 0; batch classifier loss: 0.462333; batch adversarial loss: 0.572395\n",
      "epoch 47; iter: 0; batch classifier loss: 0.368300; batch adversarial loss: 0.525586\n",
      "epoch 48; iter: 0; batch classifier loss: 0.440096; batch adversarial loss: 0.552384\n",
      "epoch 49; iter: 0; batch classifier loss: 0.458514; batch adversarial loss: 0.617260\n",
      "epoch 50; iter: 0; batch classifier loss: 0.480854; batch adversarial loss: 0.527465\n",
      "epoch 51; iter: 0; batch classifier loss: 0.428085; batch adversarial loss: 0.523919\n",
      "epoch 52; iter: 0; batch classifier loss: 0.407545; batch adversarial loss: 0.570279\n",
      "epoch 53; iter: 0; batch classifier loss: 0.480800; batch adversarial loss: 0.543990\n",
      "epoch 54; iter: 0; batch classifier loss: 0.467622; batch adversarial loss: 0.551461\n",
      "epoch 55; iter: 0; batch classifier loss: 0.382519; batch adversarial loss: 0.554301\n",
      "epoch 56; iter: 0; batch classifier loss: 0.394975; batch adversarial loss: 0.544960\n",
      "epoch 57; iter: 0; batch classifier loss: 0.390682; batch adversarial loss: 0.473922\n",
      "epoch 58; iter: 0; batch classifier loss: 0.442636; batch adversarial loss: 0.571355\n",
      "epoch 59; iter: 0; batch classifier loss: 0.392959; batch adversarial loss: 0.462825\n",
      "epoch 60; iter: 0; batch classifier loss: 0.425693; batch adversarial loss: 0.555512\n",
      "epoch 61; iter: 0; batch classifier loss: 0.421831; batch adversarial loss: 0.579183\n",
      "epoch 62; iter: 0; batch classifier loss: 0.385711; batch adversarial loss: 0.546079\n",
      "epoch 63; iter: 0; batch classifier loss: 0.400680; batch adversarial loss: 0.445656\n",
      "epoch 64; iter: 0; batch classifier loss: 0.438455; batch adversarial loss: 0.567727\n",
      "epoch 65; iter: 0; batch classifier loss: 0.481056; batch adversarial loss: 0.516807\n",
      "epoch 66; iter: 0; batch classifier loss: 0.294410; batch adversarial loss: 0.527604\n",
      "epoch 67; iter: 0; batch classifier loss: 0.445546; batch adversarial loss: 0.626329\n",
      "epoch 68; iter: 0; batch classifier loss: 0.445873; batch adversarial loss: 0.578481\n",
      "epoch 69; iter: 0; batch classifier loss: 0.427685; batch adversarial loss: 0.506613\n",
      "epoch 70; iter: 0; batch classifier loss: 0.405822; batch adversarial loss: 0.545199\n",
      "epoch 71; iter: 0; batch classifier loss: 0.402543; batch adversarial loss: 0.526144\n",
      "epoch 72; iter: 0; batch classifier loss: 0.480584; batch adversarial loss: 0.516114\n",
      "epoch 73; iter: 0; batch classifier loss: 0.440473; batch adversarial loss: 0.561739\n",
      "epoch 74; iter: 0; batch classifier loss: 0.414594; batch adversarial loss: 0.496369\n",
      "epoch 75; iter: 0; batch classifier loss: 0.426561; batch adversarial loss: 0.532015\n",
      "epoch 76; iter: 0; batch classifier loss: 0.335241; batch adversarial loss: 0.527818\n",
      "epoch 77; iter: 0; batch classifier loss: 0.390689; batch adversarial loss: 0.561675\n",
      "epoch 78; iter: 0; batch classifier loss: 0.504149; batch adversarial loss: 0.553810\n",
      "epoch 79; iter: 0; batch classifier loss: 0.396634; batch adversarial loss: 0.552139\n",
      "epoch 80; iter: 0; batch classifier loss: 0.428654; batch adversarial loss: 0.556113\n",
      "epoch 81; iter: 0; batch classifier loss: 0.407139; batch adversarial loss: 0.573895\n",
      "epoch 82; iter: 0; batch classifier loss: 0.398954; batch adversarial loss: 0.546327\n",
      "epoch 83; iter: 0; batch classifier loss: 0.400588; batch adversarial loss: 0.574319\n",
      "epoch 84; iter: 0; batch classifier loss: 0.392857; batch adversarial loss: 0.542485\n",
      "epoch 85; iter: 0; batch classifier loss: 0.438626; batch adversarial loss: 0.620687\n",
      "epoch 86; iter: 0; batch classifier loss: 0.495297; batch adversarial loss: 0.560492\n",
      "epoch 87; iter: 0; batch classifier loss: 0.412183; batch adversarial loss: 0.550897\n",
      "epoch 88; iter: 0; batch classifier loss: 0.353466; batch adversarial loss: 0.533178\n",
      "epoch 89; iter: 0; batch classifier loss: 0.335343; batch adversarial loss: 0.516553\n",
      "epoch 90; iter: 0; batch classifier loss: 0.479164; batch adversarial loss: 0.604792\n",
      "epoch 91; iter: 0; batch classifier loss: 0.456900; batch adversarial loss: 0.517649\n",
      "epoch 92; iter: 0; batch classifier loss: 0.523292; batch adversarial loss: 0.572863\n",
      "epoch 93; iter: 0; batch classifier loss: 0.371514; batch adversarial loss: 0.600423\n",
      "epoch 94; iter: 0; batch classifier loss: 0.398788; batch adversarial loss: 0.535047\n",
      "epoch 95; iter: 0; batch classifier loss: 0.365577; batch adversarial loss: 0.616075\n",
      "epoch 96; iter: 0; batch classifier loss: 0.428563; batch adversarial loss: 0.516992\n",
      "epoch 97; iter: 0; batch classifier loss: 0.375141; batch adversarial loss: 0.526341\n",
      "epoch 98; iter: 0; batch classifier loss: 0.376123; batch adversarial loss: 0.580882\n",
      "epoch 99; iter: 0; batch classifier loss: 0.387803; batch adversarial loss: 0.480669\n",
      "epoch 100; iter: 0; batch classifier loss: 0.334733; batch adversarial loss: 0.607900\n",
      "epoch 101; iter: 0; batch classifier loss: 0.451040; batch adversarial loss: 0.535702\n",
      "epoch 102; iter: 0; batch classifier loss: 0.397617; batch adversarial loss: 0.552624\n",
      "epoch 103; iter: 0; batch classifier loss: 0.423637; batch adversarial loss: 0.519293\n",
      "epoch 104; iter: 0; batch classifier loss: 0.286171; batch adversarial loss: 0.571776\n",
      "epoch 105; iter: 0; batch classifier loss: 0.433686; batch adversarial loss: 0.590989\n",
      "epoch 106; iter: 0; batch classifier loss: 0.380552; batch adversarial loss: 0.498334\n",
      "epoch 107; iter: 0; batch classifier loss: 0.375665; batch adversarial loss: 0.535398\n",
      "epoch 108; iter: 0; batch classifier loss: 0.385624; batch adversarial loss: 0.603847\n",
      "epoch 109; iter: 0; batch classifier loss: 0.415532; batch adversarial loss: 0.535696\n",
      "epoch 110; iter: 0; batch classifier loss: 0.424435; batch adversarial loss: 0.541827\n",
      "epoch 111; iter: 0; batch classifier loss: 0.349233; batch adversarial loss: 0.553779\n",
      "epoch 112; iter: 0; batch classifier loss: 0.413870; batch adversarial loss: 0.561800\n",
      "epoch 113; iter: 0; batch classifier loss: 0.362731; batch adversarial loss: 0.598774\n",
      "epoch 114; iter: 0; batch classifier loss: 0.321862; batch adversarial loss: 0.606490\n",
      "epoch 115; iter: 0; batch classifier loss: 0.370922; batch adversarial loss: 0.579084\n",
      "epoch 116; iter: 0; batch classifier loss: 0.391640; batch adversarial loss: 0.583532\n",
      "epoch 117; iter: 0; batch classifier loss: 0.443524; batch adversarial loss: 0.608405\n",
      "epoch 118; iter: 0; batch classifier loss: 0.362064; batch adversarial loss: 0.468638\n",
      "epoch 119; iter: 0; batch classifier loss: 0.381552; batch adversarial loss: 0.514862\n",
      "epoch 120; iter: 0; batch classifier loss: 0.368938; batch adversarial loss: 0.561977\n",
      "epoch 121; iter: 0; batch classifier loss: 0.327747; batch adversarial loss: 0.541349\n",
      "epoch 122; iter: 0; batch classifier loss: 0.382606; batch adversarial loss: 0.506697\n",
      "epoch 123; iter: 0; batch classifier loss: 0.404549; batch adversarial loss: 0.465974\n",
      "epoch 124; iter: 0; batch classifier loss: 0.393037; batch adversarial loss: 0.591704\n",
      "epoch 125; iter: 0; batch classifier loss: 0.464080; batch adversarial loss: 0.531890\n",
      "epoch 126; iter: 0; batch classifier loss: 0.314207; batch adversarial loss: 0.509969\n",
      "epoch 127; iter: 0; batch classifier loss: 0.449639; batch adversarial loss: 0.593216\n",
      "epoch 128; iter: 0; batch classifier loss: 0.376786; batch adversarial loss: 0.537303\n",
      "epoch 129; iter: 0; batch classifier loss: 0.379530; batch adversarial loss: 0.507279\n",
      "epoch 130; iter: 0; batch classifier loss: 0.364920; batch adversarial loss: 0.551587\n",
      "epoch 131; iter: 0; batch classifier loss: 0.361497; batch adversarial loss: 0.635714\n",
      "epoch 132; iter: 0; batch classifier loss: 0.345026; batch adversarial loss: 0.497128\n",
      "epoch 133; iter: 0; batch classifier loss: 0.381931; batch adversarial loss: 0.506159\n",
      "epoch 134; iter: 0; batch classifier loss: 0.375075; batch adversarial loss: 0.590103\n",
      "epoch 135; iter: 0; batch classifier loss: 0.441647; batch adversarial loss: 0.553792\n",
      "epoch 136; iter: 0; batch classifier loss: 0.352232; batch adversarial loss: 0.560968\n",
      "epoch 137; iter: 0; batch classifier loss: 0.435961; batch adversarial loss: 0.535396\n",
      "epoch 138; iter: 0; batch classifier loss: 0.446911; batch adversarial loss: 0.600175\n",
      "epoch 139; iter: 0; batch classifier loss: 0.358607; batch adversarial loss: 0.562952\n",
      "epoch 140; iter: 0; batch classifier loss: 0.313614; batch adversarial loss: 0.597153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 141; iter: 0; batch classifier loss: 0.310644; batch adversarial loss: 0.535157\n",
      "epoch 142; iter: 0; batch classifier loss: 0.359166; batch adversarial loss: 0.526295\n",
      "epoch 143; iter: 0; batch classifier loss: 0.341437; batch adversarial loss: 0.554956\n",
      "epoch 144; iter: 0; batch classifier loss: 0.375546; batch adversarial loss: 0.508256\n",
      "epoch 145; iter: 0; batch classifier loss: 0.405525; batch adversarial loss: 0.579239\n",
      "epoch 146; iter: 0; batch classifier loss: 0.370814; batch adversarial loss: 0.640250\n",
      "epoch 147; iter: 0; batch classifier loss: 0.361975; batch adversarial loss: 0.576140\n",
      "epoch 148; iter: 0; batch classifier loss: 0.362186; batch adversarial loss: 0.578639\n",
      "epoch 149; iter: 0; batch classifier loss: 0.343241; batch adversarial loss: 0.569052\n",
      "epoch 150; iter: 0; batch classifier loss: 0.399161; batch adversarial loss: 0.541738\n",
      "epoch 151; iter: 0; batch classifier loss: 0.423235; batch adversarial loss: 0.600942\n",
      "epoch 152; iter: 0; batch classifier loss: 0.416821; batch adversarial loss: 0.539394\n",
      "epoch 153; iter: 0; batch classifier loss: 0.302559; batch adversarial loss: 0.578573\n",
      "epoch 154; iter: 0; batch classifier loss: 0.406045; batch adversarial loss: 0.507861\n",
      "epoch 155; iter: 0; batch classifier loss: 0.383005; batch adversarial loss: 0.642244\n",
      "epoch 156; iter: 0; batch classifier loss: 0.496690; batch adversarial loss: 0.546053\n",
      "epoch 157; iter: 0; batch classifier loss: 0.375029; batch adversarial loss: 0.516820\n",
      "epoch 158; iter: 0; batch classifier loss: 0.369812; batch adversarial loss: 0.559669\n",
      "epoch 159; iter: 0; batch classifier loss: 0.426262; batch adversarial loss: 0.553141\n",
      "epoch 160; iter: 0; batch classifier loss: 0.348971; batch adversarial loss: 0.627868\n",
      "epoch 161; iter: 0; batch classifier loss: 0.397373; batch adversarial loss: 0.481143\n",
      "epoch 162; iter: 0; batch classifier loss: 0.411980; batch adversarial loss: 0.554699\n",
      "epoch 163; iter: 0; batch classifier loss: 0.402848; batch adversarial loss: 0.583045\n",
      "epoch 164; iter: 0; batch classifier loss: 0.397360; batch adversarial loss: 0.542978\n",
      "epoch 165; iter: 0; batch classifier loss: 0.382894; batch adversarial loss: 0.526412\n",
      "epoch 166; iter: 0; batch classifier loss: 0.380475; batch adversarial loss: 0.616367\n",
      "epoch 167; iter: 0; batch classifier loss: 0.399094; batch adversarial loss: 0.562507\n",
      "epoch 168; iter: 0; batch classifier loss: 0.393624; batch adversarial loss: 0.533720\n",
      "epoch 169; iter: 0; batch classifier loss: 0.347255; batch adversarial loss: 0.620695\n",
      "epoch 170; iter: 0; batch classifier loss: 0.330670; batch adversarial loss: 0.517532\n",
      "epoch 171; iter: 0; batch classifier loss: 0.379722; batch adversarial loss: 0.526540\n",
      "epoch 172; iter: 0; batch classifier loss: 0.395548; batch adversarial loss: 0.550458\n",
      "epoch 173; iter: 0; batch classifier loss: 0.375407; batch adversarial loss: 0.616533\n",
      "epoch 174; iter: 0; batch classifier loss: 0.390342; batch adversarial loss: 0.498719\n",
      "epoch 175; iter: 0; batch classifier loss: 0.356216; batch adversarial loss: 0.643012\n",
      "epoch 176; iter: 0; batch classifier loss: 0.370540; batch adversarial loss: 0.533054\n",
      "epoch 177; iter: 0; batch classifier loss: 0.355797; batch adversarial loss: 0.667926\n",
      "epoch 178; iter: 0; batch classifier loss: 0.446051; batch adversarial loss: 0.566537\n",
      "epoch 179; iter: 0; batch classifier loss: 0.364407; batch adversarial loss: 0.555051\n",
      "epoch 180; iter: 0; batch classifier loss: 0.415576; batch adversarial loss: 0.536865\n",
      "epoch 181; iter: 0; batch classifier loss: 0.421641; batch adversarial loss: 0.587817\n",
      "epoch 182; iter: 0; batch classifier loss: 0.397363; batch adversarial loss: 0.551929\n",
      "epoch 183; iter: 0; batch classifier loss: 0.397681; batch adversarial loss: 0.504069\n",
      "epoch 184; iter: 0; batch classifier loss: 0.386374; batch adversarial loss: 0.496909\n",
      "epoch 185; iter: 0; batch classifier loss: 0.411035; batch adversarial loss: 0.571554\n",
      "epoch 186; iter: 0; batch classifier loss: 0.322594; batch adversarial loss: 0.584646\n",
      "epoch 187; iter: 0; batch classifier loss: 0.407720; batch adversarial loss: 0.625292\n",
      "epoch 188; iter: 0; batch classifier loss: 0.392792; batch adversarial loss: 0.599077\n",
      "epoch 189; iter: 0; batch classifier loss: 0.360834; batch adversarial loss: 0.615221\n",
      "epoch 190; iter: 0; batch classifier loss: 0.329698; batch adversarial loss: 0.550675\n",
      "epoch 191; iter: 0; batch classifier loss: 0.379562; batch adversarial loss: 0.554281\n",
      "epoch 192; iter: 0; batch classifier loss: 0.318273; batch adversarial loss: 0.561136\n",
      "epoch 193; iter: 0; batch classifier loss: 0.460583; batch adversarial loss: 0.572498\n",
      "epoch 194; iter: 0; batch classifier loss: 0.356706; batch adversarial loss: 0.596442\n",
      "epoch 195; iter: 0; batch classifier loss: 0.373426; batch adversarial loss: 0.562553\n",
      "epoch 196; iter: 0; batch classifier loss: 0.382180; batch adversarial loss: 0.626555\n",
      "epoch 197; iter: 0; batch classifier loss: 0.301175; batch adversarial loss: 0.562447\n",
      "epoch 198; iter: 0; batch classifier loss: 0.357663; batch adversarial loss: 0.491320\n",
      "epoch 199; iter: 0; batch classifier loss: 0.407089; batch adversarial loss: 0.528497\n",
      "epoch 0; iter: 0; batch classifier loss: 0.696052; batch adversarial loss: 0.589487\n",
      "epoch 1; iter: 0; batch classifier loss: 0.609245; batch adversarial loss: 0.638909\n",
      "epoch 2; iter: 0; batch classifier loss: 0.624063; batch adversarial loss: 0.639866\n",
      "epoch 3; iter: 0; batch classifier loss: 0.573822; batch adversarial loss: 0.653072\n",
      "epoch 4; iter: 0; batch classifier loss: 0.562632; batch adversarial loss: 0.682597\n",
      "epoch 5; iter: 0; batch classifier loss: 0.534865; batch adversarial loss: 0.610442\n",
      "epoch 6; iter: 0; batch classifier loss: 0.549271; batch adversarial loss: 0.572347\n",
      "epoch 7; iter: 0; batch classifier loss: 0.522074; batch adversarial loss: 0.577548\n",
      "epoch 8; iter: 0; batch classifier loss: 0.593402; batch adversarial loss: 0.591455\n",
      "epoch 9; iter: 0; batch classifier loss: 0.602836; batch adversarial loss: 0.585769\n",
      "epoch 10; iter: 0; batch classifier loss: 0.504404; batch adversarial loss: 0.568007\n",
      "epoch 11; iter: 0; batch classifier loss: 0.554301; batch adversarial loss: 0.584415\n",
      "epoch 12; iter: 0; batch classifier loss: 0.475921; batch adversarial loss: 0.603043\n",
      "epoch 13; iter: 0; batch classifier loss: 0.619574; batch adversarial loss: 0.557335\n",
      "epoch 14; iter: 0; batch classifier loss: 0.532875; batch adversarial loss: 0.548662\n",
      "epoch 15; iter: 0; batch classifier loss: 0.498071; batch adversarial loss: 0.555988\n",
      "epoch 16; iter: 0; batch classifier loss: 0.477352; batch adversarial loss: 0.574744\n",
      "epoch 17; iter: 0; batch classifier loss: 0.470984; batch adversarial loss: 0.574102\n",
      "epoch 18; iter: 0; batch classifier loss: 0.459870; batch adversarial loss: 0.543985\n",
      "epoch 19; iter: 0; batch classifier loss: 0.439770; batch adversarial loss: 0.602437\n",
      "epoch 20; iter: 0; batch classifier loss: 0.532044; batch adversarial loss: 0.502397\n",
      "epoch 21; iter: 0; batch classifier loss: 0.447280; batch adversarial loss: 0.571529\n",
      "epoch 22; iter: 0; batch classifier loss: 0.421952; batch adversarial loss: 0.538680\n",
      "epoch 23; iter: 0; batch classifier loss: 0.509027; batch adversarial loss: 0.595252\n",
      "epoch 24; iter: 0; batch classifier loss: 0.455467; batch adversarial loss: 0.612557\n",
      "epoch 25; iter: 0; batch classifier loss: 0.532395; batch adversarial loss: 0.613449\n",
      "epoch 26; iter: 0; batch classifier loss: 0.464877; batch adversarial loss: 0.605158\n",
      "epoch 27; iter: 0; batch classifier loss: 0.440849; batch adversarial loss: 0.579391\n",
      "epoch 28; iter: 0; batch classifier loss: 0.355336; batch adversarial loss: 0.518000\n",
      "epoch 29; iter: 0; batch classifier loss: 0.405180; batch adversarial loss: 0.552045\n",
      "epoch 30; iter: 0; batch classifier loss: 0.538203; batch adversarial loss: 0.518954\n",
      "epoch 31; iter: 0; batch classifier loss: 0.436727; batch adversarial loss: 0.623970\n",
      "epoch 32; iter: 0; batch classifier loss: 0.525928; batch adversarial loss: 0.528033\n",
      "epoch 33; iter: 0; batch classifier loss: 0.429920; batch adversarial loss: 0.509466\n",
      "epoch 34; iter: 0; batch classifier loss: 0.416990; batch adversarial loss: 0.491311\n",
      "epoch 35; iter: 0; batch classifier loss: 0.508977; batch adversarial loss: 0.471396\n",
      "epoch 36; iter: 0; batch classifier loss: 0.444041; batch adversarial loss: 0.553225\n",
      "epoch 37; iter: 0; batch classifier loss: 0.418764; batch adversarial loss: 0.562774\n",
      "epoch 38; iter: 0; batch classifier loss: 0.427713; batch adversarial loss: 0.631265\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 39; iter: 0; batch classifier loss: 0.483327; batch adversarial loss: 0.571503\n",
      "epoch 40; iter: 0; batch classifier loss: 0.463688; batch adversarial loss: 0.565623\n",
      "epoch 41; iter: 0; batch classifier loss: 0.447997; batch adversarial loss: 0.493022\n",
      "epoch 42; iter: 0; batch classifier loss: 0.543721; batch adversarial loss: 0.521415\n",
      "epoch 43; iter: 0; batch classifier loss: 0.384813; batch adversarial loss: 0.508891\n",
      "epoch 44; iter: 0; batch classifier loss: 0.405475; batch adversarial loss: 0.567303\n",
      "epoch 45; iter: 0; batch classifier loss: 0.498296; batch adversarial loss: 0.590395\n",
      "epoch 46; iter: 0; batch classifier loss: 0.367437; batch adversarial loss: 0.521555\n",
      "epoch 47; iter: 0; batch classifier loss: 0.435082; batch adversarial loss: 0.556331\n",
      "epoch 48; iter: 0; batch classifier loss: 0.405766; batch adversarial loss: 0.517056\n",
      "epoch 49; iter: 0; batch classifier loss: 0.358599; batch adversarial loss: 0.490034\n",
      "epoch 50; iter: 0; batch classifier loss: 0.419410; batch adversarial loss: 0.514200\n",
      "epoch 51; iter: 0; batch classifier loss: 0.440067; batch adversarial loss: 0.531943\n",
      "epoch 52; iter: 0; batch classifier loss: 0.471111; batch adversarial loss: 0.481338\n",
      "epoch 53; iter: 0; batch classifier loss: 0.425288; batch adversarial loss: 0.540620\n",
      "epoch 54; iter: 0; batch classifier loss: 0.446583; batch adversarial loss: 0.564789\n",
      "epoch 55; iter: 0; batch classifier loss: 0.449636; batch adversarial loss: 0.618571\n",
      "epoch 56; iter: 0; batch classifier loss: 0.434555; batch adversarial loss: 0.513358\n",
      "epoch 57; iter: 0; batch classifier loss: 0.395038; batch adversarial loss: 0.561168\n",
      "epoch 58; iter: 0; batch classifier loss: 0.413453; batch adversarial loss: 0.559519\n",
      "epoch 59; iter: 0; batch classifier loss: 0.406139; batch adversarial loss: 0.540649\n",
      "epoch 60; iter: 0; batch classifier loss: 0.374683; batch adversarial loss: 0.504237\n",
      "epoch 61; iter: 0; batch classifier loss: 0.352647; batch adversarial loss: 0.558113\n",
      "epoch 62; iter: 0; batch classifier loss: 0.511183; batch adversarial loss: 0.553776\n",
      "epoch 63; iter: 0; batch classifier loss: 0.414950; batch adversarial loss: 0.517250\n",
      "epoch 64; iter: 0; batch classifier loss: 0.408965; batch adversarial loss: 0.541691\n",
      "epoch 65; iter: 0; batch classifier loss: 0.516518; batch adversarial loss: 0.583890\n",
      "epoch 66; iter: 0; batch classifier loss: 0.443569; batch adversarial loss: 0.477986\n",
      "epoch 67; iter: 0; batch classifier loss: 0.364228; batch adversarial loss: 0.505803\n",
      "epoch 68; iter: 0; batch classifier loss: 0.376115; batch adversarial loss: 0.479244\n",
      "epoch 69; iter: 0; batch classifier loss: 0.396692; batch adversarial loss: 0.486564\n",
      "epoch 70; iter: 0; batch classifier loss: 0.382859; batch adversarial loss: 0.577239\n",
      "epoch 71; iter: 0; batch classifier loss: 0.391803; batch adversarial loss: 0.555182\n",
      "epoch 72; iter: 0; batch classifier loss: 0.395849; batch adversarial loss: 0.518136\n",
      "epoch 73; iter: 0; batch classifier loss: 0.424705; batch adversarial loss: 0.565460\n",
      "epoch 74; iter: 0; batch classifier loss: 0.411083; batch adversarial loss: 0.596408\n",
      "epoch 75; iter: 0; batch classifier loss: 0.329956; batch adversarial loss: 0.569762\n",
      "epoch 76; iter: 0; batch classifier loss: 0.402505; batch adversarial loss: 0.505076\n",
      "epoch 77; iter: 0; batch classifier loss: 0.441189; batch adversarial loss: 0.509627\n",
      "epoch 78; iter: 0; batch classifier loss: 0.379197; batch adversarial loss: 0.580007\n",
      "epoch 79; iter: 0; batch classifier loss: 0.403665; batch adversarial loss: 0.629081\n",
      "epoch 80; iter: 0; batch classifier loss: 0.483856; batch adversarial loss: 0.459236\n",
      "epoch 81; iter: 0; batch classifier loss: 0.373065; batch adversarial loss: 0.601602\n",
      "epoch 82; iter: 0; batch classifier loss: 0.387046; batch adversarial loss: 0.522089\n",
      "epoch 83; iter: 0; batch classifier loss: 0.346220; batch adversarial loss: 0.484055\n",
      "epoch 84; iter: 0; batch classifier loss: 0.342870; batch adversarial loss: 0.535902\n",
      "epoch 85; iter: 0; batch classifier loss: 0.407022; batch adversarial loss: 0.582115\n",
      "epoch 86; iter: 0; batch classifier loss: 0.382066; batch adversarial loss: 0.574575\n",
      "epoch 87; iter: 0; batch classifier loss: 0.368742; batch adversarial loss: 0.604194\n",
      "epoch 88; iter: 0; batch classifier loss: 0.398919; batch adversarial loss: 0.530309\n",
      "epoch 89; iter: 0; batch classifier loss: 0.351665; batch adversarial loss: 0.515005\n",
      "epoch 90; iter: 0; batch classifier loss: 0.466249; batch adversarial loss: 0.507398\n",
      "epoch 91; iter: 0; batch classifier loss: 0.366633; batch adversarial loss: 0.506653\n",
      "epoch 92; iter: 0; batch classifier loss: 0.327846; batch adversarial loss: 0.579679\n",
      "epoch 93; iter: 0; batch classifier loss: 0.253291; batch adversarial loss: 0.548132\n",
      "epoch 94; iter: 0; batch classifier loss: 0.359478; batch adversarial loss: 0.553877\n",
      "epoch 95; iter: 0; batch classifier loss: 0.400088; batch adversarial loss: 0.525205\n",
      "epoch 96; iter: 0; batch classifier loss: 0.395836; batch adversarial loss: 0.551601\n",
      "epoch 97; iter: 0; batch classifier loss: 0.370345; batch adversarial loss: 0.592123\n",
      "epoch 98; iter: 0; batch classifier loss: 0.390839; batch adversarial loss: 0.518148\n",
      "epoch 99; iter: 0; batch classifier loss: 0.423282; batch adversarial loss: 0.483084\n",
      "epoch 100; iter: 0; batch classifier loss: 0.358730; batch adversarial loss: 0.518734\n",
      "epoch 101; iter: 0; batch classifier loss: 0.372674; batch adversarial loss: 0.523578\n",
      "epoch 102; iter: 0; batch classifier loss: 0.417909; batch adversarial loss: 0.499120\n",
      "epoch 103; iter: 0; batch classifier loss: 0.423507; batch adversarial loss: 0.582895\n",
      "epoch 104; iter: 0; batch classifier loss: 0.447693; batch adversarial loss: 0.591049\n",
      "epoch 105; iter: 0; batch classifier loss: 0.363438; batch adversarial loss: 0.573686\n",
      "epoch 106; iter: 0; batch classifier loss: 0.524831; batch adversarial loss: 0.508092\n",
      "epoch 107; iter: 0; batch classifier loss: 0.373721; batch adversarial loss: 0.666059\n",
      "epoch 108; iter: 0; batch classifier loss: 0.381516; batch adversarial loss: 0.569220\n",
      "epoch 109; iter: 0; batch classifier loss: 0.340559; batch adversarial loss: 0.552035\n",
      "epoch 110; iter: 0; batch classifier loss: 0.362262; batch adversarial loss: 0.582127\n",
      "epoch 111; iter: 0; batch classifier loss: 0.426184; batch adversarial loss: 0.565924\n",
      "epoch 112; iter: 0; batch classifier loss: 0.389261; batch adversarial loss: 0.614102\n",
      "epoch 113; iter: 0; batch classifier loss: 0.335258; batch adversarial loss: 0.530878\n",
      "epoch 114; iter: 0; batch classifier loss: 0.376382; batch adversarial loss: 0.597960\n",
      "epoch 115; iter: 0; batch classifier loss: 0.358147; batch adversarial loss: 0.536666\n",
      "epoch 116; iter: 0; batch classifier loss: 0.381226; batch adversarial loss: 0.474384\n",
      "epoch 117; iter: 0; batch classifier loss: 0.414205; batch adversarial loss: 0.543607\n",
      "epoch 118; iter: 0; batch classifier loss: 0.373071; batch adversarial loss: 0.507215\n",
      "epoch 119; iter: 0; batch classifier loss: 0.311395; batch adversarial loss: 0.526521\n",
      "epoch 120; iter: 0; batch classifier loss: 0.385770; batch adversarial loss: 0.569195\n",
      "epoch 121; iter: 0; batch classifier loss: 0.388442; batch adversarial loss: 0.515103\n",
      "epoch 122; iter: 0; batch classifier loss: 0.324996; batch adversarial loss: 0.497926\n",
      "epoch 123; iter: 0; batch classifier loss: 0.294602; batch adversarial loss: 0.540497\n",
      "epoch 124; iter: 0; batch classifier loss: 0.331272; batch adversarial loss: 0.602202\n",
      "epoch 125; iter: 0; batch classifier loss: 0.416483; batch adversarial loss: 0.478430\n",
      "epoch 126; iter: 0; batch classifier loss: 0.402500; batch adversarial loss: 0.536982\n",
      "epoch 127; iter: 0; batch classifier loss: 0.336021; batch adversarial loss: 0.518284\n",
      "epoch 128; iter: 0; batch classifier loss: 0.419091; batch adversarial loss: 0.500263\n",
      "epoch 129; iter: 0; batch classifier loss: 0.398079; batch adversarial loss: 0.530489\n",
      "epoch 130; iter: 0; batch classifier loss: 0.370515; batch adversarial loss: 0.591076\n",
      "epoch 131; iter: 0; batch classifier loss: 0.386007; batch adversarial loss: 0.507223\n",
      "epoch 132; iter: 0; batch classifier loss: 0.393079; batch adversarial loss: 0.505451\n",
      "epoch 133; iter: 0; batch classifier loss: 0.414527; batch adversarial loss: 0.493113\n",
      "epoch 134; iter: 0; batch classifier loss: 0.413203; batch adversarial loss: 0.513842\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 135; iter: 0; batch classifier loss: 0.414702; batch adversarial loss: 0.516747\n",
      "epoch 136; iter: 0; batch classifier loss: 0.416125; batch adversarial loss: 0.533705\n",
      "epoch 137; iter: 0; batch classifier loss: 0.375206; batch adversarial loss: 0.511027\n",
      "epoch 138; iter: 0; batch classifier loss: 0.346621; batch adversarial loss: 0.553349\n",
      "epoch 139; iter: 0; batch classifier loss: 0.343790; batch adversarial loss: 0.558470\n",
      "epoch 140; iter: 0; batch classifier loss: 0.323987; batch adversarial loss: 0.547993\n",
      "epoch 141; iter: 0; batch classifier loss: 0.429973; batch adversarial loss: 0.598790\n",
      "epoch 142; iter: 0; batch classifier loss: 0.348884; batch adversarial loss: 0.587896\n",
      "epoch 143; iter: 0; batch classifier loss: 0.328905; batch adversarial loss: 0.508562\n",
      "epoch 144; iter: 0; batch classifier loss: 0.464643; batch adversarial loss: 0.552952\n",
      "epoch 145; iter: 0; batch classifier loss: 0.377525; batch adversarial loss: 0.547322\n",
      "epoch 146; iter: 0; batch classifier loss: 0.367316; batch adversarial loss: 0.577726\n",
      "epoch 147; iter: 0; batch classifier loss: 0.293844; batch adversarial loss: 0.504145\n",
      "epoch 148; iter: 0; batch classifier loss: 0.363568; batch adversarial loss: 0.474105\n",
      "epoch 149; iter: 0; batch classifier loss: 0.314095; batch adversarial loss: 0.505466\n",
      "epoch 150; iter: 0; batch classifier loss: 0.441498; batch adversarial loss: 0.580385\n",
      "epoch 151; iter: 0; batch classifier loss: 0.336042; batch adversarial loss: 0.579740\n",
      "epoch 152; iter: 0; batch classifier loss: 0.379863; batch adversarial loss: 0.508209\n",
      "epoch 153; iter: 0; batch classifier loss: 0.349010; batch adversarial loss: 0.536204\n",
      "epoch 154; iter: 0; batch classifier loss: 0.371225; batch adversarial loss: 0.571184\n",
      "epoch 155; iter: 0; batch classifier loss: 0.379499; batch adversarial loss: 0.595930\n",
      "epoch 156; iter: 0; batch classifier loss: 0.450932; batch adversarial loss: 0.517020\n",
      "epoch 157; iter: 0; batch classifier loss: 0.464199; batch adversarial loss: 0.516665\n",
      "epoch 158; iter: 0; batch classifier loss: 0.450139; batch adversarial loss: 0.574802\n",
      "epoch 159; iter: 0; batch classifier loss: 0.418080; batch adversarial loss: 0.530109\n",
      "epoch 160; iter: 0; batch classifier loss: 0.314460; batch adversarial loss: 0.513793\n",
      "epoch 161; iter: 0; batch classifier loss: 0.385679; batch adversarial loss: 0.591075\n",
      "epoch 162; iter: 0; batch classifier loss: 0.340557; batch adversarial loss: 0.528451\n",
      "epoch 163; iter: 0; batch classifier loss: 0.403331; batch adversarial loss: 0.470483\n",
      "epoch 164; iter: 0; batch classifier loss: 0.373172; batch adversarial loss: 0.492530\n",
      "epoch 165; iter: 0; batch classifier loss: 0.344866; batch adversarial loss: 0.535845\n",
      "epoch 166; iter: 0; batch classifier loss: 0.327003; batch adversarial loss: 0.516479\n",
      "epoch 167; iter: 0; batch classifier loss: 0.360996; batch adversarial loss: 0.563294\n",
      "epoch 168; iter: 0; batch classifier loss: 0.341703; batch adversarial loss: 0.560933\n",
      "epoch 169; iter: 0; batch classifier loss: 0.405101; batch adversarial loss: 0.534683\n",
      "epoch 170; iter: 0; batch classifier loss: 0.296954; batch adversarial loss: 0.458355\n",
      "epoch 171; iter: 0; batch classifier loss: 0.370487; batch adversarial loss: 0.574169\n",
      "epoch 172; iter: 0; batch classifier loss: 0.357729; batch adversarial loss: 0.561598\n",
      "epoch 173; iter: 0; batch classifier loss: 0.333814; batch adversarial loss: 0.521863\n",
      "epoch 174; iter: 0; batch classifier loss: 0.335238; batch adversarial loss: 0.511500\n",
      "epoch 175; iter: 0; batch classifier loss: 0.304063; batch adversarial loss: 0.474322\n",
      "epoch 176; iter: 0; batch classifier loss: 0.314960; batch adversarial loss: 0.540097\n",
      "epoch 177; iter: 0; batch classifier loss: 0.410059; batch adversarial loss: 0.473006\n",
      "epoch 178; iter: 0; batch classifier loss: 0.423174; batch adversarial loss: 0.551834\n",
      "epoch 179; iter: 0; batch classifier loss: 0.456479; batch adversarial loss: 0.556368\n",
      "epoch 180; iter: 0; batch classifier loss: 0.422512; batch adversarial loss: 0.574388\n",
      "epoch 181; iter: 0; batch classifier loss: 0.358204; batch adversarial loss: 0.475956\n",
      "epoch 182; iter: 0; batch classifier loss: 0.445149; batch adversarial loss: 0.575617\n",
      "epoch 183; iter: 0; batch classifier loss: 0.353755; batch adversarial loss: 0.606261\n",
      "epoch 184; iter: 0; batch classifier loss: 0.285918; batch adversarial loss: 0.501125\n",
      "epoch 185; iter: 0; batch classifier loss: 0.360170; batch adversarial loss: 0.530349\n",
      "epoch 186; iter: 0; batch classifier loss: 0.404517; batch adversarial loss: 0.561122\n",
      "epoch 187; iter: 0; batch classifier loss: 0.313725; batch adversarial loss: 0.527798\n",
      "epoch 188; iter: 0; batch classifier loss: 0.342383; batch adversarial loss: 0.569205\n",
      "epoch 189; iter: 0; batch classifier loss: 0.414742; batch adversarial loss: 0.561215\n",
      "epoch 190; iter: 0; batch classifier loss: 0.376920; batch adversarial loss: 0.535816\n",
      "epoch 191; iter: 0; batch classifier loss: 0.432246; batch adversarial loss: 0.508538\n",
      "epoch 192; iter: 0; batch classifier loss: 0.292472; batch adversarial loss: 0.572645\n",
      "epoch 193; iter: 0; batch classifier loss: 0.388446; batch adversarial loss: 0.640996\n",
      "epoch 194; iter: 0; batch classifier loss: 0.405159; batch adversarial loss: 0.562089\n",
      "epoch 195; iter: 0; batch classifier loss: 0.434824; batch adversarial loss: 0.536888\n",
      "epoch 196; iter: 0; batch classifier loss: 0.391955; batch adversarial loss: 0.578906\n",
      "epoch 197; iter: 0; batch classifier loss: 0.353980; batch adversarial loss: 0.560531\n",
      "epoch 198; iter: 0; batch classifier loss: 0.377641; batch adversarial loss: 0.583780\n",
      "epoch 199; iter: 0; batch classifier loss: 0.340207; batch adversarial loss: 0.567552\n",
      "epoch 0; iter: 0; batch classifier loss: 0.718686; batch adversarial loss: 1.112421\n",
      "epoch 1; iter: 0; batch classifier loss: 0.893546; batch adversarial loss: 1.432979\n",
      "epoch 2; iter: 0; batch classifier loss: 1.134556; batch adversarial loss: 1.438325\n",
      "epoch 3; iter: 0; batch classifier loss: 1.259919; batch adversarial loss: 1.379465\n",
      "epoch 4; iter: 0; batch classifier loss: 1.194142; batch adversarial loss: 1.267836\n",
      "epoch 5; iter: 0; batch classifier loss: 1.184881; batch adversarial loss: 1.147981\n",
      "epoch 6; iter: 0; batch classifier loss: 1.353685; batch adversarial loss: 1.103231\n",
      "epoch 7; iter: 0; batch classifier loss: 1.256863; batch adversarial loss: 0.982234\n",
      "epoch 8; iter: 0; batch classifier loss: 1.245430; batch adversarial loss: 0.912782\n",
      "epoch 9; iter: 0; batch classifier loss: 1.195040; batch adversarial loss: 0.850033\n",
      "epoch 10; iter: 0; batch classifier loss: 1.192227; batch adversarial loss: 0.783348\n",
      "epoch 11; iter: 0; batch classifier loss: 0.962498; batch adversarial loss: 0.745003\n",
      "epoch 12; iter: 0; batch classifier loss: 0.860030; batch adversarial loss: 0.707347\n",
      "epoch 13; iter: 0; batch classifier loss: 0.689675; batch adversarial loss: 0.676053\n",
      "epoch 14; iter: 0; batch classifier loss: 0.638316; batch adversarial loss: 0.642104\n",
      "epoch 15; iter: 0; batch classifier loss: 0.561635; batch adversarial loss: 0.636948\n",
      "epoch 16; iter: 0; batch classifier loss: 0.592020; batch adversarial loss: 0.564499\n",
      "epoch 17; iter: 0; batch classifier loss: 0.595810; batch adversarial loss: 0.646220\n",
      "epoch 18; iter: 0; batch classifier loss: 0.514073; batch adversarial loss: 0.599297\n",
      "epoch 19; iter: 0; batch classifier loss: 0.521385; batch adversarial loss: 0.571510\n",
      "epoch 20; iter: 0; batch classifier loss: 0.529247; batch adversarial loss: 0.601913\n",
      "epoch 21; iter: 0; batch classifier loss: 0.565336; batch adversarial loss: 0.510391\n",
      "epoch 22; iter: 0; batch classifier loss: 0.522453; batch adversarial loss: 0.629945\n",
      "epoch 23; iter: 0; batch classifier loss: 0.463618; batch adversarial loss: 0.570145\n",
      "epoch 24; iter: 0; batch classifier loss: 0.532287; batch adversarial loss: 0.590572\n",
      "epoch 25; iter: 0; batch classifier loss: 0.435333; batch adversarial loss: 0.579745\n",
      "epoch 26; iter: 0; batch classifier loss: 0.556096; batch adversarial loss: 0.564814\n",
      "epoch 27; iter: 0; batch classifier loss: 0.405093; batch adversarial loss: 0.569230\n",
      "epoch 28; iter: 0; batch classifier loss: 0.486912; batch adversarial loss: 0.587898\n",
      "epoch 29; iter: 0; batch classifier loss: 0.553537; batch adversarial loss: 0.539917\n",
      "epoch 30; iter: 0; batch classifier loss: 0.440929; batch adversarial loss: 0.632024\n",
      "epoch 31; iter: 0; batch classifier loss: 0.484660; batch adversarial loss: 0.593039\n",
      "epoch 32; iter: 0; batch classifier loss: 0.516574; batch adversarial loss: 0.488640\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 33; iter: 0; batch classifier loss: 0.421979; batch adversarial loss: 0.533386\n",
      "epoch 34; iter: 0; batch classifier loss: 0.449836; batch adversarial loss: 0.535749\n",
      "epoch 35; iter: 0; batch classifier loss: 0.466909; batch adversarial loss: 0.579201\n",
      "epoch 36; iter: 0; batch classifier loss: 0.440240; batch adversarial loss: 0.605441\n",
      "epoch 37; iter: 0; batch classifier loss: 0.512962; batch adversarial loss: 0.557939\n",
      "epoch 38; iter: 0; batch classifier loss: 0.479132; batch adversarial loss: 0.522389\n",
      "epoch 39; iter: 0; batch classifier loss: 0.499030; batch adversarial loss: 0.574010\n",
      "epoch 40; iter: 0; batch classifier loss: 0.453214; batch adversarial loss: 0.505313\n",
      "epoch 41; iter: 0; batch classifier loss: 0.469099; batch adversarial loss: 0.464871\n",
      "epoch 42; iter: 0; batch classifier loss: 0.467400; batch adversarial loss: 0.590255\n",
      "epoch 43; iter: 0; batch classifier loss: 0.471705; batch adversarial loss: 0.536299\n",
      "epoch 44; iter: 0; batch classifier loss: 0.410555; batch adversarial loss: 0.551587\n",
      "epoch 45; iter: 0; batch classifier loss: 0.405132; batch adversarial loss: 0.595150\n",
      "epoch 46; iter: 0; batch classifier loss: 0.415238; batch adversarial loss: 0.645025\n",
      "epoch 47; iter: 0; batch classifier loss: 0.438001; batch adversarial loss: 0.535158\n",
      "epoch 48; iter: 0; batch classifier loss: 0.415420; batch adversarial loss: 0.638065\n",
      "epoch 49; iter: 0; batch classifier loss: 0.446932; batch adversarial loss: 0.500331\n",
      "epoch 50; iter: 0; batch classifier loss: 0.417894; batch adversarial loss: 0.563488\n",
      "epoch 51; iter: 0; batch classifier loss: 0.390830; batch adversarial loss: 0.610677\n",
      "epoch 52; iter: 0; batch classifier loss: 0.407992; batch adversarial loss: 0.551197\n",
      "epoch 53; iter: 0; batch classifier loss: 0.394098; batch adversarial loss: 0.567461\n",
      "epoch 54; iter: 0; batch classifier loss: 0.391924; batch adversarial loss: 0.575661\n",
      "epoch 55; iter: 0; batch classifier loss: 0.400928; batch adversarial loss: 0.583793\n",
      "epoch 56; iter: 0; batch classifier loss: 0.516958; batch adversarial loss: 0.601606\n",
      "epoch 57; iter: 0; batch classifier loss: 0.453098; batch adversarial loss: 0.639337\n",
      "epoch 58; iter: 0; batch classifier loss: 0.369726; batch adversarial loss: 0.587544\n",
      "epoch 59; iter: 0; batch classifier loss: 0.405469; batch adversarial loss: 0.589279\n",
      "epoch 60; iter: 0; batch classifier loss: 0.406227; batch adversarial loss: 0.484731\n",
      "epoch 61; iter: 0; batch classifier loss: 0.438478; batch adversarial loss: 0.560414\n",
      "epoch 62; iter: 0; batch classifier loss: 0.506292; batch adversarial loss: 0.588097\n",
      "epoch 63; iter: 0; batch classifier loss: 0.469602; batch adversarial loss: 0.561746\n",
      "epoch 64; iter: 0; batch classifier loss: 0.410918; batch adversarial loss: 0.462698\n",
      "epoch 65; iter: 0; batch classifier loss: 0.535196; batch adversarial loss: 0.519106\n",
      "epoch 66; iter: 0; batch classifier loss: 0.365363; batch adversarial loss: 0.509212\n",
      "epoch 67; iter: 0; batch classifier loss: 0.395355; batch adversarial loss: 0.531071\n",
      "epoch 68; iter: 0; batch classifier loss: 0.425572; batch adversarial loss: 0.500074\n",
      "epoch 69; iter: 0; batch classifier loss: 0.398823; batch adversarial loss: 0.589949\n",
      "epoch 70; iter: 0; batch classifier loss: 0.446611; batch adversarial loss: 0.541338\n",
      "epoch 71; iter: 0; batch classifier loss: 0.440613; batch adversarial loss: 0.581595\n",
      "epoch 72; iter: 0; batch classifier loss: 0.428126; batch adversarial loss: 0.610007\n",
      "epoch 73; iter: 0; batch classifier loss: 0.440569; batch adversarial loss: 0.534160\n",
      "epoch 74; iter: 0; batch classifier loss: 0.388950; batch adversarial loss: 0.555249\n",
      "epoch 75; iter: 0; batch classifier loss: 0.338861; batch adversarial loss: 0.552165\n",
      "epoch 76; iter: 0; batch classifier loss: 0.393615; batch adversarial loss: 0.481824\n",
      "epoch 77; iter: 0; batch classifier loss: 0.429887; batch adversarial loss: 0.589368\n",
      "epoch 78; iter: 0; batch classifier loss: 0.414117; batch adversarial loss: 0.516853\n",
      "epoch 79; iter: 0; batch classifier loss: 0.410011; batch adversarial loss: 0.545073\n",
      "epoch 80; iter: 0; batch classifier loss: 0.390811; batch adversarial loss: 0.571743\n",
      "epoch 81; iter: 0; batch classifier loss: 0.407714; batch adversarial loss: 0.527648\n",
      "epoch 82; iter: 0; batch classifier loss: 0.322842; batch adversarial loss: 0.581182\n",
      "epoch 83; iter: 0; batch classifier loss: 0.400531; batch adversarial loss: 0.572199\n",
      "epoch 84; iter: 0; batch classifier loss: 0.483895; batch adversarial loss: 0.571104\n",
      "epoch 85; iter: 0; batch classifier loss: 0.372863; batch adversarial loss: 0.508589\n",
      "epoch 86; iter: 0; batch classifier loss: 0.428736; batch adversarial loss: 0.541557\n",
      "epoch 87; iter: 0; batch classifier loss: 0.385987; batch adversarial loss: 0.551927\n",
      "epoch 88; iter: 0; batch classifier loss: 0.458213; batch adversarial loss: 0.554672\n",
      "epoch 89; iter: 0; batch classifier loss: 0.372979; batch adversarial loss: 0.615619\n",
      "epoch 90; iter: 0; batch classifier loss: 0.378469; batch adversarial loss: 0.607962\n",
      "epoch 91; iter: 0; batch classifier loss: 0.455608; batch adversarial loss: 0.526695\n",
      "epoch 92; iter: 0; batch classifier loss: 0.406115; batch adversarial loss: 0.509183\n",
      "epoch 93; iter: 0; batch classifier loss: 0.398276; batch adversarial loss: 0.562465\n",
      "epoch 94; iter: 0; batch classifier loss: 0.352442; batch adversarial loss: 0.571060\n",
      "epoch 95; iter: 0; batch classifier loss: 0.340833; batch adversarial loss: 0.642002\n",
      "epoch 96; iter: 0; batch classifier loss: 0.329903; batch adversarial loss: 0.499888\n",
      "epoch 97; iter: 0; batch classifier loss: 0.378933; batch adversarial loss: 0.535563\n",
      "epoch 98; iter: 0; batch classifier loss: 0.383345; batch adversarial loss: 0.598403\n",
      "epoch 99; iter: 0; batch classifier loss: 0.395582; batch adversarial loss: 0.535503\n",
      "epoch 100; iter: 0; batch classifier loss: 0.406869; batch adversarial loss: 0.518626\n",
      "epoch 101; iter: 0; batch classifier loss: 0.456034; batch adversarial loss: 0.508783\n",
      "epoch 102; iter: 0; batch classifier loss: 0.305182; batch adversarial loss: 0.571535\n",
      "epoch 103; iter: 0; batch classifier loss: 0.356153; batch adversarial loss: 0.534582\n",
      "epoch 104; iter: 0; batch classifier loss: 0.341206; batch adversarial loss: 0.545147\n",
      "epoch 105; iter: 0; batch classifier loss: 0.407157; batch adversarial loss: 0.498928\n",
      "epoch 106; iter: 0; batch classifier loss: 0.352941; batch adversarial loss: 0.526658\n",
      "epoch 107; iter: 0; batch classifier loss: 0.336107; batch adversarial loss: 0.544865\n",
      "epoch 108; iter: 0; batch classifier loss: 0.348005; batch adversarial loss: 0.508520\n",
      "epoch 109; iter: 0; batch classifier loss: 0.372791; batch adversarial loss: 0.625165\n",
      "epoch 110; iter: 0; batch classifier loss: 0.348810; batch adversarial loss: 0.563049\n",
      "epoch 111; iter: 0; batch classifier loss: 0.304090; batch adversarial loss: 0.562063\n",
      "epoch 112; iter: 0; batch classifier loss: 0.417468; batch adversarial loss: 0.553177\n",
      "epoch 113; iter: 0; batch classifier loss: 0.437156; batch adversarial loss: 0.716691\n",
      "epoch 114; iter: 0; batch classifier loss: 0.312030; batch adversarial loss: 0.563065\n",
      "epoch 115; iter: 0; batch classifier loss: 0.363995; batch adversarial loss: 0.535083\n",
      "epoch 116; iter: 0; batch classifier loss: 0.352533; batch adversarial loss: 0.500284\n",
      "epoch 117; iter: 0; batch classifier loss: 0.345620; batch adversarial loss: 0.589166\n",
      "epoch 118; iter: 0; batch classifier loss: 0.356552; batch adversarial loss: 0.562499\n",
      "epoch 119; iter: 0; batch classifier loss: 0.327264; batch adversarial loss: 0.562251\n",
      "epoch 120; iter: 0; batch classifier loss: 0.291776; batch adversarial loss: 0.536051\n",
      "epoch 121; iter: 0; batch classifier loss: 0.297677; batch adversarial loss: 0.562440\n",
      "epoch 122; iter: 0; batch classifier loss: 0.395876; batch adversarial loss: 0.580859\n",
      "epoch 123; iter: 0; batch classifier loss: 0.299846; batch adversarial loss: 0.480922\n",
      "epoch 124; iter: 0; batch classifier loss: 0.384516; batch adversarial loss: 0.544161\n",
      "epoch 125; iter: 0; batch classifier loss: 0.367961; batch adversarial loss: 0.589027\n",
      "epoch 126; iter: 0; batch classifier loss: 0.369994; batch adversarial loss: 0.580506\n",
      "epoch 127; iter: 0; batch classifier loss: 0.366124; batch adversarial loss: 0.491582\n",
      "epoch 128; iter: 0; batch classifier loss: 0.361837; batch adversarial loss: 0.562162\n",
      "epoch 129; iter: 0; batch classifier loss: 0.448980; batch adversarial loss: 0.570950\n",
      "epoch 130; iter: 0; batch classifier loss: 0.368492; batch adversarial loss: 0.499829\n",
      "epoch 131; iter: 0; batch classifier loss: 0.421155; batch adversarial loss: 0.571660\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 132; iter: 0; batch classifier loss: 0.369308; batch adversarial loss: 0.536999\n",
      "epoch 133; iter: 0; batch classifier loss: 0.402699; batch adversarial loss: 0.607693\n",
      "epoch 134; iter: 0; batch classifier loss: 0.385814; batch adversarial loss: 0.481748\n",
      "epoch 135; iter: 0; batch classifier loss: 0.445604; batch adversarial loss: 0.589138\n",
      "epoch 136; iter: 0; batch classifier loss: 0.329422; batch adversarial loss: 0.634725\n",
      "epoch 137; iter: 0; batch classifier loss: 0.310525; batch adversarial loss: 0.490524\n",
      "epoch 138; iter: 0; batch classifier loss: 0.383414; batch adversarial loss: 0.499633\n",
      "epoch 139; iter: 0; batch classifier loss: 0.434021; batch adversarial loss: 0.544316\n",
      "epoch 140; iter: 0; batch classifier loss: 0.225455; batch adversarial loss: 0.545771\n",
      "epoch 141; iter: 0; batch classifier loss: 0.329909; batch adversarial loss: 0.499169\n",
      "epoch 142; iter: 0; batch classifier loss: 0.331449; batch adversarial loss: 0.580371\n",
      "epoch 143; iter: 0; batch classifier loss: 0.310417; batch adversarial loss: 0.535651\n",
      "epoch 144; iter: 0; batch classifier loss: 0.372126; batch adversarial loss: 0.508712\n",
      "epoch 145; iter: 0; batch classifier loss: 0.313296; batch adversarial loss: 0.517171\n",
      "epoch 146; iter: 0; batch classifier loss: 0.349134; batch adversarial loss: 0.544069\n",
      "epoch 147; iter: 0; batch classifier loss: 0.298362; batch adversarial loss: 0.526238\n",
      "epoch 148; iter: 0; batch classifier loss: 0.345773; batch adversarial loss: 0.500601\n",
      "epoch 149; iter: 0; batch classifier loss: 0.338786; batch adversarial loss: 0.588995\n",
      "epoch 150; iter: 0; batch classifier loss: 0.401922; batch adversarial loss: 0.570808\n",
      "epoch 151; iter: 0; batch classifier loss: 0.336592; batch adversarial loss: 0.562451\n",
      "epoch 152; iter: 0; batch classifier loss: 0.320338; batch adversarial loss: 0.526766\n",
      "epoch 153; iter: 0; batch classifier loss: 0.380086; batch adversarial loss: 0.544648\n",
      "epoch 154; iter: 0; batch classifier loss: 0.361052; batch adversarial loss: 0.544403\n",
      "epoch 155; iter: 0; batch classifier loss: 0.376498; batch adversarial loss: 0.544486\n",
      "epoch 156; iter: 0; batch classifier loss: 0.387934; batch adversarial loss: 0.581884\n",
      "epoch 157; iter: 0; batch classifier loss: 0.377507; batch adversarial loss: 0.598290\n",
      "epoch 158; iter: 0; batch classifier loss: 0.259339; batch adversarial loss: 0.454008\n",
      "epoch 159; iter: 0; batch classifier loss: 0.393896; batch adversarial loss: 0.517600\n",
      "epoch 160; iter: 0; batch classifier loss: 0.376764; batch adversarial loss: 0.489742\n",
      "epoch 161; iter: 0; batch classifier loss: 0.365516; batch adversarial loss: 0.516822\n",
      "epoch 162; iter: 0; batch classifier loss: 0.329862; batch adversarial loss: 0.482382\n",
      "epoch 163; iter: 0; batch classifier loss: 0.288873; batch adversarial loss: 0.581376\n",
      "epoch 164; iter: 0; batch classifier loss: 0.364254; batch adversarial loss: 0.544771\n",
      "epoch 165; iter: 0; batch classifier loss: 0.313002; batch adversarial loss: 0.499347\n",
      "epoch 166; iter: 0; batch classifier loss: 0.303123; batch adversarial loss: 0.580322\n",
      "epoch 167; iter: 0; batch classifier loss: 0.357893; batch adversarial loss: 0.535622\n",
      "epoch 168; iter: 0; batch classifier loss: 0.412821; batch adversarial loss: 0.589241\n",
      "epoch 169; iter: 0; batch classifier loss: 0.370900; batch adversarial loss: 0.580196\n",
      "epoch 170; iter: 0; batch classifier loss: 0.355582; batch adversarial loss: 0.589573\n",
      "epoch 171; iter: 0; batch classifier loss: 0.304235; batch adversarial loss: 0.590184\n",
      "epoch 172; iter: 0; batch classifier loss: 0.322224; batch adversarial loss: 0.607155\n",
      "epoch 173; iter: 0; batch classifier loss: 0.420012; batch adversarial loss: 0.508661\n",
      "epoch 174; iter: 0; batch classifier loss: 0.407189; batch adversarial loss: 0.570886\n",
      "epoch 175; iter: 0; batch classifier loss: 0.282269; batch adversarial loss: 0.526010\n",
      "epoch 176; iter: 0; batch classifier loss: 0.358155; batch adversarial loss: 0.617062\n",
      "epoch 177; iter: 0; batch classifier loss: 0.347256; batch adversarial loss: 0.535996\n",
      "epoch 178; iter: 0; batch classifier loss: 0.342821; batch adversarial loss: 0.571328\n",
      "epoch 179; iter: 0; batch classifier loss: 0.374269; batch adversarial loss: 0.535544\n",
      "epoch 180; iter: 0; batch classifier loss: 0.331726; batch adversarial loss: 0.518049\n",
      "epoch 181; iter: 0; batch classifier loss: 0.324519; batch adversarial loss: 0.517502\n",
      "epoch 182; iter: 0; batch classifier loss: 0.352823; batch adversarial loss: 0.652277\n",
      "epoch 183; iter: 0; batch classifier loss: 0.303822; batch adversarial loss: 0.508535\n",
      "epoch 184; iter: 0; batch classifier loss: 0.303341; batch adversarial loss: 0.626323\n",
      "epoch 185; iter: 0; batch classifier loss: 0.314756; batch adversarial loss: 0.571461\n",
      "epoch 186; iter: 0; batch classifier loss: 0.309624; batch adversarial loss: 0.507897\n",
      "epoch 187; iter: 0; batch classifier loss: 0.294669; batch adversarial loss: 0.625196\n",
      "epoch 188; iter: 0; batch classifier loss: 0.330757; batch adversarial loss: 0.535234\n",
      "epoch 189; iter: 0; batch classifier loss: 0.308820; batch adversarial loss: 0.535947\n",
      "epoch 190; iter: 0; batch classifier loss: 0.264018; batch adversarial loss: 0.553411\n",
      "epoch 191; iter: 0; batch classifier loss: 0.357893; batch adversarial loss: 0.562369\n",
      "epoch 192; iter: 0; batch classifier loss: 0.336695; batch adversarial loss: 0.562787\n",
      "epoch 193; iter: 0; batch classifier loss: 0.356361; batch adversarial loss: 0.580191\n",
      "epoch 194; iter: 0; batch classifier loss: 0.358976; batch adversarial loss: 0.562858\n",
      "epoch 195; iter: 0; batch classifier loss: 0.323205; batch adversarial loss: 0.563089\n",
      "epoch 196; iter: 0; batch classifier loss: 0.376114; batch adversarial loss: 0.509351\n",
      "epoch 197; iter: 0; batch classifier loss: 0.297372; batch adversarial loss: 0.535317\n",
      "epoch 198; iter: 0; batch classifier loss: 0.292245; batch adversarial loss: 0.535485\n",
      "epoch 199; iter: 0; batch classifier loss: 0.371222; batch adversarial loss: 0.616153\n",
      "epoch 0; iter: 0; batch classifier loss: 0.682121; batch adversarial loss: 0.932907\n",
      "epoch 1; iter: 0; batch classifier loss: 0.867098; batch adversarial loss: 1.241405\n",
      "epoch 2; iter: 0; batch classifier loss: 1.024732; batch adversarial loss: 1.167980\n",
      "epoch 3; iter: 0; batch classifier loss: 0.840769; batch adversarial loss: 1.180674\n",
      "epoch 4; iter: 0; batch classifier loss: 0.946478; batch adversarial loss: 1.015753\n",
      "epoch 5; iter: 0; batch classifier loss: 0.965553; batch adversarial loss: 0.932499\n",
      "epoch 6; iter: 0; batch classifier loss: 0.777195; batch adversarial loss: 0.870082\n",
      "epoch 7; iter: 0; batch classifier loss: 0.713221; batch adversarial loss: 0.800292\n",
      "epoch 8; iter: 0; batch classifier loss: 0.651931; batch adversarial loss: 0.710565\n",
      "epoch 9; iter: 0; batch classifier loss: 0.563826; batch adversarial loss: 0.641709\n",
      "epoch 10; iter: 0; batch classifier loss: 0.558074; batch adversarial loss: 0.635835\n",
      "epoch 11; iter: 0; batch classifier loss: 0.525295; batch adversarial loss: 0.618778\n",
      "epoch 12; iter: 0; batch classifier loss: 0.563498; batch adversarial loss: 0.626910\n",
      "epoch 13; iter: 0; batch classifier loss: 0.482876; batch adversarial loss: 0.586853\n",
      "epoch 14; iter: 0; batch classifier loss: 0.497261; batch adversarial loss: 0.611925\n",
      "epoch 15; iter: 0; batch classifier loss: 0.567944; batch adversarial loss: 0.586497\n",
      "epoch 16; iter: 0; batch classifier loss: 0.528796; batch adversarial loss: 0.615548\n",
      "epoch 17; iter: 0; batch classifier loss: 0.535712; batch adversarial loss: 0.588681\n",
      "epoch 18; iter: 0; batch classifier loss: 0.468580; batch adversarial loss: 0.613229\n",
      "epoch 19; iter: 0; batch classifier loss: 0.567394; batch adversarial loss: 0.621364\n",
      "epoch 20; iter: 0; batch classifier loss: 0.479627; batch adversarial loss: 0.608867\n",
      "epoch 21; iter: 0; batch classifier loss: 0.436710; batch adversarial loss: 0.516916\n",
      "epoch 22; iter: 0; batch classifier loss: 0.440961; batch adversarial loss: 0.578066\n",
      "epoch 23; iter: 0; batch classifier loss: 0.567051; batch adversarial loss: 0.583246\n",
      "epoch 24; iter: 0; batch classifier loss: 0.488611; batch adversarial loss: 0.564806\n",
      "epoch 25; iter: 0; batch classifier loss: 0.489522; batch adversarial loss: 0.570115\n",
      "epoch 26; iter: 0; batch classifier loss: 0.455789; batch adversarial loss: 0.602893\n",
      "epoch 27; iter: 0; batch classifier loss: 0.488237; batch adversarial loss: 0.524230\n",
      "epoch 28; iter: 0; batch classifier loss: 0.448845; batch adversarial loss: 0.573889\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 29; iter: 0; batch classifier loss: 0.531752; batch adversarial loss: 0.502014\n",
      "epoch 30; iter: 0; batch classifier loss: 0.464863; batch adversarial loss: 0.571904\n",
      "epoch 31; iter: 0; batch classifier loss: 0.494817; batch adversarial loss: 0.622091\n",
      "epoch 32; iter: 0; batch classifier loss: 0.520920; batch adversarial loss: 0.587888\n",
      "epoch 33; iter: 0; batch classifier loss: 0.472393; batch adversarial loss: 0.590899\n",
      "epoch 34; iter: 0; batch classifier loss: 0.495887; batch adversarial loss: 0.548172\n",
      "epoch 35; iter: 0; batch classifier loss: 0.421111; batch adversarial loss: 0.624810\n",
      "epoch 36; iter: 0; batch classifier loss: 0.386642; batch adversarial loss: 0.583097\n",
      "epoch 37; iter: 0; batch classifier loss: 0.419141; batch adversarial loss: 0.603081\n",
      "epoch 38; iter: 0; batch classifier loss: 0.444672; batch adversarial loss: 0.498821\n",
      "epoch 39; iter: 0; batch classifier loss: 0.508611; batch adversarial loss: 0.515710\n",
      "epoch 40; iter: 0; batch classifier loss: 0.480902; batch adversarial loss: 0.529919\n",
      "epoch 41; iter: 0; batch classifier loss: 0.406508; batch adversarial loss: 0.592009\n",
      "epoch 42; iter: 0; batch classifier loss: 0.389107; batch adversarial loss: 0.535626\n",
      "epoch 43; iter: 0; batch classifier loss: 0.424761; batch adversarial loss: 0.535619\n",
      "epoch 44; iter: 0; batch classifier loss: 0.388982; batch adversarial loss: 0.591112\n",
      "epoch 45; iter: 0; batch classifier loss: 0.409677; batch adversarial loss: 0.588997\n",
      "epoch 46; iter: 0; batch classifier loss: 0.459075; batch adversarial loss: 0.598859\n",
      "epoch 47; iter: 0; batch classifier loss: 0.460716; batch adversarial loss: 0.535527\n",
      "epoch 48; iter: 0; batch classifier loss: 0.387324; batch adversarial loss: 0.534794\n",
      "epoch 49; iter: 0; batch classifier loss: 0.432975; batch adversarial loss: 0.536619\n",
      "epoch 50; iter: 0; batch classifier loss: 0.417892; batch adversarial loss: 0.507815\n",
      "epoch 51; iter: 0; batch classifier loss: 0.418758; batch adversarial loss: 0.573280\n",
      "epoch 52; iter: 0; batch classifier loss: 0.450805; batch adversarial loss: 0.610796\n",
      "epoch 53; iter: 0; batch classifier loss: 0.416154; batch adversarial loss: 0.517149\n",
      "epoch 54; iter: 0; batch classifier loss: 0.401601; batch adversarial loss: 0.544949\n",
      "epoch 55; iter: 0; batch classifier loss: 0.442883; batch adversarial loss: 0.564597\n",
      "epoch 56; iter: 0; batch classifier loss: 0.379998; batch adversarial loss: 0.545412\n",
      "epoch 57; iter: 0; batch classifier loss: 0.421314; batch adversarial loss: 0.635047\n",
      "epoch 58; iter: 0; batch classifier loss: 0.448131; batch adversarial loss: 0.553297\n",
      "epoch 59; iter: 0; batch classifier loss: 0.414556; batch adversarial loss: 0.525447\n",
      "epoch 60; iter: 0; batch classifier loss: 0.367237; batch adversarial loss: 0.498299\n",
      "epoch 61; iter: 0; batch classifier loss: 0.366725; batch adversarial loss: 0.571954\n",
      "epoch 62; iter: 0; batch classifier loss: 0.439431; batch adversarial loss: 0.555656\n",
      "epoch 63; iter: 0; batch classifier loss: 0.309098; batch adversarial loss: 0.517369\n",
      "epoch 64; iter: 0; batch classifier loss: 0.380264; batch adversarial loss: 0.599597\n",
      "epoch 65; iter: 0; batch classifier loss: 0.410274; batch adversarial loss: 0.542840\n",
      "epoch 66; iter: 0; batch classifier loss: 0.468707; batch adversarial loss: 0.525124\n",
      "epoch 67; iter: 0; batch classifier loss: 0.372366; batch adversarial loss: 0.509426\n",
      "epoch 68; iter: 0; batch classifier loss: 0.434070; batch adversarial loss: 0.544002\n",
      "epoch 69; iter: 0; batch classifier loss: 0.489538; batch adversarial loss: 0.523287\n",
      "epoch 70; iter: 0; batch classifier loss: 0.430751; batch adversarial loss: 0.524670\n",
      "epoch 71; iter: 0; batch classifier loss: 0.396338; batch adversarial loss: 0.542881\n",
      "epoch 72; iter: 0; batch classifier loss: 0.353690; batch adversarial loss: 0.544059\n",
      "epoch 73; iter: 0; batch classifier loss: 0.384594; batch adversarial loss: 0.500138\n",
      "epoch 74; iter: 0; batch classifier loss: 0.429982; batch adversarial loss: 0.541651\n",
      "epoch 75; iter: 0; batch classifier loss: 0.393920; batch adversarial loss: 0.572788\n",
      "epoch 76; iter: 0; batch classifier loss: 0.343407; batch adversarial loss: 0.544073\n",
      "epoch 77; iter: 0; batch classifier loss: 0.331301; batch adversarial loss: 0.506043\n",
      "epoch 78; iter: 0; batch classifier loss: 0.360605; batch adversarial loss: 0.524868\n",
      "epoch 79; iter: 0; batch classifier loss: 0.380826; batch adversarial loss: 0.531037\n",
      "epoch 80; iter: 0; batch classifier loss: 0.432004; batch adversarial loss: 0.586534\n",
      "epoch 81; iter: 0; batch classifier loss: 0.399501; batch adversarial loss: 0.551234\n",
      "epoch 82; iter: 0; batch classifier loss: 0.372619; batch adversarial loss: 0.474974\n",
      "epoch 83; iter: 0; batch classifier loss: 0.319862; batch adversarial loss: 0.608986\n",
      "epoch 84; iter: 0; batch classifier loss: 0.374848; batch adversarial loss: 0.559383\n",
      "epoch 85; iter: 0; batch classifier loss: 0.343232; batch adversarial loss: 0.575625\n",
      "epoch 86; iter: 0; batch classifier loss: 0.351488; batch adversarial loss: 0.545862\n",
      "epoch 87; iter: 0; batch classifier loss: 0.333938; batch adversarial loss: 0.567511\n",
      "epoch 88; iter: 0; batch classifier loss: 0.371608; batch adversarial loss: 0.541086\n",
      "epoch 89; iter: 0; batch classifier loss: 0.380600; batch adversarial loss: 0.483237\n",
      "epoch 90; iter: 0; batch classifier loss: 0.404023; batch adversarial loss: 0.540708\n",
      "epoch 91; iter: 0; batch classifier loss: 0.384665; batch adversarial loss: 0.535977\n",
      "epoch 92; iter: 0; batch classifier loss: 0.343450; batch adversarial loss: 0.615276\n",
      "epoch 93; iter: 0; batch classifier loss: 0.364165; batch adversarial loss: 0.597323\n",
      "epoch 94; iter: 0; batch classifier loss: 0.345069; batch adversarial loss: 0.588943\n",
      "epoch 95; iter: 0; batch classifier loss: 0.364601; batch adversarial loss: 0.527664\n",
      "epoch 96; iter: 0; batch classifier loss: 0.428951; batch adversarial loss: 0.557577\n",
      "epoch 97; iter: 0; batch classifier loss: 0.405324; batch adversarial loss: 0.613648\n",
      "epoch 98; iter: 0; batch classifier loss: 0.317585; batch adversarial loss: 0.577536\n",
      "epoch 99; iter: 0; batch classifier loss: 0.385711; batch adversarial loss: 0.536251\n",
      "epoch 100; iter: 0; batch classifier loss: 0.336719; batch adversarial loss: 0.615318\n",
      "epoch 101; iter: 0; batch classifier loss: 0.443223; batch adversarial loss: 0.570217\n",
      "epoch 102; iter: 0; batch classifier loss: 0.343449; batch adversarial loss: 0.591787\n",
      "epoch 103; iter: 0; batch classifier loss: 0.376410; batch adversarial loss: 0.491459\n",
      "epoch 104; iter: 0; batch classifier loss: 0.274350; batch adversarial loss: 0.541515\n",
      "epoch 105; iter: 0; batch classifier loss: 0.340076; batch adversarial loss: 0.517815\n",
      "epoch 106; iter: 0; batch classifier loss: 0.322686; batch adversarial loss: 0.580020\n",
      "epoch 107; iter: 0; batch classifier loss: 0.417832; batch adversarial loss: 0.507265\n",
      "epoch 108; iter: 0; batch classifier loss: 0.352166; batch adversarial loss: 0.524514\n",
      "epoch 109; iter: 0; batch classifier loss: 0.375547; batch adversarial loss: 0.492823\n",
      "epoch 110; iter: 0; batch classifier loss: 0.252795; batch adversarial loss: 0.526427\n",
      "epoch 111; iter: 0; batch classifier loss: 0.317367; batch adversarial loss: 0.635581\n",
      "epoch 112; iter: 0; batch classifier loss: 0.429720; batch adversarial loss: 0.612268\n",
      "epoch 113; iter: 0; batch classifier loss: 0.339954; batch adversarial loss: 0.507274\n",
      "epoch 114; iter: 0; batch classifier loss: 0.360432; batch adversarial loss: 0.497099\n",
      "epoch 115; iter: 0; batch classifier loss: 0.301393; batch adversarial loss: 0.536562\n",
      "epoch 116; iter: 0; batch classifier loss: 0.396873; batch adversarial loss: 0.553227\n",
      "epoch 117; iter: 0; batch classifier loss: 0.409253; batch adversarial loss: 0.535963\n",
      "epoch 118; iter: 0; batch classifier loss: 0.398611; batch adversarial loss: 0.505139\n",
      "epoch 119; iter: 0; batch classifier loss: 0.296119; batch adversarial loss: 0.542132\n",
      "epoch 120; iter: 0; batch classifier loss: 0.362342; batch adversarial loss: 0.534268\n",
      "epoch 121; iter: 0; batch classifier loss: 0.403277; batch adversarial loss: 0.490018\n",
      "epoch 122; iter: 0; batch classifier loss: 0.356385; batch adversarial loss: 0.580462\n",
      "epoch 123; iter: 0; batch classifier loss: 0.389048; batch adversarial loss: 0.474749\n",
      "epoch 124; iter: 0; batch classifier loss: 0.368497; batch adversarial loss: 0.437152\n",
      "epoch 125; iter: 0; batch classifier loss: 0.289688; batch adversarial loss: 0.472478\n",
      "epoch 126; iter: 0; batch classifier loss: 0.340849; batch adversarial loss: 0.546068\n",
      "epoch 127; iter: 0; batch classifier loss: 0.315232; batch adversarial loss: 0.563550\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 128; iter: 0; batch classifier loss: 0.357282; batch adversarial loss: 0.553408\n",
      "epoch 129; iter: 0; batch classifier loss: 0.389790; batch adversarial loss: 0.634029\n",
      "epoch 130; iter: 0; batch classifier loss: 0.397401; batch adversarial loss: 0.553337\n",
      "epoch 131; iter: 0; batch classifier loss: 0.382127; batch adversarial loss: 0.508989\n",
      "epoch 132; iter: 0; batch classifier loss: 0.301803; batch adversarial loss: 0.554675\n",
      "epoch 133; iter: 0; batch classifier loss: 0.335822; batch adversarial loss: 0.528085\n",
      "epoch 134; iter: 0; batch classifier loss: 0.401532; batch adversarial loss: 0.517766\n",
      "epoch 135; iter: 0; batch classifier loss: 0.420073; batch adversarial loss: 0.508852\n",
      "epoch 136; iter: 0; batch classifier loss: 0.399157; batch adversarial loss: 0.589146\n",
      "epoch 137; iter: 0; batch classifier loss: 0.284987; batch adversarial loss: 0.525638\n",
      "epoch 138; iter: 0; batch classifier loss: 0.306705; batch adversarial loss: 0.535900\n",
      "epoch 139; iter: 0; batch classifier loss: 0.322954; batch adversarial loss: 0.553320\n",
      "epoch 140; iter: 0; batch classifier loss: 0.440492; batch adversarial loss: 0.591510\n",
      "epoch 141; iter: 0; batch classifier loss: 0.450471; batch adversarial loss: 0.533778\n",
      "epoch 142; iter: 0; batch classifier loss: 0.393529; batch adversarial loss: 0.543595\n",
      "epoch 143; iter: 0; batch classifier loss: 0.398974; batch adversarial loss: 0.588600\n",
      "epoch 144; iter: 0; batch classifier loss: 0.360534; batch adversarial loss: 0.571879\n",
      "epoch 145; iter: 0; batch classifier loss: 0.375512; batch adversarial loss: 0.507947\n",
      "epoch 146; iter: 0; batch classifier loss: 0.372192; batch adversarial loss: 0.499056\n",
      "epoch 147; iter: 0; batch classifier loss: 0.424713; batch adversarial loss: 0.546100\n",
      "epoch 148; iter: 0; batch classifier loss: 0.366853; batch adversarial loss: 0.489730\n",
      "epoch 149; iter: 0; batch classifier loss: 0.409585; batch adversarial loss: 0.564578\n",
      "epoch 150; iter: 0; batch classifier loss: 0.376466; batch adversarial loss: 0.590493\n",
      "epoch 151; iter: 0; batch classifier loss: 0.419792; batch adversarial loss: 0.461798\n",
      "epoch 152; iter: 0; batch classifier loss: 0.397616; batch adversarial loss: 0.662609\n",
      "epoch 153; iter: 0; batch classifier loss: 0.234603; batch adversarial loss: 0.532385\n",
      "epoch 154; iter: 0; batch classifier loss: 0.333550; batch adversarial loss: 0.586856\n",
      "epoch 155; iter: 0; batch classifier loss: 0.310773; batch adversarial loss: 0.580273\n",
      "epoch 156; iter: 0; batch classifier loss: 0.331558; batch adversarial loss: 0.506916\n",
      "epoch 157; iter: 0; batch classifier loss: 0.365587; batch adversarial loss: 0.552353\n",
      "epoch 158; iter: 0; batch classifier loss: 0.355981; batch adversarial loss: 0.543158\n",
      "epoch 159; iter: 0; batch classifier loss: 0.262755; batch adversarial loss: 0.507354\n",
      "epoch 160; iter: 0; batch classifier loss: 0.261853; batch adversarial loss: 0.553651\n",
      "epoch 161; iter: 0; batch classifier loss: 0.370450; batch adversarial loss: 0.535447\n",
      "epoch 162; iter: 0; batch classifier loss: 0.288721; batch adversarial loss: 0.582157\n",
      "epoch 163; iter: 0; batch classifier loss: 0.347661; batch adversarial loss: 0.510081\n",
      "epoch 164; iter: 0; batch classifier loss: 0.386953; batch adversarial loss: 0.544546\n",
      "epoch 165; iter: 0; batch classifier loss: 0.305513; batch adversarial loss: 0.564180\n",
      "epoch 166; iter: 0; batch classifier loss: 0.308470; batch adversarial loss: 0.554800\n",
      "epoch 167; iter: 0; batch classifier loss: 0.356640; batch adversarial loss: 0.488112\n",
      "epoch 168; iter: 0; batch classifier loss: 0.464492; batch adversarial loss: 0.490020\n",
      "epoch 169; iter: 0; batch classifier loss: 0.315888; batch adversarial loss: 0.573019\n",
      "epoch 170; iter: 0; batch classifier loss: 0.324431; batch adversarial loss: 0.518321\n",
      "epoch 171; iter: 0; batch classifier loss: 0.295910; batch adversarial loss: 0.634556\n",
      "epoch 172; iter: 0; batch classifier loss: 0.328498; batch adversarial loss: 0.606318\n",
      "epoch 173; iter: 0; batch classifier loss: 0.373186; batch adversarial loss: 0.517993\n",
      "epoch 174; iter: 0; batch classifier loss: 0.422795; batch adversarial loss: 0.608965\n",
      "epoch 175; iter: 0; batch classifier loss: 0.320261; batch adversarial loss: 0.489958\n",
      "epoch 176; iter: 0; batch classifier loss: 0.352668; batch adversarial loss: 0.544516\n",
      "epoch 177; iter: 0; batch classifier loss: 0.406743; batch adversarial loss: 0.545038\n",
      "epoch 178; iter: 0; batch classifier loss: 0.391132; batch adversarial loss: 0.524879\n",
      "epoch 179; iter: 0; batch classifier loss: 0.369983; batch adversarial loss: 0.508472\n",
      "epoch 180; iter: 0; batch classifier loss: 0.362272; batch adversarial loss: 0.562880\n",
      "epoch 181; iter: 0; batch classifier loss: 0.342275; batch adversarial loss: 0.480134\n",
      "epoch 182; iter: 0; batch classifier loss: 0.337037; batch adversarial loss: 0.489635\n",
      "epoch 183; iter: 0; batch classifier loss: 0.336924; batch adversarial loss: 0.517408\n",
      "epoch 184; iter: 0; batch classifier loss: 0.363018; batch adversarial loss: 0.498932\n",
      "epoch 185; iter: 0; batch classifier loss: 0.402725; batch adversarial loss: 0.525992\n",
      "epoch 186; iter: 0; batch classifier loss: 0.346804; batch adversarial loss: 0.534684\n",
      "epoch 187; iter: 0; batch classifier loss: 0.402218; batch adversarial loss: 0.507780\n",
      "epoch 188; iter: 0; batch classifier loss: 0.275503; batch adversarial loss: 0.480669\n",
      "epoch 189; iter: 0; batch classifier loss: 0.355285; batch adversarial loss: 0.580965\n",
      "epoch 190; iter: 0; batch classifier loss: 0.297414; batch adversarial loss: 0.562976\n",
      "epoch 191; iter: 0; batch classifier loss: 0.299399; batch adversarial loss: 0.598825\n",
      "epoch 192; iter: 0; batch classifier loss: 0.313017; batch adversarial loss: 0.581552\n",
      "epoch 193; iter: 0; batch classifier loss: 0.337276; batch adversarial loss: 0.544377\n",
      "epoch 194; iter: 0; batch classifier loss: 0.365131; batch adversarial loss: 0.562236\n",
      "epoch 195; iter: 0; batch classifier loss: 0.315258; batch adversarial loss: 0.553683\n",
      "epoch 196; iter: 0; batch classifier loss: 0.292964; batch adversarial loss: 0.508685\n",
      "epoch 197; iter: 0; batch classifier loss: 0.309660; batch adversarial loss: 0.572899\n",
      "epoch 198; iter: 0; batch classifier loss: 0.371042; batch adversarial loss: 0.491034\n",
      "epoch 199; iter: 0; batch classifier loss: 0.370094; batch adversarial loss: 0.533914\n",
      "epoch 0; iter: 0; batch classifier loss: 0.718253; batch adversarial loss: 0.827944\n",
      "epoch 1; iter: 0; batch classifier loss: 0.627082; batch adversarial loss: 0.834485\n",
      "epoch 2; iter: 0; batch classifier loss: 0.577385; batch adversarial loss: 0.745975\n",
      "epoch 3; iter: 0; batch classifier loss: 0.538520; batch adversarial loss: 0.708093\n",
      "epoch 4; iter: 0; batch classifier loss: 0.612498; batch adversarial loss: 0.654755\n",
      "epoch 5; iter: 0; batch classifier loss: 0.611088; batch adversarial loss: 0.688309\n",
      "epoch 6; iter: 0; batch classifier loss: 0.529089; batch adversarial loss: 0.637268\n",
      "epoch 7; iter: 0; batch classifier loss: 0.554224; batch adversarial loss: 0.648750\n",
      "epoch 8; iter: 0; batch classifier loss: 0.510246; batch adversarial loss: 0.633305\n",
      "epoch 9; iter: 0; batch classifier loss: 0.571682; batch adversarial loss: 0.614886\n",
      "epoch 10; iter: 0; batch classifier loss: 0.580848; batch adversarial loss: 0.610069\n",
      "epoch 11; iter: 0; batch classifier loss: 0.545362; batch adversarial loss: 0.593446\n",
      "epoch 12; iter: 0; batch classifier loss: 0.499344; batch adversarial loss: 0.576532\n",
      "epoch 13; iter: 0; batch classifier loss: 0.476788; batch adversarial loss: 0.583962\n",
      "epoch 14; iter: 0; batch classifier loss: 0.458826; batch adversarial loss: 0.521682\n",
      "epoch 15; iter: 0; batch classifier loss: 0.523202; batch adversarial loss: 0.578277\n",
      "epoch 16; iter: 0; batch classifier loss: 0.469309; batch adversarial loss: 0.582616\n",
      "epoch 17; iter: 0; batch classifier loss: 0.513286; batch adversarial loss: 0.568385\n",
      "epoch 18; iter: 0; batch classifier loss: 0.548045; batch adversarial loss: 0.552359\n",
      "epoch 19; iter: 0; batch classifier loss: 0.421743; batch adversarial loss: 0.515487\n",
      "epoch 20; iter: 0; batch classifier loss: 0.489589; batch adversarial loss: 0.575356\n",
      "epoch 21; iter: 0; batch classifier loss: 0.511166; batch adversarial loss: 0.542692\n",
      "epoch 22; iter: 0; batch classifier loss: 0.493087; batch adversarial loss: 0.530623\n",
      "epoch 23; iter: 0; batch classifier loss: 0.479637; batch adversarial loss: 0.544770\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 24; iter: 0; batch classifier loss: 0.510742; batch adversarial loss: 0.571341\n",
      "epoch 25; iter: 0; batch classifier loss: 0.504300; batch adversarial loss: 0.589141\n",
      "epoch 26; iter: 0; batch classifier loss: 0.465306; batch adversarial loss: 0.512874\n",
      "epoch 27; iter: 0; batch classifier loss: 0.500753; batch adversarial loss: 0.529589\n",
      "epoch 28; iter: 0; batch classifier loss: 0.445321; batch adversarial loss: 0.573564\n",
      "epoch 29; iter: 0; batch classifier loss: 0.479099; batch adversarial loss: 0.590227\n",
      "epoch 30; iter: 0; batch classifier loss: 0.473933; batch adversarial loss: 0.572859\n",
      "epoch 31; iter: 0; batch classifier loss: 0.472142; batch adversarial loss: 0.543369\n",
      "epoch 32; iter: 0; batch classifier loss: 0.490463; batch adversarial loss: 0.547974\n",
      "epoch 33; iter: 0; batch classifier loss: 0.401209; batch adversarial loss: 0.508500\n",
      "epoch 34; iter: 0; batch classifier loss: 0.541275; batch adversarial loss: 0.516658\n",
      "epoch 35; iter: 0; batch classifier loss: 0.471424; batch adversarial loss: 0.543709\n",
      "epoch 36; iter: 0; batch classifier loss: 0.414270; batch adversarial loss: 0.578092\n",
      "epoch 37; iter: 0; batch classifier loss: 0.509355; batch adversarial loss: 0.511397\n",
      "epoch 38; iter: 0; batch classifier loss: 0.406821; batch adversarial loss: 0.601949\n",
      "epoch 39; iter: 0; batch classifier loss: 0.394345; batch adversarial loss: 0.547173\n",
      "epoch 40; iter: 0; batch classifier loss: 0.406922; batch adversarial loss: 0.485587\n",
      "epoch 41; iter: 0; batch classifier loss: 0.412259; batch adversarial loss: 0.508622\n",
      "epoch 42; iter: 0; batch classifier loss: 0.445354; batch adversarial loss: 0.519036\n",
      "epoch 43; iter: 0; batch classifier loss: 0.541502; batch adversarial loss: 0.492238\n",
      "epoch 44; iter: 0; batch classifier loss: 0.441452; batch adversarial loss: 0.582566\n",
      "epoch 45; iter: 0; batch classifier loss: 0.480067; batch adversarial loss: 0.558222\n",
      "epoch 46; iter: 0; batch classifier loss: 0.439377; batch adversarial loss: 0.533959\n",
      "epoch 47; iter: 0; batch classifier loss: 0.457623; batch adversarial loss: 0.526348\n",
      "epoch 48; iter: 0; batch classifier loss: 0.430981; batch adversarial loss: 0.609703\n",
      "epoch 49; iter: 0; batch classifier loss: 0.439730; batch adversarial loss: 0.501751\n",
      "epoch 50; iter: 0; batch classifier loss: 0.442484; batch adversarial loss: 0.534122\n",
      "epoch 51; iter: 0; batch classifier loss: 0.424491; batch adversarial loss: 0.607552\n",
      "epoch 52; iter: 0; batch classifier loss: 0.451896; batch adversarial loss: 0.591984\n",
      "epoch 53; iter: 0; batch classifier loss: 0.387274; batch adversarial loss: 0.489825\n",
      "epoch 54; iter: 0; batch classifier loss: 0.506892; batch adversarial loss: 0.580768\n",
      "epoch 55; iter: 0; batch classifier loss: 0.423124; batch adversarial loss: 0.582684\n",
      "epoch 56; iter: 0; batch classifier loss: 0.446912; batch adversarial loss: 0.519493\n",
      "epoch 57; iter: 0; batch classifier loss: 0.363588; batch adversarial loss: 0.619165\n",
      "epoch 58; iter: 0; batch classifier loss: 0.358728; batch adversarial loss: 0.535911\n",
      "epoch 59; iter: 0; batch classifier loss: 0.396839; batch adversarial loss: 0.589493\n",
      "epoch 60; iter: 0; batch classifier loss: 0.383661; batch adversarial loss: 0.543665\n",
      "epoch 61; iter: 0; batch classifier loss: 0.481974; batch adversarial loss: 0.571209\n",
      "epoch 62; iter: 0; batch classifier loss: 0.389389; batch adversarial loss: 0.537728\n",
      "epoch 63; iter: 0; batch classifier loss: 0.453958; batch adversarial loss: 0.506970\n",
      "epoch 64; iter: 0; batch classifier loss: 0.341156; batch adversarial loss: 0.580308\n",
      "epoch 65; iter: 0; batch classifier loss: 0.428179; batch adversarial loss: 0.546590\n",
      "epoch 66; iter: 0; batch classifier loss: 0.298737; batch adversarial loss: 0.480347\n",
      "epoch 67; iter: 0; batch classifier loss: 0.372418; batch adversarial loss: 0.514249\n",
      "epoch 68; iter: 0; batch classifier loss: 0.509615; batch adversarial loss: 0.535220\n",
      "epoch 69; iter: 0; batch classifier loss: 0.380227; batch adversarial loss: 0.572877\n",
      "epoch 70; iter: 0; batch classifier loss: 0.384621; batch adversarial loss: 0.517181\n",
      "epoch 71; iter: 0; batch classifier loss: 0.372245; batch adversarial loss: 0.498957\n",
      "epoch 72; iter: 0; batch classifier loss: 0.435588; batch adversarial loss: 0.487759\n",
      "epoch 73; iter: 0; batch classifier loss: 0.399177; batch adversarial loss: 0.488226\n",
      "epoch 74; iter: 0; batch classifier loss: 0.471655; batch adversarial loss: 0.498369\n",
      "epoch 75; iter: 0; batch classifier loss: 0.372056; batch adversarial loss: 0.672888\n",
      "epoch 76; iter: 0; batch classifier loss: 0.385348; batch adversarial loss: 0.519074\n",
      "epoch 77; iter: 0; batch classifier loss: 0.405102; batch adversarial loss: 0.497985\n",
      "epoch 78; iter: 0; batch classifier loss: 0.508599; batch adversarial loss: 0.609247\n",
      "epoch 79; iter: 0; batch classifier loss: 0.394631; batch adversarial loss: 0.602906\n",
      "epoch 80; iter: 0; batch classifier loss: 0.322279; batch adversarial loss: 0.647401\n",
      "epoch 81; iter: 0; batch classifier loss: 0.509402; batch adversarial loss: 0.634639\n",
      "epoch 82; iter: 0; batch classifier loss: 0.345780; batch adversarial loss: 0.507651\n",
      "epoch 83; iter: 0; batch classifier loss: 0.391189; batch adversarial loss: 0.582203\n",
      "epoch 84; iter: 0; batch classifier loss: 0.367298; batch adversarial loss: 0.496930\n",
      "epoch 85; iter: 0; batch classifier loss: 0.402052; batch adversarial loss: 0.479574\n",
      "epoch 86; iter: 0; batch classifier loss: 0.338231; batch adversarial loss: 0.553926\n",
      "epoch 87; iter: 0; batch classifier loss: 0.423381; batch adversarial loss: 0.553813\n",
      "epoch 88; iter: 0; batch classifier loss: 0.400778; batch adversarial loss: 0.517272\n",
      "epoch 89; iter: 0; batch classifier loss: 0.394175; batch adversarial loss: 0.451934\n",
      "epoch 90; iter: 0; batch classifier loss: 0.350639; batch adversarial loss: 0.508082\n",
      "epoch 91; iter: 0; batch classifier loss: 0.369711; batch adversarial loss: 0.462137\n",
      "epoch 92; iter: 0; batch classifier loss: 0.355505; batch adversarial loss: 0.551668\n",
      "epoch 93; iter: 0; batch classifier loss: 0.446726; batch adversarial loss: 0.517946\n",
      "epoch 94; iter: 0; batch classifier loss: 0.418596; batch adversarial loss: 0.554318\n",
      "epoch 95; iter: 0; batch classifier loss: 0.368188; batch adversarial loss: 0.598275\n",
      "epoch 96; iter: 0; batch classifier loss: 0.405469; batch adversarial loss: 0.551716\n",
      "epoch 97; iter: 0; batch classifier loss: 0.416138; batch adversarial loss: 0.505716\n",
      "epoch 98; iter: 0; batch classifier loss: 0.438550; batch adversarial loss: 0.523720\n",
      "epoch 99; iter: 0; batch classifier loss: 0.425876; batch adversarial loss: 0.553092\n",
      "epoch 100; iter: 0; batch classifier loss: 0.381744; batch adversarial loss: 0.553920\n",
      "epoch 101; iter: 0; batch classifier loss: 0.433432; batch adversarial loss: 0.563119\n",
      "epoch 102; iter: 0; batch classifier loss: 0.428482; batch adversarial loss: 0.564906\n",
      "epoch 103; iter: 0; batch classifier loss: 0.366999; batch adversarial loss: 0.553507\n",
      "epoch 104; iter: 0; batch classifier loss: 0.326945; batch adversarial loss: 0.592094\n",
      "epoch 105; iter: 0; batch classifier loss: 0.428049; batch adversarial loss: 0.561657\n",
      "epoch 106; iter: 0; batch classifier loss: 0.314548; batch adversarial loss: 0.504126\n",
      "epoch 107; iter: 0; batch classifier loss: 0.388243; batch adversarial loss: 0.468328\n",
      "epoch 108; iter: 0; batch classifier loss: 0.352511; batch adversarial loss: 0.507244\n",
      "epoch 109; iter: 0; batch classifier loss: 0.423931; batch adversarial loss: 0.472177\n",
      "epoch 110; iter: 0; batch classifier loss: 0.407138; batch adversarial loss: 0.525259\n",
      "epoch 111; iter: 0; batch classifier loss: 0.359785; batch adversarial loss: 0.590970\n",
      "epoch 112; iter: 0; batch classifier loss: 0.285123; batch adversarial loss: 0.571889\n",
      "epoch 113; iter: 0; batch classifier loss: 0.410307; batch adversarial loss: 0.517529\n",
      "epoch 114; iter: 0; batch classifier loss: 0.388921; batch adversarial loss: 0.544635\n",
      "epoch 115; iter: 0; batch classifier loss: 0.335055; batch adversarial loss: 0.508298\n",
      "epoch 116; iter: 0; batch classifier loss: 0.339051; batch adversarial loss: 0.461921\n",
      "epoch 117; iter: 0; batch classifier loss: 0.314661; batch adversarial loss: 0.562634\n",
      "epoch 118; iter: 0; batch classifier loss: 0.365059; batch adversarial loss: 0.564955\n",
      "epoch 119; iter: 0; batch classifier loss: 0.342583; batch adversarial loss: 0.507194\n",
      "epoch 120; iter: 0; batch classifier loss: 0.326394; batch adversarial loss: 0.560665\n",
      "epoch 121; iter: 0; batch classifier loss: 0.381293; batch adversarial loss: 0.515558\n",
      "epoch 122; iter: 0; batch classifier loss: 0.335997; batch adversarial loss: 0.573819\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 123; iter: 0; batch classifier loss: 0.390241; batch adversarial loss: 0.487375\n",
      "epoch 124; iter: 0; batch classifier loss: 0.399779; batch adversarial loss: 0.525229\n",
      "epoch 125; iter: 0; batch classifier loss: 0.412256; batch adversarial loss: 0.543988\n",
      "epoch 126; iter: 0; batch classifier loss: 0.407107; batch adversarial loss: 0.562982\n",
      "epoch 127; iter: 0; batch classifier loss: 0.348201; batch adversarial loss: 0.563537\n",
      "epoch 128; iter: 0; batch classifier loss: 0.332527; batch adversarial loss: 0.590398\n",
      "epoch 129; iter: 0; batch classifier loss: 0.374822; batch adversarial loss: 0.487879\n",
      "epoch 130; iter: 0; batch classifier loss: 0.393923; batch adversarial loss: 0.514268\n",
      "epoch 131; iter: 0; batch classifier loss: 0.294252; batch adversarial loss: 0.480631\n",
      "epoch 132; iter: 0; batch classifier loss: 0.388283; batch adversarial loss: 0.571988\n",
      "epoch 133; iter: 0; batch classifier loss: 0.353235; batch adversarial loss: 0.554711\n",
      "epoch 134; iter: 0; batch classifier loss: 0.369669; batch adversarial loss: 0.488449\n",
      "epoch 135; iter: 0; batch classifier loss: 0.313289; batch adversarial loss: 0.573748\n",
      "epoch 136; iter: 0; batch classifier loss: 0.315971; batch adversarial loss: 0.528441\n",
      "epoch 137; iter: 0; batch classifier loss: 0.341445; batch adversarial loss: 0.543680\n",
      "epoch 138; iter: 0; batch classifier loss: 0.386582; batch adversarial loss: 0.489542\n",
      "epoch 139; iter: 0; batch classifier loss: 0.410907; batch adversarial loss: 0.576209\n",
      "epoch 140; iter: 0; batch classifier loss: 0.321590; batch adversarial loss: 0.607036\n",
      "epoch 141; iter: 0; batch classifier loss: 0.390702; batch adversarial loss: 0.516599\n",
      "epoch 142; iter: 0; batch classifier loss: 0.433122; batch adversarial loss: 0.534947\n",
      "epoch 143; iter: 0; batch classifier loss: 0.419044; batch adversarial loss: 0.571303\n",
      "epoch 144; iter: 0; batch classifier loss: 0.424747; batch adversarial loss: 0.619131\n",
      "epoch 145; iter: 0; batch classifier loss: 0.360262; batch adversarial loss: 0.507248\n",
      "epoch 146; iter: 0; batch classifier loss: 0.395898; batch adversarial loss: 0.527039\n",
      "epoch 147; iter: 0; batch classifier loss: 0.352800; batch adversarial loss: 0.480598\n",
      "epoch 148; iter: 0; batch classifier loss: 0.413470; batch adversarial loss: 0.542548\n",
      "epoch 149; iter: 0; batch classifier loss: 0.385405; batch adversarial loss: 0.525153\n",
      "epoch 150; iter: 0; batch classifier loss: 0.363507; batch adversarial loss: 0.562235\n",
      "epoch 151; iter: 0; batch classifier loss: 0.325381; batch adversarial loss: 0.525148\n",
      "epoch 152; iter: 0; batch classifier loss: 0.394944; batch adversarial loss: 0.517425\n",
      "epoch 153; iter: 0; batch classifier loss: 0.351726; batch adversarial loss: 0.479759\n",
      "epoch 154; iter: 0; batch classifier loss: 0.438494; batch adversarial loss: 0.574011\n",
      "epoch 155; iter: 0; batch classifier loss: 0.373760; batch adversarial loss: 0.571616\n",
      "epoch 156; iter: 0; batch classifier loss: 0.363620; batch adversarial loss: 0.533460\n",
      "epoch 157; iter: 0; batch classifier loss: 0.413465; batch adversarial loss: 0.527788\n",
      "epoch 158; iter: 0; batch classifier loss: 0.339845; batch adversarial loss: 0.534184\n",
      "epoch 159; iter: 0; batch classifier loss: 0.439215; batch adversarial loss: 0.479466\n",
      "epoch 160; iter: 0; batch classifier loss: 0.384326; batch adversarial loss: 0.543057\n",
      "epoch 161; iter: 0; batch classifier loss: 0.302249; batch adversarial loss: 0.598688\n",
      "epoch 162; iter: 0; batch classifier loss: 0.324367; batch adversarial loss: 0.543032\n",
      "epoch 163; iter: 0; batch classifier loss: 0.385000; batch adversarial loss: 0.535344\n",
      "epoch 164; iter: 0; batch classifier loss: 0.409636; batch adversarial loss: 0.509881\n",
      "epoch 165; iter: 0; batch classifier loss: 0.343791; batch adversarial loss: 0.610845\n",
      "epoch 166; iter: 0; batch classifier loss: 0.414575; batch adversarial loss: 0.554153\n",
      "epoch 167; iter: 0; batch classifier loss: 0.316639; batch adversarial loss: 0.458205\n",
      "epoch 168; iter: 0; batch classifier loss: 0.339616; batch adversarial loss: 0.488346\n",
      "epoch 169; iter: 0; batch classifier loss: 0.395502; batch adversarial loss: 0.561223\n",
      "epoch 170; iter: 0; batch classifier loss: 0.378062; batch adversarial loss: 0.527117\n",
      "epoch 171; iter: 0; batch classifier loss: 0.320235; batch adversarial loss: 0.598014\n",
      "epoch 172; iter: 0; batch classifier loss: 0.397557; batch adversarial loss: 0.602480\n",
      "epoch 173; iter: 0; batch classifier loss: 0.404202; batch adversarial loss: 0.489626\n",
      "epoch 174; iter: 0; batch classifier loss: 0.362113; batch adversarial loss: 0.478884\n",
      "epoch 175; iter: 0; batch classifier loss: 0.368006; batch adversarial loss: 0.629050\n",
      "epoch 176; iter: 0; batch classifier loss: 0.384284; batch adversarial loss: 0.590901\n",
      "epoch 177; iter: 0; batch classifier loss: 0.311485; batch adversarial loss: 0.657162\n",
      "epoch 178; iter: 0; batch classifier loss: 0.320148; batch adversarial loss: 0.628383\n",
      "epoch 179; iter: 0; batch classifier loss: 0.345010; batch adversarial loss: 0.509309\n",
      "epoch 180; iter: 0; batch classifier loss: 0.305758; batch adversarial loss: 0.486987\n",
      "epoch 181; iter: 0; batch classifier loss: 0.421255; batch adversarial loss: 0.479010\n",
      "epoch 182; iter: 0; batch classifier loss: 0.377249; batch adversarial loss: 0.545288\n",
      "epoch 183; iter: 0; batch classifier loss: 0.416685; batch adversarial loss: 0.599158\n",
      "epoch 184; iter: 0; batch classifier loss: 0.350820; batch adversarial loss: 0.543583\n",
      "epoch 185; iter: 0; batch classifier loss: 0.347302; batch adversarial loss: 0.635027\n",
      "epoch 186; iter: 0; batch classifier loss: 0.361274; batch adversarial loss: 0.541414\n",
      "epoch 187; iter: 0; batch classifier loss: 0.370647; batch adversarial loss: 0.643703\n",
      "epoch 188; iter: 0; batch classifier loss: 0.367422; batch adversarial loss: 0.591676\n",
      "epoch 189; iter: 0; batch classifier loss: 0.377946; batch adversarial loss: 0.524374\n",
      "epoch 190; iter: 0; batch classifier loss: 0.377463; batch adversarial loss: 0.545154\n",
      "epoch 191; iter: 0; batch classifier loss: 0.380822; batch adversarial loss: 0.608403\n",
      "epoch 192; iter: 0; batch classifier loss: 0.351079; batch adversarial loss: 0.497624\n",
      "epoch 193; iter: 0; batch classifier loss: 0.389833; batch adversarial loss: 0.599553\n",
      "epoch 194; iter: 0; batch classifier loss: 0.399841; batch adversarial loss: 0.526122\n",
      "epoch 195; iter: 0; batch classifier loss: 0.386829; batch adversarial loss: 0.517478\n",
      "epoch 196; iter: 0; batch classifier loss: 0.407678; batch adversarial loss: 0.519067\n",
      "epoch 197; iter: 0; batch classifier loss: 0.361679; batch adversarial loss: 0.546770\n",
      "epoch 198; iter: 0; batch classifier loss: 0.345056; batch adversarial loss: 0.523786\n",
      "epoch 199; iter: 0; batch classifier loss: 0.431258; batch adversarial loss: 0.546551\n",
      "epoch 0; iter: 0; batch classifier loss: 0.748811; batch adversarial loss: 0.768682\n",
      "epoch 1; iter: 0; batch classifier loss: 0.617981; batch adversarial loss: 0.715196\n",
      "epoch 2; iter: 0; batch classifier loss: 0.567309; batch adversarial loss: 0.674378\n",
      "epoch 3; iter: 0; batch classifier loss: 0.550278; batch adversarial loss: 0.647066\n",
      "epoch 4; iter: 0; batch classifier loss: 0.573678; batch adversarial loss: 0.634207\n",
      "epoch 5; iter: 0; batch classifier loss: 0.567637; batch adversarial loss: 0.633234\n",
      "epoch 6; iter: 0; batch classifier loss: 0.511935; batch adversarial loss: 0.591721\n",
      "epoch 7; iter: 0; batch classifier loss: 0.573572; batch adversarial loss: 0.560144\n",
      "epoch 8; iter: 0; batch classifier loss: 0.519507; batch adversarial loss: 0.589538\n",
      "epoch 9; iter: 0; batch classifier loss: 0.534766; batch adversarial loss: 0.547026\n",
      "epoch 10; iter: 0; batch classifier loss: 0.506596; batch adversarial loss: 0.578975\n",
      "epoch 11; iter: 0; batch classifier loss: 0.560698; batch adversarial loss: 0.610310\n",
      "epoch 12; iter: 0; batch classifier loss: 0.588283; batch adversarial loss: 0.579843\n",
      "epoch 13; iter: 0; batch classifier loss: 0.462083; batch adversarial loss: 0.552193\n",
      "epoch 14; iter: 0; batch classifier loss: 0.554859; batch adversarial loss: 0.597200\n",
      "epoch 15; iter: 0; batch classifier loss: 0.451401; batch adversarial loss: 0.596029\n",
      "epoch 16; iter: 0; batch classifier loss: 0.430663; batch adversarial loss: 0.602503\n",
      "epoch 17; iter: 0; batch classifier loss: 0.549573; batch adversarial loss: 0.511651\n",
      "epoch 18; iter: 0; batch classifier loss: 0.529123; batch adversarial loss: 0.527439\n",
      "epoch 19; iter: 0; batch classifier loss: 0.481524; batch adversarial loss: 0.579008\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20; iter: 0; batch classifier loss: 0.483447; batch adversarial loss: 0.604528\n",
      "epoch 21; iter: 0; batch classifier loss: 0.453009; batch adversarial loss: 0.537530\n",
      "epoch 22; iter: 0; batch classifier loss: 0.419480; batch adversarial loss: 0.554291\n",
      "epoch 23; iter: 0; batch classifier loss: 0.543647; batch adversarial loss: 0.571096\n",
      "epoch 24; iter: 0; batch classifier loss: 0.523442; batch adversarial loss: 0.578365\n",
      "epoch 25; iter: 0; batch classifier loss: 0.421647; batch adversarial loss: 0.568549\n",
      "epoch 26; iter: 0; batch classifier loss: 0.498221; batch adversarial loss: 0.512957\n",
      "epoch 27; iter: 0; batch classifier loss: 0.488611; batch adversarial loss: 0.518597\n",
      "epoch 28; iter: 0; batch classifier loss: 0.475433; batch adversarial loss: 0.579464\n",
      "epoch 29; iter: 0; batch classifier loss: 0.537493; batch adversarial loss: 0.586918\n",
      "epoch 30; iter: 0; batch classifier loss: 0.496040; batch adversarial loss: 0.579084\n",
      "epoch 31; iter: 0; batch classifier loss: 0.506793; batch adversarial loss: 0.521383\n",
      "epoch 32; iter: 0; batch classifier loss: 0.481339; batch adversarial loss: 0.553857\n",
      "epoch 33; iter: 0; batch classifier loss: 0.506063; batch adversarial loss: 0.596403\n",
      "epoch 34; iter: 0; batch classifier loss: 0.411064; batch adversarial loss: 0.503000\n",
      "epoch 35; iter: 0; batch classifier loss: 0.461883; batch adversarial loss: 0.562246\n",
      "epoch 36; iter: 0; batch classifier loss: 0.545369; batch adversarial loss: 0.579263\n",
      "epoch 37; iter: 0; batch classifier loss: 0.464295; batch adversarial loss: 0.519380\n",
      "epoch 38; iter: 0; batch classifier loss: 0.390667; batch adversarial loss: 0.510500\n",
      "epoch 39; iter: 0; batch classifier loss: 0.401887; batch adversarial loss: 0.562421\n",
      "epoch 40; iter: 0; batch classifier loss: 0.456290; batch adversarial loss: 0.544875\n",
      "epoch 41; iter: 0; batch classifier loss: 0.377512; batch adversarial loss: 0.544964\n",
      "epoch 42; iter: 0; batch classifier loss: 0.420983; batch adversarial loss: 0.474687\n",
      "epoch 43; iter: 0; batch classifier loss: 0.450652; batch adversarial loss: 0.491426\n",
      "epoch 44; iter: 0; batch classifier loss: 0.485247; batch adversarial loss: 0.553976\n",
      "epoch 45; iter: 0; batch classifier loss: 0.456218; batch adversarial loss: 0.518246\n",
      "epoch 46; iter: 0; batch classifier loss: 0.497627; batch adversarial loss: 0.545207\n",
      "epoch 47; iter: 0; batch classifier loss: 0.439072; batch adversarial loss: 0.553539\n",
      "epoch 48; iter: 0; batch classifier loss: 0.364826; batch adversarial loss: 0.553775\n",
      "epoch 49; iter: 0; batch classifier loss: 0.487402; batch adversarial loss: 0.525421\n",
      "epoch 50; iter: 0; batch classifier loss: 0.531215; batch adversarial loss: 0.491622\n",
      "epoch 51; iter: 0; batch classifier loss: 0.445113; batch adversarial loss: 0.527357\n",
      "epoch 52; iter: 0; batch classifier loss: 0.450108; batch adversarial loss: 0.535339\n",
      "epoch 53; iter: 0; batch classifier loss: 0.383627; batch adversarial loss: 0.508855\n",
      "epoch 54; iter: 0; batch classifier loss: 0.374413; batch adversarial loss: 0.600105\n",
      "epoch 55; iter: 0; batch classifier loss: 0.355941; batch adversarial loss: 0.508898\n",
      "epoch 56; iter: 0; batch classifier loss: 0.444243; batch adversarial loss: 0.509009\n",
      "epoch 57; iter: 0; batch classifier loss: 0.435638; batch adversarial loss: 0.597583\n",
      "epoch 58; iter: 0; batch classifier loss: 0.428262; batch adversarial loss: 0.616149\n",
      "epoch 59; iter: 0; batch classifier loss: 0.455210; batch adversarial loss: 0.537523\n",
      "epoch 60; iter: 0; batch classifier loss: 0.352285; batch adversarial loss: 0.563045\n",
      "epoch 61; iter: 0; batch classifier loss: 0.417753; batch adversarial loss: 0.570888\n",
      "epoch 62; iter: 0; batch classifier loss: 0.377166; batch adversarial loss: 0.535188\n",
      "epoch 63; iter: 0; batch classifier loss: 0.448968; batch adversarial loss: 0.528512\n",
      "epoch 64; iter: 0; batch classifier loss: 0.404677; batch adversarial loss: 0.489510\n",
      "epoch 65; iter: 0; batch classifier loss: 0.388481; batch adversarial loss: 0.475154\n",
      "epoch 66; iter: 0; batch classifier loss: 0.447131; batch adversarial loss: 0.570598\n",
      "epoch 67; iter: 0; batch classifier loss: 0.432042; batch adversarial loss: 0.547087\n",
      "epoch 68; iter: 0; batch classifier loss: 0.466100; batch adversarial loss: 0.535199\n",
      "epoch 69; iter: 0; batch classifier loss: 0.356332; batch adversarial loss: 0.560214\n",
      "epoch 70; iter: 0; batch classifier loss: 0.354461; batch adversarial loss: 0.543057\n",
      "epoch 71; iter: 0; batch classifier loss: 0.429746; batch adversarial loss: 0.515820\n",
      "epoch 72; iter: 0; batch classifier loss: 0.413253; batch adversarial loss: 0.491298\n",
      "epoch 73; iter: 0; batch classifier loss: 0.375787; batch adversarial loss: 0.519793\n",
      "epoch 74; iter: 0; batch classifier loss: 0.320846; batch adversarial loss: 0.670608\n",
      "epoch 75; iter: 0; batch classifier loss: 0.396986; batch adversarial loss: 0.569631\n",
      "epoch 76; iter: 0; batch classifier loss: 0.361487; batch adversarial loss: 0.538029\n",
      "epoch 77; iter: 0; batch classifier loss: 0.414923; batch adversarial loss: 0.614959\n",
      "epoch 78; iter: 0; batch classifier loss: 0.421809; batch adversarial loss: 0.589855\n",
      "epoch 79; iter: 0; batch classifier loss: 0.406637; batch adversarial loss: 0.546980\n",
      "epoch 80; iter: 0; batch classifier loss: 0.435595; batch adversarial loss: 0.578511\n",
      "epoch 81; iter: 0; batch classifier loss: 0.414412; batch adversarial loss: 0.555248\n",
      "epoch 82; iter: 0; batch classifier loss: 0.357601; batch adversarial loss: 0.556376\n",
      "epoch 83; iter: 0; batch classifier loss: 0.377852; batch adversarial loss: 0.507597\n",
      "epoch 84; iter: 0; batch classifier loss: 0.368470; batch adversarial loss: 0.572461\n",
      "epoch 85; iter: 0; batch classifier loss: 0.371709; batch adversarial loss: 0.543986\n",
      "epoch 86; iter: 0; batch classifier loss: 0.397111; batch adversarial loss: 0.562379\n",
      "epoch 87; iter: 0; batch classifier loss: 0.406315; batch adversarial loss: 0.568619\n",
      "epoch 88; iter: 0; batch classifier loss: 0.356237; batch adversarial loss: 0.537680\n",
      "epoch 89; iter: 0; batch classifier loss: 0.389419; batch adversarial loss: 0.596868\n",
      "epoch 90; iter: 0; batch classifier loss: 0.315683; batch adversarial loss: 0.548480\n",
      "epoch 91; iter: 0; batch classifier loss: 0.442199; batch adversarial loss: 0.511456\n",
      "epoch 92; iter: 0; batch classifier loss: 0.402087; batch adversarial loss: 0.634989\n",
      "epoch 93; iter: 0; batch classifier loss: 0.431714; batch adversarial loss: 0.543119\n",
      "epoch 94; iter: 0; batch classifier loss: 0.326737; batch adversarial loss: 0.536196\n",
      "epoch 95; iter: 0; batch classifier loss: 0.423037; batch adversarial loss: 0.536321\n",
      "epoch 96; iter: 0; batch classifier loss: 0.395906; batch adversarial loss: 0.535277\n",
      "epoch 97; iter: 0; batch classifier loss: 0.371835; batch adversarial loss: 0.545789\n",
      "epoch 98; iter: 0; batch classifier loss: 0.391842; batch adversarial loss: 0.545930\n",
      "epoch 99; iter: 0; batch classifier loss: 0.458141; batch adversarial loss: 0.480275\n",
      "epoch 100; iter: 0; batch classifier loss: 0.416020; batch adversarial loss: 0.640931\n",
      "epoch 101; iter: 0; batch classifier loss: 0.370842; batch adversarial loss: 0.492851\n",
      "epoch 102; iter: 0; batch classifier loss: 0.391822; batch adversarial loss: 0.501468\n",
      "epoch 103; iter: 0; batch classifier loss: 0.374676; batch adversarial loss: 0.511329\n",
      "epoch 104; iter: 0; batch classifier loss: 0.397985; batch adversarial loss: 0.563061\n",
      "epoch 105; iter: 0; batch classifier loss: 0.348750; batch adversarial loss: 0.592065\n",
      "epoch 106; iter: 0; batch classifier loss: 0.345915; batch adversarial loss: 0.518903\n",
      "epoch 107; iter: 0; batch classifier loss: 0.423055; batch adversarial loss: 0.472101\n",
      "epoch 108; iter: 0; batch classifier loss: 0.337906; batch adversarial loss: 0.570349\n",
      "epoch 109; iter: 0; batch classifier loss: 0.430701; batch adversarial loss: 0.518630\n",
      "epoch 110; iter: 0; batch classifier loss: 0.409582; batch adversarial loss: 0.605784\n",
      "epoch 111; iter: 0; batch classifier loss: 0.448767; batch adversarial loss: 0.527957\n",
      "epoch 112; iter: 0; batch classifier loss: 0.336721; batch adversarial loss: 0.623915\n",
      "epoch 113; iter: 0; batch classifier loss: 0.399264; batch adversarial loss: 0.587913\n",
      "epoch 114; iter: 0; batch classifier loss: 0.353986; batch adversarial loss: 0.553607\n",
      "epoch 115; iter: 0; batch classifier loss: 0.417767; batch adversarial loss: 0.546919\n",
      "epoch 116; iter: 0; batch classifier loss: 0.320844; batch adversarial loss: 0.560988\n",
      "epoch 117; iter: 0; batch classifier loss: 0.455291; batch adversarial loss: 0.538445\n",
      "epoch 118; iter: 0; batch classifier loss: 0.377530; batch adversarial loss: 0.560791\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 119; iter: 0; batch classifier loss: 0.426069; batch adversarial loss: 0.562210\n",
      "epoch 120; iter: 0; batch classifier loss: 0.304910; batch adversarial loss: 0.499966\n",
      "epoch 121; iter: 0; batch classifier loss: 0.403535; batch adversarial loss: 0.564063\n",
      "epoch 122; iter: 0; batch classifier loss: 0.338389; batch adversarial loss: 0.501115\n",
      "epoch 123; iter: 0; batch classifier loss: 0.385888; batch adversarial loss: 0.544007\n",
      "epoch 124; iter: 0; batch classifier loss: 0.469057; batch adversarial loss: 0.508569\n",
      "epoch 125; iter: 0; batch classifier loss: 0.356199; batch adversarial loss: 0.488038\n",
      "epoch 126; iter: 0; batch classifier loss: 0.411140; batch adversarial loss: 0.614334\n",
      "epoch 127; iter: 0; batch classifier loss: 0.415983; batch adversarial loss: 0.661545\n",
      "epoch 128; iter: 0; batch classifier loss: 0.338548; batch adversarial loss: 0.510899\n",
      "epoch 129; iter: 0; batch classifier loss: 0.388602; batch adversarial loss: 0.528922\n",
      "epoch 130; iter: 0; batch classifier loss: 0.445671; batch adversarial loss: 0.572725\n",
      "epoch 131; iter: 0; batch classifier loss: 0.323622; batch adversarial loss: 0.475233\n",
      "epoch 132; iter: 0; batch classifier loss: 0.359960; batch adversarial loss: 0.516248\n",
      "epoch 133; iter: 0; batch classifier loss: 0.308619; batch adversarial loss: 0.576982\n",
      "epoch 134; iter: 0; batch classifier loss: 0.336115; batch adversarial loss: 0.572257\n",
      "epoch 135; iter: 0; batch classifier loss: 0.347110; batch adversarial loss: 0.571132\n",
      "epoch 136; iter: 0; batch classifier loss: 0.365807; batch adversarial loss: 0.498221\n",
      "epoch 137; iter: 0; batch classifier loss: 0.369544; batch adversarial loss: 0.535937\n",
      "epoch 138; iter: 0; batch classifier loss: 0.433989; batch adversarial loss: 0.562072\n",
      "epoch 139; iter: 0; batch classifier loss: 0.435272; batch adversarial loss: 0.608470\n",
      "epoch 140; iter: 0; batch classifier loss: 0.346690; batch adversarial loss: 0.490710\n",
      "epoch 141; iter: 0; batch classifier loss: 0.421007; batch adversarial loss: 0.590368\n",
      "epoch 142; iter: 0; batch classifier loss: 0.445929; batch adversarial loss: 0.464819\n",
      "epoch 143; iter: 0; batch classifier loss: 0.360618; batch adversarial loss: 0.484941\n",
      "epoch 144; iter: 0; batch classifier loss: 0.392004; batch adversarial loss: 0.555157\n",
      "epoch 145; iter: 0; batch classifier loss: 0.374010; batch adversarial loss: 0.482578\n",
      "epoch 146; iter: 0; batch classifier loss: 0.307816; batch adversarial loss: 0.572360\n",
      "epoch 147; iter: 0; batch classifier loss: 0.307200; batch adversarial loss: 0.536723\n",
      "epoch 148; iter: 0; batch classifier loss: 0.329323; batch adversarial loss: 0.570878\n",
      "epoch 149; iter: 0; batch classifier loss: 0.382179; batch adversarial loss: 0.544585\n",
      "epoch 150; iter: 0; batch classifier loss: 0.360421; batch adversarial loss: 0.561586\n",
      "epoch 151; iter: 0; batch classifier loss: 0.402003; batch adversarial loss: 0.524422\n",
      "epoch 152; iter: 0; batch classifier loss: 0.415789; batch adversarial loss: 0.605301\n",
      "epoch 153; iter: 0; batch classifier loss: 0.339149; batch adversarial loss: 0.499330\n",
      "epoch 154; iter: 0; batch classifier loss: 0.424792; batch adversarial loss: 0.525102\n",
      "epoch 155; iter: 0; batch classifier loss: 0.368239; batch adversarial loss: 0.527228\n",
      "epoch 156; iter: 0; batch classifier loss: 0.381454; batch adversarial loss: 0.560583\n",
      "epoch 157; iter: 0; batch classifier loss: 0.377060; batch adversarial loss: 0.508199\n",
      "epoch 158; iter: 0; batch classifier loss: 0.301354; batch adversarial loss: 0.544299\n",
      "epoch 159; iter: 0; batch classifier loss: 0.308870; batch adversarial loss: 0.534701\n",
      "epoch 160; iter: 0; batch classifier loss: 0.377491; batch adversarial loss: 0.633113\n",
      "epoch 161; iter: 0; batch classifier loss: 0.254439; batch adversarial loss: 0.534045\n",
      "epoch 162; iter: 0; batch classifier loss: 0.347207; batch adversarial loss: 0.509503\n",
      "epoch 163; iter: 0; batch classifier loss: 0.311495; batch adversarial loss: 0.526109\n",
      "epoch 164; iter: 0; batch classifier loss: 0.330106; batch adversarial loss: 0.554994\n",
      "epoch 165; iter: 0; batch classifier loss: 0.346086; batch adversarial loss: 0.493250\n",
      "epoch 166; iter: 0; batch classifier loss: 0.369745; batch adversarial loss: 0.590115\n",
      "epoch 167; iter: 0; batch classifier loss: 0.359936; batch adversarial loss: 0.520426\n",
      "epoch 168; iter: 0; batch classifier loss: 0.433948; batch adversarial loss: 0.521047\n",
      "epoch 169; iter: 0; batch classifier loss: 0.416204; batch adversarial loss: 0.596268\n",
      "epoch 170; iter: 0; batch classifier loss: 0.439406; batch adversarial loss: 0.537377\n",
      "epoch 171; iter: 0; batch classifier loss: 0.323008; batch adversarial loss: 0.599031\n",
      "epoch 172; iter: 0; batch classifier loss: 0.423733; batch adversarial loss: 0.506774\n",
      "epoch 173; iter: 0; batch classifier loss: 0.313114; batch adversarial loss: 0.516920\n",
      "epoch 174; iter: 0; batch classifier loss: 0.356093; batch adversarial loss: 0.516704\n",
      "epoch 175; iter: 0; batch classifier loss: 0.275720; batch adversarial loss: 0.489260\n",
      "epoch 176; iter: 0; batch classifier loss: 0.334614; batch adversarial loss: 0.489377\n",
      "epoch 177; iter: 0; batch classifier loss: 0.410709; batch adversarial loss: 0.437195\n",
      "epoch 178; iter: 0; batch classifier loss: 0.375794; batch adversarial loss: 0.535054\n",
      "epoch 179; iter: 0; batch classifier loss: 0.360786; batch adversarial loss: 0.542497\n",
      "epoch 180; iter: 0; batch classifier loss: 0.303948; batch adversarial loss: 0.553767\n",
      "epoch 181; iter: 0; batch classifier loss: 0.312359; batch adversarial loss: 0.517899\n",
      "epoch 182; iter: 0; batch classifier loss: 0.294476; batch adversarial loss: 0.535038\n",
      "epoch 183; iter: 0; batch classifier loss: 0.344629; batch adversarial loss: 0.586490\n",
      "epoch 184; iter: 0; batch classifier loss: 0.398951; batch adversarial loss: 0.535361\n",
      "epoch 185; iter: 0; batch classifier loss: 0.430776; batch adversarial loss: 0.553544\n",
      "epoch 186; iter: 0; batch classifier loss: 0.324440; batch adversarial loss: 0.553663\n",
      "epoch 187; iter: 0; batch classifier loss: 0.375819; batch adversarial loss: 0.580849\n",
      "epoch 188; iter: 0; batch classifier loss: 0.313409; batch adversarial loss: 0.535621\n",
      "epoch 189; iter: 0; batch classifier loss: 0.414449; batch adversarial loss: 0.536025\n",
      "epoch 190; iter: 0; batch classifier loss: 0.467250; batch adversarial loss: 0.536708\n",
      "epoch 191; iter: 0; batch classifier loss: 0.380712; batch adversarial loss: 0.533828\n",
      "epoch 192; iter: 0; batch classifier loss: 0.401810; batch adversarial loss: 0.560963\n",
      "epoch 193; iter: 0; batch classifier loss: 0.437294; batch adversarial loss: 0.631341\n",
      "epoch 194; iter: 0; batch classifier loss: 0.343654; batch adversarial loss: 0.590675\n",
      "epoch 195; iter: 0; batch classifier loss: 0.401954; batch adversarial loss: 0.552242\n",
      "epoch 196; iter: 0; batch classifier loss: 0.350459; batch adversarial loss: 0.480922\n",
      "epoch 197; iter: 0; batch classifier loss: 0.350910; batch adversarial loss: 0.547822\n",
      "epoch 198; iter: 0; batch classifier loss: 0.329676; batch adversarial loss: 0.588715\n",
      "epoch 199; iter: 0; batch classifier loss: 0.416305; batch adversarial loss: 0.582650\n",
      "epoch 0; iter: 0; batch classifier loss: 0.665336; batch adversarial loss: 0.655364\n",
      "epoch 1; iter: 0; batch classifier loss: 0.562434; batch adversarial loss: 0.639297\n",
      "epoch 2; iter: 0; batch classifier loss: 0.610575; batch adversarial loss: 0.610975\n",
      "epoch 3; iter: 0; batch classifier loss: 0.530311; batch adversarial loss: 0.646640\n",
      "epoch 4; iter: 0; batch classifier loss: 0.571344; batch adversarial loss: 0.667575\n",
      "epoch 5; iter: 0; batch classifier loss: 0.587841; batch adversarial loss: 0.601134\n",
      "epoch 6; iter: 0; batch classifier loss: 0.539854; batch adversarial loss: 0.598218\n",
      "epoch 7; iter: 0; batch classifier loss: 0.581805; batch adversarial loss: 0.626494\n",
      "epoch 8; iter: 0; batch classifier loss: 0.506202; batch adversarial loss: 0.590080\n",
      "epoch 9; iter: 0; batch classifier loss: 0.565160; batch adversarial loss: 0.567177\n",
      "epoch 10; iter: 0; batch classifier loss: 0.550941; batch adversarial loss: 0.589149\n",
      "epoch 11; iter: 0; batch classifier loss: 0.540378; batch adversarial loss: 0.562542\n",
      "epoch 12; iter: 0; batch classifier loss: 0.544468; batch adversarial loss: 0.526860\n",
      "epoch 13; iter: 0; batch classifier loss: 0.527429; batch adversarial loss: 0.533898\n",
      "epoch 14; iter: 0; batch classifier loss: 0.406696; batch adversarial loss: 0.546904\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 15; iter: 0; batch classifier loss: 0.570456; batch adversarial loss: 0.549758\n",
      "epoch 16; iter: 0; batch classifier loss: 0.525145; batch adversarial loss: 0.589231\n",
      "epoch 17; iter: 0; batch classifier loss: 0.462612; batch adversarial loss: 0.560582\n",
      "epoch 18; iter: 0; batch classifier loss: 0.592340; batch adversarial loss: 0.559420\n",
      "epoch 19; iter: 0; batch classifier loss: 0.512094; batch adversarial loss: 0.572938\n",
      "epoch 20; iter: 0; batch classifier loss: 0.499399; batch adversarial loss: 0.564912\n",
      "epoch 21; iter: 0; batch classifier loss: 0.501611; batch adversarial loss: 0.552336\n",
      "epoch 22; iter: 0; batch classifier loss: 0.510710; batch adversarial loss: 0.548553\n",
      "epoch 23; iter: 0; batch classifier loss: 0.444559; batch adversarial loss: 0.601217\n",
      "epoch 24; iter: 0; batch classifier loss: 0.487480; batch adversarial loss: 0.585856\n",
      "epoch 25; iter: 0; batch classifier loss: 0.451658; batch adversarial loss: 0.579591\n",
      "epoch 26; iter: 0; batch classifier loss: 0.522001; batch adversarial loss: 0.564986\n",
      "epoch 27; iter: 0; batch classifier loss: 0.479254; batch adversarial loss: 0.546447\n",
      "epoch 28; iter: 0; batch classifier loss: 0.506613; batch adversarial loss: 0.512547\n",
      "epoch 29; iter: 0; batch classifier loss: 0.480908; batch adversarial loss: 0.547225\n",
      "epoch 30; iter: 0; batch classifier loss: 0.475894; batch adversarial loss: 0.596004\n",
      "epoch 31; iter: 0; batch classifier loss: 0.465715; batch adversarial loss: 0.479517\n",
      "epoch 32; iter: 0; batch classifier loss: 0.531170; batch adversarial loss: 0.571302\n",
      "epoch 33; iter: 0; batch classifier loss: 0.502438; batch adversarial loss: 0.581071\n",
      "epoch 34; iter: 0; batch classifier loss: 0.486677; batch adversarial loss: 0.579776\n",
      "epoch 35; iter: 0; batch classifier loss: 0.477614; batch adversarial loss: 0.553713\n",
      "epoch 36; iter: 0; batch classifier loss: 0.442969; batch adversarial loss: 0.450150\n",
      "epoch 37; iter: 0; batch classifier loss: 0.450374; batch adversarial loss: 0.501662\n",
      "epoch 38; iter: 0; batch classifier loss: 0.434005; batch adversarial loss: 0.622470\n",
      "epoch 39; iter: 0; batch classifier loss: 0.416760; batch adversarial loss: 0.570946\n",
      "epoch 40; iter: 0; batch classifier loss: 0.419847; batch adversarial loss: 0.527767\n",
      "epoch 41; iter: 0; batch classifier loss: 0.398442; batch adversarial loss: 0.492832\n",
      "epoch 42; iter: 0; batch classifier loss: 0.439948; batch adversarial loss: 0.553256\n",
      "epoch 43; iter: 0; batch classifier loss: 0.478519; batch adversarial loss: 0.498861\n",
      "epoch 44; iter: 0; batch classifier loss: 0.442587; batch adversarial loss: 0.487423\n",
      "epoch 45; iter: 0; batch classifier loss: 0.402842; batch adversarial loss: 0.523259\n",
      "epoch 46; iter: 0; batch classifier loss: 0.378460; batch adversarial loss: 0.525219\n",
      "epoch 47; iter: 0; batch classifier loss: 0.441672; batch adversarial loss: 0.655364\n",
      "epoch 48; iter: 0; batch classifier loss: 0.510377; batch adversarial loss: 0.514944\n",
      "epoch 49; iter: 0; batch classifier loss: 0.490084; batch adversarial loss: 0.514263\n",
      "epoch 50; iter: 0; batch classifier loss: 0.529845; batch adversarial loss: 0.527680\n",
      "epoch 51; iter: 0; batch classifier loss: 0.510316; batch adversarial loss: 0.539676\n",
      "epoch 52; iter: 0; batch classifier loss: 0.443247; batch adversarial loss: 0.476483\n",
      "epoch 53; iter: 0; batch classifier loss: 0.478664; batch adversarial loss: 0.523927\n",
      "epoch 54; iter: 0; batch classifier loss: 0.441754; batch adversarial loss: 0.537754\n",
      "epoch 55; iter: 0; batch classifier loss: 0.397920; batch adversarial loss: 0.521474\n",
      "epoch 56; iter: 0; batch classifier loss: 0.524796; batch adversarial loss: 0.502740\n",
      "epoch 57; iter: 0; batch classifier loss: 0.451073; batch adversarial loss: 0.536903\n",
      "epoch 58; iter: 0; batch classifier loss: 0.501365; batch adversarial loss: 0.535531\n",
      "epoch 59; iter: 0; batch classifier loss: 0.469098; batch adversarial loss: 0.519426\n",
      "epoch 60; iter: 0; batch classifier loss: 0.363091; batch adversarial loss: 0.587526\n",
      "epoch 61; iter: 0; batch classifier loss: 0.490045; batch adversarial loss: 0.527952\n",
      "epoch 62; iter: 0; batch classifier loss: 0.406670; batch adversarial loss: 0.554129\n",
      "epoch 63; iter: 0; batch classifier loss: 0.403470; batch adversarial loss: 0.518707\n",
      "epoch 64; iter: 0; batch classifier loss: 0.391401; batch adversarial loss: 0.492198\n",
      "epoch 65; iter: 0; batch classifier loss: 0.414565; batch adversarial loss: 0.543769\n",
      "epoch 66; iter: 0; batch classifier loss: 0.432088; batch adversarial loss: 0.519641\n",
      "epoch 67; iter: 0; batch classifier loss: 0.406739; batch adversarial loss: 0.551923\n",
      "epoch 68; iter: 0; batch classifier loss: 0.407026; batch adversarial loss: 0.519134\n",
      "epoch 69; iter: 0; batch classifier loss: 0.461206; batch adversarial loss: 0.509247\n",
      "epoch 70; iter: 0; batch classifier loss: 0.433296; batch adversarial loss: 0.518264\n",
      "epoch 71; iter: 0; batch classifier loss: 0.398046; batch adversarial loss: 0.588611\n",
      "epoch 72; iter: 0; batch classifier loss: 0.355519; batch adversarial loss: 0.518872\n",
      "epoch 73; iter: 0; batch classifier loss: 0.377291; batch adversarial loss: 0.570883\n",
      "epoch 74; iter: 0; batch classifier loss: 0.420082; batch adversarial loss: 0.526468\n",
      "epoch 75; iter: 0; batch classifier loss: 0.475810; batch adversarial loss: 0.580598\n",
      "epoch 76; iter: 0; batch classifier loss: 0.358524; batch adversarial loss: 0.579799\n",
      "epoch 77; iter: 0; batch classifier loss: 0.411683; batch adversarial loss: 0.598244\n",
      "epoch 78; iter: 0; batch classifier loss: 0.435309; batch adversarial loss: 0.614933\n",
      "epoch 79; iter: 0; batch classifier loss: 0.377990; batch adversarial loss: 0.544228\n",
      "epoch 80; iter: 0; batch classifier loss: 0.407556; batch adversarial loss: 0.510110\n",
      "epoch 81; iter: 0; batch classifier loss: 0.461962; batch adversarial loss: 0.536122\n",
      "epoch 82; iter: 0; batch classifier loss: 0.397111; batch adversarial loss: 0.553206\n",
      "epoch 83; iter: 0; batch classifier loss: 0.360975; batch adversarial loss: 0.607019\n",
      "epoch 84; iter: 0; batch classifier loss: 0.440008; batch adversarial loss: 0.569944\n",
      "epoch 85; iter: 0; batch classifier loss: 0.411110; batch adversarial loss: 0.597687\n",
      "epoch 86; iter: 0; batch classifier loss: 0.367541; batch adversarial loss: 0.527665\n",
      "epoch 87; iter: 0; batch classifier loss: 0.410539; batch adversarial loss: 0.501832\n",
      "epoch 88; iter: 0; batch classifier loss: 0.355907; batch adversarial loss: 0.561802\n",
      "epoch 89; iter: 0; batch classifier loss: 0.379446; batch adversarial loss: 0.456841\n",
      "epoch 90; iter: 0; batch classifier loss: 0.430349; batch adversarial loss: 0.580123\n",
      "epoch 91; iter: 0; batch classifier loss: 0.439274; batch adversarial loss: 0.493067\n",
      "epoch 92; iter: 0; batch classifier loss: 0.359092; batch adversarial loss: 0.537347\n",
      "epoch 93; iter: 0; batch classifier loss: 0.433326; batch adversarial loss: 0.475559\n",
      "epoch 94; iter: 0; batch classifier loss: 0.426715; batch adversarial loss: 0.614971\n",
      "epoch 95; iter: 0; batch classifier loss: 0.343224; batch adversarial loss: 0.552421\n",
      "epoch 96; iter: 0; batch classifier loss: 0.470529; batch adversarial loss: 0.589603\n",
      "epoch 97; iter: 0; batch classifier loss: 0.452695; batch adversarial loss: 0.580591\n",
      "epoch 98; iter: 0; batch classifier loss: 0.430453; batch adversarial loss: 0.562634\n",
      "epoch 99; iter: 0; batch classifier loss: 0.439501; batch adversarial loss: 0.607279\n",
      "epoch 100; iter: 0; batch classifier loss: 0.412948; batch adversarial loss: 0.517307\n",
      "epoch 101; iter: 0; batch classifier loss: 0.372095; batch adversarial loss: 0.545164\n",
      "epoch 102; iter: 0; batch classifier loss: 0.430757; batch adversarial loss: 0.527496\n",
      "epoch 103; iter: 0; batch classifier loss: 0.403259; batch adversarial loss: 0.589891\n",
      "epoch 104; iter: 0; batch classifier loss: 0.434583; batch adversarial loss: 0.597982\n",
      "epoch 105; iter: 0; batch classifier loss: 0.406592; batch adversarial loss: 0.614453\n",
      "epoch 106; iter: 0; batch classifier loss: 0.455467; batch adversarial loss: 0.633363\n",
      "epoch 107; iter: 0; batch classifier loss: 0.364981; batch adversarial loss: 0.561682\n",
      "epoch 108; iter: 0; batch classifier loss: 0.393514; batch adversarial loss: 0.598935\n",
      "epoch 109; iter: 0; batch classifier loss: 0.351079; batch adversarial loss: 0.580447\n",
      "epoch 110; iter: 0; batch classifier loss: 0.388360; batch adversarial loss: 0.499902\n",
      "epoch 111; iter: 0; batch classifier loss: 0.355265; batch adversarial loss: 0.544795\n",
      "epoch 112; iter: 0; batch classifier loss: 0.391877; batch adversarial loss: 0.473661\n",
      "epoch 113; iter: 0; batch classifier loss: 0.324559; batch adversarial loss: 0.553538\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 114; iter: 0; batch classifier loss: 0.349548; batch adversarial loss: 0.563214\n",
      "epoch 115; iter: 0; batch classifier loss: 0.406009; batch adversarial loss: 0.519211\n",
      "epoch 116; iter: 0; batch classifier loss: 0.405246; batch adversarial loss: 0.545660\n",
      "epoch 117; iter: 0; batch classifier loss: 0.337180; batch adversarial loss: 0.588009\n",
      "epoch 118; iter: 0; batch classifier loss: 0.399023; batch adversarial loss: 0.632289\n",
      "epoch 119; iter: 0; batch classifier loss: 0.396172; batch adversarial loss: 0.615684\n",
      "epoch 120; iter: 0; batch classifier loss: 0.381883; batch adversarial loss: 0.518653\n",
      "epoch 121; iter: 0; batch classifier loss: 0.435269; batch adversarial loss: 0.572433\n",
      "epoch 122; iter: 0; batch classifier loss: 0.346995; batch adversarial loss: 0.578544\n",
      "epoch 123; iter: 0; batch classifier loss: 0.455534; batch adversarial loss: 0.536111\n",
      "epoch 124; iter: 0; batch classifier loss: 0.379300; batch adversarial loss: 0.598192\n",
      "epoch 125; iter: 0; batch classifier loss: 0.448562; batch adversarial loss: 0.528889\n",
      "epoch 126; iter: 0; batch classifier loss: 0.382244; batch adversarial loss: 0.624482\n",
      "epoch 127; iter: 0; batch classifier loss: 0.272332; batch adversarial loss: 0.535103\n",
      "epoch 128; iter: 0; batch classifier loss: 0.439824; batch adversarial loss: 0.518815\n",
      "epoch 129; iter: 0; batch classifier loss: 0.409427; batch adversarial loss: 0.537264\n",
      "epoch 130; iter: 0; batch classifier loss: 0.386312; batch adversarial loss: 0.554053\n",
      "epoch 131; iter: 0; batch classifier loss: 0.296250; batch adversarial loss: 0.589042\n",
      "epoch 132; iter: 0; batch classifier loss: 0.440439; batch adversarial loss: 0.519301\n",
      "epoch 133; iter: 0; batch classifier loss: 0.395652; batch adversarial loss: 0.580133\n",
      "epoch 134; iter: 0; batch classifier loss: 0.376789; batch adversarial loss: 0.515789\n",
      "epoch 135; iter: 0; batch classifier loss: 0.441155; batch adversarial loss: 0.517783\n",
      "epoch 136; iter: 0; batch classifier loss: 0.414370; batch adversarial loss: 0.499945\n",
      "epoch 137; iter: 0; batch classifier loss: 0.364049; batch adversarial loss: 0.544500\n",
      "epoch 138; iter: 0; batch classifier loss: 0.359684; batch adversarial loss: 0.587142\n",
      "epoch 139; iter: 0; batch classifier loss: 0.328851; batch adversarial loss: 0.492279\n",
      "epoch 140; iter: 0; batch classifier loss: 0.317429; batch adversarial loss: 0.684526\n",
      "epoch 141; iter: 0; batch classifier loss: 0.409525; batch adversarial loss: 0.499357\n",
      "epoch 142; iter: 0; batch classifier loss: 0.365406; batch adversarial loss: 0.570912\n",
      "epoch 143; iter: 0; batch classifier loss: 0.502276; batch adversarial loss: 0.544537\n",
      "epoch 144; iter: 0; batch classifier loss: 0.368221; batch adversarial loss: 0.481386\n",
      "epoch 145; iter: 0; batch classifier loss: 0.381726; batch adversarial loss: 0.596124\n",
      "epoch 146; iter: 0; batch classifier loss: 0.325803; batch adversarial loss: 0.526751\n",
      "epoch 147; iter: 0; batch classifier loss: 0.386735; batch adversarial loss: 0.500525\n",
      "epoch 148; iter: 0; batch classifier loss: 0.296568; batch adversarial loss: 0.526926\n",
      "epoch 149; iter: 0; batch classifier loss: 0.454881; batch adversarial loss: 0.553467\n",
      "epoch 150; iter: 0; batch classifier loss: 0.382714; batch adversarial loss: 0.509530\n",
      "epoch 151; iter: 0; batch classifier loss: 0.341656; batch adversarial loss: 0.492514\n",
      "epoch 152; iter: 0; batch classifier loss: 0.340548; batch adversarial loss: 0.499765\n",
      "epoch 153; iter: 0; batch classifier loss: 0.414376; batch adversarial loss: 0.572328\n",
      "epoch 154; iter: 0; batch classifier loss: 0.380539; batch adversarial loss: 0.589018\n",
      "epoch 155; iter: 0; batch classifier loss: 0.351916; batch adversarial loss: 0.596677\n",
      "epoch 156; iter: 0; batch classifier loss: 0.310009; batch adversarial loss: 0.579366\n",
      "epoch 157; iter: 0; batch classifier loss: 0.358431; batch adversarial loss: 0.555822\n",
      "epoch 158; iter: 0; batch classifier loss: 0.330680; batch adversarial loss: 0.597621\n",
      "epoch 159; iter: 0; batch classifier loss: 0.404956; batch adversarial loss: 0.570369\n",
      "epoch 160; iter: 0; batch classifier loss: 0.421198; batch adversarial loss: 0.553450\n",
      "epoch 161; iter: 0; batch classifier loss: 0.287583; batch adversarial loss: 0.518911\n",
      "epoch 162; iter: 0; batch classifier loss: 0.381369; batch adversarial loss: 0.553542\n",
      "epoch 163; iter: 0; batch classifier loss: 0.334103; batch adversarial loss: 0.589348\n",
      "epoch 164; iter: 0; batch classifier loss: 0.344573; batch adversarial loss: 0.553077\n",
      "epoch 165; iter: 0; batch classifier loss: 0.318840; batch adversarial loss: 0.587341\n",
      "epoch 166; iter: 0; batch classifier loss: 0.334997; batch adversarial loss: 0.588747\n",
      "epoch 167; iter: 0; batch classifier loss: 0.378946; batch adversarial loss: 0.641822\n",
      "epoch 168; iter: 0; batch classifier loss: 0.306769; batch adversarial loss: 0.544231\n",
      "epoch 169; iter: 0; batch classifier loss: 0.299037; batch adversarial loss: 0.552420\n",
      "epoch 170; iter: 0; batch classifier loss: 0.345899; batch adversarial loss: 0.590587\n",
      "epoch 171; iter: 0; batch classifier loss: 0.357461; batch adversarial loss: 0.572562\n",
      "epoch 172; iter: 0; batch classifier loss: 0.446331; batch adversarial loss: 0.526818\n",
      "epoch 173; iter: 0; batch classifier loss: 0.385633; batch adversarial loss: 0.624208\n",
      "epoch 174; iter: 0; batch classifier loss: 0.385643; batch adversarial loss: 0.553326\n",
      "epoch 175; iter: 0; batch classifier loss: 0.314307; batch adversarial loss: 0.561513\n",
      "epoch 176; iter: 0; batch classifier loss: 0.338079; batch adversarial loss: 0.518940\n",
      "epoch 177; iter: 0; batch classifier loss: 0.385807; batch adversarial loss: 0.484694\n",
      "epoch 178; iter: 0; batch classifier loss: 0.416241; batch adversarial loss: 0.614748\n",
      "epoch 179; iter: 0; batch classifier loss: 0.450012; batch adversarial loss: 0.536379\n",
      "epoch 180; iter: 0; batch classifier loss: 0.377160; batch adversarial loss: 0.551095\n",
      "epoch 181; iter: 0; batch classifier loss: 0.353234; batch adversarial loss: 0.561675\n",
      "epoch 182; iter: 0; batch classifier loss: 0.433144; batch adversarial loss: 0.543964\n",
      "epoch 183; iter: 0; batch classifier loss: 0.439383; batch adversarial loss: 0.517990\n",
      "epoch 184; iter: 0; batch classifier loss: 0.366073; batch adversarial loss: 0.580147\n",
      "epoch 185; iter: 0; batch classifier loss: 0.367650; batch adversarial loss: 0.562180\n",
      "epoch 186; iter: 0; batch classifier loss: 0.385862; batch adversarial loss: 0.562517\n",
      "epoch 187; iter: 0; batch classifier loss: 0.336336; batch adversarial loss: 0.604909\n",
      "epoch 188; iter: 0; batch classifier loss: 0.304453; batch adversarial loss: 0.554704\n",
      "epoch 189; iter: 0; batch classifier loss: 0.388374; batch adversarial loss: 0.605499\n",
      "epoch 190; iter: 0; batch classifier loss: 0.367780; batch adversarial loss: 0.544559\n",
      "epoch 191; iter: 0; batch classifier loss: 0.389975; batch adversarial loss: 0.490292\n",
      "epoch 192; iter: 0; batch classifier loss: 0.293470; batch adversarial loss: 0.526779\n",
      "epoch 193; iter: 0; batch classifier loss: 0.411848; batch adversarial loss: 0.473078\n",
      "epoch 194; iter: 0; batch classifier loss: 0.412659; batch adversarial loss: 0.537924\n",
      "epoch 195; iter: 0; batch classifier loss: 0.262243; batch adversarial loss: 0.551993\n",
      "epoch 196; iter: 0; batch classifier loss: 0.322780; batch adversarial loss: 0.561382\n",
      "epoch 197; iter: 0; batch classifier loss: 0.340222; batch adversarial loss: 0.589837\n",
      "epoch 198; iter: 0; batch classifier loss: 0.321658; batch adversarial loss: 0.580810\n",
      "epoch 199; iter: 0; batch classifier loss: 0.398152; batch adversarial loss: 0.562734\n",
      "epoch 0; iter: 0; batch classifier loss: 0.682644; batch adversarial loss: 0.682099\n",
      "epoch 1; iter: 0; batch classifier loss: 0.582667; batch adversarial loss: 0.663652\n",
      "epoch 2; iter: 0; batch classifier loss: 0.574226; batch adversarial loss: 0.665215\n",
      "epoch 3; iter: 0; batch classifier loss: 0.661027; batch adversarial loss: 0.647123\n",
      "epoch 4; iter: 0; batch classifier loss: 0.570139; batch adversarial loss: 0.617128\n",
      "epoch 5; iter: 0; batch classifier loss: 0.561387; batch adversarial loss: 0.636821\n",
      "epoch 6; iter: 0; batch classifier loss: 0.584748; batch adversarial loss: 0.624179\n",
      "epoch 7; iter: 0; batch classifier loss: 0.545705; batch adversarial loss: 0.621885\n",
      "epoch 8; iter: 0; batch classifier loss: 0.562078; batch adversarial loss: 0.624212\n",
      "epoch 9; iter: 0; batch classifier loss: 0.538248; batch adversarial loss: 0.553746\n",
      "epoch 10; iter: 0; batch classifier loss: 0.572813; batch adversarial loss: 0.585607\n",
      "epoch 11; iter: 0; batch classifier loss: 0.595169; batch adversarial loss: 0.571669\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12; iter: 0; batch classifier loss: 0.510569; batch adversarial loss: 0.589336\n",
      "epoch 13; iter: 0; batch classifier loss: 0.536696; batch adversarial loss: 0.580429\n",
      "epoch 14; iter: 0; batch classifier loss: 0.478900; batch adversarial loss: 0.626352\n",
      "epoch 15; iter: 0; batch classifier loss: 0.523688; batch adversarial loss: 0.546933\n",
      "epoch 16; iter: 0; batch classifier loss: 0.529841; batch adversarial loss: 0.604700\n",
      "epoch 17; iter: 0; batch classifier loss: 0.474315; batch adversarial loss: 0.530891\n",
      "epoch 18; iter: 0; batch classifier loss: 0.534118; batch adversarial loss: 0.500715\n",
      "epoch 19; iter: 0; batch classifier loss: 0.550963; batch adversarial loss: 0.530117\n",
      "epoch 20; iter: 0; batch classifier loss: 0.436536; batch adversarial loss: 0.603661\n",
      "epoch 21; iter: 0; batch classifier loss: 0.480112; batch adversarial loss: 0.583558\n",
      "epoch 22; iter: 0; batch classifier loss: 0.521907; batch adversarial loss: 0.580575\n",
      "epoch 23; iter: 0; batch classifier loss: 0.476578; batch adversarial loss: 0.566706\n",
      "epoch 24; iter: 0; batch classifier loss: 0.480532; batch adversarial loss: 0.559512\n",
      "epoch 25; iter: 0; batch classifier loss: 0.477865; batch adversarial loss: 0.520842\n",
      "epoch 26; iter: 0; batch classifier loss: 0.578854; batch adversarial loss: 0.473866\n",
      "epoch 27; iter: 0; batch classifier loss: 0.479840; batch adversarial loss: 0.547961\n",
      "epoch 28; iter: 0; batch classifier loss: 0.488022; batch adversarial loss: 0.591174\n",
      "epoch 29; iter: 0; batch classifier loss: 0.446926; batch adversarial loss: 0.462622\n",
      "epoch 30; iter: 0; batch classifier loss: 0.374937; batch adversarial loss: 0.639485\n",
      "epoch 31; iter: 0; batch classifier loss: 0.435503; batch adversarial loss: 0.586580\n",
      "epoch 32; iter: 0; batch classifier loss: 0.481594; batch adversarial loss: 0.518631\n",
      "epoch 33; iter: 0; batch classifier loss: 0.504910; batch adversarial loss: 0.614632\n",
      "epoch 34; iter: 0; batch classifier loss: 0.482052; batch adversarial loss: 0.527389\n",
      "epoch 35; iter: 0; batch classifier loss: 0.529719; batch adversarial loss: 0.590816\n",
      "epoch 36; iter: 0; batch classifier loss: 0.456565; batch adversarial loss: 0.598379\n",
      "epoch 37; iter: 0; batch classifier loss: 0.497553; batch adversarial loss: 0.528144\n",
      "epoch 38; iter: 0; batch classifier loss: 0.482932; batch adversarial loss: 0.633046\n",
      "epoch 39; iter: 0; batch classifier loss: 0.481031; batch adversarial loss: 0.570395\n",
      "epoch 40; iter: 0; batch classifier loss: 0.491737; batch adversarial loss: 0.570673\n",
      "epoch 41; iter: 0; batch classifier loss: 0.525185; batch adversarial loss: 0.517614\n",
      "epoch 42; iter: 0; batch classifier loss: 0.417342; batch adversarial loss: 0.596224\n",
      "epoch 43; iter: 0; batch classifier loss: 0.466887; batch adversarial loss: 0.516985\n",
      "epoch 44; iter: 0; batch classifier loss: 0.520558; batch adversarial loss: 0.515895\n",
      "epoch 45; iter: 0; batch classifier loss: 0.458181; batch adversarial loss: 0.598784\n",
      "epoch 46; iter: 0; batch classifier loss: 0.470593; batch adversarial loss: 0.490476\n",
      "epoch 47; iter: 0; batch classifier loss: 0.415829; batch adversarial loss: 0.526170\n",
      "epoch 48; iter: 0; batch classifier loss: 0.409615; batch adversarial loss: 0.546218\n",
      "epoch 49; iter: 0; batch classifier loss: 0.472084; batch adversarial loss: 0.557291\n",
      "epoch 50; iter: 0; batch classifier loss: 0.393073; batch adversarial loss: 0.520432\n",
      "epoch 51; iter: 0; batch classifier loss: 0.434305; batch adversarial loss: 0.571196\n",
      "epoch 52; iter: 0; batch classifier loss: 0.531659; batch adversarial loss: 0.518495\n",
      "epoch 53; iter: 0; batch classifier loss: 0.444804; batch adversarial loss: 0.528380\n",
      "epoch 54; iter: 0; batch classifier loss: 0.397312; batch adversarial loss: 0.517323\n",
      "epoch 55; iter: 0; batch classifier loss: 0.513241; batch adversarial loss: 0.605430\n",
      "epoch 56; iter: 0; batch classifier loss: 0.483538; batch adversarial loss: 0.544572\n",
      "epoch 57; iter: 0; batch classifier loss: 0.455396; batch adversarial loss: 0.499630\n",
      "epoch 58; iter: 0; batch classifier loss: 0.396603; batch adversarial loss: 0.526592\n",
      "epoch 59; iter: 0; batch classifier loss: 0.414446; batch adversarial loss: 0.528518\n",
      "epoch 60; iter: 0; batch classifier loss: 0.400698; batch adversarial loss: 0.535342\n",
      "epoch 61; iter: 0; batch classifier loss: 0.481244; batch adversarial loss: 0.481267\n",
      "epoch 62; iter: 0; batch classifier loss: 0.399024; batch adversarial loss: 0.545918\n",
      "epoch 63; iter: 0; batch classifier loss: 0.406740; batch adversarial loss: 0.526024\n",
      "epoch 64; iter: 0; batch classifier loss: 0.419116; batch adversarial loss: 0.545019\n",
      "epoch 65; iter: 0; batch classifier loss: 0.453275; batch adversarial loss: 0.534906\n",
      "epoch 66; iter: 0; batch classifier loss: 0.417907; batch adversarial loss: 0.544141\n",
      "epoch 67; iter: 0; batch classifier loss: 0.427575; batch adversarial loss: 0.534550\n",
      "epoch 68; iter: 0; batch classifier loss: 0.422414; batch adversarial loss: 0.526351\n",
      "epoch 69; iter: 0; batch classifier loss: 0.457144; batch adversarial loss: 0.562773\n",
      "epoch 70; iter: 0; batch classifier loss: 0.428329; batch adversarial loss: 0.499816\n",
      "epoch 71; iter: 0; batch classifier loss: 0.544172; batch adversarial loss: 0.633902\n",
      "epoch 72; iter: 0; batch classifier loss: 0.423766; batch adversarial loss: 0.580572\n",
      "epoch 73; iter: 0; batch classifier loss: 0.351158; batch adversarial loss: 0.570976\n",
      "epoch 74; iter: 0; batch classifier loss: 0.363657; batch adversarial loss: 0.481264\n",
      "epoch 75; iter: 0; batch classifier loss: 0.400653; batch adversarial loss: 0.581571\n",
      "epoch 76; iter: 0; batch classifier loss: 0.418493; batch adversarial loss: 0.563528\n",
      "epoch 77; iter: 0; batch classifier loss: 0.402405; batch adversarial loss: 0.480911\n",
      "epoch 78; iter: 0; batch classifier loss: 0.378759; batch adversarial loss: 0.508901\n",
      "epoch 79; iter: 0; batch classifier loss: 0.388916; batch adversarial loss: 0.527219\n",
      "epoch 80; iter: 0; batch classifier loss: 0.402426; batch adversarial loss: 0.569910\n",
      "epoch 81; iter: 0; batch classifier loss: 0.393306; batch adversarial loss: 0.446301\n",
      "epoch 82; iter: 0; batch classifier loss: 0.422144; batch adversarial loss: 0.562424\n",
      "epoch 83; iter: 0; batch classifier loss: 0.406422; batch adversarial loss: 0.544641\n",
      "epoch 84; iter: 0; batch classifier loss: 0.400293; batch adversarial loss: 0.499541\n",
      "epoch 85; iter: 0; batch classifier loss: 0.456125; batch adversarial loss: 0.570507\n",
      "epoch 86; iter: 0; batch classifier loss: 0.417231; batch adversarial loss: 0.508863\n",
      "epoch 87; iter: 0; batch classifier loss: 0.450531; batch adversarial loss: 0.545730\n",
      "epoch 88; iter: 0; batch classifier loss: 0.414883; batch adversarial loss: 0.607977\n",
      "epoch 89; iter: 0; batch classifier loss: 0.424156; batch adversarial loss: 0.472784\n",
      "epoch 90; iter: 0; batch classifier loss: 0.394804; batch adversarial loss: 0.527029\n",
      "epoch 91; iter: 0; batch classifier loss: 0.438200; batch adversarial loss: 0.536265\n",
      "epoch 92; iter: 0; batch classifier loss: 0.446850; batch adversarial loss: 0.554706\n",
      "epoch 93; iter: 0; batch classifier loss: 0.437405; batch adversarial loss: 0.508494\n",
      "epoch 94; iter: 0; batch classifier loss: 0.349709; batch adversarial loss: 0.499296\n",
      "epoch 95; iter: 0; batch classifier loss: 0.393903; batch adversarial loss: 0.517394\n",
      "epoch 96; iter: 0; batch classifier loss: 0.418683; batch adversarial loss: 0.580158\n",
      "epoch 97; iter: 0; batch classifier loss: 0.335027; batch adversarial loss: 0.508581\n",
      "epoch 98; iter: 0; batch classifier loss: 0.344983; batch adversarial loss: 0.570991\n",
      "epoch 99; iter: 0; batch classifier loss: 0.460334; batch adversarial loss: 0.518679\n",
      "epoch 100; iter: 0; batch classifier loss: 0.417519; batch adversarial loss: 0.562390\n",
      "epoch 101; iter: 0; batch classifier loss: 0.388237; batch adversarial loss: 0.616903\n",
      "epoch 102; iter: 0; batch classifier loss: 0.361899; batch adversarial loss: 0.554110\n",
      "epoch 103; iter: 0; batch classifier loss: 0.403762; batch adversarial loss: 0.527274\n",
      "epoch 104; iter: 0; batch classifier loss: 0.354383; batch adversarial loss: 0.525894\n",
      "epoch 105; iter: 0; batch classifier loss: 0.442847; batch adversarial loss: 0.499796\n",
      "epoch 106; iter: 0; batch classifier loss: 0.398554; batch adversarial loss: 0.464373\n",
      "epoch 107; iter: 0; batch classifier loss: 0.412158; batch adversarial loss: 0.653325\n",
      "epoch 108; iter: 0; batch classifier loss: 0.405157; batch adversarial loss: 0.499666\n",
      "epoch 109; iter: 0; batch classifier loss: 0.370276; batch adversarial loss: 0.588619\n",
      "epoch 110; iter: 0; batch classifier loss: 0.425178; batch adversarial loss: 0.507678\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 111; iter: 0; batch classifier loss: 0.389371; batch adversarial loss: 0.500800\n",
      "epoch 112; iter: 0; batch classifier loss: 0.351422; batch adversarial loss: 0.489819\n",
      "epoch 113; iter: 0; batch classifier loss: 0.311020; batch adversarial loss: 0.481196\n",
      "epoch 114; iter: 0; batch classifier loss: 0.422701; batch adversarial loss: 0.626046\n",
      "epoch 115; iter: 0; batch classifier loss: 0.401146; batch adversarial loss: 0.544904\n",
      "epoch 116; iter: 0; batch classifier loss: 0.402682; batch adversarial loss: 0.499631\n",
      "epoch 117; iter: 0; batch classifier loss: 0.377154; batch adversarial loss: 0.509418\n",
      "epoch 118; iter: 0; batch classifier loss: 0.406861; batch adversarial loss: 0.563168\n",
      "epoch 119; iter: 0; batch classifier loss: 0.427293; batch adversarial loss: 0.499525\n",
      "epoch 120; iter: 0; batch classifier loss: 0.373125; batch adversarial loss: 0.598298\n",
      "epoch 121; iter: 0; batch classifier loss: 0.411735; batch adversarial loss: 0.509345\n",
      "epoch 122; iter: 0; batch classifier loss: 0.372475; batch adversarial loss: 0.572486\n",
      "epoch 123; iter: 0; batch classifier loss: 0.403660; batch adversarial loss: 0.517348\n",
      "epoch 124; iter: 0; batch classifier loss: 0.318274; batch adversarial loss: 0.570192\n",
      "epoch 125; iter: 0; batch classifier loss: 0.363121; batch adversarial loss: 0.518537\n",
      "epoch 126; iter: 0; batch classifier loss: 0.364481; batch adversarial loss: 0.544382\n",
      "epoch 127; iter: 0; batch classifier loss: 0.402662; batch adversarial loss: 0.517483\n",
      "epoch 128; iter: 0; batch classifier loss: 0.342453; batch adversarial loss: 0.544702\n",
      "epoch 129; iter: 0; batch classifier loss: 0.438000; batch adversarial loss: 0.525608\n",
      "epoch 130; iter: 0; batch classifier loss: 0.389177; batch adversarial loss: 0.518184\n",
      "epoch 131; iter: 0; batch classifier loss: 0.390828; batch adversarial loss: 0.590245\n",
      "epoch 132; iter: 0; batch classifier loss: 0.464944; batch adversarial loss: 0.633516\n",
      "epoch 133; iter: 0; batch classifier loss: 0.417741; batch adversarial loss: 0.599206\n",
      "epoch 134; iter: 0; batch classifier loss: 0.382977; batch adversarial loss: 0.482100\n",
      "epoch 135; iter: 0; batch classifier loss: 0.356906; batch adversarial loss: 0.526845\n",
      "epoch 136; iter: 0; batch classifier loss: 0.322526; batch adversarial loss: 0.553812\n",
      "epoch 137; iter: 0; batch classifier loss: 0.356022; batch adversarial loss: 0.554942\n",
      "epoch 138; iter: 0; batch classifier loss: 0.445353; batch adversarial loss: 0.534476\n",
      "epoch 139; iter: 0; batch classifier loss: 0.362854; batch adversarial loss: 0.536346\n",
      "epoch 140; iter: 0; batch classifier loss: 0.386793; batch adversarial loss: 0.509896\n",
      "epoch 141; iter: 0; batch classifier loss: 0.372527; batch adversarial loss: 0.553734\n",
      "epoch 142; iter: 0; batch classifier loss: 0.412479; batch adversarial loss: 0.544719\n",
      "epoch 143; iter: 0; batch classifier loss: 0.418939; batch adversarial loss: 0.562476\n",
      "epoch 144; iter: 0; batch classifier loss: 0.352963; batch adversarial loss: 0.572220\n",
      "epoch 145; iter: 0; batch classifier loss: 0.432874; batch adversarial loss: 0.588802\n",
      "epoch 146; iter: 0; batch classifier loss: 0.379866; batch adversarial loss: 0.544294\n",
      "epoch 147; iter: 0; batch classifier loss: 0.352820; batch adversarial loss: 0.527591\n",
      "epoch 148; iter: 0; batch classifier loss: 0.325956; batch adversarial loss: 0.545282\n",
      "epoch 149; iter: 0; batch classifier loss: 0.342495; batch adversarial loss: 0.481660\n",
      "epoch 150; iter: 0; batch classifier loss: 0.389484; batch adversarial loss: 0.508951\n",
      "epoch 151; iter: 0; batch classifier loss: 0.335054; batch adversarial loss: 0.518325\n",
      "epoch 152; iter: 0; batch classifier loss: 0.426340; batch adversarial loss: 0.527782\n",
      "epoch 153; iter: 0; batch classifier loss: 0.279857; batch adversarial loss: 0.490690\n",
      "epoch 154; iter: 0; batch classifier loss: 0.350147; batch adversarial loss: 0.571504\n",
      "epoch 155; iter: 0; batch classifier loss: 0.351519; batch adversarial loss: 0.562569\n",
      "epoch 156; iter: 0; batch classifier loss: 0.396233; batch adversarial loss: 0.624643\n",
      "epoch 157; iter: 0; batch classifier loss: 0.329656; batch adversarial loss: 0.519146\n",
      "epoch 158; iter: 0; batch classifier loss: 0.357025; batch adversarial loss: 0.536167\n",
      "epoch 159; iter: 0; batch classifier loss: 0.462552; batch adversarial loss: 0.597028\n",
      "epoch 160; iter: 0; batch classifier loss: 0.414663; batch adversarial loss: 0.545068\n",
      "epoch 161; iter: 0; batch classifier loss: 0.408109; batch adversarial loss: 0.517852\n",
      "epoch 162; iter: 0; batch classifier loss: 0.401377; batch adversarial loss: 0.589648\n",
      "epoch 163; iter: 0; batch classifier loss: 0.399576; batch adversarial loss: 0.554344\n",
      "epoch 164; iter: 0; batch classifier loss: 0.408505; batch adversarial loss: 0.570821\n",
      "epoch 165; iter: 0; batch classifier loss: 0.316617; batch adversarial loss: 0.624985\n",
      "epoch 166; iter: 0; batch classifier loss: 0.316108; batch adversarial loss: 0.518252\n",
      "epoch 167; iter: 0; batch classifier loss: 0.386602; batch adversarial loss: 0.517552\n",
      "epoch 168; iter: 0; batch classifier loss: 0.341529; batch adversarial loss: 0.590005\n",
      "epoch 169; iter: 0; batch classifier loss: 0.326436; batch adversarial loss: 0.535895\n",
      "epoch 170; iter: 0; batch classifier loss: 0.399882; batch adversarial loss: 0.607164\n",
      "epoch 171; iter: 0; batch classifier loss: 0.438992; batch adversarial loss: 0.544769\n",
      "epoch 172; iter: 0; batch classifier loss: 0.355564; batch adversarial loss: 0.489693\n",
      "epoch 173; iter: 0; batch classifier loss: 0.445739; batch adversarial loss: 0.472846\n",
      "epoch 174; iter: 0; batch classifier loss: 0.338422; batch adversarial loss: 0.517703\n",
      "epoch 175; iter: 0; batch classifier loss: 0.322011; batch adversarial loss: 0.544828\n",
      "epoch 176; iter: 0; batch classifier loss: 0.356992; batch adversarial loss: 0.481158\n",
      "epoch 177; iter: 0; batch classifier loss: 0.342234; batch adversarial loss: 0.571148\n",
      "epoch 178; iter: 0; batch classifier loss: 0.418564; batch adversarial loss: 0.580685\n",
      "epoch 179; iter: 0; batch classifier loss: 0.433494; batch adversarial loss: 0.562443\n",
      "epoch 180; iter: 0; batch classifier loss: 0.387158; batch adversarial loss: 0.517940\n",
      "epoch 181; iter: 0; batch classifier loss: 0.288287; batch adversarial loss: 0.590090\n",
      "epoch 182; iter: 0; batch classifier loss: 0.431946; batch adversarial loss: 0.581154\n",
      "epoch 183; iter: 0; batch classifier loss: 0.331995; batch adversarial loss: 0.499262\n",
      "epoch 184; iter: 0; batch classifier loss: 0.410227; batch adversarial loss: 0.572484\n",
      "epoch 185; iter: 0; batch classifier loss: 0.441153; batch adversarial loss: 0.562545\n",
      "epoch 186; iter: 0; batch classifier loss: 0.396459; batch adversarial loss: 0.535831\n",
      "epoch 187; iter: 0; batch classifier loss: 0.424316; batch adversarial loss: 0.509319\n",
      "epoch 188; iter: 0; batch classifier loss: 0.424576; batch adversarial loss: 0.589090\n",
      "epoch 189; iter: 0; batch classifier loss: 0.423208; batch adversarial loss: 0.526607\n",
      "epoch 190; iter: 0; batch classifier loss: 0.363880; batch adversarial loss: 0.526270\n",
      "epoch 191; iter: 0; batch classifier loss: 0.389274; batch adversarial loss: 0.534831\n",
      "epoch 192; iter: 0; batch classifier loss: 0.347203; batch adversarial loss: 0.481195\n",
      "epoch 193; iter: 0; batch classifier loss: 0.454226; batch adversarial loss: 0.517489\n",
      "epoch 194; iter: 0; batch classifier loss: 0.397256; batch adversarial loss: 0.545337\n",
      "epoch 195; iter: 0; batch classifier loss: 0.320682; batch adversarial loss: 0.516883\n",
      "epoch 196; iter: 0; batch classifier loss: 0.401976; batch adversarial loss: 0.572318\n",
      "epoch 197; iter: 0; batch classifier loss: 0.401587; batch adversarial loss: 0.545020\n",
      "epoch 198; iter: 0; batch classifier loss: 0.363366; batch adversarial loss: 0.445372\n",
      "epoch 199; iter: 0; batch classifier loss: 0.387484; batch adversarial loss: 0.535595\n",
      "epoch 0; iter: 0; batch classifier loss: 0.759553; batch adversarial loss: 0.613276\n",
      "epoch 1; iter: 0; batch classifier loss: 0.618182; batch adversarial loss: 0.656348\n",
      "epoch 2; iter: 0; batch classifier loss: 0.581023; batch adversarial loss: 0.651772\n",
      "epoch 3; iter: 0; batch classifier loss: 0.561829; batch adversarial loss: 0.602829\n",
      "epoch 4; iter: 0; batch classifier loss: 0.615070; batch adversarial loss: 0.584228\n",
      "epoch 5; iter: 0; batch classifier loss: 0.523391; batch adversarial loss: 0.587376\n",
      "epoch 6; iter: 0; batch classifier loss: 0.598891; batch adversarial loss: 0.606740\n",
      "epoch 7; iter: 0; batch classifier loss: 0.496214; batch adversarial loss: 0.634929\n",
      "epoch 8; iter: 0; batch classifier loss: 0.488715; batch adversarial loss: 0.599556\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9; iter: 0; batch classifier loss: 0.564652; batch adversarial loss: 0.536045\n",
      "epoch 10; iter: 0; batch classifier loss: 0.540394; batch adversarial loss: 0.610717\n",
      "epoch 11; iter: 0; batch classifier loss: 0.519929; batch adversarial loss: 0.653294\n",
      "epoch 12; iter: 0; batch classifier loss: 0.582005; batch adversarial loss: 0.569373\n",
      "epoch 13; iter: 0; batch classifier loss: 0.570425; batch adversarial loss: 0.555511\n",
      "epoch 14; iter: 0; batch classifier loss: 0.572278; batch adversarial loss: 0.591081\n",
      "epoch 15; iter: 0; batch classifier loss: 0.519215; batch adversarial loss: 0.592264\n",
      "epoch 16; iter: 0; batch classifier loss: 0.513449; batch adversarial loss: 0.573874\n",
      "epoch 17; iter: 0; batch classifier loss: 0.575910; batch adversarial loss: 0.549345\n",
      "epoch 18; iter: 0; batch classifier loss: 0.443083; batch adversarial loss: 0.571935\n",
      "epoch 19; iter: 0; batch classifier loss: 0.511248; batch adversarial loss: 0.564338\n",
      "epoch 20; iter: 0; batch classifier loss: 0.493125; batch adversarial loss: 0.554994\n",
      "epoch 21; iter: 0; batch classifier loss: 0.485807; batch adversarial loss: 0.610970\n",
      "epoch 22; iter: 0; batch classifier loss: 0.532365; batch adversarial loss: 0.629250\n",
      "epoch 23; iter: 0; batch classifier loss: 0.505745; batch adversarial loss: 0.603513\n",
      "epoch 24; iter: 0; batch classifier loss: 0.440475; batch adversarial loss: 0.549861\n",
      "epoch 25; iter: 0; batch classifier loss: 0.469008; batch adversarial loss: 0.529859\n",
      "epoch 26; iter: 0; batch classifier loss: 0.468645; batch adversarial loss: 0.502889\n",
      "epoch 27; iter: 0; batch classifier loss: 0.475294; batch adversarial loss: 0.446724\n",
      "epoch 28; iter: 0; batch classifier loss: 0.478143; batch adversarial loss: 0.546576\n",
      "epoch 29; iter: 0; batch classifier loss: 0.492402; batch adversarial loss: 0.568021\n",
      "epoch 30; iter: 0; batch classifier loss: 0.415832; batch adversarial loss: 0.526307\n",
      "epoch 31; iter: 0; batch classifier loss: 0.408323; batch adversarial loss: 0.622224\n",
      "epoch 32; iter: 0; batch classifier loss: 0.495937; batch adversarial loss: 0.554279\n",
      "epoch 33; iter: 0; batch classifier loss: 0.478568; batch adversarial loss: 0.529379\n",
      "epoch 34; iter: 0; batch classifier loss: 0.466883; batch adversarial loss: 0.622402\n",
      "epoch 35; iter: 0; batch classifier loss: 0.406278; batch adversarial loss: 0.596829\n",
      "epoch 36; iter: 0; batch classifier loss: 0.480372; batch adversarial loss: 0.537295\n",
      "epoch 37; iter: 0; batch classifier loss: 0.372971; batch adversarial loss: 0.528113\n",
      "epoch 38; iter: 0; batch classifier loss: 0.392371; batch adversarial loss: 0.604911\n",
      "epoch 39; iter: 0; batch classifier loss: 0.464680; batch adversarial loss: 0.484905\n",
      "epoch 40; iter: 0; batch classifier loss: 0.475642; batch adversarial loss: 0.597132\n",
      "epoch 41; iter: 0; batch classifier loss: 0.522881; batch adversarial loss: 0.579608\n",
      "epoch 42; iter: 0; batch classifier loss: 0.337278; batch adversarial loss: 0.544965\n",
      "epoch 43; iter: 0; batch classifier loss: 0.426968; batch adversarial loss: 0.509933\n",
      "epoch 44; iter: 0; batch classifier loss: 0.422022; batch adversarial loss: 0.527563\n",
      "epoch 45; iter: 0; batch classifier loss: 0.430720; batch adversarial loss: 0.640740\n",
      "epoch 46; iter: 0; batch classifier loss: 0.474411; batch adversarial loss: 0.571307\n",
      "epoch 47; iter: 0; batch classifier loss: 0.412917; batch adversarial loss: 0.491650\n",
      "epoch 48; iter: 0; batch classifier loss: 0.463618; batch adversarial loss: 0.571330\n",
      "epoch 49; iter: 0; batch classifier loss: 0.414809; batch adversarial loss: 0.535744\n",
      "epoch 50; iter: 0; batch classifier loss: 0.416184; batch adversarial loss: 0.535497\n",
      "epoch 51; iter: 0; batch classifier loss: 0.447163; batch adversarial loss: 0.517931\n",
      "epoch 52; iter: 0; batch classifier loss: 0.386566; batch adversarial loss: 0.658264\n",
      "epoch 53; iter: 0; batch classifier loss: 0.381400; batch adversarial loss: 0.597160\n",
      "epoch 54; iter: 0; batch classifier loss: 0.334732; batch adversarial loss: 0.545904\n",
      "epoch 55; iter: 0; batch classifier loss: 0.471492; batch adversarial loss: 0.545155\n",
      "epoch 56; iter: 0; batch classifier loss: 0.475566; batch adversarial loss: 0.544747\n",
      "epoch 57; iter: 0; batch classifier loss: 0.415717; batch adversarial loss: 0.525423\n",
      "epoch 58; iter: 0; batch classifier loss: 0.442908; batch adversarial loss: 0.509824\n",
      "epoch 59; iter: 0; batch classifier loss: 0.445129; batch adversarial loss: 0.534727\n",
      "epoch 60; iter: 0; batch classifier loss: 0.406281; batch adversarial loss: 0.545093\n",
      "epoch 61; iter: 0; batch classifier loss: 0.434684; batch adversarial loss: 0.633759\n",
      "epoch 62; iter: 0; batch classifier loss: 0.464158; batch adversarial loss: 0.519071\n",
      "epoch 63; iter: 0; batch classifier loss: 0.416891; batch adversarial loss: 0.553519\n",
      "epoch 64; iter: 0; batch classifier loss: 0.397668; batch adversarial loss: 0.562089\n",
      "epoch 65; iter: 0; batch classifier loss: 0.382828; batch adversarial loss: 0.509625\n",
      "epoch 66; iter: 0; batch classifier loss: 0.419619; batch adversarial loss: 0.534519\n",
      "epoch 67; iter: 0; batch classifier loss: 0.395966; batch adversarial loss: 0.526570\n",
      "epoch 68; iter: 0; batch classifier loss: 0.310960; batch adversarial loss: 0.579241\n",
      "epoch 69; iter: 0; batch classifier loss: 0.395852; batch adversarial loss: 0.535436\n",
      "epoch 70; iter: 0; batch classifier loss: 0.481364; batch adversarial loss: 0.553895\n",
      "epoch 71; iter: 0; batch classifier loss: 0.427432; batch adversarial loss: 0.545673\n",
      "epoch 72; iter: 0; batch classifier loss: 0.405323; batch adversarial loss: 0.571085\n",
      "epoch 73; iter: 0; batch classifier loss: 0.422558; batch adversarial loss: 0.535568\n",
      "epoch 74; iter: 0; batch classifier loss: 0.350009; batch adversarial loss: 0.563004\n",
      "epoch 75; iter: 0; batch classifier loss: 0.443175; batch adversarial loss: 0.625507\n",
      "epoch 76; iter: 0; batch classifier loss: 0.375241; batch adversarial loss: 0.562763\n",
      "epoch 77; iter: 0; batch classifier loss: 0.435936; batch adversarial loss: 0.543955\n",
      "epoch 78; iter: 0; batch classifier loss: 0.431744; batch adversarial loss: 0.578571\n",
      "epoch 79; iter: 0; batch classifier loss: 0.480092; batch adversarial loss: 0.455186\n",
      "epoch 80; iter: 0; batch classifier loss: 0.356968; batch adversarial loss: 0.589359\n",
      "epoch 81; iter: 0; batch classifier loss: 0.461709; batch adversarial loss: 0.598263\n",
      "epoch 82; iter: 0; batch classifier loss: 0.389721; batch adversarial loss: 0.616737\n",
      "epoch 83; iter: 0; batch classifier loss: 0.413500; batch adversarial loss: 0.604846\n",
      "epoch 84; iter: 0; batch classifier loss: 0.384259; batch adversarial loss: 0.551284\n",
      "epoch 85; iter: 0; batch classifier loss: 0.300302; batch adversarial loss: 0.527049\n",
      "epoch 86; iter: 0; batch classifier loss: 0.361298; batch adversarial loss: 0.554435\n",
      "epoch 87; iter: 0; batch classifier loss: 0.396508; batch adversarial loss: 0.528710\n",
      "epoch 88; iter: 0; batch classifier loss: 0.351846; batch adversarial loss: 0.508813\n",
      "epoch 89; iter: 0; batch classifier loss: 0.456759; batch adversarial loss: 0.606510\n",
      "epoch 90; iter: 0; batch classifier loss: 0.422412; batch adversarial loss: 0.579951\n",
      "epoch 91; iter: 0; batch classifier loss: 0.405798; batch adversarial loss: 0.570145\n",
      "epoch 92; iter: 0; batch classifier loss: 0.388839; batch adversarial loss: 0.605866\n",
      "epoch 93; iter: 0; batch classifier loss: 0.370461; batch adversarial loss: 0.545840\n",
      "epoch 94; iter: 0; batch classifier loss: 0.374991; batch adversarial loss: 0.454601\n",
      "epoch 95; iter: 0; batch classifier loss: 0.393996; batch adversarial loss: 0.612510\n",
      "epoch 96; iter: 0; batch classifier loss: 0.399178; batch adversarial loss: 0.596865\n",
      "epoch 97; iter: 0; batch classifier loss: 0.416316; batch adversarial loss: 0.554227\n",
      "epoch 98; iter: 0; batch classifier loss: 0.391031; batch adversarial loss: 0.437429\n",
      "epoch 99; iter: 0; batch classifier loss: 0.318183; batch adversarial loss: 0.516470\n",
      "epoch 100; iter: 0; batch classifier loss: 0.294248; batch adversarial loss: 0.589197\n",
      "epoch 101; iter: 0; batch classifier loss: 0.405489; batch adversarial loss: 0.553121\n",
      "epoch 102; iter: 0; batch classifier loss: 0.331276; batch adversarial loss: 0.526398\n",
      "epoch 103; iter: 0; batch classifier loss: 0.358395; batch adversarial loss: 0.545112\n",
      "epoch 104; iter: 0; batch classifier loss: 0.369412; batch adversarial loss: 0.555052\n",
      "epoch 105; iter: 0; batch classifier loss: 0.463761; batch adversarial loss: 0.605540\n",
      "epoch 106; iter: 0; batch classifier loss: 0.353652; batch adversarial loss: 0.490614\n",
      "epoch 107; iter: 0; batch classifier loss: 0.402597; batch adversarial loss: 0.517690\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 108; iter: 0; batch classifier loss: 0.417306; batch adversarial loss: 0.552867\n",
      "epoch 109; iter: 0; batch classifier loss: 0.394200; batch adversarial loss: 0.570125\n",
      "epoch 110; iter: 0; batch classifier loss: 0.363603; batch adversarial loss: 0.535637\n",
      "epoch 111; iter: 0; batch classifier loss: 0.421317; batch adversarial loss: 0.562518\n",
      "epoch 112; iter: 0; batch classifier loss: 0.351342; batch adversarial loss: 0.563142\n",
      "epoch 113; iter: 0; batch classifier loss: 0.406868; batch adversarial loss: 0.536117\n",
      "epoch 114; iter: 0; batch classifier loss: 0.368813; batch adversarial loss: 0.491549\n",
      "epoch 115; iter: 0; batch classifier loss: 0.344301; batch adversarial loss: 0.501851\n",
      "epoch 116; iter: 0; batch classifier loss: 0.368690; batch adversarial loss: 0.605468\n",
      "epoch 117; iter: 0; batch classifier loss: 0.394734; batch adversarial loss: 0.605712\n",
      "epoch 118; iter: 0; batch classifier loss: 0.409428; batch adversarial loss: 0.527718\n",
      "epoch 119; iter: 0; batch classifier loss: 0.380010; batch adversarial loss: 0.623573\n",
      "epoch 120; iter: 0; batch classifier loss: 0.440588; batch adversarial loss: 0.561048\n",
      "epoch 121; iter: 0; batch classifier loss: 0.320369; batch adversarial loss: 0.528836\n",
      "epoch 122; iter: 0; batch classifier loss: 0.355773; batch adversarial loss: 0.579327\n",
      "epoch 123; iter: 0; batch classifier loss: 0.353528; batch adversarial loss: 0.560557\n",
      "epoch 124; iter: 0; batch classifier loss: 0.402528; batch adversarial loss: 0.589238\n",
      "epoch 125; iter: 0; batch classifier loss: 0.368639; batch adversarial loss: 0.518093\n",
      "epoch 126; iter: 0; batch classifier loss: 0.339642; batch adversarial loss: 0.589181\n",
      "epoch 127; iter: 0; batch classifier loss: 0.427212; batch adversarial loss: 0.510062\n",
      "epoch 128; iter: 0; batch classifier loss: 0.444846; batch adversarial loss: 0.526637\n",
      "epoch 129; iter: 0; batch classifier loss: 0.375742; batch adversarial loss: 0.562007\n",
      "epoch 130; iter: 0; batch classifier loss: 0.365509; batch adversarial loss: 0.579258\n",
      "epoch 131; iter: 0; batch classifier loss: 0.396913; batch adversarial loss: 0.650486\n",
      "epoch 132; iter: 0; batch classifier loss: 0.361294; batch adversarial loss: 0.543635\n",
      "epoch 133; iter: 0; batch classifier loss: 0.363982; batch adversarial loss: 0.632988\n",
      "epoch 134; iter: 0; batch classifier loss: 0.316790; batch adversarial loss: 0.651060\n",
      "epoch 135; iter: 0; batch classifier loss: 0.314463; batch adversarial loss: 0.563132\n",
      "epoch 136; iter: 0; batch classifier loss: 0.333320; batch adversarial loss: 0.571165\n",
      "epoch 137; iter: 0; batch classifier loss: 0.344072; batch adversarial loss: 0.579631\n",
      "epoch 138; iter: 0; batch classifier loss: 0.403470; batch adversarial loss: 0.562367\n",
      "epoch 139; iter: 0; batch classifier loss: 0.326523; batch adversarial loss: 0.545082\n",
      "epoch 140; iter: 0; batch classifier loss: 0.361200; batch adversarial loss: 0.633860\n",
      "epoch 141; iter: 0; batch classifier loss: 0.383904; batch adversarial loss: 0.545802\n",
      "epoch 142; iter: 0; batch classifier loss: 0.322394; batch adversarial loss: 0.516922\n",
      "epoch 143; iter: 0; batch classifier loss: 0.423328; batch adversarial loss: 0.571514\n",
      "epoch 144; iter: 0; batch classifier loss: 0.419778; batch adversarial loss: 0.561680\n",
      "epoch 145; iter: 0; batch classifier loss: 0.362773; batch adversarial loss: 0.554876\n",
      "epoch 146; iter: 0; batch classifier loss: 0.408014; batch adversarial loss: 0.509259\n",
      "epoch 147; iter: 0; batch classifier loss: 0.308529; batch adversarial loss: 0.570205\n",
      "epoch 148; iter: 0; batch classifier loss: 0.303172; batch adversarial loss: 0.613604\n",
      "epoch 149; iter: 0; batch classifier loss: 0.400390; batch adversarial loss: 0.606815\n",
      "epoch 150; iter: 0; batch classifier loss: 0.430245; batch adversarial loss: 0.474365\n",
      "epoch 151; iter: 0; batch classifier loss: 0.405318; batch adversarial loss: 0.615992\n",
      "epoch 152; iter: 0; batch classifier loss: 0.375800; batch adversarial loss: 0.615251\n",
      "epoch 153; iter: 0; batch classifier loss: 0.366933; batch adversarial loss: 0.501780\n",
      "epoch 154; iter: 0; batch classifier loss: 0.365447; batch adversarial loss: 0.579722\n",
      "epoch 155; iter: 0; batch classifier loss: 0.287661; batch adversarial loss: 0.534852\n",
      "epoch 156; iter: 0; batch classifier loss: 0.330963; batch adversarial loss: 0.597183\n",
      "epoch 157; iter: 0; batch classifier loss: 0.393834; batch adversarial loss: 0.553400\n",
      "epoch 158; iter: 0; batch classifier loss: 0.377948; batch adversarial loss: 0.553763\n",
      "epoch 159; iter: 0; batch classifier loss: 0.304111; batch adversarial loss: 0.543844\n",
      "epoch 160; iter: 0; batch classifier loss: 0.370632; batch adversarial loss: 0.491410\n",
      "epoch 161; iter: 0; batch classifier loss: 0.365475; batch adversarial loss: 0.572410\n",
      "epoch 162; iter: 0; batch classifier loss: 0.410753; batch adversarial loss: 0.525884\n",
      "epoch 163; iter: 0; batch classifier loss: 0.336060; batch adversarial loss: 0.555018\n",
      "epoch 164; iter: 0; batch classifier loss: 0.363301; batch adversarial loss: 0.661162\n",
      "epoch 165; iter: 0; batch classifier loss: 0.358263; batch adversarial loss: 0.536121\n",
      "epoch 166; iter: 0; batch classifier loss: 0.409059; batch adversarial loss: 0.552633\n",
      "epoch 167; iter: 0; batch classifier loss: 0.350351; batch adversarial loss: 0.615594\n",
      "epoch 168; iter: 0; batch classifier loss: 0.341706; batch adversarial loss: 0.482864\n",
      "epoch 169; iter: 0; batch classifier loss: 0.340989; batch adversarial loss: 0.517842\n",
      "epoch 170; iter: 0; batch classifier loss: 0.317459; batch adversarial loss: 0.561697\n",
      "epoch 171; iter: 0; batch classifier loss: 0.354065; batch adversarial loss: 0.544491\n",
      "epoch 172; iter: 0; batch classifier loss: 0.407611; batch adversarial loss: 0.509653\n",
      "epoch 173; iter: 0; batch classifier loss: 0.362533; batch adversarial loss: 0.535650\n",
      "epoch 174; iter: 0; batch classifier loss: 0.510982; batch adversarial loss: 0.534980\n",
      "epoch 175; iter: 0; batch classifier loss: 0.351967; batch adversarial loss: 0.553616\n",
      "epoch 176; iter: 0; batch classifier loss: 0.330546; batch adversarial loss: 0.642485\n",
      "epoch 177; iter: 0; batch classifier loss: 0.380141; batch adversarial loss: 0.545593\n",
      "epoch 178; iter: 0; batch classifier loss: 0.408745; batch adversarial loss: 0.543570\n",
      "epoch 179; iter: 0; batch classifier loss: 0.321438; batch adversarial loss: 0.525996\n",
      "epoch 180; iter: 0; batch classifier loss: 0.329116; batch adversarial loss: 0.519137\n",
      "epoch 181; iter: 0; batch classifier loss: 0.400705; batch adversarial loss: 0.580611\n",
      "epoch 182; iter: 0; batch classifier loss: 0.456195; batch adversarial loss: 0.616831\n",
      "epoch 183; iter: 0; batch classifier loss: 0.506274; batch adversarial loss: 0.544933\n",
      "epoch 184; iter: 0; batch classifier loss: 0.355300; batch adversarial loss: 0.544403\n",
      "epoch 185; iter: 0; batch classifier loss: 0.354076; batch adversarial loss: 0.598100\n",
      "epoch 186; iter: 0; batch classifier loss: 0.308107; batch adversarial loss: 0.579831\n",
      "epoch 187; iter: 0; batch classifier loss: 0.390999; batch adversarial loss: 0.561592\n",
      "epoch 188; iter: 0; batch classifier loss: 0.410457; batch adversarial loss: 0.615075\n",
      "epoch 189; iter: 0; batch classifier loss: 0.297660; batch adversarial loss: 0.553849\n",
      "epoch 190; iter: 0; batch classifier loss: 0.360162; batch adversarial loss: 0.571650\n",
      "epoch 191; iter: 0; batch classifier loss: 0.283267; batch adversarial loss: 0.535553\n",
      "epoch 192; iter: 0; batch classifier loss: 0.314240; batch adversarial loss: 0.580490\n",
      "epoch 193; iter: 0; batch classifier loss: 0.349715; batch adversarial loss: 0.616224\n",
      "epoch 194; iter: 0; batch classifier loss: 0.322219; batch adversarial loss: 0.543562\n",
      "epoch 195; iter: 0; batch classifier loss: 0.392954; batch adversarial loss: 0.563798\n",
      "epoch 196; iter: 0; batch classifier loss: 0.403106; batch adversarial loss: 0.571837\n",
      "epoch 197; iter: 0; batch classifier loss: 0.455587; batch adversarial loss: 0.465903\n",
      "epoch 198; iter: 0; batch classifier loss: 0.328843; batch adversarial loss: 0.554504\n",
      "epoch 199; iter: 0; batch classifier loss: 0.413824; batch adversarial loss: 0.561590\n",
      "epoch 0; iter: 0; batch classifier loss: 0.694093; batch adversarial loss: 0.807176\n",
      "epoch 1; iter: 0; batch classifier loss: 0.626018; batch adversarial loss: 0.848003\n",
      "epoch 2; iter: 0; batch classifier loss: 0.577770; batch adversarial loss: 0.745364\n",
      "epoch 3; iter: 0; batch classifier loss: 0.492586; batch adversarial loss: 0.708956\n",
      "epoch 4; iter: 0; batch classifier loss: 0.550250; batch adversarial loss: 0.667783\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5; iter: 0; batch classifier loss: 0.516803; batch adversarial loss: 0.667399\n",
      "epoch 6; iter: 0; batch classifier loss: 0.485596; batch adversarial loss: 0.654911\n",
      "epoch 7; iter: 0; batch classifier loss: 0.565336; batch adversarial loss: 0.651237\n",
      "epoch 8; iter: 0; batch classifier loss: 0.627292; batch adversarial loss: 0.625185\n",
      "epoch 9; iter: 0; batch classifier loss: 0.614804; batch adversarial loss: 0.590755\n",
      "epoch 10; iter: 0; batch classifier loss: 0.610244; batch adversarial loss: 0.610133\n",
      "epoch 11; iter: 0; batch classifier loss: 0.496149; batch adversarial loss: 0.568102\n",
      "epoch 12; iter: 0; batch classifier loss: 0.578147; batch adversarial loss: 0.583286\n",
      "epoch 13; iter: 0; batch classifier loss: 0.569579; batch adversarial loss: 0.574040\n",
      "epoch 14; iter: 0; batch classifier loss: 0.509114; batch adversarial loss: 0.570583\n",
      "epoch 15; iter: 0; batch classifier loss: 0.516329; batch adversarial loss: 0.537878\n",
      "epoch 16; iter: 0; batch classifier loss: 0.488254; batch adversarial loss: 0.498161\n",
      "epoch 17; iter: 0; batch classifier loss: 0.541366; batch adversarial loss: 0.590675\n",
      "epoch 18; iter: 0; batch classifier loss: 0.590072; batch adversarial loss: 0.542259\n",
      "epoch 19; iter: 0; batch classifier loss: 0.555523; batch adversarial loss: 0.571050\n",
      "epoch 20; iter: 0; batch classifier loss: 0.497614; batch adversarial loss: 0.608404\n",
      "epoch 21; iter: 0; batch classifier loss: 0.603589; batch adversarial loss: 0.543360\n",
      "epoch 22; iter: 0; batch classifier loss: 0.524957; batch adversarial loss: 0.495908\n",
      "epoch 23; iter: 0; batch classifier loss: 0.464021; batch adversarial loss: 0.466715\n",
      "epoch 24; iter: 0; batch classifier loss: 0.441996; batch adversarial loss: 0.484297\n",
      "epoch 25; iter: 0; batch classifier loss: 0.570139; batch adversarial loss: 0.559944\n",
      "epoch 26; iter: 0; batch classifier loss: 0.505270; batch adversarial loss: 0.528261\n",
      "epoch 27; iter: 0; batch classifier loss: 0.441537; batch adversarial loss: 0.563944\n",
      "epoch 28; iter: 0; batch classifier loss: 0.525404; batch adversarial loss: 0.498396\n",
      "epoch 29; iter: 0; batch classifier loss: 0.484530; batch adversarial loss: 0.596814\n",
      "epoch 30; iter: 0; batch classifier loss: 0.446958; batch adversarial loss: 0.559943\n",
      "epoch 31; iter: 0; batch classifier loss: 0.559177; batch adversarial loss: 0.540178\n",
      "epoch 32; iter: 0; batch classifier loss: 0.446468; batch adversarial loss: 0.532408\n",
      "epoch 33; iter: 0; batch classifier loss: 0.464452; batch adversarial loss: 0.534470\n",
      "epoch 34; iter: 0; batch classifier loss: 0.465558; batch adversarial loss: 0.491233\n",
      "epoch 35; iter: 0; batch classifier loss: 0.580580; batch adversarial loss: 0.494377\n",
      "epoch 36; iter: 0; batch classifier loss: 0.434301; batch adversarial loss: 0.609266\n",
      "epoch 37; iter: 0; batch classifier loss: 0.497690; batch adversarial loss: 0.526714\n",
      "epoch 38; iter: 0; batch classifier loss: 0.512719; batch adversarial loss: 0.509970\n",
      "epoch 39; iter: 0; batch classifier loss: 0.425077; batch adversarial loss: 0.601430\n",
      "epoch 40; iter: 0; batch classifier loss: 0.444693; batch adversarial loss: 0.545201\n",
      "epoch 41; iter: 0; batch classifier loss: 0.401021; batch adversarial loss: 0.582317\n",
      "epoch 42; iter: 0; batch classifier loss: 0.382046; batch adversarial loss: 0.565224\n",
      "epoch 43; iter: 0; batch classifier loss: 0.454173; batch adversarial loss: 0.553889\n",
      "epoch 44; iter: 0; batch classifier loss: 0.406818; batch adversarial loss: 0.491677\n",
      "epoch 45; iter: 0; batch classifier loss: 0.419764; batch adversarial loss: 0.580357\n",
      "epoch 46; iter: 0; batch classifier loss: 0.464120; batch adversarial loss: 0.608138\n",
      "epoch 47; iter: 0; batch classifier loss: 0.414598; batch adversarial loss: 0.545295\n",
      "epoch 48; iter: 0; batch classifier loss: 0.418851; batch adversarial loss: 0.590654\n",
      "epoch 49; iter: 0; batch classifier loss: 0.445137; batch adversarial loss: 0.562662\n",
      "epoch 50; iter: 0; batch classifier loss: 0.373935; batch adversarial loss: 0.553914\n",
      "epoch 51; iter: 0; batch classifier loss: 0.404612; batch adversarial loss: 0.590692\n",
      "epoch 52; iter: 0; batch classifier loss: 0.536344; batch adversarial loss: 0.516924\n",
      "epoch 53; iter: 0; batch classifier loss: 0.405934; batch adversarial loss: 0.618527\n",
      "epoch 54; iter: 0; batch classifier loss: 0.414202; batch adversarial loss: 0.535016\n",
      "epoch 55; iter: 0; batch classifier loss: 0.419129; batch adversarial loss: 0.544336\n",
      "epoch 56; iter: 0; batch classifier loss: 0.411460; batch adversarial loss: 0.544984\n",
      "epoch 57; iter: 0; batch classifier loss: 0.422892; batch adversarial loss: 0.581979\n",
      "epoch 58; iter: 0; batch classifier loss: 0.392587; batch adversarial loss: 0.525536\n",
      "epoch 59; iter: 0; batch classifier loss: 0.412433; batch adversarial loss: 0.522648\n",
      "epoch 60; iter: 0; batch classifier loss: 0.356808; batch adversarial loss: 0.570015\n",
      "epoch 61; iter: 0; batch classifier loss: 0.407011; batch adversarial loss: 0.642853\n",
      "epoch 62; iter: 0; batch classifier loss: 0.380682; batch adversarial loss: 0.514868\n",
      "epoch 63; iter: 0; batch classifier loss: 0.369402; batch adversarial loss: 0.575393\n",
      "epoch 64; iter: 0; batch classifier loss: 0.384038; batch adversarial loss: 0.506599\n",
      "epoch 65; iter: 0; batch classifier loss: 0.370056; batch adversarial loss: 0.545684\n",
      "epoch 66; iter: 0; batch classifier loss: 0.417631; batch adversarial loss: 0.450173\n",
      "epoch 67; iter: 0; batch classifier loss: 0.363656; batch adversarial loss: 0.617791\n",
      "epoch 68; iter: 0; batch classifier loss: 0.410488; batch adversarial loss: 0.524340\n",
      "epoch 69; iter: 0; batch classifier loss: 0.404307; batch adversarial loss: 0.478968\n",
      "epoch 70; iter: 0; batch classifier loss: 0.361995; batch adversarial loss: 0.506871\n",
      "epoch 71; iter: 0; batch classifier loss: 0.408241; batch adversarial loss: 0.563928\n",
      "epoch 72; iter: 0; batch classifier loss: 0.449429; batch adversarial loss: 0.570328\n",
      "epoch 73; iter: 0; batch classifier loss: 0.392625; batch adversarial loss: 0.518038\n",
      "epoch 74; iter: 0; batch classifier loss: 0.382963; batch adversarial loss: 0.609558\n",
      "epoch 75; iter: 0; batch classifier loss: 0.367878; batch adversarial loss: 0.591936\n",
      "epoch 76; iter: 0; batch classifier loss: 0.413999; batch adversarial loss: 0.508042\n",
      "epoch 77; iter: 0; batch classifier loss: 0.448152; batch adversarial loss: 0.618940\n",
      "epoch 78; iter: 0; batch classifier loss: 0.390613; batch adversarial loss: 0.590659\n",
      "epoch 79; iter: 0; batch classifier loss: 0.410397; batch adversarial loss: 0.544176\n",
      "epoch 80; iter: 0; batch classifier loss: 0.418699; batch adversarial loss: 0.498456\n",
      "epoch 81; iter: 0; batch classifier loss: 0.428532; batch adversarial loss: 0.581328\n",
      "epoch 82; iter: 0; batch classifier loss: 0.359730; batch adversarial loss: 0.609185\n",
      "epoch 83; iter: 0; batch classifier loss: 0.390315; batch adversarial loss: 0.553629\n",
      "epoch 84; iter: 0; batch classifier loss: 0.365931; batch adversarial loss: 0.573006\n",
      "epoch 85; iter: 0; batch classifier loss: 0.423486; batch adversarial loss: 0.497793\n",
      "epoch 86; iter: 0; batch classifier loss: 0.410984; batch adversarial loss: 0.544608\n",
      "epoch 87; iter: 0; batch classifier loss: 0.332033; batch adversarial loss: 0.601661\n",
      "epoch 88; iter: 0; batch classifier loss: 0.399212; batch adversarial loss: 0.572163\n",
      "epoch 89; iter: 0; batch classifier loss: 0.312951; batch adversarial loss: 0.470875\n",
      "epoch 90; iter: 0; batch classifier loss: 0.366880; batch adversarial loss: 0.544634\n",
      "epoch 91; iter: 0; batch classifier loss: 0.402234; batch adversarial loss: 0.487396\n",
      "epoch 92; iter: 0; batch classifier loss: 0.374812; batch adversarial loss: 0.543759\n",
      "epoch 93; iter: 0; batch classifier loss: 0.405522; batch adversarial loss: 0.647618\n",
      "epoch 94; iter: 0; batch classifier loss: 0.376497; batch adversarial loss: 0.459589\n",
      "epoch 95; iter: 0; batch classifier loss: 0.360242; batch adversarial loss: 0.554532\n",
      "epoch 96; iter: 0; batch classifier loss: 0.410839; batch adversarial loss: 0.591763\n",
      "epoch 97; iter: 0; batch classifier loss: 0.376733; batch adversarial loss: 0.506944\n",
      "epoch 98; iter: 0; batch classifier loss: 0.327206; batch adversarial loss: 0.479823\n",
      "epoch 99; iter: 0; batch classifier loss: 0.392552; batch adversarial loss: 0.572443\n",
      "epoch 100; iter: 0; batch classifier loss: 0.315481; batch adversarial loss: 0.535121\n",
      "epoch 101; iter: 0; batch classifier loss: 0.403033; batch adversarial loss: 0.749736\n",
      "epoch 102; iter: 0; batch classifier loss: 0.491970; batch adversarial loss: 0.497387\n",
      "epoch 103; iter: 0; batch classifier loss: 0.385496; batch adversarial loss: 0.544489\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 104; iter: 0; batch classifier loss: 0.399685; batch adversarial loss: 0.581038\n",
      "epoch 105; iter: 0; batch classifier loss: 0.411709; batch adversarial loss: 0.543771\n",
      "epoch 106; iter: 0; batch classifier loss: 0.370540; batch adversarial loss: 0.591135\n",
      "epoch 107; iter: 0; batch classifier loss: 0.468915; batch adversarial loss: 0.498498\n",
      "epoch 108; iter: 0; batch classifier loss: 0.391603; batch adversarial loss: 0.516145\n",
      "epoch 109; iter: 0; batch classifier loss: 0.389194; batch adversarial loss: 0.488375\n",
      "epoch 110; iter: 0; batch classifier loss: 0.525365; batch adversarial loss: 0.563187\n",
      "epoch 111; iter: 0; batch classifier loss: 0.365200; batch adversarial loss: 0.440238\n",
      "epoch 112; iter: 0; batch classifier loss: 0.372976; batch adversarial loss: 0.524457\n",
      "epoch 113; iter: 0; batch classifier loss: 0.337828; batch adversarial loss: 0.543798\n",
      "epoch 114; iter: 0; batch classifier loss: 0.385170; batch adversarial loss: 0.563609\n",
      "epoch 115; iter: 0; batch classifier loss: 0.429039; batch adversarial loss: 0.532506\n",
      "epoch 116; iter: 0; batch classifier loss: 0.428195; batch adversarial loss: 0.599475\n",
      "epoch 117; iter: 0; batch classifier loss: 0.375975; batch adversarial loss: 0.467299\n",
      "epoch 118; iter: 0; batch classifier loss: 0.496045; batch adversarial loss: 0.430875\n",
      "epoch 119; iter: 0; batch classifier loss: 0.375195; batch adversarial loss: 0.505451\n",
      "epoch 120; iter: 0; batch classifier loss: 0.434454; batch adversarial loss: 0.535692\n",
      "epoch 121; iter: 0; batch classifier loss: 0.299556; batch adversarial loss: 0.536278\n",
      "epoch 122; iter: 0; batch classifier loss: 0.416955; batch adversarial loss: 0.518257\n",
      "epoch 123; iter: 0; batch classifier loss: 0.394468; batch adversarial loss: 0.516723\n",
      "epoch 124; iter: 0; batch classifier loss: 0.339965; batch adversarial loss: 0.517309\n",
      "epoch 125; iter: 0; batch classifier loss: 0.336828; batch adversarial loss: 0.535358\n",
      "epoch 126; iter: 0; batch classifier loss: 0.424485; batch adversarial loss: 0.562715\n",
      "epoch 127; iter: 0; batch classifier loss: 0.404378; batch adversarial loss: 0.562752\n",
      "epoch 128; iter: 0; batch classifier loss: 0.357522; batch adversarial loss: 0.507512\n",
      "epoch 129; iter: 0; batch classifier loss: 0.446409; batch adversarial loss: 0.470383\n",
      "epoch 130; iter: 0; batch classifier loss: 0.437185; batch adversarial loss: 0.480637\n",
      "epoch 131; iter: 0; batch classifier loss: 0.370400; batch adversarial loss: 0.645660\n",
      "epoch 132; iter: 0; batch classifier loss: 0.377172; batch adversarial loss: 0.498203\n",
      "epoch 133; iter: 0; batch classifier loss: 0.378884; batch adversarial loss: 0.579500\n",
      "epoch 134; iter: 0; batch classifier loss: 0.317481; batch adversarial loss: 0.506354\n",
      "epoch 135; iter: 0; batch classifier loss: 0.394331; batch adversarial loss: 0.442339\n",
      "epoch 136; iter: 0; batch classifier loss: 0.375857; batch adversarial loss: 0.564047\n",
      "epoch 137; iter: 0; batch classifier loss: 0.333599; batch adversarial loss: 0.526035\n",
      "epoch 138; iter: 0; batch classifier loss: 0.390261; batch adversarial loss: 0.534720\n",
      "epoch 139; iter: 0; batch classifier loss: 0.368949; batch adversarial loss: 0.487981\n",
      "epoch 140; iter: 0; batch classifier loss: 0.343745; batch adversarial loss: 0.553709\n",
      "epoch 141; iter: 0; batch classifier loss: 0.406325; batch adversarial loss: 0.478092\n",
      "epoch 142; iter: 0; batch classifier loss: 0.326801; batch adversarial loss: 0.553906\n",
      "epoch 143; iter: 0; batch classifier loss: 0.352651; batch adversarial loss: 0.555079\n",
      "epoch 144; iter: 0; batch classifier loss: 0.455245; batch adversarial loss: 0.460647\n",
      "epoch 145; iter: 0; batch classifier loss: 0.318014; batch adversarial loss: 0.525699\n",
      "epoch 146; iter: 0; batch classifier loss: 0.422388; batch adversarial loss: 0.498036\n",
      "epoch 147; iter: 0; batch classifier loss: 0.353495; batch adversarial loss: 0.441551\n",
      "epoch 148; iter: 0; batch classifier loss: 0.337127; batch adversarial loss: 0.488107\n",
      "epoch 149; iter: 0; batch classifier loss: 0.347824; batch adversarial loss: 0.535241\n",
      "epoch 150; iter: 0; batch classifier loss: 0.396107; batch adversarial loss: 0.543967\n",
      "epoch 151; iter: 0; batch classifier loss: 0.339919; batch adversarial loss: 0.543764\n",
      "epoch 152; iter: 0; batch classifier loss: 0.403123; batch adversarial loss: 0.553993\n",
      "epoch 153; iter: 0; batch classifier loss: 0.365374; batch adversarial loss: 0.516394\n",
      "epoch 154; iter: 0; batch classifier loss: 0.329330; batch adversarial loss: 0.581624\n",
      "epoch 155; iter: 0; batch classifier loss: 0.384477; batch adversarial loss: 0.507699\n",
      "epoch 156; iter: 0; batch classifier loss: 0.376539; batch adversarial loss: 0.534980\n",
      "epoch 157; iter: 0; batch classifier loss: 0.428068; batch adversarial loss: 0.554422\n",
      "epoch 158; iter: 0; batch classifier loss: 0.360652; batch adversarial loss: 0.469608\n",
      "epoch 159; iter: 0; batch classifier loss: 0.370610; batch adversarial loss: 0.488597\n",
      "epoch 160; iter: 0; batch classifier loss: 0.383691; batch adversarial loss: 0.515843\n",
      "epoch 161; iter: 0; batch classifier loss: 0.408549; batch adversarial loss: 0.564165\n",
      "epoch 162; iter: 0; batch classifier loss: 0.385946; batch adversarial loss: 0.451101\n",
      "epoch 163; iter: 0; batch classifier loss: 0.378001; batch adversarial loss: 0.526208\n",
      "epoch 164; iter: 0; batch classifier loss: 0.394566; batch adversarial loss: 0.591373\n",
      "epoch 165; iter: 0; batch classifier loss: 0.431835; batch adversarial loss: 0.526246\n",
      "epoch 166; iter: 0; batch classifier loss: 0.337313; batch adversarial loss: 0.526000\n",
      "epoch 167; iter: 0; batch classifier loss: 0.324504; batch adversarial loss: 0.524815\n",
      "epoch 168; iter: 0; batch classifier loss: 0.463674; batch adversarial loss: 0.534646\n",
      "epoch 169; iter: 0; batch classifier loss: 0.390547; batch adversarial loss: 0.555274\n",
      "epoch 170; iter: 0; batch classifier loss: 0.354042; batch adversarial loss: 0.526283\n",
      "epoch 171; iter: 0; batch classifier loss: 0.396704; batch adversarial loss: 0.506676\n",
      "epoch 172; iter: 0; batch classifier loss: 0.340628; batch adversarial loss: 0.544136\n",
      "epoch 173; iter: 0; batch classifier loss: 0.301619; batch adversarial loss: 0.563870\n",
      "epoch 174; iter: 0; batch classifier loss: 0.415821; batch adversarial loss: 0.628838\n",
      "epoch 175; iter: 0; batch classifier loss: 0.389745; batch adversarial loss: 0.525702\n",
      "epoch 176; iter: 0; batch classifier loss: 0.347622; batch adversarial loss: 0.451073\n",
      "epoch 177; iter: 0; batch classifier loss: 0.313719; batch adversarial loss: 0.572444\n",
      "epoch 178; iter: 0; batch classifier loss: 0.371683; batch adversarial loss: 0.563117\n",
      "epoch 179; iter: 0; batch classifier loss: 0.333283; batch adversarial loss: 0.487962\n",
      "epoch 180; iter: 0; batch classifier loss: 0.331489; batch adversarial loss: 0.497773\n",
      "epoch 181; iter: 0; batch classifier loss: 0.414028; batch adversarial loss: 0.618448\n",
      "epoch 182; iter: 0; batch classifier loss: 0.366170; batch adversarial loss: 0.573243\n",
      "epoch 183; iter: 0; batch classifier loss: 0.331220; batch adversarial loss: 0.516013\n",
      "epoch 184; iter: 0; batch classifier loss: 0.427868; batch adversarial loss: 0.498076\n",
      "epoch 185; iter: 0; batch classifier loss: 0.409875; batch adversarial loss: 0.563424\n",
      "epoch 186; iter: 0; batch classifier loss: 0.398337; batch adversarial loss: 0.591153\n",
      "epoch 187; iter: 0; batch classifier loss: 0.373848; batch adversarial loss: 0.525771\n",
      "epoch 188; iter: 0; batch classifier loss: 0.391945; batch adversarial loss: 0.506874\n",
      "epoch 189; iter: 0; batch classifier loss: 0.412979; batch adversarial loss: 0.619432\n",
      "epoch 190; iter: 0; batch classifier loss: 0.336995; batch adversarial loss: 0.628192\n",
      "epoch 191; iter: 0; batch classifier loss: 0.439044; batch adversarial loss: 0.508096\n",
      "epoch 192; iter: 0; batch classifier loss: 0.381676; batch adversarial loss: 0.563464\n",
      "epoch 193; iter: 0; batch classifier loss: 0.294209; batch adversarial loss: 0.488385\n",
      "epoch 194; iter: 0; batch classifier loss: 0.353650; batch adversarial loss: 0.573373\n",
      "epoch 195; iter: 0; batch classifier loss: 0.362537; batch adversarial loss: 0.552080\n",
      "epoch 196; iter: 0; batch classifier loss: 0.362483; batch adversarial loss: 0.498311\n",
      "epoch 197; iter: 0; batch classifier loss: 0.354273; batch adversarial loss: 0.544178\n",
      "epoch 198; iter: 0; batch classifier loss: 0.265557; batch adversarial loss: 0.487156\n",
      "epoch 199; iter: 0; batch classifier loss: 0.315878; batch adversarial loss: 0.656397\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.650615; batch adversarial loss: 0.861297\n",
      "epoch 1; iter: 0; batch classifier loss: 0.983278; batch adversarial loss: 1.520820\n",
      "epoch 2; iter: 0; batch classifier loss: 0.970666; batch adversarial loss: 1.493649\n",
      "epoch 3; iter: 0; batch classifier loss: 1.167677; batch adversarial loss: 1.403507\n",
      "epoch 4; iter: 0; batch classifier loss: 1.316149; batch adversarial loss: 1.256766\n",
      "epoch 5; iter: 0; batch classifier loss: 1.182370; batch adversarial loss: 1.185466\n",
      "epoch 6; iter: 0; batch classifier loss: 1.245536; batch adversarial loss: 1.088295\n",
      "epoch 7; iter: 0; batch classifier loss: 1.259477; batch adversarial loss: 1.014598\n",
      "epoch 8; iter: 0; batch classifier loss: 1.106381; batch adversarial loss: 0.933292\n",
      "epoch 9; iter: 0; batch classifier loss: 1.091676; batch adversarial loss: 0.877830\n",
      "epoch 10; iter: 0; batch classifier loss: 1.291417; batch adversarial loss: 0.802657\n",
      "epoch 11; iter: 0; batch classifier loss: 1.093701; batch adversarial loss: 0.761097\n",
      "epoch 12; iter: 0; batch classifier loss: 0.984527; batch adversarial loss: 0.683699\n",
      "epoch 13; iter: 0; batch classifier loss: 0.865085; batch adversarial loss: 0.687750\n",
      "epoch 14; iter: 0; batch classifier loss: 0.659638; batch adversarial loss: 0.636945\n",
      "epoch 15; iter: 0; batch classifier loss: 0.751994; batch adversarial loss: 0.631421\n",
      "epoch 16; iter: 0; batch classifier loss: 0.639870; batch adversarial loss: 0.578061\n",
      "epoch 17; iter: 0; batch classifier loss: 0.556364; batch adversarial loss: 0.581237\n",
      "epoch 18; iter: 0; batch classifier loss: 0.525329; batch adversarial loss: 0.579662\n",
      "epoch 19; iter: 0; batch classifier loss: 0.625036; batch adversarial loss: 0.600388\n",
      "epoch 20; iter: 0; batch classifier loss: 0.490342; batch adversarial loss: 0.539089\n",
      "epoch 21; iter: 0; batch classifier loss: 0.462285; batch adversarial loss: 0.588496\n",
      "epoch 22; iter: 0; batch classifier loss: 0.493942; batch adversarial loss: 0.523953\n",
      "epoch 23; iter: 0; batch classifier loss: 0.596216; batch adversarial loss: 0.601900\n",
      "epoch 24; iter: 0; batch classifier loss: 0.507430; batch adversarial loss: 0.604593\n",
      "epoch 25; iter: 0; batch classifier loss: 0.455057; batch adversarial loss: 0.546670\n",
      "epoch 26; iter: 0; batch classifier loss: 0.500186; batch adversarial loss: 0.602764\n",
      "epoch 27; iter: 0; batch classifier loss: 0.436440; batch adversarial loss: 0.583223\n",
      "epoch 28; iter: 0; batch classifier loss: 0.527288; batch adversarial loss: 0.549954\n",
      "epoch 29; iter: 0; batch classifier loss: 0.474264; batch adversarial loss: 0.594302\n",
      "epoch 30; iter: 0; batch classifier loss: 0.441591; batch adversarial loss: 0.524512\n",
      "epoch 31; iter: 0; batch classifier loss: 0.475401; batch adversarial loss: 0.561919\n",
      "epoch 32; iter: 0; batch classifier loss: 0.537227; batch adversarial loss: 0.514868\n",
      "epoch 33; iter: 0; batch classifier loss: 0.530315; batch adversarial loss: 0.529918\n",
      "epoch 34; iter: 0; batch classifier loss: 0.485848; batch adversarial loss: 0.554101\n",
      "epoch 35; iter: 0; batch classifier loss: 0.438339; batch adversarial loss: 0.512875\n",
      "epoch 36; iter: 0; batch classifier loss: 0.415460; batch adversarial loss: 0.495473\n",
      "epoch 37; iter: 0; batch classifier loss: 0.416510; batch adversarial loss: 0.520633\n",
      "epoch 38; iter: 0; batch classifier loss: 0.481680; batch adversarial loss: 0.519386\n",
      "epoch 39; iter: 0; batch classifier loss: 0.463859; batch adversarial loss: 0.579812\n",
      "epoch 40; iter: 0; batch classifier loss: 0.481347; batch adversarial loss: 0.588841\n",
      "epoch 41; iter: 0; batch classifier loss: 0.467387; batch adversarial loss: 0.544379\n",
      "epoch 42; iter: 0; batch classifier loss: 0.411407; batch adversarial loss: 0.570865\n",
      "epoch 43; iter: 0; batch classifier loss: 0.469427; batch adversarial loss: 0.482633\n",
      "epoch 44; iter: 0; batch classifier loss: 0.543929; batch adversarial loss: 0.471874\n",
      "epoch 45; iter: 0; batch classifier loss: 0.459237; batch adversarial loss: 0.616076\n",
      "epoch 46; iter: 0; batch classifier loss: 0.427082; batch adversarial loss: 0.527107\n",
      "epoch 47; iter: 0; batch classifier loss: 0.452789; batch adversarial loss: 0.490575\n",
      "epoch 48; iter: 0; batch classifier loss: 0.435541; batch adversarial loss: 0.542619\n",
      "epoch 49; iter: 0; batch classifier loss: 0.404445; batch adversarial loss: 0.597450\n",
      "epoch 50; iter: 0; batch classifier loss: 0.506218; batch adversarial loss: 0.562242\n",
      "epoch 51; iter: 0; batch classifier loss: 0.482775; batch adversarial loss: 0.532651\n",
      "epoch 52; iter: 0; batch classifier loss: 0.372097; batch adversarial loss: 0.487311\n",
      "epoch 53; iter: 0; batch classifier loss: 0.441508; batch adversarial loss: 0.587609\n",
      "epoch 54; iter: 0; batch classifier loss: 0.385314; batch adversarial loss: 0.513255\n",
      "epoch 55; iter: 0; batch classifier loss: 0.445460; batch adversarial loss: 0.493555\n",
      "epoch 56; iter: 0; batch classifier loss: 0.392956; batch adversarial loss: 0.568059\n",
      "epoch 57; iter: 0; batch classifier loss: 0.369259; batch adversarial loss: 0.580652\n",
      "epoch 58; iter: 0; batch classifier loss: 0.466495; batch adversarial loss: 0.480619\n",
      "epoch 59; iter: 0; batch classifier loss: 0.412977; batch adversarial loss: 0.589952\n",
      "epoch 60; iter: 0; batch classifier loss: 0.339350; batch adversarial loss: 0.533828\n",
      "epoch 61; iter: 0; batch classifier loss: 0.457106; batch adversarial loss: 0.655140\n",
      "epoch 62; iter: 0; batch classifier loss: 0.417155; batch adversarial loss: 0.608072\n",
      "epoch 63; iter: 0; batch classifier loss: 0.460782; batch adversarial loss: 0.623950\n",
      "epoch 64; iter: 0; batch classifier loss: 0.429836; batch adversarial loss: 0.533748\n",
      "epoch 65; iter: 0; batch classifier loss: 0.392583; batch adversarial loss: 0.534246\n",
      "epoch 66; iter: 0; batch classifier loss: 0.388267; batch adversarial loss: 0.604610\n",
      "epoch 67; iter: 0; batch classifier loss: 0.458228; batch adversarial loss: 0.535886\n",
      "epoch 68; iter: 0; batch classifier loss: 0.390591; batch adversarial loss: 0.477151\n",
      "epoch 69; iter: 0; batch classifier loss: 0.400008; batch adversarial loss: 0.593600\n",
      "epoch 70; iter: 0; batch classifier loss: 0.357378; batch adversarial loss: 0.566383\n",
      "epoch 71; iter: 0; batch classifier loss: 0.420921; batch adversarial loss: 0.573702\n",
      "epoch 72; iter: 0; batch classifier loss: 0.427655; batch adversarial loss: 0.457879\n",
      "epoch 73; iter: 0; batch classifier loss: 0.387208; batch adversarial loss: 0.568463\n",
      "epoch 74; iter: 0; batch classifier loss: 0.433693; batch adversarial loss: 0.518356\n",
      "epoch 75; iter: 0; batch classifier loss: 0.294472; batch adversarial loss: 0.546376\n",
      "epoch 76; iter: 0; batch classifier loss: 0.432167; batch adversarial loss: 0.528606\n",
      "epoch 77; iter: 0; batch classifier loss: 0.449008; batch adversarial loss: 0.573520\n",
      "epoch 78; iter: 0; batch classifier loss: 0.380435; batch adversarial loss: 0.493923\n",
      "epoch 79; iter: 0; batch classifier loss: 0.406778; batch adversarial loss: 0.599007\n",
      "epoch 80; iter: 0; batch classifier loss: 0.421376; batch adversarial loss: 0.509457\n",
      "epoch 81; iter: 0; batch classifier loss: 0.336510; batch adversarial loss: 0.571693\n",
      "epoch 82; iter: 0; batch classifier loss: 0.352607; batch adversarial loss: 0.579871\n",
      "epoch 83; iter: 0; batch classifier loss: 0.398830; batch adversarial loss: 0.553884\n",
      "epoch 84; iter: 0; batch classifier loss: 0.401328; batch adversarial loss: 0.625773\n",
      "epoch 85; iter: 0; batch classifier loss: 0.428559; batch adversarial loss: 0.507223\n",
      "epoch 86; iter: 0; batch classifier loss: 0.384351; batch adversarial loss: 0.597578\n",
      "epoch 87; iter: 0; batch classifier loss: 0.393540; batch adversarial loss: 0.525988\n",
      "epoch 88; iter: 0; batch classifier loss: 0.398374; batch adversarial loss: 0.535402\n",
      "epoch 89; iter: 0; batch classifier loss: 0.483853; batch adversarial loss: 0.536062\n",
      "epoch 90; iter: 0; batch classifier loss: 0.434555; batch adversarial loss: 0.499366\n",
      "epoch 91; iter: 0; batch classifier loss: 0.379818; batch adversarial loss: 0.490076\n",
      "epoch 92; iter: 0; batch classifier loss: 0.375347; batch adversarial loss: 0.582294\n",
      "epoch 93; iter: 0; batch classifier loss: 0.467692; batch adversarial loss: 0.600736\n",
      "epoch 94; iter: 0; batch classifier loss: 0.451838; batch adversarial loss: 0.591254\n",
      "epoch 95; iter: 0; batch classifier loss: 0.432576; batch adversarial loss: 0.600680\n",
      "epoch 96; iter: 0; batch classifier loss: 0.373955; batch adversarial loss: 0.563441\n",
      "epoch 97; iter: 0; batch classifier loss: 0.338133; batch adversarial loss: 0.516505\n",
      "epoch 98; iter: 0; batch classifier loss: 0.424047; batch adversarial loss: 0.534867\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 99; iter: 0; batch classifier loss: 0.409341; batch adversarial loss: 0.515940\n",
      "epoch 100; iter: 0; batch classifier loss: 0.357189; batch adversarial loss: 0.634909\n",
      "epoch 101; iter: 0; batch classifier loss: 0.400383; batch adversarial loss: 0.564529\n",
      "epoch 102; iter: 0; batch classifier loss: 0.351024; batch adversarial loss: 0.450008\n",
      "epoch 103; iter: 0; batch classifier loss: 0.358681; batch adversarial loss: 0.543915\n",
      "epoch 104; iter: 0; batch classifier loss: 0.323013; batch adversarial loss: 0.583556\n",
      "epoch 105; iter: 0; batch classifier loss: 0.330383; batch adversarial loss: 0.561616\n",
      "epoch 106; iter: 0; batch classifier loss: 0.364558; batch adversarial loss: 0.552687\n",
      "epoch 107; iter: 0; batch classifier loss: 0.409696; batch adversarial loss: 0.598654\n",
      "epoch 108; iter: 0; batch classifier loss: 0.404493; batch adversarial loss: 0.528290\n",
      "epoch 109; iter: 0; batch classifier loss: 0.364894; batch adversarial loss: 0.573289\n",
      "epoch 110; iter: 0; batch classifier loss: 0.319056; batch adversarial loss: 0.544802\n",
      "epoch 111; iter: 0; batch classifier loss: 0.329118; batch adversarial loss: 0.526793\n",
      "epoch 112; iter: 0; batch classifier loss: 0.368007; batch adversarial loss: 0.478363\n",
      "epoch 113; iter: 0; batch classifier loss: 0.464617; batch adversarial loss: 0.553035\n",
      "epoch 114; iter: 0; batch classifier loss: 0.331533; batch adversarial loss: 0.552699\n",
      "epoch 115; iter: 0; batch classifier loss: 0.313681; batch adversarial loss: 0.516309\n",
      "epoch 116; iter: 0; batch classifier loss: 0.380666; batch adversarial loss: 0.543114\n",
      "epoch 117; iter: 0; batch classifier loss: 0.390255; batch adversarial loss: 0.623783\n",
      "epoch 118; iter: 0; batch classifier loss: 0.414652; batch adversarial loss: 0.477795\n",
      "epoch 119; iter: 0; batch classifier loss: 0.376066; batch adversarial loss: 0.544872\n",
      "epoch 120; iter: 0; batch classifier loss: 0.349506; batch adversarial loss: 0.555530\n",
      "epoch 121; iter: 0; batch classifier loss: 0.333478; batch adversarial loss: 0.506278\n",
      "epoch 122; iter: 0; batch classifier loss: 0.409598; batch adversarial loss: 0.516402\n",
      "epoch 123; iter: 0; batch classifier loss: 0.276889; batch adversarial loss: 0.574756\n",
      "epoch 124; iter: 0; batch classifier loss: 0.377114; batch adversarial loss: 0.563400\n",
      "epoch 125; iter: 0; batch classifier loss: 0.334781; batch adversarial loss: 0.442776\n",
      "epoch 126; iter: 0; batch classifier loss: 0.429932; batch adversarial loss: 0.571151\n",
      "epoch 127; iter: 0; batch classifier loss: 0.356606; batch adversarial loss: 0.644657\n",
      "epoch 128; iter: 0; batch classifier loss: 0.390669; batch adversarial loss: 0.544004\n",
      "epoch 129; iter: 0; batch classifier loss: 0.405931; batch adversarial loss: 0.505662\n",
      "epoch 130; iter: 0; batch classifier loss: 0.303520; batch adversarial loss: 0.453448\n",
      "epoch 131; iter: 0; batch classifier loss: 0.361997; batch adversarial loss: 0.555275\n",
      "epoch 132; iter: 0; batch classifier loss: 0.447782; batch adversarial loss: 0.552227\n",
      "epoch 133; iter: 0; batch classifier loss: 0.371967; batch adversarial loss: 0.617088\n",
      "epoch 134; iter: 0; batch classifier loss: 0.427052; batch adversarial loss: 0.507934\n",
      "epoch 135; iter: 0; batch classifier loss: 0.433182; batch adversarial loss: 0.582191\n",
      "epoch 136; iter: 0; batch classifier loss: 0.378427; batch adversarial loss: 0.489648\n",
      "epoch 137; iter: 0; batch classifier loss: 0.356781; batch adversarial loss: 0.597495\n",
      "epoch 138; iter: 0; batch classifier loss: 0.370460; batch adversarial loss: 0.481504\n",
      "epoch 139; iter: 0; batch classifier loss: 0.291259; batch adversarial loss: 0.553498\n",
      "epoch 140; iter: 0; batch classifier loss: 0.365940; batch adversarial loss: 0.461672\n",
      "epoch 141; iter: 0; batch classifier loss: 0.334852; batch adversarial loss: 0.590084\n",
      "epoch 142; iter: 0; batch classifier loss: 0.390970; batch adversarial loss: 0.600120\n",
      "epoch 143; iter: 0; batch classifier loss: 0.360390; batch adversarial loss: 0.599766\n",
      "epoch 144; iter: 0; batch classifier loss: 0.366162; batch adversarial loss: 0.561771\n",
      "epoch 145; iter: 0; batch classifier loss: 0.340508; batch adversarial loss: 0.461382\n",
      "epoch 146; iter: 0; batch classifier loss: 0.299101; batch adversarial loss: 0.564155\n",
      "epoch 147; iter: 0; batch classifier loss: 0.340851; batch adversarial loss: 0.600463\n",
      "epoch 148; iter: 0; batch classifier loss: 0.364898; batch adversarial loss: 0.579216\n",
      "epoch 149; iter: 0; batch classifier loss: 0.366751; batch adversarial loss: 0.544256\n",
      "epoch 150; iter: 0; batch classifier loss: 0.325635; batch adversarial loss: 0.543076\n",
      "epoch 151; iter: 0; batch classifier loss: 0.357394; batch adversarial loss: 0.561700\n",
      "epoch 152; iter: 0; batch classifier loss: 0.376923; batch adversarial loss: 0.644513\n",
      "epoch 153; iter: 0; batch classifier loss: 0.354960; batch adversarial loss: 0.608039\n",
      "epoch 154; iter: 0; batch classifier loss: 0.253303; batch adversarial loss: 0.564076\n",
      "epoch 155; iter: 0; batch classifier loss: 0.406012; batch adversarial loss: 0.562792\n",
      "epoch 156; iter: 0; batch classifier loss: 0.345387; batch adversarial loss: 0.581731\n",
      "epoch 157; iter: 0; batch classifier loss: 0.339835; batch adversarial loss: 0.499779\n",
      "epoch 158; iter: 0; batch classifier loss: 0.301575; batch adversarial loss: 0.591038\n",
      "epoch 159; iter: 0; batch classifier loss: 0.341130; batch adversarial loss: 0.626690\n",
      "epoch 160; iter: 0; batch classifier loss: 0.350655; batch adversarial loss: 0.634620\n",
      "epoch 161; iter: 0; batch classifier loss: 0.300155; batch adversarial loss: 0.480459\n",
      "epoch 162; iter: 0; batch classifier loss: 0.344291; batch adversarial loss: 0.591716\n",
      "epoch 163; iter: 0; batch classifier loss: 0.355558; batch adversarial loss: 0.581187\n",
      "epoch 164; iter: 0; batch classifier loss: 0.323922; batch adversarial loss: 0.618262\n",
      "epoch 165; iter: 0; batch classifier loss: 0.343485; batch adversarial loss: 0.562624\n",
      "epoch 166; iter: 0; batch classifier loss: 0.297540; batch adversarial loss: 0.553281\n",
      "epoch 167; iter: 0; batch classifier loss: 0.318349; batch adversarial loss: 0.545011\n",
      "epoch 168; iter: 0; batch classifier loss: 0.327071; batch adversarial loss: 0.534241\n",
      "epoch 169; iter: 0; batch classifier loss: 0.349754; batch adversarial loss: 0.589961\n",
      "epoch 170; iter: 0; batch classifier loss: 0.362579; batch adversarial loss: 0.507910\n",
      "epoch 171; iter: 0; batch classifier loss: 0.362819; batch adversarial loss: 0.518317\n",
      "epoch 172; iter: 0; batch classifier loss: 0.334775; batch adversarial loss: 0.534059\n",
      "epoch 173; iter: 0; batch classifier loss: 0.279824; batch adversarial loss: 0.534230\n",
      "epoch 174; iter: 0; batch classifier loss: 0.370264; batch adversarial loss: 0.590400\n",
      "epoch 175; iter: 0; batch classifier loss: 0.320603; batch adversarial loss: 0.524888\n",
      "epoch 176; iter: 0; batch classifier loss: 0.365033; batch adversarial loss: 0.560824\n",
      "epoch 177; iter: 0; batch classifier loss: 0.387060; batch adversarial loss: 0.572303\n",
      "epoch 178; iter: 0; batch classifier loss: 0.317321; batch adversarial loss: 0.535387\n",
      "epoch 179; iter: 0; batch classifier loss: 0.361930; batch adversarial loss: 0.515798\n",
      "epoch 180; iter: 0; batch classifier loss: 0.333327; batch adversarial loss: 0.581864\n",
      "epoch 181; iter: 0; batch classifier loss: 0.346891; batch adversarial loss: 0.662639\n",
      "epoch 182; iter: 0; batch classifier loss: 0.325800; batch adversarial loss: 0.545141\n",
      "epoch 183; iter: 0; batch classifier loss: 0.337216; batch adversarial loss: 0.644213\n",
      "epoch 184; iter: 0; batch classifier loss: 0.313501; batch adversarial loss: 0.516770\n",
      "epoch 185; iter: 0; batch classifier loss: 0.318605; batch adversarial loss: 0.571784\n",
      "epoch 186; iter: 0; batch classifier loss: 0.376397; batch adversarial loss: 0.498636\n",
      "epoch 187; iter: 0; batch classifier loss: 0.317258; batch adversarial loss: 0.534379\n",
      "epoch 188; iter: 0; batch classifier loss: 0.370608; batch adversarial loss: 0.525463\n",
      "epoch 189; iter: 0; batch classifier loss: 0.228145; batch adversarial loss: 0.600515\n",
      "epoch 190; iter: 0; batch classifier loss: 0.266372; batch adversarial loss: 0.498409\n",
      "epoch 191; iter: 0; batch classifier loss: 0.370666; batch adversarial loss: 0.471881\n",
      "epoch 192; iter: 0; batch classifier loss: 0.366650; batch adversarial loss: 0.490120\n",
      "epoch 193; iter: 0; batch classifier loss: 0.454931; batch adversarial loss: 0.598535\n",
      "epoch 194; iter: 0; batch classifier loss: 0.374812; batch adversarial loss: 0.534169\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 195; iter: 0; batch classifier loss: 0.256868; batch adversarial loss: 0.553836\n",
      "epoch 196; iter: 0; batch classifier loss: 0.320894; batch adversarial loss: 0.598689\n",
      "epoch 197; iter: 0; batch classifier loss: 0.287290; batch adversarial loss: 0.563367\n",
      "epoch 198; iter: 0; batch classifier loss: 0.424554; batch adversarial loss: 0.544960\n",
      "epoch 199; iter: 0; batch classifier loss: 0.285445; batch adversarial loss: 0.462413\n",
      "epoch 0; iter: 0; batch classifier loss: 0.701252; batch adversarial loss: 0.873332\n",
      "epoch 1; iter: 0; batch classifier loss: 0.716076; batch adversarial loss: 0.841857\n",
      "epoch 2; iter: 0; batch classifier loss: 0.571511; batch adversarial loss: 0.846975\n",
      "epoch 3; iter: 0; batch classifier loss: 0.598576; batch adversarial loss: 0.751278\n",
      "epoch 4; iter: 0; batch classifier loss: 0.641573; batch adversarial loss: 0.709176\n",
      "epoch 5; iter: 0; batch classifier loss: 0.627962; batch adversarial loss: 0.706612\n",
      "epoch 6; iter: 0; batch classifier loss: 0.548562; batch adversarial loss: 0.629066\n",
      "epoch 7; iter: 0; batch classifier loss: 0.552778; batch adversarial loss: 0.648760\n",
      "epoch 8; iter: 0; batch classifier loss: 0.534599; batch adversarial loss: 0.620133\n",
      "epoch 9; iter: 0; batch classifier loss: 0.614464; batch adversarial loss: 0.594168\n",
      "epoch 10; iter: 0; batch classifier loss: 0.533529; batch adversarial loss: 0.636280\n",
      "epoch 11; iter: 0; batch classifier loss: 0.542958; batch adversarial loss: 0.614053\n",
      "epoch 12; iter: 0; batch classifier loss: 0.475114; batch adversarial loss: 0.610120\n",
      "epoch 13; iter: 0; batch classifier loss: 0.600849; batch adversarial loss: 0.583734\n",
      "epoch 14; iter: 0; batch classifier loss: 0.495878; batch adversarial loss: 0.606890\n",
      "epoch 15; iter: 0; batch classifier loss: 0.560416; batch adversarial loss: 0.594502\n",
      "epoch 16; iter: 0; batch classifier loss: 0.487147; batch adversarial loss: 0.559726\n",
      "epoch 17; iter: 0; batch classifier loss: 0.482392; batch adversarial loss: 0.576311\n",
      "epoch 18; iter: 0; batch classifier loss: 0.530190; batch adversarial loss: 0.550167\n",
      "epoch 19; iter: 0; batch classifier loss: 0.588123; batch adversarial loss: 0.545026\n",
      "epoch 20; iter: 0; batch classifier loss: 0.544419; batch adversarial loss: 0.563382\n",
      "epoch 21; iter: 0; batch classifier loss: 0.499768; batch adversarial loss: 0.600297\n",
      "epoch 22; iter: 0; batch classifier loss: 0.453174; batch adversarial loss: 0.601834\n",
      "epoch 23; iter: 0; batch classifier loss: 0.525801; batch adversarial loss: 0.491549\n",
      "epoch 24; iter: 0; batch classifier loss: 0.570419; batch adversarial loss: 0.612949\n",
      "epoch 25; iter: 0; batch classifier loss: 0.473629; batch adversarial loss: 0.550046\n",
      "epoch 26; iter: 0; batch classifier loss: 0.451746; batch adversarial loss: 0.571941\n",
      "epoch 27; iter: 0; batch classifier loss: 0.413002; batch adversarial loss: 0.532385\n",
      "epoch 28; iter: 0; batch classifier loss: 0.488096; batch adversarial loss: 0.617683\n",
      "epoch 29; iter: 0; batch classifier loss: 0.462801; batch adversarial loss: 0.539438\n",
      "epoch 30; iter: 0; batch classifier loss: 0.467297; batch adversarial loss: 0.483406\n",
      "epoch 31; iter: 0; batch classifier loss: 0.491723; batch adversarial loss: 0.537511\n",
      "epoch 32; iter: 0; batch classifier loss: 0.495292; batch adversarial loss: 0.606318\n",
      "epoch 33; iter: 0; batch classifier loss: 0.436380; batch adversarial loss: 0.569825\n",
      "epoch 34; iter: 0; batch classifier loss: 0.452164; batch adversarial loss: 0.617007\n",
      "epoch 35; iter: 0; batch classifier loss: 0.543613; batch adversarial loss: 0.543757\n",
      "epoch 36; iter: 0; batch classifier loss: 0.450939; batch adversarial loss: 0.603910\n",
      "epoch 37; iter: 0; batch classifier loss: 0.500119; batch adversarial loss: 0.500107\n",
      "epoch 38; iter: 0; batch classifier loss: 0.554154; batch adversarial loss: 0.531211\n",
      "epoch 39; iter: 0; batch classifier loss: 0.384036; batch adversarial loss: 0.547307\n",
      "epoch 40; iter: 0; batch classifier loss: 0.401799; batch adversarial loss: 0.574460\n",
      "epoch 41; iter: 0; batch classifier loss: 0.493436; batch adversarial loss: 0.572255\n",
      "epoch 42; iter: 0; batch classifier loss: 0.410911; batch adversarial loss: 0.584548\n",
      "epoch 43; iter: 0; batch classifier loss: 0.469034; batch adversarial loss: 0.557071\n",
      "epoch 44; iter: 0; batch classifier loss: 0.401810; batch adversarial loss: 0.535310\n",
      "epoch 45; iter: 0; batch classifier loss: 0.508892; batch adversarial loss: 0.559121\n",
      "epoch 46; iter: 0; batch classifier loss: 0.468596; batch adversarial loss: 0.536510\n",
      "epoch 47; iter: 0; batch classifier loss: 0.403640; batch adversarial loss: 0.592762\n",
      "epoch 48; iter: 0; batch classifier loss: 0.471906; batch adversarial loss: 0.566930\n",
      "epoch 49; iter: 0; batch classifier loss: 0.396454; batch adversarial loss: 0.560017\n",
      "epoch 50; iter: 0; batch classifier loss: 0.479629; batch adversarial loss: 0.582400\n",
      "epoch 51; iter: 0; batch classifier loss: 0.363400; batch adversarial loss: 0.524395\n",
      "epoch 52; iter: 0; batch classifier loss: 0.419758; batch adversarial loss: 0.453048\n",
      "epoch 53; iter: 0; batch classifier loss: 0.511099; batch adversarial loss: 0.549595\n",
      "epoch 54; iter: 0; batch classifier loss: 0.445567; batch adversarial loss: 0.536574\n",
      "epoch 55; iter: 0; batch classifier loss: 0.551713; batch adversarial loss: 0.557363\n",
      "epoch 56; iter: 0; batch classifier loss: 0.416415; batch adversarial loss: 0.595615\n",
      "epoch 57; iter: 0; batch classifier loss: 0.414758; batch adversarial loss: 0.619318\n",
      "epoch 58; iter: 0; batch classifier loss: 0.431634; batch adversarial loss: 0.526589\n",
      "epoch 59; iter: 0; batch classifier loss: 0.465619; batch adversarial loss: 0.435499\n",
      "epoch 60; iter: 0; batch classifier loss: 0.493756; batch adversarial loss: 0.552812\n",
      "epoch 61; iter: 0; batch classifier loss: 0.417626; batch adversarial loss: 0.578207\n",
      "epoch 62; iter: 0; batch classifier loss: 0.437323; batch adversarial loss: 0.516590\n",
      "epoch 63; iter: 0; batch classifier loss: 0.413719; batch adversarial loss: 0.556922\n",
      "epoch 64; iter: 0; batch classifier loss: 0.329931; batch adversarial loss: 0.572383\n",
      "epoch 65; iter: 0; batch classifier loss: 0.465505; batch adversarial loss: 0.534853\n",
      "epoch 66; iter: 0; batch classifier loss: 0.341451; batch adversarial loss: 0.544398\n",
      "epoch 67; iter: 0; batch classifier loss: 0.420427; batch adversarial loss: 0.478086\n",
      "epoch 68; iter: 0; batch classifier loss: 0.425673; batch adversarial loss: 0.510554\n",
      "epoch 69; iter: 0; batch classifier loss: 0.410830; batch adversarial loss: 0.536262\n",
      "epoch 70; iter: 0; batch classifier loss: 0.375238; batch adversarial loss: 0.497436\n",
      "epoch 71; iter: 0; batch classifier loss: 0.461212; batch adversarial loss: 0.529239\n",
      "epoch 72; iter: 0; batch classifier loss: 0.338749; batch adversarial loss: 0.528150\n",
      "epoch 73; iter: 0; batch classifier loss: 0.411005; batch adversarial loss: 0.515709\n",
      "epoch 74; iter: 0; batch classifier loss: 0.390449; batch adversarial loss: 0.534919\n",
      "epoch 75; iter: 0; batch classifier loss: 0.330178; batch adversarial loss: 0.534128\n",
      "epoch 76; iter: 0; batch classifier loss: 0.312170; batch adversarial loss: 0.573257\n",
      "epoch 77; iter: 0; batch classifier loss: 0.425914; batch adversarial loss: 0.522739\n",
      "epoch 78; iter: 0; batch classifier loss: 0.525440; batch adversarial loss: 0.582968\n",
      "epoch 79; iter: 0; batch classifier loss: 0.375484; batch adversarial loss: 0.611138\n",
      "epoch 80; iter: 0; batch classifier loss: 0.384472; batch adversarial loss: 0.484543\n",
      "epoch 81; iter: 0; batch classifier loss: 0.423571; batch adversarial loss: 0.519436\n",
      "epoch 82; iter: 0; batch classifier loss: 0.421625; batch adversarial loss: 0.524419\n",
      "epoch 83; iter: 0; batch classifier loss: 0.448891; batch adversarial loss: 0.553004\n",
      "epoch 84; iter: 0; batch classifier loss: 0.392575; batch adversarial loss: 0.525455\n",
      "epoch 85; iter: 0; batch classifier loss: 0.459135; batch adversarial loss: 0.504607\n",
      "epoch 86; iter: 0; batch classifier loss: 0.362566; batch adversarial loss: 0.524626\n",
      "epoch 87; iter: 0; batch classifier loss: 0.412586; batch adversarial loss: 0.514492\n",
      "epoch 88; iter: 0; batch classifier loss: 0.488883; batch adversarial loss: 0.517969\n",
      "epoch 89; iter: 0; batch classifier loss: 0.388015; batch adversarial loss: 0.534693\n",
      "epoch 90; iter: 0; batch classifier loss: 0.320676; batch adversarial loss: 0.580648\n",
      "epoch 91; iter: 0; batch classifier loss: 0.396248; batch adversarial loss: 0.552210\n",
      "epoch 92; iter: 0; batch classifier loss: 0.432839; batch adversarial loss: 0.564566\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 93; iter: 0; batch classifier loss: 0.379932; batch adversarial loss: 0.507535\n",
      "epoch 94; iter: 0; batch classifier loss: 0.436095; batch adversarial loss: 0.525579\n",
      "epoch 95; iter: 0; batch classifier loss: 0.427423; batch adversarial loss: 0.656864\n",
      "epoch 96; iter: 0; batch classifier loss: 0.388040; batch adversarial loss: 0.499017\n",
      "epoch 97; iter: 0; batch classifier loss: 0.392484; batch adversarial loss: 0.563243\n",
      "epoch 98; iter: 0; batch classifier loss: 0.357154; batch adversarial loss: 0.564612\n",
      "epoch 99; iter: 0; batch classifier loss: 0.443266; batch adversarial loss: 0.469913\n",
      "epoch 100; iter: 0; batch classifier loss: 0.439111; batch adversarial loss: 0.536755\n",
      "epoch 101; iter: 0; batch classifier loss: 0.347815; batch adversarial loss: 0.543112\n",
      "epoch 102; iter: 0; batch classifier loss: 0.359146; batch adversarial loss: 0.497325\n",
      "epoch 103; iter: 0; batch classifier loss: 0.391182; batch adversarial loss: 0.543825\n",
      "epoch 104; iter: 0; batch classifier loss: 0.391236; batch adversarial loss: 0.479034\n",
      "epoch 105; iter: 0; batch classifier loss: 0.415785; batch adversarial loss: 0.487664\n",
      "epoch 106; iter: 0; batch classifier loss: 0.436607; batch adversarial loss: 0.524798\n",
      "epoch 107; iter: 0; batch classifier loss: 0.431599; batch adversarial loss: 0.580784\n",
      "epoch 108; iter: 0; batch classifier loss: 0.353636; batch adversarial loss: 0.553984\n",
      "epoch 109; iter: 0; batch classifier loss: 0.317915; batch adversarial loss: 0.522963\n",
      "epoch 110; iter: 0; batch classifier loss: 0.392257; batch adversarial loss: 0.536369\n",
      "epoch 111; iter: 0; batch classifier loss: 0.401545; batch adversarial loss: 0.515341\n",
      "epoch 112; iter: 0; batch classifier loss: 0.463169; batch adversarial loss: 0.571518\n",
      "epoch 113; iter: 0; batch classifier loss: 0.340053; batch adversarial loss: 0.555138\n",
      "epoch 114; iter: 0; batch classifier loss: 0.380343; batch adversarial loss: 0.573461\n",
      "epoch 115; iter: 0; batch classifier loss: 0.382123; batch adversarial loss: 0.506027\n",
      "epoch 116; iter: 0; batch classifier loss: 0.402117; batch adversarial loss: 0.526938\n",
      "epoch 117; iter: 0; batch classifier loss: 0.401490; batch adversarial loss: 0.602633\n",
      "epoch 118; iter: 0; batch classifier loss: 0.401252; batch adversarial loss: 0.657570\n",
      "epoch 119; iter: 0; batch classifier loss: 0.406622; batch adversarial loss: 0.553029\n",
      "epoch 120; iter: 0; batch classifier loss: 0.433575; batch adversarial loss: 0.553982\n",
      "epoch 121; iter: 0; batch classifier loss: 0.453759; batch adversarial loss: 0.450833\n",
      "epoch 122; iter: 0; batch classifier loss: 0.434621; batch adversarial loss: 0.555043\n",
      "epoch 123; iter: 0; batch classifier loss: 0.379768; batch adversarial loss: 0.515381\n",
      "epoch 124; iter: 0; batch classifier loss: 0.397873; batch adversarial loss: 0.506486\n",
      "epoch 125; iter: 0; batch classifier loss: 0.419785; batch adversarial loss: 0.535211\n",
      "epoch 126; iter: 0; batch classifier loss: 0.371356; batch adversarial loss: 0.562027\n",
      "epoch 127; iter: 0; batch classifier loss: 0.355692; batch adversarial loss: 0.449944\n",
      "epoch 128; iter: 0; batch classifier loss: 0.474162; batch adversarial loss: 0.545001\n",
      "epoch 129; iter: 0; batch classifier loss: 0.360017; batch adversarial loss: 0.554168\n",
      "epoch 130; iter: 0; batch classifier loss: 0.374048; batch adversarial loss: 0.517000\n",
      "epoch 131; iter: 0; batch classifier loss: 0.415754; batch adversarial loss: 0.498358\n",
      "epoch 132; iter: 0; batch classifier loss: 0.350011; batch adversarial loss: 0.496534\n",
      "epoch 133; iter: 0; batch classifier loss: 0.265512; batch adversarial loss: 0.545583\n",
      "epoch 134; iter: 0; batch classifier loss: 0.371602; batch adversarial loss: 0.580902\n",
      "epoch 135; iter: 0; batch classifier loss: 0.490234; batch adversarial loss: 0.515649\n",
      "epoch 136; iter: 0; batch classifier loss: 0.430033; batch adversarial loss: 0.524841\n",
      "epoch 137; iter: 0; batch classifier loss: 0.281778; batch adversarial loss: 0.499462\n",
      "epoch 138; iter: 0; batch classifier loss: 0.382216; batch adversarial loss: 0.601175\n",
      "epoch 139; iter: 0; batch classifier loss: 0.465773; batch adversarial loss: 0.553371\n",
      "epoch 140; iter: 0; batch classifier loss: 0.326490; batch adversarial loss: 0.547255\n",
      "epoch 141; iter: 0; batch classifier loss: 0.411303; batch adversarial loss: 0.553825\n",
      "epoch 142; iter: 0; batch classifier loss: 0.318276; batch adversarial loss: 0.564966\n",
      "epoch 143; iter: 0; batch classifier loss: 0.374369; batch adversarial loss: 0.487788\n",
      "epoch 144; iter: 0; batch classifier loss: 0.404483; batch adversarial loss: 0.561707\n",
      "epoch 145; iter: 0; batch classifier loss: 0.381535; batch adversarial loss: 0.486978\n",
      "epoch 146; iter: 0; batch classifier loss: 0.457376; batch adversarial loss: 0.525883\n",
      "epoch 147; iter: 0; batch classifier loss: 0.364133; batch adversarial loss: 0.506085\n",
      "epoch 148; iter: 0; batch classifier loss: 0.335056; batch adversarial loss: 0.524496\n",
      "epoch 149; iter: 0; batch classifier loss: 0.427769; batch adversarial loss: 0.609668\n",
      "epoch 150; iter: 0; batch classifier loss: 0.317696; batch adversarial loss: 0.507780\n",
      "epoch 151; iter: 0; batch classifier loss: 0.331024; batch adversarial loss: 0.489474\n",
      "epoch 152; iter: 0; batch classifier loss: 0.408405; batch adversarial loss: 0.507462\n",
      "epoch 153; iter: 0; batch classifier loss: 0.384513; batch adversarial loss: 0.498385\n",
      "epoch 154; iter: 0; batch classifier loss: 0.389473; batch adversarial loss: 0.544408\n",
      "epoch 155; iter: 0; batch classifier loss: 0.404746; batch adversarial loss: 0.629342\n",
      "epoch 156; iter: 0; batch classifier loss: 0.326189; batch adversarial loss: 0.487670\n",
      "epoch 157; iter: 0; batch classifier loss: 0.315207; batch adversarial loss: 0.516755\n",
      "epoch 158; iter: 0; batch classifier loss: 0.398053; batch adversarial loss: 0.496048\n",
      "epoch 159; iter: 0; batch classifier loss: 0.384712; batch adversarial loss: 0.495832\n",
      "epoch 160; iter: 0; batch classifier loss: 0.320182; batch adversarial loss: 0.450281\n",
      "epoch 161; iter: 0; batch classifier loss: 0.367005; batch adversarial loss: 0.564399\n",
      "epoch 162; iter: 0; batch classifier loss: 0.376357; batch adversarial loss: 0.620860\n",
      "epoch 163; iter: 0; batch classifier loss: 0.463870; batch adversarial loss: 0.582010\n",
      "epoch 164; iter: 0; batch classifier loss: 0.346970; batch adversarial loss: 0.581989\n",
      "epoch 165; iter: 0; batch classifier loss: 0.430563; batch adversarial loss: 0.600620\n",
      "epoch 166; iter: 0; batch classifier loss: 0.306945; batch adversarial loss: 0.506089\n",
      "epoch 167; iter: 0; batch classifier loss: 0.383355; batch adversarial loss: 0.573087\n",
      "epoch 168; iter: 0; batch classifier loss: 0.406037; batch adversarial loss: 0.488324\n",
      "epoch 169; iter: 0; batch classifier loss: 0.290269; batch adversarial loss: 0.564746\n",
      "epoch 170; iter: 0; batch classifier loss: 0.361244; batch adversarial loss: 0.629361\n",
      "epoch 171; iter: 0; batch classifier loss: 0.346179; batch adversarial loss: 0.516204\n",
      "epoch 172; iter: 0; batch classifier loss: 0.370171; batch adversarial loss: 0.570128\n",
      "epoch 173; iter: 0; batch classifier loss: 0.314358; batch adversarial loss: 0.488749\n",
      "epoch 174; iter: 0; batch classifier loss: 0.406025; batch adversarial loss: 0.505835\n",
      "epoch 175; iter: 0; batch classifier loss: 0.409289; batch adversarial loss: 0.629373\n",
      "epoch 176; iter: 0; batch classifier loss: 0.317025; batch adversarial loss: 0.544013\n",
      "epoch 177; iter: 0; batch classifier loss: 0.411232; batch adversarial loss: 0.524197\n",
      "epoch 178; iter: 0; batch classifier loss: 0.371364; batch adversarial loss: 0.564139\n",
      "epoch 179; iter: 0; batch classifier loss: 0.407682; batch adversarial loss: 0.536125\n",
      "epoch 180; iter: 0; batch classifier loss: 0.376542; batch adversarial loss: 0.507034\n",
      "epoch 181; iter: 0; batch classifier loss: 0.359619; batch adversarial loss: 0.518015\n",
      "epoch 182; iter: 0; batch classifier loss: 0.358248; batch adversarial loss: 0.534045\n",
      "epoch 183; iter: 0; batch classifier loss: 0.388762; batch adversarial loss: 0.507258\n",
      "epoch 184; iter: 0; batch classifier loss: 0.310748; batch adversarial loss: 0.534885\n",
      "epoch 185; iter: 0; batch classifier loss: 0.310191; batch adversarial loss: 0.545979\n",
      "epoch 186; iter: 0; batch classifier loss: 0.289548; batch adversarial loss: 0.627924\n",
      "epoch 187; iter: 0; batch classifier loss: 0.340339; batch adversarial loss: 0.574866\n",
      "epoch 188; iter: 0; batch classifier loss: 0.325683; batch adversarial loss: 0.563108\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 189; iter: 0; batch classifier loss: 0.379969; batch adversarial loss: 0.564234\n",
      "epoch 190; iter: 0; batch classifier loss: 0.433950; batch adversarial loss: 0.556010\n",
      "epoch 191; iter: 0; batch classifier loss: 0.347520; batch adversarial loss: 0.580332\n",
      "epoch 192; iter: 0; batch classifier loss: 0.353656; batch adversarial loss: 0.581225\n",
      "epoch 193; iter: 0; batch classifier loss: 0.402709; batch adversarial loss: 0.498125\n",
      "epoch 194; iter: 0; batch classifier loss: 0.368669; batch adversarial loss: 0.536884\n",
      "epoch 195; iter: 0; batch classifier loss: 0.420798; batch adversarial loss: 0.439713\n",
      "epoch 196; iter: 0; batch classifier loss: 0.422480; batch adversarial loss: 0.551996\n",
      "epoch 197; iter: 0; batch classifier loss: 0.342199; batch adversarial loss: 0.460963\n",
      "epoch 198; iter: 0; batch classifier loss: 0.388171; batch adversarial loss: 0.517371\n",
      "epoch 199; iter: 0; batch classifier loss: 0.278601; batch adversarial loss: 0.507600\n",
      "epoch 0; iter: 0; batch classifier loss: 0.684447; batch adversarial loss: 0.853312\n",
      "epoch 1; iter: 0; batch classifier loss: 0.788287; batch adversarial loss: 0.925288\n",
      "epoch 2; iter: 0; batch classifier loss: 0.962416; batch adversarial loss: 0.864439\n",
      "epoch 3; iter: 0; batch classifier loss: 0.952902; batch adversarial loss: 0.794161\n",
      "epoch 4; iter: 0; batch classifier loss: 0.958393; batch adversarial loss: 0.734600\n",
      "epoch 5; iter: 0; batch classifier loss: 0.924873; batch adversarial loss: 0.678886\n",
      "epoch 6; iter: 0; batch classifier loss: 0.795782; batch adversarial loss: 0.632350\n",
      "epoch 7; iter: 0; batch classifier loss: 0.583393; batch adversarial loss: 0.583787\n",
      "epoch 8; iter: 0; batch classifier loss: 0.642902; batch adversarial loss: 0.564296\n",
      "epoch 9; iter: 0; batch classifier loss: 0.648755; batch adversarial loss: 0.563896\n",
      "epoch 10; iter: 0; batch classifier loss: 0.665376; batch adversarial loss: 0.567911\n",
      "epoch 11; iter: 0; batch classifier loss: 0.566118; batch adversarial loss: 0.561358\n",
      "epoch 12; iter: 0; batch classifier loss: 0.501265; batch adversarial loss: 0.536380\n",
      "epoch 13; iter: 0; batch classifier loss: 0.521031; batch adversarial loss: 0.566045\n",
      "epoch 14; iter: 0; batch classifier loss: 0.413892; batch adversarial loss: 0.557968\n",
      "epoch 15; iter: 0; batch classifier loss: 0.524332; batch adversarial loss: 0.506152\n",
      "epoch 16; iter: 0; batch classifier loss: 0.513211; batch adversarial loss: 0.524545\n",
      "epoch 17; iter: 0; batch classifier loss: 0.541119; batch adversarial loss: 0.534059\n",
      "epoch 18; iter: 0; batch classifier loss: 0.510747; batch adversarial loss: 0.521242\n",
      "epoch 19; iter: 0; batch classifier loss: 0.430638; batch adversarial loss: 0.590490\n",
      "epoch 20; iter: 0; batch classifier loss: 0.516012; batch adversarial loss: 0.532515\n",
      "epoch 21; iter: 0; batch classifier loss: 0.492717; batch adversarial loss: 0.581136\n",
      "epoch 22; iter: 0; batch classifier loss: 0.373558; batch adversarial loss: 0.495128\n",
      "epoch 23; iter: 0; batch classifier loss: 0.455756; batch adversarial loss: 0.510707\n",
      "epoch 24; iter: 0; batch classifier loss: 0.490158; batch adversarial loss: 0.603114\n",
      "epoch 25; iter: 0; batch classifier loss: 0.455379; batch adversarial loss: 0.559942\n",
      "epoch 26; iter: 0; batch classifier loss: 0.511652; batch adversarial loss: 0.582534\n",
      "epoch 27; iter: 0; batch classifier loss: 0.488457; batch adversarial loss: 0.541821\n",
      "epoch 28; iter: 0; batch classifier loss: 0.475881; batch adversarial loss: 0.583636\n",
      "epoch 29; iter: 0; batch classifier loss: 0.452453; batch adversarial loss: 0.492857\n",
      "epoch 30; iter: 0; batch classifier loss: 0.453550; batch adversarial loss: 0.579960\n",
      "epoch 31; iter: 0; batch classifier loss: 0.444782; batch adversarial loss: 0.560903\n",
      "epoch 32; iter: 0; batch classifier loss: 0.414318; batch adversarial loss: 0.574814\n",
      "epoch 33; iter: 0; batch classifier loss: 0.521964; batch adversarial loss: 0.546275\n",
      "epoch 34; iter: 0; batch classifier loss: 0.438479; batch adversarial loss: 0.534905\n",
      "epoch 35; iter: 0; batch classifier loss: 0.371249; batch adversarial loss: 0.575713\n",
      "epoch 36; iter: 0; batch classifier loss: 0.432278; batch adversarial loss: 0.496067\n",
      "epoch 37; iter: 0; batch classifier loss: 0.472967; batch adversarial loss: 0.492724\n",
      "epoch 38; iter: 0; batch classifier loss: 0.478684; batch adversarial loss: 0.572455\n",
      "epoch 39; iter: 0; batch classifier loss: 0.467400; batch adversarial loss: 0.527944\n",
      "epoch 40; iter: 0; batch classifier loss: 0.472323; batch adversarial loss: 0.529323\n",
      "epoch 41; iter: 0; batch classifier loss: 0.434252; batch adversarial loss: 0.509934\n",
      "epoch 42; iter: 0; batch classifier loss: 0.484480; batch adversarial loss: 0.553511\n",
      "epoch 43; iter: 0; batch classifier loss: 0.425106; batch adversarial loss: 0.500010\n",
      "epoch 44; iter: 0; batch classifier loss: 0.428481; batch adversarial loss: 0.517899\n",
      "epoch 45; iter: 0; batch classifier loss: 0.497662; batch adversarial loss: 0.571349\n",
      "epoch 46; iter: 0; batch classifier loss: 0.407500; batch adversarial loss: 0.517100\n",
      "epoch 47; iter: 0; batch classifier loss: 0.416831; batch adversarial loss: 0.535286\n",
      "epoch 48; iter: 0; batch classifier loss: 0.399397; batch adversarial loss: 0.562338\n",
      "epoch 49; iter: 0; batch classifier loss: 0.396327; batch adversarial loss: 0.497832\n",
      "epoch 50; iter: 0; batch classifier loss: 0.395305; batch adversarial loss: 0.573028\n",
      "epoch 51; iter: 0; batch classifier loss: 0.498876; batch adversarial loss: 0.574030\n",
      "epoch 52; iter: 0; batch classifier loss: 0.420726; batch adversarial loss: 0.543885\n",
      "epoch 53; iter: 0; batch classifier loss: 0.519868; batch adversarial loss: 0.703750\n",
      "epoch 54; iter: 0; batch classifier loss: 0.461237; batch adversarial loss: 0.553698\n",
      "epoch 55; iter: 0; batch classifier loss: 0.414825; batch adversarial loss: 0.572825\n",
      "epoch 56; iter: 0; batch classifier loss: 0.415245; batch adversarial loss: 0.460322\n",
      "epoch 57; iter: 0; batch classifier loss: 0.476121; batch adversarial loss: 0.583066\n",
      "epoch 58; iter: 0; batch classifier loss: 0.338497; batch adversarial loss: 0.581636\n",
      "epoch 59; iter: 0; batch classifier loss: 0.343499; batch adversarial loss: 0.505557\n",
      "epoch 60; iter: 0; batch classifier loss: 0.407378; batch adversarial loss: 0.562291\n",
      "epoch 61; iter: 0; batch classifier loss: 0.376894; batch adversarial loss: 0.534747\n",
      "epoch 62; iter: 0; batch classifier loss: 0.403741; batch adversarial loss: 0.610030\n",
      "epoch 63; iter: 0; batch classifier loss: 0.461975; batch adversarial loss: 0.524101\n",
      "epoch 64; iter: 0; batch classifier loss: 0.423395; batch adversarial loss: 0.582600\n",
      "epoch 65; iter: 0; batch classifier loss: 0.388716; batch adversarial loss: 0.525290\n",
      "epoch 66; iter: 0; batch classifier loss: 0.366898; batch adversarial loss: 0.516250\n",
      "epoch 67; iter: 0; batch classifier loss: 0.434930; batch adversarial loss: 0.543988\n",
      "epoch 68; iter: 0; batch classifier loss: 0.447821; batch adversarial loss: 0.496886\n",
      "epoch 69; iter: 0; batch classifier loss: 0.384841; batch adversarial loss: 0.536943\n",
      "epoch 70; iter: 0; batch classifier loss: 0.366359; batch adversarial loss: 0.460486\n",
      "epoch 71; iter: 0; batch classifier loss: 0.372549; batch adversarial loss: 0.532454\n",
      "epoch 72; iter: 0; batch classifier loss: 0.419761; batch adversarial loss: 0.477046\n",
      "epoch 73; iter: 0; batch classifier loss: 0.310533; batch adversarial loss: 0.488268\n",
      "epoch 74; iter: 0; batch classifier loss: 0.373526; batch adversarial loss: 0.512204\n",
      "epoch 75; iter: 0; batch classifier loss: 0.446046; batch adversarial loss: 0.508492\n",
      "epoch 76; iter: 0; batch classifier loss: 0.482661; batch adversarial loss: 0.535377\n",
      "epoch 77; iter: 0; batch classifier loss: 0.432780; batch adversarial loss: 0.544899\n",
      "epoch 78; iter: 0; batch classifier loss: 0.313287; batch adversarial loss: 0.543127\n",
      "epoch 79; iter: 0; batch classifier loss: 0.351882; batch adversarial loss: 0.532925\n",
      "epoch 80; iter: 0; batch classifier loss: 0.383313; batch adversarial loss: 0.523843\n",
      "epoch 81; iter: 0; batch classifier loss: 0.409016; batch adversarial loss: 0.516032\n",
      "epoch 82; iter: 0; batch classifier loss: 0.342121; batch adversarial loss: 0.546740\n",
      "epoch 83; iter: 0; batch classifier loss: 0.417083; batch adversarial loss: 0.602435\n",
      "epoch 84; iter: 0; batch classifier loss: 0.396347; batch adversarial loss: 0.575135\n",
      "epoch 85; iter: 0; batch classifier loss: 0.413967; batch adversarial loss: 0.534685\n",
      "epoch 86; iter: 0; batch classifier loss: 0.382982; batch adversarial loss: 0.574850\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 87; iter: 0; batch classifier loss: 0.396503; batch adversarial loss: 0.545256\n",
      "epoch 88; iter: 0; batch classifier loss: 0.443344; batch adversarial loss: 0.591082\n",
      "epoch 89; iter: 0; batch classifier loss: 0.434372; batch adversarial loss: 0.571014\n",
      "epoch 90; iter: 0; batch classifier loss: 0.426364; batch adversarial loss: 0.611468\n",
      "epoch 91; iter: 0; batch classifier loss: 0.350900; batch adversarial loss: 0.543660\n",
      "epoch 92; iter: 0; batch classifier loss: 0.370304; batch adversarial loss: 0.610924\n",
      "epoch 93; iter: 0; batch classifier loss: 0.472196; batch adversarial loss: 0.479560\n",
      "epoch 94; iter: 0; batch classifier loss: 0.411248; batch adversarial loss: 0.611040\n",
      "epoch 95; iter: 0; batch classifier loss: 0.435727; batch adversarial loss: 0.584438\n",
      "epoch 96; iter: 0; batch classifier loss: 0.373802; batch adversarial loss: 0.486667\n",
      "epoch 97; iter: 0; batch classifier loss: 0.421082; batch adversarial loss: 0.563184\n",
      "epoch 98; iter: 0; batch classifier loss: 0.349744; batch adversarial loss: 0.504539\n",
      "epoch 99; iter: 0; batch classifier loss: 0.299155; batch adversarial loss: 0.505137\n",
      "epoch 100; iter: 0; batch classifier loss: 0.391496; batch adversarial loss: 0.561620\n",
      "epoch 101; iter: 0; batch classifier loss: 0.412659; batch adversarial loss: 0.482021\n",
      "epoch 102; iter: 0; batch classifier loss: 0.363049; batch adversarial loss: 0.580612\n",
      "epoch 103; iter: 0; batch classifier loss: 0.357698; batch adversarial loss: 0.526300\n",
      "epoch 104; iter: 0; batch classifier loss: 0.419029; batch adversarial loss: 0.572387\n",
      "epoch 105; iter: 0; batch classifier loss: 0.384533; batch adversarial loss: 0.590538\n",
      "epoch 106; iter: 0; batch classifier loss: 0.366145; batch adversarial loss: 0.551510\n",
      "epoch 107; iter: 0; batch classifier loss: 0.429203; batch adversarial loss: 0.477744\n",
      "epoch 108; iter: 0; batch classifier loss: 0.438250; batch adversarial loss: 0.573921\n",
      "epoch 109; iter: 0; batch classifier loss: 0.386434; batch adversarial loss: 0.489132\n",
      "epoch 110; iter: 0; batch classifier loss: 0.457070; batch adversarial loss: 0.429367\n",
      "epoch 111; iter: 0; batch classifier loss: 0.418094; batch adversarial loss: 0.544722\n",
      "epoch 112; iter: 0; batch classifier loss: 0.359725; batch adversarial loss: 0.521624\n",
      "epoch 113; iter: 0; batch classifier loss: 0.366846; batch adversarial loss: 0.586967\n",
      "epoch 114; iter: 0; batch classifier loss: 0.355743; batch adversarial loss: 0.496129\n",
      "epoch 115; iter: 0; batch classifier loss: 0.390631; batch adversarial loss: 0.532493\n",
      "epoch 116; iter: 0; batch classifier loss: 0.436889; batch adversarial loss: 0.477477\n",
      "epoch 117; iter: 0; batch classifier loss: 0.413994; batch adversarial loss: 0.449679\n",
      "epoch 118; iter: 0; batch classifier loss: 0.378950; batch adversarial loss: 0.555575\n",
      "epoch 119; iter: 0; batch classifier loss: 0.425084; batch adversarial loss: 0.486669\n",
      "epoch 120; iter: 0; batch classifier loss: 0.349039; batch adversarial loss: 0.620705\n",
      "epoch 121; iter: 0; batch classifier loss: 0.346745; batch adversarial loss: 0.524275\n",
      "epoch 122; iter: 0; batch classifier loss: 0.371354; batch adversarial loss: 0.502516\n",
      "epoch 123; iter: 0; batch classifier loss: 0.307003; batch adversarial loss: 0.615082\n",
      "epoch 124; iter: 0; batch classifier loss: 0.340775; batch adversarial loss: 0.504412\n",
      "epoch 125; iter: 0; batch classifier loss: 0.393430; batch adversarial loss: 0.505542\n",
      "epoch 126; iter: 0; batch classifier loss: 0.396985; batch adversarial loss: 0.523791\n",
      "epoch 127; iter: 0; batch classifier loss: 0.338930; batch adversarial loss: 0.516865\n",
      "epoch 128; iter: 0; batch classifier loss: 0.303430; batch adversarial loss: 0.469318\n",
      "epoch 129; iter: 0; batch classifier loss: 0.359060; batch adversarial loss: 0.466234\n",
      "epoch 130; iter: 0; batch classifier loss: 0.312582; batch adversarial loss: 0.527909\n",
      "epoch 131; iter: 0; batch classifier loss: 0.335491; batch adversarial loss: 0.606625\n",
      "epoch 132; iter: 0; batch classifier loss: 0.364646; batch adversarial loss: 0.523576\n",
      "epoch 133; iter: 0; batch classifier loss: 0.365245; batch adversarial loss: 0.606901\n",
      "epoch 134; iter: 0; batch classifier loss: 0.386269; batch adversarial loss: 0.508606\n",
      "epoch 135; iter: 0; batch classifier loss: 0.348255; batch adversarial loss: 0.558643\n",
      "epoch 136; iter: 0; batch classifier loss: 0.414925; batch adversarial loss: 0.545137\n",
      "epoch 137; iter: 0; batch classifier loss: 0.404588; batch adversarial loss: 0.448487\n",
      "epoch 138; iter: 0; batch classifier loss: 0.281369; batch adversarial loss: 0.478968\n",
      "epoch 139; iter: 0; batch classifier loss: 0.435121; batch adversarial loss: 0.497869\n",
      "epoch 140; iter: 0; batch classifier loss: 0.374047; batch adversarial loss: 0.430929\n",
      "epoch 141; iter: 0; batch classifier loss: 0.411598; batch adversarial loss: 0.512642\n",
      "epoch 142; iter: 0; batch classifier loss: 0.330530; batch adversarial loss: 0.535909\n",
      "epoch 143; iter: 0; batch classifier loss: 0.370084; batch adversarial loss: 0.524632\n",
      "epoch 144; iter: 0; batch classifier loss: 0.409145; batch adversarial loss: 0.631014\n",
      "epoch 145; iter: 0; batch classifier loss: 0.421045; batch adversarial loss: 0.525954\n",
      "epoch 146; iter: 0; batch classifier loss: 0.392643; batch adversarial loss: 0.573121\n",
      "epoch 147; iter: 0; batch classifier loss: 0.380175; batch adversarial loss: 0.500958\n",
      "epoch 148; iter: 0; batch classifier loss: 0.378523; batch adversarial loss: 0.572988\n",
      "epoch 149; iter: 0; batch classifier loss: 0.293930; batch adversarial loss: 0.535148\n",
      "epoch 150; iter: 0; batch classifier loss: 0.305918; batch adversarial loss: 0.523690\n",
      "epoch 151; iter: 0; batch classifier loss: 0.375459; batch adversarial loss: 0.644688\n",
      "epoch 152; iter: 0; batch classifier loss: 0.336913; batch adversarial loss: 0.565269\n",
      "epoch 153; iter: 0; batch classifier loss: 0.304150; batch adversarial loss: 0.539261\n",
      "epoch 154; iter: 0; batch classifier loss: 0.423733; batch adversarial loss: 0.559884\n",
      "epoch 155; iter: 0; batch classifier loss: 0.324694; batch adversarial loss: 0.589313\n",
      "epoch 156; iter: 0; batch classifier loss: 0.333547; batch adversarial loss: 0.498491\n",
      "epoch 157; iter: 0; batch classifier loss: 0.307173; batch adversarial loss: 0.560799\n",
      "epoch 158; iter: 0; batch classifier loss: 0.367508; batch adversarial loss: 0.547878\n",
      "epoch 159; iter: 0; batch classifier loss: 0.322156; batch adversarial loss: 0.516168\n",
      "epoch 160; iter: 0; batch classifier loss: 0.384082; batch adversarial loss: 0.551849\n",
      "epoch 161; iter: 0; batch classifier loss: 0.424016; batch adversarial loss: 0.468347\n",
      "epoch 162; iter: 0; batch classifier loss: 0.351666; batch adversarial loss: 0.523642\n",
      "epoch 163; iter: 0; batch classifier loss: 0.420880; batch adversarial loss: 0.517960\n",
      "epoch 164; iter: 0; batch classifier loss: 0.380494; batch adversarial loss: 0.489210\n",
      "epoch 165; iter: 0; batch classifier loss: 0.346817; batch adversarial loss: 0.580976\n",
      "epoch 166; iter: 0; batch classifier loss: 0.355233; batch adversarial loss: 0.534302\n",
      "epoch 167; iter: 0; batch classifier loss: 0.409766; batch adversarial loss: 0.596318\n",
      "epoch 168; iter: 0; batch classifier loss: 0.331716; batch adversarial loss: 0.462680\n",
      "epoch 169; iter: 0; batch classifier loss: 0.280039; batch adversarial loss: 0.564137\n",
      "epoch 170; iter: 0; batch classifier loss: 0.310280; batch adversarial loss: 0.598012\n",
      "epoch 171; iter: 0; batch classifier loss: 0.317321; batch adversarial loss: 0.505243\n",
      "epoch 172; iter: 0; batch classifier loss: 0.426228; batch adversarial loss: 0.516473\n",
      "epoch 173; iter: 0; batch classifier loss: 0.308871; batch adversarial loss: 0.586301\n",
      "epoch 174; iter: 0; batch classifier loss: 0.268238; batch adversarial loss: 0.551016\n",
      "epoch 175; iter: 0; batch classifier loss: 0.389802; batch adversarial loss: 0.477724\n",
      "epoch 176; iter: 0; batch classifier loss: 0.330865; batch adversarial loss: 0.561718\n",
      "epoch 177; iter: 0; batch classifier loss: 0.284082; batch adversarial loss: 0.601457\n",
      "epoch 178; iter: 0; batch classifier loss: 0.433644; batch adversarial loss: 0.525070\n",
      "epoch 179; iter: 0; batch classifier loss: 0.337362; batch adversarial loss: 0.575235\n",
      "epoch 180; iter: 0; batch classifier loss: 0.424118; batch adversarial loss: 0.537941\n",
      "epoch 181; iter: 0; batch classifier loss: 0.380136; batch adversarial loss: 0.609752\n",
      "epoch 182; iter: 0; batch classifier loss: 0.340107; batch adversarial loss: 0.583916\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 183; iter: 0; batch classifier loss: 0.384409; batch adversarial loss: 0.575874\n",
      "epoch 184; iter: 0; batch classifier loss: 0.392802; batch adversarial loss: 0.621355\n",
      "epoch 185; iter: 0; batch classifier loss: 0.318178; batch adversarial loss: 0.547924\n",
      "epoch 186; iter: 0; batch classifier loss: 0.432689; batch adversarial loss: 0.529131\n",
      "epoch 187; iter: 0; batch classifier loss: 0.325820; batch adversarial loss: 0.553309\n",
      "epoch 188; iter: 0; batch classifier loss: 0.253984; batch adversarial loss: 0.541530\n",
      "epoch 189; iter: 0; batch classifier loss: 0.339875; batch adversarial loss: 0.535758\n",
      "epoch 190; iter: 0; batch classifier loss: 0.338367; batch adversarial loss: 0.571633\n",
      "epoch 191; iter: 0; batch classifier loss: 0.364526; batch adversarial loss: 0.544558\n",
      "epoch 192; iter: 0; batch classifier loss: 0.365608; batch adversarial loss: 0.479010\n",
      "epoch 193; iter: 0; batch classifier loss: 0.398505; batch adversarial loss: 0.551389\n",
      "epoch 194; iter: 0; batch classifier loss: 0.388576; batch adversarial loss: 0.469362\n",
      "epoch 195; iter: 0; batch classifier loss: 0.342145; batch adversarial loss: 0.560461\n",
      "epoch 196; iter: 0; batch classifier loss: 0.390114; batch adversarial loss: 0.562759\n",
      "epoch 197; iter: 0; batch classifier loss: 0.245877; batch adversarial loss: 0.517284\n",
      "epoch 198; iter: 0; batch classifier loss: 0.316888; batch adversarial loss: 0.487860\n",
      "epoch 199; iter: 0; batch classifier loss: 0.382566; batch adversarial loss: 0.567842\n",
      "epoch 0; iter: 0; batch classifier loss: 0.696702; batch adversarial loss: 0.881945\n",
      "epoch 1; iter: 0; batch classifier loss: 0.901205; batch adversarial loss: 1.146399\n",
      "epoch 2; iter: 0; batch classifier loss: 1.057184; batch adversarial loss: 1.145728\n",
      "epoch 3; iter: 0; batch classifier loss: 1.050544; batch adversarial loss: 1.077158\n",
      "epoch 4; iter: 0; batch classifier loss: 1.094666; batch adversarial loss: 1.004300\n",
      "epoch 5; iter: 0; batch classifier loss: 0.993321; batch adversarial loss: 0.869063\n",
      "epoch 6; iter: 0; batch classifier loss: 0.870383; batch adversarial loss: 0.790034\n",
      "epoch 7; iter: 0; batch classifier loss: 0.982438; batch adversarial loss: 0.764703\n",
      "epoch 8; iter: 0; batch classifier loss: 0.748044; batch adversarial loss: 0.694739\n",
      "epoch 9; iter: 0; batch classifier loss: 0.616715; batch adversarial loss: 0.646995\n",
      "epoch 10; iter: 0; batch classifier loss: 0.543511; batch adversarial loss: 0.669118\n",
      "epoch 11; iter: 0; batch classifier loss: 0.561040; batch adversarial loss: 0.636593\n",
      "epoch 12; iter: 0; batch classifier loss: 0.572957; batch adversarial loss: 0.650920\n",
      "epoch 13; iter: 0; batch classifier loss: 0.518219; batch adversarial loss: 0.563691\n",
      "epoch 14; iter: 0; batch classifier loss: 0.503576; batch adversarial loss: 0.535383\n",
      "epoch 15; iter: 0; batch classifier loss: 0.540875; batch adversarial loss: 0.611593\n",
      "epoch 16; iter: 0; batch classifier loss: 0.570088; batch adversarial loss: 0.590081\n",
      "epoch 17; iter: 0; batch classifier loss: 0.532330; batch adversarial loss: 0.611396\n",
      "epoch 18; iter: 0; batch classifier loss: 0.519935; batch adversarial loss: 0.568331\n",
      "epoch 19; iter: 0; batch classifier loss: 0.552193; batch adversarial loss: 0.541582\n",
      "epoch 20; iter: 0; batch classifier loss: 0.515710; batch adversarial loss: 0.624949\n",
      "epoch 21; iter: 0; batch classifier loss: 0.407437; batch adversarial loss: 0.515371\n",
      "epoch 22; iter: 0; batch classifier loss: 0.515169; batch adversarial loss: 0.539559\n",
      "epoch 23; iter: 0; batch classifier loss: 0.500875; batch adversarial loss: 0.519197\n",
      "epoch 24; iter: 0; batch classifier loss: 0.499833; batch adversarial loss: 0.584169\n",
      "epoch 25; iter: 0; batch classifier loss: 0.472095; batch adversarial loss: 0.583812\n",
      "epoch 26; iter: 0; batch classifier loss: 0.399564; batch adversarial loss: 0.550510\n",
      "epoch 27; iter: 0; batch classifier loss: 0.494851; batch adversarial loss: 0.598702\n",
      "epoch 28; iter: 0; batch classifier loss: 0.430110; batch adversarial loss: 0.550011\n",
      "epoch 29; iter: 0; batch classifier loss: 0.439798; batch adversarial loss: 0.552829\n",
      "epoch 30; iter: 0; batch classifier loss: 0.504727; batch adversarial loss: 0.495797\n",
      "epoch 31; iter: 0; batch classifier loss: 0.439615; batch adversarial loss: 0.547767\n",
      "epoch 32; iter: 0; batch classifier loss: 0.404075; batch adversarial loss: 0.613482\n",
      "epoch 33; iter: 0; batch classifier loss: 0.435648; batch adversarial loss: 0.599301\n",
      "epoch 34; iter: 0; batch classifier loss: 0.426661; batch adversarial loss: 0.576621\n",
      "epoch 35; iter: 0; batch classifier loss: 0.451106; batch adversarial loss: 0.633862\n",
      "epoch 36; iter: 0; batch classifier loss: 0.448433; batch adversarial loss: 0.548179\n",
      "epoch 37; iter: 0; batch classifier loss: 0.482554; batch adversarial loss: 0.611196\n",
      "epoch 38; iter: 0; batch classifier loss: 0.414970; batch adversarial loss: 0.570635\n",
      "epoch 39; iter: 0; batch classifier loss: 0.406643; batch adversarial loss: 0.518480\n",
      "epoch 40; iter: 0; batch classifier loss: 0.494471; batch adversarial loss: 0.543849\n",
      "epoch 41; iter: 0; batch classifier loss: 0.389498; batch adversarial loss: 0.584231\n",
      "epoch 42; iter: 0; batch classifier loss: 0.406968; batch adversarial loss: 0.531450\n",
      "epoch 43; iter: 0; batch classifier loss: 0.387796; batch adversarial loss: 0.564494\n",
      "epoch 44; iter: 0; batch classifier loss: 0.423026; batch adversarial loss: 0.576639\n",
      "epoch 45; iter: 0; batch classifier loss: 0.460652; batch adversarial loss: 0.565562\n",
      "epoch 46; iter: 0; batch classifier loss: 0.516602; batch adversarial loss: 0.579054\n",
      "epoch 47; iter: 0; batch classifier loss: 0.380443; batch adversarial loss: 0.551886\n",
      "epoch 48; iter: 0; batch classifier loss: 0.488895; batch adversarial loss: 0.519287\n",
      "epoch 49; iter: 0; batch classifier loss: 0.413725; batch adversarial loss: 0.573675\n",
      "epoch 50; iter: 0; batch classifier loss: 0.400792; batch adversarial loss: 0.573683\n",
      "epoch 51; iter: 0; batch classifier loss: 0.429261; batch adversarial loss: 0.545890\n",
      "epoch 52; iter: 0; batch classifier loss: 0.444940; batch adversarial loss: 0.561523\n",
      "epoch 53; iter: 0; batch classifier loss: 0.465037; batch adversarial loss: 0.518404\n",
      "epoch 54; iter: 0; batch classifier loss: 0.465801; batch adversarial loss: 0.552683\n",
      "epoch 55; iter: 0; batch classifier loss: 0.476373; batch adversarial loss: 0.595597\n",
      "epoch 56; iter: 0; batch classifier loss: 0.432442; batch adversarial loss: 0.497124\n",
      "epoch 57; iter: 0; batch classifier loss: 0.405787; batch adversarial loss: 0.549674\n",
      "epoch 58; iter: 0; batch classifier loss: 0.441993; batch adversarial loss: 0.567104\n",
      "epoch 59; iter: 0; batch classifier loss: 0.458626; batch adversarial loss: 0.615560\n",
      "epoch 60; iter: 0; batch classifier loss: 0.434467; batch adversarial loss: 0.601107\n",
      "epoch 61; iter: 0; batch classifier loss: 0.375760; batch adversarial loss: 0.563261\n",
      "epoch 62; iter: 0; batch classifier loss: 0.442770; batch adversarial loss: 0.535053\n",
      "epoch 63; iter: 0; batch classifier loss: 0.398949; batch adversarial loss: 0.561269\n",
      "epoch 64; iter: 0; batch classifier loss: 0.358155; batch adversarial loss: 0.583753\n",
      "epoch 65; iter: 0; batch classifier loss: 0.426041; batch adversarial loss: 0.518789\n",
      "epoch 66; iter: 0; batch classifier loss: 0.438641; batch adversarial loss: 0.534386\n",
      "epoch 67; iter: 0; batch classifier loss: 0.436619; batch adversarial loss: 0.617810\n",
      "epoch 68; iter: 0; batch classifier loss: 0.383327; batch adversarial loss: 0.513585\n",
      "epoch 69; iter: 0; batch classifier loss: 0.422011; batch adversarial loss: 0.569797\n",
      "epoch 70; iter: 0; batch classifier loss: 0.415911; batch adversarial loss: 0.578396\n",
      "epoch 71; iter: 0; batch classifier loss: 0.463017; batch adversarial loss: 0.585881\n",
      "epoch 72; iter: 0; batch classifier loss: 0.401944; batch adversarial loss: 0.545347\n",
      "epoch 73; iter: 0; batch classifier loss: 0.411759; batch adversarial loss: 0.525776\n",
      "epoch 74; iter: 0; batch classifier loss: 0.376740; batch adversarial loss: 0.526477\n",
      "epoch 75; iter: 0; batch classifier loss: 0.392517; batch adversarial loss: 0.572596\n",
      "epoch 76; iter: 0; batch classifier loss: 0.343512; batch adversarial loss: 0.564859\n",
      "epoch 77; iter: 0; batch classifier loss: 0.361773; batch adversarial loss: 0.582630\n",
      "epoch 78; iter: 0; batch classifier loss: 0.437777; batch adversarial loss: 0.596587\n",
      "epoch 79; iter: 0; batch classifier loss: 0.422713; batch adversarial loss: 0.560393\n",
      "epoch 80; iter: 0; batch classifier loss: 0.414761; batch adversarial loss: 0.481967\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 81; iter: 0; batch classifier loss: 0.356582; batch adversarial loss: 0.526262\n",
      "epoch 82; iter: 0; batch classifier loss: 0.431428; batch adversarial loss: 0.561355\n",
      "epoch 83; iter: 0; batch classifier loss: 0.429960; batch adversarial loss: 0.572706\n",
      "epoch 84; iter: 0; batch classifier loss: 0.406200; batch adversarial loss: 0.598957\n",
      "epoch 85; iter: 0; batch classifier loss: 0.358083; batch adversarial loss: 0.479558\n",
      "epoch 86; iter: 0; batch classifier loss: 0.337642; batch adversarial loss: 0.551320\n",
      "epoch 87; iter: 0; batch classifier loss: 0.334416; batch adversarial loss: 0.615378\n",
      "epoch 88; iter: 0; batch classifier loss: 0.334666; batch adversarial loss: 0.581021\n",
      "epoch 89; iter: 0; batch classifier loss: 0.315303; batch adversarial loss: 0.514926\n",
      "epoch 90; iter: 0; batch classifier loss: 0.386484; batch adversarial loss: 0.534726\n",
      "epoch 91; iter: 0; batch classifier loss: 0.340361; batch adversarial loss: 0.558948\n",
      "epoch 92; iter: 0; batch classifier loss: 0.398038; batch adversarial loss: 0.493212\n",
      "epoch 93; iter: 0; batch classifier loss: 0.332212; batch adversarial loss: 0.569142\n",
      "epoch 94; iter: 0; batch classifier loss: 0.404170; batch adversarial loss: 0.510840\n",
      "epoch 95; iter: 0; batch classifier loss: 0.344593; batch adversarial loss: 0.570462\n",
      "epoch 96; iter: 0; batch classifier loss: 0.302783; batch adversarial loss: 0.632163\n",
      "epoch 97; iter: 0; batch classifier loss: 0.418913; batch adversarial loss: 0.543398\n",
      "epoch 98; iter: 0; batch classifier loss: 0.391709; batch adversarial loss: 0.473621\n",
      "epoch 99; iter: 0; batch classifier loss: 0.362556; batch adversarial loss: 0.546920\n",
      "epoch 100; iter: 0; batch classifier loss: 0.347740; batch adversarial loss: 0.544685\n",
      "epoch 101; iter: 0; batch classifier loss: 0.414138; batch adversarial loss: 0.518383\n",
      "epoch 102; iter: 0; batch classifier loss: 0.416941; batch adversarial loss: 0.552533\n",
      "epoch 103; iter: 0; batch classifier loss: 0.369577; batch adversarial loss: 0.519072\n",
      "epoch 104; iter: 0; batch classifier loss: 0.385433; batch adversarial loss: 0.579969\n",
      "epoch 105; iter: 0; batch classifier loss: 0.329120; batch adversarial loss: 0.492539\n",
      "epoch 106; iter: 0; batch classifier loss: 0.307076; batch adversarial loss: 0.483347\n",
      "epoch 107; iter: 0; batch classifier loss: 0.379038; batch adversarial loss: 0.580074\n",
      "epoch 108; iter: 0; batch classifier loss: 0.329811; batch adversarial loss: 0.544961\n",
      "epoch 109; iter: 0; batch classifier loss: 0.396106; batch adversarial loss: 0.624670\n",
      "epoch 110; iter: 0; batch classifier loss: 0.336616; batch adversarial loss: 0.580092\n",
      "epoch 111; iter: 0; batch classifier loss: 0.314700; batch adversarial loss: 0.562507\n",
      "epoch 112; iter: 0; batch classifier loss: 0.364495; batch adversarial loss: 0.598316\n",
      "epoch 113; iter: 0; batch classifier loss: 0.291969; batch adversarial loss: 0.455420\n",
      "epoch 114; iter: 0; batch classifier loss: 0.317347; batch adversarial loss: 0.571458\n",
      "epoch 115; iter: 0; batch classifier loss: 0.304756; batch adversarial loss: 0.526650\n",
      "epoch 116; iter: 0; batch classifier loss: 0.331381; batch adversarial loss: 0.491318\n",
      "epoch 117; iter: 0; batch classifier loss: 0.386193; batch adversarial loss: 0.553682\n",
      "epoch 118; iter: 0; batch classifier loss: 0.345416; batch adversarial loss: 0.499812\n",
      "epoch 119; iter: 0; batch classifier loss: 0.383798; batch adversarial loss: 0.651668\n",
      "epoch 120; iter: 0; batch classifier loss: 0.380096; batch adversarial loss: 0.472973\n",
      "epoch 121; iter: 0; batch classifier loss: 0.302452; batch adversarial loss: 0.562896\n",
      "epoch 122; iter: 0; batch classifier loss: 0.414332; batch adversarial loss: 0.499727\n",
      "epoch 123; iter: 0; batch classifier loss: 0.334538; batch adversarial loss: 0.571548\n",
      "epoch 124; iter: 0; batch classifier loss: 0.378858; batch adversarial loss: 0.535751\n",
      "epoch 125; iter: 0; batch classifier loss: 0.305364; batch adversarial loss: 0.508601\n",
      "epoch 126; iter: 0; batch classifier loss: 0.315562; batch adversarial loss: 0.526659\n",
      "epoch 127; iter: 0; batch classifier loss: 0.350206; batch adversarial loss: 0.508578\n",
      "epoch 128; iter: 0; batch classifier loss: 0.469642; batch adversarial loss: 0.553975\n",
      "epoch 129; iter: 0; batch classifier loss: 0.283919; batch adversarial loss: 0.571332\n",
      "epoch 130; iter: 0; batch classifier loss: 0.408091; batch adversarial loss: 0.580405\n",
      "epoch 131; iter: 0; batch classifier loss: 0.363251; batch adversarial loss: 0.679345\n",
      "epoch 132; iter: 0; batch classifier loss: 0.327451; batch adversarial loss: 0.580411\n",
      "epoch 133; iter: 0; batch classifier loss: 0.399175; batch adversarial loss: 0.544578\n",
      "epoch 134; iter: 0; batch classifier loss: 0.347328; batch adversarial loss: 0.544640\n",
      "epoch 135; iter: 0; batch classifier loss: 0.417943; batch adversarial loss: 0.562528\n",
      "epoch 136; iter: 0; batch classifier loss: 0.320594; batch adversarial loss: 0.517521\n",
      "epoch 137; iter: 0; batch classifier loss: 0.327451; batch adversarial loss: 0.481646\n",
      "epoch 138; iter: 0; batch classifier loss: 0.337321; batch adversarial loss: 0.508853\n",
      "epoch 139; iter: 0; batch classifier loss: 0.320491; batch adversarial loss: 0.544286\n",
      "epoch 140; iter: 0; batch classifier loss: 0.260172; batch adversarial loss: 0.481773\n",
      "epoch 141; iter: 0; batch classifier loss: 0.330844; batch adversarial loss: 0.517094\n",
      "epoch 142; iter: 0; batch classifier loss: 0.428291; batch adversarial loss: 0.517352\n",
      "epoch 143; iter: 0; batch classifier loss: 0.330169; batch adversarial loss: 0.525159\n",
      "epoch 144; iter: 0; batch classifier loss: 0.289346; batch adversarial loss: 0.535196\n",
      "epoch 145; iter: 0; batch classifier loss: 0.440334; batch adversarial loss: 0.542497\n",
      "epoch 146; iter: 0; batch classifier loss: 0.338096; batch adversarial loss: 0.608221\n",
      "epoch 147; iter: 0; batch classifier loss: 0.326114; batch adversarial loss: 0.589027\n",
      "epoch 148; iter: 0; batch classifier loss: 0.391961; batch adversarial loss: 0.634641\n",
      "epoch 149; iter: 0; batch classifier loss: 0.436700; batch adversarial loss: 0.473798\n",
      "epoch 150; iter: 0; batch classifier loss: 0.378015; batch adversarial loss: 0.598107\n",
      "epoch 151; iter: 0; batch classifier loss: 0.322939; batch adversarial loss: 0.465010\n",
      "epoch 152; iter: 0; batch classifier loss: 0.364232; batch adversarial loss: 0.500175\n",
      "epoch 153; iter: 0; batch classifier loss: 0.372642; batch adversarial loss: 0.499794\n",
      "epoch 154; iter: 0; batch classifier loss: 0.426977; batch adversarial loss: 0.508889\n",
      "epoch 155; iter: 0; batch classifier loss: 0.412197; batch adversarial loss: 0.598776\n",
      "epoch 156; iter: 0; batch classifier loss: 0.356800; batch adversarial loss: 0.544390\n",
      "epoch 157; iter: 0; batch classifier loss: 0.405524; batch adversarial loss: 0.589538\n",
      "epoch 158; iter: 0; batch classifier loss: 0.315569; batch adversarial loss: 0.508820\n",
      "epoch 159; iter: 0; batch classifier loss: 0.329847; batch adversarial loss: 0.588528\n",
      "epoch 160; iter: 0; batch classifier loss: 0.399621; batch adversarial loss: 0.526327\n",
      "epoch 161; iter: 0; batch classifier loss: 0.373086; batch adversarial loss: 0.563402\n",
      "epoch 162; iter: 0; batch classifier loss: 0.307524; batch adversarial loss: 0.534377\n",
      "epoch 163; iter: 0; batch classifier loss: 0.343895; batch adversarial loss: 0.491190\n",
      "epoch 164; iter: 0; batch classifier loss: 0.315950; batch adversarial loss: 0.553303\n",
      "epoch 165; iter: 0; batch classifier loss: 0.436914; batch adversarial loss: 0.615396\n",
      "epoch 166; iter: 0; batch classifier loss: 0.445923; batch adversarial loss: 0.553840\n",
      "epoch 167; iter: 0; batch classifier loss: 0.305183; batch adversarial loss: 0.607158\n",
      "epoch 168; iter: 0; batch classifier loss: 0.299905; batch adversarial loss: 0.633322\n",
      "epoch 169; iter: 0; batch classifier loss: 0.343240; batch adversarial loss: 0.589285\n",
      "epoch 170; iter: 0; batch classifier loss: 0.375989; batch adversarial loss: 0.464834\n",
      "epoch 171; iter: 0; batch classifier loss: 0.350108; batch adversarial loss: 0.509279\n",
      "epoch 172; iter: 0; batch classifier loss: 0.371440; batch adversarial loss: 0.553520\n",
      "epoch 173; iter: 0; batch classifier loss: 0.327157; batch adversarial loss: 0.491001\n",
      "epoch 174; iter: 0; batch classifier loss: 0.448132; batch adversarial loss: 0.580745\n",
      "epoch 175; iter: 0; batch classifier loss: 0.293694; batch adversarial loss: 0.553553\n",
      "epoch 176; iter: 0; batch classifier loss: 0.426229; batch adversarial loss: 0.491002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 177; iter: 0; batch classifier loss: 0.309691; batch adversarial loss: 0.571743\n",
      "epoch 178; iter: 0; batch classifier loss: 0.366972; batch adversarial loss: 0.615758\n",
      "epoch 179; iter: 0; batch classifier loss: 0.279582; batch adversarial loss: 0.607106\n",
      "epoch 180; iter: 0; batch classifier loss: 0.349357; batch adversarial loss: 0.535827\n",
      "epoch 181; iter: 0; batch classifier loss: 0.287144; batch adversarial loss: 0.553721\n",
      "epoch 182; iter: 0; batch classifier loss: 0.403016; batch adversarial loss: 0.615401\n",
      "epoch 183; iter: 0; batch classifier loss: 0.278908; batch adversarial loss: 0.642118\n",
      "epoch 184; iter: 0; batch classifier loss: 0.373019; batch adversarial loss: 0.642988\n",
      "epoch 185; iter: 0; batch classifier loss: 0.315591; batch adversarial loss: 0.536504\n",
      "epoch 186; iter: 0; batch classifier loss: 0.354730; batch adversarial loss: 0.562973\n",
      "epoch 187; iter: 0; batch classifier loss: 0.302863; batch adversarial loss: 0.562167\n",
      "epoch 188; iter: 0; batch classifier loss: 0.317992; batch adversarial loss: 0.563212\n",
      "epoch 189; iter: 0; batch classifier loss: 0.287656; batch adversarial loss: 0.589367\n",
      "epoch 190; iter: 0; batch classifier loss: 0.383060; batch adversarial loss: 0.571552\n",
      "epoch 191; iter: 0; batch classifier loss: 0.266085; batch adversarial loss: 0.490736\n",
      "epoch 192; iter: 0; batch classifier loss: 0.342551; batch adversarial loss: 0.562702\n",
      "epoch 193; iter: 0; batch classifier loss: 0.248490; batch adversarial loss: 0.579832\n",
      "epoch 194; iter: 0; batch classifier loss: 0.372484; batch adversarial loss: 0.535623\n",
      "epoch 195; iter: 0; batch classifier loss: 0.347662; batch adversarial loss: 0.543908\n",
      "epoch 196; iter: 0; batch classifier loss: 0.346064; batch adversarial loss: 0.580933\n",
      "epoch 197; iter: 0; batch classifier loss: 0.357526; batch adversarial loss: 0.517309\n",
      "epoch 198; iter: 0; batch classifier loss: 0.253382; batch adversarial loss: 0.518343\n",
      "epoch 199; iter: 0; batch classifier loss: 0.269997; batch adversarial loss: 0.526975\n",
      "epoch 0; iter: 0; batch classifier loss: 0.682292; batch adversarial loss: 0.630370\n",
      "epoch 1; iter: 0; batch classifier loss: 0.512564; batch adversarial loss: 0.653745\n",
      "epoch 2; iter: 0; batch classifier loss: 0.580447; batch adversarial loss: 0.671657\n",
      "epoch 3; iter: 0; batch classifier loss: 0.606698; batch adversarial loss: 0.682095\n",
      "epoch 4; iter: 0; batch classifier loss: 0.571404; batch adversarial loss: 0.640998\n",
      "epoch 5; iter: 0; batch classifier loss: 0.625199; batch adversarial loss: 0.709877\n",
      "epoch 6; iter: 0; batch classifier loss: 0.591868; batch adversarial loss: 0.668463\n",
      "epoch 7; iter: 0; batch classifier loss: 0.556909; batch adversarial loss: 0.646294\n",
      "epoch 8; iter: 0; batch classifier loss: 0.496029; batch adversarial loss: 0.654649\n",
      "epoch 9; iter: 0; batch classifier loss: 0.476346; batch adversarial loss: 0.667064\n",
      "epoch 10; iter: 0; batch classifier loss: 0.588201; batch adversarial loss: 0.637710\n",
      "epoch 11; iter: 0; batch classifier loss: 0.553950; batch adversarial loss: 0.595778\n",
      "epoch 12; iter: 0; batch classifier loss: 0.518965; batch adversarial loss: 0.617908\n",
      "epoch 13; iter: 0; batch classifier loss: 0.468669; batch adversarial loss: 0.598324\n",
      "epoch 14; iter: 0; batch classifier loss: 0.513725; batch adversarial loss: 0.611351\n",
      "epoch 15; iter: 0; batch classifier loss: 0.489440; batch adversarial loss: 0.542666\n",
      "epoch 16; iter: 0; batch classifier loss: 0.532026; batch adversarial loss: 0.590926\n",
      "epoch 17; iter: 0; batch classifier loss: 0.443672; batch adversarial loss: 0.566958\n",
      "epoch 18; iter: 0; batch classifier loss: 0.493150; batch adversarial loss: 0.621468\n",
      "epoch 19; iter: 0; batch classifier loss: 0.503698; batch adversarial loss: 0.551533\n",
      "epoch 20; iter: 0; batch classifier loss: 0.494659; batch adversarial loss: 0.571161\n",
      "epoch 21; iter: 0; batch classifier loss: 0.511684; batch adversarial loss: 0.580065\n",
      "epoch 22; iter: 0; batch classifier loss: 0.503556; batch adversarial loss: 0.495277\n",
      "epoch 23; iter: 0; batch classifier loss: 0.451526; batch adversarial loss: 0.542052\n",
      "epoch 24; iter: 0; batch classifier loss: 0.497318; batch adversarial loss: 0.537022\n",
      "epoch 25; iter: 0; batch classifier loss: 0.489362; batch adversarial loss: 0.601119\n",
      "epoch 26; iter: 0; batch classifier loss: 0.381198; batch adversarial loss: 0.547850\n",
      "epoch 27; iter: 0; batch classifier loss: 0.501963; batch adversarial loss: 0.625658\n",
      "epoch 28; iter: 0; batch classifier loss: 0.407304; batch adversarial loss: 0.587579\n",
      "epoch 29; iter: 0; batch classifier loss: 0.408158; batch adversarial loss: 0.587402\n",
      "epoch 30; iter: 0; batch classifier loss: 0.404465; batch adversarial loss: 0.609164\n",
      "epoch 31; iter: 0; batch classifier loss: 0.454654; batch adversarial loss: 0.575605\n",
      "epoch 32; iter: 0; batch classifier loss: 0.549585; batch adversarial loss: 0.640534\n",
      "epoch 33; iter: 0; batch classifier loss: 0.486962; batch adversarial loss: 0.517059\n",
      "epoch 34; iter: 0; batch classifier loss: 0.510390; batch adversarial loss: 0.642359\n",
      "epoch 35; iter: 0; batch classifier loss: 0.396053; batch adversarial loss: 0.544220\n",
      "epoch 36; iter: 0; batch classifier loss: 0.435444; batch adversarial loss: 0.588932\n",
      "epoch 37; iter: 0; batch classifier loss: 0.388162; batch adversarial loss: 0.535918\n",
      "epoch 38; iter: 0; batch classifier loss: 0.375157; batch adversarial loss: 0.553782\n",
      "epoch 39; iter: 0; batch classifier loss: 0.453850; batch adversarial loss: 0.571328\n",
      "epoch 40; iter: 0; batch classifier loss: 0.394727; batch adversarial loss: 0.526322\n",
      "epoch 41; iter: 0; batch classifier loss: 0.481280; batch adversarial loss: 0.508762\n",
      "epoch 42; iter: 0; batch classifier loss: 0.451991; batch adversarial loss: 0.526618\n",
      "epoch 43; iter: 0; batch classifier loss: 0.403248; batch adversarial loss: 0.589858\n",
      "epoch 44; iter: 0; batch classifier loss: 0.476177; batch adversarial loss: 0.527054\n",
      "epoch 45; iter: 0; batch classifier loss: 0.416636; batch adversarial loss: 0.526527\n",
      "epoch 46; iter: 0; batch classifier loss: 0.391701; batch adversarial loss: 0.562995\n",
      "epoch 47; iter: 0; batch classifier loss: 0.446070; batch adversarial loss: 0.480395\n",
      "epoch 48; iter: 0; batch classifier loss: 0.411282; batch adversarial loss: 0.598942\n",
      "epoch 49; iter: 0; batch classifier loss: 0.424348; batch adversarial loss: 0.644741\n",
      "epoch 50; iter: 0; batch classifier loss: 0.371677; batch adversarial loss: 0.572070\n",
      "epoch 51; iter: 0; batch classifier loss: 0.441810; batch adversarial loss: 0.590125\n",
      "epoch 52; iter: 0; batch classifier loss: 0.359010; batch adversarial loss: 0.499563\n",
      "epoch 53; iter: 0; batch classifier loss: 0.323164; batch adversarial loss: 0.571625\n",
      "epoch 54; iter: 0; batch classifier loss: 0.447788; batch adversarial loss: 0.499822\n",
      "epoch 55; iter: 0; batch classifier loss: 0.384484; batch adversarial loss: 0.499635\n",
      "epoch 56; iter: 0; batch classifier loss: 0.435543; batch adversarial loss: 0.490656\n",
      "epoch 57; iter: 0; batch classifier loss: 0.395293; batch adversarial loss: 0.608262\n",
      "epoch 58; iter: 0; batch classifier loss: 0.429927; batch adversarial loss: 0.544517\n",
      "epoch 59; iter: 0; batch classifier loss: 0.388716; batch adversarial loss: 0.544575\n",
      "epoch 60; iter: 0; batch classifier loss: 0.317511; batch adversarial loss: 0.517170\n",
      "epoch 61; iter: 0; batch classifier loss: 0.435216; batch adversarial loss: 0.580916\n",
      "epoch 62; iter: 0; batch classifier loss: 0.409374; batch adversarial loss: 0.563212\n",
      "epoch 63; iter: 0; batch classifier loss: 0.329822; batch adversarial loss: 0.572276\n",
      "epoch 64; iter: 0; batch classifier loss: 0.434338; batch adversarial loss: 0.581391\n",
      "epoch 65; iter: 0; batch classifier loss: 0.415549; batch adversarial loss: 0.544395\n",
      "epoch 66; iter: 0; batch classifier loss: 0.419774; batch adversarial loss: 0.563117\n",
      "epoch 67; iter: 0; batch classifier loss: 0.340836; batch adversarial loss: 0.591948\n",
      "epoch 68; iter: 0; batch classifier loss: 0.419863; batch adversarial loss: 0.496582\n",
      "epoch 69; iter: 0; batch classifier loss: 0.387986; batch adversarial loss: 0.570210\n",
      "epoch 70; iter: 0; batch classifier loss: 0.461446; batch adversarial loss: 0.556865\n",
      "epoch 71; iter: 0; batch classifier loss: 0.355387; batch adversarial loss: 0.524324\n",
      "epoch 72; iter: 0; batch classifier loss: 0.419820; batch adversarial loss: 0.502232\n",
      "epoch 73; iter: 0; batch classifier loss: 0.330961; batch adversarial loss: 0.491054\n",
      "epoch 74; iter: 0; batch classifier loss: 0.316463; batch adversarial loss: 0.530223\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 75; iter: 0; batch classifier loss: 0.374809; batch adversarial loss: 0.553402\n",
      "epoch 76; iter: 0; batch classifier loss: 0.390152; batch adversarial loss: 0.608748\n",
      "epoch 77; iter: 0; batch classifier loss: 0.421716; batch adversarial loss: 0.643946\n",
      "epoch 78; iter: 0; batch classifier loss: 0.414776; batch adversarial loss: 0.535596\n",
      "epoch 79; iter: 0; batch classifier loss: 0.359148; batch adversarial loss: 0.580425\n",
      "epoch 80; iter: 0; batch classifier loss: 0.395306; batch adversarial loss: 0.394368\n",
      "epoch 81; iter: 0; batch classifier loss: 0.447957; batch adversarial loss: 0.633815\n",
      "epoch 82; iter: 0; batch classifier loss: 0.308292; batch adversarial loss: 0.526820\n",
      "epoch 83; iter: 0; batch classifier loss: 0.392921; batch adversarial loss: 0.481752\n",
      "epoch 84; iter: 0; batch classifier loss: 0.416564; batch adversarial loss: 0.553508\n",
      "epoch 85; iter: 0; batch classifier loss: 0.377068; batch adversarial loss: 0.527753\n",
      "epoch 86; iter: 0; batch classifier loss: 0.377558; batch adversarial loss: 0.571667\n",
      "epoch 87; iter: 0; batch classifier loss: 0.420740; batch adversarial loss: 0.545106\n",
      "epoch 88; iter: 0; batch classifier loss: 0.343783; batch adversarial loss: 0.562633\n",
      "epoch 89; iter: 0; batch classifier loss: 0.363167; batch adversarial loss: 0.562742\n",
      "epoch 90; iter: 0; batch classifier loss: 0.370618; batch adversarial loss: 0.570133\n",
      "epoch 91; iter: 0; batch classifier loss: 0.334098; batch adversarial loss: 0.534793\n",
      "epoch 92; iter: 0; batch classifier loss: 0.450222; batch adversarial loss: 0.507965\n",
      "epoch 93; iter: 0; batch classifier loss: 0.340190; batch adversarial loss: 0.507866\n",
      "epoch 94; iter: 0; batch classifier loss: 0.345709; batch adversarial loss: 0.581546\n",
      "epoch 95; iter: 0; batch classifier loss: 0.348931; batch adversarial loss: 0.487719\n",
      "epoch 96; iter: 0; batch classifier loss: 0.326336; batch adversarial loss: 0.525983\n",
      "epoch 97; iter: 0; batch classifier loss: 0.416546; batch adversarial loss: 0.524988\n",
      "epoch 98; iter: 0; batch classifier loss: 0.365407; batch adversarial loss: 0.525160\n",
      "epoch 99; iter: 0; batch classifier loss: 0.378945; batch adversarial loss: 0.559198\n",
      "epoch 100; iter: 0; batch classifier loss: 0.376624; batch adversarial loss: 0.478948\n",
      "epoch 101; iter: 0; batch classifier loss: 0.396568; batch adversarial loss: 0.628818\n",
      "epoch 102; iter: 0; batch classifier loss: 0.393627; batch adversarial loss: 0.515275\n",
      "epoch 103; iter: 0; batch classifier loss: 0.374022; batch adversarial loss: 0.544279\n",
      "epoch 104; iter: 0; batch classifier loss: 0.361566; batch adversarial loss: 0.506728\n",
      "epoch 105; iter: 0; batch classifier loss: 0.416971; batch adversarial loss: 0.537836\n",
      "epoch 106; iter: 0; batch classifier loss: 0.394383; batch adversarial loss: 0.588839\n",
      "epoch 107; iter: 0; batch classifier loss: 0.384333; batch adversarial loss: 0.600324\n",
      "epoch 108; iter: 0; batch classifier loss: 0.383327; batch adversarial loss: 0.597884\n",
      "epoch 109; iter: 0; batch classifier loss: 0.394645; batch adversarial loss: 0.572149\n",
      "epoch 110; iter: 0; batch classifier loss: 0.371448; batch adversarial loss: 0.525316\n",
      "epoch 111; iter: 0; batch classifier loss: 0.464646; batch adversarial loss: 0.510804\n",
      "epoch 112; iter: 0; batch classifier loss: 0.314309; batch adversarial loss: 0.590422\n",
      "epoch 113; iter: 0; batch classifier loss: 0.367963; batch adversarial loss: 0.579908\n",
      "epoch 114; iter: 0; batch classifier loss: 0.331588; batch adversarial loss: 0.591044\n",
      "epoch 115; iter: 0; batch classifier loss: 0.337456; batch adversarial loss: 0.465498\n",
      "epoch 116; iter: 0; batch classifier loss: 0.400090; batch adversarial loss: 0.641852\n",
      "epoch 117; iter: 0; batch classifier loss: 0.406540; batch adversarial loss: 0.608040\n",
      "epoch 118; iter: 0; batch classifier loss: 0.370142; batch adversarial loss: 0.561509\n",
      "epoch 119; iter: 0; batch classifier loss: 0.383909; batch adversarial loss: 0.543445\n",
      "epoch 120; iter: 0; batch classifier loss: 0.377739; batch adversarial loss: 0.490228\n",
      "epoch 121; iter: 0; batch classifier loss: 0.301471; batch adversarial loss: 0.527133\n",
      "epoch 122; iter: 0; batch classifier loss: 0.353754; batch adversarial loss: 0.517388\n",
      "epoch 123; iter: 0; batch classifier loss: 0.405424; batch adversarial loss: 0.581088\n",
      "epoch 124; iter: 0; batch classifier loss: 0.305795; batch adversarial loss: 0.589074\n",
      "epoch 125; iter: 0; batch classifier loss: 0.398468; batch adversarial loss: 0.553958\n",
      "epoch 126; iter: 0; batch classifier loss: 0.327504; batch adversarial loss: 0.563665\n",
      "epoch 127; iter: 0; batch classifier loss: 0.446648; batch adversarial loss: 0.508157\n",
      "epoch 128; iter: 0; batch classifier loss: 0.320310; batch adversarial loss: 0.598322\n",
      "epoch 129; iter: 0; batch classifier loss: 0.358584; batch adversarial loss: 0.572164\n",
      "epoch 130; iter: 0; batch classifier loss: 0.385095; batch adversarial loss: 0.580912\n",
      "epoch 131; iter: 0; batch classifier loss: 0.324419; batch adversarial loss: 0.490597\n",
      "epoch 132; iter: 0; batch classifier loss: 0.307205; batch adversarial loss: 0.499824\n",
      "epoch 133; iter: 0; batch classifier loss: 0.348500; batch adversarial loss: 0.499659\n",
      "epoch 134; iter: 0; batch classifier loss: 0.359093; batch adversarial loss: 0.634737\n",
      "epoch 135; iter: 0; batch classifier loss: 0.338861; batch adversarial loss: 0.608091\n",
      "epoch 136; iter: 0; batch classifier loss: 0.364648; batch adversarial loss: 0.571638\n",
      "epoch 137; iter: 0; batch classifier loss: 0.332296; batch adversarial loss: 0.617046\n",
      "epoch 138; iter: 0; batch classifier loss: 0.340892; batch adversarial loss: 0.508179\n",
      "epoch 139; iter: 0; batch classifier loss: 0.357102; batch adversarial loss: 0.526661\n",
      "epoch 140; iter: 0; batch classifier loss: 0.373415; batch adversarial loss: 0.462709\n",
      "epoch 141; iter: 0; batch classifier loss: 0.389550; batch adversarial loss: 0.536354\n",
      "epoch 142; iter: 0; batch classifier loss: 0.432694; batch adversarial loss: 0.490296\n",
      "epoch 143; iter: 0; batch classifier loss: 0.366765; batch adversarial loss: 0.598198\n",
      "epoch 144; iter: 0; batch classifier loss: 0.292621; batch adversarial loss: 0.545920\n",
      "epoch 145; iter: 0; batch classifier loss: 0.318523; batch adversarial loss: 0.597741\n",
      "epoch 146; iter: 0; batch classifier loss: 0.397332; batch adversarial loss: 0.554961\n",
      "epoch 147; iter: 0; batch classifier loss: 0.437619; batch adversarial loss: 0.571295\n",
      "epoch 148; iter: 0; batch classifier loss: 0.444896; batch adversarial loss: 0.581018\n",
      "epoch 149; iter: 0; batch classifier loss: 0.378631; batch adversarial loss: 0.610594\n",
      "epoch 150; iter: 0; batch classifier loss: 0.426411; batch adversarial loss: 0.617739\n",
      "epoch 151; iter: 0; batch classifier loss: 0.416349; batch adversarial loss: 0.700022\n",
      "epoch 152; iter: 0; batch classifier loss: 0.250239; batch adversarial loss: 0.609384\n",
      "epoch 153; iter: 0; batch classifier loss: 0.303593; batch adversarial loss: 0.517069\n",
      "epoch 154; iter: 0; batch classifier loss: 0.408195; batch adversarial loss: 0.553378\n",
      "epoch 155; iter: 0; batch classifier loss: 0.351893; batch adversarial loss: 0.544606\n",
      "epoch 156; iter: 0; batch classifier loss: 0.414108; batch adversarial loss: 0.489645\n",
      "epoch 157; iter: 0; batch classifier loss: 0.349944; batch adversarial loss: 0.599396\n",
      "epoch 158; iter: 0; batch classifier loss: 0.418798; batch adversarial loss: 0.562487\n",
      "epoch 159; iter: 0; batch classifier loss: 0.385610; batch adversarial loss: 0.572219\n",
      "epoch 160; iter: 0; batch classifier loss: 0.302587; batch adversarial loss: 0.626817\n",
      "epoch 161; iter: 0; batch classifier loss: 0.332048; batch adversarial loss: 0.589853\n",
      "epoch 162; iter: 0; batch classifier loss: 0.378321; batch adversarial loss: 0.553483\n",
      "epoch 163; iter: 0; batch classifier loss: 0.295821; batch adversarial loss: 0.526642\n",
      "epoch 164; iter: 0; batch classifier loss: 0.342477; batch adversarial loss: 0.498229\n",
      "epoch 165; iter: 0; batch classifier loss: 0.369807; batch adversarial loss: 0.608006\n",
      "epoch 166; iter: 0; batch classifier loss: 0.465157; batch adversarial loss: 0.580558\n",
      "epoch 167; iter: 0; batch classifier loss: 0.310580; batch adversarial loss: 0.535178\n",
      "epoch 168; iter: 0; batch classifier loss: 0.343718; batch adversarial loss: 0.598078\n",
      "epoch 169; iter: 0; batch classifier loss: 0.408571; batch adversarial loss: 0.590308\n",
      "epoch 170; iter: 0; batch classifier loss: 0.373479; batch adversarial loss: 0.490283\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 171; iter: 0; batch classifier loss: 0.317922; batch adversarial loss: 0.589407\n",
      "epoch 172; iter: 0; batch classifier loss: 0.377098; batch adversarial loss: 0.544865\n",
      "epoch 173; iter: 0; batch classifier loss: 0.367596; batch adversarial loss: 0.580238\n",
      "epoch 174; iter: 0; batch classifier loss: 0.294491; batch adversarial loss: 0.563515\n",
      "epoch 175; iter: 0; batch classifier loss: 0.360157; batch adversarial loss: 0.519025\n",
      "epoch 176; iter: 0; batch classifier loss: 0.486038; batch adversarial loss: 0.589619\n",
      "epoch 177; iter: 0; batch classifier loss: 0.305368; batch adversarial loss: 0.488719\n",
      "epoch 178; iter: 0; batch classifier loss: 0.362826; batch adversarial loss: 0.580558\n",
      "epoch 179; iter: 0; batch classifier loss: 0.372882; batch adversarial loss: 0.646724\n",
      "epoch 180; iter: 0; batch classifier loss: 0.408704; batch adversarial loss: 0.535694\n",
      "epoch 181; iter: 0; batch classifier loss: 0.342802; batch adversarial loss: 0.552816\n",
      "epoch 182; iter: 0; batch classifier loss: 0.358045; batch adversarial loss: 0.690385\n",
      "epoch 183; iter: 0; batch classifier loss: 0.397535; batch adversarial loss: 0.553525\n",
      "epoch 184; iter: 0; batch classifier loss: 0.357509; batch adversarial loss: 0.571931\n",
      "epoch 185; iter: 0; batch classifier loss: 0.346533; batch adversarial loss: 0.571739\n",
      "epoch 186; iter: 0; batch classifier loss: 0.330581; batch adversarial loss: 0.499143\n",
      "epoch 187; iter: 0; batch classifier loss: 0.359793; batch adversarial loss: 0.580771\n",
      "epoch 188; iter: 0; batch classifier loss: 0.337267; batch adversarial loss: 0.507872\n",
      "epoch 189; iter: 0; batch classifier loss: 0.371722; batch adversarial loss: 0.563480\n",
      "epoch 190; iter: 0; batch classifier loss: 0.338245; batch adversarial loss: 0.543561\n",
      "epoch 191; iter: 0; batch classifier loss: 0.294533; batch adversarial loss: 0.526115\n",
      "epoch 192; iter: 0; batch classifier loss: 0.347988; batch adversarial loss: 0.434860\n",
      "epoch 193; iter: 0; batch classifier loss: 0.375468; batch adversarial loss: 0.572267\n",
      "epoch 194; iter: 0; batch classifier loss: 0.332487; batch adversarial loss: 0.543816\n",
      "epoch 195; iter: 0; batch classifier loss: 0.368043; batch adversarial loss: 0.517502\n",
      "epoch 196; iter: 0; batch classifier loss: 0.339943; batch adversarial loss: 0.562283\n",
      "epoch 197; iter: 0; batch classifier loss: 0.289733; batch adversarial loss: 0.563143\n",
      "epoch 198; iter: 0; batch classifier loss: 0.371340; batch adversarial loss: 0.579922\n",
      "epoch 199; iter: 0; batch classifier loss: 0.546829; batch adversarial loss: 0.582076\n",
      "epoch 0; iter: 0; batch classifier loss: 0.745972; batch adversarial loss: 0.658454\n",
      "epoch 1; iter: 0; batch classifier loss: 0.624361; batch adversarial loss: 0.656266\n",
      "epoch 2; iter: 0; batch classifier loss: 0.532867; batch adversarial loss: 0.618660\n",
      "epoch 3; iter: 0; batch classifier loss: 0.564253; batch adversarial loss: 0.627632\n",
      "epoch 4; iter: 0; batch classifier loss: 0.511060; batch adversarial loss: 0.674175\n",
      "epoch 5; iter: 0; batch classifier loss: 0.629459; batch adversarial loss: 0.669739\n",
      "epoch 6; iter: 0; batch classifier loss: 0.542686; batch adversarial loss: 0.628664\n",
      "epoch 7; iter: 0; batch classifier loss: 0.592833; batch adversarial loss: 0.607457\n",
      "epoch 8; iter: 0; batch classifier loss: 0.546604; batch adversarial loss: 0.623025\n",
      "epoch 9; iter: 0; batch classifier loss: 0.493692; batch adversarial loss: 0.627627\n",
      "epoch 10; iter: 0; batch classifier loss: 0.610226; batch adversarial loss: 0.562886\n",
      "epoch 11; iter: 0; batch classifier loss: 0.526813; batch adversarial loss: 0.553195\n",
      "epoch 12; iter: 0; batch classifier loss: 0.598491; batch adversarial loss: 0.569990\n",
      "epoch 13; iter: 0; batch classifier loss: 0.535008; batch adversarial loss: 0.675252\n",
      "epoch 14; iter: 0; batch classifier loss: 0.457914; batch adversarial loss: 0.539343\n",
      "epoch 15; iter: 0; batch classifier loss: 0.555026; batch adversarial loss: 0.640246\n",
      "epoch 16; iter: 0; batch classifier loss: 0.526902; batch adversarial loss: 0.489268\n",
      "epoch 17; iter: 0; batch classifier loss: 0.516177; batch adversarial loss: 0.565071\n",
      "epoch 18; iter: 0; batch classifier loss: 0.576750; batch adversarial loss: 0.543240\n",
      "epoch 19; iter: 0; batch classifier loss: 0.490087; batch adversarial loss: 0.516742\n",
      "epoch 20; iter: 0; batch classifier loss: 0.461304; batch adversarial loss: 0.626321\n",
      "epoch 21; iter: 0; batch classifier loss: 0.508209; batch adversarial loss: 0.568849\n",
      "epoch 22; iter: 0; batch classifier loss: 0.491115; batch adversarial loss: 0.497158\n",
      "epoch 23; iter: 0; batch classifier loss: 0.499550; batch adversarial loss: 0.481730\n",
      "epoch 24; iter: 0; batch classifier loss: 0.428967; batch adversarial loss: 0.550301\n",
      "epoch 25; iter: 0; batch classifier loss: 0.537896; batch adversarial loss: 0.558034\n",
      "epoch 26; iter: 0; batch classifier loss: 0.506489; batch adversarial loss: 0.525876\n",
      "epoch 27; iter: 0; batch classifier loss: 0.399027; batch adversarial loss: 0.506148\n",
      "epoch 28; iter: 0; batch classifier loss: 0.398459; batch adversarial loss: 0.547251\n",
      "epoch 29; iter: 0; batch classifier loss: 0.481551; batch adversarial loss: 0.531218\n",
      "epoch 30; iter: 0; batch classifier loss: 0.459934; batch adversarial loss: 0.546270\n",
      "epoch 31; iter: 0; batch classifier loss: 0.474589; batch adversarial loss: 0.562227\n",
      "epoch 32; iter: 0; batch classifier loss: 0.415053; batch adversarial loss: 0.520533\n",
      "epoch 33; iter: 0; batch classifier loss: 0.517707; batch adversarial loss: 0.562597\n",
      "epoch 34; iter: 0; batch classifier loss: 0.476850; batch adversarial loss: 0.502419\n",
      "epoch 35; iter: 0; batch classifier loss: 0.448723; batch adversarial loss: 0.580171\n",
      "epoch 36; iter: 0; batch classifier loss: 0.438763; batch adversarial loss: 0.579525\n",
      "epoch 37; iter: 0; batch classifier loss: 0.388755; batch adversarial loss: 0.500949\n",
      "epoch 38; iter: 0; batch classifier loss: 0.480356; batch adversarial loss: 0.562791\n",
      "epoch 39; iter: 0; batch classifier loss: 0.376139; batch adversarial loss: 0.563159\n",
      "epoch 40; iter: 0; batch classifier loss: 0.434764; batch adversarial loss: 0.580959\n",
      "epoch 41; iter: 0; batch classifier loss: 0.422547; batch adversarial loss: 0.525711\n",
      "epoch 42; iter: 0; batch classifier loss: 0.421517; batch adversarial loss: 0.527339\n",
      "epoch 43; iter: 0; batch classifier loss: 0.430017; batch adversarial loss: 0.588998\n",
      "epoch 44; iter: 0; batch classifier loss: 0.414204; batch adversarial loss: 0.625339\n",
      "epoch 45; iter: 0; batch classifier loss: 0.366598; batch adversarial loss: 0.579421\n",
      "epoch 46; iter: 0; batch classifier loss: 0.401728; batch adversarial loss: 0.491850\n",
      "epoch 47; iter: 0; batch classifier loss: 0.452442; batch adversarial loss: 0.571866\n",
      "epoch 48; iter: 0; batch classifier loss: 0.406015; batch adversarial loss: 0.518630\n",
      "epoch 49; iter: 0; batch classifier loss: 0.464155; batch adversarial loss: 0.515626\n",
      "epoch 50; iter: 0; batch classifier loss: 0.431997; batch adversarial loss: 0.562086\n",
      "epoch 51; iter: 0; batch classifier loss: 0.435275; batch adversarial loss: 0.545002\n",
      "epoch 52; iter: 0; batch classifier loss: 0.444667; batch adversarial loss: 0.535446\n",
      "epoch 53; iter: 0; batch classifier loss: 0.404435; batch adversarial loss: 0.542958\n",
      "epoch 54; iter: 0; batch classifier loss: 0.481248; batch adversarial loss: 0.578433\n",
      "epoch 55; iter: 0; batch classifier loss: 0.435525; batch adversarial loss: 0.536565\n",
      "epoch 56; iter: 0; batch classifier loss: 0.380597; batch adversarial loss: 0.473684\n",
      "epoch 57; iter: 0; batch classifier loss: 0.458756; batch adversarial loss: 0.582080\n",
      "epoch 58; iter: 0; batch classifier loss: 0.401391; batch adversarial loss: 0.634960\n",
      "epoch 59; iter: 0; batch classifier loss: 0.497534; batch adversarial loss: 0.535364\n",
      "epoch 60; iter: 0; batch classifier loss: 0.407311; batch adversarial loss: 0.570009\n",
      "epoch 61; iter: 0; batch classifier loss: 0.412072; batch adversarial loss: 0.527842\n",
      "epoch 62; iter: 0; batch classifier loss: 0.492938; batch adversarial loss: 0.553828\n",
      "epoch 63; iter: 0; batch classifier loss: 0.472344; batch adversarial loss: 0.534887\n",
      "epoch 64; iter: 0; batch classifier loss: 0.447712; batch adversarial loss: 0.562140\n",
      "epoch 65; iter: 0; batch classifier loss: 0.396352; batch adversarial loss: 0.589356\n",
      "epoch 66; iter: 0; batch classifier loss: 0.380937; batch adversarial loss: 0.474549\n",
      "epoch 67; iter: 0; batch classifier loss: 0.466057; batch adversarial loss: 0.534683\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 68; iter: 0; batch classifier loss: 0.406293; batch adversarial loss: 0.555002\n",
      "epoch 69; iter: 0; batch classifier loss: 0.430944; batch adversarial loss: 0.554499\n",
      "epoch 70; iter: 0; batch classifier loss: 0.446837; batch adversarial loss: 0.574117\n",
      "epoch 71; iter: 0; batch classifier loss: 0.412782; batch adversarial loss: 0.543537\n",
      "epoch 72; iter: 0; batch classifier loss: 0.430033; batch adversarial loss: 0.579490\n",
      "epoch 73; iter: 0; batch classifier loss: 0.390884; batch adversarial loss: 0.581940\n",
      "epoch 74; iter: 0; batch classifier loss: 0.497771; batch adversarial loss: 0.561312\n",
      "epoch 75; iter: 0; batch classifier loss: 0.389932; batch adversarial loss: 0.509861\n",
      "epoch 76; iter: 0; batch classifier loss: 0.349694; batch adversarial loss: 0.574077\n",
      "epoch 77; iter: 0; batch classifier loss: 0.433370; batch adversarial loss: 0.580539\n",
      "epoch 78; iter: 0; batch classifier loss: 0.356613; batch adversarial loss: 0.525968\n",
      "epoch 79; iter: 0; batch classifier loss: 0.369610; batch adversarial loss: 0.598527\n",
      "epoch 80; iter: 0; batch classifier loss: 0.431326; batch adversarial loss: 0.500028\n",
      "epoch 81; iter: 0; batch classifier loss: 0.368740; batch adversarial loss: 0.588410\n",
      "epoch 82; iter: 0; batch classifier loss: 0.394432; batch adversarial loss: 0.588332\n",
      "epoch 83; iter: 0; batch classifier loss: 0.353183; batch adversarial loss: 0.597067\n",
      "epoch 84; iter: 0; batch classifier loss: 0.355268; batch adversarial loss: 0.508942\n",
      "epoch 85; iter: 0; batch classifier loss: 0.343495; batch adversarial loss: 0.551231\n",
      "epoch 86; iter: 0; batch classifier loss: 0.334688; batch adversarial loss: 0.516428\n",
      "epoch 87; iter: 0; batch classifier loss: 0.448776; batch adversarial loss: 0.581663\n",
      "epoch 88; iter: 0; batch classifier loss: 0.373108; batch adversarial loss: 0.509769\n",
      "epoch 89; iter: 0; batch classifier loss: 0.375284; batch adversarial loss: 0.528505\n",
      "epoch 90; iter: 0; batch classifier loss: 0.398632; batch adversarial loss: 0.544362\n",
      "epoch 91; iter: 0; batch classifier loss: 0.425184; batch adversarial loss: 0.482887\n",
      "epoch 92; iter: 0; batch classifier loss: 0.387401; batch adversarial loss: 0.584021\n",
      "epoch 93; iter: 0; batch classifier loss: 0.404679; batch adversarial loss: 0.515695\n",
      "epoch 94; iter: 0; batch classifier loss: 0.434918; batch adversarial loss: 0.563825\n",
      "epoch 95; iter: 0; batch classifier loss: 0.420970; batch adversarial loss: 0.578777\n",
      "epoch 96; iter: 0; batch classifier loss: 0.431434; batch adversarial loss: 0.555262\n",
      "epoch 97; iter: 0; batch classifier loss: 0.388056; batch adversarial loss: 0.492332\n",
      "epoch 98; iter: 0; batch classifier loss: 0.371689; batch adversarial loss: 0.579572\n",
      "epoch 99; iter: 0; batch classifier loss: 0.369623; batch adversarial loss: 0.547716\n",
      "epoch 100; iter: 0; batch classifier loss: 0.318736; batch adversarial loss: 0.624641\n",
      "epoch 101; iter: 0; batch classifier loss: 0.353539; batch adversarial loss: 0.578742\n",
      "epoch 102; iter: 0; batch classifier loss: 0.402472; batch adversarial loss: 0.623767\n",
      "epoch 103; iter: 0; batch classifier loss: 0.411382; batch adversarial loss: 0.515863\n",
      "epoch 104; iter: 0; batch classifier loss: 0.342259; batch adversarial loss: 0.543764\n",
      "epoch 105; iter: 0; batch classifier loss: 0.408965; batch adversarial loss: 0.517892\n",
      "epoch 106; iter: 0; batch classifier loss: 0.354226; batch adversarial loss: 0.555406\n",
      "epoch 107; iter: 0; batch classifier loss: 0.413391; batch adversarial loss: 0.527273\n",
      "epoch 108; iter: 0; batch classifier loss: 0.356931; batch adversarial loss: 0.578902\n",
      "epoch 109; iter: 0; batch classifier loss: 0.347725; batch adversarial loss: 0.570138\n",
      "epoch 110; iter: 0; batch classifier loss: 0.347375; batch adversarial loss: 0.439838\n",
      "epoch 111; iter: 0; batch classifier loss: 0.408644; batch adversarial loss: 0.590569\n",
      "epoch 112; iter: 0; batch classifier loss: 0.463253; batch adversarial loss: 0.527395\n",
      "epoch 113; iter: 0; batch classifier loss: 0.475106; batch adversarial loss: 0.530338\n",
      "epoch 114; iter: 0; batch classifier loss: 0.337730; batch adversarial loss: 0.497857\n",
      "epoch 115; iter: 0; batch classifier loss: 0.303511; batch adversarial loss: 0.579493\n",
      "epoch 116; iter: 0; batch classifier loss: 0.327725; batch adversarial loss: 0.659904\n",
      "epoch 117; iter: 0; batch classifier loss: 0.363897; batch adversarial loss: 0.625782\n",
      "epoch 118; iter: 0; batch classifier loss: 0.385575; batch adversarial loss: 0.514347\n",
      "epoch 119; iter: 0; batch classifier loss: 0.307251; batch adversarial loss: 0.615796\n",
      "epoch 120; iter: 0; batch classifier loss: 0.396909; batch adversarial loss: 0.568515\n",
      "epoch 121; iter: 0; batch classifier loss: 0.389633; batch adversarial loss: 0.617143\n",
      "epoch 122; iter: 0; batch classifier loss: 0.412539; batch adversarial loss: 0.516301\n",
      "epoch 123; iter: 0; batch classifier loss: 0.408281; batch adversarial loss: 0.561430\n",
      "epoch 124; iter: 0; batch classifier loss: 0.286180; batch adversarial loss: 0.517560\n",
      "epoch 125; iter: 0; batch classifier loss: 0.479617; batch adversarial loss: 0.580210\n",
      "epoch 126; iter: 0; batch classifier loss: 0.306163; batch adversarial loss: 0.616551\n",
      "epoch 127; iter: 0; batch classifier loss: 0.408705; batch adversarial loss: 0.609018\n",
      "epoch 128; iter: 0; batch classifier loss: 0.383627; batch adversarial loss: 0.590654\n",
      "epoch 129; iter: 0; batch classifier loss: 0.371427; batch adversarial loss: 0.537865\n",
      "epoch 130; iter: 0; batch classifier loss: 0.459745; batch adversarial loss: 0.490784\n",
      "epoch 131; iter: 0; batch classifier loss: 0.486908; batch adversarial loss: 0.626818\n",
      "epoch 132; iter: 0; batch classifier loss: 0.382924; batch adversarial loss: 0.562034\n",
      "epoch 133; iter: 0; batch classifier loss: 0.374400; batch adversarial loss: 0.609127\n",
      "epoch 134; iter: 0; batch classifier loss: 0.339373; batch adversarial loss: 0.570212\n",
      "epoch 135; iter: 0; batch classifier loss: 0.377350; batch adversarial loss: 0.563520\n",
      "epoch 136; iter: 0; batch classifier loss: 0.386317; batch adversarial loss: 0.580648\n",
      "epoch 137; iter: 0; batch classifier loss: 0.396736; batch adversarial loss: 0.571307\n",
      "epoch 138; iter: 0; batch classifier loss: 0.405864; batch adversarial loss: 0.490194\n",
      "epoch 139; iter: 0; batch classifier loss: 0.384609; batch adversarial loss: 0.488520\n",
      "epoch 140; iter: 0; batch classifier loss: 0.364728; batch adversarial loss: 0.556029\n",
      "epoch 141; iter: 0; batch classifier loss: 0.273069; batch adversarial loss: 0.481770\n",
      "epoch 142; iter: 0; batch classifier loss: 0.406642; batch adversarial loss: 0.545279\n",
      "epoch 143; iter: 0; batch classifier loss: 0.379486; batch adversarial loss: 0.536067\n",
      "epoch 144; iter: 0; batch classifier loss: 0.366034; batch adversarial loss: 0.501636\n",
      "epoch 145; iter: 0; batch classifier loss: 0.329699; batch adversarial loss: 0.613880\n",
      "epoch 146; iter: 0; batch classifier loss: 0.365904; batch adversarial loss: 0.473658\n",
      "epoch 147; iter: 0; batch classifier loss: 0.404483; batch adversarial loss: 0.608124\n",
      "epoch 148; iter: 0; batch classifier loss: 0.384630; batch adversarial loss: 0.535194\n",
      "epoch 149; iter: 0; batch classifier loss: 0.342146; batch adversarial loss: 0.563870\n",
      "epoch 150; iter: 0; batch classifier loss: 0.277881; batch adversarial loss: 0.545257\n",
      "epoch 151; iter: 0; batch classifier loss: 0.368354; batch adversarial loss: 0.579580\n",
      "epoch 152; iter: 0; batch classifier loss: 0.361171; batch adversarial loss: 0.499658\n",
      "epoch 153; iter: 0; batch classifier loss: 0.393326; batch adversarial loss: 0.606639\n",
      "epoch 154; iter: 0; batch classifier loss: 0.372722; batch adversarial loss: 0.542491\n",
      "epoch 155; iter: 0; batch classifier loss: 0.403355; batch adversarial loss: 0.580873\n",
      "epoch 156; iter: 0; batch classifier loss: 0.298456; batch adversarial loss: 0.607447\n",
      "epoch 157; iter: 0; batch classifier loss: 0.364093; batch adversarial loss: 0.607979\n",
      "epoch 158; iter: 0; batch classifier loss: 0.360105; batch adversarial loss: 0.553801\n",
      "epoch 159; iter: 0; batch classifier loss: 0.393387; batch adversarial loss: 0.609337\n",
      "epoch 160; iter: 0; batch classifier loss: 0.330051; batch adversarial loss: 0.545195\n",
      "epoch 161; iter: 0; batch classifier loss: 0.341595; batch adversarial loss: 0.662808\n",
      "epoch 162; iter: 0; batch classifier loss: 0.386931; batch adversarial loss: 0.535577\n",
      "epoch 163; iter: 0; batch classifier loss: 0.419525; batch adversarial loss: 0.696624\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 164; iter: 0; batch classifier loss: 0.403375; batch adversarial loss: 0.585411\n",
      "epoch 165; iter: 0; batch classifier loss: 0.416731; batch adversarial loss: 0.554407\n",
      "epoch 166; iter: 0; batch classifier loss: 0.322146; batch adversarial loss: 0.553708\n",
      "epoch 167; iter: 0; batch classifier loss: 0.305944; batch adversarial loss: 0.533025\n",
      "epoch 168; iter: 0; batch classifier loss: 0.352769; batch adversarial loss: 0.563075\n",
      "epoch 169; iter: 0; batch classifier loss: 0.377442; batch adversarial loss: 0.586724\n",
      "epoch 170; iter: 0; batch classifier loss: 0.372517; batch adversarial loss: 0.572280\n",
      "epoch 171; iter: 0; batch classifier loss: 0.298909; batch adversarial loss: 0.608439\n",
      "epoch 172; iter: 0; batch classifier loss: 0.354506; batch adversarial loss: 0.501007\n",
      "epoch 173; iter: 0; batch classifier loss: 0.453551; batch adversarial loss: 0.580850\n",
      "epoch 174; iter: 0; batch classifier loss: 0.360700; batch adversarial loss: 0.549114\n",
      "epoch 175; iter: 0; batch classifier loss: 0.285995; batch adversarial loss: 0.587403\n",
      "epoch 176; iter: 0; batch classifier loss: 0.381408; batch adversarial loss: 0.552970\n",
      "epoch 177; iter: 0; batch classifier loss: 0.349014; batch adversarial loss: 0.535688\n",
      "epoch 178; iter: 0; batch classifier loss: 0.374400; batch adversarial loss: 0.536320\n",
      "epoch 179; iter: 0; batch classifier loss: 0.353745; batch adversarial loss: 0.526432\n",
      "epoch 180; iter: 0; batch classifier loss: 0.337039; batch adversarial loss: 0.559604\n",
      "epoch 181; iter: 0; batch classifier loss: 0.314813; batch adversarial loss: 0.553126\n",
      "epoch 182; iter: 0; batch classifier loss: 0.462128; batch adversarial loss: 0.520487\n",
      "epoch 183; iter: 0; batch classifier loss: 0.358290; batch adversarial loss: 0.542769\n",
      "epoch 184; iter: 0; batch classifier loss: 0.337137; batch adversarial loss: 0.609862\n",
      "epoch 185; iter: 0; batch classifier loss: 0.344357; batch adversarial loss: 0.635012\n",
      "epoch 186; iter: 0; batch classifier loss: 0.392998; batch adversarial loss: 0.561065\n",
      "epoch 187; iter: 0; batch classifier loss: 0.401517; batch adversarial loss: 0.526812\n",
      "epoch 188; iter: 0; batch classifier loss: 0.367446; batch adversarial loss: 0.555940\n",
      "epoch 189; iter: 0; batch classifier loss: 0.343386; batch adversarial loss: 0.553099\n",
      "epoch 190; iter: 0; batch classifier loss: 0.263923; batch adversarial loss: 0.509447\n",
      "epoch 191; iter: 0; batch classifier loss: 0.396271; batch adversarial loss: 0.526134\n",
      "epoch 192; iter: 0; batch classifier loss: 0.373358; batch adversarial loss: 0.552197\n",
      "epoch 193; iter: 0; batch classifier loss: 0.347331; batch adversarial loss: 0.602028\n",
      "epoch 194; iter: 0; batch classifier loss: 0.371842; batch adversarial loss: 0.519733\n",
      "epoch 195; iter: 0; batch classifier loss: 0.433879; batch adversarial loss: 0.598916\n",
      "epoch 196; iter: 0; batch classifier loss: 0.383611; batch adversarial loss: 0.518802\n",
      "epoch 197; iter: 0; batch classifier loss: 0.311933; batch adversarial loss: 0.560664\n",
      "epoch 198; iter: 0; batch classifier loss: 0.325176; batch adversarial loss: 0.626994\n",
      "epoch 199; iter: 0; batch classifier loss: 0.362050; batch adversarial loss: 0.552028\n",
      "epoch 0; iter: 0; batch classifier loss: 0.651281; batch adversarial loss: 0.585113\n",
      "epoch 1; iter: 0; batch classifier loss: 0.638938; batch adversarial loss: 0.630249\n",
      "epoch 2; iter: 0; batch classifier loss: 0.612164; batch adversarial loss: 0.694796\n",
      "epoch 3; iter: 0; batch classifier loss: 0.662468; batch adversarial loss: 0.671915\n",
      "epoch 4; iter: 0; batch classifier loss: 0.579937; batch adversarial loss: 0.671395\n",
      "epoch 5; iter: 0; batch classifier loss: 0.725235; batch adversarial loss: 0.764957\n",
      "epoch 6; iter: 0; batch classifier loss: 0.654023; batch adversarial loss: 0.655427\n",
      "epoch 7; iter: 0; batch classifier loss: 0.542115; batch adversarial loss: 0.657620\n",
      "epoch 8; iter: 0; batch classifier loss: 0.535292; batch adversarial loss: 0.626171\n",
      "epoch 9; iter: 0; batch classifier loss: 0.647723; batch adversarial loss: 0.616819\n",
      "epoch 10; iter: 0; batch classifier loss: 0.530134; batch adversarial loss: 0.590879\n",
      "epoch 11; iter: 0; batch classifier loss: 0.501914; batch adversarial loss: 0.577687\n",
      "epoch 12; iter: 0; batch classifier loss: 0.479118; batch adversarial loss: 0.570936\n",
      "epoch 13; iter: 0; batch classifier loss: 0.540997; batch adversarial loss: 0.545194\n",
      "epoch 14; iter: 0; batch classifier loss: 0.558866; batch adversarial loss: 0.584408\n",
      "epoch 15; iter: 0; batch classifier loss: 0.500155; batch adversarial loss: 0.560215\n",
      "epoch 16; iter: 0; batch classifier loss: 0.492401; batch adversarial loss: 0.569218\n",
      "epoch 17; iter: 0; batch classifier loss: 0.552073; batch adversarial loss: 0.649815\n",
      "epoch 18; iter: 0; batch classifier loss: 0.515496; batch adversarial loss: 0.572386\n",
      "epoch 19; iter: 0; batch classifier loss: 0.511748; batch adversarial loss: 0.563659\n",
      "epoch 20; iter: 0; batch classifier loss: 0.451780; batch adversarial loss: 0.571132\n",
      "epoch 21; iter: 0; batch classifier loss: 0.532191; batch adversarial loss: 0.533005\n",
      "epoch 22; iter: 0; batch classifier loss: 0.395439; batch adversarial loss: 0.487017\n",
      "epoch 23; iter: 0; batch classifier loss: 0.480708; batch adversarial loss: 0.587263\n",
      "epoch 24; iter: 0; batch classifier loss: 0.533545; batch adversarial loss: 0.612895\n",
      "epoch 25; iter: 0; batch classifier loss: 0.537896; batch adversarial loss: 0.536240\n",
      "epoch 26; iter: 0; batch classifier loss: 0.451132; batch adversarial loss: 0.539193\n",
      "epoch 27; iter: 0; batch classifier loss: 0.516033; batch adversarial loss: 0.614861\n",
      "epoch 28; iter: 0; batch classifier loss: 0.442460; batch adversarial loss: 0.508308\n",
      "epoch 29; iter: 0; batch classifier loss: 0.468497; batch adversarial loss: 0.580924\n",
      "epoch 30; iter: 0; batch classifier loss: 0.473140; batch adversarial loss: 0.534617\n",
      "epoch 31; iter: 0; batch classifier loss: 0.550987; batch adversarial loss: 0.481395\n",
      "epoch 32; iter: 0; batch classifier loss: 0.452247; batch adversarial loss: 0.515462\n",
      "epoch 33; iter: 0; batch classifier loss: 0.430519; batch adversarial loss: 0.577765\n",
      "epoch 34; iter: 0; batch classifier loss: 0.452466; batch adversarial loss: 0.565322\n",
      "epoch 35; iter: 0; batch classifier loss: 0.457127; batch adversarial loss: 0.521118\n",
      "epoch 36; iter: 0; batch classifier loss: 0.439755; batch adversarial loss: 0.566299\n",
      "epoch 37; iter: 0; batch classifier loss: 0.475877; batch adversarial loss: 0.543743\n",
      "epoch 38; iter: 0; batch classifier loss: 0.482698; batch adversarial loss: 0.541933\n",
      "epoch 39; iter: 0; batch classifier loss: 0.465163; batch adversarial loss: 0.546064\n",
      "epoch 40; iter: 0; batch classifier loss: 0.464093; batch adversarial loss: 0.543003\n",
      "epoch 41; iter: 0; batch classifier loss: 0.523265; batch adversarial loss: 0.590286\n",
      "epoch 42; iter: 0; batch classifier loss: 0.451378; batch adversarial loss: 0.475092\n",
      "epoch 43; iter: 0; batch classifier loss: 0.470125; batch adversarial loss: 0.616394\n",
      "epoch 44; iter: 0; batch classifier loss: 0.414507; batch adversarial loss: 0.610894\n",
      "epoch 45; iter: 0; batch classifier loss: 0.434524; batch adversarial loss: 0.527768\n",
      "epoch 46; iter: 0; batch classifier loss: 0.477803; batch adversarial loss: 0.552079\n",
      "epoch 47; iter: 0; batch classifier loss: 0.460598; batch adversarial loss: 0.550179\n",
      "epoch 48; iter: 0; batch classifier loss: 0.416900; batch adversarial loss: 0.583842\n",
      "epoch 49; iter: 0; batch classifier loss: 0.445798; batch adversarial loss: 0.518201\n",
      "epoch 50; iter: 0; batch classifier loss: 0.454811; batch adversarial loss: 0.518073\n",
      "epoch 51; iter: 0; batch classifier loss: 0.407768; batch adversarial loss: 0.530364\n",
      "epoch 52; iter: 0; batch classifier loss: 0.443795; batch adversarial loss: 0.517744\n",
      "epoch 53; iter: 0; batch classifier loss: 0.428348; batch adversarial loss: 0.546232\n",
      "epoch 54; iter: 0; batch classifier loss: 0.422210; batch adversarial loss: 0.536087\n",
      "epoch 55; iter: 0; batch classifier loss: 0.418081; batch adversarial loss: 0.591473\n",
      "epoch 56; iter: 0; batch classifier loss: 0.406423; batch adversarial loss: 0.599041\n",
      "epoch 57; iter: 0; batch classifier loss: 0.345241; batch adversarial loss: 0.527356\n",
      "epoch 58; iter: 0; batch classifier loss: 0.463129; batch adversarial loss: 0.473314\n",
      "epoch 59; iter: 0; batch classifier loss: 0.411583; batch adversarial loss: 0.554843\n",
      "epoch 60; iter: 0; batch classifier loss: 0.460373; batch adversarial loss: 0.509721\n",
      "epoch 61; iter: 0; batch classifier loss: 0.417356; batch adversarial loss: 0.617336\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 62; iter: 0; batch classifier loss: 0.384024; batch adversarial loss: 0.597580\n",
      "epoch 63; iter: 0; batch classifier loss: 0.413074; batch adversarial loss: 0.507630\n",
      "epoch 64; iter: 0; batch classifier loss: 0.439128; batch adversarial loss: 0.605975\n",
      "epoch 65; iter: 0; batch classifier loss: 0.476333; batch adversarial loss: 0.630545\n",
      "epoch 66; iter: 0; batch classifier loss: 0.469008; batch adversarial loss: 0.519950\n",
      "epoch 67; iter: 0; batch classifier loss: 0.414240; batch adversarial loss: 0.513931\n",
      "epoch 68; iter: 0; batch classifier loss: 0.397073; batch adversarial loss: 0.471162\n",
      "epoch 69; iter: 0; batch classifier loss: 0.517204; batch adversarial loss: 0.490872\n",
      "epoch 70; iter: 0; batch classifier loss: 0.442434; batch adversarial loss: 0.583462\n",
      "epoch 71; iter: 0; batch classifier loss: 0.437854; batch adversarial loss: 0.550508\n",
      "epoch 72; iter: 0; batch classifier loss: 0.398486; batch adversarial loss: 0.539524\n",
      "epoch 73; iter: 0; batch classifier loss: 0.391287; batch adversarial loss: 0.515392\n",
      "epoch 74; iter: 0; batch classifier loss: 0.341134; batch adversarial loss: 0.547726\n",
      "epoch 75; iter: 0; batch classifier loss: 0.378195; batch adversarial loss: 0.513897\n",
      "epoch 76; iter: 0; batch classifier loss: 0.438621; batch adversarial loss: 0.525166\n",
      "epoch 77; iter: 0; batch classifier loss: 0.447817; batch adversarial loss: 0.581834\n",
      "epoch 78; iter: 0; batch classifier loss: 0.401019; batch adversarial loss: 0.511222\n",
      "epoch 79; iter: 0; batch classifier loss: 0.463235; batch adversarial loss: 0.554384\n",
      "epoch 80; iter: 0; batch classifier loss: 0.363041; batch adversarial loss: 0.580265\n",
      "epoch 81; iter: 0; batch classifier loss: 0.466194; batch adversarial loss: 0.604292\n",
      "epoch 82; iter: 0; batch classifier loss: 0.357722; batch adversarial loss: 0.581440\n",
      "epoch 83; iter: 0; batch classifier loss: 0.388239; batch adversarial loss: 0.547537\n",
      "epoch 84; iter: 0; batch classifier loss: 0.378476; batch adversarial loss: 0.561755\n",
      "epoch 85; iter: 0; batch classifier loss: 0.348925; batch adversarial loss: 0.462658\n",
      "epoch 86; iter: 0; batch classifier loss: 0.323137; batch adversarial loss: 0.478150\n",
      "epoch 87; iter: 0; batch classifier loss: 0.397618; batch adversarial loss: 0.586212\n",
      "epoch 88; iter: 0; batch classifier loss: 0.432210; batch adversarial loss: 0.570325\n",
      "epoch 89; iter: 0; batch classifier loss: 0.394185; batch adversarial loss: 0.622688\n",
      "epoch 90; iter: 0; batch classifier loss: 0.413505; batch adversarial loss: 0.527355\n",
      "epoch 91; iter: 0; batch classifier loss: 0.422919; batch adversarial loss: 0.527813\n",
      "epoch 92; iter: 0; batch classifier loss: 0.426786; batch adversarial loss: 0.472034\n",
      "epoch 93; iter: 0; batch classifier loss: 0.413969; batch adversarial loss: 0.591067\n",
      "epoch 94; iter: 0; batch classifier loss: 0.377637; batch adversarial loss: 0.581546\n",
      "epoch 95; iter: 0; batch classifier loss: 0.448607; batch adversarial loss: 0.518426\n",
      "epoch 96; iter: 0; batch classifier loss: 0.345926; batch adversarial loss: 0.544045\n",
      "epoch 97; iter: 0; batch classifier loss: 0.416256; batch adversarial loss: 0.571738\n",
      "epoch 98; iter: 0; batch classifier loss: 0.444720; batch adversarial loss: 0.524872\n",
      "epoch 99; iter: 0; batch classifier loss: 0.344178; batch adversarial loss: 0.536111\n",
      "epoch 100; iter: 0; batch classifier loss: 0.352713; batch adversarial loss: 0.554438\n",
      "epoch 101; iter: 0; batch classifier loss: 0.358538; batch adversarial loss: 0.589546\n",
      "epoch 102; iter: 0; batch classifier loss: 0.435935; batch adversarial loss: 0.498105\n",
      "epoch 103; iter: 0; batch classifier loss: 0.375748; batch adversarial loss: 0.509820\n",
      "epoch 104; iter: 0; batch classifier loss: 0.385169; batch adversarial loss: 0.509376\n",
      "epoch 105; iter: 0; batch classifier loss: 0.335440; batch adversarial loss: 0.418774\n",
      "epoch 106; iter: 0; batch classifier loss: 0.478689; batch adversarial loss: 0.563925\n",
      "epoch 107; iter: 0; batch classifier loss: 0.412318; batch adversarial loss: 0.588275\n",
      "epoch 108; iter: 0; batch classifier loss: 0.384849; batch adversarial loss: 0.551589\n",
      "epoch 109; iter: 0; batch classifier loss: 0.340236; batch adversarial loss: 0.543745\n",
      "epoch 110; iter: 0; batch classifier loss: 0.396019; batch adversarial loss: 0.513065\n",
      "epoch 111; iter: 0; batch classifier loss: 0.418856; batch adversarial loss: 0.444472\n",
      "epoch 112; iter: 0; batch classifier loss: 0.430261; batch adversarial loss: 0.551018\n",
      "epoch 113; iter: 0; batch classifier loss: 0.432124; batch adversarial loss: 0.535006\n",
      "epoch 114; iter: 0; batch classifier loss: 0.351940; batch adversarial loss: 0.574873\n",
      "epoch 115; iter: 0; batch classifier loss: 0.426012; batch adversarial loss: 0.644661\n",
      "epoch 116; iter: 0; batch classifier loss: 0.380300; batch adversarial loss: 0.611618\n",
      "epoch 117; iter: 0; batch classifier loss: 0.377640; batch adversarial loss: 0.570883\n",
      "epoch 118; iter: 0; batch classifier loss: 0.392235; batch adversarial loss: 0.489598\n",
      "epoch 119; iter: 0; batch classifier loss: 0.368622; batch adversarial loss: 0.537378\n",
      "epoch 120; iter: 0; batch classifier loss: 0.427092; batch adversarial loss: 0.543463\n",
      "epoch 121; iter: 0; batch classifier loss: 0.316557; batch adversarial loss: 0.536233\n",
      "epoch 122; iter: 0; batch classifier loss: 0.427898; batch adversarial loss: 0.599583\n",
      "epoch 123; iter: 0; batch classifier loss: 0.369040; batch adversarial loss: 0.585059\n",
      "epoch 124; iter: 0; batch classifier loss: 0.326447; batch adversarial loss: 0.597051\n",
      "epoch 125; iter: 0; batch classifier loss: 0.381547; batch adversarial loss: 0.544181\n",
      "epoch 126; iter: 0; batch classifier loss: 0.447429; batch adversarial loss: 0.515886\n",
      "epoch 127; iter: 0; batch classifier loss: 0.303859; batch adversarial loss: 0.498503\n",
      "epoch 128; iter: 0; batch classifier loss: 0.357842; batch adversarial loss: 0.489071\n",
      "epoch 129; iter: 0; batch classifier loss: 0.334161; batch adversarial loss: 0.580839\n",
      "epoch 130; iter: 0; batch classifier loss: 0.364180; batch adversarial loss: 0.527580\n",
      "epoch 131; iter: 0; batch classifier loss: 0.347615; batch adversarial loss: 0.490650\n",
      "epoch 132; iter: 0; batch classifier loss: 0.357605; batch adversarial loss: 0.601491\n",
      "epoch 133; iter: 0; batch classifier loss: 0.350804; batch adversarial loss: 0.546393\n",
      "epoch 134; iter: 0; batch classifier loss: 0.359133; batch adversarial loss: 0.524502\n",
      "epoch 135; iter: 0; batch classifier loss: 0.436312; batch adversarial loss: 0.507114\n",
      "epoch 136; iter: 0; batch classifier loss: 0.297243; batch adversarial loss: 0.491065\n",
      "epoch 137; iter: 0; batch classifier loss: 0.352511; batch adversarial loss: 0.516855\n",
      "epoch 138; iter: 0; batch classifier loss: 0.378951; batch adversarial loss: 0.513210\n",
      "epoch 139; iter: 0; batch classifier loss: 0.336483; batch adversarial loss: 0.545870\n",
      "epoch 140; iter: 0; batch classifier loss: 0.378215; batch adversarial loss: 0.562669\n",
      "epoch 141; iter: 0; batch classifier loss: 0.405738; batch adversarial loss: 0.552548\n",
      "epoch 142; iter: 0; batch classifier loss: 0.339963; batch adversarial loss: 0.527418\n",
      "epoch 143; iter: 0; batch classifier loss: 0.380441; batch adversarial loss: 0.607265\n",
      "epoch 144; iter: 0; batch classifier loss: 0.282641; batch adversarial loss: 0.490642\n",
      "epoch 145; iter: 0; batch classifier loss: 0.355779; batch adversarial loss: 0.554420\n",
      "epoch 146; iter: 0; batch classifier loss: 0.414600; batch adversarial loss: 0.564657\n",
      "epoch 147; iter: 0; batch classifier loss: 0.379252; batch adversarial loss: 0.617146\n",
      "epoch 148; iter: 0; batch classifier loss: 0.405883; batch adversarial loss: 0.527517\n",
      "epoch 149; iter: 0; batch classifier loss: 0.318978; batch adversarial loss: 0.615216\n",
      "epoch 150; iter: 0; batch classifier loss: 0.271718; batch adversarial loss: 0.645257\n",
      "epoch 151; iter: 0; batch classifier loss: 0.395604; batch adversarial loss: 0.508572\n",
      "epoch 152; iter: 0; batch classifier loss: 0.364933; batch adversarial loss: 0.534190\n",
      "epoch 153; iter: 0; batch classifier loss: 0.393252; batch adversarial loss: 0.582100\n",
      "epoch 154; iter: 0; batch classifier loss: 0.345723; batch adversarial loss: 0.581511\n",
      "epoch 155; iter: 0; batch classifier loss: 0.477995; batch adversarial loss: 0.588525\n",
      "epoch 156; iter: 0; batch classifier loss: 0.295462; batch adversarial loss: 0.545779\n",
      "epoch 157; iter: 0; batch classifier loss: 0.363558; batch adversarial loss: 0.520203\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 158; iter: 0; batch classifier loss: 0.296121; batch adversarial loss: 0.479159\n",
      "epoch 159; iter: 0; batch classifier loss: 0.329869; batch adversarial loss: 0.583223\n",
      "epoch 160; iter: 0; batch classifier loss: 0.362201; batch adversarial loss: 0.562106\n",
      "epoch 161; iter: 0; batch classifier loss: 0.354227; batch adversarial loss: 0.543183\n",
      "epoch 162; iter: 0; batch classifier loss: 0.314794; batch adversarial loss: 0.535978\n",
      "epoch 163; iter: 0; batch classifier loss: 0.339007; batch adversarial loss: 0.512426\n",
      "epoch 164; iter: 0; batch classifier loss: 0.340540; batch adversarial loss: 0.544120\n",
      "epoch 165; iter: 0; batch classifier loss: 0.445265; batch adversarial loss: 0.516789\n",
      "epoch 166; iter: 0; batch classifier loss: 0.370330; batch adversarial loss: 0.573786\n",
      "epoch 167; iter: 0; batch classifier loss: 0.325681; batch adversarial loss: 0.589325\n",
      "epoch 168; iter: 0; batch classifier loss: 0.347113; batch adversarial loss: 0.535242\n",
      "epoch 169; iter: 0; batch classifier loss: 0.445561; batch adversarial loss: 0.519434\n",
      "epoch 170; iter: 0; batch classifier loss: 0.365234; batch adversarial loss: 0.537504\n",
      "epoch 171; iter: 0; batch classifier loss: 0.297499; batch adversarial loss: 0.597811\n",
      "epoch 172; iter: 0; batch classifier loss: 0.374784; batch adversarial loss: 0.560483\n",
      "epoch 173; iter: 0; batch classifier loss: 0.327888; batch adversarial loss: 0.498864\n",
      "epoch 174; iter: 0; batch classifier loss: 0.422302; batch adversarial loss: 0.497830\n",
      "epoch 175; iter: 0; batch classifier loss: 0.318007; batch adversarial loss: 0.555564\n",
      "epoch 176; iter: 0; batch classifier loss: 0.387306; batch adversarial loss: 0.561149\n",
      "epoch 177; iter: 0; batch classifier loss: 0.309289; batch adversarial loss: 0.572326\n",
      "epoch 178; iter: 0; batch classifier loss: 0.261723; batch adversarial loss: 0.553558\n",
      "epoch 179; iter: 0; batch classifier loss: 0.391814; batch adversarial loss: 0.499962\n",
      "epoch 180; iter: 0; batch classifier loss: 0.467785; batch adversarial loss: 0.551549\n",
      "epoch 181; iter: 0; batch classifier loss: 0.349676; batch adversarial loss: 0.552029\n",
      "epoch 182; iter: 0; batch classifier loss: 0.332347; batch adversarial loss: 0.552277\n",
      "epoch 183; iter: 0; batch classifier loss: 0.397758; batch adversarial loss: 0.536485\n",
      "epoch 184; iter: 0; batch classifier loss: 0.367108; batch adversarial loss: 0.607805\n",
      "epoch 185; iter: 0; batch classifier loss: 0.286070; batch adversarial loss: 0.491388\n",
      "epoch 186; iter: 0; batch classifier loss: 0.389572; batch adversarial loss: 0.515867\n",
      "epoch 187; iter: 0; batch classifier loss: 0.284133; batch adversarial loss: 0.554756\n",
      "epoch 188; iter: 0; batch classifier loss: 0.354813; batch adversarial loss: 0.488089\n",
      "epoch 189; iter: 0; batch classifier loss: 0.378414; batch adversarial loss: 0.543212\n",
      "epoch 190; iter: 0; batch classifier loss: 0.340404; batch adversarial loss: 0.598943\n",
      "epoch 191; iter: 0; batch classifier loss: 0.363659; batch adversarial loss: 0.555034\n",
      "epoch 192; iter: 0; batch classifier loss: 0.341582; batch adversarial loss: 0.653590\n",
      "epoch 193; iter: 0; batch classifier loss: 0.424464; batch adversarial loss: 0.564443\n",
      "epoch 194; iter: 0; batch classifier loss: 0.310200; batch adversarial loss: 0.565930\n",
      "epoch 195; iter: 0; batch classifier loss: 0.399437; batch adversarial loss: 0.606891\n",
      "epoch 196; iter: 0; batch classifier loss: 0.403585; batch adversarial loss: 0.472930\n",
      "epoch 197; iter: 0; batch classifier loss: 0.372780; batch adversarial loss: 0.605682\n",
      "epoch 198; iter: 0; batch classifier loss: 0.254097; batch adversarial loss: 0.487868\n",
      "epoch 199; iter: 0; batch classifier loss: 0.389807; batch adversarial loss: 0.553628\n",
      "epoch 0; iter: 0; batch classifier loss: 0.755842; batch adversarial loss: 0.959291\n",
      "epoch 1; iter: 0; batch classifier loss: 0.863700; batch adversarial loss: 1.009300\n",
      "epoch 2; iter: 0; batch classifier loss: 0.904878; batch adversarial loss: 0.936002\n",
      "epoch 3; iter: 0; batch classifier loss: 1.070946; batch adversarial loss: 0.871150\n",
      "epoch 4; iter: 0; batch classifier loss: 0.954677; batch adversarial loss: 0.784633\n",
      "epoch 5; iter: 0; batch classifier loss: 0.879266; batch adversarial loss: 0.723385\n",
      "epoch 6; iter: 0; batch classifier loss: 0.771305; batch adversarial loss: 0.682356\n",
      "epoch 7; iter: 0; batch classifier loss: 0.669809; batch adversarial loss: 0.640581\n",
      "epoch 8; iter: 0; batch classifier loss: 0.559118; batch adversarial loss: 0.649221\n",
      "epoch 9; iter: 0; batch classifier loss: 0.518790; batch adversarial loss: 0.598985\n",
      "epoch 10; iter: 0; batch classifier loss: 0.594124; batch adversarial loss: 0.563015\n",
      "epoch 11; iter: 0; batch classifier loss: 0.524852; batch adversarial loss: 0.584122\n",
      "epoch 12; iter: 0; batch classifier loss: 0.531204; batch adversarial loss: 0.573192\n",
      "epoch 13; iter: 0; batch classifier loss: 0.482400; batch adversarial loss: 0.594955\n",
      "epoch 14; iter: 0; batch classifier loss: 0.558889; batch adversarial loss: 0.558422\n",
      "epoch 15; iter: 0; batch classifier loss: 0.537365; batch adversarial loss: 0.530591\n",
      "epoch 16; iter: 0; batch classifier loss: 0.466733; batch adversarial loss: 0.519104\n",
      "epoch 17; iter: 0; batch classifier loss: 0.483117; batch adversarial loss: 0.560211\n",
      "epoch 18; iter: 0; batch classifier loss: 0.517432; batch adversarial loss: 0.490346\n",
      "epoch 19; iter: 0; batch classifier loss: 0.530101; batch adversarial loss: 0.536802\n",
      "epoch 20; iter: 0; batch classifier loss: 0.480083; batch adversarial loss: 0.461658\n",
      "epoch 21; iter: 0; batch classifier loss: 0.512330; batch adversarial loss: 0.518327\n",
      "epoch 22; iter: 0; batch classifier loss: 0.446460; batch adversarial loss: 0.508013\n",
      "epoch 23; iter: 0; batch classifier loss: 0.442652; batch adversarial loss: 0.563860\n",
      "epoch 24; iter: 0; batch classifier loss: 0.505942; batch adversarial loss: 0.610578\n",
      "epoch 25; iter: 0; batch classifier loss: 0.490328; batch adversarial loss: 0.551594\n",
      "epoch 26; iter: 0; batch classifier loss: 0.517486; batch adversarial loss: 0.553678\n",
      "epoch 27; iter: 0; batch classifier loss: 0.533027; batch adversarial loss: 0.570348\n",
      "epoch 28; iter: 0; batch classifier loss: 0.514615; batch adversarial loss: 0.549907\n",
      "epoch 29; iter: 0; batch classifier loss: 0.464300; batch adversarial loss: 0.565032\n",
      "epoch 30; iter: 0; batch classifier loss: 0.425358; batch adversarial loss: 0.554751\n",
      "epoch 31; iter: 0; batch classifier loss: 0.549282; batch adversarial loss: 0.560439\n",
      "epoch 32; iter: 0; batch classifier loss: 0.582576; batch adversarial loss: 0.473856\n",
      "epoch 33; iter: 0; batch classifier loss: 0.421335; batch adversarial loss: 0.615182\n",
      "epoch 34; iter: 0; batch classifier loss: 0.414742; batch adversarial loss: 0.467023\n",
      "epoch 35; iter: 0; batch classifier loss: 0.468918; batch adversarial loss: 0.563101\n",
      "epoch 36; iter: 0; batch classifier loss: 0.430902; batch adversarial loss: 0.522030\n",
      "epoch 37; iter: 0; batch classifier loss: 0.494589; batch adversarial loss: 0.491842\n",
      "epoch 38; iter: 0; batch classifier loss: 0.535890; batch adversarial loss: 0.606593\n",
      "epoch 39; iter: 0; batch classifier loss: 0.452435; batch adversarial loss: 0.529794\n",
      "epoch 40; iter: 0; batch classifier loss: 0.467348; batch adversarial loss: 0.563342\n",
      "epoch 41; iter: 0; batch classifier loss: 0.446937; batch adversarial loss: 0.557419\n",
      "epoch 42; iter: 0; batch classifier loss: 0.468680; batch adversarial loss: 0.574130\n",
      "epoch 43; iter: 0; batch classifier loss: 0.454803; batch adversarial loss: 0.572011\n",
      "epoch 44; iter: 0; batch classifier loss: 0.453196; batch adversarial loss: 0.474239\n",
      "epoch 45; iter: 0; batch classifier loss: 0.515716; batch adversarial loss: 0.598564\n",
      "epoch 46; iter: 0; batch classifier loss: 0.436484; batch adversarial loss: 0.562167\n",
      "epoch 47; iter: 0; batch classifier loss: 0.476398; batch adversarial loss: 0.535701\n",
      "epoch 48; iter: 0; batch classifier loss: 0.423583; batch adversarial loss: 0.537806\n",
      "epoch 49; iter: 0; batch classifier loss: 0.396875; batch adversarial loss: 0.561100\n",
      "epoch 50; iter: 0; batch classifier loss: 0.484253; batch adversarial loss: 0.570197\n",
      "epoch 51; iter: 0; batch classifier loss: 0.384806; batch adversarial loss: 0.571886\n",
      "epoch 52; iter: 0; batch classifier loss: 0.502067; batch adversarial loss: 0.500748\n",
      "epoch 53; iter: 0; batch classifier loss: 0.443936; batch adversarial loss: 0.553673\n",
      "epoch 54; iter: 0; batch classifier loss: 0.422339; batch adversarial loss: 0.553871\n",
      "epoch 55; iter: 0; batch classifier loss: 0.406876; batch adversarial loss: 0.589923\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 56; iter: 0; batch classifier loss: 0.440671; batch adversarial loss: 0.526677\n",
      "epoch 57; iter: 0; batch classifier loss: 0.433650; batch adversarial loss: 0.462315\n",
      "epoch 58; iter: 0; batch classifier loss: 0.402150; batch adversarial loss: 0.580799\n",
      "epoch 59; iter: 0; batch classifier loss: 0.422036; batch adversarial loss: 0.489749\n",
      "epoch 60; iter: 0; batch classifier loss: 0.398598; batch adversarial loss: 0.499225\n",
      "epoch 61; iter: 0; batch classifier loss: 0.425059; batch adversarial loss: 0.571798\n",
      "epoch 62; iter: 0; batch classifier loss: 0.422754; batch adversarial loss: 0.534745\n",
      "epoch 63; iter: 0; batch classifier loss: 0.411315; batch adversarial loss: 0.616803\n",
      "epoch 64; iter: 0; batch classifier loss: 0.369209; batch adversarial loss: 0.525688\n",
      "epoch 65; iter: 0; batch classifier loss: 0.325513; batch adversarial loss: 0.562608\n",
      "epoch 66; iter: 0; batch classifier loss: 0.475976; batch adversarial loss: 0.552998\n",
      "epoch 67; iter: 0; batch classifier loss: 0.435485; batch adversarial loss: 0.489830\n",
      "epoch 68; iter: 0; batch classifier loss: 0.379744; batch adversarial loss: 0.571450\n",
      "epoch 69; iter: 0; batch classifier loss: 0.484555; batch adversarial loss: 0.644936\n",
      "epoch 70; iter: 0; batch classifier loss: 0.422253; batch adversarial loss: 0.525587\n",
      "epoch 71; iter: 0; batch classifier loss: 0.391788; batch adversarial loss: 0.545826\n",
      "epoch 72; iter: 0; batch classifier loss: 0.401281; batch adversarial loss: 0.554803\n",
      "epoch 73; iter: 0; batch classifier loss: 0.401524; batch adversarial loss: 0.618419\n",
      "epoch 74; iter: 0; batch classifier loss: 0.392705; batch adversarial loss: 0.535912\n",
      "epoch 75; iter: 0; batch classifier loss: 0.443801; batch adversarial loss: 0.570513\n",
      "epoch 76; iter: 0; batch classifier loss: 0.410431; batch adversarial loss: 0.580386\n",
      "epoch 77; iter: 0; batch classifier loss: 0.296252; batch adversarial loss: 0.569559\n",
      "epoch 78; iter: 0; batch classifier loss: 0.376644; batch adversarial loss: 0.514478\n",
      "epoch 79; iter: 0; batch classifier loss: 0.300427; batch adversarial loss: 0.546520\n",
      "epoch 80; iter: 0; batch classifier loss: 0.369038; batch adversarial loss: 0.527763\n",
      "epoch 81; iter: 0; batch classifier loss: 0.389657; batch adversarial loss: 0.460261\n",
      "epoch 82; iter: 0; batch classifier loss: 0.372693; batch adversarial loss: 0.522316\n",
      "epoch 83; iter: 0; batch classifier loss: 0.413597; batch adversarial loss: 0.478387\n",
      "epoch 84; iter: 0; batch classifier loss: 0.385894; batch adversarial loss: 0.541426\n",
      "epoch 85; iter: 0; batch classifier loss: 0.437006; batch adversarial loss: 0.499453\n",
      "epoch 86; iter: 0; batch classifier loss: 0.370849; batch adversarial loss: 0.535226\n",
      "epoch 87; iter: 0; batch classifier loss: 0.396290; batch adversarial loss: 0.525965\n",
      "epoch 88; iter: 0; batch classifier loss: 0.422771; batch adversarial loss: 0.536408\n",
      "epoch 89; iter: 0; batch classifier loss: 0.409713; batch adversarial loss: 0.535542\n",
      "epoch 90; iter: 0; batch classifier loss: 0.394928; batch adversarial loss: 0.608347\n",
      "epoch 91; iter: 0; batch classifier loss: 0.363858; batch adversarial loss: 0.578585\n",
      "epoch 92; iter: 0; batch classifier loss: 0.414244; batch adversarial loss: 0.543860\n",
      "epoch 93; iter: 0; batch classifier loss: 0.374620; batch adversarial loss: 0.544683\n",
      "epoch 94; iter: 0; batch classifier loss: 0.431670; batch adversarial loss: 0.569037\n",
      "epoch 95; iter: 0; batch classifier loss: 0.347814; batch adversarial loss: 0.547139\n",
      "epoch 96; iter: 0; batch classifier loss: 0.391053; batch adversarial loss: 0.603459\n",
      "epoch 97; iter: 0; batch classifier loss: 0.405720; batch adversarial loss: 0.524671\n",
      "epoch 98; iter: 0; batch classifier loss: 0.308919; batch adversarial loss: 0.593336\n",
      "epoch 99; iter: 0; batch classifier loss: 0.438277; batch adversarial loss: 0.409600\n",
      "epoch 100; iter: 0; batch classifier loss: 0.313130; batch adversarial loss: 0.559896\n",
      "epoch 101; iter: 0; batch classifier loss: 0.336020; batch adversarial loss: 0.579970\n",
      "epoch 102; iter: 0; batch classifier loss: 0.394190; batch adversarial loss: 0.514071\n",
      "epoch 103; iter: 0; batch classifier loss: 0.442519; batch adversarial loss: 0.545324\n",
      "epoch 104; iter: 0; batch classifier loss: 0.376346; batch adversarial loss: 0.529400\n",
      "epoch 105; iter: 0; batch classifier loss: 0.351458; batch adversarial loss: 0.543610\n",
      "epoch 106; iter: 0; batch classifier loss: 0.357812; batch adversarial loss: 0.476811\n",
      "epoch 107; iter: 0; batch classifier loss: 0.381835; batch adversarial loss: 0.489498\n",
      "epoch 108; iter: 0; batch classifier loss: 0.405334; batch adversarial loss: 0.616947\n",
      "epoch 109; iter: 0; batch classifier loss: 0.404526; batch adversarial loss: 0.497997\n",
      "epoch 110; iter: 0; batch classifier loss: 0.403672; batch adversarial loss: 0.568732\n",
      "epoch 111; iter: 0; batch classifier loss: 0.454126; batch adversarial loss: 0.533260\n",
      "epoch 112; iter: 0; batch classifier loss: 0.353003; batch adversarial loss: 0.489729\n",
      "epoch 113; iter: 0; batch classifier loss: 0.328233; batch adversarial loss: 0.541351\n",
      "epoch 114; iter: 0; batch classifier loss: 0.360391; batch adversarial loss: 0.518314\n",
      "epoch 115; iter: 0; batch classifier loss: 0.383842; batch adversarial loss: 0.589095\n",
      "epoch 116; iter: 0; batch classifier loss: 0.400416; batch adversarial loss: 0.566777\n",
      "epoch 117; iter: 0; batch classifier loss: 0.318199; batch adversarial loss: 0.589271\n",
      "epoch 118; iter: 0; batch classifier loss: 0.337192; batch adversarial loss: 0.505823\n",
      "epoch 119; iter: 0; batch classifier loss: 0.357919; batch adversarial loss: 0.496189\n",
      "epoch 120; iter: 0; batch classifier loss: 0.338818; batch adversarial loss: 0.537234\n",
      "epoch 121; iter: 0; batch classifier loss: 0.392322; batch adversarial loss: 0.547826\n",
      "epoch 122; iter: 0; batch classifier loss: 0.410603; batch adversarial loss: 0.528136\n",
      "epoch 123; iter: 0; batch classifier loss: 0.425628; batch adversarial loss: 0.533940\n",
      "epoch 124; iter: 0; batch classifier loss: 0.274615; batch adversarial loss: 0.571843\n",
      "epoch 125; iter: 0; batch classifier loss: 0.345945; batch adversarial loss: 0.561987\n",
      "epoch 126; iter: 0; batch classifier loss: 0.340996; batch adversarial loss: 0.561481\n",
      "epoch 127; iter: 0; batch classifier loss: 0.317052; batch adversarial loss: 0.515354\n",
      "epoch 128; iter: 0; batch classifier loss: 0.329884; batch adversarial loss: 0.625999\n",
      "epoch 129; iter: 0; batch classifier loss: 0.306200; batch adversarial loss: 0.690398\n",
      "epoch 130; iter: 0; batch classifier loss: 0.283119; batch adversarial loss: 0.586265\n",
      "epoch 131; iter: 0; batch classifier loss: 0.349238; batch adversarial loss: 0.525134\n",
      "epoch 132; iter: 0; batch classifier loss: 0.378305; batch adversarial loss: 0.452878\n",
      "epoch 133; iter: 0; batch classifier loss: 0.346734; batch adversarial loss: 0.496639\n",
      "epoch 134; iter: 0; batch classifier loss: 0.372490; batch adversarial loss: 0.482969\n",
      "epoch 135; iter: 0; batch classifier loss: 0.400099; batch adversarial loss: 0.535841\n",
      "epoch 136; iter: 0; batch classifier loss: 0.364867; batch adversarial loss: 0.580003\n",
      "epoch 137; iter: 0; batch classifier loss: 0.281599; batch adversarial loss: 0.531389\n",
      "epoch 138; iter: 0; batch classifier loss: 0.369080; batch adversarial loss: 0.569054\n",
      "epoch 139; iter: 0; batch classifier loss: 0.348107; batch adversarial loss: 0.570923\n",
      "epoch 140; iter: 0; batch classifier loss: 0.278099; batch adversarial loss: 0.576516\n",
      "epoch 141; iter: 0; batch classifier loss: 0.435935; batch adversarial loss: 0.553371\n",
      "epoch 142; iter: 0; batch classifier loss: 0.363264; batch adversarial loss: 0.608933\n",
      "epoch 143; iter: 0; batch classifier loss: 0.345436; batch adversarial loss: 0.573637\n",
      "epoch 144; iter: 0; batch classifier loss: 0.380321; batch adversarial loss: 0.487863\n",
      "epoch 145; iter: 0; batch classifier loss: 0.380401; batch adversarial loss: 0.498856\n",
      "epoch 146; iter: 0; batch classifier loss: 0.243899; batch adversarial loss: 0.535404\n",
      "epoch 147; iter: 0; batch classifier loss: 0.412614; batch adversarial loss: 0.556707\n",
      "epoch 148; iter: 0; batch classifier loss: 0.334899; batch adversarial loss: 0.596542\n",
      "epoch 149; iter: 0; batch classifier loss: 0.363449; batch adversarial loss: 0.544098\n",
      "epoch 150; iter: 0; batch classifier loss: 0.312849; batch adversarial loss: 0.522837\n",
      "epoch 151; iter: 0; batch classifier loss: 0.309232; batch adversarial loss: 0.553153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 152; iter: 0; batch classifier loss: 0.344438; batch adversarial loss: 0.526929\n",
      "epoch 153; iter: 0; batch classifier loss: 0.436659; batch adversarial loss: 0.591819\n",
      "epoch 154; iter: 0; batch classifier loss: 0.298441; batch adversarial loss: 0.524375\n",
      "epoch 155; iter: 0; batch classifier loss: 0.346610; batch adversarial loss: 0.478847\n",
      "epoch 156; iter: 0; batch classifier loss: 0.335015; batch adversarial loss: 0.560641\n",
      "epoch 157; iter: 0; batch classifier loss: 0.396650; batch adversarial loss: 0.524945\n",
      "epoch 158; iter: 0; batch classifier loss: 0.319886; batch adversarial loss: 0.497228\n",
      "epoch 159; iter: 0; batch classifier loss: 0.423595; batch adversarial loss: 0.599410\n",
      "epoch 160; iter: 0; batch classifier loss: 0.344430; batch adversarial loss: 0.545060\n",
      "epoch 161; iter: 0; batch classifier loss: 0.372135; batch adversarial loss: 0.522710\n",
      "epoch 162; iter: 0; batch classifier loss: 0.317970; batch adversarial loss: 0.548211\n",
      "epoch 163; iter: 0; batch classifier loss: 0.352866; batch adversarial loss: 0.572245\n",
      "epoch 164; iter: 0; batch classifier loss: 0.339050; batch adversarial loss: 0.601262\n",
      "epoch 165; iter: 0; batch classifier loss: 0.347112; batch adversarial loss: 0.573521\n",
      "epoch 166; iter: 0; batch classifier loss: 0.361254; batch adversarial loss: 0.623459\n",
      "epoch 167; iter: 0; batch classifier loss: 0.302046; batch adversarial loss: 0.614148\n",
      "epoch 168; iter: 0; batch classifier loss: 0.309989; batch adversarial loss: 0.564736\n",
      "epoch 169; iter: 0; batch classifier loss: 0.319934; batch adversarial loss: 0.541547\n",
      "epoch 170; iter: 0; batch classifier loss: 0.327831; batch adversarial loss: 0.557232\n",
      "epoch 171; iter: 0; batch classifier loss: 0.369132; batch adversarial loss: 0.549702\n",
      "epoch 172; iter: 0; batch classifier loss: 0.287425; batch adversarial loss: 0.491556\n",
      "epoch 173; iter: 0; batch classifier loss: 0.398287; batch adversarial loss: 0.498248\n",
      "epoch 174; iter: 0; batch classifier loss: 0.379828; batch adversarial loss: 0.532523\n",
      "epoch 175; iter: 0; batch classifier loss: 0.452619; batch adversarial loss: 0.538503\n",
      "epoch 176; iter: 0; batch classifier loss: 0.337695; batch adversarial loss: 0.583290\n",
      "epoch 177; iter: 0; batch classifier loss: 0.355038; batch adversarial loss: 0.562080\n",
      "epoch 178; iter: 0; batch classifier loss: 0.252203; batch adversarial loss: 0.542027\n",
      "epoch 179; iter: 0; batch classifier loss: 0.291398; batch adversarial loss: 0.553680\n",
      "epoch 180; iter: 0; batch classifier loss: 0.336551; batch adversarial loss: 0.560212\n",
      "epoch 181; iter: 0; batch classifier loss: 0.321521; batch adversarial loss: 0.632155\n",
      "epoch 182; iter: 0; batch classifier loss: 0.304758; batch adversarial loss: 0.544041\n",
      "epoch 183; iter: 0; batch classifier loss: 0.354306; batch adversarial loss: 0.499109\n",
      "epoch 184; iter: 0; batch classifier loss: 0.373475; batch adversarial loss: 0.568347\n",
      "epoch 185; iter: 0; batch classifier loss: 0.329114; batch adversarial loss: 0.654877\n",
      "epoch 186; iter: 0; batch classifier loss: 0.366565; batch adversarial loss: 0.546105\n",
      "epoch 187; iter: 0; batch classifier loss: 0.376800; batch adversarial loss: 0.528761\n",
      "epoch 188; iter: 0; batch classifier loss: 0.377796; batch adversarial loss: 0.524951\n",
      "epoch 189; iter: 0; batch classifier loss: 0.330069; batch adversarial loss: 0.623342\n",
      "epoch 190; iter: 0; batch classifier loss: 0.315432; batch adversarial loss: 0.560069\n",
      "epoch 191; iter: 0; batch classifier loss: 0.306099; batch adversarial loss: 0.589925\n",
      "epoch 192; iter: 0; batch classifier loss: 0.305190; batch adversarial loss: 0.548228\n",
      "epoch 193; iter: 0; batch classifier loss: 0.320894; batch adversarial loss: 0.634921\n",
      "epoch 194; iter: 0; batch classifier loss: 0.402524; batch adversarial loss: 0.508704\n",
      "epoch 195; iter: 0; batch classifier loss: 0.406430; batch adversarial loss: 0.498970\n",
      "epoch 196; iter: 0; batch classifier loss: 0.320469; batch adversarial loss: 0.505251\n",
      "epoch 197; iter: 0; batch classifier loss: 0.308092; batch adversarial loss: 0.545262\n",
      "epoch 198; iter: 0; batch classifier loss: 0.354266; batch adversarial loss: 0.478405\n",
      "epoch 199; iter: 0; batch classifier loss: 0.308778; batch adversarial loss: 0.607340\n",
      "epoch 0; iter: 0; batch classifier loss: 0.702342; batch adversarial loss: 0.811140\n",
      "epoch 1; iter: 0; batch classifier loss: 0.793216; batch adversarial loss: 0.854219\n",
      "epoch 2; iter: 0; batch classifier loss: 0.682945; batch adversarial loss: 0.814573\n",
      "epoch 3; iter: 0; batch classifier loss: 0.585186; batch adversarial loss: 0.729160\n",
      "epoch 4; iter: 0; batch classifier loss: 0.539293; batch adversarial loss: 0.692951\n",
      "epoch 5; iter: 0; batch classifier loss: 0.540179; batch adversarial loss: 0.644560\n",
      "epoch 6; iter: 0; batch classifier loss: 0.539695; batch adversarial loss: 0.638114\n",
      "epoch 7; iter: 0; batch classifier loss: 0.515974; batch adversarial loss: 0.632477\n",
      "epoch 8; iter: 0; batch classifier loss: 0.563707; batch adversarial loss: 0.616778\n",
      "epoch 9; iter: 0; batch classifier loss: 0.532652; batch adversarial loss: 0.626106\n",
      "epoch 10; iter: 0; batch classifier loss: 0.511113; batch adversarial loss: 0.607770\n",
      "epoch 11; iter: 0; batch classifier loss: 0.525285; batch adversarial loss: 0.602759\n",
      "epoch 12; iter: 0; batch classifier loss: 0.578966; batch adversarial loss: 0.628999\n",
      "epoch 13; iter: 0; batch classifier loss: 0.479331; batch adversarial loss: 0.566174\n",
      "epoch 14; iter: 0; batch classifier loss: 0.486928; batch adversarial loss: 0.609737\n",
      "epoch 15; iter: 0; batch classifier loss: 0.541264; batch adversarial loss: 0.555120\n",
      "epoch 16; iter: 0; batch classifier loss: 0.521181; batch adversarial loss: 0.608173\n",
      "epoch 17; iter: 0; batch classifier loss: 0.499819; batch adversarial loss: 0.518067\n",
      "epoch 18; iter: 0; batch classifier loss: 0.523692; batch adversarial loss: 0.579869\n",
      "epoch 19; iter: 0; batch classifier loss: 0.463337; batch adversarial loss: 0.538797\n",
      "epoch 20; iter: 0; batch classifier loss: 0.463807; batch adversarial loss: 0.607977\n",
      "epoch 21; iter: 0; batch classifier loss: 0.477059; batch adversarial loss: 0.541966\n",
      "epoch 22; iter: 0; batch classifier loss: 0.492656; batch adversarial loss: 0.554088\n",
      "epoch 23; iter: 0; batch classifier loss: 0.456409; batch adversarial loss: 0.534288\n",
      "epoch 24; iter: 0; batch classifier loss: 0.562877; batch adversarial loss: 0.549147\n",
      "epoch 25; iter: 0; batch classifier loss: 0.376166; batch adversarial loss: 0.552033\n",
      "epoch 26; iter: 0; batch classifier loss: 0.522046; batch adversarial loss: 0.591743\n",
      "epoch 27; iter: 0; batch classifier loss: 0.505164; batch adversarial loss: 0.604191\n",
      "epoch 28; iter: 0; batch classifier loss: 0.496847; batch adversarial loss: 0.567799\n",
      "epoch 29; iter: 0; batch classifier loss: 0.524534; batch adversarial loss: 0.542908\n",
      "epoch 30; iter: 0; batch classifier loss: 0.479861; batch adversarial loss: 0.520283\n",
      "epoch 31; iter: 0; batch classifier loss: 0.500738; batch adversarial loss: 0.553943\n",
      "epoch 32; iter: 0; batch classifier loss: 0.459462; batch adversarial loss: 0.551914\n",
      "epoch 33; iter: 0; batch classifier loss: 0.519594; batch adversarial loss: 0.584400\n",
      "epoch 34; iter: 0; batch classifier loss: 0.505998; batch adversarial loss: 0.520814\n",
      "epoch 35; iter: 0; batch classifier loss: 0.444813; batch adversarial loss: 0.479358\n",
      "epoch 36; iter: 0; batch classifier loss: 0.449010; batch adversarial loss: 0.621032\n",
      "epoch 37; iter: 0; batch classifier loss: 0.486726; batch adversarial loss: 0.564013\n",
      "epoch 38; iter: 0; batch classifier loss: 0.542410; batch adversarial loss: 0.511156\n",
      "epoch 39; iter: 0; batch classifier loss: 0.432665; batch adversarial loss: 0.546407\n",
      "epoch 40; iter: 0; batch classifier loss: 0.396348; batch adversarial loss: 0.519674\n",
      "epoch 41; iter: 0; batch classifier loss: 0.467727; batch adversarial loss: 0.616245\n",
      "epoch 42; iter: 0; batch classifier loss: 0.412128; batch adversarial loss: 0.622818\n",
      "epoch 43; iter: 0; batch classifier loss: 0.415250; batch adversarial loss: 0.639575\n",
      "epoch 44; iter: 0; batch classifier loss: 0.488527; batch adversarial loss: 0.544576\n",
      "epoch 45; iter: 0; batch classifier loss: 0.456779; batch adversarial loss: 0.594798\n",
      "epoch 46; iter: 0; batch classifier loss: 0.447365; batch adversarial loss: 0.519911\n",
      "epoch 47; iter: 0; batch classifier loss: 0.442271; batch adversarial loss: 0.554390\n",
      "epoch 48; iter: 0; batch classifier loss: 0.387014; batch adversarial loss: 0.519309\n",
      "epoch 49; iter: 0; batch classifier loss: 0.393573; batch adversarial loss: 0.570810\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 50; iter: 0; batch classifier loss: 0.454169; batch adversarial loss: 0.527990\n",
      "epoch 51; iter: 0; batch classifier loss: 0.394108; batch adversarial loss: 0.589288\n",
      "epoch 52; iter: 0; batch classifier loss: 0.455354; batch adversarial loss: 0.535668\n",
      "epoch 53; iter: 0; batch classifier loss: 0.455973; batch adversarial loss: 0.483949\n",
      "epoch 54; iter: 0; batch classifier loss: 0.450590; batch adversarial loss: 0.579916\n",
      "epoch 55; iter: 0; batch classifier loss: 0.418482; batch adversarial loss: 0.589140\n",
      "epoch 56; iter: 0; batch classifier loss: 0.391573; batch adversarial loss: 0.544923\n",
      "epoch 57; iter: 0; batch classifier loss: 0.457916; batch adversarial loss: 0.571446\n",
      "epoch 58; iter: 0; batch classifier loss: 0.381108; batch adversarial loss: 0.482723\n",
      "epoch 59; iter: 0; batch classifier loss: 0.481979; batch adversarial loss: 0.588907\n",
      "epoch 60; iter: 0; batch classifier loss: 0.305960; batch adversarial loss: 0.509072\n",
      "epoch 61; iter: 0; batch classifier loss: 0.444867; batch adversarial loss: 0.562291\n",
      "epoch 62; iter: 0; batch classifier loss: 0.380200; batch adversarial loss: 0.562571\n",
      "epoch 63; iter: 0; batch classifier loss: 0.392746; batch adversarial loss: 0.535788\n",
      "epoch 64; iter: 0; batch classifier loss: 0.408174; batch adversarial loss: 0.517931\n",
      "epoch 65; iter: 0; batch classifier loss: 0.377655; batch adversarial loss: 0.597999\n",
      "epoch 66; iter: 0; batch classifier loss: 0.386814; batch adversarial loss: 0.535635\n",
      "epoch 67; iter: 0; batch classifier loss: 0.470080; batch adversarial loss: 0.580304\n",
      "epoch 68; iter: 0; batch classifier loss: 0.353538; batch adversarial loss: 0.571476\n",
      "epoch 69; iter: 0; batch classifier loss: 0.406250; batch adversarial loss: 0.615798\n",
      "epoch 70; iter: 0; batch classifier loss: 0.396857; batch adversarial loss: 0.526545\n",
      "epoch 71; iter: 0; batch classifier loss: 0.351202; batch adversarial loss: 0.644002\n",
      "epoch 72; iter: 0; batch classifier loss: 0.427710; batch adversarial loss: 0.535347\n",
      "epoch 73; iter: 0; batch classifier loss: 0.408339; batch adversarial loss: 0.552913\n",
      "epoch 74; iter: 0; batch classifier loss: 0.365858; batch adversarial loss: 0.563372\n",
      "epoch 75; iter: 0; batch classifier loss: 0.373552; batch adversarial loss: 0.562194\n",
      "epoch 76; iter: 0; batch classifier loss: 0.425172; batch adversarial loss: 0.553688\n",
      "epoch 77; iter: 0; batch classifier loss: 0.400478; batch adversarial loss: 0.456004\n",
      "epoch 78; iter: 0; batch classifier loss: 0.360738; batch adversarial loss: 0.563072\n",
      "epoch 79; iter: 0; batch classifier loss: 0.400914; batch adversarial loss: 0.473488\n",
      "epoch 80; iter: 0; batch classifier loss: 0.418364; batch adversarial loss: 0.553180\n",
      "epoch 81; iter: 0; batch classifier loss: 0.481262; batch adversarial loss: 0.500546\n",
      "epoch 82; iter: 0; batch classifier loss: 0.440725; batch adversarial loss: 0.535586\n",
      "epoch 83; iter: 0; batch classifier loss: 0.422649; batch adversarial loss: 0.633292\n",
      "epoch 84; iter: 0; batch classifier loss: 0.339504; batch adversarial loss: 0.650382\n",
      "epoch 85; iter: 0; batch classifier loss: 0.357115; batch adversarial loss: 0.553570\n",
      "epoch 86; iter: 0; batch classifier loss: 0.346125; batch adversarial loss: 0.517929\n",
      "epoch 87; iter: 0; batch classifier loss: 0.352007; batch adversarial loss: 0.491677\n",
      "epoch 88; iter: 0; batch classifier loss: 0.359564; batch adversarial loss: 0.597845\n",
      "epoch 89; iter: 0; batch classifier loss: 0.391643; batch adversarial loss: 0.534874\n",
      "epoch 90; iter: 0; batch classifier loss: 0.375264; batch adversarial loss: 0.543767\n",
      "epoch 91; iter: 0; batch classifier loss: 0.393135; batch adversarial loss: 0.533619\n",
      "epoch 92; iter: 0; batch classifier loss: 0.359060; batch adversarial loss: 0.581923\n",
      "epoch 93; iter: 0; batch classifier loss: 0.407726; batch adversarial loss: 0.545079\n",
      "epoch 94; iter: 0; batch classifier loss: 0.330689; batch adversarial loss: 0.581901\n",
      "epoch 95; iter: 0; batch classifier loss: 0.398485; batch adversarial loss: 0.570750\n",
      "epoch 96; iter: 0; batch classifier loss: 0.375708; batch adversarial loss: 0.553857\n",
      "epoch 97; iter: 0; batch classifier loss: 0.320297; batch adversarial loss: 0.535041\n",
      "epoch 98; iter: 0; batch classifier loss: 0.386799; batch adversarial loss: 0.606673\n",
      "epoch 99; iter: 0; batch classifier loss: 0.403240; batch adversarial loss: 0.491401\n",
      "epoch 100; iter: 0; batch classifier loss: 0.445181; batch adversarial loss: 0.535659\n",
      "epoch 101; iter: 0; batch classifier loss: 0.384854; batch adversarial loss: 0.474135\n",
      "epoch 102; iter: 0; batch classifier loss: 0.359587; batch adversarial loss: 0.544619\n",
      "epoch 103; iter: 0; batch classifier loss: 0.453721; batch adversarial loss: 0.510690\n",
      "epoch 104; iter: 0; batch classifier loss: 0.424810; batch adversarial loss: 0.509646\n",
      "epoch 105; iter: 0; batch classifier loss: 0.346534; batch adversarial loss: 0.613752\n",
      "epoch 106; iter: 0; batch classifier loss: 0.412320; batch adversarial loss: 0.597119\n",
      "epoch 107; iter: 0; batch classifier loss: 0.310176; batch adversarial loss: 0.607558\n",
      "epoch 108; iter: 0; batch classifier loss: 0.372399; batch adversarial loss: 0.500884\n",
      "epoch 109; iter: 0; batch classifier loss: 0.347775; batch adversarial loss: 0.518639\n",
      "epoch 110; iter: 0; batch classifier loss: 0.266076; batch adversarial loss: 0.588864\n",
      "epoch 111; iter: 0; batch classifier loss: 0.398525; batch adversarial loss: 0.456558\n",
      "epoch 112; iter: 0; batch classifier loss: 0.367807; batch adversarial loss: 0.597966\n",
      "epoch 113; iter: 0; batch classifier loss: 0.419951; batch adversarial loss: 0.633697\n",
      "epoch 114; iter: 0; batch classifier loss: 0.382360; batch adversarial loss: 0.642569\n",
      "epoch 115; iter: 0; batch classifier loss: 0.420988; batch adversarial loss: 0.553250\n",
      "epoch 116; iter: 0; batch classifier loss: 0.404184; batch adversarial loss: 0.553211\n",
      "epoch 117; iter: 0; batch classifier loss: 0.399959; batch adversarial loss: 0.536017\n",
      "epoch 118; iter: 0; batch classifier loss: 0.416781; batch adversarial loss: 0.553602\n",
      "epoch 119; iter: 0; batch classifier loss: 0.302321; batch adversarial loss: 0.633925\n",
      "epoch 120; iter: 0; batch classifier loss: 0.442399; batch adversarial loss: 0.464371\n",
      "epoch 121; iter: 0; batch classifier loss: 0.444675; batch adversarial loss: 0.589423\n",
      "epoch 122; iter: 0; batch classifier loss: 0.317928; batch adversarial loss: 0.598106\n",
      "epoch 123; iter: 0; batch classifier loss: 0.352252; batch adversarial loss: 0.518334\n",
      "epoch 124; iter: 0; batch classifier loss: 0.371382; batch adversarial loss: 0.633270\n",
      "epoch 125; iter: 0; batch classifier loss: 0.393654; batch adversarial loss: 0.500352\n",
      "epoch 126; iter: 0; batch classifier loss: 0.390523; batch adversarial loss: 0.597669\n",
      "epoch 127; iter: 0; batch classifier loss: 0.381445; batch adversarial loss: 0.518142\n",
      "epoch 128; iter: 0; batch classifier loss: 0.399218; batch adversarial loss: 0.562729\n",
      "epoch 129; iter: 0; batch classifier loss: 0.394320; batch adversarial loss: 0.527215\n",
      "epoch 130; iter: 0; batch classifier loss: 0.418462; batch adversarial loss: 0.544933\n",
      "epoch 131; iter: 0; batch classifier loss: 0.377869; batch adversarial loss: 0.615792\n",
      "epoch 132; iter: 0; batch classifier loss: 0.458584; batch adversarial loss: 0.562188\n",
      "epoch 133; iter: 0; batch classifier loss: 0.371878; batch adversarial loss: 0.553597\n",
      "epoch 134; iter: 0; batch classifier loss: 0.296752; batch adversarial loss: 0.518153\n",
      "epoch 135; iter: 0; batch classifier loss: 0.370822; batch adversarial loss: 0.509404\n",
      "epoch 136; iter: 0; batch classifier loss: 0.409247; batch adversarial loss: 0.482220\n",
      "epoch 137; iter: 0; batch classifier loss: 0.443858; batch adversarial loss: 0.500259\n",
      "epoch 138; iter: 0; batch classifier loss: 0.405221; batch adversarial loss: 0.580394\n",
      "epoch 139; iter: 0; batch classifier loss: 0.326507; batch adversarial loss: 0.518103\n",
      "epoch 140; iter: 0; batch classifier loss: 0.345143; batch adversarial loss: 0.491271\n",
      "epoch 141; iter: 0; batch classifier loss: 0.390618; batch adversarial loss: 0.500107\n",
      "epoch 142; iter: 0; batch classifier loss: 0.353363; batch adversarial loss: 0.509146\n",
      "epoch 143; iter: 0; batch classifier loss: 0.393478; batch adversarial loss: 0.535708\n",
      "epoch 144; iter: 0; batch classifier loss: 0.326235; batch adversarial loss: 0.615851\n",
      "epoch 145; iter: 0; batch classifier loss: 0.382173; batch adversarial loss: 0.598064\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 146; iter: 0; batch classifier loss: 0.375680; batch adversarial loss: 0.571328\n",
      "epoch 147; iter: 0; batch classifier loss: 0.359576; batch adversarial loss: 0.491016\n",
      "epoch 148; iter: 0; batch classifier loss: 0.353921; batch adversarial loss: 0.518512\n",
      "epoch 149; iter: 0; batch classifier loss: 0.341618; batch adversarial loss: 0.491528\n",
      "epoch 150; iter: 0; batch classifier loss: 0.229891; batch adversarial loss: 0.562125\n",
      "epoch 151; iter: 0; batch classifier loss: 0.426250; batch adversarial loss: 0.571635\n",
      "epoch 152; iter: 0; batch classifier loss: 0.403226; batch adversarial loss: 0.518380\n",
      "epoch 153; iter: 0; batch classifier loss: 0.263908; batch adversarial loss: 0.571770\n",
      "epoch 154; iter: 0; batch classifier loss: 0.369885; batch adversarial loss: 0.562647\n",
      "epoch 155; iter: 0; batch classifier loss: 0.397490; batch adversarial loss: 0.615432\n",
      "epoch 156; iter: 0; batch classifier loss: 0.387703; batch adversarial loss: 0.597625\n",
      "epoch 157; iter: 0; batch classifier loss: 0.433887; batch adversarial loss: 0.660209\n",
      "epoch 158; iter: 0; batch classifier loss: 0.355359; batch adversarial loss: 0.607000\n",
      "epoch 159; iter: 0; batch classifier loss: 0.362087; batch adversarial loss: 0.517860\n",
      "epoch 160; iter: 0; batch classifier loss: 0.339025; batch adversarial loss: 0.544455\n",
      "epoch 161; iter: 0; batch classifier loss: 0.325204; batch adversarial loss: 0.562472\n",
      "epoch 162; iter: 0; batch classifier loss: 0.305861; batch adversarial loss: 0.553594\n",
      "epoch 163; iter: 0; batch classifier loss: 0.381295; batch adversarial loss: 0.500651\n",
      "epoch 164; iter: 0; batch classifier loss: 0.354832; batch adversarial loss: 0.642190\n",
      "epoch 165; iter: 0; batch classifier loss: 0.304987; batch adversarial loss: 0.535788\n",
      "epoch 166; iter: 0; batch classifier loss: 0.355566; batch adversarial loss: 0.553483\n",
      "epoch 167; iter: 0; batch classifier loss: 0.392470; batch adversarial loss: 0.553396\n",
      "epoch 168; iter: 0; batch classifier loss: 0.327273; batch adversarial loss: 0.509139\n",
      "epoch 169; iter: 0; batch classifier loss: 0.368319; batch adversarial loss: 0.544891\n",
      "epoch 170; iter: 0; batch classifier loss: 0.369030; batch adversarial loss: 0.571384\n",
      "epoch 171; iter: 0; batch classifier loss: 0.276304; batch adversarial loss: 0.562622\n",
      "epoch 172; iter: 0; batch classifier loss: 0.318460; batch adversarial loss: 0.562679\n",
      "epoch 173; iter: 0; batch classifier loss: 0.419700; batch adversarial loss: 0.633214\n",
      "epoch 174; iter: 0; batch classifier loss: 0.356727; batch adversarial loss: 0.553430\n",
      "epoch 175; iter: 0; batch classifier loss: 0.356830; batch adversarial loss: 0.562320\n",
      "epoch 176; iter: 0; batch classifier loss: 0.338749; batch adversarial loss: 0.535846\n",
      "epoch 177; iter: 0; batch classifier loss: 0.433366; batch adversarial loss: 0.535814\n",
      "epoch 178; iter: 0; batch classifier loss: 0.350504; batch adversarial loss: 0.607119\n",
      "epoch 179; iter: 0; batch classifier loss: 0.279259; batch adversarial loss: 0.553745\n",
      "epoch 180; iter: 0; batch classifier loss: 0.376813; batch adversarial loss: 0.536065\n",
      "epoch 181; iter: 0; batch classifier loss: 0.389197; batch adversarial loss: 0.571531\n",
      "epoch 182; iter: 0; batch classifier loss: 0.429575; batch adversarial loss: 0.615579\n",
      "epoch 183; iter: 0; batch classifier loss: 0.361877; batch adversarial loss: 0.517985\n",
      "epoch 184; iter: 0; batch classifier loss: 0.247032; batch adversarial loss: 0.544735\n",
      "epoch 185; iter: 0; batch classifier loss: 0.335260; batch adversarial loss: 0.535966\n",
      "epoch 186; iter: 0; batch classifier loss: 0.348888; batch adversarial loss: 0.526913\n",
      "epoch 187; iter: 0; batch classifier loss: 0.265273; batch adversarial loss: 0.562282\n",
      "epoch 188; iter: 0; batch classifier loss: 0.366355; batch adversarial loss: 0.597576\n",
      "epoch 189; iter: 0; batch classifier loss: 0.356364; batch adversarial loss: 0.598121\n",
      "epoch 190; iter: 0; batch classifier loss: 0.384019; batch adversarial loss: 0.518215\n",
      "epoch 191; iter: 0; batch classifier loss: 0.378295; batch adversarial loss: 0.580135\n",
      "epoch 192; iter: 0; batch classifier loss: 0.368078; batch adversarial loss: 0.598574\n",
      "epoch 193; iter: 0; batch classifier loss: 0.350431; batch adversarial loss: 0.597991\n",
      "epoch 194; iter: 0; batch classifier loss: 0.385452; batch adversarial loss: 0.553455\n",
      "epoch 195; iter: 0; batch classifier loss: 0.366586; batch adversarial loss: 0.562784\n",
      "epoch 196; iter: 0; batch classifier loss: 0.338955; batch adversarial loss: 0.553670\n",
      "epoch 197; iter: 0; batch classifier loss: 0.352093; batch adversarial loss: 0.659684\n",
      "epoch 198; iter: 0; batch classifier loss: 0.368219; batch adversarial loss: 0.606678\n",
      "epoch 199; iter: 0; batch classifier loss: 0.370813; batch adversarial loss: 0.589128\n",
      "epoch 0; iter: 0; batch classifier loss: 0.706389; batch adversarial loss: 0.917013\n",
      "epoch 1; iter: 0; batch classifier loss: 0.958462; batch adversarial loss: 1.191745\n",
      "epoch 2; iter: 0; batch classifier loss: 1.019915; batch adversarial loss: 1.031963\n",
      "epoch 3; iter: 0; batch classifier loss: 1.163272; batch adversarial loss: 1.038152\n",
      "epoch 4; iter: 0; batch classifier loss: 0.958310; batch adversarial loss: 0.877790\n",
      "epoch 5; iter: 0; batch classifier loss: 1.057115; batch adversarial loss: 0.836368\n",
      "epoch 6; iter: 0; batch classifier loss: 0.746029; batch adversarial loss: 0.730216\n",
      "epoch 7; iter: 0; batch classifier loss: 0.867237; batch adversarial loss: 0.726187\n",
      "epoch 8; iter: 0; batch classifier loss: 0.674748; batch adversarial loss: 0.681183\n",
      "epoch 9; iter: 0; batch classifier loss: 0.586235; batch adversarial loss: 0.638789\n",
      "epoch 10; iter: 0; batch classifier loss: 0.502002; batch adversarial loss: 0.628002\n",
      "epoch 11; iter: 0; batch classifier loss: 0.527197; batch adversarial loss: 0.602197\n",
      "epoch 12; iter: 0; batch classifier loss: 0.572681; batch adversarial loss: 0.582316\n",
      "epoch 13; iter: 0; batch classifier loss: 0.584772; batch adversarial loss: 0.581219\n",
      "epoch 14; iter: 0; batch classifier loss: 0.532933; batch adversarial loss: 0.566833\n",
      "epoch 15; iter: 0; batch classifier loss: 0.520498; batch adversarial loss: 0.572428\n",
      "epoch 16; iter: 0; batch classifier loss: 0.478818; batch adversarial loss: 0.522038\n",
      "epoch 17; iter: 0; batch classifier loss: 0.491753; batch adversarial loss: 0.612924\n",
      "epoch 18; iter: 0; batch classifier loss: 0.494641; batch adversarial loss: 0.536863\n",
      "epoch 19; iter: 0; batch classifier loss: 0.567951; batch adversarial loss: 0.495191\n",
      "epoch 20; iter: 0; batch classifier loss: 0.491726; batch adversarial loss: 0.533461\n",
      "epoch 21; iter: 0; batch classifier loss: 0.488286; batch adversarial loss: 0.598088\n",
      "epoch 22; iter: 0; batch classifier loss: 0.487092; batch adversarial loss: 0.532850\n",
      "epoch 23; iter: 0; batch classifier loss: 0.415490; batch adversarial loss: 0.544741\n",
      "epoch 24; iter: 0; batch classifier loss: 0.466691; batch adversarial loss: 0.569512\n",
      "epoch 25; iter: 0; batch classifier loss: 0.426487; batch adversarial loss: 0.573195\n",
      "epoch 26; iter: 0; batch classifier loss: 0.409559; batch adversarial loss: 0.547874\n",
      "epoch 27; iter: 0; batch classifier loss: 0.402802; batch adversarial loss: 0.541953\n",
      "epoch 28; iter: 0; batch classifier loss: 0.425878; batch adversarial loss: 0.515217\n",
      "epoch 29; iter: 0; batch classifier loss: 0.456047; batch adversarial loss: 0.529663\n",
      "epoch 30; iter: 0; batch classifier loss: 0.445634; batch adversarial loss: 0.574578\n",
      "epoch 31; iter: 0; batch classifier loss: 0.416669; batch adversarial loss: 0.516102\n",
      "epoch 32; iter: 0; batch classifier loss: 0.436341; batch adversarial loss: 0.515898\n",
      "epoch 33; iter: 0; batch classifier loss: 0.483953; batch adversarial loss: 0.529701\n",
      "epoch 34; iter: 0; batch classifier loss: 0.453653; batch adversarial loss: 0.578399\n",
      "epoch 35; iter: 0; batch classifier loss: 0.458502; batch adversarial loss: 0.567690\n",
      "epoch 36; iter: 0; batch classifier loss: 0.399297; batch adversarial loss: 0.585742\n",
      "epoch 37; iter: 0; batch classifier loss: 0.432933; batch adversarial loss: 0.558537\n",
      "epoch 38; iter: 0; batch classifier loss: 0.481906; batch adversarial loss: 0.549558\n",
      "epoch 39; iter: 0; batch classifier loss: 0.482954; batch adversarial loss: 0.573151\n",
      "epoch 40; iter: 0; batch classifier loss: 0.441597; batch adversarial loss: 0.535635\n",
      "epoch 41; iter: 0; batch classifier loss: 0.444734; batch adversarial loss: 0.535356\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 42; iter: 0; batch classifier loss: 0.449354; batch adversarial loss: 0.527156\n",
      "epoch 43; iter: 0; batch classifier loss: 0.438255; batch adversarial loss: 0.508474\n",
      "epoch 44; iter: 0; batch classifier loss: 0.402573; batch adversarial loss: 0.575066\n",
      "epoch 45; iter: 0; batch classifier loss: 0.415702; batch adversarial loss: 0.529459\n",
      "epoch 46; iter: 0; batch classifier loss: 0.397274; batch adversarial loss: 0.535962\n",
      "epoch 47; iter: 0; batch classifier loss: 0.439011; batch adversarial loss: 0.535017\n",
      "epoch 48; iter: 0; batch classifier loss: 0.442105; batch adversarial loss: 0.527448\n",
      "epoch 49; iter: 0; batch classifier loss: 0.436278; batch adversarial loss: 0.518582\n",
      "epoch 50; iter: 0; batch classifier loss: 0.438503; batch adversarial loss: 0.489902\n",
      "epoch 51; iter: 0; batch classifier loss: 0.445273; batch adversarial loss: 0.570396\n",
      "epoch 52; iter: 0; batch classifier loss: 0.352320; batch adversarial loss: 0.600302\n",
      "epoch 53; iter: 0; batch classifier loss: 0.498834; batch adversarial loss: 0.529533\n",
      "epoch 54; iter: 0; batch classifier loss: 0.395179; batch adversarial loss: 0.555988\n",
      "epoch 55; iter: 0; batch classifier loss: 0.390084; batch adversarial loss: 0.527927\n",
      "epoch 56; iter: 0; batch classifier loss: 0.436115; batch adversarial loss: 0.535859\n",
      "epoch 57; iter: 0; batch classifier loss: 0.354467; batch adversarial loss: 0.508439\n",
      "epoch 58; iter: 0; batch classifier loss: 0.445975; batch adversarial loss: 0.509561\n",
      "epoch 59; iter: 0; batch classifier loss: 0.411179; batch adversarial loss: 0.544677\n",
      "epoch 60; iter: 0; batch classifier loss: 0.412492; batch adversarial loss: 0.555214\n",
      "epoch 61; iter: 0; batch classifier loss: 0.357347; batch adversarial loss: 0.533998\n",
      "epoch 62; iter: 0; batch classifier loss: 0.445046; batch adversarial loss: 0.572319\n",
      "epoch 63; iter: 0; batch classifier loss: 0.360435; batch adversarial loss: 0.583372\n",
      "epoch 64; iter: 0; batch classifier loss: 0.393354; batch adversarial loss: 0.543979\n",
      "epoch 65; iter: 0; batch classifier loss: 0.332652; batch adversarial loss: 0.497511\n",
      "epoch 66; iter: 0; batch classifier loss: 0.370919; batch adversarial loss: 0.439954\n",
      "epoch 67; iter: 0; batch classifier loss: 0.408572; batch adversarial loss: 0.544255\n",
      "epoch 68; iter: 0; batch classifier loss: 0.309672; batch adversarial loss: 0.572872\n",
      "epoch 69; iter: 0; batch classifier loss: 0.363509; batch adversarial loss: 0.555973\n",
      "epoch 70; iter: 0; batch classifier loss: 0.387729; batch adversarial loss: 0.544731\n",
      "epoch 71; iter: 0; batch classifier loss: 0.393857; batch adversarial loss: 0.517540\n",
      "epoch 72; iter: 0; batch classifier loss: 0.435704; batch adversarial loss: 0.582715\n",
      "epoch 73; iter: 0; batch classifier loss: 0.395547; batch adversarial loss: 0.534387\n",
      "epoch 74; iter: 0; batch classifier loss: 0.283266; batch adversarial loss: 0.563836\n",
      "epoch 75; iter: 0; batch classifier loss: 0.455422; batch adversarial loss: 0.544338\n",
      "epoch 76; iter: 0; batch classifier loss: 0.404125; batch adversarial loss: 0.553790\n",
      "epoch 77; iter: 0; batch classifier loss: 0.458076; batch adversarial loss: 0.540325\n",
      "epoch 78; iter: 0; batch classifier loss: 0.372706; batch adversarial loss: 0.588696\n",
      "epoch 79; iter: 0; batch classifier loss: 0.305819; batch adversarial loss: 0.562337\n",
      "epoch 80; iter: 0; batch classifier loss: 0.331875; batch adversarial loss: 0.594383\n",
      "epoch 81; iter: 0; batch classifier loss: 0.371320; batch adversarial loss: 0.497122\n",
      "epoch 82; iter: 0; batch classifier loss: 0.334817; batch adversarial loss: 0.502637\n",
      "epoch 83; iter: 0; batch classifier loss: 0.332081; batch adversarial loss: 0.573128\n",
      "epoch 84; iter: 0; batch classifier loss: 0.345405; batch adversarial loss: 0.646244\n",
      "epoch 85; iter: 0; batch classifier loss: 0.383598; batch adversarial loss: 0.519293\n",
      "epoch 86; iter: 0; batch classifier loss: 0.417574; batch adversarial loss: 0.524938\n",
      "epoch 87; iter: 0; batch classifier loss: 0.395982; batch adversarial loss: 0.572245\n",
      "epoch 88; iter: 0; batch classifier loss: 0.398598; batch adversarial loss: 0.627227\n",
      "epoch 89; iter: 0; batch classifier loss: 0.433063; batch adversarial loss: 0.594107\n",
      "epoch 90; iter: 0; batch classifier loss: 0.390084; batch adversarial loss: 0.564782\n",
      "epoch 91; iter: 0; batch classifier loss: 0.404506; batch adversarial loss: 0.568873\n",
      "epoch 92; iter: 0; batch classifier loss: 0.384901; batch adversarial loss: 0.569691\n",
      "epoch 93; iter: 0; batch classifier loss: 0.433748; batch adversarial loss: 0.448882\n",
      "epoch 94; iter: 0; batch classifier loss: 0.396308; batch adversarial loss: 0.487171\n",
      "epoch 95; iter: 0; batch classifier loss: 0.340315; batch adversarial loss: 0.467955\n",
      "epoch 96; iter: 0; batch classifier loss: 0.414391; batch adversarial loss: 0.517870\n",
      "epoch 97; iter: 0; batch classifier loss: 0.425017; batch adversarial loss: 0.605617\n",
      "epoch 98; iter: 0; batch classifier loss: 0.410626; batch adversarial loss: 0.520322\n",
      "epoch 99; iter: 0; batch classifier loss: 0.415241; batch adversarial loss: 0.547770\n",
      "epoch 100; iter: 0; batch classifier loss: 0.318984; batch adversarial loss: 0.571431\n",
      "epoch 101; iter: 0; batch classifier loss: 0.393290; batch adversarial loss: 0.503257\n",
      "epoch 102; iter: 0; batch classifier loss: 0.365445; batch adversarial loss: 0.556011\n",
      "epoch 103; iter: 0; batch classifier loss: 0.422181; batch adversarial loss: 0.487244\n",
      "epoch 104; iter: 0; batch classifier loss: 0.362982; batch adversarial loss: 0.572867\n",
      "epoch 105; iter: 0; batch classifier loss: 0.318840; batch adversarial loss: 0.541127\n",
      "epoch 106; iter: 0; batch classifier loss: 0.407601; batch adversarial loss: 0.542079\n",
      "epoch 107; iter: 0; batch classifier loss: 0.392639; batch adversarial loss: 0.526384\n",
      "epoch 108; iter: 0; batch classifier loss: 0.406109; batch adversarial loss: 0.543476\n",
      "epoch 109; iter: 0; batch classifier loss: 0.331201; batch adversarial loss: 0.517454\n",
      "epoch 110; iter: 0; batch classifier loss: 0.326891; batch adversarial loss: 0.507749\n",
      "epoch 111; iter: 0; batch classifier loss: 0.372394; batch adversarial loss: 0.553173\n",
      "epoch 112; iter: 0; batch classifier loss: 0.443671; batch adversarial loss: 0.515919\n",
      "epoch 113; iter: 0; batch classifier loss: 0.348473; batch adversarial loss: 0.556440\n",
      "epoch 114; iter: 0; batch classifier loss: 0.373943; batch adversarial loss: 0.560921\n",
      "epoch 115; iter: 0; batch classifier loss: 0.340211; batch adversarial loss: 0.468789\n",
      "epoch 116; iter: 0; batch classifier loss: 0.381609; batch adversarial loss: 0.563971\n",
      "epoch 117; iter: 0; batch classifier loss: 0.378655; batch adversarial loss: 0.582851\n",
      "epoch 118; iter: 0; batch classifier loss: 0.335655; batch adversarial loss: 0.532889\n",
      "epoch 119; iter: 0; batch classifier loss: 0.286350; batch adversarial loss: 0.530223\n",
      "epoch 120; iter: 0; batch classifier loss: 0.346032; batch adversarial loss: 0.639967\n",
      "epoch 121; iter: 0; batch classifier loss: 0.342744; batch adversarial loss: 0.502543\n",
      "epoch 122; iter: 0; batch classifier loss: 0.332239; batch adversarial loss: 0.505047\n",
      "epoch 123; iter: 0; batch classifier loss: 0.376481; batch adversarial loss: 0.561053\n",
      "epoch 124; iter: 0; batch classifier loss: 0.400891; batch adversarial loss: 0.524985\n",
      "epoch 125; iter: 0; batch classifier loss: 0.324150; batch adversarial loss: 0.496463\n",
      "epoch 126; iter: 0; batch classifier loss: 0.391938; batch adversarial loss: 0.575716\n",
      "epoch 127; iter: 0; batch classifier loss: 0.309012; batch adversarial loss: 0.548279\n",
      "epoch 128; iter: 0; batch classifier loss: 0.383756; batch adversarial loss: 0.544811\n",
      "epoch 129; iter: 0; batch classifier loss: 0.308341; batch adversarial loss: 0.443525\n",
      "epoch 130; iter: 0; batch classifier loss: 0.425589; batch adversarial loss: 0.572723\n",
      "epoch 131; iter: 0; batch classifier loss: 0.374748; batch adversarial loss: 0.479884\n",
      "epoch 132; iter: 0; batch classifier loss: 0.344728; batch adversarial loss: 0.523501\n",
      "epoch 133; iter: 0; batch classifier loss: 0.300905; batch adversarial loss: 0.522792\n",
      "epoch 134; iter: 0; batch classifier loss: 0.392685; batch adversarial loss: 0.614802\n",
      "epoch 135; iter: 0; batch classifier loss: 0.284538; batch adversarial loss: 0.540145\n",
      "epoch 136; iter: 0; batch classifier loss: 0.382418; batch adversarial loss: 0.499391\n",
      "epoch 137; iter: 0; batch classifier loss: 0.353573; batch adversarial loss: 0.573529\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 138; iter: 0; batch classifier loss: 0.335318; batch adversarial loss: 0.614071\n",
      "epoch 139; iter: 0; batch classifier loss: 0.367249; batch adversarial loss: 0.556756\n",
      "epoch 140; iter: 0; batch classifier loss: 0.343077; batch adversarial loss: 0.519578\n",
      "epoch 141; iter: 0; batch classifier loss: 0.343479; batch adversarial loss: 0.551646\n",
      "epoch 142; iter: 0; batch classifier loss: 0.295483; batch adversarial loss: 0.617643\n",
      "epoch 143; iter: 0; batch classifier loss: 0.367471; batch adversarial loss: 0.506755\n",
      "epoch 144; iter: 0; batch classifier loss: 0.266798; batch adversarial loss: 0.561681\n",
      "epoch 145; iter: 0; batch classifier loss: 0.305160; batch adversarial loss: 0.679006\n",
      "epoch 146; iter: 0; batch classifier loss: 0.391273; batch adversarial loss: 0.573231\n",
      "epoch 147; iter: 0; batch classifier loss: 0.362310; batch adversarial loss: 0.488270\n",
      "epoch 148; iter: 0; batch classifier loss: 0.365098; batch adversarial loss: 0.569451\n",
      "epoch 149; iter: 0; batch classifier loss: 0.367866; batch adversarial loss: 0.619529\n",
      "epoch 150; iter: 0; batch classifier loss: 0.340739; batch adversarial loss: 0.527685\n",
      "epoch 151; iter: 0; batch classifier loss: 0.349617; batch adversarial loss: 0.535043\n",
      "epoch 152; iter: 0; batch classifier loss: 0.380914; batch adversarial loss: 0.547758\n",
      "epoch 153; iter: 0; batch classifier loss: 0.292802; batch adversarial loss: 0.552582\n",
      "epoch 154; iter: 0; batch classifier loss: 0.377452; batch adversarial loss: 0.496497\n",
      "epoch 155; iter: 0; batch classifier loss: 0.307307; batch adversarial loss: 0.538503\n",
      "epoch 156; iter: 0; batch classifier loss: 0.271722; batch adversarial loss: 0.565825\n",
      "epoch 157; iter: 0; batch classifier loss: 0.272143; batch adversarial loss: 0.545801\n",
      "epoch 158; iter: 0; batch classifier loss: 0.353892; batch adversarial loss: 0.512836\n",
      "epoch 159; iter: 0; batch classifier loss: 0.298846; batch adversarial loss: 0.536946\n",
      "epoch 160; iter: 0; batch classifier loss: 0.350904; batch adversarial loss: 0.507064\n",
      "epoch 161; iter: 0; batch classifier loss: 0.329578; batch adversarial loss: 0.553217\n",
      "epoch 162; iter: 0; batch classifier loss: 0.272022; batch adversarial loss: 0.516390\n",
      "epoch 163; iter: 0; batch classifier loss: 0.336315; batch adversarial loss: 0.479934\n",
      "epoch 164; iter: 0; batch classifier loss: 0.379193; batch adversarial loss: 0.477157\n",
      "epoch 165; iter: 0; batch classifier loss: 0.418009; batch adversarial loss: 0.518766\n",
      "epoch 166; iter: 0; batch classifier loss: 0.296574; batch adversarial loss: 0.617105\n",
      "epoch 167; iter: 0; batch classifier loss: 0.348813; batch adversarial loss: 0.529419\n",
      "epoch 168; iter: 0; batch classifier loss: 0.321622; batch adversarial loss: 0.585864\n",
      "epoch 169; iter: 0; batch classifier loss: 0.383007; batch adversarial loss: 0.566476\n",
      "epoch 170; iter: 0; batch classifier loss: 0.258862; batch adversarial loss: 0.529158\n",
      "epoch 171; iter: 0; batch classifier loss: 0.431511; batch adversarial loss: 0.534451\n",
      "epoch 172; iter: 0; batch classifier loss: 0.238212; batch adversarial loss: 0.597869\n",
      "epoch 173; iter: 0; batch classifier loss: 0.344247; batch adversarial loss: 0.580893\n",
      "epoch 174; iter: 0; batch classifier loss: 0.357269; batch adversarial loss: 0.570397\n",
      "epoch 175; iter: 0; batch classifier loss: 0.367785; batch adversarial loss: 0.572659\n",
      "epoch 176; iter: 0; batch classifier loss: 0.364499; batch adversarial loss: 0.607683\n",
      "epoch 177; iter: 0; batch classifier loss: 0.264922; batch adversarial loss: 0.540521\n",
      "epoch 178; iter: 0; batch classifier loss: 0.330678; batch adversarial loss: 0.516319\n",
      "epoch 179; iter: 0; batch classifier loss: 0.354833; batch adversarial loss: 0.456163\n",
      "epoch 180; iter: 0; batch classifier loss: 0.249067; batch adversarial loss: 0.507528\n",
      "epoch 181; iter: 0; batch classifier loss: 0.270289; batch adversarial loss: 0.537818\n",
      "epoch 182; iter: 0; batch classifier loss: 0.401734; batch adversarial loss: 0.447526\n",
      "epoch 183; iter: 0; batch classifier loss: 0.318887; batch adversarial loss: 0.521212\n",
      "epoch 184; iter: 0; batch classifier loss: 0.383496; batch adversarial loss: 0.542480\n",
      "epoch 185; iter: 0; batch classifier loss: 0.395577; batch adversarial loss: 0.541547\n",
      "epoch 186; iter: 0; batch classifier loss: 0.313666; batch adversarial loss: 0.509966\n",
      "epoch 187; iter: 0; batch classifier loss: 0.294438; batch adversarial loss: 0.540174\n",
      "epoch 188; iter: 0; batch classifier loss: 0.386118; batch adversarial loss: 0.532830\n",
      "epoch 189; iter: 0; batch classifier loss: 0.323022; batch adversarial loss: 0.578061\n",
      "epoch 190; iter: 0; batch classifier loss: 0.328251; batch adversarial loss: 0.585034\n",
      "epoch 191; iter: 0; batch classifier loss: 0.322547; batch adversarial loss: 0.549017\n",
      "epoch 192; iter: 0; batch classifier loss: 0.341332; batch adversarial loss: 0.553728\n",
      "epoch 193; iter: 0; batch classifier loss: 0.325466; batch adversarial loss: 0.527013\n",
      "epoch 194; iter: 0; batch classifier loss: 0.316631; batch adversarial loss: 0.582740\n",
      "epoch 195; iter: 0; batch classifier loss: 0.325601; batch adversarial loss: 0.579957\n",
      "epoch 196; iter: 0; batch classifier loss: 0.445606; batch adversarial loss: 0.595630\n",
      "epoch 197; iter: 0; batch classifier loss: 0.339163; batch adversarial loss: 0.519202\n",
      "epoch 198; iter: 0; batch classifier loss: 0.283343; batch adversarial loss: 0.465680\n",
      "epoch 199; iter: 0; batch classifier loss: 0.380625; batch adversarial loss: 0.562440\n",
      "epoch 0; iter: 0; batch classifier loss: 0.671938; batch adversarial loss: 0.672432\n",
      "epoch 1; iter: 0; batch classifier loss: 0.578882; batch adversarial loss: 0.654910\n",
      "epoch 2; iter: 0; batch classifier loss: 0.608293; batch adversarial loss: 0.650586\n",
      "epoch 3; iter: 0; batch classifier loss: 0.562817; batch adversarial loss: 0.687080\n",
      "epoch 4; iter: 0; batch classifier loss: 0.599344; batch adversarial loss: 0.663036\n",
      "epoch 5; iter: 0; batch classifier loss: 0.545852; batch adversarial loss: 0.651551\n",
      "epoch 6; iter: 0; batch classifier loss: 0.542459; batch adversarial loss: 0.621465\n",
      "epoch 7; iter: 0; batch classifier loss: 0.531460; batch adversarial loss: 0.628754\n",
      "epoch 8; iter: 0; batch classifier loss: 0.542325; batch adversarial loss: 0.536857\n",
      "epoch 9; iter: 0; batch classifier loss: 0.548942; batch adversarial loss: 0.523637\n",
      "epoch 10; iter: 0; batch classifier loss: 0.545526; batch adversarial loss: 0.590054\n",
      "epoch 11; iter: 0; batch classifier loss: 0.524447; batch adversarial loss: 0.657021\n",
      "epoch 12; iter: 0; batch classifier loss: 0.538190; batch adversarial loss: 0.600189\n",
      "epoch 13; iter: 0; batch classifier loss: 0.477872; batch adversarial loss: 0.587857\n",
      "epoch 14; iter: 0; batch classifier loss: 0.476247; batch adversarial loss: 0.595509\n",
      "epoch 15; iter: 0; batch classifier loss: 0.495642; batch adversarial loss: 0.577078\n",
      "epoch 16; iter: 0; batch classifier loss: 0.483966; batch adversarial loss: 0.512505\n",
      "epoch 17; iter: 0; batch classifier loss: 0.509031; batch adversarial loss: 0.540915\n",
      "epoch 18; iter: 0; batch classifier loss: 0.478465; batch adversarial loss: 0.610072\n",
      "epoch 19; iter: 0; batch classifier loss: 0.581838; batch adversarial loss: 0.588469\n",
      "epoch 20; iter: 0; batch classifier loss: 0.524484; batch adversarial loss: 0.553089\n",
      "epoch 21; iter: 0; batch classifier loss: 0.504608; batch adversarial loss: 0.505408\n",
      "epoch 22; iter: 0; batch classifier loss: 0.496451; batch adversarial loss: 0.520139\n",
      "epoch 23; iter: 0; batch classifier loss: 0.506866; batch adversarial loss: 0.512615\n",
      "epoch 24; iter: 0; batch classifier loss: 0.544334; batch adversarial loss: 0.556950\n",
      "epoch 25; iter: 0; batch classifier loss: 0.522196; batch adversarial loss: 0.580820\n",
      "epoch 26; iter: 0; batch classifier loss: 0.461539; batch adversarial loss: 0.578379\n",
      "epoch 27; iter: 0; batch classifier loss: 0.459729; batch adversarial loss: 0.521349\n",
      "epoch 28; iter: 0; batch classifier loss: 0.470039; batch adversarial loss: 0.560961\n",
      "epoch 29; iter: 0; batch classifier loss: 0.508047; batch adversarial loss: 0.532225\n",
      "epoch 30; iter: 0; batch classifier loss: 0.421943; batch adversarial loss: 0.491261\n",
      "epoch 31; iter: 0; batch classifier loss: 0.446440; batch adversarial loss: 0.522781\n",
      "epoch 32; iter: 0; batch classifier loss: 0.448470; batch adversarial loss: 0.626661\n",
      "epoch 33; iter: 0; batch classifier loss: 0.423683; batch adversarial loss: 0.578749\n",
      "epoch 34; iter: 0; batch classifier loss: 0.599060; batch adversarial loss: 0.594501\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 35; iter: 0; batch classifier loss: 0.453498; batch adversarial loss: 0.586316\n",
      "epoch 36; iter: 0; batch classifier loss: 0.402689; batch adversarial loss: 0.520325\n",
      "epoch 37; iter: 0; batch classifier loss: 0.448426; batch adversarial loss: 0.523164\n",
      "epoch 38; iter: 0; batch classifier loss: 0.444750; batch adversarial loss: 0.536829\n",
      "epoch 39; iter: 0; batch classifier loss: 0.351891; batch adversarial loss: 0.505405\n",
      "epoch 40; iter: 0; batch classifier loss: 0.487228; batch adversarial loss: 0.662782\n",
      "epoch 41; iter: 0; batch classifier loss: 0.464537; batch adversarial loss: 0.568391\n",
      "epoch 42; iter: 0; batch classifier loss: 0.478002; batch adversarial loss: 0.567590\n",
      "epoch 43; iter: 0; batch classifier loss: 0.477333; batch adversarial loss: 0.577907\n",
      "epoch 44; iter: 0; batch classifier loss: 0.433451; batch adversarial loss: 0.543842\n",
      "epoch 45; iter: 0; batch classifier loss: 0.520961; batch adversarial loss: 0.442308\n",
      "epoch 46; iter: 0; batch classifier loss: 0.445897; batch adversarial loss: 0.558485\n",
      "epoch 47; iter: 0; batch classifier loss: 0.323018; batch adversarial loss: 0.547605\n",
      "epoch 48; iter: 0; batch classifier loss: 0.473414; batch adversarial loss: 0.581082\n",
      "epoch 49; iter: 0; batch classifier loss: 0.394902; batch adversarial loss: 0.482392\n",
      "epoch 50; iter: 0; batch classifier loss: 0.432506; batch adversarial loss: 0.579136\n",
      "epoch 51; iter: 0; batch classifier loss: 0.393758; batch adversarial loss: 0.607733\n",
      "epoch 52; iter: 0; batch classifier loss: 0.465971; batch adversarial loss: 0.604731\n",
      "epoch 53; iter: 0; batch classifier loss: 0.496704; batch adversarial loss: 0.649508\n",
      "epoch 54; iter: 0; batch classifier loss: 0.446880; batch adversarial loss: 0.693155\n",
      "epoch 55; iter: 0; batch classifier loss: 0.404796; batch adversarial loss: 0.519603\n",
      "epoch 56; iter: 0; batch classifier loss: 0.432690; batch adversarial loss: 0.544331\n",
      "epoch 57; iter: 0; batch classifier loss: 0.509557; batch adversarial loss: 0.605730\n",
      "epoch 58; iter: 0; batch classifier loss: 0.443169; batch adversarial loss: 0.562191\n",
      "epoch 59; iter: 0; batch classifier loss: 0.426595; batch adversarial loss: 0.596509\n",
      "epoch 60; iter: 0; batch classifier loss: 0.349869; batch adversarial loss: 0.545567\n",
      "epoch 61; iter: 0; batch classifier loss: 0.376787; batch adversarial loss: 0.578673\n",
      "epoch 62; iter: 0; batch classifier loss: 0.433148; batch adversarial loss: 0.604954\n",
      "epoch 63; iter: 0; batch classifier loss: 0.474856; batch adversarial loss: 0.586287\n",
      "epoch 64; iter: 0; batch classifier loss: 0.428231; batch adversarial loss: 0.537621\n",
      "epoch 65; iter: 0; batch classifier loss: 0.397414; batch adversarial loss: 0.563357\n",
      "epoch 66; iter: 0; batch classifier loss: 0.451220; batch adversarial loss: 0.604498\n",
      "epoch 67; iter: 0; batch classifier loss: 0.437804; batch adversarial loss: 0.561577\n",
      "epoch 68; iter: 0; batch classifier loss: 0.415112; batch adversarial loss: 0.612374\n",
      "epoch 69; iter: 0; batch classifier loss: 0.468473; batch adversarial loss: 0.567937\n",
      "epoch 70; iter: 0; batch classifier loss: 0.365376; batch adversarial loss: 0.595710\n",
      "epoch 71; iter: 0; batch classifier loss: 0.468817; batch adversarial loss: 0.553053\n",
      "epoch 72; iter: 0; batch classifier loss: 0.479631; batch adversarial loss: 0.536724\n",
      "epoch 73; iter: 0; batch classifier loss: 0.346501; batch adversarial loss: 0.528279\n",
      "epoch 74; iter: 0; batch classifier loss: 0.452064; batch adversarial loss: 0.607606\n",
      "epoch 75; iter: 0; batch classifier loss: 0.373157; batch adversarial loss: 0.526283\n",
      "epoch 76; iter: 0; batch classifier loss: 0.532160; batch adversarial loss: 0.518838\n",
      "epoch 77; iter: 0; batch classifier loss: 0.370803; batch adversarial loss: 0.553451\n",
      "epoch 78; iter: 0; batch classifier loss: 0.447433; batch adversarial loss: 0.571319\n",
      "epoch 79; iter: 0; batch classifier loss: 0.394278; batch adversarial loss: 0.511149\n",
      "epoch 80; iter: 0; batch classifier loss: 0.416126; batch adversarial loss: 0.519925\n",
      "epoch 81; iter: 0; batch classifier loss: 0.404294; batch adversarial loss: 0.624117\n",
      "epoch 82; iter: 0; batch classifier loss: 0.474354; batch adversarial loss: 0.562891\n",
      "epoch 83; iter: 0; batch classifier loss: 0.442709; batch adversarial loss: 0.519609\n",
      "epoch 84; iter: 0; batch classifier loss: 0.368493; batch adversarial loss: 0.578625\n",
      "epoch 85; iter: 0; batch classifier loss: 0.441883; batch adversarial loss: 0.588225\n",
      "epoch 86; iter: 0; batch classifier loss: 0.418020; batch adversarial loss: 0.570895\n",
      "epoch 87; iter: 0; batch classifier loss: 0.365520; batch adversarial loss: 0.503802\n",
      "epoch 88; iter: 0; batch classifier loss: 0.381022; batch adversarial loss: 0.529295\n",
      "epoch 89; iter: 0; batch classifier loss: 0.413325; batch adversarial loss: 0.581861\n",
      "epoch 90; iter: 0; batch classifier loss: 0.392754; batch adversarial loss: 0.599319\n",
      "epoch 91; iter: 0; batch classifier loss: 0.460264; batch adversarial loss: 0.628019\n",
      "epoch 92; iter: 0; batch classifier loss: 0.373765; batch adversarial loss: 0.546157\n",
      "epoch 93; iter: 0; batch classifier loss: 0.372192; batch adversarial loss: 0.613396\n",
      "epoch 94; iter: 0; batch classifier loss: 0.377822; batch adversarial loss: 0.631287\n",
      "epoch 95; iter: 0; batch classifier loss: 0.410974; batch adversarial loss: 0.561892\n",
      "epoch 96; iter: 0; batch classifier loss: 0.405178; batch adversarial loss: 0.606446\n",
      "epoch 97; iter: 0; batch classifier loss: 0.430745; batch adversarial loss: 0.528656\n",
      "epoch 98; iter: 0; batch classifier loss: 0.410047; batch adversarial loss: 0.513125\n",
      "epoch 99; iter: 0; batch classifier loss: 0.467633; batch adversarial loss: 0.622300\n",
      "epoch 100; iter: 0; batch classifier loss: 0.343990; batch adversarial loss: 0.592365\n",
      "epoch 101; iter: 0; batch classifier loss: 0.332746; batch adversarial loss: 0.553335\n",
      "epoch 102; iter: 0; batch classifier loss: 0.359223; batch adversarial loss: 0.530420\n",
      "epoch 103; iter: 0; batch classifier loss: 0.419130; batch adversarial loss: 0.558651\n",
      "epoch 104; iter: 0; batch classifier loss: 0.354313; batch adversarial loss: 0.553773\n",
      "epoch 105; iter: 0; batch classifier loss: 0.389868; batch adversarial loss: 0.502647\n",
      "epoch 106; iter: 0; batch classifier loss: 0.413000; batch adversarial loss: 0.543841\n",
      "epoch 107; iter: 0; batch classifier loss: 0.463606; batch adversarial loss: 0.613499\n",
      "epoch 108; iter: 0; batch classifier loss: 0.383778; batch adversarial loss: 0.639450\n",
      "epoch 109; iter: 0; batch classifier loss: 0.354459; batch adversarial loss: 0.597058\n",
      "epoch 110; iter: 0; batch classifier loss: 0.320334; batch adversarial loss: 0.562916\n",
      "epoch 111; iter: 0; batch classifier loss: 0.354104; batch adversarial loss: 0.629469\n",
      "epoch 112; iter: 0; batch classifier loss: 0.433848; batch adversarial loss: 0.580106\n",
      "epoch 113; iter: 0; batch classifier loss: 0.338802; batch adversarial loss: 0.529070\n",
      "epoch 114; iter: 0; batch classifier loss: 0.394998; batch adversarial loss: 0.528057\n",
      "epoch 115; iter: 0; batch classifier loss: 0.346920; batch adversarial loss: 0.577843\n",
      "epoch 116; iter: 0; batch classifier loss: 0.390833; batch adversarial loss: 0.536847\n",
      "epoch 117; iter: 0; batch classifier loss: 0.373260; batch adversarial loss: 0.585510\n",
      "epoch 118; iter: 0; batch classifier loss: 0.352473; batch adversarial loss: 0.592062\n",
      "epoch 119; iter: 0; batch classifier loss: 0.382548; batch adversarial loss: 0.569733\n",
      "epoch 120; iter: 0; batch classifier loss: 0.435065; batch adversarial loss: 0.504476\n",
      "epoch 121; iter: 0; batch classifier loss: 0.423094; batch adversarial loss: 0.622023\n",
      "epoch 122; iter: 0; batch classifier loss: 0.367849; batch adversarial loss: 0.597325\n",
      "epoch 123; iter: 0; batch classifier loss: 0.403781; batch adversarial loss: 0.670346\n",
      "epoch 124; iter: 0; batch classifier loss: 0.299961; batch adversarial loss: 0.570230\n",
      "epoch 125; iter: 0; batch classifier loss: 0.308438; batch adversarial loss: 0.581173\n",
      "epoch 126; iter: 0; batch classifier loss: 0.392560; batch adversarial loss: 0.564040\n",
      "epoch 127; iter: 0; batch classifier loss: 0.417670; batch adversarial loss: 0.586857\n",
      "epoch 128; iter: 0; batch classifier loss: 0.343338; batch adversarial loss: 0.613603\n",
      "epoch 129; iter: 0; batch classifier loss: 0.386769; batch adversarial loss: 0.562664\n",
      "epoch 130; iter: 0; batch classifier loss: 0.406439; batch adversarial loss: 0.570995\n",
      "epoch 131; iter: 0; batch classifier loss: 0.355434; batch adversarial loss: 0.468104\n",
      "epoch 132; iter: 0; batch classifier loss: 0.413323; batch adversarial loss: 0.611640\n",
      "epoch 133; iter: 0; batch classifier loss: 0.416558; batch adversarial loss: 0.630045\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 134; iter: 0; batch classifier loss: 0.368095; batch adversarial loss: 0.585909\n",
      "epoch 135; iter: 0; batch classifier loss: 0.348516; batch adversarial loss: 0.628672\n",
      "epoch 136; iter: 0; batch classifier loss: 0.375580; batch adversarial loss: 0.578619\n",
      "epoch 137; iter: 0; batch classifier loss: 0.407307; batch adversarial loss: 0.562006\n",
      "epoch 138; iter: 0; batch classifier loss: 0.350422; batch adversarial loss: 0.486618\n",
      "epoch 139; iter: 0; batch classifier loss: 0.390984; batch adversarial loss: 0.513005\n",
      "epoch 140; iter: 0; batch classifier loss: 0.386191; batch adversarial loss: 0.551637\n",
      "epoch 141; iter: 0; batch classifier loss: 0.437329; batch adversarial loss: 0.580147\n",
      "epoch 142; iter: 0; batch classifier loss: 0.335531; batch adversarial loss: 0.543244\n",
      "epoch 143; iter: 0; batch classifier loss: 0.448262; batch adversarial loss: 0.536840\n",
      "epoch 144; iter: 0; batch classifier loss: 0.369900; batch adversarial loss: 0.477419\n",
      "epoch 145; iter: 0; batch classifier loss: 0.447136; batch adversarial loss: 0.569655\n",
      "epoch 146; iter: 0; batch classifier loss: 0.382805; batch adversarial loss: 0.597882\n",
      "epoch 147; iter: 0; batch classifier loss: 0.313513; batch adversarial loss: 0.610772\n",
      "epoch 148; iter: 0; batch classifier loss: 0.399417; batch adversarial loss: 0.513420\n",
      "epoch 149; iter: 0; batch classifier loss: 0.330407; batch adversarial loss: 0.562063\n",
      "epoch 150; iter: 0; batch classifier loss: 0.369115; batch adversarial loss: 0.528877\n",
      "epoch 151; iter: 0; batch classifier loss: 0.407971; batch adversarial loss: 0.559575\n",
      "epoch 152; iter: 0; batch classifier loss: 0.374506; batch adversarial loss: 0.612799\n",
      "epoch 153; iter: 0; batch classifier loss: 0.342274; batch adversarial loss: 0.529865\n",
      "epoch 154; iter: 0; batch classifier loss: 0.361586; batch adversarial loss: 0.535849\n",
      "epoch 155; iter: 0; batch classifier loss: 0.316296; batch adversarial loss: 0.587291\n",
      "epoch 156; iter: 0; batch classifier loss: 0.366937; batch adversarial loss: 0.621518\n",
      "epoch 157; iter: 0; batch classifier loss: 0.328801; batch adversarial loss: 0.562113\n",
      "epoch 158; iter: 0; batch classifier loss: 0.319298; batch adversarial loss: 0.530156\n",
      "epoch 159; iter: 0; batch classifier loss: 0.385502; batch adversarial loss: 0.511281\n",
      "epoch 160; iter: 0; batch classifier loss: 0.343173; batch adversarial loss: 0.594421\n",
      "epoch 161; iter: 0; batch classifier loss: 0.471593; batch adversarial loss: 0.529390\n",
      "epoch 162; iter: 0; batch classifier loss: 0.413068; batch adversarial loss: 0.586773\n",
      "epoch 163; iter: 0; batch classifier loss: 0.416664; batch adversarial loss: 0.537496\n",
      "epoch 164; iter: 0; batch classifier loss: 0.346918; batch adversarial loss: 0.519403\n",
      "epoch 165; iter: 0; batch classifier loss: 0.343174; batch adversarial loss: 0.562963\n",
      "epoch 166; iter: 0; batch classifier loss: 0.356426; batch adversarial loss: 0.593939\n",
      "epoch 167; iter: 0; batch classifier loss: 0.437099; batch adversarial loss: 0.544960\n",
      "epoch 168; iter: 0; batch classifier loss: 0.364199; batch adversarial loss: 0.535889\n",
      "epoch 169; iter: 0; batch classifier loss: 0.403897; batch adversarial loss: 0.518511\n",
      "epoch 170; iter: 0; batch classifier loss: 0.362917; batch adversarial loss: 0.623887\n",
      "epoch 171; iter: 0; batch classifier loss: 0.329381; batch adversarial loss: 0.563441\n",
      "epoch 172; iter: 0; batch classifier loss: 0.497069; batch adversarial loss: 0.596503\n",
      "epoch 173; iter: 0; batch classifier loss: 0.377916; batch adversarial loss: 0.553135\n",
      "epoch 174; iter: 0; batch classifier loss: 0.386569; batch adversarial loss: 0.562967\n",
      "epoch 175; iter: 0; batch classifier loss: 0.339759; batch adversarial loss: 0.606031\n",
      "epoch 176; iter: 0; batch classifier loss: 0.234703; batch adversarial loss: 0.640717\n",
      "epoch 177; iter: 0; batch classifier loss: 0.363742; batch adversarial loss: 0.546099\n",
      "epoch 178; iter: 0; batch classifier loss: 0.317362; batch adversarial loss: 0.589655\n",
      "epoch 179; iter: 0; batch classifier loss: 0.307780; batch adversarial loss: 0.572185\n",
      "epoch 180; iter: 0; batch classifier loss: 0.395674; batch adversarial loss: 0.544349\n",
      "epoch 181; iter: 0; batch classifier loss: 0.371369; batch adversarial loss: 0.614861\n",
      "epoch 182; iter: 0; batch classifier loss: 0.458546; batch adversarial loss: 0.554799\n",
      "epoch 183; iter: 0; batch classifier loss: 0.395280; batch adversarial loss: 0.586855\n",
      "epoch 184; iter: 0; batch classifier loss: 0.344736; batch adversarial loss: 0.538485\n",
      "epoch 185; iter: 0; batch classifier loss: 0.368886; batch adversarial loss: 0.636323\n",
      "epoch 186; iter: 0; batch classifier loss: 0.318798; batch adversarial loss: 0.555146\n",
      "epoch 187; iter: 0; batch classifier loss: 0.365058; batch adversarial loss: 0.494182\n",
      "epoch 188; iter: 0; batch classifier loss: 0.527625; batch adversarial loss: 0.510414\n",
      "epoch 189; iter: 0; batch classifier loss: 0.322720; batch adversarial loss: 0.654818\n",
      "epoch 190; iter: 0; batch classifier loss: 0.420761; batch adversarial loss: 0.561628\n",
      "epoch 191; iter: 0; batch classifier loss: 0.352294; batch adversarial loss: 0.563512\n",
      "epoch 192; iter: 0; batch classifier loss: 0.336979; batch adversarial loss: 0.560729\n",
      "epoch 193; iter: 0; batch classifier loss: 0.374620; batch adversarial loss: 0.632463\n",
      "epoch 194; iter: 0; batch classifier loss: 0.313331; batch adversarial loss: 0.518443\n",
      "epoch 195; iter: 0; batch classifier loss: 0.315061; batch adversarial loss: 0.613421\n",
      "epoch 196; iter: 0; batch classifier loss: 0.318831; batch adversarial loss: 0.552682\n",
      "epoch 197; iter: 0; batch classifier loss: 0.301469; batch adversarial loss: 0.562809\n",
      "epoch 198; iter: 0; batch classifier loss: 0.330271; batch adversarial loss: 0.663601\n",
      "epoch 199; iter: 0; batch classifier loss: 0.307105; batch adversarial loss: 0.604606\n",
      "epoch 0; iter: 0; batch classifier loss: 0.706025; batch adversarial loss: 0.657972\n",
      "epoch 1; iter: 0; batch classifier loss: 0.575828; batch adversarial loss: 0.652815\n",
      "epoch 2; iter: 0; batch classifier loss: 0.591288; batch adversarial loss: 0.654731\n",
      "epoch 3; iter: 0; batch classifier loss: 0.682709; batch adversarial loss: 0.653414\n",
      "epoch 4; iter: 0; batch classifier loss: 0.580033; batch adversarial loss: 0.653731\n",
      "epoch 5; iter: 0; batch classifier loss: 0.542078; batch adversarial loss: 0.611537\n",
      "epoch 6; iter: 0; batch classifier loss: 0.536547; batch adversarial loss: 0.627706\n",
      "epoch 7; iter: 0; batch classifier loss: 0.485383; batch adversarial loss: 0.597882\n",
      "epoch 8; iter: 0; batch classifier loss: 0.529798; batch adversarial loss: 0.618968\n",
      "epoch 9; iter: 0; batch classifier loss: 0.569465; batch adversarial loss: 0.598691\n",
      "epoch 10; iter: 0; batch classifier loss: 0.506908; batch adversarial loss: 0.576301\n",
      "epoch 11; iter: 0; batch classifier loss: 0.523658; batch adversarial loss: 0.579484\n",
      "epoch 12; iter: 0; batch classifier loss: 0.514973; batch adversarial loss: 0.536798\n",
      "epoch 13; iter: 0; batch classifier loss: 0.559994; batch adversarial loss: 0.621340\n",
      "epoch 14; iter: 0; batch classifier loss: 0.572068; batch adversarial loss: 0.539564\n",
      "epoch 15; iter: 0; batch classifier loss: 0.473219; batch adversarial loss: 0.550813\n",
      "epoch 16; iter: 0; batch classifier loss: 0.482541; batch adversarial loss: 0.602973\n",
      "epoch 17; iter: 0; batch classifier loss: 0.522989; batch adversarial loss: 0.580294\n",
      "epoch 18; iter: 0; batch classifier loss: 0.548549; batch adversarial loss: 0.641896\n",
      "epoch 19; iter: 0; batch classifier loss: 0.506351; batch adversarial loss: 0.569942\n",
      "epoch 20; iter: 0; batch classifier loss: 0.493759; batch adversarial loss: 0.526383\n",
      "epoch 21; iter: 0; batch classifier loss: 0.523348; batch adversarial loss: 0.598761\n",
      "epoch 22; iter: 0; batch classifier loss: 0.509251; batch adversarial loss: 0.472472\n",
      "epoch 23; iter: 0; batch classifier loss: 0.492873; batch adversarial loss: 0.485336\n",
      "epoch 24; iter: 0; batch classifier loss: 0.559876; batch adversarial loss: 0.481353\n",
      "epoch 25; iter: 0; batch classifier loss: 0.436755; batch adversarial loss: 0.628037\n",
      "epoch 26; iter: 0; batch classifier loss: 0.491073; batch adversarial loss: 0.584539\n",
      "epoch 27; iter: 0; batch classifier loss: 0.509300; batch adversarial loss: 0.568474\n",
      "epoch 28; iter: 0; batch classifier loss: 0.442500; batch adversarial loss: 0.631465\n",
      "epoch 29; iter: 0; batch classifier loss: 0.493553; batch adversarial loss: 0.598443\n",
      "epoch 30; iter: 0; batch classifier loss: 0.520386; batch adversarial loss: 0.629512\n",
      "epoch 31; iter: 0; batch classifier loss: 0.444405; batch adversarial loss: 0.579385\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 32; iter: 0; batch classifier loss: 0.491381; batch adversarial loss: 0.631885\n",
      "epoch 33; iter: 0; batch classifier loss: 0.482444; batch adversarial loss: 0.531609\n",
      "epoch 34; iter: 0; batch classifier loss: 0.419859; batch adversarial loss: 0.530189\n",
      "epoch 35; iter: 0; batch classifier loss: 0.468991; batch adversarial loss: 0.581108\n",
      "epoch 36; iter: 0; batch classifier loss: 0.454344; batch adversarial loss: 0.561792\n",
      "epoch 37; iter: 0; batch classifier loss: 0.456836; batch adversarial loss: 0.528027\n",
      "epoch 38; iter: 0; batch classifier loss: 0.484554; batch adversarial loss: 0.528484\n",
      "epoch 39; iter: 0; batch classifier loss: 0.380444; batch adversarial loss: 0.536219\n",
      "epoch 40; iter: 0; batch classifier loss: 0.407780; batch adversarial loss: 0.561181\n",
      "epoch 41; iter: 0; batch classifier loss: 0.363788; batch adversarial loss: 0.633542\n",
      "epoch 42; iter: 0; batch classifier loss: 0.407522; batch adversarial loss: 0.545838\n",
      "epoch 43; iter: 0; batch classifier loss: 0.375242; batch adversarial loss: 0.605304\n",
      "epoch 44; iter: 0; batch classifier loss: 0.471902; batch adversarial loss: 0.543972\n",
      "epoch 45; iter: 0; batch classifier loss: 0.503767; batch adversarial loss: 0.552803\n",
      "epoch 46; iter: 0; batch classifier loss: 0.412860; batch adversarial loss: 0.569623\n",
      "epoch 47; iter: 0; batch classifier loss: 0.487137; batch adversarial loss: 0.569458\n",
      "epoch 48; iter: 0; batch classifier loss: 0.548117; batch adversarial loss: 0.529534\n",
      "epoch 49; iter: 0; batch classifier loss: 0.338649; batch adversarial loss: 0.606532\n",
      "epoch 50; iter: 0; batch classifier loss: 0.363463; batch adversarial loss: 0.510724\n",
      "epoch 51; iter: 0; batch classifier loss: 0.442104; batch adversarial loss: 0.544598\n",
      "epoch 52; iter: 0; batch classifier loss: 0.491101; batch adversarial loss: 0.571499\n",
      "epoch 53; iter: 0; batch classifier loss: 0.480541; batch adversarial loss: 0.527854\n",
      "epoch 54; iter: 0; batch classifier loss: 0.366039; batch adversarial loss: 0.491688\n",
      "epoch 55; iter: 0; batch classifier loss: 0.478995; batch adversarial loss: 0.535787\n",
      "epoch 56; iter: 0; batch classifier loss: 0.415787; batch adversarial loss: 0.570813\n",
      "epoch 57; iter: 0; batch classifier loss: 0.468008; batch adversarial loss: 0.579906\n",
      "epoch 58; iter: 0; batch classifier loss: 0.425583; batch adversarial loss: 0.588825\n",
      "epoch 59; iter: 0; batch classifier loss: 0.388972; batch adversarial loss: 0.544586\n",
      "epoch 60; iter: 0; batch classifier loss: 0.426666; batch adversarial loss: 0.535825\n",
      "epoch 61; iter: 0; batch classifier loss: 0.412384; batch adversarial loss: 0.570986\n",
      "epoch 62; iter: 0; batch classifier loss: 0.407235; batch adversarial loss: 0.535895\n",
      "epoch 63; iter: 0; batch classifier loss: 0.388630; batch adversarial loss: 0.544329\n",
      "epoch 64; iter: 0; batch classifier loss: 0.393710; batch adversarial loss: 0.526909\n",
      "epoch 65; iter: 0; batch classifier loss: 0.374093; batch adversarial loss: 0.500261\n",
      "epoch 66; iter: 0; batch classifier loss: 0.414669; batch adversarial loss: 0.535775\n",
      "epoch 67; iter: 0; batch classifier loss: 0.394951; batch adversarial loss: 0.518020\n",
      "epoch 68; iter: 0; batch classifier loss: 0.342318; batch adversarial loss: 0.535449\n",
      "epoch 69; iter: 0; batch classifier loss: 0.521685; batch adversarial loss: 0.570351\n",
      "epoch 70; iter: 0; batch classifier loss: 0.368443; batch adversarial loss: 0.643069\n",
      "epoch 71; iter: 0; batch classifier loss: 0.487387; batch adversarial loss: 0.552526\n",
      "epoch 72; iter: 0; batch classifier loss: 0.441873; batch adversarial loss: 0.498378\n",
      "epoch 73; iter: 0; batch classifier loss: 0.419070; batch adversarial loss: 0.540331\n",
      "epoch 74; iter: 0; batch classifier loss: 0.390195; batch adversarial loss: 0.597465\n",
      "epoch 75; iter: 0; batch classifier loss: 0.476602; batch adversarial loss: 0.531821\n",
      "epoch 76; iter: 0; batch classifier loss: 0.347585; batch adversarial loss: 0.533392\n",
      "epoch 77; iter: 0; batch classifier loss: 0.522437; batch adversarial loss: 0.538011\n",
      "epoch 78; iter: 0; batch classifier loss: 0.479982; batch adversarial loss: 0.591752\n",
      "epoch 79; iter: 0; batch classifier loss: 0.415173; batch adversarial loss: 0.562583\n",
      "epoch 80; iter: 0; batch classifier loss: 0.369611; batch adversarial loss: 0.604030\n",
      "epoch 81; iter: 0; batch classifier loss: 0.364731; batch adversarial loss: 0.538412\n",
      "epoch 82; iter: 0; batch classifier loss: 0.455194; batch adversarial loss: 0.597448\n",
      "epoch 83; iter: 0; batch classifier loss: 0.352318; batch adversarial loss: 0.580327\n",
      "epoch 84; iter: 0; batch classifier loss: 0.384394; batch adversarial loss: 0.570321\n",
      "epoch 85; iter: 0; batch classifier loss: 0.414071; batch adversarial loss: 0.605542\n",
      "epoch 86; iter: 0; batch classifier loss: 0.389017; batch adversarial loss: 0.580026\n",
      "epoch 87; iter: 0; batch classifier loss: 0.368959; batch adversarial loss: 0.632042\n",
      "epoch 88; iter: 0; batch classifier loss: 0.313025; batch adversarial loss: 0.562924\n",
      "epoch 89; iter: 0; batch classifier loss: 0.450812; batch adversarial loss: 0.500191\n",
      "epoch 90; iter: 0; batch classifier loss: 0.384891; batch adversarial loss: 0.535367\n",
      "epoch 91; iter: 0; batch classifier loss: 0.354963; batch adversarial loss: 0.526883\n",
      "epoch 92; iter: 0; batch classifier loss: 0.450944; batch adversarial loss: 0.536024\n",
      "epoch 93; iter: 0; batch classifier loss: 0.406262; batch adversarial loss: 0.571332\n",
      "epoch 94; iter: 0; batch classifier loss: 0.361960; batch adversarial loss: 0.553378\n",
      "epoch 95; iter: 0; batch classifier loss: 0.449564; batch adversarial loss: 0.553288\n",
      "epoch 96; iter: 0; batch classifier loss: 0.346938; batch adversarial loss: 0.535560\n",
      "epoch 97; iter: 0; batch classifier loss: 0.381838; batch adversarial loss: 0.562142\n",
      "epoch 98; iter: 0; batch classifier loss: 0.349073; batch adversarial loss: 0.553631\n",
      "epoch 99; iter: 0; batch classifier loss: 0.385573; batch adversarial loss: 0.535916\n",
      "epoch 100; iter: 0; batch classifier loss: 0.443340; batch adversarial loss: 0.526934\n",
      "epoch 101; iter: 0; batch classifier loss: 0.373353; batch adversarial loss: 0.500394\n",
      "epoch 102; iter: 0; batch classifier loss: 0.407121; batch adversarial loss: 0.509048\n",
      "epoch 103; iter: 0; batch classifier loss: 0.418022; batch adversarial loss: 0.553686\n",
      "epoch 104; iter: 0; batch classifier loss: 0.392681; batch adversarial loss: 0.553629\n",
      "epoch 105; iter: 0; batch classifier loss: 0.282595; batch adversarial loss: 0.571869\n",
      "epoch 106; iter: 0; batch classifier loss: 0.412568; batch adversarial loss: 0.571418\n",
      "epoch 107; iter: 0; batch classifier loss: 0.329028; batch adversarial loss: 0.491143\n",
      "epoch 108; iter: 0; batch classifier loss: 0.322169; batch adversarial loss: 0.518082\n",
      "epoch 109; iter: 0; batch classifier loss: 0.379468; batch adversarial loss: 0.615724\n",
      "epoch 110; iter: 0; batch classifier loss: 0.416514; batch adversarial loss: 0.509205\n",
      "epoch 111; iter: 0; batch classifier loss: 0.420819; batch adversarial loss: 0.544472\n",
      "epoch 112; iter: 0; batch classifier loss: 0.386420; batch adversarial loss: 0.624368\n",
      "epoch 113; iter: 0; batch classifier loss: 0.425869; batch adversarial loss: 0.509572\n",
      "epoch 114; iter: 0; batch classifier loss: 0.375650; batch adversarial loss: 0.650151\n",
      "epoch 115; iter: 0; batch classifier loss: 0.288676; batch adversarial loss: 0.562003\n",
      "epoch 116; iter: 0; batch classifier loss: 0.359062; batch adversarial loss: 0.493133\n",
      "epoch 117; iter: 0; batch classifier loss: 0.387575; batch adversarial loss: 0.604059\n",
      "epoch 118; iter: 0; batch classifier loss: 0.390891; batch adversarial loss: 0.526121\n",
      "epoch 119; iter: 0; batch classifier loss: 0.467175; batch adversarial loss: 0.624001\n",
      "epoch 120; iter: 0; batch classifier loss: 0.341330; batch adversarial loss: 0.572083\n",
      "epoch 121; iter: 0; batch classifier loss: 0.362589; batch adversarial loss: 0.571783\n",
      "epoch 122; iter: 0; batch classifier loss: 0.320875; batch adversarial loss: 0.526749\n",
      "epoch 123; iter: 0; batch classifier loss: 0.366620; batch adversarial loss: 0.482002\n",
      "epoch 124; iter: 0; batch classifier loss: 0.401810; batch adversarial loss: 0.508736\n",
      "epoch 125; iter: 0; batch classifier loss: 0.375857; batch adversarial loss: 0.607483\n",
      "epoch 126; iter: 0; batch classifier loss: 0.368985; batch adversarial loss: 0.580641\n",
      "epoch 127; iter: 0; batch classifier loss: 0.396959; batch adversarial loss: 0.644290\n",
      "epoch 128; iter: 0; batch classifier loss: 0.357620; batch adversarial loss: 0.562299\n",
      "epoch 129; iter: 0; batch classifier loss: 0.362498; batch adversarial loss: 0.562657\n",
      "epoch 130; iter: 0; batch classifier loss: 0.393943; batch adversarial loss: 0.490159\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 131; iter: 0; batch classifier loss: 0.361408; batch adversarial loss: 0.553899\n",
      "epoch 132; iter: 0; batch classifier loss: 0.299692; batch adversarial loss: 0.571557\n",
      "epoch 133; iter: 0; batch classifier loss: 0.398150; batch adversarial loss: 0.588729\n",
      "epoch 134; iter: 0; batch classifier loss: 0.376608; batch adversarial loss: 0.519820\n",
      "epoch 135; iter: 0; batch classifier loss: 0.408970; batch adversarial loss: 0.562560\n",
      "epoch 136; iter: 0; batch classifier loss: 0.346923; batch adversarial loss: 0.527822\n",
      "epoch 137; iter: 0; batch classifier loss: 0.340355; batch adversarial loss: 0.545330\n",
      "epoch 138; iter: 0; batch classifier loss: 0.411645; batch adversarial loss: 0.562751\n",
      "epoch 139; iter: 0; batch classifier loss: 0.319684; batch adversarial loss: 0.658742\n",
      "epoch 140; iter: 0; batch classifier loss: 0.343480; batch adversarial loss: 0.553636\n",
      "epoch 141; iter: 0; batch classifier loss: 0.336273; batch adversarial loss: 0.535751\n",
      "epoch 142; iter: 0; batch classifier loss: 0.406799; batch adversarial loss: 0.535584\n",
      "epoch 143; iter: 0; batch classifier loss: 0.411314; batch adversarial loss: 0.544832\n",
      "epoch 144; iter: 0; batch classifier loss: 0.417133; batch adversarial loss: 0.526943\n",
      "epoch 145; iter: 0; batch classifier loss: 0.311005; batch adversarial loss: 0.500418\n",
      "epoch 146; iter: 0; batch classifier loss: 0.367999; batch adversarial loss: 0.562273\n",
      "epoch 147; iter: 0; batch classifier loss: 0.310090; batch adversarial loss: 0.535576\n",
      "epoch 148; iter: 0; batch classifier loss: 0.346931; batch adversarial loss: 0.561528\n",
      "epoch 149; iter: 0; batch classifier loss: 0.389377; batch adversarial loss: 0.509487\n",
      "epoch 150; iter: 0; batch classifier loss: 0.408080; batch adversarial loss: 0.597995\n",
      "epoch 151; iter: 0; batch classifier loss: 0.336478; batch adversarial loss: 0.553354\n",
      "epoch 152; iter: 0; batch classifier loss: 0.295781; batch adversarial loss: 0.553447\n",
      "epoch 153; iter: 0; batch classifier loss: 0.354606; batch adversarial loss: 0.579836\n",
      "epoch 154; iter: 0; batch classifier loss: 0.313296; batch adversarial loss: 0.544924\n",
      "epoch 155; iter: 0; batch classifier loss: 0.364198; batch adversarial loss: 0.544959\n",
      "epoch 156; iter: 0; batch classifier loss: 0.320313; batch adversarial loss: 0.517727\n",
      "epoch 157; iter: 0; batch classifier loss: 0.373334; batch adversarial loss: 0.527779\n",
      "epoch 158; iter: 0; batch classifier loss: 0.370829; batch adversarial loss: 0.588710\n",
      "epoch 159; iter: 0; batch classifier loss: 0.317133; batch adversarial loss: 0.466151\n",
      "epoch 160; iter: 0; batch classifier loss: 0.372513; batch adversarial loss: 0.553423\n",
      "epoch 161; iter: 0; batch classifier loss: 0.404036; batch adversarial loss: 0.580066\n",
      "epoch 162; iter: 0; batch classifier loss: 0.404982; batch adversarial loss: 0.535189\n",
      "epoch 163; iter: 0; batch classifier loss: 0.391638; batch adversarial loss: 0.624333\n",
      "epoch 164; iter: 0; batch classifier loss: 0.383374; batch adversarial loss: 0.562420\n",
      "epoch 165; iter: 0; batch classifier loss: 0.378347; batch adversarial loss: 0.518727\n",
      "epoch 166; iter: 0; batch classifier loss: 0.334862; batch adversarial loss: 0.491837\n",
      "epoch 167; iter: 0; batch classifier loss: 0.260073; batch adversarial loss: 0.580873\n",
      "epoch 168; iter: 0; batch classifier loss: 0.357636; batch adversarial loss: 0.535773\n",
      "epoch 169; iter: 0; batch classifier loss: 0.310386; batch adversarial loss: 0.562912\n",
      "epoch 170; iter: 0; batch classifier loss: 0.379296; batch adversarial loss: 0.562546\n",
      "epoch 171; iter: 0; batch classifier loss: 0.352940; batch adversarial loss: 0.553260\n",
      "epoch 172; iter: 0; batch classifier loss: 0.371587; batch adversarial loss: 0.606912\n",
      "epoch 173; iter: 0; batch classifier loss: 0.262995; batch adversarial loss: 0.588883\n",
      "epoch 174; iter: 0; batch classifier loss: 0.424968; batch adversarial loss: 0.634501\n",
      "epoch 175; iter: 0; batch classifier loss: 0.365234; batch adversarial loss: 0.482381\n",
      "epoch 176; iter: 0; batch classifier loss: 0.360557; batch adversarial loss: 0.527446\n",
      "epoch 177; iter: 0; batch classifier loss: 0.392226; batch adversarial loss: 0.563142\n",
      "epoch 178; iter: 0; batch classifier loss: 0.342464; batch adversarial loss: 0.510007\n",
      "epoch 179; iter: 0; batch classifier loss: 0.346403; batch adversarial loss: 0.545461\n",
      "epoch 180; iter: 0; batch classifier loss: 0.319241; batch adversarial loss: 0.446552\n",
      "epoch 181; iter: 0; batch classifier loss: 0.397332; batch adversarial loss: 0.526852\n",
      "epoch 182; iter: 0; batch classifier loss: 0.409005; batch adversarial loss: 0.589189\n",
      "epoch 183; iter: 0; batch classifier loss: 0.363250; batch adversarial loss: 0.614746\n",
      "epoch 184; iter: 0; batch classifier loss: 0.397846; batch adversarial loss: 0.526797\n",
      "epoch 185; iter: 0; batch classifier loss: 0.401966; batch adversarial loss: 0.589423\n",
      "epoch 186; iter: 0; batch classifier loss: 0.348921; batch adversarial loss: 0.526649\n",
      "epoch 187; iter: 0; batch classifier loss: 0.357110; batch adversarial loss: 0.482086\n",
      "epoch 188; iter: 0; batch classifier loss: 0.261433; batch adversarial loss: 0.463982\n",
      "epoch 189; iter: 0; batch classifier loss: 0.430556; batch adversarial loss: 0.580245\n",
      "epoch 190; iter: 0; batch classifier loss: 0.358211; batch adversarial loss: 0.590959\n",
      "epoch 191; iter: 0; batch classifier loss: 0.299816; batch adversarial loss: 0.571323\n",
      "epoch 192; iter: 0; batch classifier loss: 0.272430; batch adversarial loss: 0.562055\n",
      "epoch 193; iter: 0; batch classifier loss: 0.349380; batch adversarial loss: 0.527528\n",
      "epoch 194; iter: 0; batch classifier loss: 0.360710; batch adversarial loss: 0.588324\n",
      "epoch 195; iter: 0; batch classifier loss: 0.375403; batch adversarial loss: 0.535416\n",
      "epoch 196; iter: 0; batch classifier loss: 0.358303; batch adversarial loss: 0.552695\n",
      "epoch 197; iter: 0; batch classifier loss: 0.344138; batch adversarial loss: 0.625397\n",
      "epoch 198; iter: 0; batch classifier loss: 0.331124; batch adversarial loss: 0.587701\n",
      "epoch 199; iter: 0; batch classifier loss: 0.401195; batch adversarial loss: 0.569717\n",
      "epoch 0; iter: 0; batch classifier loss: 0.749765; batch adversarial loss: 0.624862\n",
      "epoch 1; iter: 0; batch classifier loss: 0.534670; batch adversarial loss: 0.636499\n",
      "epoch 2; iter: 0; batch classifier loss: 0.580192; batch adversarial loss: 0.627327\n",
      "epoch 3; iter: 0; batch classifier loss: 0.541395; batch adversarial loss: 0.644055\n",
      "epoch 4; iter: 0; batch classifier loss: 0.607187; batch adversarial loss: 0.644765\n",
      "epoch 5; iter: 0; batch classifier loss: 0.516747; batch adversarial loss: 0.636667\n",
      "epoch 6; iter: 0; batch classifier loss: 0.643372; batch adversarial loss: 0.609572\n",
      "epoch 7; iter: 0; batch classifier loss: 0.507636; batch adversarial loss: 0.634743\n",
      "epoch 8; iter: 0; batch classifier loss: 0.537150; batch adversarial loss: 0.603304\n",
      "epoch 9; iter: 0; batch classifier loss: 0.506719; batch adversarial loss: 0.587836\n",
      "epoch 10; iter: 0; batch classifier loss: 0.491180; batch adversarial loss: 0.598191\n",
      "epoch 11; iter: 0; batch classifier loss: 0.552094; batch adversarial loss: 0.581306\n",
      "epoch 12; iter: 0; batch classifier loss: 0.500917; batch adversarial loss: 0.581081\n",
      "epoch 13; iter: 0; batch classifier loss: 0.499858; batch adversarial loss: 0.572042\n",
      "epoch 14; iter: 0; batch classifier loss: 0.447158; batch adversarial loss: 0.523371\n",
      "epoch 15; iter: 0; batch classifier loss: 0.514088; batch adversarial loss: 0.567588\n",
      "epoch 16; iter: 0; batch classifier loss: 0.458737; batch adversarial loss: 0.574997\n",
      "epoch 17; iter: 0; batch classifier loss: 0.504388; batch adversarial loss: 0.541093\n",
      "epoch 18; iter: 0; batch classifier loss: 0.433515; batch adversarial loss: 0.653089\n",
      "epoch 19; iter: 0; batch classifier loss: 0.522021; batch adversarial loss: 0.560649\n",
      "epoch 20; iter: 0; batch classifier loss: 0.470046; batch adversarial loss: 0.574380\n",
      "epoch 21; iter: 0; batch classifier loss: 0.456903; batch adversarial loss: 0.541693\n",
      "epoch 22; iter: 0; batch classifier loss: 0.464203; batch adversarial loss: 0.496029\n",
      "epoch 23; iter: 0; batch classifier loss: 0.436786; batch adversarial loss: 0.564294\n",
      "epoch 24; iter: 0; batch classifier loss: 0.552552; batch adversarial loss: 0.539358\n",
      "epoch 25; iter: 0; batch classifier loss: 0.446456; batch adversarial loss: 0.505221\n",
      "epoch 26; iter: 0; batch classifier loss: 0.502142; batch adversarial loss: 0.538133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 27; iter: 0; batch classifier loss: 0.412296; batch adversarial loss: 0.571009\n",
      "epoch 28; iter: 0; batch classifier loss: 0.439245; batch adversarial loss: 0.581706\n",
      "epoch 29; iter: 0; batch classifier loss: 0.436696; batch adversarial loss: 0.480042\n",
      "epoch 30; iter: 0; batch classifier loss: 0.414225; batch adversarial loss: 0.579716\n",
      "epoch 31; iter: 0; batch classifier loss: 0.476783; batch adversarial loss: 0.553322\n",
      "epoch 32; iter: 0; batch classifier loss: 0.490272; batch adversarial loss: 0.518104\n",
      "epoch 33; iter: 0; batch classifier loss: 0.374407; batch adversarial loss: 0.570997\n",
      "epoch 34; iter: 0; batch classifier loss: 0.479365; batch adversarial loss: 0.608605\n",
      "epoch 35; iter: 0; batch classifier loss: 0.442089; batch adversarial loss: 0.572164\n",
      "epoch 36; iter: 0; batch classifier loss: 0.537313; batch adversarial loss: 0.589384\n",
      "epoch 37; iter: 0; batch classifier loss: 0.474400; batch adversarial loss: 0.517409\n",
      "epoch 38; iter: 0; batch classifier loss: 0.432314; batch adversarial loss: 0.553084\n",
      "epoch 39; iter: 0; batch classifier loss: 0.446678; batch adversarial loss: 0.554052\n",
      "epoch 40; iter: 0; batch classifier loss: 0.400749; batch adversarial loss: 0.489867\n",
      "epoch 41; iter: 0; batch classifier loss: 0.325780; batch adversarial loss: 0.562885\n",
      "epoch 42; iter: 0; batch classifier loss: 0.426104; batch adversarial loss: 0.571891\n",
      "epoch 43; iter: 0; batch classifier loss: 0.503352; batch adversarial loss: 0.516710\n",
      "epoch 44; iter: 0; batch classifier loss: 0.556369; batch adversarial loss: 0.507189\n",
      "epoch 45; iter: 0; batch classifier loss: 0.499069; batch adversarial loss: 0.640210\n",
      "epoch 46; iter: 0; batch classifier loss: 0.397105; batch adversarial loss: 0.499283\n",
      "epoch 47; iter: 0; batch classifier loss: 0.456432; batch adversarial loss: 0.578335\n",
      "epoch 48; iter: 0; batch classifier loss: 0.396934; batch adversarial loss: 0.610677\n",
      "epoch 49; iter: 0; batch classifier loss: 0.400102; batch adversarial loss: 0.494917\n",
      "epoch 50; iter: 0; batch classifier loss: 0.400116; batch adversarial loss: 0.525427\n",
      "epoch 51; iter: 0; batch classifier loss: 0.372821; batch adversarial loss: 0.517161\n",
      "epoch 52; iter: 0; batch classifier loss: 0.408500; batch adversarial loss: 0.521847\n",
      "epoch 53; iter: 0; batch classifier loss: 0.388653; batch adversarial loss: 0.517899\n",
      "epoch 54; iter: 0; batch classifier loss: 0.415533; batch adversarial loss: 0.572646\n",
      "epoch 55; iter: 0; batch classifier loss: 0.388535; batch adversarial loss: 0.558273\n",
      "epoch 56; iter: 0; batch classifier loss: 0.391291; batch adversarial loss: 0.507954\n",
      "epoch 57; iter: 0; batch classifier loss: 0.379337; batch adversarial loss: 0.564602\n",
      "epoch 58; iter: 0; batch classifier loss: 0.394996; batch adversarial loss: 0.544730\n",
      "epoch 59; iter: 0; batch classifier loss: 0.425809; batch adversarial loss: 0.506771\n",
      "epoch 60; iter: 0; batch classifier loss: 0.451431; batch adversarial loss: 0.563182\n",
      "epoch 61; iter: 0; batch classifier loss: 0.440372; batch adversarial loss: 0.535179\n",
      "epoch 62; iter: 0; batch classifier loss: 0.408062; batch adversarial loss: 0.544775\n",
      "epoch 63; iter: 0; batch classifier loss: 0.357268; batch adversarial loss: 0.600188\n",
      "epoch 64; iter: 0; batch classifier loss: 0.439140; batch adversarial loss: 0.599914\n",
      "epoch 65; iter: 0; batch classifier loss: 0.401914; batch adversarial loss: 0.497725\n",
      "epoch 66; iter: 0; batch classifier loss: 0.506870; batch adversarial loss: 0.499325\n",
      "epoch 67; iter: 0; batch classifier loss: 0.429828; batch adversarial loss: 0.545330\n",
      "epoch 68; iter: 0; batch classifier loss: 0.403523; batch adversarial loss: 0.582941\n",
      "epoch 69; iter: 0; batch classifier loss: 0.503651; batch adversarial loss: 0.527146\n",
      "epoch 70; iter: 0; batch classifier loss: 0.381316; batch adversarial loss: 0.573051\n",
      "epoch 71; iter: 0; batch classifier loss: 0.446811; batch adversarial loss: 0.601530\n",
      "epoch 72; iter: 0; batch classifier loss: 0.381582; batch adversarial loss: 0.619378\n",
      "epoch 73; iter: 0; batch classifier loss: 0.411710; batch adversarial loss: 0.526102\n",
      "epoch 74; iter: 0; batch classifier loss: 0.312016; batch adversarial loss: 0.636869\n",
      "epoch 75; iter: 0; batch classifier loss: 0.411144; batch adversarial loss: 0.608120\n",
      "epoch 76; iter: 0; batch classifier loss: 0.409047; batch adversarial loss: 0.517207\n",
      "epoch 77; iter: 0; batch classifier loss: 0.409517; batch adversarial loss: 0.552991\n",
      "epoch 78; iter: 0; batch classifier loss: 0.455073; batch adversarial loss: 0.553110\n",
      "epoch 79; iter: 0; batch classifier loss: 0.367343; batch adversarial loss: 0.562181\n",
      "epoch 80; iter: 0; batch classifier loss: 0.315094; batch adversarial loss: 0.516591\n",
      "epoch 81; iter: 0; batch classifier loss: 0.442062; batch adversarial loss: 0.517060\n",
      "epoch 82; iter: 0; batch classifier loss: 0.330779; batch adversarial loss: 0.587104\n",
      "epoch 83; iter: 0; batch classifier loss: 0.458672; batch adversarial loss: 0.543950\n",
      "epoch 84; iter: 0; batch classifier loss: 0.391397; batch adversarial loss: 0.562012\n",
      "epoch 85; iter: 0; batch classifier loss: 0.365601; batch adversarial loss: 0.545023\n",
      "epoch 86; iter: 0; batch classifier loss: 0.335973; batch adversarial loss: 0.644056\n",
      "epoch 87; iter: 0; batch classifier loss: 0.428224; batch adversarial loss: 0.564599\n",
      "epoch 88; iter: 0; batch classifier loss: 0.377528; batch adversarial loss: 0.661056\n",
      "epoch 89; iter: 0; batch classifier loss: 0.343390; batch adversarial loss: 0.505735\n",
      "epoch 90; iter: 0; batch classifier loss: 0.342745; batch adversarial loss: 0.582499\n",
      "epoch 91; iter: 0; batch classifier loss: 0.436414; batch adversarial loss: 0.479472\n",
      "epoch 92; iter: 0; batch classifier loss: 0.284539; batch adversarial loss: 0.607844\n",
      "epoch 93; iter: 0; batch classifier loss: 0.350845; batch adversarial loss: 0.517684\n",
      "epoch 94; iter: 0; batch classifier loss: 0.401438; batch adversarial loss: 0.573448\n",
      "epoch 95; iter: 0; batch classifier loss: 0.358613; batch adversarial loss: 0.421703\n",
      "epoch 96; iter: 0; batch classifier loss: 0.410463; batch adversarial loss: 0.487357\n",
      "epoch 97; iter: 0; batch classifier loss: 0.372038; batch adversarial loss: 0.517028\n",
      "epoch 98; iter: 0; batch classifier loss: 0.334758; batch adversarial loss: 0.562954\n",
      "epoch 99; iter: 0; batch classifier loss: 0.389918; batch adversarial loss: 0.535030\n",
      "epoch 100; iter: 0; batch classifier loss: 0.357254; batch adversarial loss: 0.515445\n",
      "epoch 101; iter: 0; batch classifier loss: 0.402819; batch adversarial loss: 0.452743\n",
      "epoch 102; iter: 0; batch classifier loss: 0.340053; batch adversarial loss: 0.589836\n",
      "epoch 103; iter: 0; batch classifier loss: 0.408784; batch adversarial loss: 0.443007\n",
      "epoch 104; iter: 0; batch classifier loss: 0.426464; batch adversarial loss: 0.507985\n",
      "epoch 105; iter: 0; batch classifier loss: 0.360926; batch adversarial loss: 0.506259\n",
      "epoch 106; iter: 0; batch classifier loss: 0.332245; batch adversarial loss: 0.505869\n",
      "epoch 107; iter: 0; batch classifier loss: 0.353484; batch adversarial loss: 0.527525\n",
      "epoch 108; iter: 0; batch classifier loss: 0.367614; batch adversarial loss: 0.524228\n",
      "epoch 109; iter: 0; batch classifier loss: 0.367755; batch adversarial loss: 0.596891\n",
      "epoch 110; iter: 0; batch classifier loss: 0.384802; batch adversarial loss: 0.645554\n",
      "epoch 111; iter: 0; batch classifier loss: 0.342754; batch adversarial loss: 0.518926\n",
      "epoch 112; iter: 0; batch classifier loss: 0.375832; batch adversarial loss: 0.533512\n",
      "epoch 113; iter: 0; batch classifier loss: 0.460396; batch adversarial loss: 0.504793\n",
      "epoch 114; iter: 0; batch classifier loss: 0.289611; batch adversarial loss: 0.545305\n",
      "epoch 115; iter: 0; batch classifier loss: 0.497038; batch adversarial loss: 0.648240\n",
      "epoch 116; iter: 0; batch classifier loss: 0.307121; batch adversarial loss: 0.486514\n",
      "epoch 117; iter: 0; batch classifier loss: 0.413849; batch adversarial loss: 0.506413\n",
      "epoch 118; iter: 0; batch classifier loss: 0.449331; batch adversarial loss: 0.562666\n",
      "epoch 119; iter: 0; batch classifier loss: 0.397812; batch adversarial loss: 0.556666\n",
      "epoch 120; iter: 0; batch classifier loss: 0.391200; batch adversarial loss: 0.611860\n",
      "epoch 121; iter: 0; batch classifier loss: 0.415802; batch adversarial loss: 0.496861\n",
      "epoch 122; iter: 0; batch classifier loss: 0.401807; batch adversarial loss: 0.552463\n",
      "epoch 123; iter: 0; batch classifier loss: 0.372615; batch adversarial loss: 0.543970\n",
      "epoch 124; iter: 0; batch classifier loss: 0.376927; batch adversarial loss: 0.546701\n",
      "epoch 125; iter: 0; batch classifier loss: 0.308622; batch adversarial loss: 0.451576\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 126; iter: 0; batch classifier loss: 0.366330; batch adversarial loss: 0.550419\n",
      "epoch 127; iter: 0; batch classifier loss: 0.447407; batch adversarial loss: 0.477189\n",
      "epoch 128; iter: 0; batch classifier loss: 0.389030; batch adversarial loss: 0.628685\n",
      "epoch 129; iter: 0; batch classifier loss: 0.478227; batch adversarial loss: 0.573194\n",
      "epoch 130; iter: 0; batch classifier loss: 0.388963; batch adversarial loss: 0.566542\n",
      "epoch 131; iter: 0; batch classifier loss: 0.384124; batch adversarial loss: 0.581876\n",
      "epoch 132; iter: 0; batch classifier loss: 0.322289; batch adversarial loss: 0.535236\n",
      "epoch 133; iter: 0; batch classifier loss: 0.400682; batch adversarial loss: 0.610105\n",
      "epoch 134; iter: 0; batch classifier loss: 0.396072; batch adversarial loss: 0.487264\n",
      "epoch 135; iter: 0; batch classifier loss: 0.344721; batch adversarial loss: 0.542737\n",
      "epoch 136; iter: 0; batch classifier loss: 0.339540; batch adversarial loss: 0.564783\n",
      "epoch 137; iter: 0; batch classifier loss: 0.386833; batch adversarial loss: 0.497659\n",
      "epoch 138; iter: 0; batch classifier loss: 0.316797; batch adversarial loss: 0.598929\n",
      "epoch 139; iter: 0; batch classifier loss: 0.432260; batch adversarial loss: 0.543370\n",
      "epoch 140; iter: 0; batch classifier loss: 0.402240; batch adversarial loss: 0.571783\n",
      "epoch 141; iter: 0; batch classifier loss: 0.240980; batch adversarial loss: 0.456559\n",
      "epoch 142; iter: 0; batch classifier loss: 0.364931; batch adversarial loss: 0.532297\n",
      "epoch 143; iter: 0; batch classifier loss: 0.331853; batch adversarial loss: 0.502881\n",
      "epoch 144; iter: 0; batch classifier loss: 0.390837; batch adversarial loss: 0.487493\n",
      "epoch 145; iter: 0; batch classifier loss: 0.256121; batch adversarial loss: 0.544880\n",
      "epoch 146; iter: 0; batch classifier loss: 0.482316; batch adversarial loss: 0.496673\n",
      "epoch 147; iter: 0; batch classifier loss: 0.450541; batch adversarial loss: 0.513427\n",
      "epoch 148; iter: 0; batch classifier loss: 0.339112; batch adversarial loss: 0.607039\n",
      "epoch 149; iter: 0; batch classifier loss: 0.384572; batch adversarial loss: 0.639879\n",
      "epoch 150; iter: 0; batch classifier loss: 0.412977; batch adversarial loss: 0.545389\n",
      "epoch 151; iter: 0; batch classifier loss: 0.343324; batch adversarial loss: 0.566115\n",
      "epoch 152; iter: 0; batch classifier loss: 0.386285; batch adversarial loss: 0.531437\n",
      "epoch 153; iter: 0; batch classifier loss: 0.322414; batch adversarial loss: 0.606839\n",
      "epoch 154; iter: 0; batch classifier loss: 0.323075; batch adversarial loss: 0.517807\n",
      "epoch 155; iter: 0; batch classifier loss: 0.349427; batch adversarial loss: 0.555514\n",
      "epoch 156; iter: 0; batch classifier loss: 0.411714; batch adversarial loss: 0.533965\n",
      "epoch 157; iter: 0; batch classifier loss: 0.353460; batch adversarial loss: 0.534329\n",
      "epoch 158; iter: 0; batch classifier loss: 0.368547; batch adversarial loss: 0.581005\n",
      "epoch 159; iter: 0; batch classifier loss: 0.383412; batch adversarial loss: 0.553922\n",
      "epoch 160; iter: 0; batch classifier loss: 0.415855; batch adversarial loss: 0.552175\n",
      "epoch 161; iter: 0; batch classifier loss: 0.350430; batch adversarial loss: 0.553081\n",
      "epoch 162; iter: 0; batch classifier loss: 0.375791; batch adversarial loss: 0.545789\n",
      "epoch 163; iter: 0; batch classifier loss: 0.375643; batch adversarial loss: 0.545420\n",
      "epoch 164; iter: 0; batch classifier loss: 0.298688; batch adversarial loss: 0.462095\n",
      "epoch 165; iter: 0; batch classifier loss: 0.435897; batch adversarial loss: 0.599918\n",
      "epoch 166; iter: 0; batch classifier loss: 0.340227; batch adversarial loss: 0.507504\n",
      "epoch 167; iter: 0; batch classifier loss: 0.412283; batch adversarial loss: 0.545799\n",
      "epoch 168; iter: 0; batch classifier loss: 0.312663; batch adversarial loss: 0.560070\n",
      "epoch 169; iter: 0; batch classifier loss: 0.372432; batch adversarial loss: 0.525187\n",
      "epoch 170; iter: 0; batch classifier loss: 0.291518; batch adversarial loss: 0.518502\n",
      "epoch 171; iter: 0; batch classifier loss: 0.371266; batch adversarial loss: 0.565331\n",
      "epoch 172; iter: 0; batch classifier loss: 0.381567; batch adversarial loss: 0.572296\n",
      "epoch 173; iter: 0; batch classifier loss: 0.297799; batch adversarial loss: 0.570302\n",
      "epoch 174; iter: 0; batch classifier loss: 0.340714; batch adversarial loss: 0.517047\n",
      "epoch 175; iter: 0; batch classifier loss: 0.306457; batch adversarial loss: 0.532476\n",
      "epoch 176; iter: 0; batch classifier loss: 0.415600; batch adversarial loss: 0.553510\n",
      "epoch 177; iter: 0; batch classifier loss: 0.332539; batch adversarial loss: 0.572772\n",
      "epoch 178; iter: 0; batch classifier loss: 0.395630; batch adversarial loss: 0.565196\n",
      "epoch 179; iter: 0; batch classifier loss: 0.374648; batch adversarial loss: 0.538168\n",
      "epoch 180; iter: 0; batch classifier loss: 0.414551; batch adversarial loss: 0.586082\n",
      "epoch 181; iter: 0; batch classifier loss: 0.412825; batch adversarial loss: 0.517942\n",
      "epoch 182; iter: 0; batch classifier loss: 0.348123; batch adversarial loss: 0.506214\n",
      "epoch 183; iter: 0; batch classifier loss: 0.395204; batch adversarial loss: 0.517356\n",
      "epoch 184; iter: 0; batch classifier loss: 0.347516; batch adversarial loss: 0.583182\n",
      "epoch 185; iter: 0; batch classifier loss: 0.372322; batch adversarial loss: 0.581975\n",
      "epoch 186; iter: 0; batch classifier loss: 0.314001; batch adversarial loss: 0.590860\n",
      "epoch 187; iter: 0; batch classifier loss: 0.313200; batch adversarial loss: 0.526687\n",
      "epoch 188; iter: 0; batch classifier loss: 0.301606; batch adversarial loss: 0.497826\n",
      "epoch 189; iter: 0; batch classifier loss: 0.317329; batch adversarial loss: 0.525063\n",
      "epoch 190; iter: 0; batch classifier loss: 0.359779; batch adversarial loss: 0.453573\n",
      "epoch 191; iter: 0; batch classifier loss: 0.380907; batch adversarial loss: 0.536164\n",
      "epoch 192; iter: 0; batch classifier loss: 0.343217; batch adversarial loss: 0.645569\n",
      "epoch 193; iter: 0; batch classifier loss: 0.313888; batch adversarial loss: 0.543224\n",
      "epoch 194; iter: 0; batch classifier loss: 0.317197; batch adversarial loss: 0.486787\n",
      "epoch 195; iter: 0; batch classifier loss: 0.375616; batch adversarial loss: 0.537971\n",
      "epoch 196; iter: 0; batch classifier loss: 0.329377; batch adversarial loss: 0.516047\n",
      "epoch 197; iter: 0; batch classifier loss: 0.390520; batch adversarial loss: 0.597729\n",
      "epoch 198; iter: 0; batch classifier loss: 0.302243; batch adversarial loss: 0.544950\n",
      "epoch 199; iter: 0; batch classifier loss: 0.298021; batch adversarial loss: 0.526568\n",
      "epoch 0; iter: 0; batch classifier loss: 0.724685; batch adversarial loss: 0.638121\n",
      "epoch 1; iter: 0; batch classifier loss: 0.614807; batch adversarial loss: 0.669970\n",
      "epoch 2; iter: 0; batch classifier loss: 0.538029; batch adversarial loss: 0.671734\n",
      "epoch 3; iter: 0; batch classifier loss: 0.617725; batch adversarial loss: 0.629966\n",
      "epoch 4; iter: 0; batch classifier loss: 0.632998; batch adversarial loss: 0.625870\n",
      "epoch 5; iter: 0; batch classifier loss: 0.571576; batch adversarial loss: 0.586405\n",
      "epoch 6; iter: 0; batch classifier loss: 0.589988; batch adversarial loss: 0.635576\n",
      "epoch 7; iter: 0; batch classifier loss: 0.605937; batch adversarial loss: 0.595172\n",
      "epoch 8; iter: 0; batch classifier loss: 0.509545; batch adversarial loss: 0.603276\n",
      "epoch 9; iter: 0; batch classifier loss: 0.599864; batch adversarial loss: 0.556964\n",
      "epoch 10; iter: 0; batch classifier loss: 0.496482; batch adversarial loss: 0.555618\n",
      "epoch 11; iter: 0; batch classifier loss: 0.544087; batch adversarial loss: 0.567895\n",
      "epoch 12; iter: 0; batch classifier loss: 0.480498; batch adversarial loss: 0.548641\n",
      "epoch 13; iter: 0; batch classifier loss: 0.617974; batch adversarial loss: 0.514526\n",
      "epoch 14; iter: 0; batch classifier loss: 0.574082; batch adversarial loss: 0.581781\n",
      "epoch 15; iter: 0; batch classifier loss: 0.494962; batch adversarial loss: 0.547224\n",
      "epoch 16; iter: 0; batch classifier loss: 0.503626; batch adversarial loss: 0.558763\n",
      "epoch 17; iter: 0; batch classifier loss: 0.463962; batch adversarial loss: 0.521332\n",
      "epoch 18; iter: 0; batch classifier loss: 0.452751; batch adversarial loss: 0.527093\n",
      "epoch 19; iter: 0; batch classifier loss: 0.524374; batch adversarial loss: 0.561128\n",
      "epoch 20; iter: 0; batch classifier loss: 0.455097; batch adversarial loss: 0.548825\n",
      "epoch 21; iter: 0; batch classifier loss: 0.465385; batch adversarial loss: 0.523595\n",
      "epoch 22; iter: 0; batch classifier loss: 0.481128; batch adversarial loss: 0.552120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 23; iter: 0; batch classifier loss: 0.492124; batch adversarial loss: 0.526277\n",
      "epoch 24; iter: 0; batch classifier loss: 0.487667; batch adversarial loss: 0.480668\n",
      "epoch 25; iter: 0; batch classifier loss: 0.495689; batch adversarial loss: 0.589887\n",
      "epoch 26; iter: 0; batch classifier loss: 0.433736; batch adversarial loss: 0.510566\n",
      "epoch 27; iter: 0; batch classifier loss: 0.482950; batch adversarial loss: 0.531020\n",
      "epoch 28; iter: 0; batch classifier loss: 0.475109; batch adversarial loss: 0.532116\n",
      "epoch 29; iter: 0; batch classifier loss: 0.396244; batch adversarial loss: 0.577910\n",
      "epoch 30; iter: 0; batch classifier loss: 0.425452; batch adversarial loss: 0.473249\n",
      "epoch 31; iter: 0; batch classifier loss: 0.463805; batch adversarial loss: 0.500858\n",
      "epoch 32; iter: 0; batch classifier loss: 0.469453; batch adversarial loss: 0.509834\n",
      "epoch 33; iter: 0; batch classifier loss: 0.480407; batch adversarial loss: 0.553843\n",
      "epoch 34; iter: 0; batch classifier loss: 0.488254; batch adversarial loss: 0.614906\n",
      "epoch 35; iter: 0; batch classifier loss: 0.426209; batch adversarial loss: 0.482744\n",
      "epoch 36; iter: 0; batch classifier loss: 0.526872; batch adversarial loss: 0.571960\n",
      "epoch 37; iter: 0; batch classifier loss: 0.592059; batch adversarial loss: 0.498648\n",
      "epoch 38; iter: 0; batch classifier loss: 0.527497; batch adversarial loss: 0.610581\n",
      "epoch 39; iter: 0; batch classifier loss: 0.434251; batch adversarial loss: 0.571425\n",
      "epoch 40; iter: 0; batch classifier loss: 0.488847; batch adversarial loss: 0.561735\n",
      "epoch 41; iter: 0; batch classifier loss: 0.462160; batch adversarial loss: 0.522194\n",
      "epoch 42; iter: 0; batch classifier loss: 0.541296; batch adversarial loss: 0.616678\n",
      "epoch 43; iter: 0; batch classifier loss: 0.398974; batch adversarial loss: 0.535046\n",
      "epoch 44; iter: 0; batch classifier loss: 0.482600; batch adversarial loss: 0.537653\n",
      "epoch 45; iter: 0; batch classifier loss: 0.433111; batch adversarial loss: 0.564812\n",
      "epoch 46; iter: 0; batch classifier loss: 0.441035; batch adversarial loss: 0.517970\n",
      "epoch 47; iter: 0; batch classifier loss: 0.520803; batch adversarial loss: 0.483250\n",
      "epoch 48; iter: 0; batch classifier loss: 0.411380; batch adversarial loss: 0.535700\n",
      "epoch 49; iter: 0; batch classifier loss: 0.411368; batch adversarial loss: 0.527208\n",
      "epoch 50; iter: 0; batch classifier loss: 0.415238; batch adversarial loss: 0.553717\n",
      "epoch 51; iter: 0; batch classifier loss: 0.413781; batch adversarial loss: 0.472788\n",
      "epoch 52; iter: 0; batch classifier loss: 0.375574; batch adversarial loss: 0.562980\n",
      "epoch 53; iter: 0; batch classifier loss: 0.403746; batch adversarial loss: 0.625641\n",
      "epoch 54; iter: 0; batch classifier loss: 0.419942; batch adversarial loss: 0.517456\n",
      "epoch 55; iter: 0; batch classifier loss: 0.478642; batch adversarial loss: 0.471563\n",
      "epoch 56; iter: 0; batch classifier loss: 0.395766; batch adversarial loss: 0.627121\n",
      "epoch 57; iter: 0; batch classifier loss: 0.372136; batch adversarial loss: 0.516715\n",
      "epoch 58; iter: 0; batch classifier loss: 0.413687; batch adversarial loss: 0.517179\n",
      "epoch 59; iter: 0; batch classifier loss: 0.417084; batch adversarial loss: 0.590038\n",
      "epoch 60; iter: 0; batch classifier loss: 0.376904; batch adversarial loss: 0.526219\n",
      "epoch 61; iter: 0; batch classifier loss: 0.413455; batch adversarial loss: 0.562539\n",
      "epoch 62; iter: 0; batch classifier loss: 0.481648; batch adversarial loss: 0.526719\n",
      "epoch 63; iter: 0; batch classifier loss: 0.433814; batch adversarial loss: 0.544256\n",
      "epoch 64; iter: 0; batch classifier loss: 0.399357; batch adversarial loss: 0.644876\n",
      "epoch 65; iter: 0; batch classifier loss: 0.471666; batch adversarial loss: 0.517586\n",
      "epoch 66; iter: 0; batch classifier loss: 0.320755; batch adversarial loss: 0.535239\n",
      "epoch 67; iter: 0; batch classifier loss: 0.404390; batch adversarial loss: 0.544122\n",
      "epoch 68; iter: 0; batch classifier loss: 0.408193; batch adversarial loss: 0.562716\n",
      "epoch 69; iter: 0; batch classifier loss: 0.377204; batch adversarial loss: 0.480686\n",
      "epoch 70; iter: 0; batch classifier loss: 0.331013; batch adversarial loss: 0.471594\n",
      "epoch 71; iter: 0; batch classifier loss: 0.335706; batch adversarial loss: 0.517282\n",
      "epoch 72; iter: 0; batch classifier loss: 0.429749; batch adversarial loss: 0.563008\n",
      "epoch 73; iter: 0; batch classifier loss: 0.474409; batch adversarial loss: 0.506494\n",
      "epoch 74; iter: 0; batch classifier loss: 0.425172; batch adversarial loss: 0.525775\n",
      "epoch 75; iter: 0; batch classifier loss: 0.402661; batch adversarial loss: 0.581143\n",
      "epoch 76; iter: 0; batch classifier loss: 0.377165; batch adversarial loss: 0.590927\n",
      "epoch 77; iter: 0; batch classifier loss: 0.458520; batch adversarial loss: 0.535396\n",
      "epoch 78; iter: 0; batch classifier loss: 0.366889; batch adversarial loss: 0.571654\n",
      "epoch 79; iter: 0; batch classifier loss: 0.384904; batch adversarial loss: 0.572007\n",
      "epoch 80; iter: 0; batch classifier loss: 0.391232; batch adversarial loss: 0.581098\n",
      "epoch 81; iter: 0; batch classifier loss: 0.470100; batch adversarial loss: 0.617361\n",
      "epoch 82; iter: 0; batch classifier loss: 0.453494; batch adversarial loss: 0.554009\n",
      "epoch 83; iter: 0; batch classifier loss: 0.398992; batch adversarial loss: 0.506696\n",
      "epoch 84; iter: 0; batch classifier loss: 0.382999; batch adversarial loss: 0.508514\n",
      "epoch 85; iter: 0; batch classifier loss: 0.443770; batch adversarial loss: 0.544180\n",
      "epoch 86; iter: 0; batch classifier loss: 0.437410; batch adversarial loss: 0.590114\n",
      "epoch 87; iter: 0; batch classifier loss: 0.399732; batch adversarial loss: 0.489760\n",
      "epoch 88; iter: 0; batch classifier loss: 0.429195; batch adversarial loss: 0.490240\n",
      "epoch 89; iter: 0; batch classifier loss: 0.364466; batch adversarial loss: 0.535260\n",
      "epoch 90; iter: 0; batch classifier loss: 0.393361; batch adversarial loss: 0.581011\n",
      "epoch 91; iter: 0; batch classifier loss: 0.334301; batch adversarial loss: 0.590263\n",
      "epoch 92; iter: 0; batch classifier loss: 0.381706; batch adversarial loss: 0.599640\n",
      "epoch 93; iter: 0; batch classifier loss: 0.357271; batch adversarial loss: 0.480628\n",
      "epoch 94; iter: 0; batch classifier loss: 0.415171; batch adversarial loss: 0.553561\n",
      "epoch 95; iter: 0; batch classifier loss: 0.419688; batch adversarial loss: 0.489509\n",
      "epoch 96; iter: 0; batch classifier loss: 0.355739; batch adversarial loss: 0.581414\n",
      "epoch 97; iter: 0; batch classifier loss: 0.425252; batch adversarial loss: 0.562972\n",
      "epoch 98; iter: 0; batch classifier loss: 0.412866; batch adversarial loss: 0.562133\n",
      "epoch 99; iter: 0; batch classifier loss: 0.417617; batch adversarial loss: 0.534612\n",
      "epoch 100; iter: 0; batch classifier loss: 0.438113; batch adversarial loss: 0.516614\n",
      "epoch 101; iter: 0; batch classifier loss: 0.465105; batch adversarial loss: 0.489271\n",
      "epoch 102; iter: 0; batch classifier loss: 0.401878; batch adversarial loss: 0.544249\n",
      "epoch 103; iter: 0; batch classifier loss: 0.386140; batch adversarial loss: 0.572197\n",
      "epoch 104; iter: 0; batch classifier loss: 0.312810; batch adversarial loss: 0.635576\n",
      "epoch 105; iter: 0; batch classifier loss: 0.446896; batch adversarial loss: 0.571730\n",
      "epoch 106; iter: 0; batch classifier loss: 0.381160; batch adversarial loss: 0.553569\n",
      "epoch 107; iter: 0; batch classifier loss: 0.442907; batch adversarial loss: 0.545475\n",
      "epoch 108; iter: 0; batch classifier loss: 0.441266; batch adversarial loss: 0.554116\n",
      "epoch 109; iter: 0; batch classifier loss: 0.318469; batch adversarial loss: 0.590411\n",
      "epoch 110; iter: 0; batch classifier loss: 0.445716; batch adversarial loss: 0.618508\n",
      "epoch 111; iter: 0; batch classifier loss: 0.361645; batch adversarial loss: 0.645197\n",
      "epoch 112; iter: 0; batch classifier loss: 0.392444; batch adversarial loss: 0.589810\n",
      "epoch 113; iter: 0; batch classifier loss: 0.338963; batch adversarial loss: 0.580938\n",
      "epoch 114; iter: 0; batch classifier loss: 0.322481; batch adversarial loss: 0.581031\n",
      "epoch 115; iter: 0; batch classifier loss: 0.424524; batch adversarial loss: 0.525951\n",
      "epoch 116; iter: 0; batch classifier loss: 0.404043; batch adversarial loss: 0.581310\n",
      "epoch 117; iter: 0; batch classifier loss: 0.358328; batch adversarial loss: 0.571961\n",
      "epoch 118; iter: 0; batch classifier loss: 0.387770; batch adversarial loss: 0.516625\n",
      "epoch 119; iter: 0; batch classifier loss: 0.432285; batch adversarial loss: 0.673445\n",
      "epoch 120; iter: 0; batch classifier loss: 0.300470; batch adversarial loss: 0.526394\n",
      "epoch 121; iter: 0; batch classifier loss: 0.395513; batch adversarial loss: 0.581632\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 122; iter: 0; batch classifier loss: 0.336755; batch adversarial loss: 0.507913\n",
      "epoch 123; iter: 0; batch classifier loss: 0.349640; batch adversarial loss: 0.590409\n",
      "epoch 124; iter: 0; batch classifier loss: 0.435324; batch adversarial loss: 0.581595\n",
      "epoch 125; iter: 0; batch classifier loss: 0.391262; batch adversarial loss: 0.572395\n",
      "epoch 126; iter: 0; batch classifier loss: 0.285565; batch adversarial loss: 0.489452\n",
      "epoch 127; iter: 0; batch classifier loss: 0.433612; batch adversarial loss: 0.581512\n",
      "epoch 128; iter: 0; batch classifier loss: 0.401919; batch adversarial loss: 0.508155\n",
      "epoch 129; iter: 0; batch classifier loss: 0.448600; batch adversarial loss: 0.599455\n",
      "epoch 130; iter: 0; batch classifier loss: 0.347634; batch adversarial loss: 0.470901\n",
      "epoch 131; iter: 0; batch classifier loss: 0.344702; batch adversarial loss: 0.498525\n",
      "epoch 132; iter: 0; batch classifier loss: 0.357753; batch adversarial loss: 0.617842\n",
      "epoch 133; iter: 0; batch classifier loss: 0.345242; batch adversarial loss: 0.544639\n",
      "epoch 134; iter: 0; batch classifier loss: 0.398777; batch adversarial loss: 0.571625\n",
      "epoch 135; iter: 0; batch classifier loss: 0.401230; batch adversarial loss: 0.535334\n",
      "epoch 136; iter: 0; batch classifier loss: 0.312334; batch adversarial loss: 0.590455\n",
      "epoch 137; iter: 0; batch classifier loss: 0.324522; batch adversarial loss: 0.526243\n",
      "epoch 138; iter: 0; batch classifier loss: 0.401998; batch adversarial loss: 0.516877\n",
      "epoch 139; iter: 0; batch classifier loss: 0.342063; batch adversarial loss: 0.590374\n",
      "epoch 140; iter: 0; batch classifier loss: 0.352790; batch adversarial loss: 0.562595\n",
      "epoch 141; iter: 0; batch classifier loss: 0.430134; batch adversarial loss: 0.581633\n",
      "epoch 142; iter: 0; batch classifier loss: 0.387966; batch adversarial loss: 0.544658\n",
      "epoch 143; iter: 0; batch classifier loss: 0.407070; batch adversarial loss: 0.516696\n",
      "epoch 144; iter: 0; batch classifier loss: 0.310224; batch adversarial loss: 0.581042\n",
      "epoch 145; iter: 0; batch classifier loss: 0.367005; batch adversarial loss: 0.544447\n",
      "epoch 146; iter: 0; batch classifier loss: 0.399559; batch adversarial loss: 0.581671\n",
      "epoch 147; iter: 0; batch classifier loss: 0.377528; batch adversarial loss: 0.498618\n",
      "epoch 148; iter: 0; batch classifier loss: 0.369862; batch adversarial loss: 0.507793\n",
      "epoch 149; iter: 0; batch classifier loss: 0.363023; batch adversarial loss: 0.535275\n",
      "epoch 150; iter: 0; batch classifier loss: 0.383454; batch adversarial loss: 0.553669\n",
      "epoch 151; iter: 0; batch classifier loss: 0.327205; batch adversarial loss: 0.617580\n",
      "epoch 152; iter: 0; batch classifier loss: 0.403796; batch adversarial loss: 0.608487\n",
      "epoch 153; iter: 0; batch classifier loss: 0.430345; batch adversarial loss: 0.571908\n",
      "epoch 154; iter: 0; batch classifier loss: 0.395494; batch adversarial loss: 0.563205\n",
      "epoch 155; iter: 0; batch classifier loss: 0.357484; batch adversarial loss: 0.608750\n",
      "epoch 156; iter: 0; batch classifier loss: 0.435233; batch adversarial loss: 0.517744\n",
      "epoch 157; iter: 0; batch classifier loss: 0.320503; batch adversarial loss: 0.526471\n",
      "epoch 158; iter: 0; batch classifier loss: 0.339518; batch adversarial loss: 0.563108\n",
      "epoch 159; iter: 0; batch classifier loss: 0.324042; batch adversarial loss: 0.590518\n",
      "epoch 160; iter: 0; batch classifier loss: 0.395894; batch adversarial loss: 0.517155\n",
      "epoch 161; iter: 0; batch classifier loss: 0.356172; batch adversarial loss: 0.589974\n",
      "epoch 162; iter: 0; batch classifier loss: 0.343553; batch adversarial loss: 0.489977\n",
      "epoch 163; iter: 0; batch classifier loss: 0.421923; batch adversarial loss: 0.590547\n",
      "epoch 164; iter: 0; batch classifier loss: 0.441073; batch adversarial loss: 0.489262\n",
      "epoch 165; iter: 0; batch classifier loss: 0.326195; batch adversarial loss: 0.609110\n",
      "epoch 166; iter: 0; batch classifier loss: 0.390141; batch adversarial loss: 0.526200\n",
      "epoch 167; iter: 0; batch classifier loss: 0.329032; batch adversarial loss: 0.525481\n",
      "epoch 168; iter: 0; batch classifier loss: 0.274316; batch adversarial loss: 0.526019\n",
      "epoch 169; iter: 0; batch classifier loss: 0.363448; batch adversarial loss: 0.535377\n",
      "epoch 170; iter: 0; batch classifier loss: 0.364738; batch adversarial loss: 0.563220\n",
      "epoch 171; iter: 0; batch classifier loss: 0.330653; batch adversarial loss: 0.590364\n",
      "epoch 172; iter: 0; batch classifier loss: 0.382337; batch adversarial loss: 0.590214\n",
      "epoch 173; iter: 0; batch classifier loss: 0.367851; batch adversarial loss: 0.581643\n",
      "epoch 174; iter: 0; batch classifier loss: 0.304681; batch adversarial loss: 0.608460\n",
      "epoch 175; iter: 0; batch classifier loss: 0.383565; batch adversarial loss: 0.553339\n",
      "epoch 176; iter: 0; batch classifier loss: 0.348196; batch adversarial loss: 0.553454\n",
      "epoch 177; iter: 0; batch classifier loss: 0.350888; batch adversarial loss: 0.507692\n",
      "epoch 178; iter: 0; batch classifier loss: 0.426413; batch adversarial loss: 0.553964\n",
      "epoch 179; iter: 0; batch classifier loss: 0.340025; batch adversarial loss: 0.571909\n",
      "epoch 180; iter: 0; batch classifier loss: 0.301129; batch adversarial loss: 0.507793\n",
      "epoch 181; iter: 0; batch classifier loss: 0.391395; batch adversarial loss: 0.590152\n",
      "epoch 182; iter: 0; batch classifier loss: 0.309141; batch adversarial loss: 0.645795\n",
      "epoch 183; iter: 0; batch classifier loss: 0.285892; batch adversarial loss: 0.480212\n",
      "epoch 184; iter: 0; batch classifier loss: 0.318249; batch adversarial loss: 0.508049\n",
      "epoch 185; iter: 0; batch classifier loss: 0.348800; batch adversarial loss: 0.535869\n",
      "epoch 186; iter: 0; batch classifier loss: 0.367538; batch adversarial loss: 0.535182\n",
      "epoch 187; iter: 0; batch classifier loss: 0.365335; batch adversarial loss: 0.507597\n",
      "epoch 188; iter: 0; batch classifier loss: 0.372035; batch adversarial loss: 0.553562\n",
      "epoch 189; iter: 0; batch classifier loss: 0.421947; batch adversarial loss: 0.553666\n",
      "epoch 190; iter: 0; batch classifier loss: 0.469981; batch adversarial loss: 0.572008\n",
      "epoch 191; iter: 0; batch classifier loss: 0.322868; batch adversarial loss: 0.544396\n",
      "epoch 192; iter: 0; batch classifier loss: 0.287116; batch adversarial loss: 0.471067\n",
      "epoch 193; iter: 0; batch classifier loss: 0.459804; batch adversarial loss: 0.517091\n",
      "epoch 194; iter: 0; batch classifier loss: 0.350986; batch adversarial loss: 0.544630\n",
      "epoch 195; iter: 0; batch classifier loss: 0.376094; batch adversarial loss: 0.544648\n",
      "epoch 196; iter: 0; batch classifier loss: 0.421872; batch adversarial loss: 0.654733\n",
      "epoch 197; iter: 0; batch classifier loss: 0.417817; batch adversarial loss: 0.526080\n",
      "epoch 198; iter: 0; batch classifier loss: 0.390387; batch adversarial loss: 0.535414\n",
      "epoch 199; iter: 0; batch classifier loss: 0.329786; batch adversarial loss: 0.581154\n",
      "epoch 0; iter: 0; batch classifier loss: 0.664689; batch adversarial loss: 0.729962\n",
      "epoch 1; iter: 0; batch classifier loss: 0.718384; batch adversarial loss: 0.825020\n",
      "epoch 2; iter: 0; batch classifier loss: 0.943359; batch adversarial loss: 0.850262\n",
      "epoch 3; iter: 0; batch classifier loss: 0.915686; batch adversarial loss: 0.757771\n",
      "epoch 4; iter: 0; batch classifier loss: 0.733205; batch adversarial loss: 0.679379\n",
      "epoch 5; iter: 0; batch classifier loss: 0.596948; batch adversarial loss: 0.642261\n",
      "epoch 6; iter: 0; batch classifier loss: 0.567813; batch adversarial loss: 0.624796\n",
      "epoch 7; iter: 0; batch classifier loss: 0.524000; batch adversarial loss: 0.579617\n",
      "epoch 8; iter: 0; batch classifier loss: 0.567836; batch adversarial loss: 0.618942\n",
      "epoch 9; iter: 0; batch classifier loss: 0.529425; batch adversarial loss: 0.612234\n",
      "epoch 10; iter: 0; batch classifier loss: 0.536195; batch adversarial loss: 0.602001\n",
      "epoch 11; iter: 0; batch classifier loss: 0.552823; batch adversarial loss: 0.616395\n",
      "epoch 12; iter: 0; batch classifier loss: 0.543767; batch adversarial loss: 0.561814\n",
      "epoch 13; iter: 0; batch classifier loss: 0.518004; batch adversarial loss: 0.518309\n",
      "epoch 14; iter: 0; batch classifier loss: 0.489468; batch adversarial loss: 0.511337\n",
      "epoch 15; iter: 0; batch classifier loss: 0.538110; batch adversarial loss: 0.571425\n",
      "epoch 16; iter: 0; batch classifier loss: 0.594806; batch adversarial loss: 0.538999\n",
      "epoch 17; iter: 0; batch classifier loss: 0.489896; batch adversarial loss: 0.585244\n",
      "epoch 18; iter: 0; batch classifier loss: 0.515972; batch adversarial loss: 0.613532\n",
      "epoch 19; iter: 0; batch classifier loss: 0.518365; batch adversarial loss: 0.579210\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20; iter: 0; batch classifier loss: 0.504718; batch adversarial loss: 0.593084\n",
      "epoch 21; iter: 0; batch classifier loss: 0.548036; batch adversarial loss: 0.572472\n",
      "epoch 22; iter: 0; batch classifier loss: 0.563302; batch adversarial loss: 0.534130\n",
      "epoch 23; iter: 0; batch classifier loss: 0.595923; batch adversarial loss: 0.473521\n",
      "epoch 24; iter: 0; batch classifier loss: 0.525481; batch adversarial loss: 0.561409\n",
      "epoch 25; iter: 0; batch classifier loss: 0.461177; batch adversarial loss: 0.569159\n",
      "epoch 26; iter: 0; batch classifier loss: 0.461784; batch adversarial loss: 0.609652\n",
      "epoch 27; iter: 0; batch classifier loss: 0.482562; batch adversarial loss: 0.555264\n",
      "epoch 28; iter: 0; batch classifier loss: 0.477608; batch adversarial loss: 0.580248\n",
      "epoch 29; iter: 0; batch classifier loss: 0.563539; batch adversarial loss: 0.531274\n",
      "epoch 30; iter: 0; batch classifier loss: 0.476073; batch adversarial loss: 0.593181\n",
      "epoch 31; iter: 0; batch classifier loss: 0.416069; batch adversarial loss: 0.517634\n",
      "epoch 32; iter: 0; batch classifier loss: 0.396504; batch adversarial loss: 0.558928\n",
      "epoch 33; iter: 0; batch classifier loss: 0.431319; batch adversarial loss: 0.594279\n",
      "epoch 34; iter: 0; batch classifier loss: 0.452290; batch adversarial loss: 0.530382\n",
      "epoch 35; iter: 0; batch classifier loss: 0.497814; batch adversarial loss: 0.613064\n",
      "epoch 36; iter: 0; batch classifier loss: 0.434761; batch adversarial loss: 0.592894\n",
      "epoch 37; iter: 0; batch classifier loss: 0.414444; batch adversarial loss: 0.601516\n",
      "epoch 38; iter: 0; batch classifier loss: 0.523764; batch adversarial loss: 0.592031\n",
      "epoch 39; iter: 0; batch classifier loss: 0.429003; batch adversarial loss: 0.555517\n",
      "epoch 40; iter: 0; batch classifier loss: 0.496032; batch adversarial loss: 0.503584\n",
      "epoch 41; iter: 0; batch classifier loss: 0.415052; batch adversarial loss: 0.514346\n",
      "epoch 42; iter: 0; batch classifier loss: 0.465390; batch adversarial loss: 0.489261\n",
      "epoch 43; iter: 0; batch classifier loss: 0.409945; batch adversarial loss: 0.598236\n",
      "epoch 44; iter: 0; batch classifier loss: 0.453756; batch adversarial loss: 0.579828\n",
      "epoch 45; iter: 0; batch classifier loss: 0.450434; batch adversarial loss: 0.535787\n",
      "epoch 46; iter: 0; batch classifier loss: 0.473279; batch adversarial loss: 0.546131\n",
      "epoch 47; iter: 0; batch classifier loss: 0.407471; batch adversarial loss: 0.543886\n",
      "epoch 48; iter: 0; batch classifier loss: 0.492020; batch adversarial loss: 0.578162\n",
      "epoch 49; iter: 0; batch classifier loss: 0.465470; batch adversarial loss: 0.572943\n",
      "epoch 50; iter: 0; batch classifier loss: 0.503906; batch adversarial loss: 0.553952\n",
      "epoch 51; iter: 0; batch classifier loss: 0.484000; batch adversarial loss: 0.544388\n",
      "epoch 52; iter: 0; batch classifier loss: 0.456341; batch adversarial loss: 0.510597\n",
      "epoch 53; iter: 0; batch classifier loss: 0.391712; batch adversarial loss: 0.605721\n",
      "epoch 54; iter: 0; batch classifier loss: 0.402387; batch adversarial loss: 0.501104\n",
      "epoch 55; iter: 0; batch classifier loss: 0.387876; batch adversarial loss: 0.527405\n",
      "epoch 56; iter: 0; batch classifier loss: 0.454416; batch adversarial loss: 0.553722\n",
      "epoch 57; iter: 0; batch classifier loss: 0.461074; batch adversarial loss: 0.526909\n",
      "epoch 58; iter: 0; batch classifier loss: 0.407756; batch adversarial loss: 0.642162\n",
      "epoch 59; iter: 0; batch classifier loss: 0.478419; batch adversarial loss: 0.553779\n",
      "epoch 60; iter: 0; batch classifier loss: 0.455779; batch adversarial loss: 0.507380\n",
      "epoch 61; iter: 0; batch classifier loss: 0.450962; batch adversarial loss: 0.535607\n",
      "epoch 62; iter: 0; batch classifier loss: 0.410678; batch adversarial loss: 0.553646\n",
      "epoch 63; iter: 0; batch classifier loss: 0.446971; batch adversarial loss: 0.607402\n",
      "epoch 64; iter: 0; batch classifier loss: 0.441801; batch adversarial loss: 0.508611\n",
      "epoch 65; iter: 0; batch classifier loss: 0.401394; batch adversarial loss: 0.625520\n",
      "epoch 66; iter: 0; batch classifier loss: 0.413116; batch adversarial loss: 0.580896\n",
      "epoch 67; iter: 0; batch classifier loss: 0.441869; batch adversarial loss: 0.588137\n",
      "epoch 68; iter: 0; batch classifier loss: 0.363100; batch adversarial loss: 0.643130\n",
      "epoch 69; iter: 0; batch classifier loss: 0.447938; batch adversarial loss: 0.606350\n",
      "epoch 70; iter: 0; batch classifier loss: 0.398946; batch adversarial loss: 0.544759\n",
      "epoch 71; iter: 0; batch classifier loss: 0.331229; batch adversarial loss: 0.491174\n",
      "epoch 72; iter: 0; batch classifier loss: 0.393040; batch adversarial loss: 0.535695\n",
      "epoch 73; iter: 0; batch classifier loss: 0.424977; batch adversarial loss: 0.508616\n",
      "epoch 74; iter: 0; batch classifier loss: 0.315177; batch adversarial loss: 0.482325\n",
      "epoch 75; iter: 0; batch classifier loss: 0.379374; batch adversarial loss: 0.607947\n",
      "epoch 76; iter: 0; batch classifier loss: 0.348275; batch adversarial loss: 0.527074\n",
      "epoch 77; iter: 0; batch classifier loss: 0.387496; batch adversarial loss: 0.608495\n",
      "epoch 78; iter: 0; batch classifier loss: 0.447104; batch adversarial loss: 0.534346\n",
      "epoch 79; iter: 0; batch classifier loss: 0.428475; batch adversarial loss: 0.542829\n",
      "epoch 80; iter: 0; batch classifier loss: 0.366464; batch adversarial loss: 0.580674\n",
      "epoch 81; iter: 0; batch classifier loss: 0.373072; batch adversarial loss: 0.606114\n",
      "epoch 82; iter: 0; batch classifier loss: 0.388478; batch adversarial loss: 0.543397\n",
      "epoch 83; iter: 0; batch classifier loss: 0.361993; batch adversarial loss: 0.490190\n",
      "epoch 84; iter: 0; batch classifier loss: 0.470196; batch adversarial loss: 0.508748\n",
      "epoch 85; iter: 0; batch classifier loss: 0.380883; batch adversarial loss: 0.578471\n",
      "epoch 86; iter: 0; batch classifier loss: 0.432584; batch adversarial loss: 0.535528\n",
      "epoch 87; iter: 0; batch classifier loss: 0.395983; batch adversarial loss: 0.564597\n",
      "epoch 88; iter: 0; batch classifier loss: 0.430177; batch adversarial loss: 0.563344\n",
      "epoch 89; iter: 0; batch classifier loss: 0.405857; batch adversarial loss: 0.661660\n",
      "epoch 90; iter: 0; batch classifier loss: 0.413187; batch adversarial loss: 0.474465\n",
      "epoch 91; iter: 0; batch classifier loss: 0.413518; batch adversarial loss: 0.579530\n",
      "epoch 92; iter: 0; batch classifier loss: 0.397655; batch adversarial loss: 0.526442\n",
      "epoch 93; iter: 0; batch classifier loss: 0.364577; batch adversarial loss: 0.606694\n",
      "epoch 94; iter: 0; batch classifier loss: 0.374699; batch adversarial loss: 0.507041\n",
      "epoch 95; iter: 0; batch classifier loss: 0.321274; batch adversarial loss: 0.552064\n",
      "epoch 96; iter: 0; batch classifier loss: 0.352825; batch adversarial loss: 0.624597\n",
      "epoch 97; iter: 0; batch classifier loss: 0.382527; batch adversarial loss: 0.571328\n",
      "epoch 98; iter: 0; batch classifier loss: 0.341465; batch adversarial loss: 0.650561\n",
      "epoch 99; iter: 0; batch classifier loss: 0.401556; batch adversarial loss: 0.516291\n",
      "epoch 100; iter: 0; batch classifier loss: 0.410704; batch adversarial loss: 0.560873\n",
      "epoch 101; iter: 0; batch classifier loss: 0.392812; batch adversarial loss: 0.536994\n",
      "epoch 102; iter: 0; batch classifier loss: 0.394729; batch adversarial loss: 0.537781\n",
      "epoch 103; iter: 0; batch classifier loss: 0.394105; batch adversarial loss: 0.559003\n",
      "epoch 104; iter: 0; batch classifier loss: 0.339017; batch adversarial loss: 0.540437\n",
      "epoch 105; iter: 0; batch classifier loss: 0.388309; batch adversarial loss: 0.569657\n",
      "epoch 106; iter: 0; batch classifier loss: 0.416548; batch adversarial loss: 0.544831\n",
      "epoch 107; iter: 0; batch classifier loss: 0.327778; batch adversarial loss: 0.515491\n",
      "epoch 108; iter: 0; batch classifier loss: 0.332649; batch adversarial loss: 0.553230\n",
      "epoch 109; iter: 0; batch classifier loss: 0.425056; batch adversarial loss: 0.596928\n",
      "epoch 110; iter: 0; batch classifier loss: 0.416920; batch adversarial loss: 0.633547\n",
      "epoch 111; iter: 0; batch classifier loss: 0.348856; batch adversarial loss: 0.559916\n",
      "epoch 112; iter: 0; batch classifier loss: 0.403311; batch adversarial loss: 0.527001\n",
      "epoch 113; iter: 0; batch classifier loss: 0.319263; batch adversarial loss: 0.499562\n",
      "epoch 114; iter: 0; batch classifier loss: 0.399248; batch adversarial loss: 0.552873\n",
      "epoch 115; iter: 0; batch classifier loss: 0.407228; batch adversarial loss: 0.518482\n",
      "epoch 116; iter: 0; batch classifier loss: 0.320901; batch adversarial loss: 0.506753\n",
      "epoch 117; iter: 0; batch classifier loss: 0.387595; batch adversarial loss: 0.543068\n",
      "epoch 118; iter: 0; batch classifier loss: 0.430914; batch adversarial loss: 0.502228\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 119; iter: 0; batch classifier loss: 0.455961; batch adversarial loss: 0.537203\n",
      "epoch 120; iter: 0; batch classifier loss: 0.373054; batch adversarial loss: 0.571856\n",
      "epoch 121; iter: 0; batch classifier loss: 0.382396; batch adversarial loss: 0.545290\n",
      "epoch 122; iter: 0; batch classifier loss: 0.371080; batch adversarial loss: 0.562646\n",
      "epoch 123; iter: 0; batch classifier loss: 0.365267; batch adversarial loss: 0.563327\n",
      "epoch 124; iter: 0; batch classifier loss: 0.383645; batch adversarial loss: 0.502116\n",
      "epoch 125; iter: 0; batch classifier loss: 0.391697; batch adversarial loss: 0.490172\n",
      "epoch 126; iter: 0; batch classifier loss: 0.315158; batch adversarial loss: 0.570074\n",
      "epoch 127; iter: 0; batch classifier loss: 0.362569; batch adversarial loss: 0.554283\n",
      "epoch 128; iter: 0; batch classifier loss: 0.399630; batch adversarial loss: 0.507677\n",
      "epoch 129; iter: 0; batch classifier loss: 0.326474; batch adversarial loss: 0.617373\n",
      "epoch 130; iter: 0; batch classifier loss: 0.360165; batch adversarial loss: 0.635756\n",
      "epoch 131; iter: 0; batch classifier loss: 0.330983; batch adversarial loss: 0.608529\n",
      "epoch 132; iter: 0; batch classifier loss: 0.397205; batch adversarial loss: 0.570058\n",
      "epoch 133; iter: 0; batch classifier loss: 0.362261; batch adversarial loss: 0.496983\n",
      "epoch 134; iter: 0; batch classifier loss: 0.390599; batch adversarial loss: 0.476125\n",
      "epoch 135; iter: 0; batch classifier loss: 0.360593; batch adversarial loss: 0.474230\n",
      "epoch 136; iter: 0; batch classifier loss: 0.278079; batch adversarial loss: 0.541146\n",
      "epoch 137; iter: 0; batch classifier loss: 0.293724; batch adversarial loss: 0.526572\n",
      "epoch 138; iter: 0; batch classifier loss: 0.441766; batch adversarial loss: 0.563986\n",
      "epoch 139; iter: 0; batch classifier loss: 0.387178; batch adversarial loss: 0.516620\n",
      "epoch 140; iter: 0; batch classifier loss: 0.375742; batch adversarial loss: 0.525098\n",
      "epoch 141; iter: 0; batch classifier loss: 0.334160; batch adversarial loss: 0.536457\n",
      "epoch 142; iter: 0; batch classifier loss: 0.378161; batch adversarial loss: 0.599407\n",
      "epoch 143; iter: 0; batch classifier loss: 0.334452; batch adversarial loss: 0.554985\n",
      "epoch 144; iter: 0; batch classifier loss: 0.429425; batch adversarial loss: 0.589774\n",
      "epoch 145; iter: 0; batch classifier loss: 0.345823; batch adversarial loss: 0.596949\n",
      "epoch 146; iter: 0; batch classifier loss: 0.359335; batch adversarial loss: 0.501485\n",
      "epoch 147; iter: 0; batch classifier loss: 0.447681; batch adversarial loss: 0.631946\n",
      "epoch 148; iter: 0; batch classifier loss: 0.333547; batch adversarial loss: 0.515153\n",
      "epoch 149; iter: 0; batch classifier loss: 0.392096; batch adversarial loss: 0.509340\n",
      "epoch 150; iter: 0; batch classifier loss: 0.287111; batch adversarial loss: 0.626603\n",
      "epoch 151; iter: 0; batch classifier loss: 0.382667; batch adversarial loss: 0.554931\n",
      "epoch 152; iter: 0; batch classifier loss: 0.340936; batch adversarial loss: 0.611430\n",
      "epoch 153; iter: 0; batch classifier loss: 0.352356; batch adversarial loss: 0.551575\n",
      "epoch 154; iter: 0; batch classifier loss: 0.374320; batch adversarial loss: 0.521370\n",
      "epoch 155; iter: 0; batch classifier loss: 0.377163; batch adversarial loss: 0.544624\n",
      "epoch 156; iter: 0; batch classifier loss: 0.400972; batch adversarial loss: 0.504555\n",
      "epoch 157; iter: 0; batch classifier loss: 0.371968; batch adversarial loss: 0.509194\n",
      "epoch 158; iter: 0; batch classifier loss: 0.355721; batch adversarial loss: 0.516957\n",
      "epoch 159; iter: 0; batch classifier loss: 0.392353; batch adversarial loss: 0.558424\n",
      "epoch 160; iter: 0; batch classifier loss: 0.382488; batch adversarial loss: 0.648621\n",
      "epoch 161; iter: 0; batch classifier loss: 0.382293; batch adversarial loss: 0.542702\n",
      "epoch 162; iter: 0; batch classifier loss: 0.368995; batch adversarial loss: 0.496722\n",
      "epoch 163; iter: 0; batch classifier loss: 0.338093; batch adversarial loss: 0.559989\n",
      "epoch 164; iter: 0; batch classifier loss: 0.291119; batch adversarial loss: 0.625483\n",
      "epoch 165; iter: 0; batch classifier loss: 0.364246; batch adversarial loss: 0.647570\n",
      "epoch 166; iter: 0; batch classifier loss: 0.366233; batch adversarial loss: 0.562777\n",
      "epoch 167; iter: 0; batch classifier loss: 0.276062; batch adversarial loss: 0.590099\n",
      "epoch 168; iter: 0; batch classifier loss: 0.307097; batch adversarial loss: 0.610618\n",
      "epoch 169; iter: 0; batch classifier loss: 0.394901; batch adversarial loss: 0.636053\n",
      "epoch 170; iter: 0; batch classifier loss: 0.348644; batch adversarial loss: 0.530023\n",
      "epoch 171; iter: 0; batch classifier loss: 0.328259; batch adversarial loss: 0.488748\n",
      "epoch 172; iter: 0; batch classifier loss: 0.407248; batch adversarial loss: 0.536899\n",
      "epoch 173; iter: 0; batch classifier loss: 0.369718; batch adversarial loss: 0.669531\n",
      "epoch 174; iter: 0; batch classifier loss: 0.375107; batch adversarial loss: 0.684067\n",
      "epoch 175; iter: 0; batch classifier loss: 0.384473; batch adversarial loss: 0.526268\n",
      "epoch 176; iter: 0; batch classifier loss: 0.415139; batch adversarial loss: 0.535664\n",
      "epoch 177; iter: 0; batch classifier loss: 0.353458; batch adversarial loss: 0.613135\n",
      "epoch 178; iter: 0; batch classifier loss: 0.301962; batch adversarial loss: 0.591659\n",
      "epoch 179; iter: 0; batch classifier loss: 0.285168; batch adversarial loss: 0.534271\n",
      "epoch 180; iter: 0; batch classifier loss: 0.346463; batch adversarial loss: 0.555150\n",
      "epoch 181; iter: 0; batch classifier loss: 0.312645; batch adversarial loss: 0.608554\n",
      "epoch 182; iter: 0; batch classifier loss: 0.380904; batch adversarial loss: 0.561974\n",
      "epoch 183; iter: 0; batch classifier loss: 0.375057; batch adversarial loss: 0.518535\n",
      "epoch 184; iter: 0; batch classifier loss: 0.366771; batch adversarial loss: 0.578918\n",
      "epoch 185; iter: 0; batch classifier loss: 0.361383; batch adversarial loss: 0.500061\n",
      "epoch 186; iter: 0; batch classifier loss: 0.350001; batch adversarial loss: 0.537701\n",
      "epoch 187; iter: 0; batch classifier loss: 0.335003; batch adversarial loss: 0.498374\n",
      "epoch 188; iter: 0; batch classifier loss: 0.329887; batch adversarial loss: 0.542702\n",
      "epoch 189; iter: 0; batch classifier loss: 0.364935; batch adversarial loss: 0.592860\n",
      "epoch 190; iter: 0; batch classifier loss: 0.361529; batch adversarial loss: 0.604652\n",
      "epoch 191; iter: 0; batch classifier loss: 0.381680; batch adversarial loss: 0.502929\n",
      "epoch 192; iter: 0; batch classifier loss: 0.343783; batch adversarial loss: 0.572046\n",
      "epoch 193; iter: 0; batch classifier loss: 0.278202; batch adversarial loss: 0.644506\n",
      "epoch 194; iter: 0; batch classifier loss: 0.366048; batch adversarial loss: 0.606104\n",
      "epoch 195; iter: 0; batch classifier loss: 0.347568; batch adversarial loss: 0.569602\n",
      "epoch 196; iter: 0; batch classifier loss: 0.293461; batch adversarial loss: 0.593041\n",
      "epoch 197; iter: 0; batch classifier loss: 0.396529; batch adversarial loss: 0.573274\n",
      "epoch 198; iter: 0; batch classifier loss: 0.371597; batch adversarial loss: 0.586169\n",
      "epoch 199; iter: 0; batch classifier loss: 0.283580; batch adversarial loss: 0.606104\n",
      "epoch 0; iter: 0; batch classifier loss: 0.679308; batch adversarial loss: 0.639276\n",
      "epoch 1; iter: 0; batch classifier loss: 0.628376; batch adversarial loss: 0.653204\n",
      "epoch 2; iter: 0; batch classifier loss: 0.559289; batch adversarial loss: 0.621298\n",
      "epoch 3; iter: 0; batch classifier loss: 0.591136; batch adversarial loss: 0.619409\n",
      "epoch 4; iter: 0; batch classifier loss: 0.601311; batch adversarial loss: 0.634456\n",
      "epoch 5; iter: 0; batch classifier loss: 0.598329; batch adversarial loss: 0.613347\n",
      "epoch 6; iter: 0; batch classifier loss: 0.578960; batch adversarial loss: 0.609716\n",
      "epoch 7; iter: 0; batch classifier loss: 0.492944; batch adversarial loss: 0.597701\n",
      "epoch 8; iter: 0; batch classifier loss: 0.566498; batch adversarial loss: 0.589577\n",
      "epoch 9; iter: 0; batch classifier loss: 0.551959; batch adversarial loss: 0.587819\n",
      "epoch 10; iter: 0; batch classifier loss: 0.482470; batch adversarial loss: 0.634239\n",
      "epoch 11; iter: 0; batch classifier loss: 0.496645; batch adversarial loss: 0.598429\n",
      "epoch 12; iter: 0; batch classifier loss: 0.514064; batch adversarial loss: 0.664388\n",
      "epoch 13; iter: 0; batch classifier loss: 0.557658; batch adversarial loss: 0.603071\n",
      "epoch 14; iter: 0; batch classifier loss: 0.486804; batch adversarial loss: 0.599682\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 15; iter: 0; batch classifier loss: 0.661955; batch adversarial loss: 0.597598\n",
      "epoch 16; iter: 0; batch classifier loss: 0.526732; batch adversarial loss: 0.564440\n",
      "epoch 17; iter: 0; batch classifier loss: 0.529336; batch adversarial loss: 0.574525\n",
      "epoch 18; iter: 0; batch classifier loss: 0.547794; batch adversarial loss: 0.599535\n",
      "epoch 19; iter: 0; batch classifier loss: 0.456865; batch adversarial loss: 0.577306\n",
      "epoch 20; iter: 0; batch classifier loss: 0.444410; batch adversarial loss: 0.554280\n",
      "epoch 21; iter: 0; batch classifier loss: 0.497393; batch adversarial loss: 0.573843\n",
      "epoch 22; iter: 0; batch classifier loss: 0.491467; batch adversarial loss: 0.617182\n",
      "epoch 23; iter: 0; batch classifier loss: 0.512219; batch adversarial loss: 0.563657\n",
      "epoch 24; iter: 0; batch classifier loss: 0.464710; batch adversarial loss: 0.610301\n",
      "epoch 25; iter: 0; batch classifier loss: 0.519037; batch adversarial loss: 0.525610\n",
      "epoch 26; iter: 0; batch classifier loss: 0.464072; batch adversarial loss: 0.521306\n",
      "epoch 27; iter: 0; batch classifier loss: 0.413837; batch adversarial loss: 0.511902\n",
      "epoch 28; iter: 0; batch classifier loss: 0.475146; batch adversarial loss: 0.561795\n",
      "epoch 29; iter: 0; batch classifier loss: 0.426364; batch adversarial loss: 0.544848\n",
      "epoch 30; iter: 0; batch classifier loss: 0.428640; batch adversarial loss: 0.578528\n",
      "epoch 31; iter: 0; batch classifier loss: 0.442346; batch adversarial loss: 0.607732\n",
      "epoch 32; iter: 0; batch classifier loss: 0.477850; batch adversarial loss: 0.578583\n",
      "epoch 33; iter: 0; batch classifier loss: 0.459798; batch adversarial loss: 0.547326\n",
      "epoch 34; iter: 0; batch classifier loss: 0.483315; batch adversarial loss: 0.579765\n",
      "epoch 35; iter: 0; batch classifier loss: 0.398525; batch adversarial loss: 0.541004\n",
      "epoch 36; iter: 0; batch classifier loss: 0.525622; batch adversarial loss: 0.535009\n",
      "epoch 37; iter: 0; batch classifier loss: 0.493170; batch adversarial loss: 0.577527\n",
      "epoch 38; iter: 0; batch classifier loss: 0.430123; batch adversarial loss: 0.596825\n",
      "epoch 39; iter: 0; batch classifier loss: 0.455747; batch adversarial loss: 0.518827\n",
      "epoch 40; iter: 0; batch classifier loss: 0.418179; batch adversarial loss: 0.552802\n",
      "epoch 41; iter: 0; batch classifier loss: 0.436349; batch adversarial loss: 0.545137\n",
      "epoch 42; iter: 0; batch classifier loss: 0.409653; batch adversarial loss: 0.631795\n",
      "epoch 43; iter: 0; batch classifier loss: 0.453366; batch adversarial loss: 0.649644\n",
      "epoch 44; iter: 0; batch classifier loss: 0.356732; batch adversarial loss: 0.632194\n",
      "epoch 45; iter: 0; batch classifier loss: 0.426340; batch adversarial loss: 0.562107\n",
      "epoch 46; iter: 0; batch classifier loss: 0.505083; batch adversarial loss: 0.544110\n",
      "epoch 47; iter: 0; batch classifier loss: 0.421042; batch adversarial loss: 0.625490\n",
      "epoch 48; iter: 0; batch classifier loss: 0.412910; batch adversarial loss: 0.521630\n",
      "epoch 49; iter: 0; batch classifier loss: 0.410226; batch adversarial loss: 0.597868\n",
      "epoch 50; iter: 0; batch classifier loss: 0.369450; batch adversarial loss: 0.584458\n",
      "epoch 51; iter: 0; batch classifier loss: 0.374103; batch adversarial loss: 0.535690\n",
      "epoch 52; iter: 0; batch classifier loss: 0.461180; batch adversarial loss: 0.529325\n",
      "epoch 53; iter: 0; batch classifier loss: 0.389117; batch adversarial loss: 0.617229\n",
      "epoch 54; iter: 0; batch classifier loss: 0.416389; batch adversarial loss: 0.493408\n",
      "epoch 55; iter: 0; batch classifier loss: 0.388722; batch adversarial loss: 0.510649\n",
      "epoch 56; iter: 0; batch classifier loss: 0.508496; batch adversarial loss: 0.562185\n",
      "epoch 57; iter: 0; batch classifier loss: 0.388644; batch adversarial loss: 0.526986\n",
      "epoch 58; iter: 0; batch classifier loss: 0.506732; batch adversarial loss: 0.492371\n",
      "epoch 59; iter: 0; batch classifier loss: 0.369865; batch adversarial loss: 0.589060\n",
      "epoch 60; iter: 0; batch classifier loss: 0.457433; batch adversarial loss: 0.552022\n",
      "epoch 61; iter: 0; batch classifier loss: 0.543980; batch adversarial loss: 0.515448\n",
      "epoch 62; iter: 0; batch classifier loss: 0.423911; batch adversarial loss: 0.552242\n",
      "epoch 63; iter: 0; batch classifier loss: 0.380357; batch adversarial loss: 0.552413\n",
      "epoch 64; iter: 0; batch classifier loss: 0.406108; batch adversarial loss: 0.578837\n",
      "epoch 65; iter: 0; batch classifier loss: 0.427245; batch adversarial loss: 0.635807\n",
      "epoch 66; iter: 0; batch classifier loss: 0.382282; batch adversarial loss: 0.481977\n",
      "epoch 67; iter: 0; batch classifier loss: 0.378046; batch adversarial loss: 0.617103\n",
      "epoch 68; iter: 0; batch classifier loss: 0.430133; batch adversarial loss: 0.652952\n",
      "epoch 69; iter: 0; batch classifier loss: 0.369414; batch adversarial loss: 0.501229\n",
      "epoch 70; iter: 0; batch classifier loss: 0.415851; batch adversarial loss: 0.571261\n",
      "epoch 71; iter: 0; batch classifier loss: 0.332815; batch adversarial loss: 0.553781\n",
      "epoch 72; iter: 0; batch classifier loss: 0.435554; batch adversarial loss: 0.553797\n",
      "epoch 73; iter: 0; batch classifier loss: 0.367975; batch adversarial loss: 0.492899\n",
      "epoch 74; iter: 0; batch classifier loss: 0.424976; batch adversarial loss: 0.562341\n",
      "epoch 75; iter: 0; batch classifier loss: 0.404840; batch adversarial loss: 0.605278\n",
      "epoch 76; iter: 0; batch classifier loss: 0.376829; batch adversarial loss: 0.553181\n",
      "epoch 77; iter: 0; batch classifier loss: 0.463303; batch adversarial loss: 0.612576\n",
      "epoch 78; iter: 0; batch classifier loss: 0.448882; batch adversarial loss: 0.571022\n",
      "epoch 79; iter: 0; batch classifier loss: 0.415755; batch adversarial loss: 0.508391\n",
      "epoch 80; iter: 0; batch classifier loss: 0.409819; batch adversarial loss: 0.527415\n",
      "epoch 81; iter: 0; batch classifier loss: 0.318945; batch adversarial loss: 0.605738\n",
      "epoch 82; iter: 0; batch classifier loss: 0.430173; batch adversarial loss: 0.499785\n",
      "epoch 83; iter: 0; batch classifier loss: 0.372427; batch adversarial loss: 0.568964\n",
      "epoch 84; iter: 0; batch classifier loss: 0.370115; batch adversarial loss: 0.569125\n",
      "epoch 85; iter: 0; batch classifier loss: 0.435595; batch adversarial loss: 0.581966\n",
      "epoch 86; iter: 0; batch classifier loss: 0.455105; batch adversarial loss: 0.563333\n",
      "epoch 87; iter: 0; batch classifier loss: 0.395564; batch adversarial loss: 0.501869\n",
      "epoch 88; iter: 0; batch classifier loss: 0.374546; batch adversarial loss: 0.516136\n",
      "epoch 89; iter: 0; batch classifier loss: 0.412794; batch adversarial loss: 0.622502\n",
      "epoch 90; iter: 0; batch classifier loss: 0.377939; batch adversarial loss: 0.550394\n",
      "epoch 91; iter: 0; batch classifier loss: 0.400946; batch adversarial loss: 0.542935\n",
      "epoch 92; iter: 0; batch classifier loss: 0.406476; batch adversarial loss: 0.532134\n",
      "epoch 93; iter: 0; batch classifier loss: 0.427132; batch adversarial loss: 0.516361\n",
      "epoch 94; iter: 0; batch classifier loss: 0.425410; batch adversarial loss: 0.507739\n",
      "epoch 95; iter: 0; batch classifier loss: 0.400693; batch adversarial loss: 0.524300\n",
      "epoch 96; iter: 0; batch classifier loss: 0.423407; batch adversarial loss: 0.473304\n",
      "epoch 97; iter: 0; batch classifier loss: 0.433245; batch adversarial loss: 0.489882\n",
      "epoch 98; iter: 0; batch classifier loss: 0.371255; batch adversarial loss: 0.570642\n",
      "epoch 99; iter: 0; batch classifier loss: 0.455943; batch adversarial loss: 0.569938\n",
      "epoch 100; iter: 0; batch classifier loss: 0.338203; batch adversarial loss: 0.588549\n",
      "epoch 101; iter: 0; batch classifier loss: 0.371897; batch adversarial loss: 0.518188\n",
      "epoch 102; iter: 0; batch classifier loss: 0.392725; batch adversarial loss: 0.571682\n",
      "epoch 103; iter: 0; batch classifier loss: 0.424479; batch adversarial loss: 0.553242\n",
      "epoch 104; iter: 0; batch classifier loss: 0.395224; batch adversarial loss: 0.526713\n",
      "epoch 105; iter: 0; batch classifier loss: 0.322957; batch adversarial loss: 0.572446\n",
      "epoch 106; iter: 0; batch classifier loss: 0.363431; batch adversarial loss: 0.509679\n",
      "epoch 107; iter: 0; batch classifier loss: 0.348488; batch adversarial loss: 0.562945\n",
      "epoch 108; iter: 0; batch classifier loss: 0.413874; batch adversarial loss: 0.578794\n",
      "epoch 109; iter: 0; batch classifier loss: 0.412662; batch adversarial loss: 0.562404\n",
      "epoch 110; iter: 0; batch classifier loss: 0.373427; batch adversarial loss: 0.572412\n",
      "epoch 111; iter: 0; batch classifier loss: 0.348386; batch adversarial loss: 0.578041\n",
      "epoch 112; iter: 0; batch classifier loss: 0.359432; batch adversarial loss: 0.563709\n",
      "epoch 113; iter: 0; batch classifier loss: 0.422199; batch adversarial loss: 0.508451\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 114; iter: 0; batch classifier loss: 0.438397; batch adversarial loss: 0.579424\n",
      "epoch 115; iter: 0; batch classifier loss: 0.481295; batch adversarial loss: 0.544916\n",
      "epoch 116; iter: 0; batch classifier loss: 0.388203; batch adversarial loss: 0.536261\n",
      "epoch 117; iter: 0; batch classifier loss: 0.369002; batch adversarial loss: 0.580472\n",
      "epoch 118; iter: 0; batch classifier loss: 0.415290; batch adversarial loss: 0.563424\n",
      "epoch 119; iter: 0; batch classifier loss: 0.404421; batch adversarial loss: 0.615249\n",
      "epoch 120; iter: 0; batch classifier loss: 0.464773; batch adversarial loss: 0.517152\n",
      "epoch 121; iter: 0; batch classifier loss: 0.390164; batch adversarial loss: 0.578416\n",
      "epoch 122; iter: 0; batch classifier loss: 0.351357; batch adversarial loss: 0.570825\n",
      "epoch 123; iter: 0; batch classifier loss: 0.435157; batch adversarial loss: 0.514193\n",
      "epoch 124; iter: 0; batch classifier loss: 0.421631; batch adversarial loss: 0.542455\n",
      "epoch 125; iter: 0; batch classifier loss: 0.343495; batch adversarial loss: 0.571802\n",
      "epoch 126; iter: 0; batch classifier loss: 0.356329; batch adversarial loss: 0.560038\n",
      "epoch 127; iter: 0; batch classifier loss: 0.468204; batch adversarial loss: 0.572445\n",
      "epoch 128; iter: 0; batch classifier loss: 0.329082; batch adversarial loss: 0.607311\n",
      "epoch 129; iter: 0; batch classifier loss: 0.361623; batch adversarial loss: 0.569403\n",
      "epoch 130; iter: 0; batch classifier loss: 0.356111; batch adversarial loss: 0.528184\n",
      "epoch 131; iter: 0; batch classifier loss: 0.344932; batch adversarial loss: 0.564858\n",
      "epoch 132; iter: 0; batch classifier loss: 0.394264; batch adversarial loss: 0.555322\n",
      "epoch 133; iter: 0; batch classifier loss: 0.372453; batch adversarial loss: 0.598342\n",
      "epoch 134; iter: 0; batch classifier loss: 0.472804; batch adversarial loss: 0.527998\n",
      "epoch 135; iter: 0; batch classifier loss: 0.425482; batch adversarial loss: 0.517984\n",
      "epoch 136; iter: 0; batch classifier loss: 0.402243; batch adversarial loss: 0.472864\n",
      "epoch 137; iter: 0; batch classifier loss: 0.336904; batch adversarial loss: 0.645265\n",
      "epoch 138; iter: 0; batch classifier loss: 0.268411; batch adversarial loss: 0.527300\n",
      "epoch 139; iter: 0; batch classifier loss: 0.356292; batch adversarial loss: 0.554672\n",
      "epoch 140; iter: 0; batch classifier loss: 0.409633; batch adversarial loss: 0.500773\n",
      "epoch 141; iter: 0; batch classifier loss: 0.338620; batch adversarial loss: 0.535809\n",
      "epoch 142; iter: 0; batch classifier loss: 0.418636; batch adversarial loss: 0.535229\n",
      "epoch 143; iter: 0; batch classifier loss: 0.390665; batch adversarial loss: 0.447201\n",
      "epoch 144; iter: 0; batch classifier loss: 0.344505; batch adversarial loss: 0.585364\n",
      "epoch 145; iter: 0; batch classifier loss: 0.364255; batch adversarial loss: 0.597177\n",
      "epoch 146; iter: 0; batch classifier loss: 0.388882; batch adversarial loss: 0.511404\n",
      "epoch 147; iter: 0; batch classifier loss: 0.273416; batch adversarial loss: 0.621728\n",
      "epoch 148; iter: 0; batch classifier loss: 0.354794; batch adversarial loss: 0.479329\n",
      "epoch 149; iter: 0; batch classifier loss: 0.382718; batch adversarial loss: 0.581757\n",
      "epoch 150; iter: 0; batch classifier loss: 0.337809; batch adversarial loss: 0.480935\n",
      "epoch 151; iter: 0; batch classifier loss: 0.486661; batch adversarial loss: 0.651750\n",
      "epoch 152; iter: 0; batch classifier loss: 0.425685; batch adversarial loss: 0.549210\n",
      "epoch 153; iter: 0; batch classifier loss: 0.399959; batch adversarial loss: 0.532075\n",
      "epoch 154; iter: 0; batch classifier loss: 0.370183; batch adversarial loss: 0.561810\n",
      "epoch 155; iter: 0; batch classifier loss: 0.388780; batch adversarial loss: 0.501145\n",
      "epoch 156; iter: 0; batch classifier loss: 0.338165; batch adversarial loss: 0.482757\n",
      "epoch 157; iter: 0; batch classifier loss: 0.328484; batch adversarial loss: 0.510697\n",
      "epoch 158; iter: 0; batch classifier loss: 0.362537; batch adversarial loss: 0.572793\n",
      "epoch 159; iter: 0; batch classifier loss: 0.400010; batch adversarial loss: 0.605750\n",
      "epoch 160; iter: 0; batch classifier loss: 0.336037; batch adversarial loss: 0.519558\n",
      "epoch 161; iter: 0; batch classifier loss: 0.424319; batch adversarial loss: 0.545055\n",
      "epoch 162; iter: 0; batch classifier loss: 0.304685; batch adversarial loss: 0.563245\n",
      "epoch 163; iter: 0; batch classifier loss: 0.397002; batch adversarial loss: 0.570442\n",
      "epoch 164; iter: 0; batch classifier loss: 0.375049; batch adversarial loss: 0.597826\n",
      "epoch 165; iter: 0; batch classifier loss: 0.458857; batch adversarial loss: 0.536728\n",
      "epoch 166; iter: 0; batch classifier loss: 0.459993; batch adversarial loss: 0.562259\n",
      "epoch 167; iter: 0; batch classifier loss: 0.375781; batch adversarial loss: 0.535617\n",
      "epoch 168; iter: 0; batch classifier loss: 0.370756; batch adversarial loss: 0.562471\n",
      "epoch 169; iter: 0; batch classifier loss: 0.340244; batch adversarial loss: 0.526742\n",
      "epoch 170; iter: 0; batch classifier loss: 0.322673; batch adversarial loss: 0.509263\n",
      "epoch 171; iter: 0; batch classifier loss: 0.335663; batch adversarial loss: 0.525319\n",
      "epoch 172; iter: 0; batch classifier loss: 0.372724; batch adversarial loss: 0.555597\n",
      "epoch 173; iter: 0; batch classifier loss: 0.452666; batch adversarial loss: 0.516253\n",
      "epoch 174; iter: 0; batch classifier loss: 0.351638; batch adversarial loss: 0.534725\n",
      "epoch 175; iter: 0; batch classifier loss: 0.452506; batch adversarial loss: 0.570414\n",
      "epoch 176; iter: 0; batch classifier loss: 0.453471; batch adversarial loss: 0.546548\n",
      "epoch 177; iter: 0; batch classifier loss: 0.334382; batch adversarial loss: 0.562097\n",
      "epoch 178; iter: 0; batch classifier loss: 0.324091; batch adversarial loss: 0.624396\n",
      "epoch 179; iter: 0; batch classifier loss: 0.330895; batch adversarial loss: 0.552934\n",
      "epoch 180; iter: 0; batch classifier loss: 0.336542; batch adversarial loss: 0.571886\n",
      "epoch 181; iter: 0; batch classifier loss: 0.410397; batch adversarial loss: 0.517393\n",
      "epoch 182; iter: 0; batch classifier loss: 0.366160; batch adversarial loss: 0.526206\n",
      "epoch 183; iter: 0; batch classifier loss: 0.517343; batch adversarial loss: 0.545815\n",
      "epoch 184; iter: 0; batch classifier loss: 0.373544; batch adversarial loss: 0.536961\n",
      "epoch 185; iter: 0; batch classifier loss: 0.299568; batch adversarial loss: 0.500418\n",
      "epoch 186; iter: 0; batch classifier loss: 0.326628; batch adversarial loss: 0.546166\n",
      "epoch 187; iter: 0; batch classifier loss: 0.392980; batch adversarial loss: 0.622884\n",
      "epoch 188; iter: 0; batch classifier loss: 0.277687; batch adversarial loss: 0.615315\n",
      "epoch 189; iter: 0; batch classifier loss: 0.391394; batch adversarial loss: 0.588234\n",
      "epoch 190; iter: 0; batch classifier loss: 0.445391; batch adversarial loss: 0.561512\n",
      "epoch 191; iter: 0; batch classifier loss: 0.295707; batch adversarial loss: 0.571036\n",
      "epoch 192; iter: 0; batch classifier loss: 0.371307; batch adversarial loss: 0.561705\n",
      "epoch 193; iter: 0; batch classifier loss: 0.334383; batch adversarial loss: 0.509030\n",
      "epoch 194; iter: 0; batch classifier loss: 0.357272; batch adversarial loss: 0.545503\n",
      "epoch 195; iter: 0; batch classifier loss: 0.338699; batch adversarial loss: 0.500057\n",
      "epoch 196; iter: 0; batch classifier loss: 0.402187; batch adversarial loss: 0.596811\n",
      "epoch 197; iter: 0; batch classifier loss: 0.337662; batch adversarial loss: 0.605540\n",
      "epoch 198; iter: 0; batch classifier loss: 0.306979; batch adversarial loss: 0.553349\n",
      "epoch 199; iter: 0; batch classifier loss: 0.365532; batch adversarial loss: 0.614578\n",
      "epoch 0; iter: 0; batch classifier loss: 0.703953; batch adversarial loss: 0.663220\n",
      "epoch 1; iter: 0; batch classifier loss: 0.577973; batch adversarial loss: 0.661882\n",
      "epoch 2; iter: 0; batch classifier loss: 0.622617; batch adversarial loss: 0.636781\n",
      "epoch 3; iter: 0; batch classifier loss: 0.575924; batch adversarial loss: 0.616859\n",
      "epoch 4; iter: 0; batch classifier loss: 0.573928; batch adversarial loss: 0.600780\n",
      "epoch 5; iter: 0; batch classifier loss: 0.590150; batch adversarial loss: 0.601336\n",
      "epoch 6; iter: 0; batch classifier loss: 0.514125; batch adversarial loss: 0.589912\n",
      "epoch 7; iter: 0; batch classifier loss: 0.528043; batch adversarial loss: 0.626465\n",
      "epoch 8; iter: 0; batch classifier loss: 0.575874; batch adversarial loss: 0.649037\n",
      "epoch 9; iter: 0; batch classifier loss: 0.501087; batch adversarial loss: 0.544997\n",
      "epoch 10; iter: 0; batch classifier loss: 0.535104; batch adversarial loss: 0.580319\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11; iter: 0; batch classifier loss: 0.585984; batch adversarial loss: 0.595504\n",
      "epoch 12; iter: 0; batch classifier loss: 0.553394; batch adversarial loss: 0.587695\n",
      "epoch 13; iter: 0; batch classifier loss: 0.568732; batch adversarial loss: 0.574286\n",
      "epoch 14; iter: 0; batch classifier loss: 0.490898; batch adversarial loss: 0.604552\n",
      "epoch 15; iter: 0; batch classifier loss: 0.485246; batch adversarial loss: 0.584812\n",
      "epoch 16; iter: 0; batch classifier loss: 0.547428; batch adversarial loss: 0.580476\n",
      "epoch 17; iter: 0; batch classifier loss: 0.457174; batch adversarial loss: 0.550119\n",
      "epoch 18; iter: 0; batch classifier loss: 0.467469; batch adversarial loss: 0.631820\n",
      "epoch 19; iter: 0; batch classifier loss: 0.520349; batch adversarial loss: 0.656617\n",
      "epoch 20; iter: 0; batch classifier loss: 0.450170; batch adversarial loss: 0.560682\n",
      "epoch 21; iter: 0; batch classifier loss: 0.510133; batch adversarial loss: 0.564381\n",
      "epoch 22; iter: 0; batch classifier loss: 0.451965; batch adversarial loss: 0.604349\n",
      "epoch 23; iter: 0; batch classifier loss: 0.509500; batch adversarial loss: 0.576279\n",
      "epoch 24; iter: 0; batch classifier loss: 0.476292; batch adversarial loss: 0.566390\n",
      "epoch 25; iter: 0; batch classifier loss: 0.431829; batch adversarial loss: 0.503640\n",
      "epoch 26; iter: 0; batch classifier loss: 0.452188; batch adversarial loss: 0.563833\n",
      "epoch 27; iter: 0; batch classifier loss: 0.487385; batch adversarial loss: 0.507986\n",
      "epoch 28; iter: 0; batch classifier loss: 0.469370; batch adversarial loss: 0.586809\n",
      "epoch 29; iter: 0; batch classifier loss: 0.462549; batch adversarial loss: 0.554365\n",
      "epoch 30; iter: 0; batch classifier loss: 0.426040; batch adversarial loss: 0.595168\n",
      "epoch 31; iter: 0; batch classifier loss: 0.516244; batch adversarial loss: 0.579329\n",
      "epoch 32; iter: 0; batch classifier loss: 0.406941; batch adversarial loss: 0.536496\n",
      "epoch 33; iter: 0; batch classifier loss: 0.433995; batch adversarial loss: 0.477676\n",
      "epoch 34; iter: 0; batch classifier loss: 0.455190; batch adversarial loss: 0.613862\n",
      "epoch 35; iter: 0; batch classifier loss: 0.410891; batch adversarial loss: 0.580193\n",
      "epoch 36; iter: 0; batch classifier loss: 0.487834; batch adversarial loss: 0.485040\n",
      "epoch 37; iter: 0; batch classifier loss: 0.469261; batch adversarial loss: 0.536619\n",
      "epoch 38; iter: 0; batch classifier loss: 0.439995; batch adversarial loss: 0.545109\n",
      "epoch 39; iter: 0; batch classifier loss: 0.433046; batch adversarial loss: 0.562500\n",
      "epoch 40; iter: 0; batch classifier loss: 0.415711; batch adversarial loss: 0.527412\n",
      "epoch 41; iter: 0; batch classifier loss: 0.399554; batch adversarial loss: 0.527454\n",
      "epoch 42; iter: 0; batch classifier loss: 0.479942; batch adversarial loss: 0.571529\n",
      "epoch 43; iter: 0; batch classifier loss: 0.460930; batch adversarial loss: 0.589193\n",
      "epoch 44; iter: 0; batch classifier loss: 0.495316; batch adversarial loss: 0.543453\n",
      "epoch 45; iter: 0; batch classifier loss: 0.327547; batch adversarial loss: 0.606226\n",
      "epoch 46; iter: 0; batch classifier loss: 0.467046; batch adversarial loss: 0.536713\n",
      "epoch 47; iter: 0; batch classifier loss: 0.452225; batch adversarial loss: 0.544882\n",
      "epoch 48; iter: 0; batch classifier loss: 0.403244; batch adversarial loss: 0.571064\n",
      "epoch 49; iter: 0; batch classifier loss: 0.388278; batch adversarial loss: 0.605745\n",
      "epoch 50; iter: 0; batch classifier loss: 0.367875; batch adversarial loss: 0.527634\n",
      "epoch 51; iter: 0; batch classifier loss: 0.393767; batch adversarial loss: 0.597203\n",
      "epoch 52; iter: 0; batch classifier loss: 0.448641; batch adversarial loss: 0.597612\n",
      "epoch 53; iter: 0; batch classifier loss: 0.434532; batch adversarial loss: 0.597308\n",
      "epoch 54; iter: 0; batch classifier loss: 0.405544; batch adversarial loss: 0.518534\n",
      "epoch 55; iter: 0; batch classifier loss: 0.440564; batch adversarial loss: 0.562457\n",
      "epoch 56; iter: 0; batch classifier loss: 0.454652; batch adversarial loss: 0.518112\n",
      "epoch 57; iter: 0; batch classifier loss: 0.482412; batch adversarial loss: 0.544266\n",
      "epoch 58; iter: 0; batch classifier loss: 0.375827; batch adversarial loss: 0.518441\n",
      "epoch 59; iter: 0; batch classifier loss: 0.363640; batch adversarial loss: 0.544828\n",
      "epoch 60; iter: 0; batch classifier loss: 0.334327; batch adversarial loss: 0.571349\n",
      "epoch 61; iter: 0; batch classifier loss: 0.457648; batch adversarial loss: 0.597187\n",
      "epoch 62; iter: 0; batch classifier loss: 0.317778; batch adversarial loss: 0.562579\n",
      "epoch 63; iter: 0; batch classifier loss: 0.431699; batch adversarial loss: 0.501225\n",
      "epoch 64; iter: 0; batch classifier loss: 0.384928; batch adversarial loss: 0.544637\n",
      "epoch 65; iter: 0; batch classifier loss: 0.438147; batch adversarial loss: 0.500349\n",
      "epoch 66; iter: 0; batch classifier loss: 0.334113; batch adversarial loss: 0.579816\n",
      "epoch 67; iter: 0; batch classifier loss: 0.378149; batch adversarial loss: 0.500926\n",
      "epoch 68; iter: 0; batch classifier loss: 0.434889; batch adversarial loss: 0.624125\n",
      "epoch 69; iter: 0; batch classifier loss: 0.395035; batch adversarial loss: 0.562932\n",
      "epoch 70; iter: 0; batch classifier loss: 0.437650; batch adversarial loss: 0.544437\n",
      "epoch 71; iter: 0; batch classifier loss: 0.427291; batch adversarial loss: 0.509820\n",
      "epoch 72; iter: 0; batch classifier loss: 0.362932; batch adversarial loss: 0.623328\n",
      "epoch 73; iter: 0; batch classifier loss: 0.345146; batch adversarial loss: 0.526957\n",
      "epoch 74; iter: 0; batch classifier loss: 0.446852; batch adversarial loss: 0.447724\n",
      "epoch 75; iter: 0; batch classifier loss: 0.328891; batch adversarial loss: 0.562343\n",
      "epoch 76; iter: 0; batch classifier loss: 0.361137; batch adversarial loss: 0.562610\n",
      "epoch 77; iter: 0; batch classifier loss: 0.385692; batch adversarial loss: 0.580249\n",
      "epoch 78; iter: 0; batch classifier loss: 0.396749; batch adversarial loss: 0.553733\n",
      "epoch 79; iter: 0; batch classifier loss: 0.384383; batch adversarial loss: 0.633575\n",
      "epoch 80; iter: 0; batch classifier loss: 0.347883; batch adversarial loss: 0.571063\n",
      "epoch 81; iter: 0; batch classifier loss: 0.345870; batch adversarial loss: 0.544482\n",
      "epoch 82; iter: 0; batch classifier loss: 0.379537; batch adversarial loss: 0.483291\n",
      "epoch 83; iter: 0; batch classifier loss: 0.345940; batch adversarial loss: 0.456437\n",
      "epoch 84; iter: 0; batch classifier loss: 0.291857; batch adversarial loss: 0.596802\n",
      "epoch 85; iter: 0; batch classifier loss: 0.380594; batch adversarial loss: 0.474423\n",
      "epoch 86; iter: 0; batch classifier loss: 0.363387; batch adversarial loss: 0.536727\n",
      "epoch 87; iter: 0; batch classifier loss: 0.549730; batch adversarial loss: 0.570723\n",
      "epoch 88; iter: 0; batch classifier loss: 0.393713; batch adversarial loss: 0.500997\n",
      "epoch 89; iter: 0; batch classifier loss: 0.461871; batch adversarial loss: 0.588670\n",
      "epoch 90; iter: 0; batch classifier loss: 0.318481; batch adversarial loss: 0.605974\n",
      "epoch 91; iter: 0; batch classifier loss: 0.409011; batch adversarial loss: 0.544724\n",
      "epoch 92; iter: 0; batch classifier loss: 0.419157; batch adversarial loss: 0.588946\n",
      "epoch 93; iter: 0; batch classifier loss: 0.419015; batch adversarial loss: 0.552964\n",
      "epoch 94; iter: 0; batch classifier loss: 0.434286; batch adversarial loss: 0.465753\n",
      "epoch 95; iter: 0; batch classifier loss: 0.409093; batch adversarial loss: 0.588599\n",
      "epoch 96; iter: 0; batch classifier loss: 0.500752; batch adversarial loss: 0.562133\n",
      "epoch 97; iter: 0; batch classifier loss: 0.418596; batch adversarial loss: 0.492362\n",
      "epoch 98; iter: 0; batch classifier loss: 0.260076; batch adversarial loss: 0.606394\n",
      "epoch 99; iter: 0; batch classifier loss: 0.341134; batch adversarial loss: 0.544575\n",
      "epoch 100; iter: 0; batch classifier loss: 0.389016; batch adversarial loss: 0.579638\n",
      "epoch 101; iter: 0; batch classifier loss: 0.393390; batch adversarial loss: 0.527150\n",
      "epoch 102; iter: 0; batch classifier loss: 0.317983; batch adversarial loss: 0.579893\n",
      "epoch 103; iter: 0; batch classifier loss: 0.423505; batch adversarial loss: 0.589049\n",
      "epoch 104; iter: 0; batch classifier loss: 0.459920; batch adversarial loss: 0.518063\n",
      "epoch 105; iter: 0; batch classifier loss: 0.418106; batch adversarial loss: 0.580764\n",
      "epoch 106; iter: 0; batch classifier loss: 0.321330; batch adversarial loss: 0.571281\n",
      "epoch 107; iter: 0; batch classifier loss: 0.347093; batch adversarial loss: 0.544317\n",
      "epoch 108; iter: 0; batch classifier loss: 0.334751; batch adversarial loss: 0.571771\n",
      "epoch 109; iter: 0; batch classifier loss: 0.345597; batch adversarial loss: 0.571762\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 110; iter: 0; batch classifier loss: 0.310498; batch adversarial loss: 0.588626\n",
      "epoch 111; iter: 0; batch classifier loss: 0.402207; batch adversarial loss: 0.642294\n",
      "epoch 112; iter: 0; batch classifier loss: 0.329737; batch adversarial loss: 0.615784\n",
      "epoch 113; iter: 0; batch classifier loss: 0.307958; batch adversarial loss: 0.526508\n",
      "epoch 114; iter: 0; batch classifier loss: 0.339513; batch adversarial loss: 0.519335\n",
      "epoch 115; iter: 0; batch classifier loss: 0.308814; batch adversarial loss: 0.633300\n",
      "epoch 116; iter: 0; batch classifier loss: 0.406513; batch adversarial loss: 0.562859\n",
      "epoch 117; iter: 0; batch classifier loss: 0.405524; batch adversarial loss: 0.596813\n",
      "epoch 118; iter: 0; batch classifier loss: 0.386945; batch adversarial loss: 0.510164\n",
      "epoch 119; iter: 0; batch classifier loss: 0.372371; batch adversarial loss: 0.571027\n",
      "epoch 120; iter: 0; batch classifier loss: 0.439566; batch adversarial loss: 0.535539\n",
      "epoch 121; iter: 0; batch classifier loss: 0.367539; batch adversarial loss: 0.491476\n",
      "epoch 122; iter: 0; batch classifier loss: 0.406597; batch adversarial loss: 0.509161\n",
      "epoch 123; iter: 0; batch classifier loss: 0.368448; batch adversarial loss: 0.518648\n",
      "epoch 124; iter: 0; batch classifier loss: 0.378546; batch adversarial loss: 0.518299\n",
      "epoch 125; iter: 0; batch classifier loss: 0.427793; batch adversarial loss: 0.535578\n",
      "epoch 126; iter: 0; batch classifier loss: 0.355381; batch adversarial loss: 0.535726\n",
      "epoch 127; iter: 0; batch classifier loss: 0.321420; batch adversarial loss: 0.474835\n",
      "epoch 128; iter: 0; batch classifier loss: 0.290835; batch adversarial loss: 0.466821\n",
      "epoch 129; iter: 0; batch classifier loss: 0.336795; batch adversarial loss: 0.562583\n",
      "epoch 130; iter: 0; batch classifier loss: 0.327249; batch adversarial loss: 0.526844\n",
      "epoch 131; iter: 0; batch classifier loss: 0.316638; batch adversarial loss: 0.500815\n",
      "epoch 132; iter: 0; batch classifier loss: 0.314544; batch adversarial loss: 0.465600\n",
      "epoch 133; iter: 0; batch classifier loss: 0.364951; batch adversarial loss: 0.526765\n",
      "epoch 134; iter: 0; batch classifier loss: 0.410407; batch adversarial loss: 0.554072\n",
      "epoch 135; iter: 0; batch classifier loss: 0.279156; batch adversarial loss: 0.659383\n",
      "epoch 136; iter: 0; batch classifier loss: 0.355033; batch adversarial loss: 0.491914\n",
      "epoch 137; iter: 0; batch classifier loss: 0.341475; batch adversarial loss: 0.553949\n",
      "epoch 138; iter: 0; batch classifier loss: 0.439967; batch adversarial loss: 0.447974\n",
      "epoch 139; iter: 0; batch classifier loss: 0.317322; batch adversarial loss: 0.606000\n",
      "epoch 140; iter: 0; batch classifier loss: 0.366205; batch adversarial loss: 0.588107\n",
      "epoch 141; iter: 0; batch classifier loss: 0.386865; batch adversarial loss: 0.536649\n",
      "epoch 142; iter: 0; batch classifier loss: 0.274701; batch adversarial loss: 0.614915\n",
      "epoch 143; iter: 0; batch classifier loss: 0.330000; batch adversarial loss: 0.571124\n",
      "epoch 144; iter: 0; batch classifier loss: 0.367958; batch adversarial loss: 0.545207\n",
      "epoch 145; iter: 0; batch classifier loss: 0.325517; batch adversarial loss: 0.500734\n",
      "epoch 146; iter: 0; batch classifier loss: 0.309985; batch adversarial loss: 0.518459\n",
      "epoch 147; iter: 0; batch classifier loss: 0.390175; batch adversarial loss: 0.562745\n",
      "epoch 148; iter: 0; batch classifier loss: 0.336940; batch adversarial loss: 0.570922\n",
      "epoch 149; iter: 0; batch classifier loss: 0.320486; batch adversarial loss: 0.527334\n",
      "epoch 150; iter: 0; batch classifier loss: 0.418019; batch adversarial loss: 0.500890\n",
      "epoch 151; iter: 0; batch classifier loss: 0.418533; batch adversarial loss: 0.483262\n",
      "epoch 152; iter: 0; batch classifier loss: 0.304719; batch adversarial loss: 0.483032\n",
      "epoch 153; iter: 0; batch classifier loss: 0.310967; batch adversarial loss: 0.500008\n",
      "epoch 154; iter: 0; batch classifier loss: 0.319448; batch adversarial loss: 0.596355\n",
      "epoch 155; iter: 0; batch classifier loss: 0.369169; batch adversarial loss: 0.570814\n",
      "epoch 156; iter: 0; batch classifier loss: 0.346651; batch adversarial loss: 0.597465\n",
      "epoch 157; iter: 0; batch classifier loss: 0.390093; batch adversarial loss: 0.580965\n",
      "epoch 158; iter: 0; batch classifier loss: 0.419262; batch adversarial loss: 0.553196\n",
      "epoch 159; iter: 0; batch classifier loss: 0.403340; batch adversarial loss: 0.553887\n",
      "epoch 160; iter: 0; batch classifier loss: 0.434054; batch adversarial loss: 0.544937\n",
      "epoch 161; iter: 0; batch classifier loss: 0.361911; batch adversarial loss: 0.606288\n",
      "epoch 162; iter: 0; batch classifier loss: 0.387709; batch adversarial loss: 0.606241\n",
      "epoch 163; iter: 0; batch classifier loss: 0.344795; batch adversarial loss: 0.642073\n",
      "epoch 164; iter: 0; batch classifier loss: 0.283516; batch adversarial loss: 0.544670\n",
      "epoch 165; iter: 0; batch classifier loss: 0.348575; batch adversarial loss: 0.606814\n",
      "epoch 166; iter: 0; batch classifier loss: 0.499728; batch adversarial loss: 0.448603\n",
      "epoch 167; iter: 0; batch classifier loss: 0.369954; batch adversarial loss: 0.545002\n",
      "epoch 168; iter: 0; batch classifier loss: 0.365096; batch adversarial loss: 0.465178\n",
      "epoch 169; iter: 0; batch classifier loss: 0.393196; batch adversarial loss: 0.571493\n",
      "epoch 170; iter: 0; batch classifier loss: 0.229398; batch adversarial loss: 0.509453\n",
      "epoch 171; iter: 0; batch classifier loss: 0.363945; batch adversarial loss: 0.631967\n",
      "epoch 172; iter: 0; batch classifier loss: 0.266682; batch adversarial loss: 0.649910\n",
      "epoch 173; iter: 0; batch classifier loss: 0.376832; batch adversarial loss: 0.500902\n",
      "epoch 174; iter: 0; batch classifier loss: 0.384895; batch adversarial loss: 0.474160\n",
      "epoch 175; iter: 0; batch classifier loss: 0.378793; batch adversarial loss: 0.606713\n",
      "epoch 176; iter: 0; batch classifier loss: 0.302070; batch adversarial loss: 0.668059\n",
      "epoch 177; iter: 0; batch classifier loss: 0.356608; batch adversarial loss: 0.570556\n",
      "epoch 178; iter: 0; batch classifier loss: 0.294914; batch adversarial loss: 0.545612\n",
      "epoch 179; iter: 0; batch classifier loss: 0.353481; batch adversarial loss: 0.598035\n",
      "epoch 180; iter: 0; batch classifier loss: 0.374243; batch adversarial loss: 0.544874\n",
      "epoch 181; iter: 0; batch classifier loss: 0.399206; batch adversarial loss: 0.588945\n",
      "epoch 182; iter: 0; batch classifier loss: 0.352187; batch adversarial loss: 0.553688\n",
      "epoch 183; iter: 0; batch classifier loss: 0.309133; batch adversarial loss: 0.509086\n",
      "epoch 184; iter: 0; batch classifier loss: 0.387370; batch adversarial loss: 0.517685\n",
      "epoch 185; iter: 0; batch classifier loss: 0.320884; batch adversarial loss: 0.501119\n",
      "epoch 186; iter: 0; batch classifier loss: 0.399952; batch adversarial loss: 0.527479\n",
      "epoch 187; iter: 0; batch classifier loss: 0.368261; batch adversarial loss: 0.553313\n",
      "epoch 188; iter: 0; batch classifier loss: 0.318522; batch adversarial loss: 0.571930\n",
      "epoch 189; iter: 0; batch classifier loss: 0.341453; batch adversarial loss: 0.598511\n",
      "epoch 190; iter: 0; batch classifier loss: 0.368557; batch adversarial loss: 0.518850\n",
      "epoch 191; iter: 0; batch classifier loss: 0.285161; batch adversarial loss: 0.685028\n",
      "epoch 192; iter: 0; batch classifier loss: 0.363968; batch adversarial loss: 0.571841\n",
      "epoch 193; iter: 0; batch classifier loss: 0.361487; batch adversarial loss: 0.509222\n",
      "epoch 194; iter: 0; batch classifier loss: 0.351325; batch adversarial loss: 0.500065\n",
      "epoch 195; iter: 0; batch classifier loss: 0.283387; batch adversarial loss: 0.527250\n",
      "epoch 196; iter: 0; batch classifier loss: 0.439957; batch adversarial loss: 0.517231\n",
      "epoch 197; iter: 0; batch classifier loss: 0.386136; batch adversarial loss: 0.527746\n",
      "epoch 198; iter: 0; batch classifier loss: 0.321953; batch adversarial loss: 0.659978\n",
      "epoch 199; iter: 0; batch classifier loss: 0.340725; batch adversarial loss: 0.659241\n",
      "epoch 0; iter: 0; batch classifier loss: 0.673862; batch adversarial loss: 0.747529\n",
      "epoch 1; iter: 0; batch classifier loss: 0.626406; batch adversarial loss: 0.695301\n",
      "epoch 2; iter: 0; batch classifier loss: 0.574097; batch adversarial loss: 0.687526\n",
      "epoch 3; iter: 0; batch classifier loss: 0.567492; batch adversarial loss: 0.638114\n",
      "epoch 4; iter: 0; batch classifier loss: 0.594253; batch adversarial loss: 0.620139\n",
      "epoch 5; iter: 0; batch classifier loss: 0.567157; batch adversarial loss: 0.598805\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6; iter: 0; batch classifier loss: 0.579521; batch adversarial loss: 0.579940\n",
      "epoch 7; iter: 0; batch classifier loss: 0.522507; batch adversarial loss: 0.634998\n",
      "epoch 8; iter: 0; batch classifier loss: 0.578956; batch adversarial loss: 0.611916\n",
      "epoch 9; iter: 0; batch classifier loss: 0.600537; batch adversarial loss: 0.576970\n",
      "epoch 10; iter: 0; batch classifier loss: 0.529166; batch adversarial loss: 0.593453\n",
      "epoch 11; iter: 0; batch classifier loss: 0.518832; batch adversarial loss: 0.562874\n",
      "epoch 12; iter: 0; batch classifier loss: 0.526142; batch adversarial loss: 0.572890\n",
      "epoch 13; iter: 0; batch classifier loss: 0.558617; batch adversarial loss: 0.550524\n",
      "epoch 14; iter: 0; batch classifier loss: 0.604353; batch adversarial loss: 0.595869\n",
      "epoch 15; iter: 0; batch classifier loss: 0.503623; batch adversarial loss: 0.577316\n",
      "epoch 16; iter: 0; batch classifier loss: 0.514931; batch adversarial loss: 0.590231\n",
      "epoch 17; iter: 0; batch classifier loss: 0.558814; batch adversarial loss: 0.606104\n",
      "epoch 18; iter: 0; batch classifier loss: 0.536300; batch adversarial loss: 0.619937\n",
      "epoch 19; iter: 0; batch classifier loss: 0.502412; batch adversarial loss: 0.641686\n",
      "epoch 20; iter: 0; batch classifier loss: 0.428114; batch adversarial loss: 0.569983\n",
      "epoch 21; iter: 0; batch classifier loss: 0.439535; batch adversarial loss: 0.594700\n",
      "epoch 22; iter: 0; batch classifier loss: 0.460577; batch adversarial loss: 0.538452\n",
      "epoch 23; iter: 0; batch classifier loss: 0.460593; batch adversarial loss: 0.611413\n",
      "epoch 24; iter: 0; batch classifier loss: 0.447478; batch adversarial loss: 0.582574\n",
      "epoch 25; iter: 0; batch classifier loss: 0.462809; batch adversarial loss: 0.536853\n",
      "epoch 26; iter: 0; batch classifier loss: 0.475465; batch adversarial loss: 0.584114\n",
      "epoch 27; iter: 0; batch classifier loss: 0.574172; batch adversarial loss: 0.577620\n",
      "epoch 28; iter: 0; batch classifier loss: 0.474560; batch adversarial loss: 0.571821\n",
      "epoch 29; iter: 0; batch classifier loss: 0.371791; batch adversarial loss: 0.499940\n",
      "epoch 30; iter: 0; batch classifier loss: 0.499568; batch adversarial loss: 0.539970\n",
      "epoch 31; iter: 0; batch classifier loss: 0.459689; batch adversarial loss: 0.552183\n",
      "epoch 32; iter: 0; batch classifier loss: 0.496753; batch adversarial loss: 0.606547\n",
      "epoch 33; iter: 0; batch classifier loss: 0.422987; batch adversarial loss: 0.537531\n",
      "epoch 34; iter: 0; batch classifier loss: 0.454217; batch adversarial loss: 0.571218\n",
      "epoch 35; iter: 0; batch classifier loss: 0.470662; batch adversarial loss: 0.548006\n",
      "epoch 36; iter: 0; batch classifier loss: 0.466106; batch adversarial loss: 0.493413\n",
      "epoch 37; iter: 0; batch classifier loss: 0.497193; batch adversarial loss: 0.546713\n",
      "epoch 38; iter: 0; batch classifier loss: 0.503676; batch adversarial loss: 0.536870\n",
      "epoch 39; iter: 0; batch classifier loss: 0.432334; batch adversarial loss: 0.622337\n",
      "epoch 40; iter: 0; batch classifier loss: 0.380265; batch adversarial loss: 0.580481\n",
      "epoch 41; iter: 0; batch classifier loss: 0.394611; batch adversarial loss: 0.520614\n",
      "epoch 42; iter: 0; batch classifier loss: 0.516530; batch adversarial loss: 0.528395\n",
      "epoch 43; iter: 0; batch classifier loss: 0.441558; batch adversarial loss: 0.553807\n",
      "epoch 44; iter: 0; batch classifier loss: 0.402260; batch adversarial loss: 0.552575\n",
      "epoch 45; iter: 0; batch classifier loss: 0.524978; batch adversarial loss: 0.534502\n",
      "epoch 46; iter: 0; batch classifier loss: 0.458359; batch adversarial loss: 0.571598\n",
      "epoch 47; iter: 0; batch classifier loss: 0.449590; batch adversarial loss: 0.569658\n",
      "epoch 48; iter: 0; batch classifier loss: 0.464732; batch adversarial loss: 0.571147\n",
      "epoch 49; iter: 0; batch classifier loss: 0.422557; batch adversarial loss: 0.608462\n",
      "epoch 50; iter: 0; batch classifier loss: 0.389139; batch adversarial loss: 0.556134\n",
      "epoch 51; iter: 0; batch classifier loss: 0.515228; batch adversarial loss: 0.517662\n",
      "epoch 52; iter: 0; batch classifier loss: 0.408467; batch adversarial loss: 0.623066\n",
      "epoch 53; iter: 0; batch classifier loss: 0.414656; batch adversarial loss: 0.489521\n",
      "epoch 54; iter: 0; batch classifier loss: 0.374894; batch adversarial loss: 0.582120\n",
      "epoch 55; iter: 0; batch classifier loss: 0.441833; batch adversarial loss: 0.520114\n",
      "epoch 56; iter: 0; batch classifier loss: 0.346421; batch adversarial loss: 0.448483\n",
      "epoch 57; iter: 0; batch classifier loss: 0.440471; batch adversarial loss: 0.536545\n",
      "epoch 58; iter: 0; batch classifier loss: 0.477001; batch adversarial loss: 0.606787\n",
      "epoch 59; iter: 0; batch classifier loss: 0.386337; batch adversarial loss: 0.493919\n",
      "epoch 60; iter: 0; batch classifier loss: 0.456398; batch adversarial loss: 0.546034\n",
      "epoch 61; iter: 0; batch classifier loss: 0.442515; batch adversarial loss: 0.556154\n",
      "epoch 62; iter: 0; batch classifier loss: 0.406506; batch adversarial loss: 0.490515\n",
      "epoch 63; iter: 0; batch classifier loss: 0.390160; batch adversarial loss: 0.535218\n",
      "epoch 64; iter: 0; batch classifier loss: 0.467754; batch adversarial loss: 0.536101\n",
      "epoch 65; iter: 0; batch classifier loss: 0.435488; batch adversarial loss: 0.585066\n",
      "epoch 66; iter: 0; batch classifier loss: 0.471109; batch adversarial loss: 0.590047\n",
      "epoch 67; iter: 0; batch classifier loss: 0.354057; batch adversarial loss: 0.525968\n",
      "epoch 68; iter: 0; batch classifier loss: 0.442117; batch adversarial loss: 0.537040\n",
      "epoch 69; iter: 0; batch classifier loss: 0.378687; batch adversarial loss: 0.597423\n",
      "epoch 70; iter: 0; batch classifier loss: 0.424126; batch adversarial loss: 0.563478\n",
      "epoch 71; iter: 0; batch classifier loss: 0.488425; batch adversarial loss: 0.604366\n",
      "epoch 72; iter: 0; batch classifier loss: 0.446387; batch adversarial loss: 0.546283\n",
      "epoch 73; iter: 0; batch classifier loss: 0.497632; batch adversarial loss: 0.493455\n",
      "epoch 74; iter: 0; batch classifier loss: 0.439789; batch adversarial loss: 0.649797\n",
      "epoch 75; iter: 0; batch classifier loss: 0.348123; batch adversarial loss: 0.559537\n",
      "epoch 76; iter: 0; batch classifier loss: 0.444522; batch adversarial loss: 0.571639\n",
      "epoch 77; iter: 0; batch classifier loss: 0.416658; batch adversarial loss: 0.524722\n",
      "epoch 78; iter: 0; batch classifier loss: 0.470960; batch adversarial loss: 0.587201\n",
      "epoch 79; iter: 0; batch classifier loss: 0.398991; batch adversarial loss: 0.553530\n",
      "epoch 80; iter: 0; batch classifier loss: 0.393338; batch adversarial loss: 0.571259\n",
      "epoch 81; iter: 0; batch classifier loss: 0.445773; batch adversarial loss: 0.578792\n",
      "epoch 82; iter: 0; batch classifier loss: 0.393805; batch adversarial loss: 0.520342\n",
      "epoch 83; iter: 0; batch classifier loss: 0.386978; batch adversarial loss: 0.604247\n",
      "epoch 84; iter: 0; batch classifier loss: 0.439622; batch adversarial loss: 0.580304\n",
      "epoch 85; iter: 0; batch classifier loss: 0.383438; batch adversarial loss: 0.578585\n",
      "epoch 86; iter: 0; batch classifier loss: 0.359765; batch adversarial loss: 0.509772\n",
      "epoch 87; iter: 0; batch classifier loss: 0.415990; batch adversarial loss: 0.573857\n",
      "epoch 88; iter: 0; batch classifier loss: 0.399543; batch adversarial loss: 0.616822\n",
      "epoch 89; iter: 0; batch classifier loss: 0.380222; batch adversarial loss: 0.553715\n",
      "epoch 90; iter: 0; batch classifier loss: 0.405358; batch adversarial loss: 0.558922\n",
      "epoch 91; iter: 0; batch classifier loss: 0.373817; batch adversarial loss: 0.580588\n",
      "epoch 92; iter: 0; batch classifier loss: 0.404803; batch adversarial loss: 0.591123\n",
      "epoch 93; iter: 0; batch classifier loss: 0.461152; batch adversarial loss: 0.571580\n",
      "epoch 94; iter: 0; batch classifier loss: 0.391277; batch adversarial loss: 0.501850\n",
      "epoch 95; iter: 0; batch classifier loss: 0.363334; batch adversarial loss: 0.517996\n",
      "epoch 96; iter: 0; batch classifier loss: 0.367938; batch adversarial loss: 0.609819\n",
      "epoch 97; iter: 0; batch classifier loss: 0.430920; batch adversarial loss: 0.485487\n",
      "epoch 98; iter: 0; batch classifier loss: 0.342979; batch adversarial loss: 0.607273\n",
      "epoch 99; iter: 0; batch classifier loss: 0.353624; batch adversarial loss: 0.490679\n",
      "epoch 100; iter: 0; batch classifier loss: 0.344466; batch adversarial loss: 0.506134\n",
      "epoch 101; iter: 0; batch classifier loss: 0.442720; batch adversarial loss: 0.524848\n",
      "epoch 102; iter: 0; batch classifier loss: 0.376616; batch adversarial loss: 0.622533\n",
      "epoch 103; iter: 0; batch classifier loss: 0.364439; batch adversarial loss: 0.613667\n",
      "epoch 104; iter: 0; batch classifier loss: 0.357088; batch adversarial loss: 0.578275\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 105; iter: 0; batch classifier loss: 0.408458; batch adversarial loss: 0.541463\n",
      "epoch 106; iter: 0; batch classifier loss: 0.374546; batch adversarial loss: 0.596962\n",
      "epoch 107; iter: 0; batch classifier loss: 0.403604; batch adversarial loss: 0.572794\n",
      "epoch 108; iter: 0; batch classifier loss: 0.381714; batch adversarial loss: 0.572616\n",
      "epoch 109; iter: 0; batch classifier loss: 0.344112; batch adversarial loss: 0.564306\n",
      "epoch 110; iter: 0; batch classifier loss: 0.339379; batch adversarial loss: 0.590790\n",
      "epoch 111; iter: 0; batch classifier loss: 0.415624; batch adversarial loss: 0.527942\n",
      "epoch 112; iter: 0; batch classifier loss: 0.388947; batch adversarial loss: 0.482856\n",
      "epoch 113; iter: 0; batch classifier loss: 0.471011; batch adversarial loss: 0.562733\n",
      "epoch 114; iter: 0; batch classifier loss: 0.393126; batch adversarial loss: 0.567559\n",
      "epoch 115; iter: 0; batch classifier loss: 0.382948; batch adversarial loss: 0.515296\n",
      "epoch 116; iter: 0; batch classifier loss: 0.417108; batch adversarial loss: 0.545679\n",
      "epoch 117; iter: 0; batch classifier loss: 0.393808; batch adversarial loss: 0.653579\n",
      "epoch 118; iter: 0; batch classifier loss: 0.361860; batch adversarial loss: 0.542131\n",
      "epoch 119; iter: 0; batch classifier loss: 0.373061; batch adversarial loss: 0.601174\n",
      "epoch 120; iter: 0; batch classifier loss: 0.418126; batch adversarial loss: 0.559013\n",
      "epoch 121; iter: 0; batch classifier loss: 0.450688; batch adversarial loss: 0.581372\n",
      "epoch 122; iter: 0; batch classifier loss: 0.369566; batch adversarial loss: 0.528875\n",
      "epoch 123; iter: 0; batch classifier loss: 0.423505; batch adversarial loss: 0.541870\n",
      "epoch 124; iter: 0; batch classifier loss: 0.371120; batch adversarial loss: 0.500832\n",
      "epoch 125; iter: 0; batch classifier loss: 0.459243; batch adversarial loss: 0.568944\n",
      "epoch 126; iter: 0; batch classifier loss: 0.340785; batch adversarial loss: 0.552039\n",
      "epoch 127; iter: 0; batch classifier loss: 0.385409; batch adversarial loss: 0.509225\n",
      "epoch 128; iter: 0; batch classifier loss: 0.323806; batch adversarial loss: 0.473561\n",
      "epoch 129; iter: 0; batch classifier loss: 0.357691; batch adversarial loss: 0.561854\n",
      "epoch 130; iter: 0; batch classifier loss: 0.343711; batch adversarial loss: 0.542030\n",
      "epoch 131; iter: 0; batch classifier loss: 0.365846; batch adversarial loss: 0.566509\n",
      "epoch 132; iter: 0; batch classifier loss: 0.390010; batch adversarial loss: 0.500555\n",
      "epoch 133; iter: 0; batch classifier loss: 0.358948; batch adversarial loss: 0.570227\n",
      "epoch 134; iter: 0; batch classifier loss: 0.427282; batch adversarial loss: 0.572347\n",
      "epoch 135; iter: 0; batch classifier loss: 0.403011; batch adversarial loss: 0.590882\n",
      "epoch 136; iter: 0; batch classifier loss: 0.448821; batch adversarial loss: 0.552408\n",
      "epoch 137; iter: 0; batch classifier loss: 0.426051; batch adversarial loss: 0.481977\n",
      "epoch 138; iter: 0; batch classifier loss: 0.381875; batch adversarial loss: 0.536388\n",
      "epoch 139; iter: 0; batch classifier loss: 0.430049; batch adversarial loss: 0.545840\n",
      "epoch 140; iter: 0; batch classifier loss: 0.345476; batch adversarial loss: 0.554771\n",
      "epoch 141; iter: 0; batch classifier loss: 0.435899; batch adversarial loss: 0.594603\n",
      "epoch 142; iter: 0; batch classifier loss: 0.423176; batch adversarial loss: 0.555916\n",
      "epoch 143; iter: 0; batch classifier loss: 0.358224; batch adversarial loss: 0.519756\n",
      "epoch 144; iter: 0; batch classifier loss: 0.496204; batch adversarial loss: 0.553858\n",
      "epoch 145; iter: 0; batch classifier loss: 0.370319; batch adversarial loss: 0.600671\n",
      "epoch 146; iter: 0; batch classifier loss: 0.350409; batch adversarial loss: 0.545855\n",
      "epoch 147; iter: 0; batch classifier loss: 0.469707; batch adversarial loss: 0.562106\n",
      "epoch 148; iter: 0; batch classifier loss: 0.403838; batch adversarial loss: 0.519507\n",
      "epoch 149; iter: 0; batch classifier loss: 0.354923; batch adversarial loss: 0.607274\n",
      "epoch 150; iter: 0; batch classifier loss: 0.403591; batch adversarial loss: 0.625654\n",
      "epoch 151; iter: 0; batch classifier loss: 0.372195; batch adversarial loss: 0.587643\n",
      "epoch 152; iter: 0; batch classifier loss: 0.464455; batch adversarial loss: 0.615605\n",
      "epoch 153; iter: 0; batch classifier loss: 0.391460; batch adversarial loss: 0.604686\n",
      "epoch 154; iter: 0; batch classifier loss: 0.429091; batch adversarial loss: 0.570805\n",
      "epoch 155; iter: 0; batch classifier loss: 0.311676; batch adversarial loss: 0.491720\n",
      "epoch 156; iter: 0; batch classifier loss: 0.355636; batch adversarial loss: 0.582353\n",
      "epoch 157; iter: 0; batch classifier loss: 0.315389; batch adversarial loss: 0.548097\n",
      "epoch 158; iter: 0; batch classifier loss: 0.362159; batch adversarial loss: 0.627690\n",
      "epoch 159; iter: 0; batch classifier loss: 0.378261; batch adversarial loss: 0.498906\n",
      "epoch 160; iter: 0; batch classifier loss: 0.424338; batch adversarial loss: 0.525492\n",
      "epoch 161; iter: 0; batch classifier loss: 0.351319; batch adversarial loss: 0.624623\n",
      "epoch 162; iter: 0; batch classifier loss: 0.416470; batch adversarial loss: 0.552346\n",
      "epoch 163; iter: 0; batch classifier loss: 0.363465; batch adversarial loss: 0.541335\n",
      "epoch 164; iter: 0; batch classifier loss: 0.435242; batch adversarial loss: 0.525167\n",
      "epoch 165; iter: 0; batch classifier loss: 0.330113; batch adversarial loss: 0.598739\n",
      "epoch 166; iter: 0; batch classifier loss: 0.453792; batch adversarial loss: 0.577188\n",
      "epoch 167; iter: 0; batch classifier loss: 0.321974; batch adversarial loss: 0.504933\n",
      "epoch 168; iter: 0; batch classifier loss: 0.460124; batch adversarial loss: 0.543939\n",
      "epoch 169; iter: 0; batch classifier loss: 0.430163; batch adversarial loss: 0.563573\n",
      "epoch 170; iter: 0; batch classifier loss: 0.355149; batch adversarial loss: 0.538700\n",
      "epoch 171; iter: 0; batch classifier loss: 0.362167; batch adversarial loss: 0.608740\n",
      "epoch 172; iter: 0; batch classifier loss: 0.346653; batch adversarial loss: 0.544384\n",
      "epoch 173; iter: 0; batch classifier loss: 0.448272; batch adversarial loss: 0.563595\n",
      "epoch 174; iter: 0; batch classifier loss: 0.381199; batch adversarial loss: 0.580220\n",
      "epoch 175; iter: 0; batch classifier loss: 0.395443; batch adversarial loss: 0.606035\n",
      "epoch 176; iter: 0; batch classifier loss: 0.422395; batch adversarial loss: 0.535828\n",
      "epoch 177; iter: 0; batch classifier loss: 0.355588; batch adversarial loss: 0.571894\n",
      "epoch 178; iter: 0; batch classifier loss: 0.400652; batch adversarial loss: 0.474662\n",
      "epoch 179; iter: 0; batch classifier loss: 0.348175; batch adversarial loss: 0.571942\n",
      "epoch 180; iter: 0; batch classifier loss: 0.366340; batch adversarial loss: 0.552747\n",
      "epoch 181; iter: 0; batch classifier loss: 0.356409; batch adversarial loss: 0.588052\n",
      "epoch 182; iter: 0; batch classifier loss: 0.406435; batch adversarial loss: 0.562311\n",
      "epoch 183; iter: 0; batch classifier loss: 0.411778; batch adversarial loss: 0.559807\n",
      "epoch 184; iter: 0; batch classifier loss: 0.343495; batch adversarial loss: 0.604460\n",
      "epoch 185; iter: 0; batch classifier loss: 0.450330; batch adversarial loss: 0.545971\n",
      "epoch 186; iter: 0; batch classifier loss: 0.318226; batch adversarial loss: 0.550226\n",
      "epoch 187; iter: 0; batch classifier loss: 0.422112; batch adversarial loss: 0.519244\n",
      "epoch 188; iter: 0; batch classifier loss: 0.356205; batch adversarial loss: 0.569827\n",
      "epoch 189; iter: 0; batch classifier loss: 0.287048; batch adversarial loss: 0.527093\n",
      "epoch 190; iter: 0; batch classifier loss: 0.370283; batch adversarial loss: 0.525377\n",
      "epoch 191; iter: 0; batch classifier loss: 0.412720; batch adversarial loss: 0.519563\n",
      "epoch 192; iter: 0; batch classifier loss: 0.300220; batch adversarial loss: 0.612661\n",
      "epoch 193; iter: 0; batch classifier loss: 0.344730; batch adversarial loss: 0.579865\n",
      "epoch 194; iter: 0; batch classifier loss: 0.312184; batch adversarial loss: 0.546522\n",
      "epoch 195; iter: 0; batch classifier loss: 0.418236; batch adversarial loss: 0.527102\n",
      "epoch 196; iter: 0; batch classifier loss: 0.420502; batch adversarial loss: 0.616102\n",
      "epoch 197; iter: 0; batch classifier loss: 0.300319; batch adversarial loss: 0.518774\n",
      "epoch 198; iter: 0; batch classifier loss: 0.343825; batch adversarial loss: 0.496617\n",
      "epoch 199; iter: 0; batch classifier loss: 0.351256; batch adversarial loss: 0.484847\n",
      "epoch 0; iter: 0; batch classifier loss: 0.774909; batch adversarial loss: 0.679504\n",
      "epoch 1; iter: 0; batch classifier loss: 0.555307; batch adversarial loss: 0.667851\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2; iter: 0; batch classifier loss: 0.639994; batch adversarial loss: 0.627377\n",
      "epoch 3; iter: 0; batch classifier loss: 0.590733; batch adversarial loss: 0.647423\n",
      "epoch 4; iter: 0; batch classifier loss: 0.582507; batch adversarial loss: 0.628866\n",
      "epoch 5; iter: 0; batch classifier loss: 0.652390; batch adversarial loss: 0.640022\n",
      "epoch 6; iter: 0; batch classifier loss: 0.567520; batch adversarial loss: 0.646417\n",
      "epoch 7; iter: 0; batch classifier loss: 0.645900; batch adversarial loss: 0.603230\n",
      "epoch 8; iter: 0; batch classifier loss: 0.623001; batch adversarial loss: 0.611777\n",
      "epoch 9; iter: 0; batch classifier loss: 0.578373; batch adversarial loss: 0.604175\n",
      "epoch 10; iter: 0; batch classifier loss: 0.515346; batch adversarial loss: 0.592435\n",
      "epoch 11; iter: 0; batch classifier loss: 0.591955; batch adversarial loss: 0.626577\n",
      "epoch 12; iter: 0; batch classifier loss: 0.494979; batch adversarial loss: 0.565097\n",
      "epoch 13; iter: 0; batch classifier loss: 0.486410; batch adversarial loss: 0.517268\n",
      "epoch 14; iter: 0; batch classifier loss: 0.539514; batch adversarial loss: 0.569358\n",
      "epoch 15; iter: 0; batch classifier loss: 0.450770; batch adversarial loss: 0.568732\n",
      "epoch 16; iter: 0; batch classifier loss: 0.492719; batch adversarial loss: 0.519359\n",
      "epoch 17; iter: 0; batch classifier loss: 0.524988; batch adversarial loss: 0.548478\n",
      "epoch 18; iter: 0; batch classifier loss: 0.456845; batch adversarial loss: 0.551924\n",
      "epoch 19; iter: 0; batch classifier loss: 0.487215; batch adversarial loss: 0.519929\n",
      "epoch 20; iter: 0; batch classifier loss: 0.533432; batch adversarial loss: 0.513359\n",
      "epoch 21; iter: 0; batch classifier loss: 0.453539; batch adversarial loss: 0.601400\n",
      "epoch 22; iter: 0; batch classifier loss: 0.500062; batch adversarial loss: 0.630576\n",
      "epoch 23; iter: 0; batch classifier loss: 0.457133; batch adversarial loss: 0.554266\n",
      "epoch 24; iter: 0; batch classifier loss: 0.455334; batch adversarial loss: 0.606218\n",
      "epoch 25; iter: 0; batch classifier loss: 0.458358; batch adversarial loss: 0.532801\n",
      "epoch 26; iter: 0; batch classifier loss: 0.517266; batch adversarial loss: 0.493784\n",
      "epoch 27; iter: 0; batch classifier loss: 0.485607; batch adversarial loss: 0.521870\n",
      "epoch 28; iter: 0; batch classifier loss: 0.542634; batch adversarial loss: 0.670042\n",
      "epoch 29; iter: 0; batch classifier loss: 0.474072; batch adversarial loss: 0.488903\n",
      "epoch 30; iter: 0; batch classifier loss: 0.560310; batch adversarial loss: 0.603683\n",
      "epoch 31; iter: 0; batch classifier loss: 0.411987; batch adversarial loss: 0.538301\n",
      "epoch 32; iter: 0; batch classifier loss: 0.437998; batch adversarial loss: 0.570265\n",
      "epoch 33; iter: 0; batch classifier loss: 0.488538; batch adversarial loss: 0.546049\n",
      "epoch 34; iter: 0; batch classifier loss: 0.453077; batch adversarial loss: 0.536398\n",
      "epoch 35; iter: 0; batch classifier loss: 0.475236; batch adversarial loss: 0.544850\n",
      "epoch 36; iter: 0; batch classifier loss: 0.469073; batch adversarial loss: 0.509131\n",
      "epoch 37; iter: 0; batch classifier loss: 0.479156; batch adversarial loss: 0.518696\n",
      "epoch 38; iter: 0; batch classifier loss: 0.436237; batch adversarial loss: 0.535838\n",
      "epoch 39; iter: 0; batch classifier loss: 0.405399; batch adversarial loss: 0.544293\n",
      "epoch 40; iter: 0; batch classifier loss: 0.476312; batch adversarial loss: 0.502028\n",
      "epoch 41; iter: 0; batch classifier loss: 0.491426; batch adversarial loss: 0.630246\n",
      "epoch 42; iter: 0; batch classifier loss: 0.402020; batch adversarial loss: 0.546328\n",
      "epoch 43; iter: 0; batch classifier loss: 0.408250; batch adversarial loss: 0.600761\n",
      "epoch 44; iter: 0; batch classifier loss: 0.396162; batch adversarial loss: 0.543261\n",
      "epoch 45; iter: 0; batch classifier loss: 0.478139; batch adversarial loss: 0.525751\n",
      "epoch 46; iter: 0; batch classifier loss: 0.478317; batch adversarial loss: 0.580319\n",
      "epoch 47; iter: 0; batch classifier loss: 0.423590; batch adversarial loss: 0.500465\n",
      "epoch 48; iter: 0; batch classifier loss: 0.446505; batch adversarial loss: 0.563428\n",
      "epoch 49; iter: 0; batch classifier loss: 0.428645; batch adversarial loss: 0.543670\n",
      "epoch 50; iter: 0; batch classifier loss: 0.434777; batch adversarial loss: 0.508193\n",
      "epoch 51; iter: 0; batch classifier loss: 0.503309; batch adversarial loss: 0.555769\n",
      "epoch 52; iter: 0; batch classifier loss: 0.458824; batch adversarial loss: 0.536904\n",
      "epoch 53; iter: 0; batch classifier loss: 0.429200; batch adversarial loss: 0.553231\n",
      "epoch 54; iter: 0; batch classifier loss: 0.376432; batch adversarial loss: 0.600091\n",
      "epoch 55; iter: 0; batch classifier loss: 0.385635; batch adversarial loss: 0.507344\n",
      "epoch 56; iter: 0; batch classifier loss: 0.372747; batch adversarial loss: 0.535688\n",
      "epoch 57; iter: 0; batch classifier loss: 0.484126; batch adversarial loss: 0.553886\n",
      "epoch 58; iter: 0; batch classifier loss: 0.480410; batch adversarial loss: 0.480780\n",
      "epoch 59; iter: 0; batch classifier loss: 0.557175; batch adversarial loss: 0.489571\n",
      "epoch 60; iter: 0; batch classifier loss: 0.454225; batch adversarial loss: 0.553294\n",
      "epoch 61; iter: 0; batch classifier loss: 0.397681; batch adversarial loss: 0.580266\n",
      "epoch 62; iter: 0; batch classifier loss: 0.455334; batch adversarial loss: 0.535648\n",
      "epoch 63; iter: 0; batch classifier loss: 0.317578; batch adversarial loss: 0.543615\n",
      "epoch 64; iter: 0; batch classifier loss: 0.500892; batch adversarial loss: 0.498435\n",
      "epoch 65; iter: 0; batch classifier loss: 0.416598; batch adversarial loss: 0.545044\n",
      "epoch 66; iter: 0; batch classifier loss: 0.338153; batch adversarial loss: 0.508273\n",
      "epoch 67; iter: 0; batch classifier loss: 0.473650; batch adversarial loss: 0.543231\n",
      "epoch 68; iter: 0; batch classifier loss: 0.484801; batch adversarial loss: 0.561457\n",
      "epoch 69; iter: 0; batch classifier loss: 0.387855; batch adversarial loss: 0.535787\n",
      "epoch 70; iter: 0; batch classifier loss: 0.366716; batch adversarial loss: 0.672516\n",
      "epoch 71; iter: 0; batch classifier loss: 0.384929; batch adversarial loss: 0.508007\n",
      "epoch 72; iter: 0; batch classifier loss: 0.394014; batch adversarial loss: 0.591048\n",
      "epoch 73; iter: 0; batch classifier loss: 0.329751; batch adversarial loss: 0.581378\n",
      "epoch 74; iter: 0; batch classifier loss: 0.481739; batch adversarial loss: 0.535026\n",
      "epoch 75; iter: 0; batch classifier loss: 0.365363; batch adversarial loss: 0.536203\n",
      "epoch 76; iter: 0; batch classifier loss: 0.371259; batch adversarial loss: 0.501237\n",
      "epoch 77; iter: 0; batch classifier loss: 0.401234; batch adversarial loss: 0.527706\n",
      "epoch 78; iter: 0; batch classifier loss: 0.417195; batch adversarial loss: 0.625800\n",
      "epoch 79; iter: 0; batch classifier loss: 0.405343; batch adversarial loss: 0.553785\n",
      "epoch 80; iter: 0; batch classifier loss: 0.421966; batch adversarial loss: 0.562186\n",
      "epoch 81; iter: 0; batch classifier loss: 0.383537; batch adversarial loss: 0.517951\n",
      "epoch 82; iter: 0; batch classifier loss: 0.386459; batch adversarial loss: 0.508647\n",
      "epoch 83; iter: 0; batch classifier loss: 0.369500; batch adversarial loss: 0.545080\n",
      "epoch 84; iter: 0; batch classifier loss: 0.422662; batch adversarial loss: 0.508022\n",
      "epoch 85; iter: 0; batch classifier loss: 0.435013; batch adversarial loss: 0.544577\n",
      "epoch 86; iter: 0; batch classifier loss: 0.431667; batch adversarial loss: 0.462497\n",
      "epoch 87; iter: 0; batch classifier loss: 0.441948; batch adversarial loss: 0.528202\n",
      "epoch 88; iter: 0; batch classifier loss: 0.385683; batch adversarial loss: 0.507607\n",
      "epoch 89; iter: 0; batch classifier loss: 0.456822; batch adversarial loss: 0.579912\n",
      "epoch 90; iter: 0; batch classifier loss: 0.444336; batch adversarial loss: 0.534373\n",
      "epoch 91; iter: 0; batch classifier loss: 0.393057; batch adversarial loss: 0.572032\n",
      "epoch 92; iter: 0; batch classifier loss: 0.418613; batch adversarial loss: 0.589301\n",
      "epoch 93; iter: 0; batch classifier loss: 0.511268; batch adversarial loss: 0.517558\n",
      "epoch 94; iter: 0; batch classifier loss: 0.378702; batch adversarial loss: 0.517561\n",
      "epoch 95; iter: 0; batch classifier loss: 0.346980; batch adversarial loss: 0.571256\n",
      "epoch 96; iter: 0; batch classifier loss: 0.424321; batch adversarial loss: 0.508986\n",
      "epoch 97; iter: 0; batch classifier loss: 0.369715; batch adversarial loss: 0.553237\n",
      "epoch 98; iter: 0; batch classifier loss: 0.376300; batch adversarial loss: 0.553825\n",
      "epoch 99; iter: 0; batch classifier loss: 0.361231; batch adversarial loss: 0.545402\n",
      "epoch 100; iter: 0; batch classifier loss: 0.427339; batch adversarial loss: 0.553324\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 101; iter: 0; batch classifier loss: 0.352576; batch adversarial loss: 0.562011\n",
      "epoch 102; iter: 0; batch classifier loss: 0.367037; batch adversarial loss: 0.553088\n",
      "epoch 103; iter: 0; batch classifier loss: 0.341539; batch adversarial loss: 0.553809\n",
      "epoch 104; iter: 0; batch classifier loss: 0.374461; batch adversarial loss: 0.581522\n",
      "epoch 105; iter: 0; batch classifier loss: 0.381575; batch adversarial loss: 0.535908\n",
      "epoch 106; iter: 0; batch classifier loss: 0.414064; batch adversarial loss: 0.544285\n",
      "epoch 107; iter: 0; batch classifier loss: 0.357661; batch adversarial loss: 0.536113\n",
      "epoch 108; iter: 0; batch classifier loss: 0.415605; batch adversarial loss: 0.508209\n",
      "epoch 109; iter: 0; batch classifier loss: 0.433680; batch adversarial loss: 0.553808\n",
      "epoch 110; iter: 0; batch classifier loss: 0.407528; batch adversarial loss: 0.535632\n",
      "epoch 111; iter: 0; batch classifier loss: 0.419584; batch adversarial loss: 0.635540\n",
      "epoch 112; iter: 0; batch classifier loss: 0.415645; batch adversarial loss: 0.717587\n",
      "epoch 113; iter: 0; batch classifier loss: 0.409380; batch adversarial loss: 0.563218\n",
      "epoch 114; iter: 0; batch classifier loss: 0.375844; batch adversarial loss: 0.599354\n",
      "epoch 115; iter: 0; batch classifier loss: 0.356088; batch adversarial loss: 0.579995\n",
      "epoch 116; iter: 0; batch classifier loss: 0.345241; batch adversarial loss: 0.562154\n",
      "epoch 117; iter: 0; batch classifier loss: 0.345012; batch adversarial loss: 0.517429\n",
      "epoch 118; iter: 0; batch classifier loss: 0.387966; batch adversarial loss: 0.544515\n",
      "epoch 119; iter: 0; batch classifier loss: 0.350155; batch adversarial loss: 0.543915\n",
      "epoch 120; iter: 0; batch classifier loss: 0.385790; batch adversarial loss: 0.580622\n",
      "epoch 121; iter: 0; batch classifier loss: 0.369407; batch adversarial loss: 0.562650\n",
      "epoch 122; iter: 0; batch classifier loss: 0.397193; batch adversarial loss: 0.598946\n",
      "epoch 123; iter: 0; batch classifier loss: 0.359213; batch adversarial loss: 0.516797\n",
      "epoch 124; iter: 0; batch classifier loss: 0.375180; batch adversarial loss: 0.506747\n",
      "epoch 125; iter: 0; batch classifier loss: 0.423047; batch adversarial loss: 0.552821\n",
      "epoch 126; iter: 0; batch classifier loss: 0.375520; batch adversarial loss: 0.553490\n",
      "epoch 127; iter: 0; batch classifier loss: 0.413861; batch adversarial loss: 0.562197\n",
      "epoch 128; iter: 0; batch classifier loss: 0.345034; batch adversarial loss: 0.534947\n",
      "epoch 129; iter: 0; batch classifier loss: 0.385746; batch adversarial loss: 0.534115\n",
      "epoch 130; iter: 0; batch classifier loss: 0.367620; batch adversarial loss: 0.564031\n",
      "epoch 131; iter: 0; batch classifier loss: 0.405076; batch adversarial loss: 0.562435\n",
      "epoch 132; iter: 0; batch classifier loss: 0.448235; batch adversarial loss: 0.507525\n",
      "epoch 133; iter: 0; batch classifier loss: 0.434593; batch adversarial loss: 0.545168\n",
      "epoch 134; iter: 0; batch classifier loss: 0.354081; batch adversarial loss: 0.536106\n",
      "epoch 135; iter: 0; batch classifier loss: 0.392589; batch adversarial loss: 0.480732\n",
      "epoch 136; iter: 0; batch classifier loss: 0.298713; batch adversarial loss: 0.572737\n",
      "epoch 137; iter: 0; batch classifier loss: 0.350744; batch adversarial loss: 0.580476\n",
      "epoch 138; iter: 0; batch classifier loss: 0.431340; batch adversarial loss: 0.499523\n",
      "epoch 139; iter: 0; batch classifier loss: 0.316626; batch adversarial loss: 0.499614\n",
      "epoch 140; iter: 0; batch classifier loss: 0.396165; batch adversarial loss: 0.579656\n",
      "epoch 141; iter: 0; batch classifier loss: 0.358915; batch adversarial loss: 0.535859\n",
      "epoch 142; iter: 0; batch classifier loss: 0.522065; batch adversarial loss: 0.571831\n",
      "epoch 143; iter: 0; batch classifier loss: 0.450733; batch adversarial loss: 0.453411\n",
      "epoch 144; iter: 0; batch classifier loss: 0.374552; batch adversarial loss: 0.508237\n",
      "epoch 145; iter: 0; batch classifier loss: 0.382679; batch adversarial loss: 0.434865\n",
      "epoch 146; iter: 0; batch classifier loss: 0.362600; batch adversarial loss: 0.599016\n",
      "epoch 147; iter: 0; batch classifier loss: 0.397593; batch adversarial loss: 0.589641\n",
      "epoch 148; iter: 0; batch classifier loss: 0.353480; batch adversarial loss: 0.508133\n",
      "epoch 149; iter: 0; batch classifier loss: 0.374758; batch adversarial loss: 0.591245\n",
      "epoch 150; iter: 0; batch classifier loss: 0.430012; batch adversarial loss: 0.481194\n",
      "epoch 151; iter: 0; batch classifier loss: 0.392900; batch adversarial loss: 0.526968\n",
      "epoch 152; iter: 0; batch classifier loss: 0.283782; batch adversarial loss: 0.616372\n",
      "epoch 153; iter: 0; batch classifier loss: 0.311086; batch adversarial loss: 0.562708\n",
      "epoch 154; iter: 0; batch classifier loss: 0.390634; batch adversarial loss: 0.607374\n",
      "epoch 155; iter: 0; batch classifier loss: 0.356616; batch adversarial loss: 0.635888\n",
      "epoch 156; iter: 0; batch classifier loss: 0.403774; batch adversarial loss: 0.544930\n",
      "epoch 157; iter: 0; batch classifier loss: 0.505215; batch adversarial loss: 0.480979\n",
      "epoch 158; iter: 0; batch classifier loss: 0.346305; batch adversarial loss: 0.589648\n",
      "epoch 159; iter: 0; batch classifier loss: 0.406598; batch adversarial loss: 0.499699\n",
      "epoch 160; iter: 0; batch classifier loss: 0.284960; batch adversarial loss: 0.563004\n",
      "epoch 161; iter: 0; batch classifier loss: 0.281826; batch adversarial loss: 0.626359\n",
      "epoch 162; iter: 0; batch classifier loss: 0.388511; batch adversarial loss: 0.499515\n",
      "epoch 163; iter: 0; batch classifier loss: 0.331531; batch adversarial loss: 0.507334\n",
      "epoch 164; iter: 0; batch classifier loss: 0.397509; batch adversarial loss: 0.507242\n",
      "epoch 165; iter: 0; batch classifier loss: 0.368303; batch adversarial loss: 0.498970\n",
      "epoch 166; iter: 0; batch classifier loss: 0.383784; batch adversarial loss: 0.589470\n",
      "epoch 167; iter: 0; batch classifier loss: 0.369752; batch adversarial loss: 0.489861\n",
      "epoch 168; iter: 0; batch classifier loss: 0.412058; batch adversarial loss: 0.500569\n",
      "epoch 169; iter: 0; batch classifier loss: 0.325177; batch adversarial loss: 0.589673\n",
      "epoch 170; iter: 0; batch classifier loss: 0.422901; batch adversarial loss: 0.580874\n",
      "epoch 171; iter: 0; batch classifier loss: 0.391145; batch adversarial loss: 0.581448\n",
      "epoch 172; iter: 0; batch classifier loss: 0.383486; batch adversarial loss: 0.524821\n",
      "epoch 173; iter: 0; batch classifier loss: 0.434526; batch adversarial loss: 0.545262\n",
      "epoch 174; iter: 0; batch classifier loss: 0.321788; batch adversarial loss: 0.552756\n",
      "epoch 175; iter: 0; batch classifier loss: 0.322537; batch adversarial loss: 0.554313\n",
      "epoch 176; iter: 0; batch classifier loss: 0.380507; batch adversarial loss: 0.589669\n",
      "epoch 177; iter: 0; batch classifier loss: 0.337379; batch adversarial loss: 0.608676\n",
      "epoch 178; iter: 0; batch classifier loss: 0.370148; batch adversarial loss: 0.498942\n",
      "epoch 179; iter: 0; batch classifier loss: 0.404999; batch adversarial loss: 0.471452\n",
      "epoch 180; iter: 0; batch classifier loss: 0.447508; batch adversarial loss: 0.462727\n",
      "epoch 181; iter: 0; batch classifier loss: 0.390099; batch adversarial loss: 0.598063\n",
      "epoch 182; iter: 0; batch classifier loss: 0.339197; batch adversarial loss: 0.605931\n",
      "epoch 183; iter: 0; batch classifier loss: 0.306576; batch adversarial loss: 0.562529\n",
      "epoch 184; iter: 0; batch classifier loss: 0.390942; batch adversarial loss: 0.463022\n",
      "epoch 185; iter: 0; batch classifier loss: 0.403788; batch adversarial loss: 0.553389\n",
      "epoch 186; iter: 0; batch classifier loss: 0.343744; batch adversarial loss: 0.507842\n",
      "epoch 187; iter: 0; batch classifier loss: 0.416383; batch adversarial loss: 0.562149\n",
      "epoch 188; iter: 0; batch classifier loss: 0.414761; batch adversarial loss: 0.536257\n",
      "epoch 189; iter: 0; batch classifier loss: 0.368340; batch adversarial loss: 0.498542\n",
      "epoch 190; iter: 0; batch classifier loss: 0.452393; batch adversarial loss: 0.516375\n",
      "epoch 191; iter: 0; batch classifier loss: 0.330436; batch adversarial loss: 0.516981\n",
      "epoch 192; iter: 0; batch classifier loss: 0.349667; batch adversarial loss: 0.535958\n",
      "epoch 193; iter: 0; batch classifier loss: 0.309262; batch adversarial loss: 0.563016\n",
      "epoch 194; iter: 0; batch classifier loss: 0.329336; batch adversarial loss: 0.498943\n",
      "epoch 195; iter: 0; batch classifier loss: 0.318001; batch adversarial loss: 0.616563\n",
      "epoch 196; iter: 0; batch classifier loss: 0.360517; batch adversarial loss: 0.526820\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 197; iter: 0; batch classifier loss: 0.410397; batch adversarial loss: 0.490249\n",
      "epoch 198; iter: 0; batch classifier loss: 0.326175; batch adversarial loss: 0.544409\n",
      "epoch 199; iter: 0; batch classifier loss: 0.384917; batch adversarial loss: 0.553219\n",
      "epoch 0; iter: 0; batch classifier loss: 0.686259; batch adversarial loss: 0.756353\n",
      "epoch 1; iter: 0; batch classifier loss: 0.637005; batch adversarial loss: 0.732102\n",
      "epoch 2; iter: 0; batch classifier loss: 0.625980; batch adversarial loss: 0.692908\n",
      "epoch 3; iter: 0; batch classifier loss: 0.511876; batch adversarial loss: 0.655350\n",
      "epoch 4; iter: 0; batch classifier loss: 0.557739; batch adversarial loss: 0.657240\n",
      "epoch 5; iter: 0; batch classifier loss: 0.529782; batch adversarial loss: 0.624817\n",
      "epoch 6; iter: 0; batch classifier loss: 0.530995; batch adversarial loss: 0.606398\n",
      "epoch 7; iter: 0; batch classifier loss: 0.504045; batch adversarial loss: 0.573530\n",
      "epoch 8; iter: 0; batch classifier loss: 0.546639; batch adversarial loss: 0.588746\n",
      "epoch 9; iter: 0; batch classifier loss: 0.569404; batch adversarial loss: 0.573922\n",
      "epoch 10; iter: 0; batch classifier loss: 0.586008; batch adversarial loss: 0.554295\n",
      "epoch 11; iter: 0; batch classifier loss: 0.535759; batch adversarial loss: 0.595913\n",
      "epoch 12; iter: 0; batch classifier loss: 0.517926; batch adversarial loss: 0.561373\n",
      "epoch 13; iter: 0; batch classifier loss: 0.529358; batch adversarial loss: 0.585855\n",
      "epoch 14; iter: 0; batch classifier loss: 0.475722; batch adversarial loss: 0.584679\n",
      "epoch 15; iter: 0; batch classifier loss: 0.544206; batch adversarial loss: 0.575338\n",
      "epoch 16; iter: 0; batch classifier loss: 0.430327; batch adversarial loss: 0.552683\n",
      "epoch 17; iter: 0; batch classifier loss: 0.498076; batch adversarial loss: 0.556836\n",
      "epoch 18; iter: 0; batch classifier loss: 0.489113; batch adversarial loss: 0.530624\n",
      "epoch 19; iter: 0; batch classifier loss: 0.459744; batch adversarial loss: 0.548405\n",
      "epoch 20; iter: 0; batch classifier loss: 0.471565; batch adversarial loss: 0.537290\n",
      "epoch 21; iter: 0; batch classifier loss: 0.507800; batch adversarial loss: 0.535659\n",
      "epoch 22; iter: 0; batch classifier loss: 0.486670; batch adversarial loss: 0.544077\n",
      "epoch 23; iter: 0; batch classifier loss: 0.545361; batch adversarial loss: 0.525484\n",
      "epoch 24; iter: 0; batch classifier loss: 0.528195; batch adversarial loss: 0.604227\n",
      "epoch 25; iter: 0; batch classifier loss: 0.523417; batch adversarial loss: 0.594468\n",
      "epoch 26; iter: 0; batch classifier loss: 0.435367; batch adversarial loss: 0.503565\n",
      "epoch 27; iter: 0; batch classifier loss: 0.480090; batch adversarial loss: 0.555648\n",
      "epoch 28; iter: 0; batch classifier loss: 0.543188; batch adversarial loss: 0.531561\n",
      "epoch 29; iter: 0; batch classifier loss: 0.480108; batch adversarial loss: 0.586300\n",
      "epoch 30; iter: 0; batch classifier loss: 0.435753; batch adversarial loss: 0.554558\n",
      "epoch 31; iter: 0; batch classifier loss: 0.439332; batch adversarial loss: 0.579133\n",
      "epoch 32; iter: 0; batch classifier loss: 0.479985; batch adversarial loss: 0.613584\n",
      "epoch 33; iter: 0; batch classifier loss: 0.492915; batch adversarial loss: 0.519385\n",
      "epoch 34; iter: 0; batch classifier loss: 0.480737; batch adversarial loss: 0.520102\n",
      "epoch 35; iter: 0; batch classifier loss: 0.412026; batch adversarial loss: 0.579088\n",
      "epoch 36; iter: 0; batch classifier loss: 0.497751; batch adversarial loss: 0.432289\n",
      "epoch 37; iter: 0; batch classifier loss: 0.491154; batch adversarial loss: 0.553705\n",
      "epoch 38; iter: 0; batch classifier loss: 0.447719; batch adversarial loss: 0.544565\n",
      "epoch 39; iter: 0; batch classifier loss: 0.510678; batch adversarial loss: 0.571071\n",
      "epoch 40; iter: 0; batch classifier loss: 0.419563; batch adversarial loss: 0.491576\n",
      "epoch 41; iter: 0; batch classifier loss: 0.458778; batch adversarial loss: 0.553483\n",
      "epoch 42; iter: 0; batch classifier loss: 0.419841; batch adversarial loss: 0.509006\n",
      "epoch 43; iter: 0; batch classifier loss: 0.459897; batch adversarial loss: 0.518381\n",
      "epoch 44; iter: 0; batch classifier loss: 0.477279; batch adversarial loss: 0.572297\n",
      "epoch 45; iter: 0; batch classifier loss: 0.472040; batch adversarial loss: 0.491542\n",
      "epoch 46; iter: 0; batch classifier loss: 0.449808; batch adversarial loss: 0.562842\n",
      "epoch 47; iter: 0; batch classifier loss: 0.447429; batch adversarial loss: 0.553500\n",
      "epoch 48; iter: 0; batch classifier loss: 0.499531; batch adversarial loss: 0.553003\n",
      "epoch 49; iter: 0; batch classifier loss: 0.450112; batch adversarial loss: 0.675390\n",
      "epoch 50; iter: 0; batch classifier loss: 0.476026; batch adversarial loss: 0.534704\n",
      "epoch 51; iter: 0; batch classifier loss: 0.459564; batch adversarial loss: 0.624356\n",
      "epoch 52; iter: 0; batch classifier loss: 0.447945; batch adversarial loss: 0.587585\n",
      "epoch 53; iter: 0; batch classifier loss: 0.423975; batch adversarial loss: 0.606224\n",
      "epoch 54; iter: 0; batch classifier loss: 0.472695; batch adversarial loss: 0.570375\n",
      "epoch 55; iter: 0; batch classifier loss: 0.482543; batch adversarial loss: 0.527025\n",
      "epoch 56; iter: 0; batch classifier loss: 0.442799; batch adversarial loss: 0.561294\n",
      "epoch 57; iter: 0; batch classifier loss: 0.411066; batch adversarial loss: 0.472165\n",
      "epoch 58; iter: 0; batch classifier loss: 0.437280; batch adversarial loss: 0.465042\n",
      "epoch 59; iter: 0; batch classifier loss: 0.488000; batch adversarial loss: 0.524652\n",
      "epoch 60; iter: 0; batch classifier loss: 0.431809; batch adversarial loss: 0.480864\n",
      "epoch 61; iter: 0; batch classifier loss: 0.392150; batch adversarial loss: 0.556382\n",
      "epoch 62; iter: 0; batch classifier loss: 0.390185; batch adversarial loss: 0.599521\n",
      "epoch 63; iter: 0; batch classifier loss: 0.370338; batch adversarial loss: 0.506851\n",
      "epoch 64; iter: 0; batch classifier loss: 0.404054; batch adversarial loss: 0.544441\n",
      "epoch 65; iter: 0; batch classifier loss: 0.409583; batch adversarial loss: 0.580396\n",
      "epoch 66; iter: 0; batch classifier loss: 0.452361; batch adversarial loss: 0.517834\n",
      "epoch 67; iter: 0; batch classifier loss: 0.442061; batch adversarial loss: 0.526132\n",
      "epoch 68; iter: 0; batch classifier loss: 0.423849; batch adversarial loss: 0.490561\n",
      "epoch 69; iter: 0; batch classifier loss: 0.479318; batch adversarial loss: 0.581123\n",
      "epoch 70; iter: 0; batch classifier loss: 0.468916; batch adversarial loss: 0.535171\n",
      "epoch 71; iter: 0; batch classifier loss: 0.450617; batch adversarial loss: 0.525755\n",
      "epoch 72; iter: 0; batch classifier loss: 0.438543; batch adversarial loss: 0.571459\n",
      "epoch 73; iter: 0; batch classifier loss: 0.392107; batch adversarial loss: 0.678734\n",
      "epoch 74; iter: 0; batch classifier loss: 0.428692; batch adversarial loss: 0.625303\n",
      "epoch 75; iter: 0; batch classifier loss: 0.366876; batch adversarial loss: 0.526341\n",
      "epoch 76; iter: 0; batch classifier loss: 0.392394; batch adversarial loss: 0.588834\n",
      "epoch 77; iter: 0; batch classifier loss: 0.390742; batch adversarial loss: 0.538324\n",
      "epoch 78; iter: 0; batch classifier loss: 0.353791; batch adversarial loss: 0.579027\n",
      "epoch 79; iter: 0; batch classifier loss: 0.493056; batch adversarial loss: 0.452601\n",
      "epoch 80; iter: 0; batch classifier loss: 0.401877; batch adversarial loss: 0.610351\n",
      "epoch 81; iter: 0; batch classifier loss: 0.399081; batch adversarial loss: 0.535471\n",
      "epoch 82; iter: 0; batch classifier loss: 0.397221; batch adversarial loss: 0.535049\n",
      "epoch 83; iter: 0; batch classifier loss: 0.400292; batch adversarial loss: 0.598644\n",
      "epoch 84; iter: 0; batch classifier loss: 0.405135; batch adversarial loss: 0.535676\n",
      "epoch 85; iter: 0; batch classifier loss: 0.454018; batch adversarial loss: 0.546157\n",
      "epoch 86; iter: 0; batch classifier loss: 0.421104; batch adversarial loss: 0.527289\n",
      "epoch 87; iter: 0; batch classifier loss: 0.345410; batch adversarial loss: 0.527655\n",
      "epoch 88; iter: 0; batch classifier loss: 0.424292; batch adversarial loss: 0.506267\n",
      "epoch 89; iter: 0; batch classifier loss: 0.446433; batch adversarial loss: 0.561160\n",
      "epoch 90; iter: 0; batch classifier loss: 0.392120; batch adversarial loss: 0.652725\n",
      "epoch 91; iter: 0; batch classifier loss: 0.413955; batch adversarial loss: 0.562808\n",
      "epoch 92; iter: 0; batch classifier loss: 0.324424; batch adversarial loss: 0.570605\n",
      "epoch 93; iter: 0; batch classifier loss: 0.360845; batch adversarial loss: 0.581132\n",
      "epoch 94; iter: 0; batch classifier loss: 0.383509; batch adversarial loss: 0.544107\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 95; iter: 0; batch classifier loss: 0.463090; batch adversarial loss: 0.535562\n",
      "epoch 96; iter: 0; batch classifier loss: 0.338039; batch adversarial loss: 0.536823\n",
      "epoch 97; iter: 0; batch classifier loss: 0.430139; batch adversarial loss: 0.497626\n",
      "epoch 98; iter: 0; batch classifier loss: 0.342941; batch adversarial loss: 0.517999\n",
      "epoch 99; iter: 0; batch classifier loss: 0.377459; batch adversarial loss: 0.497550\n",
      "epoch 100; iter: 0; batch classifier loss: 0.349087; batch adversarial loss: 0.535573\n",
      "epoch 101; iter: 0; batch classifier loss: 0.392018; batch adversarial loss: 0.471899\n",
      "epoch 102; iter: 0; batch classifier loss: 0.391363; batch adversarial loss: 0.615167\n",
      "epoch 103; iter: 0; batch classifier loss: 0.370552; batch adversarial loss: 0.510011\n",
      "epoch 104; iter: 0; batch classifier loss: 0.343899; batch adversarial loss: 0.560976\n",
      "epoch 105; iter: 0; batch classifier loss: 0.429322; batch adversarial loss: 0.608072\n",
      "epoch 106; iter: 0; batch classifier loss: 0.352130; batch adversarial loss: 0.570412\n",
      "epoch 107; iter: 0; batch classifier loss: 0.434540; batch adversarial loss: 0.477804\n",
      "epoch 108; iter: 0; batch classifier loss: 0.373050; batch adversarial loss: 0.578140\n",
      "epoch 109; iter: 0; batch classifier loss: 0.347897; batch adversarial loss: 0.479628\n",
      "epoch 110; iter: 0; batch classifier loss: 0.369222; batch adversarial loss: 0.552259\n",
      "epoch 111; iter: 0; batch classifier loss: 0.318446; batch adversarial loss: 0.507444\n",
      "epoch 112; iter: 0; batch classifier loss: 0.336445; batch adversarial loss: 0.588789\n",
      "epoch 113; iter: 0; batch classifier loss: 0.424084; batch adversarial loss: 0.535439\n",
      "epoch 114; iter: 0; batch classifier loss: 0.401201; batch adversarial loss: 0.561790\n",
      "epoch 115; iter: 0; batch classifier loss: 0.475482; batch adversarial loss: 0.534824\n",
      "epoch 116; iter: 0; batch classifier loss: 0.355696; batch adversarial loss: 0.507693\n",
      "epoch 117; iter: 0; batch classifier loss: 0.402366; batch adversarial loss: 0.600002\n",
      "epoch 118; iter: 0; batch classifier loss: 0.379792; batch adversarial loss: 0.525109\n",
      "epoch 119; iter: 0; batch classifier loss: 0.362211; batch adversarial loss: 0.563817\n",
      "epoch 120; iter: 0; batch classifier loss: 0.350503; batch adversarial loss: 0.691327\n",
      "epoch 121; iter: 0; batch classifier loss: 0.402106; batch adversarial loss: 0.564295\n",
      "epoch 122; iter: 0; batch classifier loss: 0.406041; batch adversarial loss: 0.515747\n",
      "epoch 123; iter: 0; batch classifier loss: 0.327817; batch adversarial loss: 0.464853\n",
      "epoch 124; iter: 0; batch classifier loss: 0.341134; batch adversarial loss: 0.554529\n",
      "epoch 125; iter: 0; batch classifier loss: 0.284992; batch adversarial loss: 0.482494\n",
      "epoch 126; iter: 0; batch classifier loss: 0.347632; batch adversarial loss: 0.516129\n",
      "epoch 127; iter: 0; batch classifier loss: 0.467672; batch adversarial loss: 0.518225\n",
      "epoch 128; iter: 0; batch classifier loss: 0.340759; batch adversarial loss: 0.480264\n",
      "epoch 129; iter: 0; batch classifier loss: 0.415431; batch adversarial loss: 0.553600\n",
      "epoch 130; iter: 0; batch classifier loss: 0.386948; batch adversarial loss: 0.481108\n",
      "epoch 131; iter: 0; batch classifier loss: 0.449831; batch adversarial loss: 0.598006\n",
      "epoch 132; iter: 0; batch classifier loss: 0.410651; batch adversarial loss: 0.489699\n",
      "epoch 133; iter: 0; batch classifier loss: 0.387078; batch adversarial loss: 0.608012\n",
      "epoch 134; iter: 0; batch classifier loss: 0.370137; batch adversarial loss: 0.506601\n",
      "epoch 135; iter: 0; batch classifier loss: 0.473956; batch adversarial loss: 0.518324\n",
      "epoch 136; iter: 0; batch classifier loss: 0.330072; batch adversarial loss: 0.563115\n",
      "epoch 137; iter: 0; batch classifier loss: 0.353811; batch adversarial loss: 0.496786\n",
      "epoch 138; iter: 0; batch classifier loss: 0.382126; batch adversarial loss: 0.591055\n",
      "epoch 139; iter: 0; batch classifier loss: 0.396335; batch adversarial loss: 0.570171\n",
      "epoch 140; iter: 0; batch classifier loss: 0.383183; batch adversarial loss: 0.526758\n",
      "epoch 141; iter: 0; batch classifier loss: 0.314790; batch adversarial loss: 0.570870\n",
      "epoch 142; iter: 0; batch classifier loss: 0.340894; batch adversarial loss: 0.516627\n",
      "epoch 143; iter: 0; batch classifier loss: 0.471408; batch adversarial loss: 0.542418\n",
      "epoch 144; iter: 0; batch classifier loss: 0.339337; batch adversarial loss: 0.553143\n",
      "epoch 145; iter: 0; batch classifier loss: 0.456797; batch adversarial loss: 0.536180\n",
      "epoch 146; iter: 0; batch classifier loss: 0.317642; batch adversarial loss: 0.642671\n",
      "epoch 147; iter: 0; batch classifier loss: 0.370883; batch adversarial loss: 0.506900\n",
      "epoch 148; iter: 0; batch classifier loss: 0.370104; batch adversarial loss: 0.572280\n",
      "epoch 149; iter: 0; batch classifier loss: 0.337233; batch adversarial loss: 0.514966\n",
      "epoch 150; iter: 0; batch classifier loss: 0.354443; batch adversarial loss: 0.545440\n",
      "epoch 151; iter: 0; batch classifier loss: 0.346979; batch adversarial loss: 0.581047\n",
      "epoch 152; iter: 0; batch classifier loss: 0.398259; batch adversarial loss: 0.561769\n",
      "epoch 153; iter: 0; batch classifier loss: 0.392946; batch adversarial loss: 0.453697\n",
      "epoch 154; iter: 0; batch classifier loss: 0.422405; batch adversarial loss: 0.533586\n",
      "epoch 155; iter: 0; batch classifier loss: 0.429885; batch adversarial loss: 0.636428\n",
      "epoch 156; iter: 0; batch classifier loss: 0.335355; batch adversarial loss: 0.544344\n",
      "epoch 157; iter: 0; batch classifier loss: 0.435328; batch adversarial loss: 0.498709\n",
      "epoch 158; iter: 0; batch classifier loss: 0.323695; batch adversarial loss: 0.580216\n",
      "epoch 159; iter: 0; batch classifier loss: 0.332191; batch adversarial loss: 0.561177\n",
      "epoch 160; iter: 0; batch classifier loss: 0.332319; batch adversarial loss: 0.570513\n",
      "epoch 161; iter: 0; batch classifier loss: 0.271849; batch adversarial loss: 0.580649\n",
      "epoch 162; iter: 0; batch classifier loss: 0.364030; batch adversarial loss: 0.570917\n",
      "epoch 163; iter: 0; batch classifier loss: 0.364277; batch adversarial loss: 0.564549\n",
      "epoch 164; iter: 0; batch classifier loss: 0.402333; batch adversarial loss: 0.488912\n",
      "epoch 165; iter: 0; batch classifier loss: 0.369615; batch adversarial loss: 0.562632\n",
      "epoch 166; iter: 0; batch classifier loss: 0.381443; batch adversarial loss: 0.535423\n",
      "epoch 167; iter: 0; batch classifier loss: 0.394367; batch adversarial loss: 0.497286\n",
      "epoch 168; iter: 0; batch classifier loss: 0.343803; batch adversarial loss: 0.508344\n",
      "epoch 169; iter: 0; batch classifier loss: 0.338842; batch adversarial loss: 0.553145\n",
      "epoch 170; iter: 0; batch classifier loss: 0.420287; batch adversarial loss: 0.627992\n",
      "epoch 171; iter: 0; batch classifier loss: 0.317075; batch adversarial loss: 0.569726\n",
      "epoch 172; iter: 0; batch classifier loss: 0.425698; batch adversarial loss: 0.491745\n",
      "epoch 173; iter: 0; batch classifier loss: 0.316199; batch adversarial loss: 0.554215\n",
      "epoch 174; iter: 0; batch classifier loss: 0.390372; batch adversarial loss: 0.634676\n",
      "epoch 175; iter: 0; batch classifier loss: 0.364863; batch adversarial loss: 0.535126\n",
      "epoch 176; iter: 0; batch classifier loss: 0.393221; batch adversarial loss: 0.560826\n",
      "epoch 177; iter: 0; batch classifier loss: 0.361012; batch adversarial loss: 0.571644\n",
      "epoch 178; iter: 0; batch classifier loss: 0.330462; batch adversarial loss: 0.596890\n",
      "epoch 179; iter: 0; batch classifier loss: 0.366910; batch adversarial loss: 0.517841\n",
      "epoch 180; iter: 0; batch classifier loss: 0.335024; batch adversarial loss: 0.554565\n",
      "epoch 181; iter: 0; batch classifier loss: 0.362857; batch adversarial loss: 0.571895\n",
      "epoch 182; iter: 0; batch classifier loss: 0.315383; batch adversarial loss: 0.544431\n",
      "epoch 183; iter: 0; batch classifier loss: 0.448261; batch adversarial loss: 0.545050\n",
      "epoch 184; iter: 0; batch classifier loss: 0.342116; batch adversarial loss: 0.553663\n",
      "epoch 185; iter: 0; batch classifier loss: 0.260466; batch adversarial loss: 0.498929\n",
      "epoch 186; iter: 0; batch classifier loss: 0.367993; batch adversarial loss: 0.583780\n",
      "epoch 187; iter: 0; batch classifier loss: 0.385385; batch adversarial loss: 0.545804\n",
      "epoch 188; iter: 0; batch classifier loss: 0.346629; batch adversarial loss: 0.545395\n",
      "epoch 189; iter: 0; batch classifier loss: 0.356649; batch adversarial loss: 0.546678\n",
      "epoch 190; iter: 0; batch classifier loss: 0.359176; batch adversarial loss: 0.580872\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 191; iter: 0; batch classifier loss: 0.422480; batch adversarial loss: 0.489839\n",
      "epoch 192; iter: 0; batch classifier loss: 0.348666; batch adversarial loss: 0.543919\n",
      "epoch 193; iter: 0; batch classifier loss: 0.330277; batch adversarial loss: 0.613998\n",
      "epoch 194; iter: 0; batch classifier loss: 0.336259; batch adversarial loss: 0.572306\n",
      "epoch 195; iter: 0; batch classifier loss: 0.329409; batch adversarial loss: 0.589052\n",
      "epoch 196; iter: 0; batch classifier loss: 0.286015; batch adversarial loss: 0.635663\n",
      "epoch 197; iter: 0; batch classifier loss: 0.283133; batch adversarial loss: 0.544103\n",
      "epoch 198; iter: 0; batch classifier loss: 0.335955; batch adversarial loss: 0.608134\n",
      "epoch 199; iter: 0; batch classifier loss: 0.370492; batch adversarial loss: 0.572356\n",
      "epoch 0; iter: 0; batch classifier loss: 0.693177; batch adversarial loss: 0.724726\n",
      "epoch 1; iter: 0; batch classifier loss: 0.773201; batch adversarial loss: 0.853792\n",
      "epoch 2; iter: 0; batch classifier loss: 0.785504; batch adversarial loss: 0.793128\n",
      "epoch 3; iter: 0; batch classifier loss: 0.894820; batch adversarial loss: 0.741473\n",
      "epoch 4; iter: 0; batch classifier loss: 0.743462; batch adversarial loss: 0.689433\n",
      "epoch 5; iter: 0; batch classifier loss: 0.646021; batch adversarial loss: 0.609681\n",
      "epoch 6; iter: 0; batch classifier loss: 0.629654; batch adversarial loss: 0.635551\n",
      "epoch 7; iter: 0; batch classifier loss: 0.584516; batch adversarial loss: 0.635406\n",
      "epoch 8; iter: 0; batch classifier loss: 0.565646; batch adversarial loss: 0.593269\n",
      "epoch 9; iter: 0; batch classifier loss: 0.606120; batch adversarial loss: 0.583341\n",
      "epoch 10; iter: 0; batch classifier loss: 0.496000; batch adversarial loss: 0.593462\n",
      "epoch 11; iter: 0; batch classifier loss: 0.494755; batch adversarial loss: 0.594314\n",
      "epoch 12; iter: 0; batch classifier loss: 0.463419; batch adversarial loss: 0.551498\n",
      "epoch 13; iter: 0; batch classifier loss: 0.532871; batch adversarial loss: 0.563875\n",
      "epoch 14; iter: 0; batch classifier loss: 0.496028; batch adversarial loss: 0.552106\n",
      "epoch 15; iter: 0; batch classifier loss: 0.504181; batch adversarial loss: 0.575511\n",
      "epoch 16; iter: 0; batch classifier loss: 0.483338; batch adversarial loss: 0.562252\n",
      "epoch 17; iter: 0; batch classifier loss: 0.441448; batch adversarial loss: 0.539975\n",
      "epoch 18; iter: 0; batch classifier loss: 0.454558; batch adversarial loss: 0.591322\n",
      "epoch 19; iter: 0; batch classifier loss: 0.443232; batch adversarial loss: 0.594551\n",
      "epoch 20; iter: 0; batch classifier loss: 0.505416; batch adversarial loss: 0.545838\n",
      "epoch 21; iter: 0; batch classifier loss: 0.452924; batch adversarial loss: 0.633554\n",
      "epoch 22; iter: 0; batch classifier loss: 0.503738; batch adversarial loss: 0.638862\n",
      "epoch 23; iter: 0; batch classifier loss: 0.436087; batch adversarial loss: 0.588267\n",
      "epoch 24; iter: 0; batch classifier loss: 0.438776; batch adversarial loss: 0.615581\n",
      "epoch 25; iter: 0; batch classifier loss: 0.567095; batch adversarial loss: 0.579777\n",
      "epoch 26; iter: 0; batch classifier loss: 0.486032; batch adversarial loss: 0.655533\n",
      "epoch 27; iter: 0; batch classifier loss: 0.481867; batch adversarial loss: 0.502702\n",
      "epoch 28; iter: 0; batch classifier loss: 0.445166; batch adversarial loss: 0.542830\n",
      "epoch 29; iter: 0; batch classifier loss: 0.475323; batch adversarial loss: 0.573735\n",
      "epoch 30; iter: 0; batch classifier loss: 0.511317; batch adversarial loss: 0.524399\n",
      "epoch 31; iter: 0; batch classifier loss: 0.473832; batch adversarial loss: 0.579078\n",
      "epoch 32; iter: 0; batch classifier loss: 0.470812; batch adversarial loss: 0.565587\n",
      "epoch 33; iter: 0; batch classifier loss: 0.496681; batch adversarial loss: 0.625790\n",
      "epoch 34; iter: 0; batch classifier loss: 0.459580; batch adversarial loss: 0.533785\n",
      "epoch 35; iter: 0; batch classifier loss: 0.454150; batch adversarial loss: 0.431429\n",
      "epoch 36; iter: 0; batch classifier loss: 0.417696; batch adversarial loss: 0.524889\n",
      "epoch 37; iter: 0; batch classifier loss: 0.531331; batch adversarial loss: 0.517258\n",
      "epoch 38; iter: 0; batch classifier loss: 0.416656; batch adversarial loss: 0.528994\n",
      "epoch 39; iter: 0; batch classifier loss: 0.533562; batch adversarial loss: 0.546223\n",
      "epoch 40; iter: 0; batch classifier loss: 0.434017; batch adversarial loss: 0.548480\n",
      "epoch 41; iter: 0; batch classifier loss: 0.456179; batch adversarial loss: 0.546937\n",
      "epoch 42; iter: 0; batch classifier loss: 0.428643; batch adversarial loss: 0.578707\n",
      "epoch 43; iter: 0; batch classifier loss: 0.437702; batch adversarial loss: 0.600951\n",
      "epoch 44; iter: 0; batch classifier loss: 0.503011; batch adversarial loss: 0.578552\n",
      "epoch 45; iter: 0; batch classifier loss: 0.506762; batch adversarial loss: 0.578306\n",
      "epoch 46; iter: 0; batch classifier loss: 0.368579; batch adversarial loss: 0.539897\n",
      "epoch 47; iter: 0; batch classifier loss: 0.537423; batch adversarial loss: 0.550664\n",
      "epoch 48; iter: 0; batch classifier loss: 0.399015; batch adversarial loss: 0.606365\n",
      "epoch 49; iter: 0; batch classifier loss: 0.433793; batch adversarial loss: 0.500557\n",
      "epoch 50; iter: 0; batch classifier loss: 0.456577; batch adversarial loss: 0.545822\n",
      "epoch 51; iter: 0; batch classifier loss: 0.454792; batch adversarial loss: 0.473796\n",
      "epoch 52; iter: 0; batch classifier loss: 0.393667; batch adversarial loss: 0.580310\n",
      "epoch 53; iter: 0; batch classifier loss: 0.372178; batch adversarial loss: 0.553178\n",
      "epoch 54; iter: 0; batch classifier loss: 0.421557; batch adversarial loss: 0.464698\n",
      "epoch 55; iter: 0; batch classifier loss: 0.429890; batch adversarial loss: 0.555209\n",
      "epoch 56; iter: 0; batch classifier loss: 0.377383; batch adversarial loss: 0.475618\n",
      "epoch 57; iter: 0; batch classifier loss: 0.390591; batch adversarial loss: 0.543209\n",
      "epoch 58; iter: 0; batch classifier loss: 0.360777; batch adversarial loss: 0.600031\n",
      "epoch 59; iter: 0; batch classifier loss: 0.440878; batch adversarial loss: 0.500494\n",
      "epoch 60; iter: 0; batch classifier loss: 0.385285; batch adversarial loss: 0.572824\n",
      "epoch 61; iter: 0; batch classifier loss: 0.458079; batch adversarial loss: 0.590330\n",
      "epoch 62; iter: 0; batch classifier loss: 0.331461; batch adversarial loss: 0.515909\n",
      "epoch 63; iter: 0; batch classifier loss: 0.389278; batch adversarial loss: 0.534764\n",
      "epoch 64; iter: 0; batch classifier loss: 0.440444; batch adversarial loss: 0.625152\n",
      "epoch 65; iter: 0; batch classifier loss: 0.403842; batch adversarial loss: 0.615754\n",
      "epoch 66; iter: 0; batch classifier loss: 0.435830; batch adversarial loss: 0.543292\n",
      "epoch 67; iter: 0; batch classifier loss: 0.416719; batch adversarial loss: 0.562148\n",
      "epoch 68; iter: 0; batch classifier loss: 0.363487; batch adversarial loss: 0.546575\n",
      "epoch 69; iter: 0; batch classifier loss: 0.400017; batch adversarial loss: 0.618282\n",
      "epoch 70; iter: 0; batch classifier loss: 0.404733; batch adversarial loss: 0.500255\n",
      "epoch 71; iter: 0; batch classifier loss: 0.441456; batch adversarial loss: 0.499744\n",
      "epoch 72; iter: 0; batch classifier loss: 0.440363; batch adversarial loss: 0.535430\n",
      "epoch 73; iter: 0; batch classifier loss: 0.471358; batch adversarial loss: 0.489316\n",
      "epoch 74; iter: 0; batch classifier loss: 0.454668; batch adversarial loss: 0.536227\n",
      "epoch 75; iter: 0; batch classifier loss: 0.399843; batch adversarial loss: 0.606328\n",
      "epoch 76; iter: 0; batch classifier loss: 0.370242; batch adversarial loss: 0.526851\n",
      "epoch 77; iter: 0; batch classifier loss: 0.385030; batch adversarial loss: 0.525816\n",
      "epoch 78; iter: 0; batch classifier loss: 0.409973; batch adversarial loss: 0.535077\n",
      "epoch 79; iter: 0; batch classifier loss: 0.419999; batch adversarial loss: 0.616900\n",
      "epoch 80; iter: 0; batch classifier loss: 0.453922; batch adversarial loss: 0.481393\n",
      "epoch 81; iter: 0; batch classifier loss: 0.443435; batch adversarial loss: 0.553071\n",
      "epoch 82; iter: 0; batch classifier loss: 0.512681; batch adversarial loss: 0.535392\n",
      "epoch 83; iter: 0; batch classifier loss: 0.400849; batch adversarial loss: 0.508230\n",
      "epoch 84; iter: 0; batch classifier loss: 0.391728; batch adversarial loss: 0.517487\n",
      "epoch 85; iter: 0; batch classifier loss: 0.430344; batch adversarial loss: 0.554472\n",
      "epoch 86; iter: 0; batch classifier loss: 0.373948; batch adversarial loss: 0.617104\n",
      "epoch 87; iter: 0; batch classifier loss: 0.406508; batch adversarial loss: 0.507918\n",
      "epoch 88; iter: 0; batch classifier loss: 0.393696; batch adversarial loss: 0.535810\n",
      "epoch 89; iter: 0; batch classifier loss: 0.358946; batch adversarial loss: 0.544847\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 90; iter: 0; batch classifier loss: 0.398235; batch adversarial loss: 0.562812\n",
      "epoch 91; iter: 0; batch classifier loss: 0.398308; batch adversarial loss: 0.535726\n",
      "epoch 92; iter: 0; batch classifier loss: 0.392218; batch adversarial loss: 0.635457\n",
      "epoch 93; iter: 0; batch classifier loss: 0.311514; batch adversarial loss: 0.536596\n",
      "epoch 94; iter: 0; batch classifier loss: 0.377259; batch adversarial loss: 0.545478\n",
      "epoch 95; iter: 0; batch classifier loss: 0.407494; batch adversarial loss: 0.544644\n",
      "epoch 96; iter: 0; batch classifier loss: 0.403018; batch adversarial loss: 0.589445\n",
      "epoch 97; iter: 0; batch classifier loss: 0.384925; batch adversarial loss: 0.553630\n",
      "epoch 98; iter: 0; batch classifier loss: 0.458593; batch adversarial loss: 0.472198\n",
      "epoch 99; iter: 0; batch classifier loss: 0.397736; batch adversarial loss: 0.626524\n",
      "epoch 100; iter: 0; batch classifier loss: 0.386467; batch adversarial loss: 0.525424\n",
      "epoch 101; iter: 0; batch classifier loss: 0.422422; batch adversarial loss: 0.607862\n",
      "epoch 102; iter: 0; batch classifier loss: 0.335919; batch adversarial loss: 0.571755\n",
      "epoch 103; iter: 0; batch classifier loss: 0.391315; batch adversarial loss: 0.454686\n",
      "epoch 104; iter: 0; batch classifier loss: 0.472487; batch adversarial loss: 0.553833\n",
      "epoch 105; iter: 0; batch classifier loss: 0.331405; batch adversarial loss: 0.580597\n",
      "epoch 106; iter: 0; batch classifier loss: 0.347608; batch adversarial loss: 0.508514\n",
      "epoch 107; iter: 0; batch classifier loss: 0.401150; batch adversarial loss: 0.607356\n",
      "epoch 108; iter: 0; batch classifier loss: 0.427717; batch adversarial loss: 0.617253\n",
      "epoch 109; iter: 0; batch classifier loss: 0.337815; batch adversarial loss: 0.653513\n",
      "epoch 110; iter: 0; batch classifier loss: 0.364737; batch adversarial loss: 0.554028\n",
      "epoch 111; iter: 0; batch classifier loss: 0.437967; batch adversarial loss: 0.553754\n",
      "epoch 112; iter: 0; batch classifier loss: 0.324279; batch adversarial loss: 0.563988\n",
      "epoch 113; iter: 0; batch classifier loss: 0.337821; batch adversarial loss: 0.589692\n",
      "epoch 114; iter: 0; batch classifier loss: 0.344346; batch adversarial loss: 0.580756\n",
      "epoch 115; iter: 0; batch classifier loss: 0.306815; batch adversarial loss: 0.563300\n",
      "epoch 116; iter: 0; batch classifier loss: 0.349396; batch adversarial loss: 0.508217\n",
      "epoch 117; iter: 0; batch classifier loss: 0.373104; batch adversarial loss: 0.599392\n",
      "epoch 118; iter: 0; batch classifier loss: 0.365299; batch adversarial loss: 0.490681\n",
      "epoch 119; iter: 0; batch classifier loss: 0.363037; batch adversarial loss: 0.544769\n",
      "epoch 120; iter: 0; batch classifier loss: 0.277964; batch adversarial loss: 0.599470\n",
      "epoch 121; iter: 0; batch classifier loss: 0.356894; batch adversarial loss: 0.481137\n",
      "epoch 122; iter: 0; batch classifier loss: 0.396583; batch adversarial loss: 0.581235\n",
      "epoch 123; iter: 0; batch classifier loss: 0.394079; batch adversarial loss: 0.499547\n",
      "epoch 124; iter: 0; batch classifier loss: 0.373686; batch adversarial loss: 0.589169\n",
      "epoch 125; iter: 0; batch classifier loss: 0.361646; batch adversarial loss: 0.544155\n",
      "epoch 126; iter: 0; batch classifier loss: 0.394529; batch adversarial loss: 0.571709\n",
      "epoch 127; iter: 0; batch classifier loss: 0.334840; batch adversarial loss: 0.617350\n",
      "epoch 128; iter: 0; batch classifier loss: 0.392475; batch adversarial loss: 0.554518\n",
      "epoch 129; iter: 0; batch classifier loss: 0.332320; batch adversarial loss: 0.517807\n",
      "epoch 130; iter: 0; batch classifier loss: 0.311547; batch adversarial loss: 0.534917\n",
      "epoch 131; iter: 0; batch classifier loss: 0.338792; batch adversarial loss: 0.472374\n",
      "epoch 132; iter: 0; batch classifier loss: 0.430419; batch adversarial loss: 0.562313\n",
      "epoch 133; iter: 0; batch classifier loss: 0.367947; batch adversarial loss: 0.535155\n",
      "epoch 134; iter: 0; batch classifier loss: 0.382175; batch adversarial loss: 0.544817\n",
      "epoch 135; iter: 0; batch classifier loss: 0.377373; batch adversarial loss: 0.508638\n",
      "epoch 136; iter: 0; batch classifier loss: 0.385396; batch adversarial loss: 0.535700\n",
      "epoch 137; iter: 0; batch classifier loss: 0.368915; batch adversarial loss: 0.544919\n",
      "epoch 138; iter: 0; batch classifier loss: 0.349584; batch adversarial loss: 0.580943\n",
      "epoch 139; iter: 0; batch classifier loss: 0.317658; batch adversarial loss: 0.544574\n",
      "epoch 140; iter: 0; batch classifier loss: 0.311793; batch adversarial loss: 0.562421\n",
      "epoch 141; iter: 0; batch classifier loss: 0.395171; batch adversarial loss: 0.454189\n",
      "epoch 142; iter: 0; batch classifier loss: 0.374780; batch adversarial loss: 0.662769\n",
      "epoch 143; iter: 0; batch classifier loss: 0.408659; batch adversarial loss: 0.562711\n",
      "epoch 144; iter: 0; batch classifier loss: 0.320308; batch adversarial loss: 0.571180\n",
      "epoch 145; iter: 0; batch classifier loss: 0.391575; batch adversarial loss: 0.571913\n",
      "epoch 146; iter: 0; batch classifier loss: 0.416743; batch adversarial loss: 0.535716\n",
      "epoch 147; iter: 0; batch classifier loss: 0.414416; batch adversarial loss: 0.518159\n",
      "epoch 148; iter: 0; batch classifier loss: 0.358973; batch adversarial loss: 0.498926\n",
      "epoch 149; iter: 0; batch classifier loss: 0.359988; batch adversarial loss: 0.571334\n",
      "epoch 150; iter: 0; batch classifier loss: 0.387864; batch adversarial loss: 0.499288\n",
      "epoch 151; iter: 0; batch classifier loss: 0.370783; batch adversarial loss: 0.553831\n",
      "epoch 152; iter: 0; batch classifier loss: 0.384851; batch adversarial loss: 0.490918\n",
      "epoch 153; iter: 0; batch classifier loss: 0.371660; batch adversarial loss: 0.572453\n",
      "epoch 154; iter: 0; batch classifier loss: 0.395946; batch adversarial loss: 0.471944\n",
      "epoch 155; iter: 0; batch classifier loss: 0.406055; batch adversarial loss: 0.634878\n",
      "epoch 156; iter: 0; batch classifier loss: 0.350237; batch adversarial loss: 0.526044\n",
      "epoch 157; iter: 0; batch classifier loss: 0.329597; batch adversarial loss: 0.508514\n",
      "epoch 158; iter: 0; batch classifier loss: 0.392320; batch adversarial loss: 0.534895\n",
      "epoch 159; iter: 0; batch classifier loss: 0.336416; batch adversarial loss: 0.544499\n",
      "epoch 160; iter: 0; batch classifier loss: 0.365730; batch adversarial loss: 0.526091\n",
      "epoch 161; iter: 0; batch classifier loss: 0.375381; batch adversarial loss: 0.508699\n",
      "epoch 162; iter: 0; batch classifier loss: 0.407644; batch adversarial loss: 0.499039\n",
      "epoch 163; iter: 0; batch classifier loss: 0.302412; batch adversarial loss: 0.489554\n",
      "epoch 164; iter: 0; batch classifier loss: 0.360627; batch adversarial loss: 0.490048\n",
      "epoch 165; iter: 0; batch classifier loss: 0.425269; batch adversarial loss: 0.508490\n",
      "epoch 166; iter: 0; batch classifier loss: 0.345076; batch adversarial loss: 0.526956\n",
      "epoch 167; iter: 0; batch classifier loss: 0.292276; batch adversarial loss: 0.580559\n",
      "epoch 168; iter: 0; batch classifier loss: 0.332889; batch adversarial loss: 0.554159\n",
      "epoch 169; iter: 0; batch classifier loss: 0.354737; batch adversarial loss: 0.535937\n",
      "epoch 170; iter: 0; batch classifier loss: 0.406383; batch adversarial loss: 0.544391\n",
      "epoch 171; iter: 0; batch classifier loss: 0.316131; batch adversarial loss: 0.534598\n",
      "epoch 172; iter: 0; batch classifier loss: 0.301387; batch adversarial loss: 0.562643\n",
      "epoch 173; iter: 0; batch classifier loss: 0.301021; batch adversarial loss: 0.580905\n",
      "epoch 174; iter: 0; batch classifier loss: 0.403492; batch adversarial loss: 0.607097\n",
      "epoch 175; iter: 0; batch classifier loss: 0.409423; batch adversarial loss: 0.517667\n",
      "epoch 176; iter: 0; batch classifier loss: 0.385140; batch adversarial loss: 0.544864\n",
      "epoch 177; iter: 0; batch classifier loss: 0.426013; batch adversarial loss: 0.553760\n",
      "epoch 178; iter: 0; batch classifier loss: 0.358339; batch adversarial loss: 0.490438\n",
      "epoch 179; iter: 0; batch classifier loss: 0.357970; batch adversarial loss: 0.535306\n",
      "epoch 180; iter: 0; batch classifier loss: 0.327581; batch adversarial loss: 0.490639\n",
      "epoch 181; iter: 0; batch classifier loss: 0.347381; batch adversarial loss: 0.545316\n",
      "epoch 182; iter: 0; batch classifier loss: 0.299974; batch adversarial loss: 0.553799\n",
      "epoch 183; iter: 0; batch classifier loss: 0.358379; batch adversarial loss: 0.571251\n",
      "epoch 184; iter: 0; batch classifier loss: 0.368417; batch adversarial loss: 0.589536\n",
      "epoch 185; iter: 0; batch classifier loss: 0.422042; batch adversarial loss: 0.472757\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 186; iter: 0; batch classifier loss: 0.298664; batch adversarial loss: 0.589588\n",
      "epoch 187; iter: 0; batch classifier loss: 0.367592; batch adversarial loss: 0.571514\n",
      "epoch 188; iter: 0; batch classifier loss: 0.278781; batch adversarial loss: 0.589875\n",
      "epoch 189; iter: 0; batch classifier loss: 0.329102; batch adversarial loss: 0.509247\n",
      "epoch 190; iter: 0; batch classifier loss: 0.328464; batch adversarial loss: 0.563088\n",
      "epoch 191; iter: 0; batch classifier loss: 0.346835; batch adversarial loss: 0.580799\n",
      "epoch 192; iter: 0; batch classifier loss: 0.364175; batch adversarial loss: 0.516847\n",
      "epoch 193; iter: 0; batch classifier loss: 0.309735; batch adversarial loss: 0.481179\n",
      "epoch 194; iter: 0; batch classifier loss: 0.526706; batch adversarial loss: 0.563237\n",
      "epoch 195; iter: 0; batch classifier loss: 0.303708; batch adversarial loss: 0.635483\n",
      "epoch 196; iter: 0; batch classifier loss: 0.275472; batch adversarial loss: 0.481213\n",
      "epoch 197; iter: 0; batch classifier loss: 0.392727; batch adversarial loss: 0.589385\n",
      "epoch 198; iter: 0; batch classifier loss: 0.360039; batch adversarial loss: 0.527361\n",
      "epoch 199; iter: 0; batch classifier loss: 0.351713; batch adversarial loss: 0.553576\n",
      "epoch 0; iter: 0; batch classifier loss: 0.745088; batch adversarial loss: 0.714865\n",
      "epoch 1; iter: 0; batch classifier loss: 0.624756; batch adversarial loss: 0.651906\n",
      "epoch 2; iter: 0; batch classifier loss: 0.588937; batch adversarial loss: 0.645728\n",
      "epoch 3; iter: 0; batch classifier loss: 0.609238; batch adversarial loss: 0.642072\n",
      "epoch 4; iter: 0; batch classifier loss: 0.579231; batch adversarial loss: 0.625658\n",
      "epoch 5; iter: 0; batch classifier loss: 0.559619; batch adversarial loss: 0.621641\n",
      "epoch 6; iter: 0; batch classifier loss: 0.551010; batch adversarial loss: 0.599060\n",
      "epoch 7; iter: 0; batch classifier loss: 0.582190; batch adversarial loss: 0.576757\n",
      "epoch 8; iter: 0; batch classifier loss: 0.541501; batch adversarial loss: 0.603025\n",
      "epoch 9; iter: 0; batch classifier loss: 0.574488; batch adversarial loss: 0.524677\n",
      "epoch 10; iter: 0; batch classifier loss: 0.515678; batch adversarial loss: 0.587454\n",
      "epoch 11; iter: 0; batch classifier loss: 0.611389; batch adversarial loss: 0.560033\n",
      "epoch 12; iter: 0; batch classifier loss: 0.569263; batch adversarial loss: 0.589918\n",
      "epoch 13; iter: 0; batch classifier loss: 0.452733; batch adversarial loss: 0.615462\n",
      "epoch 14; iter: 0; batch classifier loss: 0.539149; batch adversarial loss: 0.573127\n",
      "epoch 15; iter: 0; batch classifier loss: 0.492795; batch adversarial loss: 0.537311\n",
      "epoch 16; iter: 0; batch classifier loss: 0.478740; batch adversarial loss: 0.572824\n",
      "epoch 17; iter: 0; batch classifier loss: 0.564923; batch adversarial loss: 0.585785\n",
      "epoch 18; iter: 0; batch classifier loss: 0.484898; batch adversarial loss: 0.628157\n",
      "epoch 19; iter: 0; batch classifier loss: 0.590338; batch adversarial loss: 0.467516\n",
      "epoch 20; iter: 0; batch classifier loss: 0.462663; batch adversarial loss: 0.563241\n",
      "epoch 21; iter: 0; batch classifier loss: 0.468689; batch adversarial loss: 0.546064\n",
      "epoch 22; iter: 0; batch classifier loss: 0.480257; batch adversarial loss: 0.547906\n",
      "epoch 23; iter: 0; batch classifier loss: 0.449621; batch adversarial loss: 0.563329\n",
      "epoch 24; iter: 0; batch classifier loss: 0.496255; batch adversarial loss: 0.534599\n",
      "epoch 25; iter: 0; batch classifier loss: 0.507260; batch adversarial loss: 0.574212\n",
      "epoch 26; iter: 0; batch classifier loss: 0.478933; batch adversarial loss: 0.559531\n",
      "epoch 27; iter: 0; batch classifier loss: 0.427004; batch adversarial loss: 0.543256\n",
      "epoch 28; iter: 0; batch classifier loss: 0.517932; batch adversarial loss: 0.650232\n",
      "epoch 29; iter: 0; batch classifier loss: 0.447853; batch adversarial loss: 0.535218\n",
      "epoch 30; iter: 0; batch classifier loss: 0.467253; batch adversarial loss: 0.595540\n",
      "epoch 31; iter: 0; batch classifier loss: 0.438606; batch adversarial loss: 0.522499\n",
      "epoch 32; iter: 0; batch classifier loss: 0.496724; batch adversarial loss: 0.564513\n",
      "epoch 33; iter: 0; batch classifier loss: 0.557484; batch adversarial loss: 0.570394\n",
      "epoch 34; iter: 0; batch classifier loss: 0.443973; batch adversarial loss: 0.538282\n",
      "epoch 35; iter: 0; batch classifier loss: 0.516669; batch adversarial loss: 0.508598\n",
      "epoch 36; iter: 0; batch classifier loss: 0.461864; batch adversarial loss: 0.578981\n",
      "epoch 37; iter: 0; batch classifier loss: 0.520276; batch adversarial loss: 0.580990\n",
      "epoch 38; iter: 0; batch classifier loss: 0.410757; batch adversarial loss: 0.598501\n",
      "epoch 39; iter: 0; batch classifier loss: 0.509287; batch adversarial loss: 0.571058\n",
      "epoch 40; iter: 0; batch classifier loss: 0.486392; batch adversarial loss: 0.553457\n",
      "epoch 41; iter: 0; batch classifier loss: 0.601133; batch adversarial loss: 0.562145\n",
      "epoch 42; iter: 0; batch classifier loss: 0.383559; batch adversarial loss: 0.562000\n",
      "epoch 43; iter: 0; batch classifier loss: 0.388666; batch adversarial loss: 0.517920\n",
      "epoch 44; iter: 0; batch classifier loss: 0.451052; batch adversarial loss: 0.535120\n",
      "epoch 45; iter: 0; batch classifier loss: 0.382362; batch adversarial loss: 0.599262\n",
      "epoch 46; iter: 0; batch classifier loss: 0.478644; batch adversarial loss: 0.553957\n",
      "epoch 47; iter: 0; batch classifier loss: 0.479003; batch adversarial loss: 0.571921\n",
      "epoch 48; iter: 0; batch classifier loss: 0.376460; batch adversarial loss: 0.535511\n",
      "epoch 49; iter: 0; batch classifier loss: 0.359248; batch adversarial loss: 0.554683\n",
      "epoch 50; iter: 0; batch classifier loss: 0.459266; batch adversarial loss: 0.526173\n",
      "epoch 51; iter: 0; batch classifier loss: 0.456903; batch adversarial loss: 0.462245\n",
      "epoch 52; iter: 0; batch classifier loss: 0.467031; batch adversarial loss: 0.480375\n",
      "epoch 53; iter: 0; batch classifier loss: 0.396203; batch adversarial loss: 0.590601\n",
      "epoch 54; iter: 0; batch classifier loss: 0.479000; batch adversarial loss: 0.562990\n",
      "epoch 55; iter: 0; batch classifier loss: 0.459543; batch adversarial loss: 0.481201\n",
      "epoch 56; iter: 0; batch classifier loss: 0.366046; batch adversarial loss: 0.517431\n",
      "epoch 57; iter: 0; batch classifier loss: 0.458348; batch adversarial loss: 0.516738\n",
      "epoch 58; iter: 0; batch classifier loss: 0.481925; batch adversarial loss: 0.573081\n",
      "epoch 59; iter: 0; batch classifier loss: 0.351137; batch adversarial loss: 0.582054\n",
      "epoch 60; iter: 0; batch classifier loss: 0.455374; batch adversarial loss: 0.600903\n",
      "epoch 61; iter: 0; batch classifier loss: 0.448165; batch adversarial loss: 0.479640\n",
      "epoch 62; iter: 0; batch classifier loss: 0.384344; batch adversarial loss: 0.601707\n",
      "epoch 63; iter: 0; batch classifier loss: 0.390832; batch adversarial loss: 0.588473\n",
      "epoch 64; iter: 0; batch classifier loss: 0.413172; batch adversarial loss: 0.582507\n",
      "epoch 65; iter: 0; batch classifier loss: 0.413114; batch adversarial loss: 0.514869\n",
      "epoch 66; iter: 0; batch classifier loss: 0.357831; batch adversarial loss: 0.589699\n",
      "epoch 67; iter: 0; batch classifier loss: 0.403004; batch adversarial loss: 0.599922\n",
      "epoch 68; iter: 0; batch classifier loss: 0.379231; batch adversarial loss: 0.527025\n",
      "epoch 69; iter: 0; batch classifier loss: 0.477450; batch adversarial loss: 0.544956\n",
      "epoch 70; iter: 0; batch classifier loss: 0.435514; batch adversarial loss: 0.553584\n",
      "epoch 71; iter: 0; batch classifier loss: 0.408626; batch adversarial loss: 0.451648\n",
      "epoch 72; iter: 0; batch classifier loss: 0.453925; batch adversarial loss: 0.543203\n",
      "epoch 73; iter: 0; batch classifier loss: 0.441649; batch adversarial loss: 0.517541\n",
      "epoch 74; iter: 0; batch classifier loss: 0.367741; batch adversarial loss: 0.524935\n",
      "epoch 75; iter: 0; batch classifier loss: 0.418098; batch adversarial loss: 0.508273\n",
      "epoch 76; iter: 0; batch classifier loss: 0.419598; batch adversarial loss: 0.561650\n",
      "epoch 77; iter: 0; batch classifier loss: 0.416108; batch adversarial loss: 0.525636\n",
      "epoch 78; iter: 0; batch classifier loss: 0.411092; batch adversarial loss: 0.599426\n",
      "epoch 79; iter: 0; batch classifier loss: 0.373671; batch adversarial loss: 0.526052\n",
      "epoch 80; iter: 0; batch classifier loss: 0.348039; batch adversarial loss: 0.527428\n",
      "epoch 81; iter: 0; batch classifier loss: 0.538083; batch adversarial loss: 0.515944\n",
      "epoch 82; iter: 0; batch classifier loss: 0.443601; batch adversarial loss: 0.562370\n",
      "epoch 83; iter: 0; batch classifier loss: 0.429142; batch adversarial loss: 0.508807\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 84; iter: 0; batch classifier loss: 0.431831; batch adversarial loss: 0.634633\n",
      "epoch 85; iter: 0; batch classifier loss: 0.333717; batch adversarial loss: 0.499916\n",
      "epoch 86; iter: 0; batch classifier loss: 0.407435; batch adversarial loss: 0.580477\n",
      "epoch 87; iter: 0; batch classifier loss: 0.372734; batch adversarial loss: 0.505165\n",
      "epoch 88; iter: 0; batch classifier loss: 0.494353; batch adversarial loss: 0.479553\n",
      "epoch 89; iter: 0; batch classifier loss: 0.454602; batch adversarial loss: 0.582654\n",
      "epoch 90; iter: 0; batch classifier loss: 0.390449; batch adversarial loss: 0.499921\n",
      "epoch 91; iter: 0; batch classifier loss: 0.457373; batch adversarial loss: 0.560971\n",
      "epoch 92; iter: 0; batch classifier loss: 0.395428; batch adversarial loss: 0.462596\n",
      "epoch 93; iter: 0; batch classifier loss: 0.462056; batch adversarial loss: 0.508883\n",
      "epoch 94; iter: 0; batch classifier loss: 0.357222; batch adversarial loss: 0.570510\n",
      "epoch 95; iter: 0; batch classifier loss: 0.375313; batch adversarial loss: 0.524748\n",
      "epoch 96; iter: 0; batch classifier loss: 0.360182; batch adversarial loss: 0.636345\n",
      "epoch 97; iter: 0; batch classifier loss: 0.340354; batch adversarial loss: 0.574322\n",
      "epoch 98; iter: 0; batch classifier loss: 0.376055; batch adversarial loss: 0.536329\n",
      "epoch 99; iter: 0; batch classifier loss: 0.419450; batch adversarial loss: 0.497466\n",
      "epoch 100; iter: 0; batch classifier loss: 0.387672; batch adversarial loss: 0.600268\n",
      "epoch 101; iter: 0; batch classifier loss: 0.408652; batch adversarial loss: 0.543261\n",
      "epoch 102; iter: 0; batch classifier loss: 0.410803; batch adversarial loss: 0.460840\n",
      "epoch 103; iter: 0; batch classifier loss: 0.440810; batch adversarial loss: 0.492365\n",
      "epoch 104; iter: 0; batch classifier loss: 0.390789; batch adversarial loss: 0.571765\n",
      "epoch 105; iter: 0; batch classifier loss: 0.378966; batch adversarial loss: 0.545170\n",
      "epoch 106; iter: 0; batch classifier loss: 0.380520; batch adversarial loss: 0.564266\n",
      "epoch 107; iter: 0; batch classifier loss: 0.347750; batch adversarial loss: 0.498138\n",
      "epoch 108; iter: 0; batch classifier loss: 0.341182; batch adversarial loss: 0.590973\n",
      "epoch 109; iter: 0; batch classifier loss: 0.360669; batch adversarial loss: 0.554652\n",
      "epoch 110; iter: 0; batch classifier loss: 0.310229; batch adversarial loss: 0.534433\n",
      "epoch 111; iter: 0; batch classifier loss: 0.347875; batch adversarial loss: 0.507575\n",
      "epoch 112; iter: 0; batch classifier loss: 0.410322; batch adversarial loss: 0.590280\n",
      "epoch 113; iter: 0; batch classifier loss: 0.512055; batch adversarial loss: 0.627200\n",
      "epoch 114; iter: 0; batch classifier loss: 0.371258; batch adversarial loss: 0.590513\n",
      "epoch 115; iter: 0; batch classifier loss: 0.383560; batch adversarial loss: 0.564145\n",
      "epoch 116; iter: 0; batch classifier loss: 0.458910; batch adversarial loss: 0.460686\n",
      "epoch 117; iter: 0; batch classifier loss: 0.392445; batch adversarial loss: 0.552722\n",
      "epoch 118; iter: 0; batch classifier loss: 0.432450; batch adversarial loss: 0.573139\n",
      "epoch 119; iter: 0; batch classifier loss: 0.363079; batch adversarial loss: 0.571652\n",
      "epoch 120; iter: 0; batch classifier loss: 0.339595; batch adversarial loss: 0.626778\n",
      "epoch 121; iter: 0; batch classifier loss: 0.344934; batch adversarial loss: 0.609271\n",
      "epoch 122; iter: 0; batch classifier loss: 0.380894; batch adversarial loss: 0.598702\n",
      "epoch 123; iter: 0; batch classifier loss: 0.334161; batch adversarial loss: 0.517795\n",
      "epoch 124; iter: 0; batch classifier loss: 0.364892; batch adversarial loss: 0.573693\n",
      "epoch 125; iter: 0; batch classifier loss: 0.377449; batch adversarial loss: 0.582903\n",
      "epoch 126; iter: 0; batch classifier loss: 0.390629; batch adversarial loss: 0.489852\n",
      "epoch 127; iter: 0; batch classifier loss: 0.389693; batch adversarial loss: 0.536002\n",
      "epoch 128; iter: 0; batch classifier loss: 0.492561; batch adversarial loss: 0.636326\n",
      "epoch 129; iter: 0; batch classifier loss: 0.382610; batch adversarial loss: 0.524863\n",
      "epoch 130; iter: 0; batch classifier loss: 0.383583; batch adversarial loss: 0.525087\n",
      "epoch 131; iter: 0; batch classifier loss: 0.359241; batch adversarial loss: 0.452256\n",
      "epoch 132; iter: 0; batch classifier loss: 0.407203; batch adversarial loss: 0.535083\n",
      "epoch 133; iter: 0; batch classifier loss: 0.388529; batch adversarial loss: 0.572680\n",
      "epoch 134; iter: 0; batch classifier loss: 0.420689; batch adversarial loss: 0.443486\n",
      "epoch 135; iter: 0; batch classifier loss: 0.382109; batch adversarial loss: 0.525069\n",
      "epoch 136; iter: 0; batch classifier loss: 0.332520; batch adversarial loss: 0.498560\n",
      "epoch 137; iter: 0; batch classifier loss: 0.408702; batch adversarial loss: 0.488597\n",
      "epoch 138; iter: 0; batch classifier loss: 0.360721; batch adversarial loss: 0.572604\n",
      "epoch 139; iter: 0; batch classifier loss: 0.358467; batch adversarial loss: 0.619659\n",
      "epoch 140; iter: 0; batch classifier loss: 0.273254; batch adversarial loss: 0.561814\n",
      "epoch 141; iter: 0; batch classifier loss: 0.399746; batch adversarial loss: 0.618195\n",
      "epoch 142; iter: 0; batch classifier loss: 0.282483; batch adversarial loss: 0.517346\n",
      "epoch 143; iter: 0; batch classifier loss: 0.448203; batch adversarial loss: 0.583117\n",
      "epoch 144; iter: 0; batch classifier loss: 0.355960; batch adversarial loss: 0.600269\n",
      "epoch 145; iter: 0; batch classifier loss: 0.292549; batch adversarial loss: 0.488296\n",
      "epoch 146; iter: 0; batch classifier loss: 0.382316; batch adversarial loss: 0.471850\n",
      "epoch 147; iter: 0; batch classifier loss: 0.329735; batch adversarial loss: 0.552485\n",
      "epoch 148; iter: 0; batch classifier loss: 0.390427; batch adversarial loss: 0.488370\n",
      "epoch 149; iter: 0; batch classifier loss: 0.387449; batch adversarial loss: 0.571082\n",
      "epoch 150; iter: 0; batch classifier loss: 0.428767; batch adversarial loss: 0.535350\n",
      "epoch 151; iter: 0; batch classifier loss: 0.339976; batch adversarial loss: 0.544775\n",
      "epoch 152; iter: 0; batch classifier loss: 0.418971; batch adversarial loss: 0.488379\n",
      "epoch 153; iter: 0; batch classifier loss: 0.376824; batch adversarial loss: 0.490591\n",
      "epoch 154; iter: 0; batch classifier loss: 0.323108; batch adversarial loss: 0.570138\n",
      "epoch 155; iter: 0; batch classifier loss: 0.366809; batch adversarial loss: 0.572447\n",
      "epoch 156; iter: 0; batch classifier loss: 0.459613; batch adversarial loss: 0.535329\n",
      "epoch 157; iter: 0; batch classifier loss: 0.354575; batch adversarial loss: 0.524951\n",
      "epoch 158; iter: 0; batch classifier loss: 0.357643; batch adversarial loss: 0.443457\n",
      "epoch 159; iter: 0; batch classifier loss: 0.388854; batch adversarial loss: 0.526162\n",
      "epoch 160; iter: 0; batch classifier loss: 0.445817; batch adversarial loss: 0.589192\n",
      "epoch 161; iter: 0; batch classifier loss: 0.317586; batch adversarial loss: 0.543610\n",
      "epoch 162; iter: 0; batch classifier loss: 0.323305; batch adversarial loss: 0.442796\n",
      "epoch 163; iter: 0; batch classifier loss: 0.401747; batch adversarial loss: 0.535010\n",
      "epoch 164; iter: 0; batch classifier loss: 0.383799; batch adversarial loss: 0.516340\n",
      "epoch 165; iter: 0; batch classifier loss: 0.276562; batch adversarial loss: 0.563919\n",
      "epoch 166; iter: 0; batch classifier loss: 0.454584; batch adversarial loss: 0.481985\n",
      "epoch 167; iter: 0; batch classifier loss: 0.387815; batch adversarial loss: 0.591166\n",
      "epoch 168; iter: 0; batch classifier loss: 0.359419; batch adversarial loss: 0.590634\n",
      "epoch 169; iter: 0; batch classifier loss: 0.352414; batch adversarial loss: 0.571052\n",
      "epoch 170; iter: 0; batch classifier loss: 0.384553; batch adversarial loss: 0.555835\n",
      "epoch 171; iter: 0; batch classifier loss: 0.363917; batch adversarial loss: 0.546376\n",
      "epoch 172; iter: 0; batch classifier loss: 0.368619; batch adversarial loss: 0.519544\n",
      "epoch 173; iter: 0; batch classifier loss: 0.430266; batch adversarial loss: 0.554926\n",
      "epoch 174; iter: 0; batch classifier loss: 0.417748; batch adversarial loss: 0.578950\n",
      "epoch 175; iter: 0; batch classifier loss: 0.396758; batch adversarial loss: 0.452917\n",
      "epoch 176; iter: 0; batch classifier loss: 0.376153; batch adversarial loss: 0.636366\n",
      "epoch 177; iter: 0; batch classifier loss: 0.355505; batch adversarial loss: 0.489838\n",
      "epoch 178; iter: 0; batch classifier loss: 0.393898; batch adversarial loss: 0.496618\n",
      "epoch 179; iter: 0; batch classifier loss: 0.450232; batch adversarial loss: 0.562345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 180; iter: 0; batch classifier loss: 0.420386; batch adversarial loss: 0.609579\n",
      "epoch 181; iter: 0; batch classifier loss: 0.327198; batch adversarial loss: 0.553211\n",
      "epoch 182; iter: 0; batch classifier loss: 0.396288; batch adversarial loss: 0.562393\n",
      "epoch 183; iter: 0; batch classifier loss: 0.398429; batch adversarial loss: 0.498277\n",
      "epoch 184; iter: 0; batch classifier loss: 0.432823; batch adversarial loss: 0.496731\n",
      "epoch 185; iter: 0; batch classifier loss: 0.378247; batch adversarial loss: 0.580595\n",
      "epoch 186; iter: 0; batch classifier loss: 0.411076; batch adversarial loss: 0.515398\n",
      "epoch 187; iter: 0; batch classifier loss: 0.340507; batch adversarial loss: 0.497803\n",
      "epoch 188; iter: 0; batch classifier loss: 0.374354; batch adversarial loss: 0.487650\n",
      "epoch 189; iter: 0; batch classifier loss: 0.371924; batch adversarial loss: 0.635858\n",
      "epoch 190; iter: 0; batch classifier loss: 0.350619; batch adversarial loss: 0.517228\n",
      "epoch 191; iter: 0; batch classifier loss: 0.392837; batch adversarial loss: 0.573701\n",
      "epoch 192; iter: 0; batch classifier loss: 0.348731; batch adversarial loss: 0.543172\n",
      "epoch 193; iter: 0; batch classifier loss: 0.349540; batch adversarial loss: 0.561243\n",
      "epoch 194; iter: 0; batch classifier loss: 0.282551; batch adversarial loss: 0.469182\n",
      "epoch 195; iter: 0; batch classifier loss: 0.403538; batch adversarial loss: 0.599736\n",
      "epoch 196; iter: 0; batch classifier loss: 0.456583; batch adversarial loss: 0.620681\n",
      "epoch 197; iter: 0; batch classifier loss: 0.272275; batch adversarial loss: 0.571262\n",
      "epoch 198; iter: 0; batch classifier loss: 0.304787; batch adversarial loss: 0.526297\n",
      "epoch 199; iter: 0; batch classifier loss: 0.336039; batch adversarial loss: 0.581244\n",
      "epoch 0; iter: 0; batch classifier loss: 0.813499; batch adversarial loss: 0.585486\n",
      "epoch 1; iter: 0; batch classifier loss: 0.565039; batch adversarial loss: 0.635014\n",
      "epoch 2; iter: 0; batch classifier loss: 0.541341; batch adversarial loss: 0.634804\n",
      "epoch 3; iter: 0; batch classifier loss: 0.610345; batch adversarial loss: 0.637232\n",
      "epoch 4; iter: 0; batch classifier loss: 0.605539; batch adversarial loss: 0.642100\n",
      "epoch 5; iter: 0; batch classifier loss: 0.662567; batch adversarial loss: 0.620210\n",
      "epoch 6; iter: 0; batch classifier loss: 0.537238; batch adversarial loss: 0.589929\n",
      "epoch 7; iter: 0; batch classifier loss: 0.546970; batch adversarial loss: 0.572056\n",
      "epoch 8; iter: 0; batch classifier loss: 0.484161; batch adversarial loss: 0.602670\n",
      "epoch 9; iter: 0; batch classifier loss: 0.519528; batch adversarial loss: 0.602279\n",
      "epoch 10; iter: 0; batch classifier loss: 0.479440; batch adversarial loss: 0.574284\n",
      "epoch 11; iter: 0; batch classifier loss: 0.538770; batch adversarial loss: 0.592993\n",
      "epoch 12; iter: 0; batch classifier loss: 0.479949; batch adversarial loss: 0.640444\n",
      "epoch 13; iter: 0; batch classifier loss: 0.560423; batch adversarial loss: 0.616472\n",
      "epoch 14; iter: 0; batch classifier loss: 0.478145; batch adversarial loss: 0.574279\n",
      "epoch 15; iter: 0; batch classifier loss: 0.418267; batch adversarial loss: 0.608526\n",
      "epoch 16; iter: 0; batch classifier loss: 0.527278; batch adversarial loss: 0.524359\n",
      "epoch 17; iter: 0; batch classifier loss: 0.498071; batch adversarial loss: 0.643902\n",
      "epoch 18; iter: 0; batch classifier loss: 0.544641; batch adversarial loss: 0.543421\n",
      "epoch 19; iter: 0; batch classifier loss: 0.475529; batch adversarial loss: 0.546004\n",
      "epoch 20; iter: 0; batch classifier loss: 0.477480; batch adversarial loss: 0.528984\n",
      "epoch 21; iter: 0; batch classifier loss: 0.429666; batch adversarial loss: 0.533830\n",
      "epoch 22; iter: 0; batch classifier loss: 0.424351; batch adversarial loss: 0.533296\n",
      "epoch 23; iter: 0; batch classifier loss: 0.478677; batch adversarial loss: 0.499335\n",
      "epoch 24; iter: 0; batch classifier loss: 0.441864; batch adversarial loss: 0.596117\n",
      "epoch 25; iter: 0; batch classifier loss: 0.535583; batch adversarial loss: 0.548168\n",
      "epoch 26; iter: 0; batch classifier loss: 0.510145; batch adversarial loss: 0.481429\n",
      "epoch 27; iter: 0; batch classifier loss: 0.492801; batch adversarial loss: 0.562682\n",
      "epoch 28; iter: 0; batch classifier loss: 0.389178; batch adversarial loss: 0.587233\n",
      "epoch 29; iter: 0; batch classifier loss: 0.443546; batch adversarial loss: 0.537861\n",
      "epoch 30; iter: 0; batch classifier loss: 0.449556; batch adversarial loss: 0.519499\n",
      "epoch 31; iter: 0; batch classifier loss: 0.411234; batch adversarial loss: 0.519282\n",
      "epoch 32; iter: 0; batch classifier loss: 0.421503; batch adversarial loss: 0.545001\n",
      "epoch 33; iter: 0; batch classifier loss: 0.424433; batch adversarial loss: 0.562126\n",
      "epoch 34; iter: 0; batch classifier loss: 0.497378; batch adversarial loss: 0.527334\n",
      "epoch 35; iter: 0; batch classifier loss: 0.425301; batch adversarial loss: 0.509676\n",
      "epoch 36; iter: 0; batch classifier loss: 0.495817; batch adversarial loss: 0.545113\n",
      "epoch 37; iter: 0; batch classifier loss: 0.458945; batch adversarial loss: 0.562179\n",
      "epoch 38; iter: 0; batch classifier loss: 0.456034; batch adversarial loss: 0.580060\n",
      "epoch 39; iter: 0; batch classifier loss: 0.487136; batch adversarial loss: 0.641403\n",
      "epoch 40; iter: 0; batch classifier loss: 0.395458; batch adversarial loss: 0.491630\n",
      "epoch 41; iter: 0; batch classifier loss: 0.474840; batch adversarial loss: 0.577282\n",
      "epoch 42; iter: 0; batch classifier loss: 0.532420; batch adversarial loss: 0.501473\n",
      "epoch 43; iter: 0; batch classifier loss: 0.401000; batch adversarial loss: 0.544753\n",
      "epoch 44; iter: 0; batch classifier loss: 0.511944; batch adversarial loss: 0.606440\n",
      "epoch 45; iter: 0; batch classifier loss: 0.451659; batch adversarial loss: 0.537858\n",
      "epoch 46; iter: 0; batch classifier loss: 0.479575; batch adversarial loss: 0.500103\n",
      "epoch 47; iter: 0; batch classifier loss: 0.474102; batch adversarial loss: 0.509369\n",
      "epoch 48; iter: 0; batch classifier loss: 0.377338; batch adversarial loss: 0.544745\n",
      "epoch 49; iter: 0; batch classifier loss: 0.438599; batch adversarial loss: 0.517489\n",
      "epoch 50; iter: 0; batch classifier loss: 0.455669; batch adversarial loss: 0.535567\n",
      "epoch 51; iter: 0; batch classifier loss: 0.475290; batch adversarial loss: 0.500159\n",
      "epoch 52; iter: 0; batch classifier loss: 0.397678; batch adversarial loss: 0.526423\n",
      "epoch 53; iter: 0; batch classifier loss: 0.392079; batch adversarial loss: 0.544255\n",
      "epoch 54; iter: 0; batch classifier loss: 0.378900; batch adversarial loss: 0.581411\n",
      "epoch 55; iter: 0; batch classifier loss: 0.363117; batch adversarial loss: 0.635805\n",
      "epoch 56; iter: 0; batch classifier loss: 0.442813; batch adversarial loss: 0.553962\n",
      "epoch 57; iter: 0; batch classifier loss: 0.450806; batch adversarial loss: 0.553960\n",
      "epoch 58; iter: 0; batch classifier loss: 0.406916; batch adversarial loss: 0.554050\n",
      "epoch 59; iter: 0; batch classifier loss: 0.383911; batch adversarial loss: 0.580517\n",
      "epoch 60; iter: 0; batch classifier loss: 0.393292; batch adversarial loss: 0.544705\n",
      "epoch 61; iter: 0; batch classifier loss: 0.452207; batch adversarial loss: 0.491477\n",
      "epoch 62; iter: 0; batch classifier loss: 0.406121; batch adversarial loss: 0.518753\n",
      "epoch 63; iter: 0; batch classifier loss: 0.419311; batch adversarial loss: 0.545157\n",
      "epoch 64; iter: 0; batch classifier loss: 0.398549; batch adversarial loss: 0.579809\n",
      "epoch 65; iter: 0; batch classifier loss: 0.398726; batch adversarial loss: 0.672443\n",
      "epoch 66; iter: 0; batch classifier loss: 0.485970; batch adversarial loss: 0.576602\n",
      "epoch 67; iter: 0; batch classifier loss: 0.435388; batch adversarial loss: 0.551430\n",
      "epoch 68; iter: 0; batch classifier loss: 0.390209; batch adversarial loss: 0.622314\n",
      "epoch 69; iter: 0; batch classifier loss: 0.369442; batch adversarial loss: 0.612003\n",
      "epoch 70; iter: 0; batch classifier loss: 0.461702; batch adversarial loss: 0.555609\n",
      "epoch 71; iter: 0; batch classifier loss: 0.408151; batch adversarial loss: 0.519818\n",
      "epoch 72; iter: 0; batch classifier loss: 0.437236; batch adversarial loss: 0.546112\n",
      "epoch 73; iter: 0; batch classifier loss: 0.364837; batch adversarial loss: 0.571678\n",
      "epoch 74; iter: 0; batch classifier loss: 0.387010; batch adversarial loss: 0.580096\n",
      "epoch 75; iter: 0; batch classifier loss: 0.481636; batch adversarial loss: 0.526639\n",
      "epoch 76; iter: 0; batch classifier loss: 0.396192; batch adversarial loss: 0.515588\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 77; iter: 0; batch classifier loss: 0.470317; batch adversarial loss: 0.555044\n",
      "epoch 78; iter: 0; batch classifier loss: 0.404755; batch adversarial loss: 0.572933\n",
      "epoch 79; iter: 0; batch classifier loss: 0.430231; batch adversarial loss: 0.536463\n",
      "epoch 80; iter: 0; batch classifier loss: 0.416049; batch adversarial loss: 0.553879\n",
      "epoch 81; iter: 0; batch classifier loss: 0.371283; batch adversarial loss: 0.562121\n",
      "epoch 82; iter: 0; batch classifier loss: 0.399344; batch adversarial loss: 0.562564\n",
      "epoch 83; iter: 0; batch classifier loss: 0.475513; batch adversarial loss: 0.574732\n",
      "epoch 84; iter: 0; batch classifier loss: 0.361742; batch adversarial loss: 0.576826\n",
      "epoch 85; iter: 0; batch classifier loss: 0.444955; batch adversarial loss: 0.597750\n",
      "epoch 86; iter: 0; batch classifier loss: 0.364215; batch adversarial loss: 0.472963\n",
      "epoch 87; iter: 0; batch classifier loss: 0.396943; batch adversarial loss: 0.508050\n",
      "epoch 88; iter: 0; batch classifier loss: 0.466703; batch adversarial loss: 0.444734\n",
      "epoch 89; iter: 0; batch classifier loss: 0.437434; batch adversarial loss: 0.544796\n",
      "epoch 90; iter: 0; batch classifier loss: 0.403399; batch adversarial loss: 0.518597\n",
      "epoch 91; iter: 0; batch classifier loss: 0.407157; batch adversarial loss: 0.612376\n",
      "epoch 92; iter: 0; batch classifier loss: 0.432969; batch adversarial loss: 0.534081\n",
      "epoch 93; iter: 0; batch classifier loss: 0.349525; batch adversarial loss: 0.552516\n",
      "epoch 94; iter: 0; batch classifier loss: 0.395343; batch adversarial loss: 0.509067\n",
      "epoch 95; iter: 0; batch classifier loss: 0.330684; batch adversarial loss: 0.609816\n",
      "epoch 96; iter: 0; batch classifier loss: 0.462350; batch adversarial loss: 0.554175\n",
      "epoch 97; iter: 0; batch classifier loss: 0.420572; batch adversarial loss: 0.516506\n",
      "epoch 98; iter: 0; batch classifier loss: 0.324001; batch adversarial loss: 0.563057\n",
      "epoch 99; iter: 0; batch classifier loss: 0.441234; batch adversarial loss: 0.562654\n",
      "epoch 100; iter: 0; batch classifier loss: 0.409213; batch adversarial loss: 0.516693\n",
      "epoch 101; iter: 0; batch classifier loss: 0.455292; batch adversarial loss: 0.535485\n",
      "epoch 102; iter: 0; batch classifier loss: 0.401021; batch adversarial loss: 0.554228\n",
      "epoch 103; iter: 0; batch classifier loss: 0.407942; batch adversarial loss: 0.580363\n",
      "epoch 104; iter: 0; batch classifier loss: 0.435139; batch adversarial loss: 0.642451\n",
      "epoch 105; iter: 0; batch classifier loss: 0.439866; batch adversarial loss: 0.563808\n",
      "epoch 106; iter: 0; batch classifier loss: 0.437247; batch adversarial loss: 0.455904\n",
      "epoch 107; iter: 0; batch classifier loss: 0.364707; batch adversarial loss: 0.482009\n",
      "epoch 108; iter: 0; batch classifier loss: 0.336930; batch adversarial loss: 0.589606\n",
      "epoch 109; iter: 0; batch classifier loss: 0.426652; batch adversarial loss: 0.517541\n",
      "epoch 110; iter: 0; batch classifier loss: 0.414402; batch adversarial loss: 0.526419\n",
      "epoch 111; iter: 0; batch classifier loss: 0.391711; batch adversarial loss: 0.561728\n",
      "epoch 112; iter: 0; batch classifier loss: 0.398307; batch adversarial loss: 0.473937\n",
      "epoch 113; iter: 0; batch classifier loss: 0.381458; batch adversarial loss: 0.501789\n",
      "epoch 114; iter: 0; batch classifier loss: 0.317108; batch adversarial loss: 0.519216\n",
      "epoch 115; iter: 0; batch classifier loss: 0.371434; batch adversarial loss: 0.555587\n",
      "epoch 116; iter: 0; batch classifier loss: 0.388343; batch adversarial loss: 0.461387\n",
      "epoch 117; iter: 0; batch classifier loss: 0.407525; batch adversarial loss: 0.526659\n",
      "epoch 118; iter: 0; batch classifier loss: 0.381337; batch adversarial loss: 0.545272\n",
      "epoch 119; iter: 0; batch classifier loss: 0.343071; batch adversarial loss: 0.553906\n",
      "epoch 120; iter: 0; batch classifier loss: 0.390712; batch adversarial loss: 0.552447\n",
      "epoch 121; iter: 0; batch classifier loss: 0.391381; batch adversarial loss: 0.561389\n",
      "epoch 122; iter: 0; batch classifier loss: 0.349876; batch adversarial loss: 0.553005\n",
      "epoch 123; iter: 0; batch classifier loss: 0.354962; batch adversarial loss: 0.563056\n",
      "epoch 124; iter: 0; batch classifier loss: 0.370780; batch adversarial loss: 0.544339\n",
      "epoch 125; iter: 0; batch classifier loss: 0.400497; batch adversarial loss: 0.527849\n",
      "epoch 126; iter: 0; batch classifier loss: 0.336880; batch adversarial loss: 0.568851\n",
      "epoch 127; iter: 0; batch classifier loss: 0.354220; batch adversarial loss: 0.491146\n",
      "epoch 128; iter: 0; batch classifier loss: 0.313257; batch adversarial loss: 0.588600\n",
      "epoch 129; iter: 0; batch classifier loss: 0.399439; batch adversarial loss: 0.544036\n",
      "epoch 130; iter: 0; batch classifier loss: 0.342410; batch adversarial loss: 0.526560\n",
      "epoch 131; iter: 0; batch classifier loss: 0.398946; batch adversarial loss: 0.471897\n",
      "epoch 132; iter: 0; batch classifier loss: 0.442569; batch adversarial loss: 0.526644\n",
      "epoch 133; iter: 0; batch classifier loss: 0.367350; batch adversarial loss: 0.590426\n",
      "epoch 134; iter: 0; batch classifier loss: 0.428925; batch adversarial loss: 0.536465\n",
      "epoch 135; iter: 0; batch classifier loss: 0.349901; batch adversarial loss: 0.526535\n",
      "epoch 136; iter: 0; batch classifier loss: 0.369828; batch adversarial loss: 0.481664\n",
      "epoch 137; iter: 0; batch classifier loss: 0.407934; batch adversarial loss: 0.563148\n",
      "epoch 138; iter: 0; batch classifier loss: 0.357637; batch adversarial loss: 0.473165\n",
      "epoch 139; iter: 0; batch classifier loss: 0.403800; batch adversarial loss: 0.539153\n",
      "epoch 140; iter: 0; batch classifier loss: 0.378101; batch adversarial loss: 0.463674\n",
      "epoch 141; iter: 0; batch classifier loss: 0.346743; batch adversarial loss: 0.573468\n",
      "epoch 142; iter: 0; batch classifier loss: 0.382896; batch adversarial loss: 0.543393\n",
      "epoch 143; iter: 0; batch classifier loss: 0.441254; batch adversarial loss: 0.510105\n",
      "epoch 144; iter: 0; batch classifier loss: 0.328242; batch adversarial loss: 0.553206\n",
      "epoch 145; iter: 0; batch classifier loss: 0.333918; batch adversarial loss: 0.526702\n",
      "epoch 146; iter: 0; batch classifier loss: 0.407108; batch adversarial loss: 0.508432\n",
      "epoch 147; iter: 0; batch classifier loss: 0.415037; batch adversarial loss: 0.525920\n",
      "epoch 148; iter: 0; batch classifier loss: 0.337638; batch adversarial loss: 0.553577\n",
      "epoch 149; iter: 0; batch classifier loss: 0.350497; batch adversarial loss: 0.552929\n",
      "epoch 150; iter: 0; batch classifier loss: 0.334400; batch adversarial loss: 0.589507\n",
      "epoch 151; iter: 0; batch classifier loss: 0.354404; batch adversarial loss: 0.553564\n",
      "epoch 152; iter: 0; batch classifier loss: 0.390557; batch adversarial loss: 0.570504\n",
      "epoch 153; iter: 0; batch classifier loss: 0.399529; batch adversarial loss: 0.562787\n",
      "epoch 154; iter: 0; batch classifier loss: 0.383975; batch adversarial loss: 0.482459\n",
      "epoch 155; iter: 0; batch classifier loss: 0.317613; batch adversarial loss: 0.517804\n",
      "epoch 156; iter: 0; batch classifier loss: 0.347832; batch adversarial loss: 0.581969\n",
      "epoch 157; iter: 0; batch classifier loss: 0.398484; batch adversarial loss: 0.546164\n",
      "epoch 158; iter: 0; batch classifier loss: 0.347321; batch adversarial loss: 0.562869\n",
      "epoch 159; iter: 0; batch classifier loss: 0.316194; batch adversarial loss: 0.552720\n",
      "epoch 160; iter: 0; batch classifier loss: 0.350076; batch adversarial loss: 0.472260\n",
      "epoch 161; iter: 0; batch classifier loss: 0.440032; batch adversarial loss: 0.589678\n",
      "epoch 162; iter: 0; batch classifier loss: 0.437938; batch adversarial loss: 0.606797\n",
      "epoch 163; iter: 0; batch classifier loss: 0.419658; batch adversarial loss: 0.589125\n",
      "epoch 164; iter: 0; batch classifier loss: 0.390379; batch adversarial loss: 0.545353\n",
      "epoch 165; iter: 0; batch classifier loss: 0.390996; batch adversarial loss: 0.588785\n",
      "epoch 166; iter: 0; batch classifier loss: 0.406714; batch adversarial loss: 0.499768\n",
      "epoch 167; iter: 0; batch classifier loss: 0.374100; batch adversarial loss: 0.515208\n",
      "epoch 168; iter: 0; batch classifier loss: 0.378927; batch adversarial loss: 0.508324\n",
      "epoch 169; iter: 0; batch classifier loss: 0.300503; batch adversarial loss: 0.571934\n",
      "epoch 170; iter: 0; batch classifier loss: 0.319229; batch adversarial loss: 0.572444\n",
      "epoch 171; iter: 0; batch classifier loss: 0.327195; batch adversarial loss: 0.560744\n",
      "epoch 172; iter: 0; batch classifier loss: 0.365194; batch adversarial loss: 0.519151\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 173; iter: 0; batch classifier loss: 0.373637; batch adversarial loss: 0.510699\n",
      "epoch 174; iter: 0; batch classifier loss: 0.341390; batch adversarial loss: 0.564642\n",
      "epoch 175; iter: 0; batch classifier loss: 0.391637; batch adversarial loss: 0.587348\n",
      "epoch 176; iter: 0; batch classifier loss: 0.326828; batch adversarial loss: 0.543493\n",
      "epoch 177; iter: 0; batch classifier loss: 0.332411; batch adversarial loss: 0.529220\n",
      "epoch 178; iter: 0; batch classifier loss: 0.362422; batch adversarial loss: 0.563159\n",
      "epoch 179; iter: 0; batch classifier loss: 0.336408; batch adversarial loss: 0.555050\n",
      "epoch 180; iter: 0; batch classifier loss: 0.415552; batch adversarial loss: 0.557837\n",
      "epoch 181; iter: 0; batch classifier loss: 0.328601; batch adversarial loss: 0.507582\n",
      "epoch 182; iter: 0; batch classifier loss: 0.316506; batch adversarial loss: 0.542162\n",
      "epoch 183; iter: 0; batch classifier loss: 0.460120; batch adversarial loss: 0.597375\n",
      "epoch 184; iter: 0; batch classifier loss: 0.332825; batch adversarial loss: 0.527264\n",
      "epoch 185; iter: 0; batch classifier loss: 0.325977; batch adversarial loss: 0.678480\n",
      "epoch 186; iter: 0; batch classifier loss: 0.358497; batch adversarial loss: 0.526656\n",
      "epoch 187; iter: 0; batch classifier loss: 0.433721; batch adversarial loss: 0.516677\n",
      "epoch 188; iter: 0; batch classifier loss: 0.413907; batch adversarial loss: 0.607699\n",
      "epoch 189; iter: 0; batch classifier loss: 0.393292; batch adversarial loss: 0.572955\n",
      "epoch 190; iter: 0; batch classifier loss: 0.361615; batch adversarial loss: 0.571119\n",
      "epoch 191; iter: 0; batch classifier loss: 0.316083; batch adversarial loss: 0.607773\n",
      "epoch 192; iter: 0; batch classifier loss: 0.323578; batch adversarial loss: 0.470522\n",
      "epoch 193; iter: 0; batch classifier loss: 0.419792; batch adversarial loss: 0.518010\n",
      "epoch 194; iter: 0; batch classifier loss: 0.356386; batch adversarial loss: 0.553611\n",
      "epoch 195; iter: 0; batch classifier loss: 0.373408; batch adversarial loss: 0.553613\n",
      "epoch 196; iter: 0; batch classifier loss: 0.344589; batch adversarial loss: 0.416943\n",
      "epoch 197; iter: 0; batch classifier loss: 0.291828; batch adversarial loss: 0.571457\n",
      "epoch 198; iter: 0; batch classifier loss: 0.344398; batch adversarial loss: 0.562455\n",
      "epoch 199; iter: 0; batch classifier loss: 0.358991; batch adversarial loss: 0.506914\n",
      "epoch 0; iter: 0; batch classifier loss: 0.719262; batch adversarial loss: 0.603129\n",
      "epoch 1; iter: 0; batch classifier loss: 0.533600; batch adversarial loss: 0.673816\n",
      "epoch 2; iter: 0; batch classifier loss: 0.537092; batch adversarial loss: 0.652941\n",
      "epoch 3; iter: 0; batch classifier loss: 0.551839; batch adversarial loss: 0.677809\n",
      "epoch 4; iter: 0; batch classifier loss: 0.665074; batch adversarial loss: 0.615624\n",
      "epoch 5; iter: 0; batch classifier loss: 0.528177; batch adversarial loss: 0.597740\n",
      "epoch 6; iter: 0; batch classifier loss: 0.627648; batch adversarial loss: 0.569628\n",
      "epoch 7; iter: 0; batch classifier loss: 0.509234; batch adversarial loss: 0.619724\n",
      "epoch 8; iter: 0; batch classifier loss: 0.547600; batch adversarial loss: 0.622558\n",
      "epoch 9; iter: 0; batch classifier loss: 0.571576; batch adversarial loss: 0.597395\n",
      "epoch 10; iter: 0; batch classifier loss: 0.505421; batch adversarial loss: 0.614261\n",
      "epoch 11; iter: 0; batch classifier loss: 0.525607; batch adversarial loss: 0.591099\n",
      "epoch 12; iter: 0; batch classifier loss: 0.570767; batch adversarial loss: 0.564685\n",
      "epoch 13; iter: 0; batch classifier loss: 0.548486; batch adversarial loss: 0.575528\n",
      "epoch 14; iter: 0; batch classifier loss: 0.560545; batch adversarial loss: 0.627707\n",
      "epoch 15; iter: 0; batch classifier loss: 0.490429; batch adversarial loss: 0.500833\n",
      "epoch 16; iter: 0; batch classifier loss: 0.535083; batch adversarial loss: 0.548607\n",
      "epoch 17; iter: 0; batch classifier loss: 0.524695; batch adversarial loss: 0.582851\n",
      "epoch 18; iter: 0; batch classifier loss: 0.462717; batch adversarial loss: 0.549839\n",
      "epoch 19; iter: 0; batch classifier loss: 0.557281; batch adversarial loss: 0.552816\n",
      "epoch 20; iter: 0; batch classifier loss: 0.495920; batch adversarial loss: 0.579000\n",
      "epoch 21; iter: 0; batch classifier loss: 0.534986; batch adversarial loss: 0.537032\n",
      "epoch 22; iter: 0; batch classifier loss: 0.419112; batch adversarial loss: 0.540736\n",
      "epoch 23; iter: 0; batch classifier loss: 0.494997; batch adversarial loss: 0.513994\n",
      "epoch 24; iter: 0; batch classifier loss: 0.547895; batch adversarial loss: 0.537696\n",
      "epoch 25; iter: 0; batch classifier loss: 0.495464; batch adversarial loss: 0.488651\n",
      "epoch 26; iter: 0; batch classifier loss: 0.496401; batch adversarial loss: 0.545260\n",
      "epoch 27; iter: 0; batch classifier loss: 0.443122; batch adversarial loss: 0.537361\n",
      "epoch 28; iter: 0; batch classifier loss: 0.481343; batch adversarial loss: 0.553816\n",
      "epoch 29; iter: 0; batch classifier loss: 0.573482; batch adversarial loss: 0.570277\n",
      "epoch 30; iter: 0; batch classifier loss: 0.496441; batch adversarial loss: 0.604528\n",
      "epoch 31; iter: 0; batch classifier loss: 0.428668; batch adversarial loss: 0.475631\n",
      "epoch 32; iter: 0; batch classifier loss: 0.483468; batch adversarial loss: 0.527224\n",
      "epoch 33; iter: 0; batch classifier loss: 0.476973; batch adversarial loss: 0.580640\n",
      "epoch 34; iter: 0; batch classifier loss: 0.535184; batch adversarial loss: 0.562527\n",
      "epoch 35; iter: 0; batch classifier loss: 0.536230; batch adversarial loss: 0.517741\n",
      "epoch 36; iter: 0; batch classifier loss: 0.540239; batch adversarial loss: 0.578476\n",
      "epoch 37; iter: 0; batch classifier loss: 0.455175; batch adversarial loss: 0.540090\n",
      "epoch 38; iter: 0; batch classifier loss: 0.501655; batch adversarial loss: 0.514509\n",
      "epoch 39; iter: 0; batch classifier loss: 0.420048; batch adversarial loss: 0.563209\n",
      "epoch 40; iter: 0; batch classifier loss: 0.425384; batch adversarial loss: 0.514282\n",
      "epoch 41; iter: 0; batch classifier loss: 0.340180; batch adversarial loss: 0.460739\n",
      "epoch 42; iter: 0; batch classifier loss: 0.538670; batch adversarial loss: 0.558429\n",
      "epoch 43; iter: 0; batch classifier loss: 0.459671; batch adversarial loss: 0.564750\n",
      "epoch 44; iter: 0; batch classifier loss: 0.429362; batch adversarial loss: 0.496686\n",
      "epoch 45; iter: 0; batch classifier loss: 0.457252; batch adversarial loss: 0.564889\n",
      "epoch 46; iter: 0; batch classifier loss: 0.440359; batch adversarial loss: 0.509831\n",
      "epoch 47; iter: 0; batch classifier loss: 0.388460; batch adversarial loss: 0.562967\n",
      "epoch 48; iter: 0; batch classifier loss: 0.368217; batch adversarial loss: 0.639088\n",
      "epoch 49; iter: 0; batch classifier loss: 0.550841; batch adversarial loss: 0.500193\n",
      "epoch 50; iter: 0; batch classifier loss: 0.418264; batch adversarial loss: 0.598230\n",
      "epoch 51; iter: 0; batch classifier loss: 0.437090; batch adversarial loss: 0.583541\n",
      "epoch 52; iter: 0; batch classifier loss: 0.485530; batch adversarial loss: 0.562663\n",
      "epoch 53; iter: 0; batch classifier loss: 0.573864; batch adversarial loss: 0.617181\n",
      "epoch 54; iter: 0; batch classifier loss: 0.402012; batch adversarial loss: 0.580166\n",
      "epoch 55; iter: 0; batch classifier loss: 0.471253; batch adversarial loss: 0.516206\n",
      "epoch 56; iter: 0; batch classifier loss: 0.398283; batch adversarial loss: 0.468177\n",
      "epoch 57; iter: 0; batch classifier loss: 0.445294; batch adversarial loss: 0.547704\n",
      "epoch 58; iter: 0; batch classifier loss: 0.538067; batch adversarial loss: 0.479163\n",
      "epoch 59; iter: 0; batch classifier loss: 0.373859; batch adversarial loss: 0.629019\n",
      "epoch 60; iter: 0; batch classifier loss: 0.485503; batch adversarial loss: 0.545961\n",
      "epoch 61; iter: 0; batch classifier loss: 0.515788; batch adversarial loss: 0.628640\n",
      "epoch 62; iter: 0; batch classifier loss: 0.468235; batch adversarial loss: 0.583200\n",
      "epoch 63; iter: 0; batch classifier loss: 0.431408; batch adversarial loss: 0.609587\n",
      "epoch 64; iter: 0; batch classifier loss: 0.438119; batch adversarial loss: 0.475298\n",
      "epoch 65; iter: 0; batch classifier loss: 0.335366; batch adversarial loss: 0.506339\n",
      "epoch 66; iter: 0; batch classifier loss: 0.475458; batch adversarial loss: 0.506346\n",
      "epoch 67; iter: 0; batch classifier loss: 0.386109; batch adversarial loss: 0.518458\n",
      "epoch 68; iter: 0; batch classifier loss: 0.388321; batch adversarial loss: 0.545856\n",
      "epoch 69; iter: 0; batch classifier loss: 0.448095; batch adversarial loss: 0.642729\n",
      "epoch 70; iter: 0; batch classifier loss: 0.394247; batch adversarial loss: 0.556853\n",
      "epoch 71; iter: 0; batch classifier loss: 0.310427; batch adversarial loss: 0.588839\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 72; iter: 0; batch classifier loss: 0.501897; batch adversarial loss: 0.526233\n",
      "epoch 73; iter: 0; batch classifier loss: 0.390332; batch adversarial loss: 0.536046\n",
      "epoch 74; iter: 0; batch classifier loss: 0.452615; batch adversarial loss: 0.555770\n",
      "epoch 75; iter: 0; batch classifier loss: 0.408059; batch adversarial loss: 0.536151\n",
      "epoch 76; iter: 0; batch classifier loss: 0.400910; batch adversarial loss: 0.535015\n",
      "epoch 77; iter: 0; batch classifier loss: 0.389053; batch adversarial loss: 0.509286\n",
      "epoch 78; iter: 0; batch classifier loss: 0.358320; batch adversarial loss: 0.488030\n",
      "epoch 79; iter: 0; batch classifier loss: 0.433786; batch adversarial loss: 0.582118\n",
      "epoch 80; iter: 0; batch classifier loss: 0.355634; batch adversarial loss: 0.563245\n",
      "epoch 81; iter: 0; batch classifier loss: 0.385807; batch adversarial loss: 0.568198\n",
      "epoch 82; iter: 0; batch classifier loss: 0.472853; batch adversarial loss: 0.515539\n",
      "epoch 83; iter: 0; batch classifier loss: 0.370086; batch adversarial loss: 0.554934\n",
      "epoch 84; iter: 0; batch classifier loss: 0.343883; batch adversarial loss: 0.472379\n",
      "epoch 85; iter: 0; batch classifier loss: 0.367833; batch adversarial loss: 0.564149\n",
      "epoch 86; iter: 0; batch classifier loss: 0.300302; batch adversarial loss: 0.555910\n",
      "epoch 87; iter: 0; batch classifier loss: 0.480844; batch adversarial loss: 0.545228\n",
      "epoch 88; iter: 0; batch classifier loss: 0.327876; batch adversarial loss: 0.599774\n",
      "epoch 89; iter: 0; batch classifier loss: 0.403135; batch adversarial loss: 0.556459\n",
      "epoch 90; iter: 0; batch classifier loss: 0.385102; batch adversarial loss: 0.482808\n",
      "epoch 91; iter: 0; batch classifier loss: 0.416868; batch adversarial loss: 0.564003\n",
      "epoch 92; iter: 0; batch classifier loss: 0.381229; batch adversarial loss: 0.520548\n",
      "epoch 93; iter: 0; batch classifier loss: 0.448138; batch adversarial loss: 0.476722\n",
      "epoch 94; iter: 0; batch classifier loss: 0.328527; batch adversarial loss: 0.572686\n",
      "epoch 95; iter: 0; batch classifier loss: 0.417202; batch adversarial loss: 0.583298\n",
      "epoch 96; iter: 0; batch classifier loss: 0.460665; batch adversarial loss: 0.584931\n",
      "epoch 97; iter: 0; batch classifier loss: 0.423316; batch adversarial loss: 0.517497\n",
      "epoch 98; iter: 0; batch classifier loss: 0.409629; batch adversarial loss: 0.508192\n",
      "epoch 99; iter: 0; batch classifier loss: 0.456556; batch adversarial loss: 0.585714\n",
      "epoch 100; iter: 0; batch classifier loss: 0.411024; batch adversarial loss: 0.545173\n",
      "epoch 101; iter: 0; batch classifier loss: 0.365744; batch adversarial loss: 0.486866\n",
      "epoch 102; iter: 0; batch classifier loss: 0.325419; batch adversarial loss: 0.554987\n",
      "epoch 103; iter: 0; batch classifier loss: 0.421102; batch adversarial loss: 0.534938\n",
      "epoch 104; iter: 0; batch classifier loss: 0.310609; batch adversarial loss: 0.551851\n",
      "epoch 105; iter: 0; batch classifier loss: 0.389641; batch adversarial loss: 0.480331\n",
      "epoch 106; iter: 0; batch classifier loss: 0.440879; batch adversarial loss: 0.516090\n",
      "epoch 107; iter: 0; batch classifier loss: 0.366261; batch adversarial loss: 0.548535\n",
      "epoch 108; iter: 0; batch classifier loss: 0.293813; batch adversarial loss: 0.544082\n",
      "epoch 109; iter: 0; batch classifier loss: 0.446453; batch adversarial loss: 0.496224\n",
      "epoch 110; iter: 0; batch classifier loss: 0.379781; batch adversarial loss: 0.591826\n",
      "epoch 111; iter: 0; batch classifier loss: 0.411506; batch adversarial loss: 0.542197\n",
      "epoch 112; iter: 0; batch classifier loss: 0.395210; batch adversarial loss: 0.488243\n",
      "epoch 113; iter: 0; batch classifier loss: 0.381559; batch adversarial loss: 0.554846\n",
      "epoch 114; iter: 0; batch classifier loss: 0.384178; batch adversarial loss: 0.480286\n",
      "epoch 115; iter: 0; batch classifier loss: 0.331605; batch adversarial loss: 0.574402\n",
      "epoch 116; iter: 0; batch classifier loss: 0.345036; batch adversarial loss: 0.582784\n",
      "epoch 117; iter: 0; batch classifier loss: 0.436027; batch adversarial loss: 0.561301\n",
      "epoch 118; iter: 0; batch classifier loss: 0.376639; batch adversarial loss: 0.506321\n",
      "epoch 119; iter: 0; batch classifier loss: 0.461001; batch adversarial loss: 0.543061\n",
      "epoch 120; iter: 0; batch classifier loss: 0.378162; batch adversarial loss: 0.576878\n",
      "epoch 121; iter: 0; batch classifier loss: 0.370052; batch adversarial loss: 0.610701\n",
      "epoch 122; iter: 0; batch classifier loss: 0.428712; batch adversarial loss: 0.534567\n",
      "epoch 123; iter: 0; batch classifier loss: 0.425302; batch adversarial loss: 0.581564\n",
      "epoch 124; iter: 0; batch classifier loss: 0.289806; batch adversarial loss: 0.545172\n",
      "epoch 125; iter: 0; batch classifier loss: 0.345057; batch adversarial loss: 0.558873\n",
      "epoch 126; iter: 0; batch classifier loss: 0.384131; batch adversarial loss: 0.528597\n",
      "epoch 127; iter: 0; batch classifier loss: 0.436992; batch adversarial loss: 0.638026\n",
      "epoch 128; iter: 0; batch classifier loss: 0.370546; batch adversarial loss: 0.570270\n",
      "epoch 129; iter: 0; batch classifier loss: 0.350180; batch adversarial loss: 0.545409\n",
      "epoch 130; iter: 0; batch classifier loss: 0.412797; batch adversarial loss: 0.520074\n",
      "epoch 131; iter: 0; batch classifier loss: 0.410801; batch adversarial loss: 0.594467\n",
      "epoch 132; iter: 0; batch classifier loss: 0.405763; batch adversarial loss: 0.530688\n",
      "epoch 133; iter: 0; batch classifier loss: 0.436406; batch adversarial loss: 0.664781\n",
      "epoch 134; iter: 0; batch classifier loss: 0.355314; batch adversarial loss: 0.513674\n",
      "epoch 135; iter: 0; batch classifier loss: 0.479376; batch adversarial loss: 0.561971\n",
      "epoch 136; iter: 0; batch classifier loss: 0.440396; batch adversarial loss: 0.602974\n",
      "epoch 137; iter: 0; batch classifier loss: 0.363623; batch adversarial loss: 0.536994\n",
      "epoch 138; iter: 0; batch classifier loss: 0.398356; batch adversarial loss: 0.550170\n",
      "epoch 139; iter: 0; batch classifier loss: 0.314930; batch adversarial loss: 0.476943\n",
      "epoch 140; iter: 0; batch classifier loss: 0.389472; batch adversarial loss: 0.576432\n",
      "epoch 141; iter: 0; batch classifier loss: 0.268218; batch adversarial loss: 0.564543\n",
      "epoch 142; iter: 0; batch classifier loss: 0.428220; batch adversarial loss: 0.608467\n",
      "epoch 143; iter: 0; batch classifier loss: 0.377823; batch adversarial loss: 0.500021\n",
      "epoch 144; iter: 0; batch classifier loss: 0.309760; batch adversarial loss: 0.582940\n",
      "epoch 145; iter: 0; batch classifier loss: 0.461269; batch adversarial loss: 0.569214\n",
      "epoch 146; iter: 0; batch classifier loss: 0.343914; batch adversarial loss: 0.627377\n",
      "epoch 147; iter: 0; batch classifier loss: 0.335310; batch adversarial loss: 0.618175\n",
      "epoch 148; iter: 0; batch classifier loss: 0.385125; batch adversarial loss: 0.526467\n",
      "epoch 149; iter: 0; batch classifier loss: 0.268723; batch adversarial loss: 0.517112\n",
      "epoch 150; iter: 0; batch classifier loss: 0.333475; batch adversarial loss: 0.535200\n",
      "epoch 151; iter: 0; batch classifier loss: 0.353848; batch adversarial loss: 0.515048\n",
      "epoch 152; iter: 0; batch classifier loss: 0.447565; batch adversarial loss: 0.549036\n",
      "epoch 153; iter: 0; batch classifier loss: 0.403465; batch adversarial loss: 0.546949\n",
      "epoch 154; iter: 0; batch classifier loss: 0.357577; batch adversarial loss: 0.604338\n",
      "epoch 155; iter: 0; batch classifier loss: 0.350525; batch adversarial loss: 0.518397\n",
      "epoch 156; iter: 0; batch classifier loss: 0.352894; batch adversarial loss: 0.610632\n",
      "epoch 157; iter: 0; batch classifier loss: 0.354158; batch adversarial loss: 0.543041\n",
      "epoch 158; iter: 0; batch classifier loss: 0.354053; batch adversarial loss: 0.557617\n",
      "epoch 159; iter: 0; batch classifier loss: 0.377966; batch adversarial loss: 0.659807\n",
      "epoch 160; iter: 0; batch classifier loss: 0.319334; batch adversarial loss: 0.545309\n",
      "epoch 161; iter: 0; batch classifier loss: 0.346750; batch adversarial loss: 0.524134\n",
      "epoch 162; iter: 0; batch classifier loss: 0.427290; batch adversarial loss: 0.490984\n",
      "epoch 163; iter: 0; batch classifier loss: 0.415420; batch adversarial loss: 0.570519\n",
      "epoch 164; iter: 0; batch classifier loss: 0.348889; batch adversarial loss: 0.470064\n",
      "epoch 165; iter: 0; batch classifier loss: 0.459491; batch adversarial loss: 0.537276\n",
      "epoch 166; iter: 0; batch classifier loss: 0.422862; batch adversarial loss: 0.551589\n",
      "epoch 167; iter: 0; batch classifier loss: 0.356010; batch adversarial loss: 0.514723\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 168; iter: 0; batch classifier loss: 0.422638; batch adversarial loss: 0.498125\n",
      "epoch 169; iter: 0; batch classifier loss: 0.405407; batch adversarial loss: 0.513507\n",
      "epoch 170; iter: 0; batch classifier loss: 0.376657; batch adversarial loss: 0.466683\n",
      "epoch 171; iter: 0; batch classifier loss: 0.399429; batch adversarial loss: 0.483235\n",
      "epoch 172; iter: 0; batch classifier loss: 0.387435; batch adversarial loss: 0.552691\n",
      "epoch 173; iter: 0; batch classifier loss: 0.398689; batch adversarial loss: 0.496495\n",
      "epoch 174; iter: 0; batch classifier loss: 0.373820; batch adversarial loss: 0.568655\n",
      "epoch 175; iter: 0; batch classifier loss: 0.380378; batch adversarial loss: 0.506244\n",
      "epoch 176; iter: 0; batch classifier loss: 0.382302; batch adversarial loss: 0.453297\n",
      "epoch 177; iter: 0; batch classifier loss: 0.308542; batch adversarial loss: 0.540922\n",
      "epoch 178; iter: 0; batch classifier loss: 0.374886; batch adversarial loss: 0.519169\n",
      "epoch 179; iter: 0; batch classifier loss: 0.319124; batch adversarial loss: 0.486721\n",
      "epoch 180; iter: 0; batch classifier loss: 0.407265; batch adversarial loss: 0.570797\n",
      "epoch 181; iter: 0; batch classifier loss: 0.439997; batch adversarial loss: 0.645945\n",
      "epoch 182; iter: 0; batch classifier loss: 0.344225; batch adversarial loss: 0.473545\n",
      "epoch 183; iter: 0; batch classifier loss: 0.315924; batch adversarial loss: 0.579916\n",
      "epoch 184; iter: 0; batch classifier loss: 0.538142; batch adversarial loss: 0.587154\n",
      "epoch 185; iter: 0; batch classifier loss: 0.387610; batch adversarial loss: 0.588764\n",
      "epoch 186; iter: 0; batch classifier loss: 0.324599; batch adversarial loss: 0.546713\n",
      "epoch 187; iter: 0; batch classifier loss: 0.455474; batch adversarial loss: 0.541333\n",
      "epoch 188; iter: 0; batch classifier loss: 0.358079; batch adversarial loss: 0.536605\n",
      "epoch 189; iter: 0; batch classifier loss: 0.358842; batch adversarial loss: 0.587810\n",
      "epoch 190; iter: 0; batch classifier loss: 0.365749; batch adversarial loss: 0.558013\n",
      "epoch 191; iter: 0; batch classifier loss: 0.313432; batch adversarial loss: 0.525879\n",
      "epoch 192; iter: 0; batch classifier loss: 0.353232; batch adversarial loss: 0.478707\n",
      "epoch 193; iter: 0; batch classifier loss: 0.441059; batch adversarial loss: 0.491004\n",
      "epoch 194; iter: 0; batch classifier loss: 0.465717; batch adversarial loss: 0.514637\n",
      "epoch 195; iter: 0; batch classifier loss: 0.419663; batch adversarial loss: 0.518498\n",
      "epoch 196; iter: 0; batch classifier loss: 0.334931; batch adversarial loss: 0.517588\n",
      "epoch 197; iter: 0; batch classifier loss: 0.335382; batch adversarial loss: 0.607739\n",
      "epoch 198; iter: 0; batch classifier loss: 0.376687; batch adversarial loss: 0.512588\n",
      "epoch 199; iter: 0; batch classifier loss: 0.313713; batch adversarial loss: 0.605012\n",
      "epoch 0; iter: 0; batch classifier loss: 0.755018; batch adversarial loss: 0.715598\n",
      "epoch 1; iter: 0; batch classifier loss: 0.569354; batch adversarial loss: 0.673466\n",
      "epoch 2; iter: 0; batch classifier loss: 0.590793; batch adversarial loss: 0.629104\n",
      "epoch 3; iter: 0; batch classifier loss: 0.578646; batch adversarial loss: 0.632817\n",
      "epoch 4; iter: 0; batch classifier loss: 0.596079; batch adversarial loss: 0.602555\n",
      "epoch 5; iter: 0; batch classifier loss: 0.526135; batch adversarial loss: 0.628644\n",
      "epoch 6; iter: 0; batch classifier loss: 0.540062; batch adversarial loss: 0.629147\n",
      "epoch 7; iter: 0; batch classifier loss: 0.554814; batch adversarial loss: 0.605542\n",
      "epoch 8; iter: 0; batch classifier loss: 0.538098; batch adversarial loss: 0.573673\n",
      "epoch 9; iter: 0; batch classifier loss: 0.532158; batch adversarial loss: 0.555077\n",
      "epoch 10; iter: 0; batch classifier loss: 0.492396; batch adversarial loss: 0.558946\n",
      "epoch 11; iter: 0; batch classifier loss: 0.582132; batch adversarial loss: 0.612171\n",
      "epoch 12; iter: 0; batch classifier loss: 0.501128; batch adversarial loss: 0.599840\n",
      "epoch 13; iter: 0; batch classifier loss: 0.554110; batch adversarial loss: 0.598010\n",
      "epoch 14; iter: 0; batch classifier loss: 0.532096; batch adversarial loss: 0.564356\n",
      "epoch 15; iter: 0; batch classifier loss: 0.534947; batch adversarial loss: 0.583984\n",
      "epoch 16; iter: 0; batch classifier loss: 0.549115; batch adversarial loss: 0.628552\n",
      "epoch 17; iter: 0; batch classifier loss: 0.618301; batch adversarial loss: 0.555804\n",
      "epoch 18; iter: 0; batch classifier loss: 0.512895; batch adversarial loss: 0.605114\n",
      "epoch 19; iter: 0; batch classifier loss: 0.546430; batch adversarial loss: 0.584764\n",
      "epoch 20; iter: 0; batch classifier loss: 0.524728; batch adversarial loss: 0.554105\n",
      "epoch 21; iter: 0; batch classifier loss: 0.533644; batch adversarial loss: 0.514114\n",
      "epoch 22; iter: 0; batch classifier loss: 0.506793; batch adversarial loss: 0.531021\n",
      "epoch 23; iter: 0; batch classifier loss: 0.450922; batch adversarial loss: 0.579386\n",
      "epoch 24; iter: 0; batch classifier loss: 0.433698; batch adversarial loss: 0.577236\n",
      "epoch 25; iter: 0; batch classifier loss: 0.513085; batch adversarial loss: 0.486917\n",
      "epoch 26; iter: 0; batch classifier loss: 0.529074; batch adversarial loss: 0.523565\n",
      "epoch 27; iter: 0; batch classifier loss: 0.427313; batch adversarial loss: 0.553068\n",
      "epoch 28; iter: 0; batch classifier loss: 0.481095; batch adversarial loss: 0.527990\n",
      "epoch 29; iter: 0; batch classifier loss: 0.510615; batch adversarial loss: 0.596015\n",
      "epoch 30; iter: 0; batch classifier loss: 0.432361; batch adversarial loss: 0.528271\n",
      "epoch 31; iter: 0; batch classifier loss: 0.462574; batch adversarial loss: 0.518671\n",
      "epoch 32; iter: 0; batch classifier loss: 0.431534; batch adversarial loss: 0.536124\n",
      "epoch 33; iter: 0; batch classifier loss: 0.477770; batch adversarial loss: 0.561837\n",
      "epoch 34; iter: 0; batch classifier loss: 0.484956; batch adversarial loss: 0.533970\n",
      "epoch 35; iter: 0; batch classifier loss: 0.422484; batch adversarial loss: 0.528903\n",
      "epoch 36; iter: 0; batch classifier loss: 0.450747; batch adversarial loss: 0.618596\n",
      "epoch 37; iter: 0; batch classifier loss: 0.423948; batch adversarial loss: 0.589929\n",
      "epoch 38; iter: 0; batch classifier loss: 0.489115; batch adversarial loss: 0.579274\n",
      "epoch 39; iter: 0; batch classifier loss: 0.424623; batch adversarial loss: 0.538239\n",
      "epoch 40; iter: 0; batch classifier loss: 0.405345; batch adversarial loss: 0.524562\n",
      "epoch 41; iter: 0; batch classifier loss: 0.444518; batch adversarial loss: 0.495670\n",
      "epoch 42; iter: 0; batch classifier loss: 0.451508; batch adversarial loss: 0.452007\n",
      "epoch 43; iter: 0; batch classifier loss: 0.455880; batch adversarial loss: 0.469235\n",
      "epoch 44; iter: 0; batch classifier loss: 0.389186; batch adversarial loss: 0.563352\n",
      "epoch 45; iter: 0; batch classifier loss: 0.452269; batch adversarial loss: 0.609825\n",
      "epoch 46; iter: 0; batch classifier loss: 0.362388; batch adversarial loss: 0.432308\n",
      "epoch 47; iter: 0; batch classifier loss: 0.373303; batch adversarial loss: 0.516909\n",
      "epoch 48; iter: 0; batch classifier loss: 0.444033; batch adversarial loss: 0.542739\n",
      "epoch 49; iter: 0; batch classifier loss: 0.552446; batch adversarial loss: 0.541337\n",
      "epoch 50; iter: 0; batch classifier loss: 0.373409; batch adversarial loss: 0.607657\n",
      "epoch 51; iter: 0; batch classifier loss: 0.389291; batch adversarial loss: 0.517604\n",
      "epoch 52; iter: 0; batch classifier loss: 0.535563; batch adversarial loss: 0.565545\n",
      "epoch 53; iter: 0; batch classifier loss: 0.393973; batch adversarial loss: 0.562764\n",
      "epoch 54; iter: 0; batch classifier loss: 0.425214; batch adversarial loss: 0.600285\n",
      "epoch 55; iter: 0; batch classifier loss: 0.428089; batch adversarial loss: 0.507537\n",
      "epoch 56; iter: 0; batch classifier loss: 0.434949; batch adversarial loss: 0.608873\n",
      "epoch 57; iter: 0; batch classifier loss: 0.421020; batch adversarial loss: 0.534745\n",
      "epoch 58; iter: 0; batch classifier loss: 0.474590; batch adversarial loss: 0.626959\n",
      "epoch 59; iter: 0; batch classifier loss: 0.441884; batch adversarial loss: 0.673134\n",
      "epoch 60; iter: 0; batch classifier loss: 0.386496; batch adversarial loss: 0.590276\n",
      "epoch 61; iter: 0; batch classifier loss: 0.429927; batch adversarial loss: 0.489462\n",
      "epoch 62; iter: 0; batch classifier loss: 0.455334; batch adversarial loss: 0.590868\n",
      "epoch 63; iter: 0; batch classifier loss: 0.443619; batch adversarial loss: 0.526805\n",
      "epoch 64; iter: 0; batch classifier loss: 0.397137; batch adversarial loss: 0.572006\n",
      "epoch 65; iter: 0; batch classifier loss: 0.383985; batch adversarial loss: 0.534077\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 66; iter: 0; batch classifier loss: 0.490014; batch adversarial loss: 0.543316\n",
      "epoch 67; iter: 0; batch classifier loss: 0.420966; batch adversarial loss: 0.479475\n",
      "epoch 68; iter: 0; batch classifier loss: 0.383143; batch adversarial loss: 0.544869\n",
      "epoch 69; iter: 0; batch classifier loss: 0.419620; batch adversarial loss: 0.609873\n",
      "epoch 70; iter: 0; batch classifier loss: 0.354674; batch adversarial loss: 0.581388\n",
      "epoch 71; iter: 0; batch classifier loss: 0.396962; batch adversarial loss: 0.562632\n",
      "epoch 72; iter: 0; batch classifier loss: 0.432499; batch adversarial loss: 0.572212\n",
      "epoch 73; iter: 0; batch classifier loss: 0.346736; batch adversarial loss: 0.590394\n",
      "epoch 74; iter: 0; batch classifier loss: 0.516476; batch adversarial loss: 0.562634\n",
      "epoch 75; iter: 0; batch classifier loss: 0.475520; batch adversarial loss: 0.599827\n",
      "epoch 76; iter: 0; batch classifier loss: 0.443505; batch adversarial loss: 0.507346\n",
      "epoch 77; iter: 0; batch classifier loss: 0.355796; batch adversarial loss: 0.544413\n",
      "epoch 78; iter: 0; batch classifier loss: 0.373458; batch adversarial loss: 0.563065\n",
      "epoch 79; iter: 0; batch classifier loss: 0.398682; batch adversarial loss: 0.553085\n",
      "epoch 80; iter: 0; batch classifier loss: 0.343740; batch adversarial loss: 0.600507\n",
      "epoch 81; iter: 0; batch classifier loss: 0.369114; batch adversarial loss: 0.544755\n",
      "epoch 82; iter: 0; batch classifier loss: 0.396363; batch adversarial loss: 0.525944\n",
      "epoch 83; iter: 0; batch classifier loss: 0.346169; batch adversarial loss: 0.507463\n",
      "epoch 84; iter: 0; batch classifier loss: 0.320685; batch adversarial loss: 0.470582\n",
      "epoch 85; iter: 0; batch classifier loss: 0.416744; batch adversarial loss: 0.535337\n",
      "epoch 86; iter: 0; batch classifier loss: 0.405497; batch adversarial loss: 0.618187\n",
      "epoch 87; iter: 0; batch classifier loss: 0.332694; batch adversarial loss: 0.563281\n",
      "epoch 88; iter: 0; batch classifier loss: 0.353821; batch adversarial loss: 0.498117\n",
      "epoch 89; iter: 0; batch classifier loss: 0.357004; batch adversarial loss: 0.553865\n",
      "epoch 90; iter: 0; batch classifier loss: 0.359495; batch adversarial loss: 0.488930\n",
      "epoch 91; iter: 0; batch classifier loss: 0.430198; batch adversarial loss: 0.581487\n",
      "epoch 92; iter: 0; batch classifier loss: 0.406609; batch adversarial loss: 0.507683\n",
      "epoch 93; iter: 0; batch classifier loss: 0.404978; batch adversarial loss: 0.553592\n",
      "epoch 94; iter: 0; batch classifier loss: 0.373139; batch adversarial loss: 0.553324\n",
      "epoch 95; iter: 0; batch classifier loss: 0.456258; batch adversarial loss: 0.535293\n",
      "epoch 96; iter: 0; batch classifier loss: 0.426744; batch adversarial loss: 0.506649\n",
      "epoch 97; iter: 0; batch classifier loss: 0.391576; batch adversarial loss: 0.563032\n",
      "epoch 98; iter: 0; batch classifier loss: 0.452550; batch adversarial loss: 0.544425\n",
      "epoch 99; iter: 0; batch classifier loss: 0.495642; batch adversarial loss: 0.534864\n",
      "epoch 100; iter: 0; batch classifier loss: 0.411887; batch adversarial loss: 0.508588\n",
      "epoch 101; iter: 0; batch classifier loss: 0.356175; batch adversarial loss: 0.545365\n",
      "epoch 102; iter: 0; batch classifier loss: 0.369831; batch adversarial loss: 0.582036\n",
      "epoch 103; iter: 0; batch classifier loss: 0.410262; batch adversarial loss: 0.647805\n",
      "epoch 104; iter: 0; batch classifier loss: 0.444806; batch adversarial loss: 0.497874\n",
      "epoch 105; iter: 0; batch classifier loss: 0.334898; batch adversarial loss: 0.535283\n",
      "epoch 106; iter: 0; batch classifier loss: 0.441589; batch adversarial loss: 0.544475\n",
      "epoch 107; iter: 0; batch classifier loss: 0.368311; batch adversarial loss: 0.553535\n",
      "epoch 108; iter: 0; batch classifier loss: 0.428018; batch adversarial loss: 0.600215\n",
      "epoch 109; iter: 0; batch classifier loss: 0.346966; batch adversarial loss: 0.525591\n",
      "epoch 110; iter: 0; batch classifier loss: 0.421662; batch adversarial loss: 0.505549\n",
      "epoch 111; iter: 0; batch classifier loss: 0.420312; batch adversarial loss: 0.550814\n",
      "epoch 112; iter: 0; batch classifier loss: 0.446596; batch adversarial loss: 0.523194\n",
      "epoch 113; iter: 0; batch classifier loss: 0.379056; batch adversarial loss: 0.609301\n",
      "epoch 114; iter: 0; batch classifier loss: 0.379840; batch adversarial loss: 0.471655\n",
      "epoch 115; iter: 0; batch classifier loss: 0.360925; batch adversarial loss: 0.579829\n",
      "epoch 116; iter: 0; batch classifier loss: 0.389512; batch adversarial loss: 0.555348\n",
      "epoch 117; iter: 0; batch classifier loss: 0.415008; batch adversarial loss: 0.517441\n",
      "epoch 118; iter: 0; batch classifier loss: 0.326838; batch adversarial loss: 0.488070\n",
      "epoch 119; iter: 0; batch classifier loss: 0.334194; batch adversarial loss: 0.668236\n",
      "epoch 120; iter: 0; batch classifier loss: 0.419954; batch adversarial loss: 0.535725\n",
      "epoch 121; iter: 0; batch classifier loss: 0.377488; batch adversarial loss: 0.532248\n",
      "epoch 122; iter: 0; batch classifier loss: 0.348926; batch adversarial loss: 0.630367\n",
      "epoch 123; iter: 0; batch classifier loss: 0.301193; batch adversarial loss: 0.592701\n",
      "epoch 124; iter: 0; batch classifier loss: 0.361892; batch adversarial loss: 0.498955\n",
      "epoch 125; iter: 0; batch classifier loss: 0.412454; batch adversarial loss: 0.564102\n",
      "epoch 126; iter: 0; batch classifier loss: 0.330022; batch adversarial loss: 0.571300\n",
      "epoch 127; iter: 0; batch classifier loss: 0.402025; batch adversarial loss: 0.517667\n",
      "epoch 128; iter: 0; batch classifier loss: 0.326949; batch adversarial loss: 0.508752\n",
      "epoch 129; iter: 0; batch classifier loss: 0.390348; batch adversarial loss: 0.580564\n",
      "epoch 130; iter: 0; batch classifier loss: 0.373297; batch adversarial loss: 0.562187\n",
      "epoch 131; iter: 0; batch classifier loss: 0.455109; batch adversarial loss: 0.572653\n",
      "epoch 132; iter: 0; batch classifier loss: 0.380244; batch adversarial loss: 0.443595\n",
      "epoch 133; iter: 0; batch classifier loss: 0.395832; batch adversarial loss: 0.571597\n",
      "epoch 134; iter: 0; batch classifier loss: 0.399810; batch adversarial loss: 0.554162\n",
      "epoch 135; iter: 0; batch classifier loss: 0.346280; batch adversarial loss: 0.433528\n",
      "epoch 136; iter: 0; batch classifier loss: 0.377675; batch adversarial loss: 0.572151\n",
      "epoch 137; iter: 0; batch classifier loss: 0.339214; batch adversarial loss: 0.497974\n",
      "epoch 138; iter: 0; batch classifier loss: 0.414370; batch adversarial loss: 0.572660\n",
      "epoch 139; iter: 0; batch classifier loss: 0.337660; batch adversarial loss: 0.544087\n",
      "epoch 140; iter: 0; batch classifier loss: 0.450141; batch adversarial loss: 0.618689\n",
      "epoch 141; iter: 0; batch classifier loss: 0.345764; batch adversarial loss: 0.535084\n",
      "epoch 142; iter: 0; batch classifier loss: 0.360607; batch adversarial loss: 0.507128\n",
      "epoch 143; iter: 0; batch classifier loss: 0.401876; batch adversarial loss: 0.563683\n",
      "epoch 144; iter: 0; batch classifier loss: 0.444330; batch adversarial loss: 0.599188\n",
      "epoch 145; iter: 0; batch classifier loss: 0.382371; batch adversarial loss: 0.515108\n",
      "epoch 146; iter: 0; batch classifier loss: 0.420459; batch adversarial loss: 0.553668\n",
      "epoch 147; iter: 0; batch classifier loss: 0.376518; batch adversarial loss: 0.627666\n",
      "epoch 148; iter: 0; batch classifier loss: 0.374141; batch adversarial loss: 0.480688\n",
      "epoch 149; iter: 0; batch classifier loss: 0.286592; batch adversarial loss: 0.561847\n",
      "epoch 150; iter: 0; batch classifier loss: 0.440245; batch adversarial loss: 0.441074\n",
      "epoch 151; iter: 0; batch classifier loss: 0.355624; batch adversarial loss: 0.638311\n",
      "epoch 152; iter: 0; batch classifier loss: 0.419441; batch adversarial loss: 0.554970\n",
      "epoch 153; iter: 0; batch classifier loss: 0.383371; batch adversarial loss: 0.583006\n",
      "epoch 154; iter: 0; batch classifier loss: 0.340154; batch adversarial loss: 0.574817\n",
      "epoch 155; iter: 0; batch classifier loss: 0.323493; batch adversarial loss: 0.525313\n",
      "epoch 156; iter: 0; batch classifier loss: 0.403366; batch adversarial loss: 0.515888\n",
      "epoch 157; iter: 0; batch classifier loss: 0.368073; batch adversarial loss: 0.452138\n",
      "epoch 158; iter: 0; batch classifier loss: 0.321759; batch adversarial loss: 0.469613\n",
      "epoch 159; iter: 0; batch classifier loss: 0.345247; batch adversarial loss: 0.488541\n",
      "epoch 160; iter: 0; batch classifier loss: 0.370459; batch adversarial loss: 0.552761\n",
      "epoch 161; iter: 0; batch classifier loss: 0.331914; batch adversarial loss: 0.489078\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 162; iter: 0; batch classifier loss: 0.363006; batch adversarial loss: 0.514778\n",
      "epoch 163; iter: 0; batch classifier loss: 0.361875; batch adversarial loss: 0.508677\n",
      "epoch 164; iter: 0; batch classifier loss: 0.385485; batch adversarial loss: 0.617264\n",
      "epoch 165; iter: 0; batch classifier loss: 0.343981; batch adversarial loss: 0.498015\n",
      "epoch 166; iter: 0; batch classifier loss: 0.436146; batch adversarial loss: 0.505367\n",
      "epoch 167; iter: 0; batch classifier loss: 0.323437; batch adversarial loss: 0.537063\n",
      "epoch 168; iter: 0; batch classifier loss: 0.344576; batch adversarial loss: 0.547632\n",
      "epoch 169; iter: 0; batch classifier loss: 0.448616; batch adversarial loss: 0.574885\n",
      "epoch 170; iter: 0; batch classifier loss: 0.408287; batch adversarial loss: 0.536244\n",
      "epoch 171; iter: 0; batch classifier loss: 0.395886; batch adversarial loss: 0.582084\n",
      "epoch 172; iter: 0; batch classifier loss: 0.391217; batch adversarial loss: 0.516479\n",
      "epoch 173; iter: 0; batch classifier loss: 0.443911; batch adversarial loss: 0.563419\n",
      "epoch 174; iter: 0; batch classifier loss: 0.350329; batch adversarial loss: 0.571173\n",
      "epoch 175; iter: 0; batch classifier loss: 0.365024; batch adversarial loss: 0.544981\n",
      "epoch 176; iter: 0; batch classifier loss: 0.356670; batch adversarial loss: 0.471061\n",
      "epoch 177; iter: 0; batch classifier loss: 0.357999; batch adversarial loss: 0.599134\n",
      "epoch 178; iter: 0; batch classifier loss: 0.417565; batch adversarial loss: 0.599744\n",
      "epoch 179; iter: 0; batch classifier loss: 0.368105; batch adversarial loss: 0.535110\n",
      "epoch 180; iter: 0; batch classifier loss: 0.330181; batch adversarial loss: 0.525334\n",
      "epoch 181; iter: 0; batch classifier loss: 0.328402; batch adversarial loss: 0.599661\n",
      "epoch 182; iter: 0; batch classifier loss: 0.338788; batch adversarial loss: 0.516865\n",
      "epoch 183; iter: 0; batch classifier loss: 0.325072; batch adversarial loss: 0.563146\n",
      "epoch 184; iter: 0; batch classifier loss: 0.324867; batch adversarial loss: 0.581145\n",
      "epoch 185; iter: 0; batch classifier loss: 0.370594; batch adversarial loss: 0.469502\n",
      "epoch 186; iter: 0; batch classifier loss: 0.348217; batch adversarial loss: 0.552918\n",
      "epoch 187; iter: 0; batch classifier loss: 0.397962; batch adversarial loss: 0.609759\n",
      "epoch 188; iter: 0; batch classifier loss: 0.379856; batch adversarial loss: 0.504384\n",
      "epoch 189; iter: 0; batch classifier loss: 0.452936; batch adversarial loss: 0.571485\n",
      "epoch 190; iter: 0; batch classifier loss: 0.407047; batch adversarial loss: 0.630814\n",
      "epoch 191; iter: 0; batch classifier loss: 0.440165; batch adversarial loss: 0.506739\n",
      "epoch 192; iter: 0; batch classifier loss: 0.371857; batch adversarial loss: 0.581351\n",
      "epoch 193; iter: 0; batch classifier loss: 0.385958; batch adversarial loss: 0.516837\n",
      "epoch 194; iter: 0; batch classifier loss: 0.352022; batch adversarial loss: 0.545498\n",
      "epoch 195; iter: 0; batch classifier loss: 0.297286; batch adversarial loss: 0.497963\n",
      "epoch 196; iter: 0; batch classifier loss: 0.284346; batch adversarial loss: 0.488753\n",
      "epoch 197; iter: 0; batch classifier loss: 0.321951; batch adversarial loss: 0.507347\n",
      "epoch 198; iter: 0; batch classifier loss: 0.354788; batch adversarial loss: 0.588726\n",
      "epoch 199; iter: 0; batch classifier loss: 0.388219; batch adversarial loss: 0.544654\n",
      "epoch 0; iter: 0; batch classifier loss: 0.669548; batch adversarial loss: 0.700448\n",
      "epoch 1; iter: 0; batch classifier loss: 0.578941; batch adversarial loss: 0.676511\n",
      "epoch 2; iter: 0; batch classifier loss: 0.571978; batch adversarial loss: 0.647148\n",
      "epoch 3; iter: 0; batch classifier loss: 0.572788; batch adversarial loss: 0.624535\n",
      "epoch 4; iter: 0; batch classifier loss: 0.618673; batch adversarial loss: 0.632965\n",
      "epoch 5; iter: 0; batch classifier loss: 0.532944; batch adversarial loss: 0.617361\n",
      "epoch 6; iter: 0; batch classifier loss: 0.531717; batch adversarial loss: 0.653203\n",
      "epoch 7; iter: 0; batch classifier loss: 0.531475; batch adversarial loss: 0.647750\n",
      "epoch 8; iter: 0; batch classifier loss: 0.558242; batch adversarial loss: 0.601195\n",
      "epoch 9; iter: 0; batch classifier loss: 0.460726; batch adversarial loss: 0.577401\n",
      "epoch 10; iter: 0; batch classifier loss: 0.589879; batch adversarial loss: 0.618672\n",
      "epoch 11; iter: 0; batch classifier loss: 0.533664; batch adversarial loss: 0.590155\n",
      "epoch 12; iter: 0; batch classifier loss: 0.553242; batch adversarial loss: 0.571372\n",
      "epoch 13; iter: 0; batch classifier loss: 0.550433; batch adversarial loss: 0.605614\n",
      "epoch 14; iter: 0; batch classifier loss: 0.563773; batch adversarial loss: 0.582747\n",
      "epoch 15; iter: 0; batch classifier loss: 0.566593; batch adversarial loss: 0.585821\n",
      "epoch 16; iter: 0; batch classifier loss: 0.503744; batch adversarial loss: 0.603037\n",
      "epoch 17; iter: 0; batch classifier loss: 0.496492; batch adversarial loss: 0.559137\n",
      "epoch 18; iter: 0; batch classifier loss: 0.480139; batch adversarial loss: 0.516430\n",
      "epoch 19; iter: 0; batch classifier loss: 0.544517; batch adversarial loss: 0.546770\n",
      "epoch 20; iter: 0; batch classifier loss: 0.580011; batch adversarial loss: 0.595114\n",
      "epoch 21; iter: 0; batch classifier loss: 0.433584; batch adversarial loss: 0.574848\n",
      "epoch 22; iter: 0; batch classifier loss: 0.515276; batch adversarial loss: 0.573614\n",
      "epoch 23; iter: 0; batch classifier loss: 0.439040; batch adversarial loss: 0.558786\n",
      "epoch 24; iter: 0; batch classifier loss: 0.493855; batch adversarial loss: 0.647346\n",
      "epoch 25; iter: 0; batch classifier loss: 0.436983; batch adversarial loss: 0.549055\n",
      "epoch 26; iter: 0; batch classifier loss: 0.492752; batch adversarial loss: 0.609841\n",
      "epoch 27; iter: 0; batch classifier loss: 0.476565; batch adversarial loss: 0.521597\n",
      "epoch 28; iter: 0; batch classifier loss: 0.463020; batch adversarial loss: 0.555078\n",
      "epoch 29; iter: 0; batch classifier loss: 0.453596; batch adversarial loss: 0.514496\n",
      "epoch 30; iter: 0; batch classifier loss: 0.473428; batch adversarial loss: 0.578534\n",
      "epoch 31; iter: 0; batch classifier loss: 0.531735; batch adversarial loss: 0.545886\n",
      "epoch 32; iter: 0; batch classifier loss: 0.481234; batch adversarial loss: 0.563097\n",
      "epoch 33; iter: 0; batch classifier loss: 0.462991; batch adversarial loss: 0.511429\n",
      "epoch 34; iter: 0; batch classifier loss: 0.485311; batch adversarial loss: 0.571754\n",
      "epoch 35; iter: 0; batch classifier loss: 0.520540; batch adversarial loss: 0.613453\n",
      "epoch 36; iter: 0; batch classifier loss: 0.500373; batch adversarial loss: 0.544752\n",
      "epoch 37; iter: 0; batch classifier loss: 0.518922; batch adversarial loss: 0.621328\n",
      "epoch 38; iter: 0; batch classifier loss: 0.434616; batch adversarial loss: 0.502620\n",
      "epoch 39; iter: 0; batch classifier loss: 0.373763; batch adversarial loss: 0.494336\n",
      "epoch 40; iter: 0; batch classifier loss: 0.418190; batch adversarial loss: 0.511054\n",
      "epoch 41; iter: 0; batch classifier loss: 0.504307; batch adversarial loss: 0.536610\n",
      "epoch 42; iter: 0; batch classifier loss: 0.498745; batch adversarial loss: 0.569380\n",
      "epoch 43; iter: 0; batch classifier loss: 0.451779; batch adversarial loss: 0.519712\n",
      "epoch 44; iter: 0; batch classifier loss: 0.484426; batch adversarial loss: 0.595572\n",
      "epoch 45; iter: 0; batch classifier loss: 0.412850; batch adversarial loss: 0.596850\n",
      "epoch 46; iter: 0; batch classifier loss: 0.382716; batch adversarial loss: 0.563790\n",
      "epoch 47; iter: 0; batch classifier loss: 0.479550; batch adversarial loss: 0.597247\n",
      "epoch 48; iter: 0; batch classifier loss: 0.465409; batch adversarial loss: 0.537167\n",
      "epoch 49; iter: 0; batch classifier loss: 0.503528; batch adversarial loss: 0.589354\n",
      "epoch 50; iter: 0; batch classifier loss: 0.413906; batch adversarial loss: 0.500479\n",
      "epoch 51; iter: 0; batch classifier loss: 0.415018; batch adversarial loss: 0.589164\n",
      "epoch 52; iter: 0; batch classifier loss: 0.410022; batch adversarial loss: 0.499891\n",
      "epoch 53; iter: 0; batch classifier loss: 0.405273; batch adversarial loss: 0.624711\n",
      "epoch 54; iter: 0; batch classifier loss: 0.501122; batch adversarial loss: 0.589967\n",
      "epoch 55; iter: 0; batch classifier loss: 0.315898; batch adversarial loss: 0.553775\n",
      "epoch 56; iter: 0; batch classifier loss: 0.485347; batch adversarial loss: 0.545206\n",
      "epoch 57; iter: 0; batch classifier loss: 0.391305; batch adversarial loss: 0.588928\n",
      "epoch 58; iter: 0; batch classifier loss: 0.454714; batch adversarial loss: 0.552960\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 59; iter: 0; batch classifier loss: 0.469795; batch adversarial loss: 0.605886\n",
      "epoch 60; iter: 0; batch classifier loss: 0.403556; batch adversarial loss: 0.554595\n",
      "epoch 61; iter: 0; batch classifier loss: 0.394166; batch adversarial loss: 0.526392\n",
      "epoch 62; iter: 0; batch classifier loss: 0.435826; batch adversarial loss: 0.579252\n",
      "epoch 63; iter: 0; batch classifier loss: 0.406009; batch adversarial loss: 0.491142\n",
      "epoch 64; iter: 0; batch classifier loss: 0.428532; batch adversarial loss: 0.562710\n",
      "epoch 65; iter: 0; batch classifier loss: 0.419255; batch adversarial loss: 0.595379\n",
      "epoch 66; iter: 0; batch classifier loss: 0.447490; batch adversarial loss: 0.597974\n",
      "epoch 67; iter: 0; batch classifier loss: 0.381152; batch adversarial loss: 0.606436\n",
      "epoch 68; iter: 0; batch classifier loss: 0.388260; batch adversarial loss: 0.552343\n",
      "epoch 69; iter: 0; batch classifier loss: 0.469263; batch adversarial loss: 0.578151\n",
      "epoch 70; iter: 0; batch classifier loss: 0.506240; batch adversarial loss: 0.563393\n",
      "epoch 71; iter: 0; batch classifier loss: 0.378423; batch adversarial loss: 0.535347\n",
      "epoch 72; iter: 0; batch classifier loss: 0.411665; batch adversarial loss: 0.617493\n",
      "epoch 73; iter: 0; batch classifier loss: 0.393360; batch adversarial loss: 0.535790\n",
      "epoch 74; iter: 0; batch classifier loss: 0.409544; batch adversarial loss: 0.518291\n",
      "epoch 75; iter: 0; batch classifier loss: 0.399501; batch adversarial loss: 0.624583\n",
      "epoch 76; iter: 0; batch classifier loss: 0.412805; batch adversarial loss: 0.615541\n",
      "epoch 77; iter: 0; batch classifier loss: 0.414175; batch adversarial loss: 0.491626\n",
      "epoch 78; iter: 0; batch classifier loss: 0.358373; batch adversarial loss: 0.562587\n",
      "epoch 79; iter: 0; batch classifier loss: 0.354232; batch adversarial loss: 0.500898\n",
      "epoch 80; iter: 0; batch classifier loss: 0.436186; batch adversarial loss: 0.535916\n",
      "epoch 81; iter: 0; batch classifier loss: 0.422937; batch adversarial loss: 0.639647\n",
      "epoch 82; iter: 0; batch classifier loss: 0.302032; batch adversarial loss: 0.528024\n",
      "epoch 83; iter: 0; batch classifier loss: 0.402177; batch adversarial loss: 0.501497\n",
      "epoch 84; iter: 0; batch classifier loss: 0.433709; batch adversarial loss: 0.579901\n",
      "epoch 85; iter: 0; batch classifier loss: 0.478568; batch adversarial loss: 0.545587\n",
      "epoch 86; iter: 0; batch classifier loss: 0.459308; batch adversarial loss: 0.545663\n",
      "epoch 87; iter: 0; batch classifier loss: 0.374684; batch adversarial loss: 0.571471\n",
      "epoch 88; iter: 0; batch classifier loss: 0.399007; batch adversarial loss: 0.571844\n",
      "epoch 89; iter: 0; batch classifier loss: 0.390424; batch adversarial loss: 0.482248\n",
      "epoch 90; iter: 0; batch classifier loss: 0.376270; batch adversarial loss: 0.563158\n",
      "epoch 91; iter: 0; batch classifier loss: 0.420659; batch adversarial loss: 0.561385\n",
      "epoch 92; iter: 0; batch classifier loss: 0.452221; batch adversarial loss: 0.508510\n",
      "epoch 93; iter: 0; batch classifier loss: 0.432204; batch adversarial loss: 0.640006\n",
      "epoch 94; iter: 0; batch classifier loss: 0.372221; batch adversarial loss: 0.606357\n",
      "epoch 95; iter: 0; batch classifier loss: 0.392975; batch adversarial loss: 0.632679\n",
      "epoch 96; iter: 0; batch classifier loss: 0.364707; batch adversarial loss: 0.526614\n",
      "epoch 97; iter: 0; batch classifier loss: 0.377588; batch adversarial loss: 0.546609\n",
      "epoch 98; iter: 0; batch classifier loss: 0.406925; batch adversarial loss: 0.526183\n",
      "epoch 99; iter: 0; batch classifier loss: 0.346383; batch adversarial loss: 0.499836\n",
      "epoch 100; iter: 0; batch classifier loss: 0.359550; batch adversarial loss: 0.597359\n",
      "epoch 101; iter: 0; batch classifier loss: 0.428134; batch adversarial loss: 0.554400\n",
      "epoch 102; iter: 0; batch classifier loss: 0.441403; batch adversarial loss: 0.572317\n",
      "epoch 103; iter: 0; batch classifier loss: 0.412208; batch adversarial loss: 0.572274\n",
      "epoch 104; iter: 0; batch classifier loss: 0.303938; batch adversarial loss: 0.562815\n",
      "epoch 105; iter: 0; batch classifier loss: 0.396304; batch adversarial loss: 0.606063\n",
      "epoch 106; iter: 0; batch classifier loss: 0.323797; batch adversarial loss: 0.596582\n",
      "epoch 107; iter: 0; batch classifier loss: 0.352412; batch adversarial loss: 0.528503\n",
      "epoch 108; iter: 0; batch classifier loss: 0.364189; batch adversarial loss: 0.563207\n",
      "epoch 109; iter: 0; batch classifier loss: 0.382845; batch adversarial loss: 0.685830\n",
      "epoch 110; iter: 0; batch classifier loss: 0.319553; batch adversarial loss: 0.621665\n",
      "epoch 111; iter: 0; batch classifier loss: 0.408973; batch adversarial loss: 0.537812\n",
      "epoch 112; iter: 0; batch classifier loss: 0.339414; batch adversarial loss: 0.598698\n",
      "epoch 113; iter: 0; batch classifier loss: 0.354164; batch adversarial loss: 0.660212\n",
      "epoch 114; iter: 0; batch classifier loss: 0.466137; batch adversarial loss: 0.473138\n",
      "epoch 115; iter: 0; batch classifier loss: 0.316832; batch adversarial loss: 0.587723\n",
      "epoch 116; iter: 0; batch classifier loss: 0.438047; batch adversarial loss: 0.580335\n",
      "epoch 117; iter: 0; batch classifier loss: 0.370611; batch adversarial loss: 0.553536\n",
      "epoch 118; iter: 0; batch classifier loss: 0.438105; batch adversarial loss: 0.516928\n",
      "epoch 119; iter: 0; batch classifier loss: 0.425008; batch adversarial loss: 0.535212\n",
      "epoch 120; iter: 0; batch classifier loss: 0.423462; batch adversarial loss: 0.561875\n",
      "epoch 121; iter: 0; batch classifier loss: 0.346063; batch adversarial loss: 0.622756\n",
      "epoch 122; iter: 0; batch classifier loss: 0.391241; batch adversarial loss: 0.560753\n",
      "epoch 123; iter: 0; batch classifier loss: 0.430513; batch adversarial loss: 0.656607\n",
      "epoch 124; iter: 0; batch classifier loss: 0.405264; batch adversarial loss: 0.571647\n",
      "epoch 125; iter: 0; batch classifier loss: 0.398285; batch adversarial loss: 0.508168\n",
      "epoch 126; iter: 0; batch classifier loss: 0.367186; batch adversarial loss: 0.599317\n",
      "epoch 127; iter: 0; batch classifier loss: 0.413752; batch adversarial loss: 0.578981\n",
      "epoch 128; iter: 0; batch classifier loss: 0.373658; batch adversarial loss: 0.642515\n",
      "epoch 129; iter: 0; batch classifier loss: 0.395858; batch adversarial loss: 0.642369\n",
      "epoch 130; iter: 0; batch classifier loss: 0.333371; batch adversarial loss: 0.534046\n",
      "epoch 131; iter: 0; batch classifier loss: 0.406525; batch adversarial loss: 0.553594\n",
      "epoch 132; iter: 0; batch classifier loss: 0.381060; batch adversarial loss: 0.525880\n",
      "epoch 133; iter: 0; batch classifier loss: 0.346673; batch adversarial loss: 0.606221\n",
      "epoch 134; iter: 0; batch classifier loss: 0.388922; batch adversarial loss: 0.537633\n",
      "epoch 135; iter: 0; batch classifier loss: 0.407472; batch adversarial loss: 0.553722\n",
      "epoch 136; iter: 0; batch classifier loss: 0.396753; batch adversarial loss: 0.508346\n",
      "epoch 137; iter: 0; batch classifier loss: 0.454146; batch adversarial loss: 0.596812\n",
      "epoch 138; iter: 0; batch classifier loss: 0.368562; batch adversarial loss: 0.527725\n",
      "epoch 139; iter: 0; batch classifier loss: 0.411398; batch adversarial loss: 0.553389\n",
      "epoch 140; iter: 0; batch classifier loss: 0.437606; batch adversarial loss: 0.590315\n",
      "epoch 141; iter: 0; batch classifier loss: 0.395663; batch adversarial loss: 0.525611\n",
      "epoch 142; iter: 0; batch classifier loss: 0.367219; batch adversarial loss: 0.554789\n",
      "epoch 143; iter: 0; batch classifier loss: 0.441556; batch adversarial loss: 0.491335\n",
      "epoch 144; iter: 0; batch classifier loss: 0.421056; batch adversarial loss: 0.497853\n",
      "epoch 145; iter: 0; batch classifier loss: 0.373503; batch adversarial loss: 0.518672\n",
      "epoch 146; iter: 0; batch classifier loss: 0.384341; batch adversarial loss: 0.586960\n",
      "epoch 147; iter: 0; batch classifier loss: 0.407795; batch adversarial loss: 0.480804\n",
      "epoch 148; iter: 0; batch classifier loss: 0.310801; batch adversarial loss: 0.518862\n",
      "epoch 149; iter: 0; batch classifier loss: 0.286440; batch adversarial loss: 0.552520\n",
      "epoch 150; iter: 0; batch classifier loss: 0.376309; batch adversarial loss: 0.578333\n",
      "epoch 151; iter: 0; batch classifier loss: 0.344447; batch adversarial loss: 0.545360\n",
      "epoch 152; iter: 0; batch classifier loss: 0.330067; batch adversarial loss: 0.592219\n",
      "epoch 153; iter: 0; batch classifier loss: 0.342517; batch adversarial loss: 0.510267\n",
      "epoch 154; iter: 0; batch classifier loss: 0.425348; batch adversarial loss: 0.553336\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 155; iter: 0; batch classifier loss: 0.415835; batch adversarial loss: 0.552891\n",
      "epoch 156; iter: 0; batch classifier loss: 0.346853; batch adversarial loss: 0.535969\n",
      "epoch 157; iter: 0; batch classifier loss: 0.468752; batch adversarial loss: 0.536543\n",
      "epoch 158; iter: 0; batch classifier loss: 0.395669; batch adversarial loss: 0.543774\n",
      "epoch 159; iter: 0; batch classifier loss: 0.363714; batch adversarial loss: 0.635236\n",
      "epoch 160; iter: 0; batch classifier loss: 0.357460; batch adversarial loss: 0.572841\n",
      "epoch 161; iter: 0; batch classifier loss: 0.376458; batch adversarial loss: 0.553097\n",
      "epoch 162; iter: 0; batch classifier loss: 0.393074; batch adversarial loss: 0.493683\n",
      "epoch 163; iter: 0; batch classifier loss: 0.352713; batch adversarial loss: 0.588884\n",
      "epoch 164; iter: 0; batch classifier loss: 0.417861; batch adversarial loss: 0.534663\n",
      "epoch 165; iter: 0; batch classifier loss: 0.316228; batch adversarial loss: 0.571130\n",
      "epoch 166; iter: 0; batch classifier loss: 0.394708; batch adversarial loss: 0.586645\n",
      "epoch 167; iter: 0; batch classifier loss: 0.425582; batch adversarial loss: 0.615002\n",
      "epoch 168; iter: 0; batch classifier loss: 0.344468; batch adversarial loss: 0.482365\n",
      "epoch 169; iter: 0; batch classifier loss: 0.395550; batch adversarial loss: 0.500998\n",
      "epoch 170; iter: 0; batch classifier loss: 0.337359; batch adversarial loss: 0.465198\n",
      "epoch 171; iter: 0; batch classifier loss: 0.333865; batch adversarial loss: 0.581269\n",
      "epoch 172; iter: 0; batch classifier loss: 0.346727; batch adversarial loss: 0.554557\n",
      "epoch 173; iter: 0; batch classifier loss: 0.367725; batch adversarial loss: 0.544144\n",
      "epoch 174; iter: 0; batch classifier loss: 0.317015; batch adversarial loss: 0.479887\n",
      "epoch 175; iter: 0; batch classifier loss: 0.447627; batch adversarial loss: 0.572252\n",
      "epoch 176; iter: 0; batch classifier loss: 0.385691; batch adversarial loss: 0.641515\n",
      "epoch 177; iter: 0; batch classifier loss: 0.336485; batch adversarial loss: 0.555140\n",
      "epoch 178; iter: 0; batch classifier loss: 0.396858; batch adversarial loss: 0.594549\n",
      "epoch 179; iter: 0; batch classifier loss: 0.366351; batch adversarial loss: 0.466951\n",
      "epoch 180; iter: 0; batch classifier loss: 0.421626; batch adversarial loss: 0.500427\n",
      "epoch 181; iter: 0; batch classifier loss: 0.445444; batch adversarial loss: 0.545177\n",
      "epoch 182; iter: 0; batch classifier loss: 0.376430; batch adversarial loss: 0.594377\n",
      "epoch 183; iter: 0; batch classifier loss: 0.323077; batch adversarial loss: 0.545105\n",
      "epoch 184; iter: 0; batch classifier loss: 0.348921; batch adversarial loss: 0.490520\n",
      "epoch 185; iter: 0; batch classifier loss: 0.365234; batch adversarial loss: 0.507847\n",
      "epoch 186; iter: 0; batch classifier loss: 0.355385; batch adversarial loss: 0.536553\n",
      "epoch 187; iter: 0; batch classifier loss: 0.428665; batch adversarial loss: 0.545469\n",
      "epoch 188; iter: 0; batch classifier loss: 0.376344; batch adversarial loss: 0.535532\n",
      "epoch 189; iter: 0; batch classifier loss: 0.475629; batch adversarial loss: 0.580697\n",
      "epoch 190; iter: 0; batch classifier loss: 0.338545; batch adversarial loss: 0.545795\n",
      "epoch 191; iter: 0; batch classifier loss: 0.422496; batch adversarial loss: 0.579666\n",
      "epoch 192; iter: 0; batch classifier loss: 0.396205; batch adversarial loss: 0.596951\n",
      "epoch 193; iter: 0; batch classifier loss: 0.294701; batch adversarial loss: 0.527002\n",
      "epoch 194; iter: 0; batch classifier loss: 0.398537; batch adversarial loss: 0.582364\n",
      "epoch 195; iter: 0; batch classifier loss: 0.385667; batch adversarial loss: 0.589878\n",
      "epoch 196; iter: 0; batch classifier loss: 0.317878; batch adversarial loss: 0.501098\n",
      "epoch 197; iter: 0; batch classifier loss: 0.323784; batch adversarial loss: 0.508595\n",
      "epoch 198; iter: 0; batch classifier loss: 0.323592; batch adversarial loss: 0.563944\n",
      "epoch 199; iter: 0; batch classifier loss: 0.379651; batch adversarial loss: 0.545002\n",
      "epoch 0; iter: 0; batch classifier loss: 0.706020; batch adversarial loss: 0.667848\n",
      "epoch 1; iter: 0; batch classifier loss: 0.633352; batch adversarial loss: 0.641427\n",
      "epoch 2; iter: 0; batch classifier loss: 0.612526; batch adversarial loss: 0.627180\n",
      "epoch 3; iter: 0; batch classifier loss: 0.525801; batch adversarial loss: 0.612681\n",
      "epoch 4; iter: 0; batch classifier loss: 0.629539; batch adversarial loss: 0.593645\n",
      "epoch 5; iter: 0; batch classifier loss: 0.580312; batch adversarial loss: 0.607766\n",
      "epoch 6; iter: 0; batch classifier loss: 0.539276; batch adversarial loss: 0.597081\n",
      "epoch 7; iter: 0; batch classifier loss: 0.529378; batch adversarial loss: 0.602992\n",
      "epoch 8; iter: 0; batch classifier loss: 0.564172; batch adversarial loss: 0.628690\n",
      "epoch 9; iter: 0; batch classifier loss: 0.608428; batch adversarial loss: 0.587748\n",
      "epoch 10; iter: 0; batch classifier loss: 0.546491; batch adversarial loss: 0.549952\n",
      "epoch 11; iter: 0; batch classifier loss: 0.516217; batch adversarial loss: 0.617330\n",
      "epoch 12; iter: 0; batch classifier loss: 0.585141; batch adversarial loss: 0.522223\n",
      "epoch 13; iter: 0; batch classifier loss: 0.501231; batch adversarial loss: 0.615318\n",
      "epoch 14; iter: 0; batch classifier loss: 0.539863; batch adversarial loss: 0.533611\n",
      "epoch 15; iter: 0; batch classifier loss: 0.558982; batch adversarial loss: 0.584037\n",
      "epoch 16; iter: 0; batch classifier loss: 0.518244; batch adversarial loss: 0.621889\n",
      "epoch 17; iter: 0; batch classifier loss: 0.619497; batch adversarial loss: 0.564973\n",
      "epoch 18; iter: 0; batch classifier loss: 0.496041; batch adversarial loss: 0.576687\n",
      "epoch 19; iter: 0; batch classifier loss: 0.415093; batch adversarial loss: 0.587406\n",
      "epoch 20; iter: 0; batch classifier loss: 0.501694; batch adversarial loss: 0.503166\n",
      "epoch 21; iter: 0; batch classifier loss: 0.604793; batch adversarial loss: 0.524384\n",
      "epoch 22; iter: 0; batch classifier loss: 0.468402; batch adversarial loss: 0.565696\n",
      "epoch 23; iter: 0; batch classifier loss: 0.484242; batch adversarial loss: 0.564026\n",
      "epoch 24; iter: 0; batch classifier loss: 0.458748; batch adversarial loss: 0.556100\n",
      "epoch 25; iter: 0; batch classifier loss: 0.518495; batch adversarial loss: 0.498844\n",
      "epoch 26; iter: 0; batch classifier loss: 0.543636; batch adversarial loss: 0.554771\n",
      "epoch 27; iter: 0; batch classifier loss: 0.428389; batch adversarial loss: 0.553918\n",
      "epoch 28; iter: 0; batch classifier loss: 0.492371; batch adversarial loss: 0.553916\n",
      "epoch 29; iter: 0; batch classifier loss: 0.389836; batch adversarial loss: 0.562251\n",
      "epoch 30; iter: 0; batch classifier loss: 0.426426; batch adversarial loss: 0.554147\n",
      "epoch 31; iter: 0; batch classifier loss: 0.515705; batch adversarial loss: 0.587710\n",
      "epoch 32; iter: 0; batch classifier loss: 0.396463; batch adversarial loss: 0.526855\n",
      "epoch 33; iter: 0; batch classifier loss: 0.466339; batch adversarial loss: 0.581153\n",
      "epoch 34; iter: 0; batch classifier loss: 0.476845; batch adversarial loss: 0.580099\n",
      "epoch 35; iter: 0; batch classifier loss: 0.483946; batch adversarial loss: 0.572165\n",
      "epoch 36; iter: 0; batch classifier loss: 0.444918; batch adversarial loss: 0.535671\n",
      "epoch 37; iter: 0; batch classifier loss: 0.387850; batch adversarial loss: 0.499334\n",
      "epoch 38; iter: 0; batch classifier loss: 0.403534; batch adversarial loss: 0.535463\n",
      "epoch 39; iter: 0; batch classifier loss: 0.474977; batch adversarial loss: 0.544642\n",
      "epoch 40; iter: 0; batch classifier loss: 0.421539; batch adversarial loss: 0.489927\n",
      "epoch 41; iter: 0; batch classifier loss: 0.486266; batch adversarial loss: 0.581221\n",
      "epoch 42; iter: 0; batch classifier loss: 0.523116; batch adversarial loss: 0.461851\n",
      "epoch 43; iter: 0; batch classifier loss: 0.391839; batch adversarial loss: 0.535061\n",
      "epoch 44; iter: 0; batch classifier loss: 0.382251; batch adversarial loss: 0.545015\n",
      "epoch 45; iter: 0; batch classifier loss: 0.434226; batch adversarial loss: 0.553382\n",
      "epoch 46; iter: 0; batch classifier loss: 0.416507; batch adversarial loss: 0.481142\n",
      "epoch 47; iter: 0; batch classifier loss: 0.496845; batch adversarial loss: 0.590645\n",
      "epoch 48; iter: 0; batch classifier loss: 0.439786; batch adversarial loss: 0.460573\n",
      "epoch 49; iter: 0; batch classifier loss: 0.427272; batch adversarial loss: 0.489295\n",
      "epoch 50; iter: 0; batch classifier loss: 0.408249; batch adversarial loss: 0.525969\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 51; iter: 0; batch classifier loss: 0.417888; batch adversarial loss: 0.591806\n",
      "epoch 52; iter: 0; batch classifier loss: 0.381831; batch adversarial loss: 0.581335\n",
      "epoch 53; iter: 0; batch classifier loss: 0.497116; batch adversarial loss: 0.508799\n",
      "epoch 54; iter: 0; batch classifier loss: 0.446228; batch adversarial loss: 0.618125\n",
      "epoch 55; iter: 0; batch classifier loss: 0.410900; batch adversarial loss: 0.535888\n",
      "epoch 56; iter: 0; batch classifier loss: 0.392770; batch adversarial loss: 0.554864\n",
      "epoch 57; iter: 0; batch classifier loss: 0.422518; batch adversarial loss: 0.470810\n",
      "epoch 58; iter: 0; batch classifier loss: 0.314142; batch adversarial loss: 0.536142\n",
      "epoch 59; iter: 0; batch classifier loss: 0.422155; batch adversarial loss: 0.590776\n",
      "epoch 60; iter: 0; batch classifier loss: 0.410480; batch adversarial loss: 0.564736\n",
      "epoch 61; iter: 0; batch classifier loss: 0.464143; batch adversarial loss: 0.544211\n",
      "epoch 62; iter: 0; batch classifier loss: 0.417652; batch adversarial loss: 0.536770\n",
      "epoch 63; iter: 0; batch classifier loss: 0.390452; batch adversarial loss: 0.543388\n",
      "epoch 64; iter: 0; batch classifier loss: 0.386393; batch adversarial loss: 0.544012\n",
      "epoch 65; iter: 0; batch classifier loss: 0.478521; batch adversarial loss: 0.525219\n",
      "epoch 66; iter: 0; batch classifier loss: 0.489516; batch adversarial loss: 0.580514\n",
      "epoch 67; iter: 0; batch classifier loss: 0.392728; batch adversarial loss: 0.551682\n",
      "epoch 68; iter: 0; batch classifier loss: 0.423483; batch adversarial loss: 0.460048\n",
      "epoch 69; iter: 0; batch classifier loss: 0.388910; batch adversarial loss: 0.536647\n",
      "epoch 70; iter: 0; batch classifier loss: 0.409810; batch adversarial loss: 0.544329\n",
      "epoch 71; iter: 0; batch classifier loss: 0.387072; batch adversarial loss: 0.480242\n",
      "epoch 72; iter: 0; batch classifier loss: 0.368760; batch adversarial loss: 0.496255\n",
      "epoch 73; iter: 0; batch classifier loss: 0.382807; batch adversarial loss: 0.507780\n",
      "epoch 74; iter: 0; batch classifier loss: 0.349121; batch adversarial loss: 0.611631\n",
      "epoch 75; iter: 0; batch classifier loss: 0.333806; batch adversarial loss: 0.555262\n",
      "epoch 76; iter: 0; batch classifier loss: 0.408790; batch adversarial loss: 0.533966\n",
      "epoch 77; iter: 0; batch classifier loss: 0.443221; batch adversarial loss: 0.527771\n",
      "epoch 78; iter: 0; batch classifier loss: 0.388143; batch adversarial loss: 0.552031\n",
      "epoch 79; iter: 0; batch classifier loss: 0.458957; batch adversarial loss: 0.489324\n",
      "epoch 80; iter: 0; batch classifier loss: 0.349901; batch adversarial loss: 0.525230\n",
      "epoch 81; iter: 0; batch classifier loss: 0.396141; batch adversarial loss: 0.611072\n",
      "epoch 82; iter: 0; batch classifier loss: 0.399580; batch adversarial loss: 0.536779\n",
      "epoch 83; iter: 0; batch classifier loss: 0.457590; batch adversarial loss: 0.611478\n",
      "epoch 84; iter: 0; batch classifier loss: 0.384971; batch adversarial loss: 0.565406\n",
      "epoch 85; iter: 0; batch classifier loss: 0.419596; batch adversarial loss: 0.536358\n",
      "epoch 86; iter: 0; batch classifier loss: 0.343426; batch adversarial loss: 0.535426\n",
      "epoch 87; iter: 0; batch classifier loss: 0.355516; batch adversarial loss: 0.528064\n",
      "epoch 88; iter: 0; batch classifier loss: 0.413661; batch adversarial loss: 0.470127\n",
      "epoch 89; iter: 0; batch classifier loss: 0.383045; batch adversarial loss: 0.574600\n",
      "epoch 90; iter: 0; batch classifier loss: 0.432989; batch adversarial loss: 0.573335\n",
      "epoch 91; iter: 0; batch classifier loss: 0.422647; batch adversarial loss: 0.534380\n",
      "epoch 92; iter: 0; batch classifier loss: 0.424800; batch adversarial loss: 0.488468\n",
      "epoch 93; iter: 0; batch classifier loss: 0.360704; batch adversarial loss: 0.564647\n",
      "epoch 94; iter: 0; batch classifier loss: 0.421411; batch adversarial loss: 0.461082\n",
      "epoch 95; iter: 0; batch classifier loss: 0.335589; batch adversarial loss: 0.647698\n",
      "epoch 96; iter: 0; batch classifier loss: 0.348237; batch adversarial loss: 0.554342\n",
      "epoch 97; iter: 0; batch classifier loss: 0.381011; batch adversarial loss: 0.403921\n",
      "epoch 98; iter: 0; batch classifier loss: 0.426831; batch adversarial loss: 0.581327\n",
      "epoch 99; iter: 0; batch classifier loss: 0.406035; batch adversarial loss: 0.407989\n",
      "epoch 100; iter: 0; batch classifier loss: 0.434336; batch adversarial loss: 0.620189\n",
      "epoch 101; iter: 0; batch classifier loss: 0.383816; batch adversarial loss: 0.541713\n",
      "epoch 102; iter: 0; batch classifier loss: 0.449253; batch adversarial loss: 0.525869\n",
      "epoch 103; iter: 0; batch classifier loss: 0.416994; batch adversarial loss: 0.565019\n",
      "epoch 104; iter: 0; batch classifier loss: 0.414675; batch adversarial loss: 0.638713\n",
      "epoch 105; iter: 0; batch classifier loss: 0.383237; batch adversarial loss: 0.512283\n",
      "epoch 106; iter: 0; batch classifier loss: 0.354358; batch adversarial loss: 0.533448\n",
      "epoch 107; iter: 0; batch classifier loss: 0.364469; batch adversarial loss: 0.525146\n",
      "epoch 108; iter: 0; batch classifier loss: 0.296311; batch adversarial loss: 0.500689\n",
      "epoch 109; iter: 0; batch classifier loss: 0.366091; batch adversarial loss: 0.666366\n",
      "epoch 110; iter: 0; batch classifier loss: 0.417016; batch adversarial loss: 0.556827\n",
      "epoch 111; iter: 0; batch classifier loss: 0.403702; batch adversarial loss: 0.546432\n",
      "epoch 112; iter: 0; batch classifier loss: 0.398455; batch adversarial loss: 0.506897\n",
      "epoch 113; iter: 0; batch classifier loss: 0.449201; batch adversarial loss: 0.496902\n",
      "epoch 114; iter: 0; batch classifier loss: 0.324347; batch adversarial loss: 0.471962\n",
      "epoch 115; iter: 0; batch classifier loss: 0.359643; batch adversarial loss: 0.619594\n",
      "epoch 116; iter: 0; batch classifier loss: 0.389825; batch adversarial loss: 0.536455\n",
      "epoch 117; iter: 0; batch classifier loss: 0.365830; batch adversarial loss: 0.563173\n",
      "epoch 118; iter: 0; batch classifier loss: 0.382191; batch adversarial loss: 0.548049\n",
      "epoch 119; iter: 0; batch classifier loss: 0.314327; batch adversarial loss: 0.541182\n",
      "epoch 120; iter: 0; batch classifier loss: 0.419760; batch adversarial loss: 0.575887\n",
      "epoch 121; iter: 0; batch classifier loss: 0.348460; batch adversarial loss: 0.552926\n",
      "epoch 122; iter: 0; batch classifier loss: 0.364595; batch adversarial loss: 0.597761\n",
      "epoch 123; iter: 0; batch classifier loss: 0.375454; batch adversarial loss: 0.588879\n",
      "epoch 124; iter: 0; batch classifier loss: 0.382760; batch adversarial loss: 0.564348\n",
      "epoch 125; iter: 0; batch classifier loss: 0.370977; batch adversarial loss: 0.548978\n",
      "epoch 126; iter: 0; batch classifier loss: 0.345368; batch adversarial loss: 0.563704\n",
      "epoch 127; iter: 0; batch classifier loss: 0.408731; batch adversarial loss: 0.546872\n",
      "epoch 128; iter: 0; batch classifier loss: 0.345955; batch adversarial loss: 0.543956\n",
      "epoch 129; iter: 0; batch classifier loss: 0.375520; batch adversarial loss: 0.607400\n",
      "epoch 130; iter: 0; batch classifier loss: 0.371359; batch adversarial loss: 0.523067\n",
      "epoch 131; iter: 0; batch classifier loss: 0.331227; batch adversarial loss: 0.496408\n",
      "epoch 132; iter: 0; batch classifier loss: 0.349391; batch adversarial loss: 0.498983\n",
      "epoch 133; iter: 0; batch classifier loss: 0.374020; batch adversarial loss: 0.637698\n",
      "epoch 134; iter: 0; batch classifier loss: 0.354266; batch adversarial loss: 0.553243\n",
      "epoch 135; iter: 0; batch classifier loss: 0.340589; batch adversarial loss: 0.552972\n",
      "epoch 136; iter: 0; batch classifier loss: 0.418918; batch adversarial loss: 0.553001\n",
      "epoch 137; iter: 0; batch classifier loss: 0.433492; batch adversarial loss: 0.580736\n",
      "epoch 138; iter: 0; batch classifier loss: 0.401362; batch adversarial loss: 0.533529\n",
      "epoch 139; iter: 0; batch classifier loss: 0.401167; batch adversarial loss: 0.581029\n",
      "epoch 140; iter: 0; batch classifier loss: 0.305703; batch adversarial loss: 0.513819\n",
      "epoch 141; iter: 0; batch classifier loss: 0.375557; batch adversarial loss: 0.516794\n",
      "epoch 142; iter: 0; batch classifier loss: 0.372840; batch adversarial loss: 0.621678\n",
      "epoch 143; iter: 0; batch classifier loss: 0.376754; batch adversarial loss: 0.607691\n",
      "epoch 144; iter: 0; batch classifier loss: 0.399855; batch adversarial loss: 0.508431\n",
      "epoch 145; iter: 0; batch classifier loss: 0.311017; batch adversarial loss: 0.589434\n",
      "epoch 146; iter: 0; batch classifier loss: 0.427531; batch adversarial loss: 0.553589\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 147; iter: 0; batch classifier loss: 0.378269; batch adversarial loss: 0.545584\n",
      "epoch 148; iter: 0; batch classifier loss: 0.405944; batch adversarial loss: 0.534801\n",
      "epoch 149; iter: 0; batch classifier loss: 0.458775; batch adversarial loss: 0.636804\n",
      "epoch 150; iter: 0; batch classifier loss: 0.353749; batch adversarial loss: 0.526764\n",
      "epoch 151; iter: 0; batch classifier loss: 0.335268; batch adversarial loss: 0.494833\n",
      "epoch 152; iter: 0; batch classifier loss: 0.296356; batch adversarial loss: 0.575064\n",
      "epoch 153; iter: 0; batch classifier loss: 0.399694; batch adversarial loss: 0.536983\n",
      "epoch 154; iter: 0; batch classifier loss: 0.299100; batch adversarial loss: 0.579968\n",
      "epoch 155; iter: 0; batch classifier loss: 0.350146; batch adversarial loss: 0.517034\n",
      "epoch 156; iter: 0; batch classifier loss: 0.402915; batch adversarial loss: 0.459206\n",
      "epoch 157; iter: 0; batch classifier loss: 0.286473; batch adversarial loss: 0.545007\n",
      "epoch 158; iter: 0; batch classifier loss: 0.355600; batch adversarial loss: 0.460513\n",
      "epoch 159; iter: 0; batch classifier loss: 0.361642; batch adversarial loss: 0.526078\n",
      "epoch 160; iter: 0; batch classifier loss: 0.353453; batch adversarial loss: 0.564652\n",
      "epoch 161; iter: 0; batch classifier loss: 0.295739; batch adversarial loss: 0.554552\n",
      "epoch 162; iter: 0; batch classifier loss: 0.351742; batch adversarial loss: 0.517631\n",
      "epoch 163; iter: 0; batch classifier loss: 0.431397; batch adversarial loss: 0.469677\n",
      "epoch 164; iter: 0; batch classifier loss: 0.414495; batch adversarial loss: 0.489555\n",
      "epoch 165; iter: 0; batch classifier loss: 0.360835; batch adversarial loss: 0.519165\n",
      "epoch 166; iter: 0; batch classifier loss: 0.338185; batch adversarial loss: 0.540571\n",
      "epoch 167; iter: 0; batch classifier loss: 0.297554; batch adversarial loss: 0.535864\n",
      "epoch 168; iter: 0; batch classifier loss: 0.406311; batch adversarial loss: 0.507721\n",
      "epoch 169; iter: 0; batch classifier loss: 0.371715; batch adversarial loss: 0.571807\n",
      "epoch 170; iter: 0; batch classifier loss: 0.345443; batch adversarial loss: 0.541994\n",
      "epoch 171; iter: 0; batch classifier loss: 0.359968; batch adversarial loss: 0.432545\n",
      "epoch 172; iter: 0; batch classifier loss: 0.425483; batch adversarial loss: 0.514044\n",
      "epoch 173; iter: 0; batch classifier loss: 0.378340; batch adversarial loss: 0.563026\n",
      "epoch 174; iter: 0; batch classifier loss: 0.404662; batch adversarial loss: 0.545465\n",
      "epoch 175; iter: 0; batch classifier loss: 0.280449; batch adversarial loss: 0.514892\n",
      "epoch 176; iter: 0; batch classifier loss: 0.361226; batch adversarial loss: 0.524500\n",
      "epoch 177; iter: 0; batch classifier loss: 0.339664; batch adversarial loss: 0.507190\n",
      "epoch 178; iter: 0; batch classifier loss: 0.342116; batch adversarial loss: 0.524618\n",
      "epoch 179; iter: 0; batch classifier loss: 0.339591; batch adversarial loss: 0.494212\n",
      "epoch 180; iter: 0; batch classifier loss: 0.270600; batch adversarial loss: 0.536968\n",
      "epoch 181; iter: 0; batch classifier loss: 0.297463; batch adversarial loss: 0.563812\n",
      "epoch 182; iter: 0; batch classifier loss: 0.406748; batch adversarial loss: 0.590173\n",
      "epoch 183; iter: 0; batch classifier loss: 0.415762; batch adversarial loss: 0.547378\n",
      "epoch 184; iter: 0; batch classifier loss: 0.349207; batch adversarial loss: 0.526129\n",
      "epoch 185; iter: 0; batch classifier loss: 0.372493; batch adversarial loss: 0.562259\n",
      "epoch 186; iter: 0; batch classifier loss: 0.297865; batch adversarial loss: 0.560795\n",
      "epoch 187; iter: 0; batch classifier loss: 0.275074; batch adversarial loss: 0.518539\n",
      "epoch 188; iter: 0; batch classifier loss: 0.373433; batch adversarial loss: 0.545672\n",
      "epoch 189; iter: 0; batch classifier loss: 0.385598; batch adversarial loss: 0.524790\n",
      "epoch 190; iter: 0; batch classifier loss: 0.309167; batch adversarial loss: 0.590907\n",
      "epoch 191; iter: 0; batch classifier loss: 0.313631; batch adversarial loss: 0.590283\n",
      "epoch 192; iter: 0; batch classifier loss: 0.324038; batch adversarial loss: 0.552984\n",
      "epoch 193; iter: 0; batch classifier loss: 0.376003; batch adversarial loss: 0.546872\n",
      "epoch 194; iter: 0; batch classifier loss: 0.339420; batch adversarial loss: 0.609113\n",
      "epoch 195; iter: 0; batch classifier loss: 0.340141; batch adversarial loss: 0.644788\n",
      "epoch 196; iter: 0; batch classifier loss: 0.270136; batch adversarial loss: 0.479134\n",
      "epoch 197; iter: 0; batch classifier loss: 0.336513; batch adversarial loss: 0.505380\n",
      "epoch 198; iter: 0; batch classifier loss: 0.353601; batch adversarial loss: 0.623447\n",
      "epoch 199; iter: 0; batch classifier loss: 0.342806; batch adversarial loss: 0.554244\n",
      "epoch 0; iter: 0; batch classifier loss: 0.640644; batch adversarial loss: 0.708319\n",
      "epoch 1; iter: 0; batch classifier loss: 0.595142; batch adversarial loss: 0.675374\n",
      "epoch 2; iter: 0; batch classifier loss: 0.634490; batch adversarial loss: 0.647489\n",
      "epoch 3; iter: 0; batch classifier loss: 0.621702; batch adversarial loss: 0.643206\n",
      "epoch 4; iter: 0; batch classifier loss: 0.574751; batch adversarial loss: 0.622181\n",
      "epoch 5; iter: 0; batch classifier loss: 0.577641; batch adversarial loss: 0.597296\n",
      "epoch 6; iter: 0; batch classifier loss: 0.488025; batch adversarial loss: 0.607230\n",
      "epoch 7; iter: 0; batch classifier loss: 0.554728; batch adversarial loss: 0.580635\n",
      "epoch 8; iter: 0; batch classifier loss: 0.546757; batch adversarial loss: 0.604844\n",
      "epoch 9; iter: 0; batch classifier loss: 0.471223; batch adversarial loss: 0.570315\n",
      "epoch 10; iter: 0; batch classifier loss: 0.427300; batch adversarial loss: 0.588128\n",
      "epoch 11; iter: 0; batch classifier loss: 0.578924; batch adversarial loss: 0.558779\n",
      "epoch 12; iter: 0; batch classifier loss: 0.550836; batch adversarial loss: 0.520929\n",
      "epoch 13; iter: 0; batch classifier loss: 0.508680; batch adversarial loss: 0.566381\n",
      "epoch 14; iter: 0; batch classifier loss: 0.519701; batch adversarial loss: 0.496982\n",
      "epoch 15; iter: 0; batch classifier loss: 0.460984; batch adversarial loss: 0.536407\n",
      "epoch 16; iter: 0; batch classifier loss: 0.542273; batch adversarial loss: 0.505520\n",
      "epoch 17; iter: 0; batch classifier loss: 0.536301; batch adversarial loss: 0.542346\n",
      "epoch 18; iter: 0; batch classifier loss: 0.513420; batch adversarial loss: 0.559190\n",
      "epoch 19; iter: 0; batch classifier loss: 0.542399; batch adversarial loss: 0.561900\n",
      "epoch 20; iter: 0; batch classifier loss: 0.431614; batch adversarial loss: 0.587623\n",
      "epoch 21; iter: 0; batch classifier loss: 0.457532; batch adversarial loss: 0.568954\n",
      "epoch 22; iter: 0; batch classifier loss: 0.478682; batch adversarial loss: 0.472871\n",
      "epoch 23; iter: 0; batch classifier loss: 0.508705; batch adversarial loss: 0.551113\n",
      "epoch 24; iter: 0; batch classifier loss: 0.565722; batch adversarial loss: 0.533041\n",
      "epoch 25; iter: 0; batch classifier loss: 0.446859; batch adversarial loss: 0.529359\n",
      "epoch 26; iter: 0; batch classifier loss: 0.433653; batch adversarial loss: 0.574059\n",
      "epoch 27; iter: 0; batch classifier loss: 0.459286; batch adversarial loss: 0.634979\n",
      "epoch 28; iter: 0; batch classifier loss: 0.474357; batch adversarial loss: 0.518867\n",
      "epoch 29; iter: 0; batch classifier loss: 0.460852; batch adversarial loss: 0.517081\n",
      "epoch 30; iter: 0; batch classifier loss: 0.439189; batch adversarial loss: 0.559373\n",
      "epoch 31; iter: 0; batch classifier loss: 0.477480; batch adversarial loss: 0.560937\n",
      "epoch 32; iter: 0; batch classifier loss: 0.409626; batch adversarial loss: 0.547430\n",
      "epoch 33; iter: 0; batch classifier loss: 0.484604; batch adversarial loss: 0.536852\n",
      "epoch 34; iter: 0; batch classifier loss: 0.450191; batch adversarial loss: 0.472984\n",
      "epoch 35; iter: 0; batch classifier loss: 0.418035; batch adversarial loss: 0.540981\n",
      "epoch 36; iter: 0; batch classifier loss: 0.408757; batch adversarial loss: 0.524164\n",
      "epoch 37; iter: 0; batch classifier loss: 0.430204; batch adversarial loss: 0.628081\n",
      "epoch 38; iter: 0; batch classifier loss: 0.411790; batch adversarial loss: 0.538709\n",
      "epoch 39; iter: 0; batch classifier loss: 0.455255; batch adversarial loss: 0.528503\n",
      "epoch 40; iter: 0; batch classifier loss: 0.471668; batch adversarial loss: 0.588274\n",
      "epoch 41; iter: 0; batch classifier loss: 0.470711; batch adversarial loss: 0.543409\n",
      "epoch 42; iter: 0; batch classifier loss: 0.543002; batch adversarial loss: 0.536839\n",
      "epoch 43; iter: 0; batch classifier loss: 0.444086; batch adversarial loss: 0.501707\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 44; iter: 0; batch classifier loss: 0.411724; batch adversarial loss: 0.547806\n",
      "epoch 45; iter: 0; batch classifier loss: 0.373757; batch adversarial loss: 0.515941\n",
      "epoch 46; iter: 0; batch classifier loss: 0.415291; batch adversarial loss: 0.607089\n",
      "epoch 47; iter: 0; batch classifier loss: 0.434379; batch adversarial loss: 0.548903\n",
      "epoch 48; iter: 0; batch classifier loss: 0.387042; batch adversarial loss: 0.566032\n",
      "epoch 49; iter: 0; batch classifier loss: 0.434490; batch adversarial loss: 0.517622\n",
      "epoch 50; iter: 0; batch classifier loss: 0.444416; batch adversarial loss: 0.559064\n",
      "epoch 51; iter: 0; batch classifier loss: 0.449618; batch adversarial loss: 0.574915\n",
      "epoch 52; iter: 0; batch classifier loss: 0.417588; batch adversarial loss: 0.530861\n",
      "epoch 53; iter: 0; batch classifier loss: 0.353109; batch adversarial loss: 0.485983\n",
      "epoch 54; iter: 0; batch classifier loss: 0.497920; batch adversarial loss: 0.571536\n",
      "epoch 55; iter: 0; batch classifier loss: 0.400816; batch adversarial loss: 0.506909\n",
      "epoch 56; iter: 0; batch classifier loss: 0.456169; batch adversarial loss: 0.582328\n",
      "epoch 57; iter: 0; batch classifier loss: 0.366315; batch adversarial loss: 0.562043\n",
      "epoch 58; iter: 0; batch classifier loss: 0.404892; batch adversarial loss: 0.466640\n",
      "epoch 59; iter: 0; batch classifier loss: 0.392044; batch adversarial loss: 0.551458\n",
      "epoch 60; iter: 0; batch classifier loss: 0.382145; batch adversarial loss: 0.591688\n",
      "epoch 61; iter: 0; batch classifier loss: 0.512136; batch adversarial loss: 0.570012\n",
      "epoch 62; iter: 0; batch classifier loss: 0.399030; batch adversarial loss: 0.550932\n",
      "epoch 63; iter: 0; batch classifier loss: 0.433613; batch adversarial loss: 0.572690\n",
      "epoch 64; iter: 0; batch classifier loss: 0.366969; batch adversarial loss: 0.543269\n",
      "epoch 65; iter: 0; batch classifier loss: 0.347971; batch adversarial loss: 0.569129\n",
      "epoch 66; iter: 0; batch classifier loss: 0.381492; batch adversarial loss: 0.578721\n",
      "epoch 67; iter: 0; batch classifier loss: 0.416335; batch adversarial loss: 0.550794\n",
      "epoch 68; iter: 0; batch classifier loss: 0.350949; batch adversarial loss: 0.495791\n",
      "epoch 69; iter: 0; batch classifier loss: 0.423609; batch adversarial loss: 0.561025\n",
      "epoch 70; iter: 0; batch classifier loss: 0.519844; batch adversarial loss: 0.495301\n",
      "epoch 71; iter: 0; batch classifier loss: 0.410493; batch adversarial loss: 0.491299\n",
      "epoch 72; iter: 0; batch classifier loss: 0.425989; batch adversarial loss: 0.558806\n",
      "epoch 73; iter: 0; batch classifier loss: 0.382940; batch adversarial loss: 0.493639\n",
      "epoch 74; iter: 0; batch classifier loss: 0.485760; batch adversarial loss: 0.625380\n",
      "epoch 75; iter: 0; batch classifier loss: 0.399106; batch adversarial loss: 0.506788\n",
      "epoch 76; iter: 0; batch classifier loss: 0.309019; batch adversarial loss: 0.596611\n",
      "epoch 77; iter: 0; batch classifier loss: 0.443878; batch adversarial loss: 0.500090\n",
      "epoch 78; iter: 0; batch classifier loss: 0.444104; batch adversarial loss: 0.535819\n",
      "epoch 79; iter: 0; batch classifier loss: 0.362485; batch adversarial loss: 0.483248\n",
      "epoch 80; iter: 0; batch classifier loss: 0.326013; batch adversarial loss: 0.516683\n",
      "epoch 81; iter: 0; batch classifier loss: 0.359463; batch adversarial loss: 0.553598\n",
      "epoch 82; iter: 0; batch classifier loss: 0.369395; batch adversarial loss: 0.542320\n",
      "epoch 83; iter: 0; batch classifier loss: 0.409905; batch adversarial loss: 0.562977\n",
      "epoch 84; iter: 0; batch classifier loss: 0.460988; batch adversarial loss: 0.484073\n",
      "epoch 85; iter: 0; batch classifier loss: 0.421538; batch adversarial loss: 0.616412\n",
      "epoch 86; iter: 0; batch classifier loss: 0.469873; batch adversarial loss: 0.580963\n",
      "epoch 87; iter: 0; batch classifier loss: 0.378634; batch adversarial loss: 0.610780\n",
      "epoch 88; iter: 0; batch classifier loss: 0.468448; batch adversarial loss: 0.569538\n",
      "epoch 89; iter: 0; batch classifier loss: 0.396164; batch adversarial loss: 0.544423\n",
      "epoch 90; iter: 0; batch classifier loss: 0.373768; batch adversarial loss: 0.560847\n",
      "epoch 91; iter: 0; batch classifier loss: 0.343697; batch adversarial loss: 0.533936\n",
      "epoch 92; iter: 0; batch classifier loss: 0.507974; batch adversarial loss: 0.526024\n",
      "epoch 93; iter: 0; batch classifier loss: 0.429799; batch adversarial loss: 0.580186\n",
      "epoch 94; iter: 0; batch classifier loss: 0.313916; batch adversarial loss: 0.618448\n",
      "epoch 95; iter: 0; batch classifier loss: 0.355886; batch adversarial loss: 0.518608\n",
      "epoch 96; iter: 0; batch classifier loss: 0.326168; batch adversarial loss: 0.553574\n",
      "epoch 97; iter: 0; batch classifier loss: 0.344735; batch adversarial loss: 0.570204\n",
      "epoch 98; iter: 0; batch classifier loss: 0.456384; batch adversarial loss: 0.554323\n",
      "epoch 99; iter: 0; batch classifier loss: 0.325222; batch adversarial loss: 0.555990\n",
      "epoch 100; iter: 0; batch classifier loss: 0.398351; batch adversarial loss: 0.527027\n",
      "epoch 101; iter: 0; batch classifier loss: 0.325908; batch adversarial loss: 0.597184\n",
      "epoch 102; iter: 0; batch classifier loss: 0.374018; batch adversarial loss: 0.570130\n",
      "epoch 103; iter: 0; batch classifier loss: 0.418277; batch adversarial loss: 0.477547\n",
      "epoch 104; iter: 0; batch classifier loss: 0.438395; batch adversarial loss: 0.553936\n",
      "epoch 105; iter: 0; batch classifier loss: 0.455181; batch adversarial loss: 0.596687\n",
      "epoch 106; iter: 0; batch classifier loss: 0.324437; batch adversarial loss: 0.561328\n",
      "epoch 107; iter: 0; batch classifier loss: 0.334700; batch adversarial loss: 0.655814\n",
      "epoch 108; iter: 0; batch classifier loss: 0.406216; batch adversarial loss: 0.535533\n",
      "epoch 109; iter: 0; batch classifier loss: 0.388663; batch adversarial loss: 0.600488\n",
      "epoch 110; iter: 0; batch classifier loss: 0.316627; batch adversarial loss: 0.551202\n",
      "epoch 111; iter: 0; batch classifier loss: 0.373272; batch adversarial loss: 0.607921\n",
      "epoch 112; iter: 0; batch classifier loss: 0.372987; batch adversarial loss: 0.560937\n",
      "epoch 113; iter: 0; batch classifier loss: 0.357335; batch adversarial loss: 0.550722\n",
      "epoch 114; iter: 0; batch classifier loss: 0.347974; batch adversarial loss: 0.504855\n",
      "epoch 115; iter: 0; batch classifier loss: 0.432655; batch adversarial loss: 0.685928\n",
      "epoch 116; iter: 0; batch classifier loss: 0.349005; batch adversarial loss: 0.578673\n",
      "epoch 117; iter: 0; batch classifier loss: 0.339952; batch adversarial loss: 0.570425\n",
      "epoch 118; iter: 0; batch classifier loss: 0.383200; batch adversarial loss: 0.534923\n",
      "epoch 119; iter: 0; batch classifier loss: 0.409180; batch adversarial loss: 0.556646\n",
      "epoch 120; iter: 0; batch classifier loss: 0.372206; batch adversarial loss: 0.578882\n",
      "epoch 121; iter: 0; batch classifier loss: 0.315621; batch adversarial loss: 0.556289\n",
      "epoch 122; iter: 0; batch classifier loss: 0.361911; batch adversarial loss: 0.572953\n",
      "epoch 123; iter: 0; batch classifier loss: 0.402529; batch adversarial loss: 0.541599\n",
      "epoch 124; iter: 0; batch classifier loss: 0.430176; batch adversarial loss: 0.499505\n",
      "epoch 125; iter: 0; batch classifier loss: 0.408807; batch adversarial loss: 0.497542\n",
      "epoch 126; iter: 0; batch classifier loss: 0.327972; batch adversarial loss: 0.641062\n",
      "epoch 127; iter: 0; batch classifier loss: 0.312044; batch adversarial loss: 0.490852\n",
      "epoch 128; iter: 0; batch classifier loss: 0.317408; batch adversarial loss: 0.509422\n",
      "epoch 129; iter: 0; batch classifier loss: 0.395483; batch adversarial loss: 0.525839\n",
      "epoch 130; iter: 0; batch classifier loss: 0.411025; batch adversarial loss: 0.509348\n",
      "epoch 131; iter: 0; batch classifier loss: 0.324545; batch adversarial loss: 0.528298\n",
      "epoch 132; iter: 0; batch classifier loss: 0.390336; batch adversarial loss: 0.578720\n",
      "epoch 133; iter: 0; batch classifier loss: 0.393302; batch adversarial loss: 0.507361\n",
      "epoch 134; iter: 0; batch classifier loss: 0.379861; batch adversarial loss: 0.535230\n",
      "epoch 135; iter: 0; batch classifier loss: 0.387341; batch adversarial loss: 0.614465\n",
      "epoch 136; iter: 0; batch classifier loss: 0.411114; batch adversarial loss: 0.553708\n",
      "epoch 137; iter: 0; batch classifier loss: 0.391186; batch adversarial loss: 0.505400\n",
      "epoch 138; iter: 0; batch classifier loss: 0.373407; batch adversarial loss: 0.590107\n",
      "epoch 139; iter: 0; batch classifier loss: 0.428828; batch adversarial loss: 0.535961\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 140; iter: 0; batch classifier loss: 0.339349; batch adversarial loss: 0.565100\n",
      "epoch 141; iter: 0; batch classifier loss: 0.406543; batch adversarial loss: 0.626119\n",
      "epoch 142; iter: 0; batch classifier loss: 0.291023; batch adversarial loss: 0.532081\n",
      "epoch 143; iter: 0; batch classifier loss: 0.395869; batch adversarial loss: 0.507484\n",
      "epoch 144; iter: 0; batch classifier loss: 0.378350; batch adversarial loss: 0.537251\n",
      "epoch 145; iter: 0; batch classifier loss: 0.339832; batch adversarial loss: 0.628543\n",
      "epoch 146; iter: 0; batch classifier loss: 0.380592; batch adversarial loss: 0.544654\n",
      "epoch 147; iter: 0; batch classifier loss: 0.337781; batch adversarial loss: 0.608005\n",
      "epoch 148; iter: 0; batch classifier loss: 0.356852; batch adversarial loss: 0.562800\n",
      "epoch 149; iter: 0; batch classifier loss: 0.391747; batch adversarial loss: 0.425117\n",
      "epoch 150; iter: 0; batch classifier loss: 0.362980; batch adversarial loss: 0.541306\n",
      "epoch 151; iter: 0; batch classifier loss: 0.386788; batch adversarial loss: 0.596624\n",
      "epoch 152; iter: 0; batch classifier loss: 0.395543; batch adversarial loss: 0.534789\n",
      "epoch 153; iter: 0; batch classifier loss: 0.324363; batch adversarial loss: 0.575765\n",
      "epoch 154; iter: 0; batch classifier loss: 0.374993; batch adversarial loss: 0.515418\n",
      "epoch 155; iter: 0; batch classifier loss: 0.350408; batch adversarial loss: 0.462846\n",
      "epoch 156; iter: 0; batch classifier loss: 0.298607; batch adversarial loss: 0.552941\n",
      "epoch 157; iter: 0; batch classifier loss: 0.349790; batch adversarial loss: 0.589369\n",
      "epoch 158; iter: 0; batch classifier loss: 0.333341; batch adversarial loss: 0.663625\n",
      "epoch 159; iter: 0; batch classifier loss: 0.374000; batch adversarial loss: 0.537615\n",
      "epoch 160; iter: 0; batch classifier loss: 0.384813; batch adversarial loss: 0.580776\n",
      "epoch 161; iter: 0; batch classifier loss: 0.291093; batch adversarial loss: 0.554093\n",
      "epoch 162; iter: 0; batch classifier loss: 0.370816; batch adversarial loss: 0.534882\n",
      "epoch 163; iter: 0; batch classifier loss: 0.334843; batch adversarial loss: 0.542509\n",
      "epoch 164; iter: 0; batch classifier loss: 0.338820; batch adversarial loss: 0.592416\n",
      "epoch 165; iter: 0; batch classifier loss: 0.364601; batch adversarial loss: 0.435949\n",
      "epoch 166; iter: 0; batch classifier loss: 0.296731; batch adversarial loss: 0.598808\n",
      "epoch 167; iter: 0; batch classifier loss: 0.369959; batch adversarial loss: 0.545506\n",
      "epoch 168; iter: 0; batch classifier loss: 0.386607; batch adversarial loss: 0.562301\n",
      "epoch 169; iter: 0; batch classifier loss: 0.359682; batch adversarial loss: 0.561730\n",
      "epoch 170; iter: 0; batch classifier loss: 0.432718; batch adversarial loss: 0.588948\n",
      "epoch 171; iter: 0; batch classifier loss: 0.395081; batch adversarial loss: 0.621455\n",
      "epoch 172; iter: 0; batch classifier loss: 0.403768; batch adversarial loss: 0.537360\n",
      "epoch 173; iter: 0; batch classifier loss: 0.303544; batch adversarial loss: 0.526325\n",
      "epoch 174; iter: 0; batch classifier loss: 0.324525; batch adversarial loss: 0.653663\n",
      "epoch 175; iter: 0; batch classifier loss: 0.347913; batch adversarial loss: 0.562479\n",
      "epoch 176; iter: 0; batch classifier loss: 0.378757; batch adversarial loss: 0.546086\n",
      "epoch 177; iter: 0; batch classifier loss: 0.390562; batch adversarial loss: 0.579434\n",
      "epoch 178; iter: 0; batch classifier loss: 0.350581; batch adversarial loss: 0.579944\n",
      "epoch 179; iter: 0; batch classifier loss: 0.397996; batch adversarial loss: 0.616078\n",
      "epoch 180; iter: 0; batch classifier loss: 0.357972; batch adversarial loss: 0.528396\n",
      "epoch 181; iter: 0; batch classifier loss: 0.325943; batch adversarial loss: 0.561922\n",
      "epoch 182; iter: 0; batch classifier loss: 0.313473; batch adversarial loss: 0.519527\n",
      "epoch 183; iter: 0; batch classifier loss: 0.366581; batch adversarial loss: 0.523813\n",
      "epoch 184; iter: 0; batch classifier loss: 0.356851; batch adversarial loss: 0.571239\n",
      "epoch 185; iter: 0; batch classifier loss: 0.438460; batch adversarial loss: 0.528516\n",
      "epoch 186; iter: 0; batch classifier loss: 0.320223; batch adversarial loss: 0.490216\n",
      "epoch 187; iter: 0; batch classifier loss: 0.322100; batch adversarial loss: 0.572755\n",
      "epoch 188; iter: 0; batch classifier loss: 0.390819; batch adversarial loss: 0.545469\n",
      "epoch 189; iter: 0; batch classifier loss: 0.304789; batch adversarial loss: 0.564046\n",
      "epoch 190; iter: 0; batch classifier loss: 0.316839; batch adversarial loss: 0.563064\n",
      "epoch 191; iter: 0; batch classifier loss: 0.426198; batch adversarial loss: 0.572439\n",
      "epoch 192; iter: 0; batch classifier loss: 0.346898; batch adversarial loss: 0.607662\n",
      "epoch 193; iter: 0; batch classifier loss: 0.307455; batch adversarial loss: 0.623402\n",
      "epoch 194; iter: 0; batch classifier loss: 0.395483; batch adversarial loss: 0.560834\n",
      "epoch 195; iter: 0; batch classifier loss: 0.330627; batch adversarial loss: 0.524974\n",
      "epoch 196; iter: 0; batch classifier loss: 0.337116; batch adversarial loss: 0.580199\n",
      "epoch 197; iter: 0; batch classifier loss: 0.338554; batch adversarial loss: 0.452128\n",
      "epoch 198; iter: 0; batch classifier loss: 0.287689; batch adversarial loss: 0.569721\n",
      "epoch 199; iter: 0; batch classifier loss: 0.340897; batch adversarial loss: 0.553010\n",
      "epoch 0; iter: 0; batch classifier loss: 0.761078; batch adversarial loss: 0.651079\n",
      "epoch 1; iter: 0; batch classifier loss: 0.594211; batch adversarial loss: 0.641526\n",
      "epoch 2; iter: 0; batch classifier loss: 0.595505; batch adversarial loss: 0.683634\n",
      "epoch 3; iter: 0; batch classifier loss: 0.582110; batch adversarial loss: 0.619892\n",
      "epoch 4; iter: 0; batch classifier loss: 0.608355; batch adversarial loss: 0.634628\n",
      "epoch 5; iter: 0; batch classifier loss: 0.498381; batch adversarial loss: 0.639032\n",
      "epoch 6; iter: 0; batch classifier loss: 0.533001; batch adversarial loss: 0.614062\n",
      "epoch 7; iter: 0; batch classifier loss: 0.491136; batch adversarial loss: 0.603564\n",
      "epoch 8; iter: 0; batch classifier loss: 0.569332; batch adversarial loss: 0.591244\n",
      "epoch 9; iter: 0; batch classifier loss: 0.458775; batch adversarial loss: 0.546174\n",
      "epoch 10; iter: 0; batch classifier loss: 0.605544; batch adversarial loss: 0.612322\n",
      "epoch 11; iter: 0; batch classifier loss: 0.546781; batch adversarial loss: 0.532094\n",
      "epoch 12; iter: 0; batch classifier loss: 0.497182; batch adversarial loss: 0.539359\n",
      "epoch 13; iter: 0; batch classifier loss: 0.506178; batch adversarial loss: 0.582005\n",
      "epoch 14; iter: 0; batch classifier loss: 0.577815; batch adversarial loss: 0.478972\n",
      "epoch 15; iter: 0; batch classifier loss: 0.451951; batch adversarial loss: 0.551102\n",
      "epoch 16; iter: 0; batch classifier loss: 0.484907; batch adversarial loss: 0.516197\n",
      "epoch 17; iter: 0; batch classifier loss: 0.536734; batch adversarial loss: 0.499765\n",
      "epoch 18; iter: 0; batch classifier loss: 0.478158; batch adversarial loss: 0.561314\n",
      "epoch 19; iter: 0; batch classifier loss: 0.538982; batch adversarial loss: 0.513389\n",
      "epoch 20; iter: 0; batch classifier loss: 0.432338; batch adversarial loss: 0.572894\n",
      "epoch 21; iter: 0; batch classifier loss: 0.433139; batch adversarial loss: 0.492801\n",
      "epoch 22; iter: 0; batch classifier loss: 0.485874; batch adversarial loss: 0.572747\n",
      "epoch 23; iter: 0; batch classifier loss: 0.503389; batch adversarial loss: 0.531499\n",
      "epoch 24; iter: 0; batch classifier loss: 0.511597; batch adversarial loss: 0.580485\n",
      "epoch 25; iter: 0; batch classifier loss: 0.492422; batch adversarial loss: 0.533308\n",
      "epoch 26; iter: 0; batch classifier loss: 0.400004; batch adversarial loss: 0.592979\n",
      "epoch 27; iter: 0; batch classifier loss: 0.513475; batch adversarial loss: 0.519584\n",
      "epoch 28; iter: 0; batch classifier loss: 0.404705; batch adversarial loss: 0.565582\n",
      "epoch 29; iter: 0; batch classifier loss: 0.507529; batch adversarial loss: 0.496589\n",
      "epoch 30; iter: 0; batch classifier loss: 0.428786; batch adversarial loss: 0.554704\n",
      "epoch 31; iter: 0; batch classifier loss: 0.436139; batch adversarial loss: 0.503420\n",
      "epoch 32; iter: 0; batch classifier loss: 0.448551; batch adversarial loss: 0.580101\n",
      "epoch 33; iter: 0; batch classifier loss: 0.365943; batch adversarial loss: 0.613716\n",
      "epoch 34; iter: 0; batch classifier loss: 0.420760; batch adversarial loss: 0.597321\n",
      "epoch 35; iter: 0; batch classifier loss: 0.436273; batch adversarial loss: 0.543519\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 36; iter: 0; batch classifier loss: 0.472082; batch adversarial loss: 0.554776\n",
      "epoch 37; iter: 0; batch classifier loss: 0.417927; batch adversarial loss: 0.455772\n",
      "epoch 38; iter: 0; batch classifier loss: 0.467369; batch adversarial loss: 0.525766\n",
      "epoch 39; iter: 0; batch classifier loss: 0.427074; batch adversarial loss: 0.579327\n",
      "epoch 40; iter: 0; batch classifier loss: 0.471077; batch adversarial loss: 0.615401\n",
      "epoch 41; iter: 0; batch classifier loss: 0.467919; batch adversarial loss: 0.580505\n",
      "epoch 42; iter: 0; batch classifier loss: 0.456003; batch adversarial loss: 0.474154\n",
      "epoch 43; iter: 0; batch classifier loss: 0.451980; batch adversarial loss: 0.561695\n",
      "epoch 44; iter: 0; batch classifier loss: 0.410418; batch adversarial loss: 0.580317\n",
      "epoch 45; iter: 0; batch classifier loss: 0.437089; batch adversarial loss: 0.518169\n",
      "epoch 46; iter: 0; batch classifier loss: 0.429477; batch adversarial loss: 0.500272\n",
      "epoch 47; iter: 0; batch classifier loss: 0.394526; batch adversarial loss: 0.607649\n",
      "epoch 48; iter: 0; batch classifier loss: 0.415577; batch adversarial loss: 0.598334\n",
      "epoch 49; iter: 0; batch classifier loss: 0.427351; batch adversarial loss: 0.589832\n",
      "epoch 50; iter: 0; batch classifier loss: 0.424026; batch adversarial loss: 0.535500\n",
      "epoch 51; iter: 0; batch classifier loss: 0.468363; batch adversarial loss: 0.570574\n",
      "epoch 52; iter: 0; batch classifier loss: 0.432478; batch adversarial loss: 0.589687\n",
      "epoch 53; iter: 0; batch classifier loss: 0.410440; batch adversarial loss: 0.508637\n",
      "epoch 54; iter: 0; batch classifier loss: 0.456677; batch adversarial loss: 0.507723\n",
      "epoch 55; iter: 0; batch classifier loss: 0.487755; batch adversarial loss: 0.506416\n",
      "epoch 56; iter: 0; batch classifier loss: 0.446756; batch adversarial loss: 0.526325\n",
      "epoch 57; iter: 0; batch classifier loss: 0.376476; batch adversarial loss: 0.553100\n",
      "epoch 58; iter: 0; batch classifier loss: 0.417762; batch adversarial loss: 0.645294\n",
      "epoch 59; iter: 0; batch classifier loss: 0.456820; batch adversarial loss: 0.599694\n",
      "epoch 60; iter: 0; batch classifier loss: 0.437321; batch adversarial loss: 0.535035\n",
      "epoch 61; iter: 0; batch classifier loss: 0.470042; batch adversarial loss: 0.562537\n",
      "epoch 62; iter: 0; batch classifier loss: 0.398657; batch adversarial loss: 0.536445\n",
      "epoch 63; iter: 0; batch classifier loss: 0.401371; batch adversarial loss: 0.553398\n",
      "epoch 64; iter: 0; batch classifier loss: 0.422885; batch adversarial loss: 0.507180\n",
      "epoch 65; iter: 0; batch classifier loss: 0.378481; batch adversarial loss: 0.598391\n",
      "epoch 66; iter: 0; batch classifier loss: 0.390287; batch adversarial loss: 0.571748\n",
      "epoch 67; iter: 0; batch classifier loss: 0.424458; batch adversarial loss: 0.544265\n",
      "epoch 68; iter: 0; batch classifier loss: 0.463835; batch adversarial loss: 0.572087\n",
      "epoch 69; iter: 0; batch classifier loss: 0.402713; batch adversarial loss: 0.607557\n",
      "epoch 70; iter: 0; batch classifier loss: 0.467560; batch adversarial loss: 0.635156\n",
      "epoch 71; iter: 0; batch classifier loss: 0.426144; batch adversarial loss: 0.562456\n",
      "epoch 72; iter: 0; batch classifier loss: 0.398309; batch adversarial loss: 0.478551\n",
      "epoch 73; iter: 0; batch classifier loss: 0.378402; batch adversarial loss: 0.553510\n",
      "epoch 74; iter: 0; batch classifier loss: 0.449897; batch adversarial loss: 0.580683\n",
      "epoch 75; iter: 0; batch classifier loss: 0.396699; batch adversarial loss: 0.571674\n",
      "epoch 76; iter: 0; batch classifier loss: 0.392309; batch adversarial loss: 0.526196\n",
      "epoch 77; iter: 0; batch classifier loss: 0.385754; batch adversarial loss: 0.489516\n",
      "epoch 78; iter: 0; batch classifier loss: 0.399301; batch adversarial loss: 0.463771\n",
      "epoch 79; iter: 0; batch classifier loss: 0.439283; batch adversarial loss: 0.534189\n",
      "epoch 80; iter: 0; batch classifier loss: 0.393919; batch adversarial loss: 0.562854\n",
      "epoch 81; iter: 0; batch classifier loss: 0.367326; batch adversarial loss: 0.607105\n",
      "epoch 82; iter: 0; batch classifier loss: 0.320256; batch adversarial loss: 0.562620\n",
      "epoch 83; iter: 0; batch classifier loss: 0.368340; batch adversarial loss: 0.525855\n",
      "epoch 84; iter: 0; batch classifier loss: 0.431342; batch adversarial loss: 0.580477\n",
      "epoch 85; iter: 0; batch classifier loss: 0.377058; batch adversarial loss: 0.607918\n",
      "epoch 86; iter: 0; batch classifier loss: 0.406130; batch adversarial loss: 0.509261\n",
      "epoch 87; iter: 0; batch classifier loss: 0.322227; batch adversarial loss: 0.472698\n",
      "epoch 88; iter: 0; batch classifier loss: 0.378141; batch adversarial loss: 0.544223\n",
      "epoch 89; iter: 0; batch classifier loss: 0.340333; batch adversarial loss: 0.552682\n",
      "epoch 90; iter: 0; batch classifier loss: 0.432982; batch adversarial loss: 0.489830\n",
      "epoch 91; iter: 0; batch classifier loss: 0.458689; batch adversarial loss: 0.499543\n",
      "epoch 92; iter: 0; batch classifier loss: 0.381969; batch adversarial loss: 0.509051\n",
      "epoch 93; iter: 0; batch classifier loss: 0.340484; batch adversarial loss: 0.544886\n",
      "epoch 94; iter: 0; batch classifier loss: 0.371676; batch adversarial loss: 0.581728\n",
      "epoch 95; iter: 0; batch classifier loss: 0.378701; batch adversarial loss: 0.616455\n",
      "epoch 96; iter: 0; batch classifier loss: 0.356878; batch adversarial loss: 0.510279\n",
      "epoch 97; iter: 0; batch classifier loss: 0.371859; batch adversarial loss: 0.535395\n",
      "epoch 98; iter: 0; batch classifier loss: 0.349052; batch adversarial loss: 0.490992\n",
      "epoch 99; iter: 0; batch classifier loss: 0.332176; batch adversarial loss: 0.616967\n",
      "epoch 100; iter: 0; batch classifier loss: 0.406413; batch adversarial loss: 0.579762\n",
      "epoch 101; iter: 0; batch classifier loss: 0.364414; batch adversarial loss: 0.553550\n",
      "epoch 102; iter: 0; batch classifier loss: 0.353910; batch adversarial loss: 0.599647\n",
      "epoch 103; iter: 0; batch classifier loss: 0.378675; batch adversarial loss: 0.553956\n",
      "epoch 104; iter: 0; batch classifier loss: 0.453885; batch adversarial loss: 0.580921\n",
      "epoch 105; iter: 0; batch classifier loss: 0.404806; batch adversarial loss: 0.543752\n",
      "epoch 106; iter: 0; batch classifier loss: 0.406301; batch adversarial loss: 0.527432\n",
      "epoch 107; iter: 0; batch classifier loss: 0.393628; batch adversarial loss: 0.500164\n",
      "epoch 108; iter: 0; batch classifier loss: 0.331138; batch adversarial loss: 0.561373\n",
      "epoch 109; iter: 0; batch classifier loss: 0.372887; batch adversarial loss: 0.517952\n",
      "epoch 110; iter: 0; batch classifier loss: 0.413416; batch adversarial loss: 0.526156\n",
      "epoch 111; iter: 0; batch classifier loss: 0.337590; batch adversarial loss: 0.453108\n",
      "epoch 112; iter: 0; batch classifier loss: 0.406159; batch adversarial loss: 0.472131\n",
      "epoch 113; iter: 0; batch classifier loss: 0.347223; batch adversarial loss: 0.535679\n",
      "epoch 114; iter: 0; batch classifier loss: 0.444361; batch adversarial loss: 0.562780\n",
      "epoch 115; iter: 0; batch classifier loss: 0.412307; batch adversarial loss: 0.471072\n",
      "epoch 116; iter: 0; batch classifier loss: 0.419272; batch adversarial loss: 0.563374\n",
      "epoch 117; iter: 0; batch classifier loss: 0.440950; batch adversarial loss: 0.589394\n",
      "epoch 118; iter: 0; batch classifier loss: 0.398943; batch adversarial loss: 0.499281\n",
      "epoch 119; iter: 0; batch classifier loss: 0.420035; batch adversarial loss: 0.553827\n",
      "epoch 120; iter: 0; batch classifier loss: 0.302060; batch adversarial loss: 0.518030\n",
      "epoch 121; iter: 0; batch classifier loss: 0.441979; batch adversarial loss: 0.553383\n",
      "epoch 122; iter: 0; batch classifier loss: 0.425511; batch adversarial loss: 0.562433\n",
      "epoch 123; iter: 0; batch classifier loss: 0.405705; batch adversarial loss: 0.509482\n",
      "epoch 124; iter: 0; batch classifier loss: 0.399392; batch adversarial loss: 0.626642\n",
      "epoch 125; iter: 0; batch classifier loss: 0.316336; batch adversarial loss: 0.535529\n",
      "epoch 126; iter: 0; batch classifier loss: 0.361794; batch adversarial loss: 0.507806\n",
      "epoch 127; iter: 0; batch classifier loss: 0.355444; batch adversarial loss: 0.544977\n",
      "epoch 128; iter: 0; batch classifier loss: 0.341852; batch adversarial loss: 0.545788\n",
      "epoch 129; iter: 0; batch classifier loss: 0.375406; batch adversarial loss: 0.624763\n",
      "epoch 130; iter: 0; batch classifier loss: 0.324625; batch adversarial loss: 0.534082\n",
      "epoch 131; iter: 0; batch classifier loss: 0.359211; batch adversarial loss: 0.490054\n",
      "epoch 132; iter: 0; batch classifier loss: 0.357812; batch adversarial loss: 0.554591\n",
      "epoch 133; iter: 0; batch classifier loss: 0.362155; batch adversarial loss: 0.497612\n",
      "epoch 134; iter: 0; batch classifier loss: 0.348618; batch adversarial loss: 0.635335\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 135; iter: 0; batch classifier loss: 0.439321; batch adversarial loss: 0.599160\n",
      "epoch 136; iter: 0; batch classifier loss: 0.394748; batch adversarial loss: 0.498998\n",
      "epoch 137; iter: 0; batch classifier loss: 0.411002; batch adversarial loss: 0.507541\n",
      "epoch 138; iter: 0; batch classifier loss: 0.322540; batch adversarial loss: 0.472898\n",
      "epoch 139; iter: 0; batch classifier loss: 0.374275; batch adversarial loss: 0.498097\n",
      "epoch 140; iter: 0; batch classifier loss: 0.395410; batch adversarial loss: 0.579877\n",
      "epoch 141; iter: 0; batch classifier loss: 0.353943; batch adversarial loss: 0.527237\n",
      "epoch 142; iter: 0; batch classifier loss: 0.442689; batch adversarial loss: 0.535390\n",
      "epoch 143; iter: 0; batch classifier loss: 0.350479; batch adversarial loss: 0.606318\n",
      "epoch 144; iter: 0; batch classifier loss: 0.395542; batch adversarial loss: 0.535317\n",
      "epoch 145; iter: 0; batch classifier loss: 0.389103; batch adversarial loss: 0.525797\n",
      "epoch 146; iter: 0; batch classifier loss: 0.400772; batch adversarial loss: 0.508430\n",
      "epoch 147; iter: 0; batch classifier loss: 0.362303; batch adversarial loss: 0.572709\n",
      "epoch 148; iter: 0; batch classifier loss: 0.316858; batch adversarial loss: 0.536616\n",
      "epoch 149; iter: 0; batch classifier loss: 0.440466; batch adversarial loss: 0.562222\n",
      "epoch 150; iter: 0; batch classifier loss: 0.362090; batch adversarial loss: 0.590448\n",
      "epoch 151; iter: 0; batch classifier loss: 0.314543; batch adversarial loss: 0.589936\n",
      "epoch 152; iter: 0; batch classifier loss: 0.345796; batch adversarial loss: 0.599448\n",
      "epoch 153; iter: 0; batch classifier loss: 0.359764; batch adversarial loss: 0.526915\n",
      "epoch 154; iter: 0; batch classifier loss: 0.372699; batch adversarial loss: 0.570236\n",
      "epoch 155; iter: 0; batch classifier loss: 0.401343; batch adversarial loss: 0.527658\n",
      "epoch 156; iter: 0; batch classifier loss: 0.363173; batch adversarial loss: 0.508417\n",
      "epoch 157; iter: 0; batch classifier loss: 0.419964; batch adversarial loss: 0.518331\n",
      "epoch 158; iter: 0; batch classifier loss: 0.393656; batch adversarial loss: 0.490377\n",
      "epoch 159; iter: 0; batch classifier loss: 0.344154; batch adversarial loss: 0.490222\n",
      "epoch 160; iter: 0; batch classifier loss: 0.303422; batch adversarial loss: 0.535904\n",
      "epoch 161; iter: 0; batch classifier loss: 0.315366; batch adversarial loss: 0.453761\n",
      "epoch 162; iter: 0; batch classifier loss: 0.373583; batch adversarial loss: 0.553101\n",
      "epoch 163; iter: 0; batch classifier loss: 0.315202; batch adversarial loss: 0.580869\n",
      "epoch 164; iter: 0; batch classifier loss: 0.395898; batch adversarial loss: 0.580665\n",
      "epoch 165; iter: 0; batch classifier loss: 0.303249; batch adversarial loss: 0.517490\n",
      "epoch 166; iter: 0; batch classifier loss: 0.409590; batch adversarial loss: 0.535544\n",
      "epoch 167; iter: 0; batch classifier loss: 0.373478; batch adversarial loss: 0.591078\n",
      "epoch 168; iter: 0; batch classifier loss: 0.327606; batch adversarial loss: 0.535091\n",
      "epoch 169; iter: 0; batch classifier loss: 0.386609; batch adversarial loss: 0.563203\n",
      "epoch 170; iter: 0; batch classifier loss: 0.371572; batch adversarial loss: 0.579610\n",
      "epoch 171; iter: 0; batch classifier loss: 0.349321; batch adversarial loss: 0.626533\n",
      "epoch 172; iter: 0; batch classifier loss: 0.407124; batch adversarial loss: 0.480573\n",
      "epoch 173; iter: 0; batch classifier loss: 0.350911; batch adversarial loss: 0.581041\n",
      "epoch 174; iter: 0; batch classifier loss: 0.374496; batch adversarial loss: 0.498877\n",
      "epoch 175; iter: 0; batch classifier loss: 0.458248; batch adversarial loss: 0.534813\n",
      "epoch 176; iter: 0; batch classifier loss: 0.361296; batch adversarial loss: 0.553179\n",
      "epoch 177; iter: 0; batch classifier loss: 0.374093; batch adversarial loss: 0.526553\n",
      "epoch 178; iter: 0; batch classifier loss: 0.379093; batch adversarial loss: 0.544831\n",
      "epoch 179; iter: 0; batch classifier loss: 0.329856; batch adversarial loss: 0.588856\n",
      "epoch 180; iter: 0; batch classifier loss: 0.484861; batch adversarial loss: 0.553209\n",
      "epoch 181; iter: 0; batch classifier loss: 0.368259; batch adversarial loss: 0.581026\n",
      "epoch 182; iter: 0; batch classifier loss: 0.404003; batch adversarial loss: 0.572439\n",
      "epoch 183; iter: 0; batch classifier loss: 0.300519; batch adversarial loss: 0.616532\n",
      "epoch 184; iter: 0; batch classifier loss: 0.319613; batch adversarial loss: 0.572318\n",
      "epoch 185; iter: 0; batch classifier loss: 0.338461; batch adversarial loss: 0.573540\n",
      "epoch 186; iter: 0; batch classifier loss: 0.325210; batch adversarial loss: 0.545121\n",
      "epoch 187; iter: 0; batch classifier loss: 0.330195; batch adversarial loss: 0.580535\n",
      "epoch 188; iter: 0; batch classifier loss: 0.413080; batch adversarial loss: 0.634603\n",
      "epoch 189; iter: 0; batch classifier loss: 0.307326; batch adversarial loss: 0.545221\n",
      "epoch 190; iter: 0; batch classifier loss: 0.332280; batch adversarial loss: 0.535006\n",
      "epoch 191; iter: 0; batch classifier loss: 0.394701; batch adversarial loss: 0.608160\n",
      "epoch 192; iter: 0; batch classifier loss: 0.359750; batch adversarial loss: 0.543983\n",
      "epoch 193; iter: 0; batch classifier loss: 0.391484; batch adversarial loss: 0.518519\n",
      "epoch 194; iter: 0; batch classifier loss: 0.308891; batch adversarial loss: 0.579950\n",
      "epoch 195; iter: 0; batch classifier loss: 0.351409; batch adversarial loss: 0.563151\n",
      "epoch 196; iter: 0; batch classifier loss: 0.290936; batch adversarial loss: 0.561793\n",
      "epoch 197; iter: 0; batch classifier loss: 0.336963; batch adversarial loss: 0.589788\n",
      "epoch 198; iter: 0; batch classifier loss: 0.363902; batch adversarial loss: 0.579090\n",
      "epoch 199; iter: 0; batch classifier loss: 0.329328; batch adversarial loss: 0.653878\n",
      "epoch 0; iter: 0; batch classifier loss: 0.675712; batch adversarial loss: 0.757916\n",
      "epoch 1; iter: 0; batch classifier loss: 0.621808; batch adversarial loss: 0.776755\n",
      "epoch 2; iter: 0; batch classifier loss: 0.659376; batch adversarial loss: 0.712585\n",
      "epoch 3; iter: 0; batch classifier loss: 0.461854; batch adversarial loss: 0.655880\n",
      "epoch 4; iter: 0; batch classifier loss: 0.616575; batch adversarial loss: 0.648954\n",
      "epoch 5; iter: 0; batch classifier loss: 0.520925; batch adversarial loss: 0.635547\n",
      "epoch 6; iter: 0; batch classifier loss: 0.556654; batch adversarial loss: 0.630138\n",
      "epoch 7; iter: 0; batch classifier loss: 0.527131; batch adversarial loss: 0.596083\n",
      "epoch 8; iter: 0; batch classifier loss: 0.522229; batch adversarial loss: 0.628247\n",
      "epoch 9; iter: 0; batch classifier loss: 0.508978; batch adversarial loss: 0.563632\n",
      "epoch 10; iter: 0; batch classifier loss: 0.555569; batch adversarial loss: 0.580918\n",
      "epoch 11; iter: 0; batch classifier loss: 0.566474; batch adversarial loss: 0.550255\n",
      "epoch 12; iter: 0; batch classifier loss: 0.519544; batch adversarial loss: 0.575545\n",
      "epoch 13; iter: 0; batch classifier loss: 0.497471; batch adversarial loss: 0.529264\n",
      "epoch 14; iter: 0; batch classifier loss: 0.498378; batch adversarial loss: 0.521371\n",
      "epoch 15; iter: 0; batch classifier loss: 0.522142; batch adversarial loss: 0.509024\n",
      "epoch 16; iter: 0; batch classifier loss: 0.542523; batch adversarial loss: 0.538830\n",
      "epoch 17; iter: 0; batch classifier loss: 0.491641; batch adversarial loss: 0.550492\n",
      "epoch 18; iter: 0; batch classifier loss: 0.489262; batch adversarial loss: 0.545571\n",
      "epoch 19; iter: 0; batch classifier loss: 0.518056; batch adversarial loss: 0.613750\n",
      "epoch 20; iter: 0; batch classifier loss: 0.508323; batch adversarial loss: 0.501955\n",
      "epoch 21; iter: 0; batch classifier loss: 0.467850; batch adversarial loss: 0.505240\n",
      "epoch 22; iter: 0; batch classifier loss: 0.522084; batch adversarial loss: 0.632794\n",
      "epoch 23; iter: 0; batch classifier loss: 0.449539; batch adversarial loss: 0.539165\n",
      "epoch 24; iter: 0; batch classifier loss: 0.429317; batch adversarial loss: 0.565910\n",
      "epoch 25; iter: 0; batch classifier loss: 0.548645; batch adversarial loss: 0.634837\n",
      "epoch 26; iter: 0; batch classifier loss: 0.474348; batch adversarial loss: 0.520393\n",
      "epoch 27; iter: 0; batch classifier loss: 0.481899; batch adversarial loss: 0.599484\n",
      "epoch 28; iter: 0; batch classifier loss: 0.479132; batch adversarial loss: 0.549871\n",
      "epoch 29; iter: 0; batch classifier loss: 0.536630; batch adversarial loss: 0.516443\n",
      "epoch 30; iter: 0; batch classifier loss: 0.469432; batch adversarial loss: 0.609968\n",
      "epoch 31; iter: 0; batch classifier loss: 0.468463; batch adversarial loss: 0.569852\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 32; iter: 0; batch classifier loss: 0.400059; batch adversarial loss: 0.577468\n",
      "epoch 33; iter: 0; batch classifier loss: 0.509085; batch adversarial loss: 0.553217\n",
      "epoch 34; iter: 0; batch classifier loss: 0.429397; batch adversarial loss: 0.595841\n",
      "epoch 35; iter: 0; batch classifier loss: 0.430294; batch adversarial loss: 0.553436\n",
      "epoch 36; iter: 0; batch classifier loss: 0.485533; batch adversarial loss: 0.589523\n",
      "epoch 37; iter: 0; batch classifier loss: 0.367192; batch adversarial loss: 0.561141\n",
      "epoch 38; iter: 0; batch classifier loss: 0.453305; batch adversarial loss: 0.589226\n",
      "epoch 39; iter: 0; batch classifier loss: 0.503592; batch adversarial loss: 0.572893\n",
      "epoch 40; iter: 0; batch classifier loss: 0.412712; batch adversarial loss: 0.501362\n",
      "epoch 41; iter: 0; batch classifier loss: 0.401318; batch adversarial loss: 0.553195\n",
      "epoch 42; iter: 0; batch classifier loss: 0.488221; batch adversarial loss: 0.579579\n",
      "epoch 43; iter: 0; batch classifier loss: 0.427162; batch adversarial loss: 0.491681\n",
      "epoch 44; iter: 0; batch classifier loss: 0.392794; batch adversarial loss: 0.615703\n",
      "epoch 45; iter: 0; batch classifier loss: 0.456884; batch adversarial loss: 0.553928\n",
      "epoch 46; iter: 0; batch classifier loss: 0.434017; batch adversarial loss: 0.544860\n",
      "epoch 47; iter: 0; batch classifier loss: 0.434475; batch adversarial loss: 0.581172\n",
      "epoch 48; iter: 0; batch classifier loss: 0.460827; batch adversarial loss: 0.552242\n",
      "epoch 49; iter: 0; batch classifier loss: 0.456258; batch adversarial loss: 0.579976\n",
      "epoch 50; iter: 0; batch classifier loss: 0.441362; batch adversarial loss: 0.582447\n",
      "epoch 51; iter: 0; batch classifier loss: 0.447943; batch adversarial loss: 0.598378\n",
      "epoch 52; iter: 0; batch classifier loss: 0.358065; batch adversarial loss: 0.607178\n",
      "epoch 53; iter: 0; batch classifier loss: 0.418020; batch adversarial loss: 0.571614\n",
      "epoch 54; iter: 0; batch classifier loss: 0.480196; batch adversarial loss: 0.535728\n",
      "epoch 55; iter: 0; batch classifier loss: 0.367583; batch adversarial loss: 0.553131\n",
      "epoch 56; iter: 0; batch classifier loss: 0.436098; batch adversarial loss: 0.563382\n",
      "epoch 57; iter: 0; batch classifier loss: 0.343185; batch adversarial loss: 0.544740\n",
      "epoch 58; iter: 0; batch classifier loss: 0.454386; batch adversarial loss: 0.634133\n",
      "epoch 59; iter: 0; batch classifier loss: 0.453733; batch adversarial loss: 0.597597\n",
      "epoch 60; iter: 0; batch classifier loss: 0.420544; batch adversarial loss: 0.498813\n",
      "epoch 61; iter: 0; batch classifier loss: 0.384208; batch adversarial loss: 0.617483\n",
      "epoch 62; iter: 0; batch classifier loss: 0.445640; batch adversarial loss: 0.563531\n",
      "epoch 63; iter: 0; batch classifier loss: 0.388266; batch adversarial loss: 0.554103\n",
      "epoch 64; iter: 0; batch classifier loss: 0.425393; batch adversarial loss: 0.580835\n",
      "epoch 65; iter: 0; batch classifier loss: 0.327206; batch adversarial loss: 0.543528\n",
      "epoch 66; iter: 0; batch classifier loss: 0.346879; batch adversarial loss: 0.527048\n",
      "epoch 67; iter: 0; batch classifier loss: 0.485313; batch adversarial loss: 0.544155\n",
      "epoch 68; iter: 0; batch classifier loss: 0.382171; batch adversarial loss: 0.525148\n",
      "epoch 69; iter: 0; batch classifier loss: 0.434512; batch adversarial loss: 0.572567\n",
      "epoch 70; iter: 0; batch classifier loss: 0.412938; batch adversarial loss: 0.545027\n",
      "epoch 71; iter: 0; batch classifier loss: 0.445927; batch adversarial loss: 0.553754\n",
      "epoch 72; iter: 0; batch classifier loss: 0.411630; batch adversarial loss: 0.517058\n",
      "epoch 73; iter: 0; batch classifier loss: 0.404451; batch adversarial loss: 0.508793\n",
      "epoch 74; iter: 0; batch classifier loss: 0.364322; batch adversarial loss: 0.598646\n",
      "epoch 75; iter: 0; batch classifier loss: 0.354991; batch adversarial loss: 0.624588\n",
      "epoch 76; iter: 0; batch classifier loss: 0.367262; batch adversarial loss: 0.562601\n",
      "epoch 77; iter: 0; batch classifier loss: 0.425447; batch adversarial loss: 0.616224\n",
      "epoch 78; iter: 0; batch classifier loss: 0.386933; batch adversarial loss: 0.544592\n",
      "epoch 79; iter: 0; batch classifier loss: 0.383064; batch adversarial loss: 0.598379\n",
      "epoch 80; iter: 0; batch classifier loss: 0.370189; batch adversarial loss: 0.571453\n",
      "epoch 81; iter: 0; batch classifier loss: 0.399662; batch adversarial loss: 0.616860\n",
      "epoch 82; iter: 0; batch classifier loss: 0.418872; batch adversarial loss: 0.518077\n",
      "epoch 83; iter: 0; batch classifier loss: 0.337492; batch adversarial loss: 0.544007\n",
      "epoch 84; iter: 0; batch classifier loss: 0.412532; batch adversarial loss: 0.526623\n",
      "epoch 85; iter: 0; batch classifier loss: 0.310251; batch adversarial loss: 0.553812\n",
      "epoch 86; iter: 0; batch classifier loss: 0.415260; batch adversarial loss: 0.436537\n",
      "epoch 87; iter: 0; batch classifier loss: 0.439451; batch adversarial loss: 0.553608\n",
      "epoch 88; iter: 0; batch classifier loss: 0.374965; batch adversarial loss: 0.543475\n",
      "epoch 89; iter: 0; batch classifier loss: 0.438749; batch adversarial loss: 0.553727\n",
      "epoch 90; iter: 0; batch classifier loss: 0.401827; batch adversarial loss: 0.499358\n",
      "epoch 91; iter: 0; batch classifier loss: 0.320023; batch adversarial loss: 0.553477\n",
      "epoch 92; iter: 0; batch classifier loss: 0.291424; batch adversarial loss: 0.598513\n",
      "epoch 93; iter: 0; batch classifier loss: 0.400990; batch adversarial loss: 0.615924\n",
      "epoch 94; iter: 0; batch classifier loss: 0.411217; batch adversarial loss: 0.562805\n",
      "epoch 95; iter: 0; batch classifier loss: 0.377350; batch adversarial loss: 0.544561\n",
      "epoch 96; iter: 0; batch classifier loss: 0.410865; batch adversarial loss: 0.589529\n",
      "epoch 97; iter: 0; batch classifier loss: 0.318817; batch adversarial loss: 0.552934\n",
      "epoch 98; iter: 0; batch classifier loss: 0.402898; batch adversarial loss: 0.590392\n",
      "epoch 99; iter: 0; batch classifier loss: 0.410141; batch adversarial loss: 0.499237\n",
      "epoch 100; iter: 0; batch classifier loss: 0.317614; batch adversarial loss: 0.544038\n",
      "epoch 101; iter: 0; batch classifier loss: 0.348961; batch adversarial loss: 0.517964\n",
      "epoch 102; iter: 0; batch classifier loss: 0.480986; batch adversarial loss: 0.544723\n",
      "epoch 103; iter: 0; batch classifier loss: 0.492816; batch adversarial loss: 0.518508\n",
      "epoch 104; iter: 0; batch classifier loss: 0.401619; batch adversarial loss: 0.553418\n",
      "epoch 105; iter: 0; batch classifier loss: 0.350642; batch adversarial loss: 0.580085\n",
      "epoch 106; iter: 0; batch classifier loss: 0.343618; batch adversarial loss: 0.545112\n",
      "epoch 107; iter: 0; batch classifier loss: 0.381113; batch adversarial loss: 0.481829\n",
      "epoch 108; iter: 0; batch classifier loss: 0.361542; batch adversarial loss: 0.544329\n",
      "epoch 109; iter: 0; batch classifier loss: 0.442941; batch adversarial loss: 0.552808\n",
      "epoch 110; iter: 0; batch classifier loss: 0.398123; batch adversarial loss: 0.617436\n",
      "epoch 111; iter: 0; batch classifier loss: 0.336902; batch adversarial loss: 0.562828\n",
      "epoch 112; iter: 0; batch classifier loss: 0.351794; batch adversarial loss: 0.544062\n",
      "epoch 113; iter: 0; batch classifier loss: 0.372919; batch adversarial loss: 0.444046\n",
      "epoch 114; iter: 0; batch classifier loss: 0.318147; batch adversarial loss: 0.535565\n",
      "epoch 115; iter: 0; batch classifier loss: 0.370443; batch adversarial loss: 0.634229\n",
      "epoch 116; iter: 0; batch classifier loss: 0.347777; batch adversarial loss: 0.580471\n",
      "epoch 117; iter: 0; batch classifier loss: 0.333249; batch adversarial loss: 0.625373\n",
      "epoch 118; iter: 0; batch classifier loss: 0.280082; batch adversarial loss: 0.535877\n",
      "epoch 119; iter: 0; batch classifier loss: 0.360038; batch adversarial loss: 0.589780\n",
      "epoch 120; iter: 0; batch classifier loss: 0.346716; batch adversarial loss: 0.499550\n",
      "epoch 121; iter: 0; batch classifier loss: 0.382007; batch adversarial loss: 0.616194\n",
      "epoch 122; iter: 0; batch classifier loss: 0.363873; batch adversarial loss: 0.571123\n",
      "epoch 123; iter: 0; batch classifier loss: 0.342484; batch adversarial loss: 0.595569\n",
      "epoch 124; iter: 0; batch classifier loss: 0.338540; batch adversarial loss: 0.552807\n",
      "epoch 125; iter: 0; batch classifier loss: 0.410816; batch adversarial loss: 0.605416\n",
      "epoch 126; iter: 0; batch classifier loss: 0.381253; batch adversarial loss: 0.578436\n",
      "epoch 127; iter: 0; batch classifier loss: 0.440437; batch adversarial loss: 0.581610\n",
      "epoch 128; iter: 0; batch classifier loss: 0.406716; batch adversarial loss: 0.547348\n",
      "epoch 129; iter: 0; batch classifier loss: 0.380536; batch adversarial loss: 0.543507\n",
      "epoch 130; iter: 0; batch classifier loss: 0.377708; batch adversarial loss: 0.543221\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 131; iter: 0; batch classifier loss: 0.428864; batch adversarial loss: 0.562966\n",
      "epoch 132; iter: 0; batch classifier loss: 0.344720; batch adversarial loss: 0.509443\n",
      "epoch 133; iter: 0; batch classifier loss: 0.367490; batch adversarial loss: 0.535418\n",
      "epoch 134; iter: 0; batch classifier loss: 0.468182; batch adversarial loss: 0.561558\n",
      "epoch 135; iter: 0; batch classifier loss: 0.414915; batch adversarial loss: 0.571257\n",
      "epoch 136; iter: 0; batch classifier loss: 0.361964; batch adversarial loss: 0.589525\n",
      "epoch 137; iter: 0; batch classifier loss: 0.428616; batch adversarial loss: 0.600550\n",
      "epoch 138; iter: 0; batch classifier loss: 0.461705; batch adversarial loss: 0.491711\n",
      "epoch 139; iter: 0; batch classifier loss: 0.245209; batch adversarial loss: 0.526731\n",
      "epoch 140; iter: 0; batch classifier loss: 0.334908; batch adversarial loss: 0.635052\n",
      "epoch 141; iter: 0; batch classifier loss: 0.444791; batch adversarial loss: 0.536223\n",
      "epoch 142; iter: 0; batch classifier loss: 0.327699; batch adversarial loss: 0.555084\n",
      "epoch 143; iter: 0; batch classifier loss: 0.428805; batch adversarial loss: 0.544913\n",
      "epoch 144; iter: 0; batch classifier loss: 0.365754; batch adversarial loss: 0.490701\n",
      "epoch 145; iter: 0; batch classifier loss: 0.323790; batch adversarial loss: 0.544297\n",
      "epoch 146; iter: 0; batch classifier loss: 0.410673; batch adversarial loss: 0.563342\n",
      "epoch 147; iter: 0; batch classifier loss: 0.321604; batch adversarial loss: 0.472512\n",
      "epoch 148; iter: 0; batch classifier loss: 0.427417; batch adversarial loss: 0.598994\n",
      "epoch 149; iter: 0; batch classifier loss: 0.362045; batch adversarial loss: 0.562262\n",
      "epoch 150; iter: 0; batch classifier loss: 0.420523; batch adversarial loss: 0.653038\n",
      "epoch 151; iter: 0; batch classifier loss: 0.314553; batch adversarial loss: 0.571674\n",
      "epoch 152; iter: 0; batch classifier loss: 0.410062; batch adversarial loss: 0.545310\n",
      "epoch 153; iter: 0; batch classifier loss: 0.320433; batch adversarial loss: 0.526603\n",
      "epoch 154; iter: 0; batch classifier loss: 0.303642; batch adversarial loss: 0.562821\n",
      "epoch 155; iter: 0; batch classifier loss: 0.377301; batch adversarial loss: 0.561256\n",
      "epoch 156; iter: 0; batch classifier loss: 0.405762; batch adversarial loss: 0.472818\n",
      "epoch 157; iter: 0; batch classifier loss: 0.403332; batch adversarial loss: 0.481735\n",
      "epoch 158; iter: 0; batch classifier loss: 0.347010; batch adversarial loss: 0.562298\n",
      "epoch 159; iter: 0; batch classifier loss: 0.389652; batch adversarial loss: 0.526071\n",
      "epoch 160; iter: 0; batch classifier loss: 0.342254; batch adversarial loss: 0.552811\n",
      "epoch 161; iter: 0; batch classifier loss: 0.391696; batch adversarial loss: 0.571858\n",
      "epoch 162; iter: 0; batch classifier loss: 0.342901; batch adversarial loss: 0.526294\n",
      "epoch 163; iter: 0; batch classifier loss: 0.343359; batch adversarial loss: 0.572213\n",
      "epoch 164; iter: 0; batch classifier loss: 0.378321; batch adversarial loss: 0.545176\n",
      "epoch 165; iter: 0; batch classifier loss: 0.289271; batch adversarial loss: 0.536264\n",
      "epoch 166; iter: 0; batch classifier loss: 0.374378; batch adversarial loss: 0.553444\n",
      "epoch 167; iter: 0; batch classifier loss: 0.334919; batch adversarial loss: 0.535942\n",
      "epoch 168; iter: 0; batch classifier loss: 0.358705; batch adversarial loss: 0.589836\n",
      "epoch 169; iter: 0; batch classifier loss: 0.399817; batch adversarial loss: 0.670778\n",
      "epoch 170; iter: 0; batch classifier loss: 0.343426; batch adversarial loss: 0.508903\n",
      "epoch 171; iter: 0; batch classifier loss: 0.383350; batch adversarial loss: 0.562423\n",
      "epoch 172; iter: 0; batch classifier loss: 0.312651; batch adversarial loss: 0.544241\n",
      "epoch 173; iter: 0; batch classifier loss: 0.392866; batch adversarial loss: 0.561951\n",
      "epoch 174; iter: 0; batch classifier loss: 0.337770; batch adversarial loss: 0.616761\n",
      "epoch 175; iter: 0; batch classifier loss: 0.313348; batch adversarial loss: 0.518179\n",
      "epoch 176; iter: 0; batch classifier loss: 0.427280; batch adversarial loss: 0.545715\n",
      "epoch 177; iter: 0; batch classifier loss: 0.439081; batch adversarial loss: 0.605340\n",
      "epoch 178; iter: 0; batch classifier loss: 0.359510; batch adversarial loss: 0.615934\n",
      "epoch 179; iter: 0; batch classifier loss: 0.411962; batch adversarial loss: 0.589919\n",
      "epoch 180; iter: 0; batch classifier loss: 0.386589; batch adversarial loss: 0.588774\n",
      "epoch 181; iter: 0; batch classifier loss: 0.396420; batch adversarial loss: 0.535246\n",
      "epoch 182; iter: 0; batch classifier loss: 0.336260; batch adversarial loss: 0.598670\n",
      "epoch 183; iter: 0; batch classifier loss: 0.375167; batch adversarial loss: 0.580486\n",
      "epoch 184; iter: 0; batch classifier loss: 0.330435; batch adversarial loss: 0.607861\n",
      "epoch 185; iter: 0; batch classifier loss: 0.335324; batch adversarial loss: 0.536756\n",
      "epoch 186; iter: 0; batch classifier loss: 0.299610; batch adversarial loss: 0.499123\n",
      "epoch 187; iter: 0; batch classifier loss: 0.342095; batch adversarial loss: 0.535253\n",
      "epoch 188; iter: 0; batch classifier loss: 0.297606; batch adversarial loss: 0.572344\n",
      "epoch 189; iter: 0; batch classifier loss: 0.324359; batch adversarial loss: 0.679867\n",
      "epoch 190; iter: 0; batch classifier loss: 0.306615; batch adversarial loss: 0.446183\n",
      "epoch 191; iter: 0; batch classifier loss: 0.339662; batch adversarial loss: 0.499304\n",
      "epoch 192; iter: 0; batch classifier loss: 0.315916; batch adversarial loss: 0.588797\n",
      "epoch 193; iter: 0; batch classifier loss: 0.353240; batch adversarial loss: 0.580457\n",
      "epoch 194; iter: 0; batch classifier loss: 0.358613; batch adversarial loss: 0.581130\n",
      "epoch 195; iter: 0; batch classifier loss: 0.326671; batch adversarial loss: 0.537367\n",
      "epoch 196; iter: 0; batch classifier loss: 0.394839; batch adversarial loss: 0.589228\n",
      "epoch 197; iter: 0; batch classifier loss: 0.367143; batch adversarial loss: 0.535927\n",
      "epoch 198; iter: 0; batch classifier loss: 0.308503; batch adversarial loss: 0.579698\n",
      "epoch 199; iter: 0; batch classifier loss: 0.315774; batch adversarial loss: 0.645103\n",
      "epoch 0; iter: 0; batch classifier loss: 0.683205; batch adversarial loss: 0.777653\n",
      "epoch 1; iter: 0; batch classifier loss: 0.676652; batch adversarial loss: 0.770046\n",
      "epoch 2; iter: 0; batch classifier loss: 0.666725; batch adversarial loss: 0.715815\n",
      "epoch 3; iter: 0; batch classifier loss: 0.573792; batch adversarial loss: 0.671439\n",
      "epoch 4; iter: 0; batch classifier loss: 0.533314; batch adversarial loss: 0.656328\n",
      "epoch 5; iter: 0; batch classifier loss: 0.593070; batch adversarial loss: 0.621212\n",
      "epoch 6; iter: 0; batch classifier loss: 0.535702; batch adversarial loss: 0.624340\n",
      "epoch 7; iter: 0; batch classifier loss: 0.586524; batch adversarial loss: 0.644676\n",
      "epoch 8; iter: 0; batch classifier loss: 0.571792; batch adversarial loss: 0.581477\n",
      "epoch 9; iter: 0; batch classifier loss: 0.579717; batch adversarial loss: 0.561335\n",
      "epoch 10; iter: 0; batch classifier loss: 0.571127; batch adversarial loss: 0.563041\n",
      "epoch 11; iter: 0; batch classifier loss: 0.527770; batch adversarial loss: 0.546009\n",
      "epoch 12; iter: 0; batch classifier loss: 0.549030; batch adversarial loss: 0.585678\n",
      "epoch 13; iter: 0; batch classifier loss: 0.448007; batch adversarial loss: 0.556113\n",
      "epoch 14; iter: 0; batch classifier loss: 0.506858; batch adversarial loss: 0.595634\n",
      "epoch 15; iter: 0; batch classifier loss: 0.484033; batch adversarial loss: 0.577039\n",
      "epoch 16; iter: 0; batch classifier loss: 0.511529; batch adversarial loss: 0.536859\n",
      "epoch 17; iter: 0; batch classifier loss: 0.522125; batch adversarial loss: 0.536687\n",
      "epoch 18; iter: 0; batch classifier loss: 0.492507; batch adversarial loss: 0.590477\n",
      "epoch 19; iter: 0; batch classifier loss: 0.510716; batch adversarial loss: 0.576305\n",
      "epoch 20; iter: 0; batch classifier loss: 0.555305; batch adversarial loss: 0.554421\n",
      "epoch 21; iter: 0; batch classifier loss: 0.477004; batch adversarial loss: 0.525834\n",
      "epoch 22; iter: 0; batch classifier loss: 0.464250; batch adversarial loss: 0.548810\n",
      "epoch 23; iter: 0; batch classifier loss: 0.500454; batch adversarial loss: 0.560129\n",
      "epoch 24; iter: 0; batch classifier loss: 0.459486; batch adversarial loss: 0.607369\n",
      "epoch 25; iter: 0; batch classifier loss: 0.521289; batch adversarial loss: 0.514732\n",
      "epoch 26; iter: 0; batch classifier loss: 0.502854; batch adversarial loss: 0.522117\n",
      "epoch 27; iter: 0; batch classifier loss: 0.576102; batch adversarial loss: 0.547248\n",
      "epoch 28; iter: 0; batch classifier loss: 0.453842; batch adversarial loss: 0.534180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 29; iter: 0; batch classifier loss: 0.521398; batch adversarial loss: 0.544339\n",
      "epoch 30; iter: 0; batch classifier loss: 0.409656; batch adversarial loss: 0.467771\n",
      "epoch 31; iter: 0; batch classifier loss: 0.452443; batch adversarial loss: 0.539388\n",
      "epoch 32; iter: 0; batch classifier loss: 0.450359; batch adversarial loss: 0.474608\n",
      "epoch 33; iter: 0; batch classifier loss: 0.539582; batch adversarial loss: 0.595559\n",
      "epoch 34; iter: 0; batch classifier loss: 0.411405; batch adversarial loss: 0.554381\n",
      "epoch 35; iter: 0; batch classifier loss: 0.415239; batch adversarial loss: 0.597294\n",
      "epoch 36; iter: 0; batch classifier loss: 0.414416; batch adversarial loss: 0.561975\n",
      "epoch 37; iter: 0; batch classifier loss: 0.491763; batch adversarial loss: 0.563275\n",
      "epoch 38; iter: 0; batch classifier loss: 0.428489; batch adversarial loss: 0.545087\n",
      "epoch 39; iter: 0; batch classifier loss: 0.358491; batch adversarial loss: 0.463566\n",
      "epoch 40; iter: 0; batch classifier loss: 0.395174; batch adversarial loss: 0.572324\n",
      "epoch 41; iter: 0; batch classifier loss: 0.418272; batch adversarial loss: 0.545796\n",
      "epoch 42; iter: 0; batch classifier loss: 0.434436; batch adversarial loss: 0.506219\n",
      "epoch 43; iter: 0; batch classifier loss: 0.420095; batch adversarial loss: 0.481513\n",
      "epoch 44; iter: 0; batch classifier loss: 0.378911; batch adversarial loss: 0.535326\n",
      "epoch 45; iter: 0; batch classifier loss: 0.409827; batch adversarial loss: 0.527240\n",
      "epoch 46; iter: 0; batch classifier loss: 0.502395; batch adversarial loss: 0.525610\n",
      "epoch 47; iter: 0; batch classifier loss: 0.465659; batch adversarial loss: 0.626154\n",
      "epoch 48; iter: 0; batch classifier loss: 0.493232; batch adversarial loss: 0.618911\n",
      "epoch 49; iter: 0; batch classifier loss: 0.481377; batch adversarial loss: 0.572692\n",
      "epoch 50; iter: 0; batch classifier loss: 0.403001; batch adversarial loss: 0.608432\n",
      "epoch 51; iter: 0; batch classifier loss: 0.429273; batch adversarial loss: 0.553436\n",
      "epoch 52; iter: 0; batch classifier loss: 0.408934; batch adversarial loss: 0.443300\n",
      "epoch 53; iter: 0; batch classifier loss: 0.349603; batch adversarial loss: 0.554170\n",
      "epoch 54; iter: 0; batch classifier loss: 0.467569; batch adversarial loss: 0.544337\n",
      "epoch 55; iter: 0; batch classifier loss: 0.454891; batch adversarial loss: 0.510215\n",
      "epoch 56; iter: 0; batch classifier loss: 0.449619; batch adversarial loss: 0.525919\n",
      "epoch 57; iter: 0; batch classifier loss: 0.397226; batch adversarial loss: 0.541813\n",
      "epoch 58; iter: 0; batch classifier loss: 0.437224; batch adversarial loss: 0.497758\n",
      "epoch 59; iter: 0; batch classifier loss: 0.445874; batch adversarial loss: 0.488304\n",
      "epoch 60; iter: 0; batch classifier loss: 0.392134; batch adversarial loss: 0.573228\n",
      "epoch 61; iter: 0; batch classifier loss: 0.507281; batch adversarial loss: 0.626750\n",
      "epoch 62; iter: 0; batch classifier loss: 0.349047; batch adversarial loss: 0.563077\n",
      "epoch 63; iter: 0; batch classifier loss: 0.461136; batch adversarial loss: 0.545598\n",
      "epoch 64; iter: 0; batch classifier loss: 0.363175; batch adversarial loss: 0.618529\n",
      "epoch 65; iter: 0; batch classifier loss: 0.428144; batch adversarial loss: 0.471419\n",
      "epoch 66; iter: 0; batch classifier loss: 0.382778; batch adversarial loss: 0.552405\n",
      "epoch 67; iter: 0; batch classifier loss: 0.385998; batch adversarial loss: 0.609436\n",
      "epoch 68; iter: 0; batch classifier loss: 0.463886; batch adversarial loss: 0.551786\n",
      "epoch 69; iter: 0; batch classifier loss: 0.393138; batch adversarial loss: 0.545854\n",
      "epoch 70; iter: 0; batch classifier loss: 0.391585; batch adversarial loss: 0.490503\n",
      "epoch 71; iter: 0; batch classifier loss: 0.406348; batch adversarial loss: 0.498115\n",
      "epoch 72; iter: 0; batch classifier loss: 0.462328; batch adversarial loss: 0.580624\n",
      "epoch 73; iter: 0; batch classifier loss: 0.384622; batch adversarial loss: 0.489376\n",
      "epoch 74; iter: 0; batch classifier loss: 0.426936; batch adversarial loss: 0.562539\n",
      "epoch 75; iter: 0; batch classifier loss: 0.421618; batch adversarial loss: 0.626225\n",
      "epoch 76; iter: 0; batch classifier loss: 0.389244; batch adversarial loss: 0.599720\n",
      "epoch 77; iter: 0; batch classifier loss: 0.411007; batch adversarial loss: 0.598980\n",
      "epoch 78; iter: 0; batch classifier loss: 0.435493; batch adversarial loss: 0.553509\n",
      "epoch 79; iter: 0; batch classifier loss: 0.375121; batch adversarial loss: 0.598781\n",
      "epoch 80; iter: 0; batch classifier loss: 0.363080; batch adversarial loss: 0.516140\n",
      "epoch 81; iter: 0; batch classifier loss: 0.424717; batch adversarial loss: 0.590428\n",
      "epoch 82; iter: 0; batch classifier loss: 0.380280; batch adversarial loss: 0.552867\n",
      "epoch 83; iter: 0; batch classifier loss: 0.381833; batch adversarial loss: 0.517671\n",
      "epoch 84; iter: 0; batch classifier loss: 0.365434; batch adversarial loss: 0.526402\n",
      "epoch 85; iter: 0; batch classifier loss: 0.336626; batch adversarial loss: 0.635648\n",
      "epoch 86; iter: 0; batch classifier loss: 0.484125; batch adversarial loss: 0.581932\n",
      "epoch 87; iter: 0; batch classifier loss: 0.361570; batch adversarial loss: 0.535907\n",
      "epoch 88; iter: 0; batch classifier loss: 0.414953; batch adversarial loss: 0.481365\n",
      "epoch 89; iter: 0; batch classifier loss: 0.376601; batch adversarial loss: 0.552917\n",
      "epoch 90; iter: 0; batch classifier loss: 0.402315; batch adversarial loss: 0.526079\n",
      "epoch 91; iter: 0; batch classifier loss: 0.422142; batch adversarial loss: 0.581155\n",
      "epoch 92; iter: 0; batch classifier loss: 0.382681; batch adversarial loss: 0.625737\n",
      "epoch 93; iter: 0; batch classifier loss: 0.395954; batch adversarial loss: 0.545119\n",
      "epoch 94; iter: 0; batch classifier loss: 0.384528; batch adversarial loss: 0.535176\n",
      "epoch 95; iter: 0; batch classifier loss: 0.425095; batch adversarial loss: 0.598575\n",
      "epoch 96; iter: 0; batch classifier loss: 0.398930; batch adversarial loss: 0.534573\n",
      "epoch 97; iter: 0; batch classifier loss: 0.393921; batch adversarial loss: 0.589712\n",
      "epoch 98; iter: 0; batch classifier loss: 0.503949; batch adversarial loss: 0.434435\n",
      "epoch 99; iter: 0; batch classifier loss: 0.405629; batch adversarial loss: 0.526064\n",
      "epoch 100; iter: 0; batch classifier loss: 0.385281; batch adversarial loss: 0.544946\n",
      "epoch 101; iter: 0; batch classifier loss: 0.341619; batch adversarial loss: 0.572954\n",
      "epoch 102; iter: 0; batch classifier loss: 0.375514; batch adversarial loss: 0.608671\n",
      "epoch 103; iter: 0; batch classifier loss: 0.401717; batch adversarial loss: 0.489595\n",
      "epoch 104; iter: 0; batch classifier loss: 0.364231; batch adversarial loss: 0.489938\n",
      "epoch 105; iter: 0; batch classifier loss: 0.416330; batch adversarial loss: 0.590163\n",
      "epoch 106; iter: 0; batch classifier loss: 0.440774; batch adversarial loss: 0.562680\n",
      "epoch 107; iter: 0; batch classifier loss: 0.382519; batch adversarial loss: 0.562920\n",
      "epoch 108; iter: 0; batch classifier loss: 0.411982; batch adversarial loss: 0.462344\n",
      "epoch 109; iter: 0; batch classifier loss: 0.372011; batch adversarial loss: 0.571754\n",
      "epoch 110; iter: 0; batch classifier loss: 0.460399; batch adversarial loss: 0.580941\n",
      "epoch 111; iter: 0; batch classifier loss: 0.482146; batch adversarial loss: 0.553302\n",
      "epoch 112; iter: 0; batch classifier loss: 0.405236; batch adversarial loss: 0.581087\n",
      "epoch 113; iter: 0; batch classifier loss: 0.402052; batch adversarial loss: 0.498920\n",
      "epoch 114; iter: 0; batch classifier loss: 0.356496; batch adversarial loss: 0.562623\n",
      "epoch 115; iter: 0; batch classifier loss: 0.438044; batch adversarial loss: 0.562558\n",
      "epoch 116; iter: 0; batch classifier loss: 0.398012; batch adversarial loss: 0.516728\n",
      "epoch 117; iter: 0; batch classifier loss: 0.425752; batch adversarial loss: 0.526237\n",
      "epoch 118; iter: 0; batch classifier loss: 0.372391; batch adversarial loss: 0.553324\n",
      "epoch 119; iter: 0; batch classifier loss: 0.319970; batch adversarial loss: 0.508050\n",
      "epoch 120; iter: 0; batch classifier loss: 0.370754; batch adversarial loss: 0.563045\n",
      "epoch 121; iter: 0; batch classifier loss: 0.366657; batch adversarial loss: 0.516837\n",
      "epoch 122; iter: 0; batch classifier loss: 0.390508; batch adversarial loss: 0.545026\n",
      "epoch 123; iter: 0; batch classifier loss: 0.439991; batch adversarial loss: 0.599200\n",
      "epoch 124; iter: 0; batch classifier loss: 0.342379; batch adversarial loss: 0.562845\n",
      "epoch 125; iter: 0; batch classifier loss: 0.404770; batch adversarial loss: 0.553588\n",
      "epoch 126; iter: 0; batch classifier loss: 0.442286; batch adversarial loss: 0.590042\n",
      "epoch 127; iter: 0; batch classifier loss: 0.357873; batch adversarial loss: 0.525915\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 128; iter: 0; batch classifier loss: 0.310766; batch adversarial loss: 0.553376\n",
      "epoch 129; iter: 0; batch classifier loss: 0.383366; batch adversarial loss: 0.572466\n",
      "epoch 130; iter: 0; batch classifier loss: 0.315776; batch adversarial loss: 0.590222\n",
      "epoch 131; iter: 0; batch classifier loss: 0.345257; batch adversarial loss: 0.562843\n",
      "epoch 132; iter: 0; batch classifier loss: 0.377597; batch adversarial loss: 0.535023\n",
      "epoch 133; iter: 0; batch classifier loss: 0.385997; batch adversarial loss: 0.599362\n",
      "epoch 134; iter: 0; batch classifier loss: 0.417962; batch adversarial loss: 0.526540\n",
      "epoch 135; iter: 0; batch classifier loss: 0.398325; batch adversarial loss: 0.452995\n",
      "epoch 136; iter: 0; batch classifier loss: 0.422713; batch adversarial loss: 0.507839\n",
      "epoch 137; iter: 0; batch classifier loss: 0.321906; batch adversarial loss: 0.517488\n",
      "epoch 138; iter: 0; batch classifier loss: 0.428929; batch adversarial loss: 0.571682\n",
      "epoch 139; iter: 0; batch classifier loss: 0.374996; batch adversarial loss: 0.590107\n",
      "epoch 140; iter: 0; batch classifier loss: 0.387976; batch adversarial loss: 0.572314\n",
      "epoch 141; iter: 0; batch classifier loss: 0.382492; batch adversarial loss: 0.535759\n",
      "epoch 142; iter: 0; batch classifier loss: 0.315949; batch adversarial loss: 0.517400\n",
      "epoch 143; iter: 0; batch classifier loss: 0.325731; batch adversarial loss: 0.553722\n",
      "epoch 144; iter: 0; batch classifier loss: 0.363616; batch adversarial loss: 0.526507\n",
      "epoch 145; iter: 0; batch classifier loss: 0.436694; batch adversarial loss: 0.508085\n",
      "epoch 146; iter: 0; batch classifier loss: 0.493645; batch adversarial loss: 0.553642\n",
      "epoch 147; iter: 0; batch classifier loss: 0.361835; batch adversarial loss: 0.599312\n",
      "epoch 148; iter: 0; batch classifier loss: 0.363665; batch adversarial loss: 0.571870\n",
      "epoch 149; iter: 0; batch classifier loss: 0.354362; batch adversarial loss: 0.562502\n",
      "epoch 150; iter: 0; batch classifier loss: 0.327170; batch adversarial loss: 0.626982\n",
      "epoch 151; iter: 0; batch classifier loss: 0.312439; batch adversarial loss: 0.599250\n",
      "epoch 152; iter: 0; batch classifier loss: 0.326350; batch adversarial loss: 0.553897\n",
      "epoch 153; iter: 0; batch classifier loss: 0.381962; batch adversarial loss: 0.489951\n",
      "epoch 154; iter: 0; batch classifier loss: 0.290189; batch adversarial loss: 0.608452\n",
      "epoch 155; iter: 0; batch classifier loss: 0.329240; batch adversarial loss: 0.617567\n",
      "epoch 156; iter: 0; batch classifier loss: 0.350946; batch adversarial loss: 0.490021\n",
      "epoch 157; iter: 0; batch classifier loss: 0.400054; batch adversarial loss: 0.544537\n",
      "epoch 158; iter: 0; batch classifier loss: 0.354609; batch adversarial loss: 0.526412\n",
      "epoch 159; iter: 0; batch classifier loss: 0.420294; batch adversarial loss: 0.517367\n",
      "epoch 160; iter: 0; batch classifier loss: 0.314333; batch adversarial loss: 0.571751\n",
      "epoch 161; iter: 0; batch classifier loss: 0.374927; batch adversarial loss: 0.544400\n",
      "epoch 162; iter: 0; batch classifier loss: 0.318387; batch adversarial loss: 0.516834\n",
      "epoch 163; iter: 0; batch classifier loss: 0.321962; batch adversarial loss: 0.599108\n",
      "epoch 164; iter: 0; batch classifier loss: 0.356994; batch adversarial loss: 0.553415\n",
      "epoch 165; iter: 0; batch classifier loss: 0.330719; batch adversarial loss: 0.581119\n",
      "epoch 166; iter: 0; batch classifier loss: 0.372795; batch adversarial loss: 0.562849\n",
      "epoch 167; iter: 0; batch classifier loss: 0.371768; batch adversarial loss: 0.489888\n",
      "epoch 168; iter: 0; batch classifier loss: 0.350023; batch adversarial loss: 0.562784\n",
      "epoch 169; iter: 0; batch classifier loss: 0.330807; batch adversarial loss: 0.535519\n",
      "epoch 170; iter: 0; batch classifier loss: 0.405059; batch adversarial loss: 0.571896\n",
      "epoch 171; iter: 0; batch classifier loss: 0.459381; batch adversarial loss: 0.562744\n",
      "epoch 172; iter: 0; batch classifier loss: 0.345870; batch adversarial loss: 0.544422\n",
      "epoch 173; iter: 0; batch classifier loss: 0.358676; batch adversarial loss: 0.535299\n",
      "epoch 174; iter: 0; batch classifier loss: 0.377050; batch adversarial loss: 0.535373\n",
      "epoch 175; iter: 0; batch classifier loss: 0.344111; batch adversarial loss: 0.562643\n",
      "epoch 176; iter: 0; batch classifier loss: 0.308090; batch adversarial loss: 0.590638\n",
      "epoch 177; iter: 0; batch classifier loss: 0.417291; batch adversarial loss: 0.571938\n",
      "epoch 178; iter: 0; batch classifier loss: 0.384750; batch adversarial loss: 0.534845\n",
      "epoch 179; iter: 0; batch classifier loss: 0.307737; batch adversarial loss: 0.544412\n",
      "epoch 180; iter: 0; batch classifier loss: 0.344620; batch adversarial loss: 0.534678\n",
      "epoch 181; iter: 0; batch classifier loss: 0.323860; batch adversarial loss: 0.572030\n",
      "epoch 182; iter: 0; batch classifier loss: 0.327858; batch adversarial loss: 0.599586\n",
      "epoch 183; iter: 0; batch classifier loss: 0.430331; batch adversarial loss: 0.540281\n",
      "epoch 184; iter: 0; batch classifier loss: 0.346462; batch adversarial loss: 0.524803\n",
      "epoch 185; iter: 0; batch classifier loss: 0.492900; batch adversarial loss: 0.570162\n",
      "epoch 186; iter: 0; batch classifier loss: 0.367185; batch adversarial loss: 0.479501\n",
      "epoch 187; iter: 0; batch classifier loss: 0.373171; batch adversarial loss: 0.458908\n",
      "epoch 188; iter: 0; batch classifier loss: 0.314288; batch adversarial loss: 0.523802\n",
      "epoch 189; iter: 0; batch classifier loss: 0.315034; batch adversarial loss: 0.499130\n",
      "epoch 190; iter: 0; batch classifier loss: 0.415717; batch adversarial loss: 0.585324\n",
      "epoch 191; iter: 0; batch classifier loss: 0.375171; batch adversarial loss: 0.578746\n",
      "epoch 192; iter: 0; batch classifier loss: 0.407176; batch adversarial loss: 0.617590\n",
      "epoch 193; iter: 0; batch classifier loss: 0.307530; batch adversarial loss: 0.498348\n",
      "epoch 194; iter: 0; batch classifier loss: 0.348822; batch adversarial loss: 0.543866\n",
      "epoch 195; iter: 0; batch classifier loss: 0.301210; batch adversarial loss: 0.527865\n",
      "epoch 196; iter: 0; batch classifier loss: 0.349528; batch adversarial loss: 0.574607\n",
      "epoch 197; iter: 0; batch classifier loss: 0.398774; batch adversarial loss: 0.534914\n",
      "epoch 198; iter: 0; batch classifier loss: 0.361484; batch adversarial loss: 0.573849\n",
      "epoch 199; iter: 0; batch classifier loss: 0.414868; batch adversarial loss: 0.616390\n",
      "epoch 0; iter: 0; batch classifier loss: 0.713439; batch adversarial loss: 0.698458\n",
      "epoch 1; iter: 0; batch classifier loss: 0.567909; batch adversarial loss: 0.664994\n",
      "epoch 2; iter: 0; batch classifier loss: 0.620964; batch adversarial loss: 0.660073\n",
      "epoch 3; iter: 0; batch classifier loss: 0.547027; batch adversarial loss: 0.663907\n",
      "epoch 4; iter: 0; batch classifier loss: 0.584663; batch adversarial loss: 0.648191\n",
      "epoch 5; iter: 0; batch classifier loss: 0.577815; batch adversarial loss: 0.569173\n",
      "epoch 6; iter: 0; batch classifier loss: 0.494440; batch adversarial loss: 0.628282\n",
      "epoch 7; iter: 0; batch classifier loss: 0.523554; batch adversarial loss: 0.612410\n",
      "epoch 8; iter: 0; batch classifier loss: 0.582932; batch adversarial loss: 0.623663\n",
      "epoch 9; iter: 0; batch classifier loss: 0.490772; batch adversarial loss: 0.610883\n",
      "epoch 10; iter: 0; batch classifier loss: 0.477039; batch adversarial loss: 0.614742\n",
      "epoch 11; iter: 0; batch classifier loss: 0.550867; batch adversarial loss: 0.588020\n",
      "epoch 12; iter: 0; batch classifier loss: 0.535347; batch adversarial loss: 0.600292\n",
      "epoch 13; iter: 0; batch classifier loss: 0.511974; batch adversarial loss: 0.507219\n",
      "epoch 14; iter: 0; batch classifier loss: 0.518007; batch adversarial loss: 0.532711\n",
      "epoch 15; iter: 0; batch classifier loss: 0.578238; batch adversarial loss: 0.622470\n",
      "epoch 16; iter: 0; batch classifier loss: 0.538613; batch adversarial loss: 0.564550\n",
      "epoch 17; iter: 0; batch classifier loss: 0.480474; batch adversarial loss: 0.532546\n",
      "epoch 18; iter: 0; batch classifier loss: 0.521583; batch adversarial loss: 0.604602\n",
      "epoch 19; iter: 0; batch classifier loss: 0.502737; batch adversarial loss: 0.606549\n",
      "epoch 20; iter: 0; batch classifier loss: 0.500986; batch adversarial loss: 0.568019\n",
      "epoch 21; iter: 0; batch classifier loss: 0.487334; batch adversarial loss: 0.599477\n",
      "epoch 22; iter: 0; batch classifier loss: 0.472341; batch adversarial loss: 0.498021\n",
      "epoch 23; iter: 0; batch classifier loss: 0.506448; batch adversarial loss: 0.605278\n",
      "epoch 24; iter: 0; batch classifier loss: 0.494936; batch adversarial loss: 0.529634\n",
      "epoch 25; iter: 0; batch classifier loss: 0.495185; batch adversarial loss: 0.502426\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 26; iter: 0; batch classifier loss: 0.413200; batch adversarial loss: 0.515282\n",
      "epoch 27; iter: 0; batch classifier loss: 0.540532; batch adversarial loss: 0.630036\n",
      "epoch 28; iter: 0; batch classifier loss: 0.494983; batch adversarial loss: 0.544940\n",
      "epoch 29; iter: 0; batch classifier loss: 0.617585; batch adversarial loss: 0.547632\n",
      "epoch 30; iter: 0; batch classifier loss: 0.450257; batch adversarial loss: 0.557962\n",
      "epoch 31; iter: 0; batch classifier loss: 0.447915; batch adversarial loss: 0.531340\n",
      "epoch 32; iter: 0; batch classifier loss: 0.466439; batch adversarial loss: 0.575902\n",
      "epoch 33; iter: 0; batch classifier loss: 0.442344; batch adversarial loss: 0.596024\n",
      "epoch 34; iter: 0; batch classifier loss: 0.451166; batch adversarial loss: 0.546866\n",
      "epoch 35; iter: 0; batch classifier loss: 0.451755; batch adversarial loss: 0.525780\n",
      "epoch 36; iter: 0; batch classifier loss: 0.530203; batch adversarial loss: 0.493496\n",
      "epoch 37; iter: 0; batch classifier loss: 0.414989; batch adversarial loss: 0.511650\n",
      "epoch 38; iter: 0; batch classifier loss: 0.489822; batch adversarial loss: 0.492112\n",
      "epoch 39; iter: 0; batch classifier loss: 0.483786; batch adversarial loss: 0.533303\n",
      "epoch 40; iter: 0; batch classifier loss: 0.512764; batch adversarial loss: 0.501032\n",
      "epoch 41; iter: 0; batch classifier loss: 0.348145; batch adversarial loss: 0.544028\n",
      "epoch 42; iter: 0; batch classifier loss: 0.459996; batch adversarial loss: 0.524963\n",
      "epoch 43; iter: 0; batch classifier loss: 0.412880; batch adversarial loss: 0.582868\n",
      "epoch 44; iter: 0; batch classifier loss: 0.431997; batch adversarial loss: 0.562963\n",
      "epoch 45; iter: 0; batch classifier loss: 0.431331; batch adversarial loss: 0.544132\n",
      "epoch 46; iter: 0; batch classifier loss: 0.421980; batch adversarial loss: 0.555314\n",
      "epoch 47; iter: 0; batch classifier loss: 0.455742; batch adversarial loss: 0.516450\n",
      "epoch 48; iter: 0; batch classifier loss: 0.369998; batch adversarial loss: 0.525842\n",
      "epoch 49; iter: 0; batch classifier loss: 0.434596; batch adversarial loss: 0.602268\n",
      "epoch 50; iter: 0; batch classifier loss: 0.470234; batch adversarial loss: 0.535399\n",
      "epoch 51; iter: 0; batch classifier loss: 0.510415; batch adversarial loss: 0.536125\n",
      "epoch 52; iter: 0; batch classifier loss: 0.450385; batch adversarial loss: 0.508749\n",
      "epoch 53; iter: 0; batch classifier loss: 0.393956; batch adversarial loss: 0.508658\n",
      "epoch 54; iter: 0; batch classifier loss: 0.461020; batch adversarial loss: 0.589567\n",
      "epoch 55; iter: 0; batch classifier loss: 0.437206; batch adversarial loss: 0.580877\n",
      "epoch 56; iter: 0; batch classifier loss: 0.448515; batch adversarial loss: 0.508208\n",
      "epoch 57; iter: 0; batch classifier loss: 0.426235; batch adversarial loss: 0.480420\n",
      "epoch 58; iter: 0; batch classifier loss: 0.496269; batch adversarial loss: 0.544806\n",
      "epoch 59; iter: 0; batch classifier loss: 0.493046; batch adversarial loss: 0.517267\n",
      "epoch 60; iter: 0; batch classifier loss: 0.524730; batch adversarial loss: 0.599658\n",
      "epoch 61; iter: 0; batch classifier loss: 0.498895; batch adversarial loss: 0.553856\n",
      "epoch 62; iter: 0; batch classifier loss: 0.448837; batch adversarial loss: 0.461360\n",
      "epoch 63; iter: 0; batch classifier loss: 0.357242; batch adversarial loss: 0.516806\n",
      "epoch 64; iter: 0; batch classifier loss: 0.459290; batch adversarial loss: 0.553602\n",
      "epoch 65; iter: 0; batch classifier loss: 0.419851; batch adversarial loss: 0.544328\n",
      "epoch 66; iter: 0; batch classifier loss: 0.399061; batch adversarial loss: 0.535083\n",
      "epoch 67; iter: 0; batch classifier loss: 0.387170; batch adversarial loss: 0.563076\n",
      "epoch 68; iter: 0; batch classifier loss: 0.424908; batch adversarial loss: 0.645783\n",
      "epoch 69; iter: 0; batch classifier loss: 0.412688; batch adversarial loss: 0.498605\n",
      "epoch 70; iter: 0; batch classifier loss: 0.385811; batch adversarial loss: 0.471380\n",
      "epoch 71; iter: 0; batch classifier loss: 0.366521; batch adversarial loss: 0.544642\n",
      "epoch 72; iter: 0; batch classifier loss: 0.491141; batch adversarial loss: 0.517472\n",
      "epoch 73; iter: 0; batch classifier loss: 0.415983; batch adversarial loss: 0.581393\n",
      "epoch 74; iter: 0; batch classifier loss: 0.416607; batch adversarial loss: 0.599655\n",
      "epoch 75; iter: 0; batch classifier loss: 0.443861; batch adversarial loss: 0.526105\n",
      "epoch 76; iter: 0; batch classifier loss: 0.440881; batch adversarial loss: 0.581533\n",
      "epoch 77; iter: 0; batch classifier loss: 0.408920; batch adversarial loss: 0.517014\n",
      "epoch 78; iter: 0; batch classifier loss: 0.417715; batch adversarial loss: 0.526310\n",
      "epoch 79; iter: 0; batch classifier loss: 0.451248; batch adversarial loss: 0.581947\n",
      "epoch 80; iter: 0; batch classifier loss: 0.413866; batch adversarial loss: 0.563081\n",
      "epoch 81; iter: 0; batch classifier loss: 0.435537; batch adversarial loss: 0.609092\n",
      "epoch 82; iter: 0; batch classifier loss: 0.395319; batch adversarial loss: 0.544432\n",
      "epoch 83; iter: 0; batch classifier loss: 0.374012; batch adversarial loss: 0.535631\n",
      "epoch 84; iter: 0; batch classifier loss: 0.445092; batch adversarial loss: 0.544986\n",
      "epoch 85; iter: 0; batch classifier loss: 0.433659; batch adversarial loss: 0.497864\n",
      "epoch 86; iter: 0; batch classifier loss: 0.370573; batch adversarial loss: 0.554336\n",
      "epoch 87; iter: 0; batch classifier loss: 0.347442; batch adversarial loss: 0.461676\n",
      "epoch 88; iter: 0; batch classifier loss: 0.372557; batch adversarial loss: 0.535241\n",
      "epoch 89; iter: 0; batch classifier loss: 0.329458; batch adversarial loss: 0.535911\n",
      "epoch 90; iter: 0; batch classifier loss: 0.509987; batch adversarial loss: 0.507812\n",
      "epoch 91; iter: 0; batch classifier loss: 0.386237; batch adversarial loss: 0.517055\n",
      "epoch 92; iter: 0; batch classifier loss: 0.453977; batch adversarial loss: 0.544646\n",
      "epoch 93; iter: 0; batch classifier loss: 0.450980; batch adversarial loss: 0.544572\n",
      "epoch 94; iter: 0; batch classifier loss: 0.375995; batch adversarial loss: 0.479728\n",
      "epoch 95; iter: 0; batch classifier loss: 0.322371; batch adversarial loss: 0.471009\n",
      "epoch 96; iter: 0; batch classifier loss: 0.430052; batch adversarial loss: 0.572651\n",
      "epoch 97; iter: 0; batch classifier loss: 0.362704; batch adversarial loss: 0.498378\n",
      "epoch 98; iter: 0; batch classifier loss: 0.449889; batch adversarial loss: 0.535235\n",
      "epoch 99; iter: 0; batch classifier loss: 0.374994; batch adversarial loss: 0.498882\n",
      "epoch 100; iter: 0; batch classifier loss: 0.367371; batch adversarial loss: 0.673209\n",
      "epoch 101; iter: 0; batch classifier loss: 0.364368; batch adversarial loss: 0.525774\n",
      "epoch 102; iter: 0; batch classifier loss: 0.300228; batch adversarial loss: 0.516619\n",
      "epoch 103; iter: 0; batch classifier loss: 0.445859; batch adversarial loss: 0.627399\n",
      "epoch 104; iter: 0; batch classifier loss: 0.341882; batch adversarial loss: 0.544485\n",
      "epoch 105; iter: 0; batch classifier loss: 0.358320; batch adversarial loss: 0.516861\n",
      "epoch 106; iter: 0; batch classifier loss: 0.438588; batch adversarial loss: 0.498289\n",
      "epoch 107; iter: 0; batch classifier loss: 0.331456; batch adversarial loss: 0.562866\n",
      "epoch 108; iter: 0; batch classifier loss: 0.365799; batch adversarial loss: 0.535761\n",
      "epoch 109; iter: 0; batch classifier loss: 0.412322; batch adversarial loss: 0.599843\n",
      "epoch 110; iter: 0; batch classifier loss: 0.365909; batch adversarial loss: 0.553745\n",
      "epoch 111; iter: 0; batch classifier loss: 0.428121; batch adversarial loss: 0.627124\n",
      "epoch 112; iter: 0; batch classifier loss: 0.433249; batch adversarial loss: 0.498498\n",
      "epoch 113; iter: 0; batch classifier loss: 0.420670; batch adversarial loss: 0.526347\n",
      "epoch 114; iter: 0; batch classifier loss: 0.358234; batch adversarial loss: 0.581591\n",
      "epoch 115; iter: 0; batch classifier loss: 0.370927; batch adversarial loss: 0.470552\n",
      "epoch 116; iter: 0; batch classifier loss: 0.342540; batch adversarial loss: 0.489466\n",
      "epoch 117; iter: 0; batch classifier loss: 0.341478; batch adversarial loss: 0.562647\n",
      "epoch 118; iter: 0; batch classifier loss: 0.452196; batch adversarial loss: 0.626663\n",
      "epoch 119; iter: 0; batch classifier loss: 0.402956; batch adversarial loss: 0.573071\n",
      "epoch 120; iter: 0; batch classifier loss: 0.314664; batch adversarial loss: 0.526734\n",
      "epoch 121; iter: 0; batch classifier loss: 0.297330; batch adversarial loss: 0.535321\n",
      "epoch 122; iter: 0; batch classifier loss: 0.408775; batch adversarial loss: 0.508018\n",
      "epoch 123; iter: 0; batch classifier loss: 0.333116; batch adversarial loss: 0.489044\n",
      "epoch 124; iter: 0; batch classifier loss: 0.406334; batch adversarial loss: 0.563232\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 125; iter: 0; batch classifier loss: 0.391618; batch adversarial loss: 0.498387\n",
      "epoch 126; iter: 0; batch classifier loss: 0.399543; batch adversarial loss: 0.461093\n",
      "epoch 127; iter: 0; batch classifier loss: 0.397589; batch adversarial loss: 0.507357\n",
      "epoch 128; iter: 0; batch classifier loss: 0.352838; batch adversarial loss: 0.526498\n",
      "epoch 129; iter: 0; batch classifier loss: 0.308306; batch adversarial loss: 0.507632\n",
      "epoch 130; iter: 0; batch classifier loss: 0.339187; batch adversarial loss: 0.516684\n",
      "epoch 131; iter: 0; batch classifier loss: 0.365243; batch adversarial loss: 0.508402\n",
      "epoch 132; iter: 0; batch classifier loss: 0.313126; batch adversarial loss: 0.580778\n",
      "epoch 133; iter: 0; batch classifier loss: 0.336766; batch adversarial loss: 0.544736\n",
      "epoch 134; iter: 0; batch classifier loss: 0.381965; batch adversarial loss: 0.526547\n",
      "epoch 135; iter: 0; batch classifier loss: 0.338979; batch adversarial loss: 0.553211\n",
      "epoch 136; iter: 0; batch classifier loss: 0.324441; batch adversarial loss: 0.626791\n",
      "epoch 137; iter: 0; batch classifier loss: 0.426932; batch adversarial loss: 0.516504\n",
      "epoch 138; iter: 0; batch classifier loss: 0.405128; batch adversarial loss: 0.581707\n",
      "epoch 139; iter: 0; batch classifier loss: 0.395188; batch adversarial loss: 0.609037\n",
      "epoch 140; iter: 0; batch classifier loss: 0.385516; batch adversarial loss: 0.599878\n",
      "epoch 141; iter: 0; batch classifier loss: 0.371194; batch adversarial loss: 0.525920\n",
      "epoch 142; iter: 0; batch classifier loss: 0.389331; batch adversarial loss: 0.617915\n",
      "epoch 143; iter: 0; batch classifier loss: 0.424564; batch adversarial loss: 0.507559\n",
      "epoch 144; iter: 0; batch classifier loss: 0.420513; batch adversarial loss: 0.535194\n",
      "epoch 145; iter: 0; batch classifier loss: 0.357569; batch adversarial loss: 0.563152\n",
      "epoch 146; iter: 0; batch classifier loss: 0.366143; batch adversarial loss: 0.599877\n",
      "epoch 147; iter: 0; batch classifier loss: 0.330774; batch adversarial loss: 0.553989\n",
      "epoch 148; iter: 0; batch classifier loss: 0.323044; batch adversarial loss: 0.535074\n",
      "epoch 149; iter: 0; batch classifier loss: 0.368255; batch adversarial loss: 0.517369\n",
      "epoch 150; iter: 0; batch classifier loss: 0.379630; batch adversarial loss: 0.535468\n",
      "epoch 151; iter: 0; batch classifier loss: 0.408355; batch adversarial loss: 0.544402\n",
      "epoch 152; iter: 0; batch classifier loss: 0.326806; batch adversarial loss: 0.516403\n",
      "epoch 153; iter: 0; batch classifier loss: 0.304495; batch adversarial loss: 0.535122\n",
      "epoch 154; iter: 0; batch classifier loss: 0.413267; batch adversarial loss: 0.673409\n",
      "epoch 155; iter: 0; batch classifier loss: 0.326567; batch adversarial loss: 0.553565\n",
      "epoch 156; iter: 0; batch classifier loss: 0.402964; batch adversarial loss: 0.498284\n",
      "epoch 157; iter: 0; batch classifier loss: 0.334553; batch adversarial loss: 0.498818\n",
      "epoch 158; iter: 0; batch classifier loss: 0.474818; batch adversarial loss: 0.544436\n",
      "epoch 159; iter: 0; batch classifier loss: 0.274884; batch adversarial loss: 0.525891\n",
      "epoch 160; iter: 0; batch classifier loss: 0.313535; batch adversarial loss: 0.590275\n",
      "epoch 161; iter: 0; batch classifier loss: 0.340759; batch adversarial loss: 0.572340\n",
      "epoch 162; iter: 0; batch classifier loss: 0.370107; batch adversarial loss: 0.600243\n",
      "epoch 163; iter: 0; batch classifier loss: 0.353849; batch adversarial loss: 0.589962\n",
      "epoch 164; iter: 0; batch classifier loss: 0.292433; batch adversarial loss: 0.580682\n",
      "epoch 165; iter: 0; batch classifier loss: 0.320042; batch adversarial loss: 0.572366\n",
      "epoch 166; iter: 0; batch classifier loss: 0.340998; batch adversarial loss: 0.489259\n",
      "epoch 167; iter: 0; batch classifier loss: 0.346602; batch adversarial loss: 0.544272\n",
      "epoch 168; iter: 0; batch classifier loss: 0.387813; batch adversarial loss: 0.527155\n",
      "epoch 169; iter: 0; batch classifier loss: 0.320603; batch adversarial loss: 0.516513\n",
      "epoch 170; iter: 0; batch classifier loss: 0.352899; batch adversarial loss: 0.498653\n",
      "epoch 171; iter: 0; batch classifier loss: 0.413766; batch adversarial loss: 0.507598\n",
      "epoch 172; iter: 0; batch classifier loss: 0.318962; batch adversarial loss: 0.563045\n",
      "epoch 173; iter: 0; batch classifier loss: 0.371178; batch adversarial loss: 0.572649\n",
      "epoch 174; iter: 0; batch classifier loss: 0.418669; batch adversarial loss: 0.516703\n",
      "epoch 175; iter: 0; batch classifier loss: 0.330247; batch adversarial loss: 0.600048\n",
      "epoch 176; iter: 0; batch classifier loss: 0.394812; batch adversarial loss: 0.589896\n",
      "epoch 177; iter: 0; batch classifier loss: 0.355766; batch adversarial loss: 0.544069\n",
      "epoch 178; iter: 0; batch classifier loss: 0.383870; batch adversarial loss: 0.517200\n",
      "epoch 179; iter: 0; batch classifier loss: 0.456047; batch adversarial loss: 0.571748\n",
      "epoch 180; iter: 0; batch classifier loss: 0.426556; batch adversarial loss: 0.489575\n",
      "epoch 181; iter: 0; batch classifier loss: 0.390227; batch adversarial loss: 0.489066\n",
      "epoch 182; iter: 0; batch classifier loss: 0.391504; batch adversarial loss: 0.526099\n",
      "epoch 183; iter: 0; batch classifier loss: 0.292020; batch adversarial loss: 0.526328\n",
      "epoch 184; iter: 0; batch classifier loss: 0.448849; batch adversarial loss: 0.488413\n",
      "epoch 185; iter: 0; batch classifier loss: 0.375480; batch adversarial loss: 0.470453\n",
      "epoch 186; iter: 0; batch classifier loss: 0.389709; batch adversarial loss: 0.498706\n",
      "epoch 187; iter: 0; batch classifier loss: 0.323249; batch adversarial loss: 0.516797\n",
      "epoch 188; iter: 0; batch classifier loss: 0.347786; batch adversarial loss: 0.553481\n",
      "epoch 189; iter: 0; batch classifier loss: 0.429392; batch adversarial loss: 0.517054\n",
      "epoch 190; iter: 0; batch classifier loss: 0.367552; batch adversarial loss: 0.516978\n",
      "epoch 191; iter: 0; batch classifier loss: 0.422881; batch adversarial loss: 0.553485\n",
      "epoch 192; iter: 0; batch classifier loss: 0.321879; batch adversarial loss: 0.526822\n",
      "epoch 193; iter: 0; batch classifier loss: 0.357726; batch adversarial loss: 0.563029\n",
      "epoch 194; iter: 0; batch classifier loss: 0.343830; batch adversarial loss: 0.563006\n",
      "epoch 195; iter: 0; batch classifier loss: 0.409265; batch adversarial loss: 0.600402\n",
      "epoch 196; iter: 0; batch classifier loss: 0.349124; batch adversarial loss: 0.434030\n",
      "epoch 197; iter: 0; batch classifier loss: 0.363196; batch adversarial loss: 0.508159\n",
      "epoch 198; iter: 0; batch classifier loss: 0.364896; batch adversarial loss: 0.534917\n",
      "epoch 199; iter: 0; batch classifier loss: 0.322874; batch adversarial loss: 0.507325\n",
      "epoch 0; iter: 0; batch classifier loss: 0.679073; batch adversarial loss: 0.712339\n",
      "epoch 1; iter: 0; batch classifier loss: 0.605368; batch adversarial loss: 0.689121\n",
      "epoch 2; iter: 0; batch classifier loss: 0.614988; batch adversarial loss: 0.661325\n",
      "epoch 3; iter: 0; batch classifier loss: 0.561208; batch adversarial loss: 0.640778\n",
      "epoch 4; iter: 0; batch classifier loss: 0.558075; batch adversarial loss: 0.638407\n",
      "epoch 5; iter: 0; batch classifier loss: 0.520546; batch adversarial loss: 0.599980\n",
      "epoch 6; iter: 0; batch classifier loss: 0.494926; batch adversarial loss: 0.562727\n",
      "epoch 7; iter: 0; batch classifier loss: 0.508185; batch adversarial loss: 0.578765\n",
      "epoch 8; iter: 0; batch classifier loss: 0.542972; batch adversarial loss: 0.559145\n",
      "epoch 9; iter: 0; batch classifier loss: 0.466241; batch adversarial loss: 0.534208\n",
      "epoch 10; iter: 0; batch classifier loss: 0.438213; batch adversarial loss: 0.572140\n",
      "epoch 11; iter: 0; batch classifier loss: 0.505565; batch adversarial loss: 0.597796\n",
      "epoch 12; iter: 0; batch classifier loss: 0.502159; batch adversarial loss: 0.636819\n",
      "epoch 13; iter: 0; batch classifier loss: 0.494767; batch adversarial loss: 0.550086\n",
      "epoch 14; iter: 0; batch classifier loss: 0.513884; batch adversarial loss: 0.617289\n",
      "epoch 15; iter: 0; batch classifier loss: 0.536875; batch adversarial loss: 0.646528\n",
      "epoch 16; iter: 0; batch classifier loss: 0.455903; batch adversarial loss: 0.507083\n",
      "epoch 17; iter: 0; batch classifier loss: 0.587726; batch adversarial loss: 0.636007\n",
      "epoch 18; iter: 0; batch classifier loss: 0.576451; batch adversarial loss: 0.617444\n",
      "epoch 19; iter: 0; batch classifier loss: 0.475624; batch adversarial loss: 0.607793\n",
      "epoch 20; iter: 0; batch classifier loss: 0.463365; batch adversarial loss: 0.531803\n",
      "epoch 21; iter: 0; batch classifier loss: 0.445333; batch adversarial loss: 0.540403\n",
      "epoch 22; iter: 0; batch classifier loss: 0.493533; batch adversarial loss: 0.564341\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 23; iter: 0; batch classifier loss: 0.514911; batch adversarial loss: 0.603594\n",
      "epoch 24; iter: 0; batch classifier loss: 0.505356; batch adversarial loss: 0.613470\n",
      "epoch 25; iter: 0; batch classifier loss: 0.521594; batch adversarial loss: 0.558876\n",
      "epoch 26; iter: 0; batch classifier loss: 0.476755; batch adversarial loss: 0.508514\n",
      "epoch 27; iter: 0; batch classifier loss: 0.459694; batch adversarial loss: 0.509085\n",
      "epoch 28; iter: 0; batch classifier loss: 0.487907; batch adversarial loss: 0.579665\n",
      "epoch 29; iter: 0; batch classifier loss: 0.422373; batch adversarial loss: 0.555845\n",
      "epoch 30; iter: 0; batch classifier loss: 0.491531; batch adversarial loss: 0.556065\n",
      "epoch 31; iter: 0; batch classifier loss: 0.434834; batch adversarial loss: 0.520850\n",
      "epoch 32; iter: 0; batch classifier loss: 0.414700; batch adversarial loss: 0.605266\n",
      "epoch 33; iter: 0; batch classifier loss: 0.501602; batch adversarial loss: 0.520634\n",
      "epoch 34; iter: 0; batch classifier loss: 0.451595; batch adversarial loss: 0.574114\n",
      "epoch 35; iter: 0; batch classifier loss: 0.435936; batch adversarial loss: 0.530212\n",
      "epoch 36; iter: 0; batch classifier loss: 0.516560; batch adversarial loss: 0.503353\n",
      "epoch 37; iter: 0; batch classifier loss: 0.454199; batch adversarial loss: 0.519726\n",
      "epoch 38; iter: 0; batch classifier loss: 0.436793; batch adversarial loss: 0.536840\n",
      "epoch 39; iter: 0; batch classifier loss: 0.453549; batch adversarial loss: 0.536790\n",
      "epoch 40; iter: 0; batch classifier loss: 0.457476; batch adversarial loss: 0.553941\n",
      "epoch 41; iter: 0; batch classifier loss: 0.446874; batch adversarial loss: 0.597136\n",
      "epoch 42; iter: 0; batch classifier loss: 0.395580; batch adversarial loss: 0.544927\n",
      "epoch 43; iter: 0; batch classifier loss: 0.380153; batch adversarial loss: 0.562516\n",
      "epoch 44; iter: 0; batch classifier loss: 0.483587; batch adversarial loss: 0.483060\n",
      "epoch 45; iter: 0; batch classifier loss: 0.417767; batch adversarial loss: 0.447143\n",
      "epoch 46; iter: 0; batch classifier loss: 0.432873; batch adversarial loss: 0.518938\n",
      "epoch 47; iter: 0; batch classifier loss: 0.335729; batch adversarial loss: 0.598923\n",
      "epoch 48; iter: 0; batch classifier loss: 0.425013; batch adversarial loss: 0.553015\n",
      "epoch 49; iter: 0; batch classifier loss: 0.435083; batch adversarial loss: 0.615798\n",
      "epoch 50; iter: 0; batch classifier loss: 0.459414; batch adversarial loss: 0.499451\n",
      "epoch 51; iter: 0; batch classifier loss: 0.399615; batch adversarial loss: 0.536607\n",
      "epoch 52; iter: 0; batch classifier loss: 0.467574; batch adversarial loss: 0.536695\n",
      "epoch 53; iter: 0; batch classifier loss: 0.369138; batch adversarial loss: 0.492407\n",
      "epoch 54; iter: 0; batch classifier loss: 0.498199; batch adversarial loss: 0.571786\n",
      "epoch 55; iter: 0; batch classifier loss: 0.384739; batch adversarial loss: 0.545019\n",
      "epoch 56; iter: 0; batch classifier loss: 0.462642; batch adversarial loss: 0.517605\n",
      "epoch 57; iter: 0; batch classifier loss: 0.343254; batch adversarial loss: 0.608136\n",
      "epoch 58; iter: 0; batch classifier loss: 0.352778; batch adversarial loss: 0.553450\n",
      "epoch 59; iter: 0; batch classifier loss: 0.375138; batch adversarial loss: 0.525214\n",
      "epoch 60; iter: 0; batch classifier loss: 0.416924; batch adversarial loss: 0.525602\n",
      "epoch 61; iter: 0; batch classifier loss: 0.444838; batch adversarial loss: 0.490483\n",
      "epoch 62; iter: 0; batch classifier loss: 0.506489; batch adversarial loss: 0.571798\n",
      "epoch 63; iter: 0; batch classifier loss: 0.502816; batch adversarial loss: 0.590658\n",
      "epoch 64; iter: 0; batch classifier loss: 0.462217; batch adversarial loss: 0.561447\n",
      "epoch 65; iter: 0; batch classifier loss: 0.426419; batch adversarial loss: 0.589082\n",
      "epoch 66; iter: 0; batch classifier loss: 0.424836; batch adversarial loss: 0.579740\n",
      "epoch 67; iter: 0; batch classifier loss: 0.365157; batch adversarial loss: 0.490109\n",
      "epoch 68; iter: 0; batch classifier loss: 0.363375; batch adversarial loss: 0.597238\n",
      "epoch 69; iter: 0; batch classifier loss: 0.451996; batch adversarial loss: 0.670280\n",
      "epoch 70; iter: 0; batch classifier loss: 0.386925; batch adversarial loss: 0.562811\n",
      "epoch 71; iter: 0; batch classifier loss: 0.436742; batch adversarial loss: 0.599026\n",
      "epoch 72; iter: 0; batch classifier loss: 0.415152; batch adversarial loss: 0.561774\n",
      "epoch 73; iter: 0; batch classifier loss: 0.408620; batch adversarial loss: 0.499218\n",
      "epoch 74; iter: 0; batch classifier loss: 0.410410; batch adversarial loss: 0.570210\n",
      "epoch 75; iter: 0; batch classifier loss: 0.397465; batch adversarial loss: 0.489970\n",
      "epoch 76; iter: 0; batch classifier loss: 0.303584; batch adversarial loss: 0.581241\n",
      "epoch 77; iter: 0; batch classifier loss: 0.324679; batch adversarial loss: 0.554757\n",
      "epoch 78; iter: 0; batch classifier loss: 0.453047; batch adversarial loss: 0.534801\n",
      "epoch 79; iter: 0; batch classifier loss: 0.447441; batch adversarial loss: 0.570294\n",
      "epoch 80; iter: 0; batch classifier loss: 0.350241; batch adversarial loss: 0.498779\n",
      "epoch 81; iter: 0; batch classifier loss: 0.351470; batch adversarial loss: 0.580212\n",
      "epoch 82; iter: 0; batch classifier loss: 0.460288; batch adversarial loss: 0.599639\n",
      "epoch 83; iter: 0; batch classifier loss: 0.405945; batch adversarial loss: 0.633947\n",
      "epoch 84; iter: 0; batch classifier loss: 0.414109; batch adversarial loss: 0.571456\n",
      "epoch 85; iter: 0; batch classifier loss: 0.473068; batch adversarial loss: 0.651382\n",
      "epoch 86; iter: 0; batch classifier loss: 0.397372; batch adversarial loss: 0.606660\n",
      "epoch 87; iter: 0; batch classifier loss: 0.437266; batch adversarial loss: 0.589787\n",
      "epoch 88; iter: 0; batch classifier loss: 0.376267; batch adversarial loss: 0.544855\n",
      "epoch 89; iter: 0; batch classifier loss: 0.386636; batch adversarial loss: 0.535150\n",
      "epoch 90; iter: 0; batch classifier loss: 0.370040; batch adversarial loss: 0.553356\n",
      "epoch 91; iter: 0; batch classifier loss: 0.419763; batch adversarial loss: 0.589636\n",
      "epoch 92; iter: 0; batch classifier loss: 0.392799; batch adversarial loss: 0.499783\n",
      "epoch 93; iter: 0; batch classifier loss: 0.330305; batch adversarial loss: 0.643031\n",
      "epoch 94; iter: 0; batch classifier loss: 0.370661; batch adversarial loss: 0.554254\n",
      "epoch 95; iter: 0; batch classifier loss: 0.411435; batch adversarial loss: 0.516862\n",
      "epoch 96; iter: 0; batch classifier loss: 0.330437; batch adversarial loss: 0.535125\n",
      "epoch 97; iter: 0; batch classifier loss: 0.336476; batch adversarial loss: 0.491172\n",
      "epoch 98; iter: 0; batch classifier loss: 0.396324; batch adversarial loss: 0.554043\n",
      "epoch 99; iter: 0; batch classifier loss: 0.423232; batch adversarial loss: 0.464203\n",
      "epoch 100; iter: 0; batch classifier loss: 0.341183; batch adversarial loss: 0.634633\n",
      "epoch 101; iter: 0; batch classifier loss: 0.374404; batch adversarial loss: 0.535559\n",
      "epoch 102; iter: 0; batch classifier loss: 0.405268; batch adversarial loss: 0.526768\n",
      "epoch 103; iter: 0; batch classifier loss: 0.389986; batch adversarial loss: 0.544322\n",
      "epoch 104; iter: 0; batch classifier loss: 0.364840; batch adversarial loss: 0.527000\n",
      "epoch 105; iter: 0; batch classifier loss: 0.384209; batch adversarial loss: 0.508183\n",
      "epoch 106; iter: 0; batch classifier loss: 0.438547; batch adversarial loss: 0.624547\n",
      "epoch 107; iter: 0; batch classifier loss: 0.403634; batch adversarial loss: 0.535497\n",
      "epoch 108; iter: 0; batch classifier loss: 0.343200; batch adversarial loss: 0.571769\n",
      "epoch 109; iter: 0; batch classifier loss: 0.346610; batch adversarial loss: 0.508495\n",
      "epoch 110; iter: 0; batch classifier loss: 0.395582; batch adversarial loss: 0.526752\n",
      "epoch 111; iter: 0; batch classifier loss: 0.430453; batch adversarial loss: 0.563059\n",
      "epoch 112; iter: 0; batch classifier loss: 0.372685; batch adversarial loss: 0.526816\n",
      "epoch 113; iter: 0; batch classifier loss: 0.517442; batch adversarial loss: 0.508899\n",
      "epoch 114; iter: 0; batch classifier loss: 0.382049; batch adversarial loss: 0.518010\n",
      "epoch 115; iter: 0; batch classifier loss: 0.401430; batch adversarial loss: 0.527119\n",
      "epoch 116; iter: 0; batch classifier loss: 0.435246; batch adversarial loss: 0.508260\n",
      "epoch 117; iter: 0; batch classifier loss: 0.344075; batch adversarial loss: 0.509759\n",
      "epoch 118; iter: 0; batch classifier loss: 0.373426; batch adversarial loss: 0.509575\n",
      "epoch 119; iter: 0; batch classifier loss: 0.331869; batch adversarial loss: 0.590245\n",
      "epoch 120; iter: 0; batch classifier loss: 0.419729; batch adversarial loss: 0.472374\n",
      "epoch 121; iter: 0; batch classifier loss: 0.355683; batch adversarial loss: 0.535876\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 122; iter: 0; batch classifier loss: 0.373727; batch adversarial loss: 0.571496\n",
      "epoch 123; iter: 0; batch classifier loss: 0.436671; batch adversarial loss: 0.517813\n",
      "epoch 124; iter: 0; batch classifier loss: 0.404180; batch adversarial loss: 0.490956\n",
      "epoch 125; iter: 0; batch classifier loss: 0.337718; batch adversarial loss: 0.526743\n",
      "epoch 126; iter: 0; batch classifier loss: 0.372989; batch adversarial loss: 0.544265\n",
      "epoch 127; iter: 0; batch classifier loss: 0.334752; batch adversarial loss: 0.580580\n",
      "epoch 128; iter: 0; batch classifier loss: 0.419316; batch adversarial loss: 0.527025\n",
      "epoch 129; iter: 0; batch classifier loss: 0.405726; batch adversarial loss: 0.498995\n",
      "epoch 130; iter: 0; batch classifier loss: 0.417583; batch adversarial loss: 0.589280\n",
      "epoch 131; iter: 0; batch classifier loss: 0.425532; batch adversarial loss: 0.499855\n",
      "epoch 132; iter: 0; batch classifier loss: 0.363913; batch adversarial loss: 0.571440\n",
      "epoch 133; iter: 0; batch classifier loss: 0.378476; batch adversarial loss: 0.580456\n",
      "epoch 134; iter: 0; batch classifier loss: 0.338667; batch adversarial loss: 0.562301\n",
      "epoch 135; iter: 0; batch classifier loss: 0.434414; batch adversarial loss: 0.463521\n",
      "epoch 136; iter: 0; batch classifier loss: 0.302957; batch adversarial loss: 0.652149\n",
      "epoch 137; iter: 0; batch classifier loss: 0.383725; batch adversarial loss: 0.553330\n",
      "epoch 138; iter: 0; batch classifier loss: 0.445048; batch adversarial loss: 0.518048\n",
      "epoch 139; iter: 0; batch classifier loss: 0.355997; batch adversarial loss: 0.526511\n",
      "epoch 140; iter: 0; batch classifier loss: 0.318546; batch adversarial loss: 0.545038\n",
      "epoch 141; iter: 0; batch classifier loss: 0.412761; batch adversarial loss: 0.472717\n",
      "epoch 142; iter: 0; batch classifier loss: 0.430696; batch adversarial loss: 0.481424\n",
      "epoch 143; iter: 0; batch classifier loss: 0.359477; batch adversarial loss: 0.535260\n",
      "epoch 144; iter: 0; batch classifier loss: 0.359493; batch adversarial loss: 0.562519\n",
      "epoch 145; iter: 0; batch classifier loss: 0.415879; batch adversarial loss: 0.482149\n",
      "epoch 146; iter: 0; batch classifier loss: 0.304893; batch adversarial loss: 0.553680\n",
      "epoch 147; iter: 0; batch classifier loss: 0.349956; batch adversarial loss: 0.491440\n",
      "epoch 148; iter: 0; batch classifier loss: 0.403340; batch adversarial loss: 0.544808\n",
      "epoch 149; iter: 0; batch classifier loss: 0.448597; batch adversarial loss: 0.544519\n",
      "epoch 150; iter: 0; batch classifier loss: 0.338700; batch adversarial loss: 0.544623\n",
      "epoch 151; iter: 0; batch classifier loss: 0.439153; batch adversarial loss: 0.554533\n",
      "epoch 152; iter: 0; batch classifier loss: 0.482155; batch adversarial loss: 0.571672\n",
      "epoch 153; iter: 0; batch classifier loss: 0.430663; batch adversarial loss: 0.553260\n",
      "epoch 154; iter: 0; batch classifier loss: 0.386377; batch adversarial loss: 0.589683\n",
      "epoch 155; iter: 0; batch classifier loss: 0.462322; batch adversarial loss: 0.634472\n",
      "epoch 156; iter: 0; batch classifier loss: 0.328147; batch adversarial loss: 0.535719\n",
      "epoch 157; iter: 0; batch classifier loss: 0.377133; batch adversarial loss: 0.544550\n",
      "epoch 158; iter: 0; batch classifier loss: 0.382078; batch adversarial loss: 0.526410\n",
      "epoch 159; iter: 0; batch classifier loss: 0.389458; batch adversarial loss: 0.491132\n",
      "epoch 160; iter: 0; batch classifier loss: 0.373620; batch adversarial loss: 0.536155\n",
      "epoch 161; iter: 0; batch classifier loss: 0.429197; batch adversarial loss: 0.508734\n",
      "epoch 162; iter: 0; batch classifier loss: 0.316050; batch adversarial loss: 0.526238\n",
      "epoch 163; iter: 0; batch classifier loss: 0.453288; batch adversarial loss: 0.552931\n",
      "epoch 164; iter: 0; batch classifier loss: 0.345328; batch adversarial loss: 0.544308\n",
      "epoch 165; iter: 0; batch classifier loss: 0.278569; batch adversarial loss: 0.527087\n",
      "epoch 166; iter: 0; batch classifier loss: 0.343454; batch adversarial loss: 0.499899\n",
      "epoch 167; iter: 0; batch classifier loss: 0.401133; batch adversarial loss: 0.490010\n",
      "epoch 168; iter: 0; batch classifier loss: 0.363372; batch adversarial loss: 0.544914\n",
      "epoch 169; iter: 0; batch classifier loss: 0.427223; batch adversarial loss: 0.589159\n",
      "epoch 170; iter: 0; batch classifier loss: 0.431820; batch adversarial loss: 0.652885\n",
      "epoch 171; iter: 0; batch classifier loss: 0.420246; batch adversarial loss: 0.535210\n",
      "epoch 172; iter: 0; batch classifier loss: 0.436209; batch adversarial loss: 0.544624\n",
      "epoch 173; iter: 0; batch classifier loss: 0.386478; batch adversarial loss: 0.571011\n",
      "epoch 174; iter: 0; batch classifier loss: 0.388584; batch adversarial loss: 0.534688\n",
      "epoch 175; iter: 0; batch classifier loss: 0.416420; batch adversarial loss: 0.517791\n",
      "epoch 176; iter: 0; batch classifier loss: 0.399588; batch adversarial loss: 0.562748\n",
      "epoch 177; iter: 0; batch classifier loss: 0.362188; batch adversarial loss: 0.517996\n",
      "epoch 178; iter: 0; batch classifier loss: 0.326451; batch adversarial loss: 0.508609\n",
      "epoch 179; iter: 0; batch classifier loss: 0.427360; batch adversarial loss: 0.571711\n",
      "epoch 180; iter: 0; batch classifier loss: 0.398154; batch adversarial loss: 0.606714\n",
      "epoch 181; iter: 0; batch classifier loss: 0.351403; batch adversarial loss: 0.562332\n",
      "epoch 182; iter: 0; batch classifier loss: 0.349751; batch adversarial loss: 0.606706\n",
      "epoch 183; iter: 0; batch classifier loss: 0.307276; batch adversarial loss: 0.544388\n",
      "epoch 184; iter: 0; batch classifier loss: 0.353822; batch adversarial loss: 0.589272\n",
      "epoch 185; iter: 0; batch classifier loss: 0.357244; batch adversarial loss: 0.473053\n",
      "epoch 186; iter: 0; batch classifier loss: 0.353445; batch adversarial loss: 0.508795\n",
      "epoch 187; iter: 0; batch classifier loss: 0.363174; batch adversarial loss: 0.517328\n",
      "epoch 188; iter: 0; batch classifier loss: 0.354855; batch adversarial loss: 0.499796\n",
      "epoch 189; iter: 0; batch classifier loss: 0.364704; batch adversarial loss: 0.517511\n",
      "epoch 190; iter: 0; batch classifier loss: 0.271661; batch adversarial loss: 0.499781\n",
      "epoch 191; iter: 0; batch classifier loss: 0.310974; batch adversarial loss: 0.552844\n",
      "epoch 192; iter: 0; batch classifier loss: 0.398815; batch adversarial loss: 0.572054\n",
      "epoch 193; iter: 0; batch classifier loss: 0.365123; batch adversarial loss: 0.571842\n",
      "epoch 194; iter: 0; batch classifier loss: 0.407121; batch adversarial loss: 0.499128\n",
      "epoch 195; iter: 0; batch classifier loss: 0.341973; batch adversarial loss: 0.608146\n",
      "epoch 196; iter: 0; batch classifier loss: 0.337872; batch adversarial loss: 0.562828\n",
      "epoch 197; iter: 0; batch classifier loss: 0.348261; batch adversarial loss: 0.587987\n",
      "epoch 198; iter: 0; batch classifier loss: 0.318054; batch adversarial loss: 0.551959\n",
      "epoch 199; iter: 0; batch classifier loss: 0.346215; batch adversarial loss: 0.517145\n",
      "epoch 0; iter: 0; batch classifier loss: 0.720738; batch adversarial loss: 0.921593\n",
      "epoch 1; iter: 0; batch classifier loss: 0.845844; batch adversarial loss: 0.985958\n",
      "epoch 2; iter: 0; batch classifier loss: 0.912577; batch adversarial loss: 0.914289\n",
      "epoch 3; iter: 0; batch classifier loss: 0.938884; batch adversarial loss: 0.840545\n",
      "epoch 4; iter: 0; batch classifier loss: 1.056645; batch adversarial loss: 0.784477\n",
      "epoch 5; iter: 0; batch classifier loss: 1.115781; batch adversarial loss: 0.723500\n",
      "epoch 6; iter: 0; batch classifier loss: 0.816320; batch adversarial loss: 0.647120\n",
      "epoch 7; iter: 0; batch classifier loss: 0.717126; batch adversarial loss: 0.610532\n",
      "epoch 8; iter: 0; batch classifier loss: 0.590949; batch adversarial loss: 0.653712\n",
      "epoch 9; iter: 0; batch classifier loss: 0.570398; batch adversarial loss: 0.578140\n",
      "epoch 10; iter: 0; batch classifier loss: 0.566684; batch adversarial loss: 0.599336\n",
      "epoch 11; iter: 0; batch classifier loss: 0.517018; batch adversarial loss: 0.610798\n",
      "epoch 12; iter: 0; batch classifier loss: 0.527433; batch adversarial loss: 0.540350\n",
      "epoch 13; iter: 0; batch classifier loss: 0.493301; batch adversarial loss: 0.611167\n",
      "epoch 14; iter: 0; batch classifier loss: 0.437117; batch adversarial loss: 0.595338\n",
      "epoch 15; iter: 0; batch classifier loss: 0.534286; batch adversarial loss: 0.554871\n",
      "epoch 16; iter: 0; batch classifier loss: 0.471574; batch adversarial loss: 0.569891\n",
      "epoch 17; iter: 0; batch classifier loss: 0.572608; batch adversarial loss: 0.560526\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 18; iter: 0; batch classifier loss: 0.506822; batch adversarial loss: 0.589446\n",
      "epoch 19; iter: 0; batch classifier loss: 0.587770; batch adversarial loss: 0.472465\n",
      "epoch 20; iter: 0; batch classifier loss: 0.443376; batch adversarial loss: 0.512222\n",
      "epoch 21; iter: 0; batch classifier loss: 0.450261; batch adversarial loss: 0.523578\n",
      "epoch 22; iter: 0; batch classifier loss: 0.476526; batch adversarial loss: 0.585804\n",
      "epoch 23; iter: 0; batch classifier loss: 0.477938; batch adversarial loss: 0.462003\n",
      "epoch 24; iter: 0; batch classifier loss: 0.469590; batch adversarial loss: 0.499165\n",
      "epoch 25; iter: 0; batch classifier loss: 0.510598; batch adversarial loss: 0.563977\n",
      "epoch 26; iter: 0; batch classifier loss: 0.560728; batch adversarial loss: 0.581360\n",
      "epoch 27; iter: 0; batch classifier loss: 0.520518; batch adversarial loss: 0.607885\n",
      "epoch 28; iter: 0; batch classifier loss: 0.473703; batch adversarial loss: 0.566676\n",
      "epoch 29; iter: 0; batch classifier loss: 0.496790; batch adversarial loss: 0.532637\n",
      "epoch 30; iter: 0; batch classifier loss: 0.439115; batch adversarial loss: 0.522222\n",
      "epoch 31; iter: 0; batch classifier loss: 0.493911; batch adversarial loss: 0.552242\n",
      "epoch 32; iter: 0; batch classifier loss: 0.473960; batch adversarial loss: 0.564678\n",
      "epoch 33; iter: 0; batch classifier loss: 0.462633; batch adversarial loss: 0.555176\n",
      "epoch 34; iter: 0; batch classifier loss: 0.475833; batch adversarial loss: 0.528632\n",
      "epoch 35; iter: 0; batch classifier loss: 0.447884; batch adversarial loss: 0.547556\n",
      "epoch 36; iter: 0; batch classifier loss: 0.477153; batch adversarial loss: 0.650243\n",
      "epoch 37; iter: 0; batch classifier loss: 0.450781; batch adversarial loss: 0.540425\n",
      "epoch 38; iter: 0; batch classifier loss: 0.497282; batch adversarial loss: 0.532741\n",
      "epoch 39; iter: 0; batch classifier loss: 0.467424; batch adversarial loss: 0.541256\n",
      "epoch 40; iter: 0; batch classifier loss: 0.431259; batch adversarial loss: 0.659043\n",
      "epoch 41; iter: 0; batch classifier loss: 0.478049; batch adversarial loss: 0.507878\n",
      "epoch 42; iter: 0; batch classifier loss: 0.435930; batch adversarial loss: 0.588704\n",
      "epoch 43; iter: 0; batch classifier loss: 0.436054; batch adversarial loss: 0.615130\n",
      "epoch 44; iter: 0; batch classifier loss: 0.368533; batch adversarial loss: 0.590338\n",
      "epoch 45; iter: 0; batch classifier loss: 0.393183; batch adversarial loss: 0.598660\n",
      "epoch 46; iter: 0; batch classifier loss: 0.346452; batch adversarial loss: 0.518546\n",
      "epoch 47; iter: 0; batch classifier loss: 0.429782; batch adversarial loss: 0.643748\n",
      "epoch 48; iter: 0; batch classifier loss: 0.410208; batch adversarial loss: 0.590396\n",
      "epoch 49; iter: 0; batch classifier loss: 0.468473; batch adversarial loss: 0.597619\n",
      "epoch 50; iter: 0; batch classifier loss: 0.352277; batch adversarial loss: 0.581896\n",
      "epoch 51; iter: 0; batch classifier loss: 0.437471; batch adversarial loss: 0.479429\n",
      "epoch 52; iter: 0; batch classifier loss: 0.414220; batch adversarial loss: 0.481795\n",
      "epoch 53; iter: 0; batch classifier loss: 0.356246; batch adversarial loss: 0.590379\n",
      "epoch 54; iter: 0; batch classifier loss: 0.443950; batch adversarial loss: 0.607134\n",
      "epoch 55; iter: 0; batch classifier loss: 0.394766; batch adversarial loss: 0.526948\n",
      "epoch 56; iter: 0; batch classifier loss: 0.421150; batch adversarial loss: 0.554379\n",
      "epoch 57; iter: 0; batch classifier loss: 0.407332; batch adversarial loss: 0.570581\n",
      "epoch 58; iter: 0; batch classifier loss: 0.467917; batch adversarial loss: 0.516894\n",
      "epoch 59; iter: 0; batch classifier loss: 0.478736; batch adversarial loss: 0.508329\n",
      "epoch 60; iter: 0; batch classifier loss: 0.359499; batch adversarial loss: 0.571695\n",
      "epoch 61; iter: 0; batch classifier loss: 0.408207; batch adversarial loss: 0.499754\n",
      "epoch 62; iter: 0; batch classifier loss: 0.378387; batch adversarial loss: 0.553398\n",
      "epoch 63; iter: 0; batch classifier loss: 0.420077; batch adversarial loss: 0.498919\n",
      "epoch 64; iter: 0; batch classifier loss: 0.414591; batch adversarial loss: 0.525400\n",
      "epoch 65; iter: 0; batch classifier loss: 0.467806; batch adversarial loss: 0.572357\n",
      "epoch 66; iter: 0; batch classifier loss: 0.437880; batch adversarial loss: 0.518580\n",
      "epoch 67; iter: 0; batch classifier loss: 0.365860; batch adversarial loss: 0.581832\n",
      "epoch 68; iter: 0; batch classifier loss: 0.362478; batch adversarial loss: 0.553329\n",
      "epoch 69; iter: 0; batch classifier loss: 0.344197; batch adversarial loss: 0.581025\n",
      "epoch 70; iter: 0; batch classifier loss: 0.410507; batch adversarial loss: 0.498923\n",
      "epoch 71; iter: 0; batch classifier loss: 0.382307; batch adversarial loss: 0.498530\n",
      "epoch 72; iter: 0; batch classifier loss: 0.366990; batch adversarial loss: 0.534863\n",
      "epoch 73; iter: 0; batch classifier loss: 0.367990; batch adversarial loss: 0.564475\n",
      "epoch 74; iter: 0; batch classifier loss: 0.363893; batch adversarial loss: 0.516492\n",
      "epoch 75; iter: 0; batch classifier loss: 0.366684; batch adversarial loss: 0.553414\n",
      "epoch 76; iter: 0; batch classifier loss: 0.466617; batch adversarial loss: 0.535543\n",
      "epoch 77; iter: 0; batch classifier loss: 0.315597; batch adversarial loss: 0.535016\n",
      "epoch 78; iter: 0; batch classifier loss: 0.390991; batch adversarial loss: 0.498863\n",
      "epoch 79; iter: 0; batch classifier loss: 0.356173; batch adversarial loss: 0.590483\n",
      "epoch 80; iter: 0; batch classifier loss: 0.452912; batch adversarial loss: 0.562261\n",
      "epoch 81; iter: 0; batch classifier loss: 0.301254; batch adversarial loss: 0.554771\n",
      "epoch 82; iter: 0; batch classifier loss: 0.372858; batch adversarial loss: 0.580279\n",
      "epoch 83; iter: 0; batch classifier loss: 0.364194; batch adversarial loss: 0.626339\n",
      "epoch 84; iter: 0; batch classifier loss: 0.343047; batch adversarial loss: 0.517076\n",
      "epoch 85; iter: 0; batch classifier loss: 0.393433; batch adversarial loss: 0.608932\n",
      "epoch 86; iter: 0; batch classifier loss: 0.350146; batch adversarial loss: 0.536550\n",
      "epoch 87; iter: 0; batch classifier loss: 0.313105; batch adversarial loss: 0.562683\n",
      "epoch 88; iter: 0; batch classifier loss: 0.376366; batch adversarial loss: 0.628485\n",
      "epoch 89; iter: 0; batch classifier loss: 0.364886; batch adversarial loss: 0.562111\n",
      "epoch 90; iter: 0; batch classifier loss: 0.421436; batch adversarial loss: 0.507778\n",
      "epoch 91; iter: 0; batch classifier loss: 0.331991; batch adversarial loss: 0.589206\n",
      "epoch 92; iter: 0; batch classifier loss: 0.357862; batch adversarial loss: 0.654628\n",
      "epoch 93; iter: 0; batch classifier loss: 0.462250; batch adversarial loss: 0.471239\n",
      "epoch 94; iter: 0; batch classifier loss: 0.350410; batch adversarial loss: 0.481300\n",
      "epoch 95; iter: 0; batch classifier loss: 0.352841; batch adversarial loss: 0.507519\n",
      "epoch 96; iter: 0; batch classifier loss: 0.364485; batch adversarial loss: 0.562583\n",
      "epoch 97; iter: 0; batch classifier loss: 0.413171; batch adversarial loss: 0.461263\n",
      "epoch 98; iter: 0; batch classifier loss: 0.306453; batch adversarial loss: 0.517210\n",
      "epoch 99; iter: 0; batch classifier loss: 0.283758; batch adversarial loss: 0.526380\n",
      "epoch 100; iter: 0; batch classifier loss: 0.329437; batch adversarial loss: 0.580992\n",
      "epoch 101; iter: 0; batch classifier loss: 0.354855; batch adversarial loss: 0.508078\n",
      "epoch 102; iter: 0; batch classifier loss: 0.442893; batch adversarial loss: 0.618241\n",
      "epoch 103; iter: 0; batch classifier loss: 0.393942; batch adversarial loss: 0.581808\n",
      "epoch 104; iter: 0; batch classifier loss: 0.343695; batch adversarial loss: 0.535622\n",
      "epoch 105; iter: 0; batch classifier loss: 0.359508; batch adversarial loss: 0.534688\n",
      "epoch 106; iter: 0; batch classifier loss: 0.351543; batch adversarial loss: 0.637262\n",
      "epoch 107; iter: 0; batch classifier loss: 0.387854; batch adversarial loss: 0.480033\n",
      "epoch 108; iter: 0; batch classifier loss: 0.415441; batch adversarial loss: 0.526172\n",
      "epoch 109; iter: 0; batch classifier loss: 0.345940; batch adversarial loss: 0.572701\n",
      "epoch 110; iter: 0; batch classifier loss: 0.336368; batch adversarial loss: 0.516284\n",
      "epoch 111; iter: 0; batch classifier loss: 0.371183; batch adversarial loss: 0.581236\n",
      "epoch 112; iter: 0; batch classifier loss: 0.388544; batch adversarial loss: 0.488844\n",
      "epoch 113; iter: 0; batch classifier loss: 0.355720; batch adversarial loss: 0.552965\n",
      "epoch 114; iter: 0; batch classifier loss: 0.357616; batch adversarial loss: 0.562583\n",
      "epoch 115; iter: 0; batch classifier loss: 0.300232; batch adversarial loss: 0.526076\n",
      "epoch 116; iter: 0; batch classifier loss: 0.395670; batch adversarial loss: 0.526326\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 117; iter: 0; batch classifier loss: 0.322313; batch adversarial loss: 0.599612\n",
      "epoch 118; iter: 0; batch classifier loss: 0.320722; batch adversarial loss: 0.563017\n",
      "epoch 119; iter: 0; batch classifier loss: 0.273732; batch adversarial loss: 0.543770\n",
      "epoch 120; iter: 0; batch classifier loss: 0.331779; batch adversarial loss: 0.634940\n",
      "epoch 121; iter: 0; batch classifier loss: 0.260712; batch adversarial loss: 0.536146\n",
      "epoch 122; iter: 0; batch classifier loss: 0.400299; batch adversarial loss: 0.535849\n",
      "epoch 123; iter: 0; batch classifier loss: 0.385886; batch adversarial loss: 0.581371\n",
      "epoch 124; iter: 0; batch classifier loss: 0.381411; batch adversarial loss: 0.544701\n",
      "epoch 125; iter: 0; batch classifier loss: 0.340386; batch adversarial loss: 0.580938\n",
      "epoch 126; iter: 0; batch classifier loss: 0.370997; batch adversarial loss: 0.564494\n",
      "epoch 127; iter: 0; batch classifier loss: 0.384883; batch adversarial loss: 0.507704\n",
      "epoch 128; iter: 0; batch classifier loss: 0.270752; batch adversarial loss: 0.561370\n",
      "epoch 129; iter: 0; batch classifier loss: 0.355396; batch adversarial loss: 0.645888\n",
      "epoch 130; iter: 0; batch classifier loss: 0.337245; batch adversarial loss: 0.516059\n",
      "epoch 131; iter: 0; batch classifier loss: 0.357587; batch adversarial loss: 0.550774\n",
      "epoch 132; iter: 0; batch classifier loss: 0.320641; batch adversarial loss: 0.525545\n",
      "epoch 133; iter: 0; batch classifier loss: 0.392064; batch adversarial loss: 0.543120\n",
      "epoch 134; iter: 0; batch classifier loss: 0.366751; batch adversarial loss: 0.489778\n",
      "epoch 135; iter: 0; batch classifier loss: 0.317106; batch adversarial loss: 0.542242\n",
      "epoch 136; iter: 0; batch classifier loss: 0.387028; batch adversarial loss: 0.470139\n",
      "epoch 137; iter: 0; batch classifier loss: 0.377932; batch adversarial loss: 0.591064\n",
      "epoch 138; iter: 0; batch classifier loss: 0.331962; batch adversarial loss: 0.581473\n",
      "epoch 139; iter: 0; batch classifier loss: 0.340096; batch adversarial loss: 0.498466\n",
      "epoch 140; iter: 0; batch classifier loss: 0.295746; batch adversarial loss: 0.571729\n",
      "epoch 141; iter: 0; batch classifier loss: 0.351470; batch adversarial loss: 0.562678\n",
      "epoch 142; iter: 0; batch classifier loss: 0.318943; batch adversarial loss: 0.571373\n",
      "epoch 143; iter: 0; batch classifier loss: 0.412525; batch adversarial loss: 0.453652\n",
      "epoch 144; iter: 0; batch classifier loss: 0.344158; batch adversarial loss: 0.516096\n",
      "epoch 145; iter: 0; batch classifier loss: 0.431944; batch adversarial loss: 0.572720\n",
      "epoch 146; iter: 0; batch classifier loss: 0.341850; batch adversarial loss: 0.544244\n",
      "epoch 147; iter: 0; batch classifier loss: 0.310091; batch adversarial loss: 0.535749\n",
      "epoch 148; iter: 0; batch classifier loss: 0.253732; batch adversarial loss: 0.480260\n",
      "epoch 149; iter: 0; batch classifier loss: 0.320538; batch adversarial loss: 0.544361\n",
      "epoch 150; iter: 0; batch classifier loss: 0.332533; batch adversarial loss: 0.562798\n",
      "epoch 151; iter: 0; batch classifier loss: 0.313499; batch adversarial loss: 0.517441\n",
      "epoch 152; iter: 0; batch classifier loss: 0.346994; batch adversarial loss: 0.581560\n",
      "epoch 153; iter: 0; batch classifier loss: 0.260883; batch adversarial loss: 0.488662\n",
      "epoch 154; iter: 0; batch classifier loss: 0.318865; batch adversarial loss: 0.553672\n",
      "epoch 155; iter: 0; batch classifier loss: 0.299495; batch adversarial loss: 0.488868\n",
      "epoch 156; iter: 0; batch classifier loss: 0.368234; batch adversarial loss: 0.489032\n",
      "epoch 157; iter: 0; batch classifier loss: 0.400366; batch adversarial loss: 0.452028\n",
      "epoch 158; iter: 0; batch classifier loss: 0.338075; batch adversarial loss: 0.517902\n",
      "epoch 159; iter: 0; batch classifier loss: 0.347261; batch adversarial loss: 0.516099\n",
      "epoch 160; iter: 0; batch classifier loss: 0.322321; batch adversarial loss: 0.534417\n",
      "epoch 161; iter: 0; batch classifier loss: 0.261862; batch adversarial loss: 0.553277\n",
      "epoch 162; iter: 0; batch classifier loss: 0.315583; batch adversarial loss: 0.605320\n",
      "epoch 163; iter: 0; batch classifier loss: 0.281366; batch adversarial loss: 0.510593\n",
      "epoch 164; iter: 0; batch classifier loss: 0.365433; batch adversarial loss: 0.491249\n",
      "epoch 165; iter: 0; batch classifier loss: 0.266956; batch adversarial loss: 0.570445\n",
      "epoch 166; iter: 0; batch classifier loss: 0.327096; batch adversarial loss: 0.609741\n",
      "epoch 167; iter: 0; batch classifier loss: 0.340554; batch adversarial loss: 0.615056\n",
      "epoch 168; iter: 0; batch classifier loss: 0.327252; batch adversarial loss: 0.518998\n",
      "epoch 169; iter: 0; batch classifier loss: 0.338888; batch adversarial loss: 0.526367\n",
      "epoch 170; iter: 0; batch classifier loss: 0.322569; batch adversarial loss: 0.567586\n",
      "epoch 171; iter: 0; batch classifier loss: 0.399971; batch adversarial loss: 0.598551\n",
      "epoch 172; iter: 0; batch classifier loss: 0.304320; batch adversarial loss: 0.516611\n",
      "epoch 173; iter: 0; batch classifier loss: 0.287062; batch adversarial loss: 0.480481\n",
      "epoch 174; iter: 0; batch classifier loss: 0.300977; batch adversarial loss: 0.481426\n",
      "epoch 175; iter: 0; batch classifier loss: 0.381221; batch adversarial loss: 0.545539\n",
      "epoch 176; iter: 0; batch classifier loss: 0.297151; batch adversarial loss: 0.499126\n",
      "epoch 177; iter: 0; batch classifier loss: 0.387607; batch adversarial loss: 0.555829\n",
      "epoch 178; iter: 0; batch classifier loss: 0.279564; batch adversarial loss: 0.580884\n",
      "epoch 179; iter: 0; batch classifier loss: 0.337916; batch adversarial loss: 0.525879\n",
      "epoch 180; iter: 0; batch classifier loss: 0.335496; batch adversarial loss: 0.526614\n",
      "epoch 181; iter: 0; batch classifier loss: 0.337652; batch adversarial loss: 0.600785\n",
      "epoch 182; iter: 0; batch classifier loss: 0.322452; batch adversarial loss: 0.618960\n",
      "epoch 183; iter: 0; batch classifier loss: 0.315113; batch adversarial loss: 0.583003\n",
      "epoch 184; iter: 0; batch classifier loss: 0.311831; batch adversarial loss: 0.562737\n",
      "epoch 185; iter: 0; batch classifier loss: 0.329110; batch adversarial loss: 0.543680\n",
      "epoch 186; iter: 0; batch classifier loss: 0.318661; batch adversarial loss: 0.553762\n",
      "epoch 187; iter: 0; batch classifier loss: 0.279564; batch adversarial loss: 0.591589\n",
      "epoch 188; iter: 0; batch classifier loss: 0.406224; batch adversarial loss: 0.588382\n",
      "epoch 189; iter: 0; batch classifier loss: 0.405285; batch adversarial loss: 0.555200\n",
      "epoch 190; iter: 0; batch classifier loss: 0.233370; batch adversarial loss: 0.480484\n",
      "epoch 191; iter: 0; batch classifier loss: 0.316894; batch adversarial loss: 0.626024\n",
      "epoch 192; iter: 0; batch classifier loss: 0.328941; batch adversarial loss: 0.498187\n",
      "epoch 193; iter: 0; batch classifier loss: 0.379624; batch adversarial loss: 0.516769\n",
      "epoch 194; iter: 0; batch classifier loss: 0.390927; batch adversarial loss: 0.526780\n",
      "epoch 195; iter: 0; batch classifier loss: 0.339011; batch adversarial loss: 0.545443\n",
      "epoch 196; iter: 0; batch classifier loss: 0.405324; batch adversarial loss: 0.536759\n",
      "epoch 197; iter: 0; batch classifier loss: 0.319739; batch adversarial loss: 0.543558\n",
      "epoch 198; iter: 0; batch classifier loss: 0.376771; batch adversarial loss: 0.627452\n",
      "epoch 199; iter: 0; batch classifier loss: 0.295106; batch adversarial loss: 0.516891\n",
      "epoch 0; iter: 0; batch classifier loss: 0.652615; batch adversarial loss: 0.765461\n",
      "epoch 1; iter: 0; batch classifier loss: 0.706910; batch adversarial loss: 0.855271\n",
      "epoch 2; iter: 0; batch classifier loss: 0.827027; batch adversarial loss: 0.820832\n",
      "epoch 3; iter: 0; batch classifier loss: 0.895171; batch adversarial loss: 0.752928\n",
      "epoch 4; iter: 0; batch classifier loss: 0.966244; batch adversarial loss: 0.690285\n",
      "epoch 5; iter: 0; batch classifier loss: 0.916089; batch adversarial loss: 0.628563\n",
      "epoch 6; iter: 0; batch classifier loss: 0.635939; batch adversarial loss: 0.618437\n",
      "epoch 7; iter: 0; batch classifier loss: 0.532045; batch adversarial loss: 0.597561\n",
      "epoch 8; iter: 0; batch classifier loss: 0.541858; batch adversarial loss: 0.589111\n",
      "epoch 9; iter: 0; batch classifier loss: 0.573870; batch adversarial loss: 0.577789\n",
      "epoch 10; iter: 0; batch classifier loss: 0.496599; batch adversarial loss: 0.578183\n",
      "epoch 11; iter: 0; batch classifier loss: 0.518314; batch adversarial loss: 0.553513\n",
      "epoch 12; iter: 0; batch classifier loss: 0.521662; batch adversarial loss: 0.625098\n",
      "epoch 13; iter: 0; batch classifier loss: 0.477464; batch adversarial loss: 0.591610\n",
      "epoch 14; iter: 0; batch classifier loss: 0.495958; batch adversarial loss: 0.550344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 15; iter: 0; batch classifier loss: 0.504516; batch adversarial loss: 0.553586\n",
      "epoch 16; iter: 0; batch classifier loss: 0.508993; batch adversarial loss: 0.573197\n",
      "epoch 17; iter: 0; batch classifier loss: 0.497271; batch adversarial loss: 0.540312\n",
      "epoch 18; iter: 0; batch classifier loss: 0.486572; batch adversarial loss: 0.556430\n",
      "epoch 19; iter: 0; batch classifier loss: 0.499548; batch adversarial loss: 0.592305\n",
      "epoch 20; iter: 0; batch classifier loss: 0.531198; batch adversarial loss: 0.505540\n",
      "epoch 21; iter: 0; batch classifier loss: 0.487800; batch adversarial loss: 0.554827\n",
      "epoch 22; iter: 0; batch classifier loss: 0.440013; batch adversarial loss: 0.562793\n",
      "epoch 23; iter: 0; batch classifier loss: 0.412163; batch adversarial loss: 0.608088\n",
      "epoch 24; iter: 0; batch classifier loss: 0.417235; batch adversarial loss: 0.590476\n",
      "epoch 25; iter: 0; batch classifier loss: 0.564273; batch adversarial loss: 0.597774\n",
      "epoch 26; iter: 0; batch classifier loss: 0.564859; batch adversarial loss: 0.554759\n",
      "epoch 27; iter: 0; batch classifier loss: 0.471179; batch adversarial loss: 0.577157\n",
      "epoch 28; iter: 0; batch classifier loss: 0.430835; batch adversarial loss: 0.521832\n",
      "epoch 29; iter: 0; batch classifier loss: 0.431899; batch adversarial loss: 0.531202\n",
      "epoch 30; iter: 0; batch classifier loss: 0.491024; batch adversarial loss: 0.490130\n",
      "epoch 31; iter: 0; batch classifier loss: 0.441531; batch adversarial loss: 0.505149\n",
      "epoch 32; iter: 0; batch classifier loss: 0.444481; batch adversarial loss: 0.536882\n",
      "epoch 33; iter: 0; batch classifier loss: 0.498322; batch adversarial loss: 0.494281\n",
      "epoch 34; iter: 0; batch classifier loss: 0.444129; batch adversarial loss: 0.562971\n",
      "epoch 35; iter: 0; batch classifier loss: 0.453987; batch adversarial loss: 0.447227\n",
      "epoch 36; iter: 0; batch classifier loss: 0.453112; batch adversarial loss: 0.597631\n",
      "epoch 37; iter: 0; batch classifier loss: 0.422825; batch adversarial loss: 0.521329\n",
      "epoch 38; iter: 0; batch classifier loss: 0.442648; batch adversarial loss: 0.594474\n",
      "epoch 39; iter: 0; batch classifier loss: 0.448551; batch adversarial loss: 0.548557\n",
      "epoch 40; iter: 0; batch classifier loss: 0.369217; batch adversarial loss: 0.517247\n",
      "epoch 41; iter: 0; batch classifier loss: 0.484227; batch adversarial loss: 0.490498\n",
      "epoch 42; iter: 0; batch classifier loss: 0.409836; batch adversarial loss: 0.533903\n",
      "epoch 43; iter: 0; batch classifier loss: 0.428904; batch adversarial loss: 0.483703\n",
      "epoch 44; iter: 0; batch classifier loss: 0.458797; batch adversarial loss: 0.585392\n",
      "epoch 45; iter: 0; batch classifier loss: 0.457039; batch adversarial loss: 0.525217\n",
      "epoch 46; iter: 0; batch classifier loss: 0.408408; batch adversarial loss: 0.515753\n",
      "epoch 47; iter: 0; batch classifier loss: 0.437231; batch adversarial loss: 0.567267\n",
      "epoch 48; iter: 0; batch classifier loss: 0.418262; batch adversarial loss: 0.489019\n",
      "epoch 49; iter: 0; batch classifier loss: 0.415975; batch adversarial loss: 0.529429\n",
      "epoch 50; iter: 0; batch classifier loss: 0.353050; batch adversarial loss: 0.571210\n",
      "epoch 51; iter: 0; batch classifier loss: 0.485818; batch adversarial loss: 0.487555\n",
      "epoch 52; iter: 0; batch classifier loss: 0.449666; batch adversarial loss: 0.490498\n",
      "epoch 53; iter: 0; batch classifier loss: 0.509386; batch adversarial loss: 0.574207\n",
      "epoch 54; iter: 0; batch classifier loss: 0.434057; batch adversarial loss: 0.514670\n",
      "epoch 55; iter: 0; batch classifier loss: 0.447118; batch adversarial loss: 0.517630\n",
      "epoch 56; iter: 0; batch classifier loss: 0.441915; batch adversarial loss: 0.489619\n",
      "epoch 57; iter: 0; batch classifier loss: 0.370434; batch adversarial loss: 0.562657\n",
      "epoch 58; iter: 0; batch classifier loss: 0.467750; batch adversarial loss: 0.517620\n",
      "epoch 59; iter: 0; batch classifier loss: 0.353256; batch adversarial loss: 0.553865\n",
      "epoch 60; iter: 0; batch classifier loss: 0.428766; batch adversarial loss: 0.563996\n",
      "epoch 61; iter: 0; batch classifier loss: 0.420086; batch adversarial loss: 0.589064\n",
      "epoch 62; iter: 0; batch classifier loss: 0.394409; batch adversarial loss: 0.500357\n",
      "epoch 63; iter: 0; batch classifier loss: 0.424182; batch adversarial loss: 0.527730\n",
      "epoch 64; iter: 0; batch classifier loss: 0.386029; batch adversarial loss: 0.547409\n",
      "epoch 65; iter: 0; batch classifier loss: 0.413016; batch adversarial loss: 0.527051\n",
      "epoch 66; iter: 0; batch classifier loss: 0.363848; batch adversarial loss: 0.562561\n",
      "epoch 67; iter: 0; batch classifier loss: 0.407608; batch adversarial loss: 0.535671\n",
      "epoch 68; iter: 0; batch classifier loss: 0.352960; batch adversarial loss: 0.509769\n",
      "epoch 69; iter: 0; batch classifier loss: 0.439796; batch adversarial loss: 0.615693\n",
      "epoch 70; iter: 0; batch classifier loss: 0.414400; batch adversarial loss: 0.517882\n",
      "epoch 71; iter: 0; batch classifier loss: 0.360235; batch adversarial loss: 0.572008\n",
      "epoch 72; iter: 0; batch classifier loss: 0.452717; batch adversarial loss: 0.472178\n",
      "epoch 73; iter: 0; batch classifier loss: 0.400929; batch adversarial loss: 0.489890\n",
      "epoch 74; iter: 0; batch classifier loss: 0.310016; batch adversarial loss: 0.508285\n",
      "epoch 75; iter: 0; batch classifier loss: 0.365209; batch adversarial loss: 0.553465\n",
      "epoch 76; iter: 0; batch classifier loss: 0.410832; batch adversarial loss: 0.571310\n",
      "epoch 77; iter: 0; batch classifier loss: 0.385553; batch adversarial loss: 0.590753\n",
      "epoch 78; iter: 0; batch classifier loss: 0.442204; batch adversarial loss: 0.517313\n",
      "epoch 79; iter: 0; batch classifier loss: 0.438801; batch adversarial loss: 0.526798\n",
      "epoch 80; iter: 0; batch classifier loss: 0.403551; batch adversarial loss: 0.589923\n",
      "epoch 81; iter: 0; batch classifier loss: 0.332867; batch adversarial loss: 0.517652\n",
      "epoch 82; iter: 0; batch classifier loss: 0.346202; batch adversarial loss: 0.544561\n",
      "epoch 83; iter: 0; batch classifier loss: 0.397808; batch adversarial loss: 0.516639\n",
      "epoch 84; iter: 0; batch classifier loss: 0.364568; batch adversarial loss: 0.554121\n",
      "epoch 85; iter: 0; batch classifier loss: 0.389680; batch adversarial loss: 0.634831\n",
      "epoch 86; iter: 0; batch classifier loss: 0.301046; batch adversarial loss: 0.507756\n",
      "epoch 87; iter: 0; batch classifier loss: 0.374730; batch adversarial loss: 0.507688\n",
      "epoch 88; iter: 0; batch classifier loss: 0.451718; batch adversarial loss: 0.598747\n",
      "epoch 89; iter: 0; batch classifier loss: 0.382824; batch adversarial loss: 0.553298\n",
      "epoch 90; iter: 0; batch classifier loss: 0.363022; batch adversarial loss: 0.489578\n",
      "epoch 91; iter: 0; batch classifier loss: 0.431258; batch adversarial loss: 0.544067\n",
      "epoch 92; iter: 0; batch classifier loss: 0.332941; batch adversarial loss: 0.590621\n",
      "epoch 93; iter: 0; batch classifier loss: 0.333245; batch adversarial loss: 0.580462\n",
      "epoch 94; iter: 0; batch classifier loss: 0.309190; batch adversarial loss: 0.535299\n",
      "epoch 95; iter: 0; batch classifier loss: 0.315647; batch adversarial loss: 0.544545\n",
      "epoch 96; iter: 0; batch classifier loss: 0.337952; batch adversarial loss: 0.544981\n",
      "epoch 97; iter: 0; batch classifier loss: 0.371046; batch adversarial loss: 0.636466\n",
      "epoch 98; iter: 0; batch classifier loss: 0.273008; batch adversarial loss: 0.498692\n",
      "epoch 99; iter: 0; batch classifier loss: 0.369568; batch adversarial loss: 0.490031\n",
      "epoch 100; iter: 0; batch classifier loss: 0.418975; batch adversarial loss: 0.589996\n",
      "epoch 101; iter: 0; batch classifier loss: 0.347084; batch adversarial loss: 0.572056\n",
      "epoch 102; iter: 0; batch classifier loss: 0.376864; batch adversarial loss: 0.581411\n",
      "epoch 103; iter: 0; batch classifier loss: 0.301066; batch adversarial loss: 0.581272\n",
      "epoch 104; iter: 0; batch classifier loss: 0.345512; batch adversarial loss: 0.617813\n",
      "epoch 105; iter: 0; batch classifier loss: 0.397809; batch adversarial loss: 0.489695\n",
      "epoch 106; iter: 0; batch classifier loss: 0.403432; batch adversarial loss: 0.544972\n",
      "epoch 107; iter: 0; batch classifier loss: 0.425758; batch adversarial loss: 0.553841\n",
      "epoch 108; iter: 0; batch classifier loss: 0.318458; batch adversarial loss: 0.499236\n",
      "epoch 109; iter: 0; batch classifier loss: 0.309826; batch adversarial loss: 0.544685\n",
      "epoch 110; iter: 0; batch classifier loss: 0.405942; batch adversarial loss: 0.516856\n",
      "epoch 111; iter: 0; batch classifier loss: 0.434683; batch adversarial loss: 0.553475\n",
      "epoch 112; iter: 0; batch classifier loss: 0.316509; batch adversarial loss: 0.508196\n",
      "epoch 113; iter: 0; batch classifier loss: 0.377849; batch adversarial loss: 0.480433\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 114; iter: 0; batch classifier loss: 0.335588; batch adversarial loss: 0.562596\n",
      "epoch 115; iter: 0; batch classifier loss: 0.386913; batch adversarial loss: 0.545370\n",
      "epoch 116; iter: 0; batch classifier loss: 0.365193; batch adversarial loss: 0.588404\n",
      "epoch 117; iter: 0; batch classifier loss: 0.328858; batch adversarial loss: 0.526115\n",
      "epoch 118; iter: 0; batch classifier loss: 0.354606; batch adversarial loss: 0.516057\n",
      "epoch 119; iter: 0; batch classifier loss: 0.328550; batch adversarial loss: 0.516969\n",
      "epoch 120; iter: 0; batch classifier loss: 0.408279; batch adversarial loss: 0.547918\n",
      "epoch 121; iter: 0; batch classifier loss: 0.378369; batch adversarial loss: 0.553714\n",
      "epoch 122; iter: 0; batch classifier loss: 0.313110; batch adversarial loss: 0.599852\n",
      "epoch 123; iter: 0; batch classifier loss: 0.456956; batch adversarial loss: 0.573714\n",
      "epoch 124; iter: 0; batch classifier loss: 0.354346; batch adversarial loss: 0.544391\n",
      "epoch 125; iter: 0; batch classifier loss: 0.369303; batch adversarial loss: 0.516921\n",
      "epoch 126; iter: 0; batch classifier loss: 0.347203; batch adversarial loss: 0.636211\n",
      "epoch 127; iter: 0; batch classifier loss: 0.432317; batch adversarial loss: 0.556056\n",
      "epoch 128; iter: 0; batch classifier loss: 0.324826; batch adversarial loss: 0.534623\n",
      "epoch 129; iter: 0; batch classifier loss: 0.340092; batch adversarial loss: 0.564052\n",
      "epoch 130; iter: 0; batch classifier loss: 0.383999; batch adversarial loss: 0.525088\n",
      "epoch 131; iter: 0; batch classifier loss: 0.321987; batch adversarial loss: 0.581313\n",
      "epoch 132; iter: 0; batch classifier loss: 0.339094; batch adversarial loss: 0.561982\n",
      "epoch 133; iter: 0; batch classifier loss: 0.384861; batch adversarial loss: 0.591612\n",
      "epoch 134; iter: 0; batch classifier loss: 0.290488; batch adversarial loss: 0.571751\n",
      "epoch 135; iter: 0; batch classifier loss: 0.363321; batch adversarial loss: 0.589607\n",
      "epoch 136; iter: 0; batch classifier loss: 0.328693; batch adversarial loss: 0.562800\n",
      "epoch 137; iter: 0; batch classifier loss: 0.349931; batch adversarial loss: 0.516273\n",
      "epoch 138; iter: 0; batch classifier loss: 0.338366; batch adversarial loss: 0.564944\n",
      "epoch 139; iter: 0; batch classifier loss: 0.269429; batch adversarial loss: 0.536802\n",
      "epoch 140; iter: 0; batch classifier loss: 0.297362; batch adversarial loss: 0.536332\n",
      "epoch 141; iter: 0; batch classifier loss: 0.351685; batch adversarial loss: 0.526418\n",
      "epoch 142; iter: 0; batch classifier loss: 0.321038; batch adversarial loss: 0.527204\n",
      "epoch 143; iter: 0; batch classifier loss: 0.326038; batch adversarial loss: 0.682496\n",
      "epoch 144; iter: 0; batch classifier loss: 0.415908; batch adversarial loss: 0.472035\n",
      "epoch 145; iter: 0; batch classifier loss: 0.379204; batch adversarial loss: 0.452400\n",
      "epoch 146; iter: 0; batch classifier loss: 0.333108; batch adversarial loss: 0.508303\n",
      "epoch 147; iter: 0; batch classifier loss: 0.330829; batch adversarial loss: 0.598749\n",
      "epoch 148; iter: 0; batch classifier loss: 0.374822; batch adversarial loss: 0.534695\n",
      "epoch 149; iter: 0; batch classifier loss: 0.440343; batch adversarial loss: 0.506720\n",
      "epoch 150; iter: 0; batch classifier loss: 0.308539; batch adversarial loss: 0.526029\n",
      "epoch 151; iter: 0; batch classifier loss: 0.324732; batch adversarial loss: 0.535094\n",
      "epoch 152; iter: 0; batch classifier loss: 0.348133; batch adversarial loss: 0.573021\n",
      "epoch 153; iter: 0; batch classifier loss: 0.269628; batch adversarial loss: 0.646306\n",
      "epoch 154; iter: 0; batch classifier loss: 0.332088; batch adversarial loss: 0.635724\n",
      "epoch 155; iter: 0; batch classifier loss: 0.277673; batch adversarial loss: 0.415626\n",
      "epoch 156; iter: 0; batch classifier loss: 0.325705; batch adversarial loss: 0.535324\n",
      "epoch 157; iter: 0; batch classifier loss: 0.317478; batch adversarial loss: 0.582505\n",
      "epoch 158; iter: 0; batch classifier loss: 0.291417; batch adversarial loss: 0.507908\n",
      "epoch 159; iter: 0; batch classifier loss: 0.343177; batch adversarial loss: 0.535260\n",
      "epoch 160; iter: 0; batch classifier loss: 0.381327; batch adversarial loss: 0.608890\n",
      "epoch 161; iter: 0; batch classifier loss: 0.311197; batch adversarial loss: 0.627924\n",
      "epoch 162; iter: 0; batch classifier loss: 0.343337; batch adversarial loss: 0.597491\n",
      "epoch 163; iter: 0; batch classifier loss: 0.355743; batch adversarial loss: 0.489938\n",
      "epoch 164; iter: 0; batch classifier loss: 0.320874; batch adversarial loss: 0.473217\n",
      "epoch 165; iter: 0; batch classifier loss: 0.261027; batch adversarial loss: 0.609621\n",
      "epoch 166; iter: 0; batch classifier loss: 0.330211; batch adversarial loss: 0.580787\n",
      "epoch 167; iter: 0; batch classifier loss: 0.289071; batch adversarial loss: 0.526204\n",
      "epoch 168; iter: 0; batch classifier loss: 0.278489; batch adversarial loss: 0.564094\n",
      "epoch 169; iter: 0; batch classifier loss: 0.324458; batch adversarial loss: 0.462947\n",
      "epoch 170; iter: 0; batch classifier loss: 0.322206; batch adversarial loss: 0.581439\n",
      "epoch 171; iter: 0; batch classifier loss: 0.262753; batch adversarial loss: 0.617725\n",
      "epoch 172; iter: 0; batch classifier loss: 0.387271; batch adversarial loss: 0.572538\n",
      "epoch 173; iter: 0; batch classifier loss: 0.338593; batch adversarial loss: 0.535518\n",
      "epoch 174; iter: 0; batch classifier loss: 0.289837; batch adversarial loss: 0.517507\n",
      "epoch 175; iter: 0; batch classifier loss: 0.277926; batch adversarial loss: 0.479094\n",
      "epoch 176; iter: 0; batch classifier loss: 0.400598; batch adversarial loss: 0.568751\n",
      "epoch 177; iter: 0; batch classifier loss: 0.291246; batch adversarial loss: 0.581434\n",
      "epoch 178; iter: 0; batch classifier loss: 0.279076; batch adversarial loss: 0.471988\n",
      "epoch 179; iter: 0; batch classifier loss: 0.338243; batch adversarial loss: 0.563614\n",
      "epoch 180; iter: 0; batch classifier loss: 0.311053; batch adversarial loss: 0.499482\n",
      "epoch 181; iter: 0; batch classifier loss: 0.330234; batch adversarial loss: 0.562209\n",
      "epoch 182; iter: 0; batch classifier loss: 0.384467; batch adversarial loss: 0.608704\n",
      "epoch 183; iter: 0; batch classifier loss: 0.361337; batch adversarial loss: 0.535605\n",
      "epoch 184; iter: 0; batch classifier loss: 0.372914; batch adversarial loss: 0.507994\n",
      "epoch 185; iter: 0; batch classifier loss: 0.310304; batch adversarial loss: 0.526054\n",
      "epoch 186; iter: 0; batch classifier loss: 0.338637; batch adversarial loss: 0.581707\n",
      "epoch 187; iter: 0; batch classifier loss: 0.322633; batch adversarial loss: 0.581183\n",
      "epoch 188; iter: 0; batch classifier loss: 0.376878; batch adversarial loss: 0.589858\n",
      "epoch 189; iter: 0; batch classifier loss: 0.292257; batch adversarial loss: 0.608650\n",
      "epoch 190; iter: 0; batch classifier loss: 0.301271; batch adversarial loss: 0.571195\n",
      "epoch 191; iter: 0; batch classifier loss: 0.295697; batch adversarial loss: 0.562442\n",
      "epoch 192; iter: 0; batch classifier loss: 0.302413; batch adversarial loss: 0.580366\n",
      "epoch 193; iter: 0; batch classifier loss: 0.416686; batch adversarial loss: 0.572220\n",
      "epoch 194; iter: 0; batch classifier loss: 0.326956; batch adversarial loss: 0.516115\n",
      "epoch 195; iter: 0; batch classifier loss: 0.291837; batch adversarial loss: 0.562513\n",
      "epoch 196; iter: 0; batch classifier loss: 0.285679; batch adversarial loss: 0.463335\n",
      "epoch 197; iter: 0; batch classifier loss: 0.363137; batch adversarial loss: 0.517187\n",
      "epoch 198; iter: 0; batch classifier loss: 0.322172; batch adversarial loss: 0.553753\n",
      "epoch 199; iter: 0; batch classifier loss: 0.289804; batch adversarial loss: 0.571741\n",
      "epoch 0; iter: 0; batch classifier loss: 0.708854; batch adversarial loss: 0.556954\n",
      "epoch 1; iter: 0; batch classifier loss: 0.614156; batch adversarial loss: 0.605162\n",
      "epoch 2; iter: 0; batch classifier loss: 0.590218; batch adversarial loss: 0.636074\n",
      "epoch 3; iter: 0; batch classifier loss: 0.606783; batch adversarial loss: 0.667119\n",
      "epoch 4; iter: 0; batch classifier loss: 0.524355; batch adversarial loss: 0.648370\n",
      "epoch 5; iter: 0; batch classifier loss: 0.555400; batch adversarial loss: 0.650860\n",
      "epoch 6; iter: 0; batch classifier loss: 0.593681; batch adversarial loss: 0.608313\n",
      "epoch 7; iter: 0; batch classifier loss: 0.650454; batch adversarial loss: 0.634250\n",
      "epoch 8; iter: 0; batch classifier loss: 0.540200; batch adversarial loss: 0.612009\n",
      "epoch 9; iter: 0; batch classifier loss: 0.620344; batch adversarial loss: 0.618491\n",
      "epoch 10; iter: 0; batch classifier loss: 0.603461; batch adversarial loss: 0.561897\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11; iter: 0; batch classifier loss: 0.485877; batch adversarial loss: 0.588001\n",
      "epoch 12; iter: 0; batch classifier loss: 0.521957; batch adversarial loss: 0.590862\n",
      "epoch 13; iter: 0; batch classifier loss: 0.485564; batch adversarial loss: 0.580655\n",
      "epoch 14; iter: 0; batch classifier loss: 0.559611; batch adversarial loss: 0.511422\n",
      "epoch 15; iter: 0; batch classifier loss: 0.451990; batch adversarial loss: 0.549055\n",
      "epoch 16; iter: 0; batch classifier loss: 0.452494; batch adversarial loss: 0.542474\n",
      "epoch 17; iter: 0; batch classifier loss: 0.487042; batch adversarial loss: 0.594888\n",
      "epoch 18; iter: 0; batch classifier loss: 0.492384; batch adversarial loss: 0.498457\n",
      "epoch 19; iter: 0; batch classifier loss: 0.437553; batch adversarial loss: 0.556871\n",
      "epoch 20; iter: 0; batch classifier loss: 0.439884; batch adversarial loss: 0.516919\n",
      "epoch 21; iter: 0; batch classifier loss: 0.444720; batch adversarial loss: 0.499876\n",
      "epoch 22; iter: 0; batch classifier loss: 0.457216; batch adversarial loss: 0.519270\n",
      "epoch 23; iter: 0; batch classifier loss: 0.428183; batch adversarial loss: 0.546228\n",
      "epoch 24; iter: 0; batch classifier loss: 0.470591; batch adversarial loss: 0.587339\n",
      "epoch 25; iter: 0; batch classifier loss: 0.469995; batch adversarial loss: 0.538359\n",
      "epoch 26; iter: 0; batch classifier loss: 0.418984; batch adversarial loss: 0.536331\n",
      "epoch 27; iter: 0; batch classifier loss: 0.442201; batch adversarial loss: 0.553146\n",
      "epoch 28; iter: 0; batch classifier loss: 0.424708; batch adversarial loss: 0.553548\n",
      "epoch 29; iter: 0; batch classifier loss: 0.476538; batch adversarial loss: 0.447949\n",
      "epoch 30; iter: 0; batch classifier loss: 0.396564; batch adversarial loss: 0.598641\n",
      "epoch 31; iter: 0; batch classifier loss: 0.418100; batch adversarial loss: 0.545090\n",
      "epoch 32; iter: 0; batch classifier loss: 0.495305; batch adversarial loss: 0.528079\n",
      "epoch 33; iter: 0; batch classifier loss: 0.442605; batch adversarial loss: 0.592072\n",
      "epoch 34; iter: 0; batch classifier loss: 0.461277; batch adversarial loss: 0.572947\n",
      "epoch 35; iter: 0; batch classifier loss: 0.464755; batch adversarial loss: 0.636194\n",
      "epoch 36; iter: 0; batch classifier loss: 0.490119; batch adversarial loss: 0.525708\n",
      "epoch 37; iter: 0; batch classifier loss: 0.389571; batch adversarial loss: 0.545000\n",
      "epoch 38; iter: 0; batch classifier loss: 0.478929; batch adversarial loss: 0.507946\n",
      "epoch 39; iter: 0; batch classifier loss: 0.515730; batch adversarial loss: 0.488722\n",
      "epoch 40; iter: 0; batch classifier loss: 0.404005; batch adversarial loss: 0.562951\n",
      "epoch 41; iter: 0; batch classifier loss: 0.444018; batch adversarial loss: 0.534902\n",
      "epoch 42; iter: 0; batch classifier loss: 0.457764; batch adversarial loss: 0.507107\n",
      "epoch 43; iter: 0; batch classifier loss: 0.427680; batch adversarial loss: 0.525676\n",
      "epoch 44; iter: 0; batch classifier loss: 0.412070; batch adversarial loss: 0.544690\n",
      "epoch 45; iter: 0; batch classifier loss: 0.498474; batch adversarial loss: 0.553889\n",
      "epoch 46; iter: 0; batch classifier loss: 0.366155; batch adversarial loss: 0.544686\n",
      "epoch 47; iter: 0; batch classifier loss: 0.392002; batch adversarial loss: 0.591779\n",
      "epoch 48; iter: 0; batch classifier loss: 0.388469; batch adversarial loss: 0.572989\n",
      "epoch 49; iter: 0; batch classifier loss: 0.410148; batch adversarial loss: 0.600891\n",
      "epoch 50; iter: 0; batch classifier loss: 0.417171; batch adversarial loss: 0.544266\n",
      "epoch 51; iter: 0; batch classifier loss: 0.455688; batch adversarial loss: 0.498180\n",
      "epoch 52; iter: 0; batch classifier loss: 0.398557; batch adversarial loss: 0.571787\n",
      "epoch 53; iter: 0; batch classifier loss: 0.344002; batch adversarial loss: 0.535918\n",
      "epoch 54; iter: 0; batch classifier loss: 0.387482; batch adversarial loss: 0.515357\n",
      "epoch 55; iter: 0; batch classifier loss: 0.429043; batch adversarial loss: 0.469033\n",
      "epoch 56; iter: 0; batch classifier loss: 0.477075; batch adversarial loss: 0.522907\n",
      "epoch 57; iter: 0; batch classifier loss: 0.454378; batch adversarial loss: 0.485890\n",
      "epoch 58; iter: 0; batch classifier loss: 0.395695; batch adversarial loss: 0.566590\n",
      "epoch 59; iter: 0; batch classifier loss: 0.476345; batch adversarial loss: 0.437262\n",
      "epoch 60; iter: 0; batch classifier loss: 0.477222; batch adversarial loss: 0.607598\n",
      "epoch 61; iter: 0; batch classifier loss: 0.451948; batch adversarial loss: 0.540041\n",
      "epoch 62; iter: 0; batch classifier loss: 0.410802; batch adversarial loss: 0.487981\n",
      "epoch 63; iter: 0; batch classifier loss: 0.383635; batch adversarial loss: 0.566094\n",
      "epoch 64; iter: 0; batch classifier loss: 0.389721; batch adversarial loss: 0.545406\n",
      "epoch 65; iter: 0; batch classifier loss: 0.389735; batch adversarial loss: 0.487706\n",
      "epoch 66; iter: 0; batch classifier loss: 0.474837; batch adversarial loss: 0.601485\n",
      "epoch 67; iter: 0; batch classifier loss: 0.352257; batch adversarial loss: 0.583623\n",
      "epoch 68; iter: 0; batch classifier loss: 0.417075; batch adversarial loss: 0.534280\n",
      "epoch 69; iter: 0; batch classifier loss: 0.365030; batch adversarial loss: 0.535448\n",
      "epoch 70; iter: 0; batch classifier loss: 0.425419; batch adversarial loss: 0.553803\n",
      "epoch 71; iter: 0; batch classifier loss: 0.411348; batch adversarial loss: 0.563888\n",
      "epoch 72; iter: 0; batch classifier loss: 0.385736; batch adversarial loss: 0.450387\n",
      "epoch 73; iter: 0; batch classifier loss: 0.387441; batch adversarial loss: 0.526457\n",
      "epoch 74; iter: 0; batch classifier loss: 0.460539; batch adversarial loss: 0.554519\n",
      "epoch 75; iter: 0; batch classifier loss: 0.365151; batch adversarial loss: 0.449942\n",
      "epoch 76; iter: 0; batch classifier loss: 0.398799; batch adversarial loss: 0.497109\n",
      "epoch 77; iter: 0; batch classifier loss: 0.405907; batch adversarial loss: 0.498397\n",
      "epoch 78; iter: 0; batch classifier loss: 0.396680; batch adversarial loss: 0.620123\n",
      "epoch 79; iter: 0; batch classifier loss: 0.498207; batch adversarial loss: 0.581751\n",
      "epoch 80; iter: 0; batch classifier loss: 0.459342; batch adversarial loss: 0.440133\n",
      "epoch 81; iter: 0; batch classifier loss: 0.344365; batch adversarial loss: 0.497326\n",
      "epoch 82; iter: 0; batch classifier loss: 0.373221; batch adversarial loss: 0.516520\n",
      "epoch 83; iter: 0; batch classifier loss: 0.524481; batch adversarial loss: 0.526166\n",
      "epoch 84; iter: 0; batch classifier loss: 0.381496; batch adversarial loss: 0.535578\n",
      "epoch 85; iter: 0; batch classifier loss: 0.419290; batch adversarial loss: 0.582315\n",
      "epoch 86; iter: 0; batch classifier loss: 0.377018; batch adversarial loss: 0.526186\n",
      "epoch 87; iter: 0; batch classifier loss: 0.410125; batch adversarial loss: 0.488092\n",
      "epoch 88; iter: 0; batch classifier loss: 0.366546; batch adversarial loss: 0.543611\n",
      "epoch 89; iter: 0; batch classifier loss: 0.507642; batch adversarial loss: 0.563315\n",
      "epoch 90; iter: 0; batch classifier loss: 0.498923; batch adversarial loss: 0.562655\n",
      "epoch 91; iter: 0; batch classifier loss: 0.382073; batch adversarial loss: 0.525889\n",
      "epoch 92; iter: 0; batch classifier loss: 0.387899; batch adversarial loss: 0.544688\n",
      "epoch 93; iter: 0; batch classifier loss: 0.388269; batch adversarial loss: 0.572113\n",
      "epoch 94; iter: 0; batch classifier loss: 0.404356; batch adversarial loss: 0.459778\n",
      "epoch 95; iter: 0; batch classifier loss: 0.437543; batch adversarial loss: 0.525037\n",
      "epoch 96; iter: 0; batch classifier loss: 0.402572; batch adversarial loss: 0.516762\n",
      "epoch 97; iter: 0; batch classifier loss: 0.338960; batch adversarial loss: 0.525210\n",
      "epoch 98; iter: 0; batch classifier loss: 0.410468; batch adversarial loss: 0.553219\n",
      "epoch 99; iter: 0; batch classifier loss: 0.355159; batch adversarial loss: 0.545674\n",
      "epoch 100; iter: 0; batch classifier loss: 0.430925; batch adversarial loss: 0.486820\n",
      "epoch 101; iter: 0; batch classifier loss: 0.332756; batch adversarial loss: 0.619434\n",
      "epoch 102; iter: 0; batch classifier loss: 0.363018; batch adversarial loss: 0.516991\n",
      "epoch 103; iter: 0; batch classifier loss: 0.458059; batch adversarial loss: 0.563245\n",
      "epoch 104; iter: 0; batch classifier loss: 0.460537; batch adversarial loss: 0.488065\n",
      "epoch 105; iter: 0; batch classifier loss: 0.421684; batch adversarial loss: 0.490397\n",
      "epoch 106; iter: 0; batch classifier loss: 0.399293; batch adversarial loss: 0.488351\n",
      "epoch 107; iter: 0; batch classifier loss: 0.400713; batch adversarial loss: 0.508123\n",
      "epoch 108; iter: 0; batch classifier loss: 0.379332; batch adversarial loss: 0.543097\n",
      "epoch 109; iter: 0; batch classifier loss: 0.336738; batch adversarial loss: 0.582239\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 110; iter: 0; batch classifier loss: 0.317056; batch adversarial loss: 0.526358\n",
      "epoch 111; iter: 0; batch classifier loss: 0.401705; batch adversarial loss: 0.498078\n",
      "epoch 112; iter: 0; batch classifier loss: 0.447973; batch adversarial loss: 0.522795\n",
      "epoch 113; iter: 0; batch classifier loss: 0.375016; batch adversarial loss: 0.489936\n",
      "epoch 114; iter: 0; batch classifier loss: 0.525354; batch adversarial loss: 0.506429\n",
      "epoch 115; iter: 0; batch classifier loss: 0.487662; batch adversarial loss: 0.583620\n",
      "epoch 116; iter: 0; batch classifier loss: 0.364338; batch adversarial loss: 0.544765\n",
      "epoch 117; iter: 0; batch classifier loss: 0.362629; batch adversarial loss: 0.582872\n",
      "epoch 118; iter: 0; batch classifier loss: 0.402706; batch adversarial loss: 0.544859\n",
      "epoch 119; iter: 0; batch classifier loss: 0.370429; batch adversarial loss: 0.506478\n",
      "epoch 120; iter: 0; batch classifier loss: 0.457981; batch adversarial loss: 0.506976\n",
      "epoch 121; iter: 0; batch classifier loss: 0.362413; batch adversarial loss: 0.478392\n",
      "epoch 122; iter: 0; batch classifier loss: 0.501194; batch adversarial loss: 0.553914\n",
      "epoch 123; iter: 0; batch classifier loss: 0.297342; batch adversarial loss: 0.497663\n",
      "epoch 124; iter: 0; batch classifier loss: 0.357782; batch adversarial loss: 0.478117\n",
      "epoch 125; iter: 0; batch classifier loss: 0.336604; batch adversarial loss: 0.564007\n",
      "epoch 126; iter: 0; batch classifier loss: 0.360658; batch adversarial loss: 0.563949\n",
      "epoch 127; iter: 0; batch classifier loss: 0.349779; batch adversarial loss: 0.554253\n",
      "epoch 128; iter: 0; batch classifier loss: 0.396742; batch adversarial loss: 0.507627\n",
      "epoch 129; iter: 0; batch classifier loss: 0.354786; batch adversarial loss: 0.459542\n",
      "epoch 130; iter: 0; batch classifier loss: 0.362349; batch adversarial loss: 0.592441\n",
      "epoch 131; iter: 0; batch classifier loss: 0.269774; batch adversarial loss: 0.582155\n",
      "epoch 132; iter: 0; batch classifier loss: 0.368718; batch adversarial loss: 0.507258\n",
      "epoch 133; iter: 0; batch classifier loss: 0.457491; batch adversarial loss: 0.507252\n",
      "epoch 134; iter: 0; batch classifier loss: 0.359050; batch adversarial loss: 0.525385\n",
      "epoch 135; iter: 0; batch classifier loss: 0.357207; batch adversarial loss: 0.543986\n",
      "epoch 136; iter: 0; batch classifier loss: 0.381163; batch adversarial loss: 0.524400\n",
      "epoch 137; iter: 0; batch classifier loss: 0.396755; batch adversarial loss: 0.525883\n",
      "epoch 138; iter: 0; batch classifier loss: 0.416651; batch adversarial loss: 0.506252\n",
      "epoch 139; iter: 0; batch classifier loss: 0.386538; batch adversarial loss: 0.618955\n",
      "epoch 140; iter: 0; batch classifier loss: 0.356038; batch adversarial loss: 0.582763\n",
      "epoch 141; iter: 0; batch classifier loss: 0.418170; batch adversarial loss: 0.601737\n",
      "epoch 142; iter: 0; batch classifier loss: 0.360512; batch adversarial loss: 0.542326\n",
      "epoch 143; iter: 0; batch classifier loss: 0.423143; batch adversarial loss: 0.471414\n",
      "epoch 144; iter: 0; batch classifier loss: 0.349227; batch adversarial loss: 0.526995\n",
      "epoch 145; iter: 0; batch classifier loss: 0.312843; batch adversarial loss: 0.572250\n",
      "epoch 146; iter: 0; batch classifier loss: 0.448656; batch adversarial loss: 0.544627\n",
      "epoch 147; iter: 0; batch classifier loss: 0.382749; batch adversarial loss: 0.525776\n",
      "epoch 148; iter: 0; batch classifier loss: 0.326799; batch adversarial loss: 0.525444\n",
      "epoch 149; iter: 0; batch classifier loss: 0.405953; batch adversarial loss: 0.506205\n",
      "epoch 150; iter: 0; batch classifier loss: 0.334265; batch adversarial loss: 0.515517\n",
      "epoch 151; iter: 0; batch classifier loss: 0.300501; batch adversarial loss: 0.563225\n",
      "epoch 152; iter: 0; batch classifier loss: 0.424413; batch adversarial loss: 0.497539\n",
      "epoch 153; iter: 0; batch classifier loss: 0.411119; batch adversarial loss: 0.478798\n",
      "epoch 154; iter: 0; batch classifier loss: 0.371880; batch adversarial loss: 0.506638\n",
      "epoch 155; iter: 0; batch classifier loss: 0.389723; batch adversarial loss: 0.516549\n",
      "epoch 156; iter: 0; batch classifier loss: 0.321354; batch adversarial loss: 0.527992\n",
      "epoch 157; iter: 0; batch classifier loss: 0.313028; batch adversarial loss: 0.487984\n",
      "epoch 158; iter: 0; batch classifier loss: 0.390325; batch adversarial loss: 0.506979\n",
      "epoch 159; iter: 0; batch classifier loss: 0.377100; batch adversarial loss: 0.610764\n",
      "epoch 160; iter: 0; batch classifier loss: 0.362691; batch adversarial loss: 0.564239\n",
      "epoch 161; iter: 0; batch classifier loss: 0.363908; batch adversarial loss: 0.629864\n",
      "epoch 162; iter: 0; batch classifier loss: 0.333846; batch adversarial loss: 0.525806\n",
      "epoch 163; iter: 0; batch classifier loss: 0.270271; batch adversarial loss: 0.592941\n",
      "epoch 164; iter: 0; batch classifier loss: 0.466928; batch adversarial loss: 0.629085\n",
      "epoch 165; iter: 0; batch classifier loss: 0.440921; batch adversarial loss: 0.553153\n",
      "epoch 166; iter: 0; batch classifier loss: 0.387084; batch adversarial loss: 0.610004\n",
      "epoch 167; iter: 0; batch classifier loss: 0.420787; batch adversarial loss: 0.516258\n",
      "epoch 168; iter: 0; batch classifier loss: 0.345520; batch adversarial loss: 0.581490\n",
      "epoch 169; iter: 0; batch classifier loss: 0.348459; batch adversarial loss: 0.552759\n",
      "epoch 170; iter: 0; batch classifier loss: 0.407122; batch adversarial loss: 0.647498\n",
      "epoch 171; iter: 0; batch classifier loss: 0.380317; batch adversarial loss: 0.544168\n",
      "epoch 172; iter: 0; batch classifier loss: 0.354674; batch adversarial loss: 0.486931\n",
      "epoch 173; iter: 0; batch classifier loss: 0.300511; batch adversarial loss: 0.517209\n",
      "epoch 174; iter: 0; batch classifier loss: 0.380465; batch adversarial loss: 0.602019\n",
      "epoch 175; iter: 0; batch classifier loss: 0.308185; batch adversarial loss: 0.563065\n",
      "epoch 176; iter: 0; batch classifier loss: 0.392938; batch adversarial loss: 0.516221\n",
      "epoch 177; iter: 0; batch classifier loss: 0.392446; batch adversarial loss: 0.610976\n",
      "epoch 178; iter: 0; batch classifier loss: 0.360532; batch adversarial loss: 0.526404\n",
      "epoch 179; iter: 0; batch classifier loss: 0.308161; batch adversarial loss: 0.497300\n",
      "epoch 180; iter: 0; batch classifier loss: 0.329158; batch adversarial loss: 0.515686\n",
      "epoch 181; iter: 0; batch classifier loss: 0.338911; batch adversarial loss: 0.564628\n",
      "epoch 182; iter: 0; batch classifier loss: 0.449737; batch adversarial loss: 0.572581\n",
      "epoch 183; iter: 0; batch classifier loss: 0.345437; batch adversarial loss: 0.599814\n",
      "epoch 184; iter: 0; batch classifier loss: 0.360745; batch adversarial loss: 0.526272\n",
      "epoch 185; iter: 0; batch classifier loss: 0.420182; batch adversarial loss: 0.535430\n",
      "epoch 186; iter: 0; batch classifier loss: 0.309911; batch adversarial loss: 0.488955\n",
      "epoch 187; iter: 0; batch classifier loss: 0.378845; batch adversarial loss: 0.611851\n",
      "epoch 188; iter: 0; batch classifier loss: 0.314440; batch adversarial loss: 0.553607\n",
      "epoch 189; iter: 0; batch classifier loss: 0.364064; batch adversarial loss: 0.543183\n",
      "epoch 190; iter: 0; batch classifier loss: 0.341069; batch adversarial loss: 0.505307\n",
      "epoch 191; iter: 0; batch classifier loss: 0.447083; batch adversarial loss: 0.544151\n",
      "epoch 192; iter: 0; batch classifier loss: 0.293799; batch adversarial loss: 0.506234\n",
      "epoch 193; iter: 0; batch classifier loss: 0.383663; batch adversarial loss: 0.497924\n",
      "epoch 194; iter: 0; batch classifier loss: 0.398599; batch adversarial loss: 0.479293\n",
      "epoch 195; iter: 0; batch classifier loss: 0.420026; batch adversarial loss: 0.563335\n",
      "epoch 196; iter: 0; batch classifier loss: 0.352147; batch adversarial loss: 0.497835\n",
      "epoch 197; iter: 0; batch classifier loss: 0.350654; batch adversarial loss: 0.505094\n",
      "epoch 198; iter: 0; batch classifier loss: 0.363559; batch adversarial loss: 0.508306\n",
      "epoch 199; iter: 0; batch classifier loss: 0.366144; batch adversarial loss: 0.507479\n",
      "epoch 0; iter: 0; batch classifier loss: 0.675863; batch adversarial loss: 0.512147\n",
      "epoch 1; iter: 0; batch classifier loss: 0.588067; batch adversarial loss: 0.681841\n",
      "epoch 2; iter: 0; batch classifier loss: 0.580777; batch adversarial loss: 0.697891\n",
      "epoch 3; iter: 0; batch classifier loss: 0.624054; batch adversarial loss: 0.844132\n",
      "epoch 4; iter: 0; batch classifier loss: 0.540719; batch adversarial loss: 0.645505\n",
      "epoch 5; iter: 0; batch classifier loss: 0.593050; batch adversarial loss: 0.706554\n",
      "epoch 6; iter: 0; batch classifier loss: 0.569571; batch adversarial loss: 0.658881\n",
      "epoch 7; iter: 0; batch classifier loss: 0.570534; batch adversarial loss: 0.691657\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8; iter: 0; batch classifier loss: 0.643394; batch adversarial loss: 0.596180\n",
      "epoch 9; iter: 0; batch classifier loss: 0.582700; batch adversarial loss: 0.582013\n",
      "epoch 10; iter: 0; batch classifier loss: 0.570219; batch adversarial loss: 0.606617\n",
      "epoch 11; iter: 0; batch classifier loss: 0.529672; batch adversarial loss: 0.608551\n",
      "epoch 12; iter: 0; batch classifier loss: 0.551964; batch adversarial loss: 0.575185\n",
      "epoch 13; iter: 0; batch classifier loss: 0.702278; batch adversarial loss: 0.526731\n",
      "epoch 14; iter: 0; batch classifier loss: 0.547928; batch adversarial loss: 0.577086\n",
      "epoch 15; iter: 0; batch classifier loss: 0.524648; batch adversarial loss: 0.555648\n",
      "epoch 16; iter: 0; batch classifier loss: 0.454590; batch adversarial loss: 0.536191\n",
      "epoch 17; iter: 0; batch classifier loss: 0.446933; batch adversarial loss: 0.524916\n",
      "epoch 18; iter: 0; batch classifier loss: 0.476585; batch adversarial loss: 0.541693\n",
      "epoch 19; iter: 0; batch classifier loss: 0.472151; batch adversarial loss: 0.497588\n",
      "epoch 20; iter: 0; batch classifier loss: 0.474514; batch adversarial loss: 0.549239\n",
      "epoch 21; iter: 0; batch classifier loss: 0.482414; batch adversarial loss: 0.578678\n",
      "epoch 22; iter: 0; batch classifier loss: 0.492074; batch adversarial loss: 0.593844\n",
      "epoch 23; iter: 0; batch classifier loss: 0.524924; batch adversarial loss: 0.536516\n",
      "epoch 24; iter: 0; batch classifier loss: 0.532203; batch adversarial loss: 0.511143\n",
      "epoch 25; iter: 0; batch classifier loss: 0.509469; batch adversarial loss: 0.573483\n",
      "epoch 26; iter: 0; batch classifier loss: 0.421441; batch adversarial loss: 0.580072\n",
      "epoch 27; iter: 0; batch classifier loss: 0.489632; batch adversarial loss: 0.543223\n",
      "epoch 28; iter: 0; batch classifier loss: 0.507549; batch adversarial loss: 0.595359\n",
      "epoch 29; iter: 0; batch classifier loss: 0.489492; batch adversarial loss: 0.569467\n",
      "epoch 30; iter: 0; batch classifier loss: 0.447272; batch adversarial loss: 0.534678\n",
      "epoch 31; iter: 0; batch classifier loss: 0.402063; batch adversarial loss: 0.551959\n",
      "epoch 32; iter: 0; batch classifier loss: 0.405546; batch adversarial loss: 0.552077\n",
      "epoch 33; iter: 0; batch classifier loss: 0.434713; batch adversarial loss: 0.543859\n",
      "epoch 34; iter: 0; batch classifier loss: 0.432142; batch adversarial loss: 0.651090\n",
      "epoch 35; iter: 0; batch classifier loss: 0.431206; batch adversarial loss: 0.546160\n",
      "epoch 36; iter: 0; batch classifier loss: 0.502816; batch adversarial loss: 0.563310\n",
      "epoch 37; iter: 0; batch classifier loss: 0.458665; batch adversarial loss: 0.527900\n",
      "epoch 38; iter: 0; batch classifier loss: 0.523533; batch adversarial loss: 0.483088\n",
      "epoch 39; iter: 0; batch classifier loss: 0.445850; batch adversarial loss: 0.607304\n",
      "epoch 40; iter: 0; batch classifier loss: 0.441132; batch adversarial loss: 0.527278\n",
      "epoch 41; iter: 0; batch classifier loss: 0.418413; batch adversarial loss: 0.615372\n",
      "epoch 42; iter: 0; batch classifier loss: 0.561485; batch adversarial loss: 0.580453\n",
      "epoch 43; iter: 0; batch classifier loss: 0.423450; batch adversarial loss: 0.544712\n",
      "epoch 44; iter: 0; batch classifier loss: 0.567900; batch adversarial loss: 0.500102\n",
      "epoch 45; iter: 0; batch classifier loss: 0.462764; batch adversarial loss: 0.544712\n",
      "epoch 46; iter: 0; batch classifier loss: 0.481164; batch adversarial loss: 0.544962\n",
      "epoch 47; iter: 0; batch classifier loss: 0.468728; batch adversarial loss: 0.535933\n",
      "epoch 48; iter: 0; batch classifier loss: 0.399328; batch adversarial loss: 0.580361\n",
      "epoch 49; iter: 0; batch classifier loss: 0.418252; batch adversarial loss: 0.544243\n",
      "epoch 50; iter: 0; batch classifier loss: 0.448558; batch adversarial loss: 0.526333\n",
      "epoch 51; iter: 0; batch classifier loss: 0.449107; batch adversarial loss: 0.543679\n",
      "epoch 52; iter: 0; batch classifier loss: 0.492243; batch adversarial loss: 0.481936\n",
      "epoch 53; iter: 0; batch classifier loss: 0.381795; batch adversarial loss: 0.481044\n",
      "epoch 54; iter: 0; batch classifier loss: 0.405642; batch adversarial loss: 0.580563\n",
      "epoch 55; iter: 0; batch classifier loss: 0.459271; batch adversarial loss: 0.535493\n",
      "epoch 56; iter: 0; batch classifier loss: 0.453854; batch adversarial loss: 0.598247\n",
      "epoch 57; iter: 0; batch classifier loss: 0.461180; batch adversarial loss: 0.562884\n",
      "epoch 58; iter: 0; batch classifier loss: 0.381404; batch adversarial loss: 0.543449\n",
      "epoch 59; iter: 0; batch classifier loss: 0.416239; batch adversarial loss: 0.482023\n",
      "epoch 60; iter: 0; batch classifier loss: 0.481732; batch adversarial loss: 0.571474\n",
      "epoch 61; iter: 0; batch classifier loss: 0.368939; batch adversarial loss: 0.560916\n",
      "epoch 62; iter: 0; batch classifier loss: 0.427962; batch adversarial loss: 0.535143\n",
      "epoch 63; iter: 0; batch classifier loss: 0.392125; batch adversarial loss: 0.514933\n",
      "epoch 64; iter: 0; batch classifier loss: 0.406277; batch adversarial loss: 0.588604\n",
      "epoch 65; iter: 0; batch classifier loss: 0.400382; batch adversarial loss: 0.639336\n",
      "epoch 66; iter: 0; batch classifier loss: 0.474431; batch adversarial loss: 0.520607\n",
      "epoch 67; iter: 0; batch classifier loss: 0.413088; batch adversarial loss: 0.517408\n",
      "epoch 68; iter: 0; batch classifier loss: 0.443354; batch adversarial loss: 0.560047\n",
      "epoch 69; iter: 0; batch classifier loss: 0.343599; batch adversarial loss: 0.579017\n",
      "epoch 70; iter: 0; batch classifier loss: 0.470939; batch adversarial loss: 0.568477\n",
      "epoch 71; iter: 0; batch classifier loss: 0.487765; batch adversarial loss: 0.522786\n",
      "epoch 72; iter: 0; batch classifier loss: 0.387363; batch adversarial loss: 0.582432\n",
      "epoch 73; iter: 0; batch classifier loss: 0.489076; batch adversarial loss: 0.509454\n",
      "epoch 74; iter: 0; batch classifier loss: 0.401530; batch adversarial loss: 0.548048\n",
      "epoch 75; iter: 0; batch classifier loss: 0.385039; batch adversarial loss: 0.569492\n",
      "epoch 76; iter: 0; batch classifier loss: 0.387663; batch adversarial loss: 0.517884\n",
      "epoch 77; iter: 0; batch classifier loss: 0.403810; batch adversarial loss: 0.535225\n",
      "epoch 78; iter: 0; batch classifier loss: 0.427592; batch adversarial loss: 0.517240\n",
      "epoch 79; iter: 0; batch classifier loss: 0.430106; batch adversarial loss: 0.506832\n",
      "epoch 80; iter: 0; batch classifier loss: 0.423533; batch adversarial loss: 0.481356\n",
      "epoch 81; iter: 0; batch classifier loss: 0.444080; batch adversarial loss: 0.591243\n",
      "epoch 82; iter: 0; batch classifier loss: 0.360753; batch adversarial loss: 0.544323\n",
      "epoch 83; iter: 0; batch classifier loss: 0.369874; batch adversarial loss: 0.609286\n",
      "epoch 84; iter: 0; batch classifier loss: 0.380246; batch adversarial loss: 0.525567\n",
      "epoch 85; iter: 0; batch classifier loss: 0.426494; batch adversarial loss: 0.518189\n",
      "epoch 86; iter: 0; batch classifier loss: 0.437713; batch adversarial loss: 0.535356\n",
      "epoch 87; iter: 0; batch classifier loss: 0.431845; batch adversarial loss: 0.517075\n",
      "epoch 88; iter: 0; batch classifier loss: 0.388160; batch adversarial loss: 0.589945\n",
      "epoch 89; iter: 0; batch classifier loss: 0.443258; batch adversarial loss: 0.579735\n",
      "epoch 90; iter: 0; batch classifier loss: 0.424635; batch adversarial loss: 0.580730\n",
      "epoch 91; iter: 0; batch classifier loss: 0.441264; batch adversarial loss: 0.490643\n",
      "epoch 92; iter: 0; batch classifier loss: 0.396270; batch adversarial loss: 0.588422\n",
      "epoch 93; iter: 0; batch classifier loss: 0.438042; batch adversarial loss: 0.571007\n",
      "epoch 94; iter: 0; batch classifier loss: 0.388929; batch adversarial loss: 0.631783\n",
      "epoch 95; iter: 0; batch classifier loss: 0.294763; batch adversarial loss: 0.588801\n",
      "epoch 96; iter: 0; batch classifier loss: 0.377649; batch adversarial loss: 0.535323\n",
      "epoch 97; iter: 0; batch classifier loss: 0.451632; batch adversarial loss: 0.536300\n",
      "epoch 98; iter: 0; batch classifier loss: 0.400095; batch adversarial loss: 0.517007\n",
      "epoch 99; iter: 0; batch classifier loss: 0.399052; batch adversarial loss: 0.636079\n",
      "epoch 100; iter: 0; batch classifier loss: 0.443333; batch adversarial loss: 0.563292\n",
      "epoch 101; iter: 0; batch classifier loss: 0.319678; batch adversarial loss: 0.572362\n",
      "epoch 102; iter: 0; batch classifier loss: 0.432648; batch adversarial loss: 0.571196\n",
      "epoch 103; iter: 0; batch classifier loss: 0.360498; batch adversarial loss: 0.561623\n",
      "epoch 104; iter: 0; batch classifier loss: 0.383783; batch adversarial loss: 0.589716\n",
      "epoch 105; iter: 0; batch classifier loss: 0.397768; batch adversarial loss: 0.544998\n",
      "epoch 106; iter: 0; batch classifier loss: 0.365432; batch adversarial loss: 0.508064\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 107; iter: 0; batch classifier loss: 0.450850; batch adversarial loss: 0.574115\n",
      "epoch 108; iter: 0; batch classifier loss: 0.393902; batch adversarial loss: 0.476060\n",
      "epoch 109; iter: 0; batch classifier loss: 0.408646; batch adversarial loss: 0.576991\n",
      "epoch 110; iter: 0; batch classifier loss: 0.343789; batch adversarial loss: 0.605166\n",
      "epoch 111; iter: 0; batch classifier loss: 0.401983; batch adversarial loss: 0.510203\n",
      "epoch 112; iter: 0; batch classifier loss: 0.447403; batch adversarial loss: 0.585816\n",
      "epoch 113; iter: 0; batch classifier loss: 0.439070; batch adversarial loss: 0.518268\n",
      "epoch 114; iter: 0; batch classifier loss: 0.376762; batch adversarial loss: 0.554345\n",
      "epoch 115; iter: 0; batch classifier loss: 0.393918; batch adversarial loss: 0.534130\n",
      "epoch 116; iter: 0; batch classifier loss: 0.381364; batch adversarial loss: 0.589769\n",
      "epoch 117; iter: 0; batch classifier loss: 0.335789; batch adversarial loss: 0.561649\n",
      "epoch 118; iter: 0; batch classifier loss: 0.406574; batch adversarial loss: 0.581541\n",
      "epoch 119; iter: 0; batch classifier loss: 0.399216; batch adversarial loss: 0.489101\n",
      "epoch 120; iter: 0; batch classifier loss: 0.382268; batch adversarial loss: 0.546154\n",
      "epoch 121; iter: 0; batch classifier loss: 0.380822; batch adversarial loss: 0.616455\n",
      "epoch 122; iter: 0; batch classifier loss: 0.349264; batch adversarial loss: 0.590106\n",
      "epoch 123; iter: 0; batch classifier loss: 0.315000; batch adversarial loss: 0.562902\n",
      "epoch 124; iter: 0; batch classifier loss: 0.447215; batch adversarial loss: 0.586292\n",
      "epoch 125; iter: 0; batch classifier loss: 0.371254; batch adversarial loss: 0.525435\n",
      "epoch 126; iter: 0; batch classifier loss: 0.422360; batch adversarial loss: 0.526892\n",
      "epoch 127; iter: 0; batch classifier loss: 0.406913; batch adversarial loss: 0.525049\n",
      "epoch 128; iter: 0; batch classifier loss: 0.380455; batch adversarial loss: 0.581432\n",
      "epoch 129; iter: 0; batch classifier loss: 0.418126; batch adversarial loss: 0.563774\n",
      "epoch 130; iter: 0; batch classifier loss: 0.314777; batch adversarial loss: 0.517379\n",
      "epoch 131; iter: 0; batch classifier loss: 0.456410; batch adversarial loss: 0.599375\n",
      "epoch 132; iter: 0; batch classifier loss: 0.380846; batch adversarial loss: 0.489285\n",
      "epoch 133; iter: 0; batch classifier loss: 0.387427; batch adversarial loss: 0.545895\n",
      "epoch 134; iter: 0; batch classifier loss: 0.362230; batch adversarial loss: 0.516586\n",
      "epoch 135; iter: 0; batch classifier loss: 0.358486; batch adversarial loss: 0.615816\n",
      "epoch 136; iter: 0; batch classifier loss: 0.334902; batch adversarial loss: 0.499276\n",
      "epoch 137; iter: 0; batch classifier loss: 0.367827; batch adversarial loss: 0.600890\n",
      "epoch 138; iter: 0; batch classifier loss: 0.471811; batch adversarial loss: 0.580734\n",
      "epoch 139; iter: 0; batch classifier loss: 0.337244; batch adversarial loss: 0.606946\n",
      "epoch 140; iter: 0; batch classifier loss: 0.479711; batch adversarial loss: 0.598767\n",
      "epoch 141; iter: 0; batch classifier loss: 0.503915; batch adversarial loss: 0.625251\n",
      "epoch 142; iter: 0; batch classifier loss: 0.410831; batch adversarial loss: 0.614777\n",
      "epoch 143; iter: 0; batch classifier loss: 0.326154; batch adversarial loss: 0.571695\n",
      "epoch 144; iter: 0; batch classifier loss: 0.469212; batch adversarial loss: 0.516231\n",
      "epoch 145; iter: 0; batch classifier loss: 0.359295; batch adversarial loss: 0.553231\n",
      "epoch 146; iter: 0; batch classifier loss: 0.383590; batch adversarial loss: 0.518918\n",
      "epoch 147; iter: 0; batch classifier loss: 0.332410; batch adversarial loss: 0.579453\n",
      "epoch 148; iter: 0; batch classifier loss: 0.331673; batch adversarial loss: 0.510206\n",
      "epoch 149; iter: 0; batch classifier loss: 0.448671; batch adversarial loss: 0.527821\n",
      "epoch 150; iter: 0; batch classifier loss: 0.446530; batch adversarial loss: 0.572357\n",
      "epoch 151; iter: 0; batch classifier loss: 0.358047; batch adversarial loss: 0.510446\n",
      "epoch 152; iter: 0; batch classifier loss: 0.287797; batch adversarial loss: 0.553714\n",
      "epoch 153; iter: 0; batch classifier loss: 0.362600; batch adversarial loss: 0.550713\n",
      "epoch 154; iter: 0; batch classifier loss: 0.360435; batch adversarial loss: 0.571690\n",
      "epoch 155; iter: 0; batch classifier loss: 0.377265; batch adversarial loss: 0.553948\n",
      "epoch 156; iter: 0; batch classifier loss: 0.347752; batch adversarial loss: 0.501129\n",
      "epoch 157; iter: 0; batch classifier loss: 0.367650; batch adversarial loss: 0.544747\n",
      "epoch 158; iter: 0; batch classifier loss: 0.360973; batch adversarial loss: 0.544818\n",
      "epoch 159; iter: 0; batch classifier loss: 0.299390; batch adversarial loss: 0.572041\n",
      "epoch 160; iter: 0; batch classifier loss: 0.284260; batch adversarial loss: 0.625066\n",
      "epoch 161; iter: 0; batch classifier loss: 0.426502; batch adversarial loss: 0.617340\n",
      "epoch 162; iter: 0; batch classifier loss: 0.418064; batch adversarial loss: 0.570757\n",
      "epoch 163; iter: 0; batch classifier loss: 0.356476; batch adversarial loss: 0.491597\n",
      "epoch 164; iter: 0; batch classifier loss: 0.386802; batch adversarial loss: 0.553817\n",
      "epoch 165; iter: 0; batch classifier loss: 0.395853; batch adversarial loss: 0.607554\n",
      "epoch 166; iter: 0; batch classifier loss: 0.421316; batch adversarial loss: 0.509910\n",
      "epoch 167; iter: 0; batch classifier loss: 0.360808; batch adversarial loss: 0.651292\n",
      "epoch 168; iter: 0; batch classifier loss: 0.372771; batch adversarial loss: 0.588853\n",
      "epoch 169; iter: 0; batch classifier loss: 0.392467; batch adversarial loss: 0.454088\n",
      "epoch 170; iter: 0; batch classifier loss: 0.341914; batch adversarial loss: 0.589514\n",
      "epoch 171; iter: 0; batch classifier loss: 0.342767; batch adversarial loss: 0.532354\n",
      "epoch 172; iter: 0; batch classifier loss: 0.367731; batch adversarial loss: 0.604355\n",
      "epoch 173; iter: 0; batch classifier loss: 0.413284; batch adversarial loss: 0.631694\n",
      "epoch 174; iter: 0; batch classifier loss: 0.390144; batch adversarial loss: 0.554380\n",
      "epoch 175; iter: 0; batch classifier loss: 0.299252; batch adversarial loss: 0.582411\n",
      "epoch 176; iter: 0; batch classifier loss: 0.308800; batch adversarial loss: 0.553716\n",
      "epoch 177; iter: 0; batch classifier loss: 0.378377; batch adversarial loss: 0.562455\n",
      "epoch 178; iter: 0; batch classifier loss: 0.485695; batch adversarial loss: 0.562688\n",
      "epoch 179; iter: 0; batch classifier loss: 0.416401; batch adversarial loss: 0.583782\n",
      "epoch 180; iter: 0; batch classifier loss: 0.400987; batch adversarial loss: 0.571721\n",
      "epoch 181; iter: 0; batch classifier loss: 0.384003; batch adversarial loss: 0.508777\n",
      "epoch 182; iter: 0; batch classifier loss: 0.383086; batch adversarial loss: 0.533971\n",
      "epoch 183; iter: 0; batch classifier loss: 0.355100; batch adversarial loss: 0.551135\n",
      "epoch 184; iter: 0; batch classifier loss: 0.365370; batch adversarial loss: 0.525472\n",
      "epoch 185; iter: 0; batch classifier loss: 0.414954; batch adversarial loss: 0.462569\n",
      "epoch 186; iter: 0; batch classifier loss: 0.304094; batch adversarial loss: 0.527552\n",
      "epoch 187; iter: 0; batch classifier loss: 0.329475; batch adversarial loss: 0.533885\n",
      "epoch 188; iter: 0; batch classifier loss: 0.321248; batch adversarial loss: 0.590298\n",
      "epoch 189; iter: 0; batch classifier loss: 0.274458; batch adversarial loss: 0.563895\n",
      "epoch 190; iter: 0; batch classifier loss: 0.456099; batch adversarial loss: 0.613981\n",
      "epoch 191; iter: 0; batch classifier loss: 0.399265; batch adversarial loss: 0.606813\n",
      "epoch 192; iter: 0; batch classifier loss: 0.313303; batch adversarial loss: 0.552751\n",
      "epoch 193; iter: 0; batch classifier loss: 0.370249; batch adversarial loss: 0.533710\n",
      "epoch 194; iter: 0; batch classifier loss: 0.365269; batch adversarial loss: 0.588761\n",
      "epoch 195; iter: 0; batch classifier loss: 0.338688; batch adversarial loss: 0.599476\n",
      "epoch 196; iter: 0; batch classifier loss: 0.342984; batch adversarial loss: 0.635153\n",
      "epoch 197; iter: 0; batch classifier loss: 0.362671; batch adversarial loss: 0.445172\n",
      "epoch 198; iter: 0; batch classifier loss: 0.381644; batch adversarial loss: 0.545039\n",
      "epoch 199; iter: 0; batch classifier loss: 0.335403; batch adversarial loss: 0.491615\n",
      "epoch 0; iter: 0; batch classifier loss: 0.745162; batch adversarial loss: 0.813602\n",
      "epoch 1; iter: 0; batch classifier loss: 0.566210; batch adversarial loss: 0.792464\n",
      "epoch 2; iter: 0; batch classifier loss: 0.580044; batch adversarial loss: 0.702350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3; iter: 0; batch classifier loss: 0.583581; batch adversarial loss: 0.737092\n",
      "epoch 4; iter: 0; batch classifier loss: 0.562738; batch adversarial loss: 0.679735\n",
      "epoch 5; iter: 0; batch classifier loss: 0.592694; batch adversarial loss: 0.649439\n",
      "epoch 6; iter: 0; batch classifier loss: 0.532702; batch adversarial loss: 0.620267\n",
      "epoch 7; iter: 0; batch classifier loss: 0.492218; batch adversarial loss: 0.617947\n",
      "epoch 8; iter: 0; batch classifier loss: 0.550517; batch adversarial loss: 0.621950\n",
      "epoch 9; iter: 0; batch classifier loss: 0.554965; batch adversarial loss: 0.624844\n",
      "epoch 10; iter: 0; batch classifier loss: 0.552979; batch adversarial loss: 0.589894\n",
      "epoch 11; iter: 0; batch classifier loss: 0.516945; batch adversarial loss: 0.577008\n",
      "epoch 12; iter: 0; batch classifier loss: 0.459147; batch adversarial loss: 0.583459\n",
      "epoch 13; iter: 0; batch classifier loss: 0.461340; batch adversarial loss: 0.606952\n",
      "epoch 14; iter: 0; batch classifier loss: 0.484619; batch adversarial loss: 0.525913\n",
      "epoch 15; iter: 0; batch classifier loss: 0.517095; batch adversarial loss: 0.571573\n",
      "epoch 16; iter: 0; batch classifier loss: 0.507249; batch adversarial loss: 0.577945\n",
      "epoch 17; iter: 0; batch classifier loss: 0.482045; batch adversarial loss: 0.568518\n",
      "epoch 18; iter: 0; batch classifier loss: 0.442904; batch adversarial loss: 0.560918\n",
      "epoch 19; iter: 0; batch classifier loss: 0.483146; batch adversarial loss: 0.518517\n",
      "epoch 20; iter: 0; batch classifier loss: 0.488667; batch adversarial loss: 0.564190\n",
      "epoch 21; iter: 0; batch classifier loss: 0.554725; batch adversarial loss: 0.599412\n",
      "epoch 22; iter: 0; batch classifier loss: 0.474718; batch adversarial loss: 0.611228\n",
      "epoch 23; iter: 0; batch classifier loss: 0.456227; batch adversarial loss: 0.539801\n",
      "epoch 24; iter: 0; batch classifier loss: 0.446086; batch adversarial loss: 0.566120\n",
      "epoch 25; iter: 0; batch classifier loss: 0.473521; batch adversarial loss: 0.546135\n",
      "epoch 26; iter: 0; batch classifier loss: 0.406461; batch adversarial loss: 0.544456\n",
      "epoch 27; iter: 0; batch classifier loss: 0.570108; batch adversarial loss: 0.577426\n",
      "epoch 28; iter: 0; batch classifier loss: 0.480722; batch adversarial loss: 0.585597\n",
      "epoch 29; iter: 0; batch classifier loss: 0.476958; batch adversarial loss: 0.532278\n",
      "epoch 30; iter: 0; batch classifier loss: 0.477332; batch adversarial loss: 0.555638\n",
      "epoch 31; iter: 0; batch classifier loss: 0.511252; batch adversarial loss: 0.547921\n",
      "epoch 32; iter: 0; batch classifier loss: 0.536837; batch adversarial loss: 0.549944\n",
      "epoch 33; iter: 0; batch classifier loss: 0.448987; batch adversarial loss: 0.547872\n",
      "epoch 34; iter: 0; batch classifier loss: 0.484833; batch adversarial loss: 0.641991\n",
      "epoch 35; iter: 0; batch classifier loss: 0.461350; batch adversarial loss: 0.524264\n",
      "epoch 36; iter: 0; batch classifier loss: 0.427844; batch adversarial loss: 0.537179\n",
      "epoch 37; iter: 0; batch classifier loss: 0.399663; batch adversarial loss: 0.486208\n",
      "epoch 38; iter: 0; batch classifier loss: 0.470375; batch adversarial loss: 0.530041\n",
      "epoch 39; iter: 0; batch classifier loss: 0.448636; batch adversarial loss: 0.566313\n",
      "epoch 40; iter: 0; batch classifier loss: 0.345026; batch adversarial loss: 0.609042\n",
      "epoch 41; iter: 0; batch classifier loss: 0.408074; batch adversarial loss: 0.534904\n",
      "epoch 42; iter: 0; batch classifier loss: 0.418182; batch adversarial loss: 0.529268\n",
      "epoch 43; iter: 0; batch classifier loss: 0.425465; batch adversarial loss: 0.597175\n",
      "epoch 44; iter: 0; batch classifier loss: 0.450578; batch adversarial loss: 0.536506\n",
      "epoch 45; iter: 0; batch classifier loss: 0.446329; batch adversarial loss: 0.599014\n",
      "epoch 46; iter: 0; batch classifier loss: 0.414139; batch adversarial loss: 0.526811\n",
      "epoch 47; iter: 0; batch classifier loss: 0.511362; batch adversarial loss: 0.527131\n",
      "epoch 48; iter: 0; batch classifier loss: 0.412113; batch adversarial loss: 0.553949\n",
      "epoch 49; iter: 0; batch classifier loss: 0.414129; batch adversarial loss: 0.571646\n",
      "epoch 50; iter: 0; batch classifier loss: 0.477313; batch adversarial loss: 0.544984\n",
      "epoch 51; iter: 0; batch classifier loss: 0.363871; batch adversarial loss: 0.669942\n",
      "epoch 52; iter: 0; batch classifier loss: 0.393158; batch adversarial loss: 0.580595\n",
      "epoch 53; iter: 0; batch classifier loss: 0.478271; batch adversarial loss: 0.544380\n",
      "epoch 54; iter: 0; batch classifier loss: 0.447043; batch adversarial loss: 0.526365\n",
      "epoch 55; iter: 0; batch classifier loss: 0.386930; batch adversarial loss: 0.535228\n",
      "epoch 56; iter: 0; batch classifier loss: 0.337730; batch adversarial loss: 0.580956\n",
      "epoch 57; iter: 0; batch classifier loss: 0.429295; batch adversarial loss: 0.617376\n",
      "epoch 58; iter: 0; batch classifier loss: 0.380059; batch adversarial loss: 0.562794\n",
      "epoch 59; iter: 0; batch classifier loss: 0.438777; batch adversarial loss: 0.517285\n",
      "epoch 60; iter: 0; batch classifier loss: 0.352202; batch adversarial loss: 0.489786\n",
      "epoch 61; iter: 0; batch classifier loss: 0.372703; batch adversarial loss: 0.544245\n",
      "epoch 62; iter: 0; batch classifier loss: 0.461419; batch adversarial loss: 0.545099\n",
      "epoch 63; iter: 0; batch classifier loss: 0.438221; batch adversarial loss: 0.534919\n",
      "epoch 64; iter: 0; batch classifier loss: 0.381434; batch adversarial loss: 0.535305\n",
      "epoch 65; iter: 0; batch classifier loss: 0.452607; batch adversarial loss: 0.554162\n",
      "epoch 66; iter: 0; batch classifier loss: 0.374835; batch adversarial loss: 0.555014\n",
      "epoch 67; iter: 0; batch classifier loss: 0.425619; batch adversarial loss: 0.489747\n",
      "epoch 68; iter: 0; batch classifier loss: 0.378172; batch adversarial loss: 0.508721\n",
      "epoch 69; iter: 0; batch classifier loss: 0.432349; batch adversarial loss: 0.535331\n",
      "epoch 70; iter: 0; batch classifier loss: 0.374656; batch adversarial loss: 0.518714\n",
      "epoch 71; iter: 0; batch classifier loss: 0.295796; batch adversarial loss: 0.572358\n",
      "epoch 72; iter: 0; batch classifier loss: 0.428922; batch adversarial loss: 0.563002\n",
      "epoch 73; iter: 0; batch classifier loss: 0.357130; batch adversarial loss: 0.489969\n",
      "epoch 74; iter: 0; batch classifier loss: 0.477455; batch adversarial loss: 0.508134\n",
      "epoch 75; iter: 0; batch classifier loss: 0.389129; batch adversarial loss: 0.607618\n",
      "epoch 76; iter: 0; batch classifier loss: 0.342868; batch adversarial loss: 0.518081\n",
      "epoch 77; iter: 0; batch classifier loss: 0.364364; batch adversarial loss: 0.462448\n",
      "epoch 78; iter: 0; batch classifier loss: 0.462118; batch adversarial loss: 0.617041\n",
      "epoch 79; iter: 0; batch classifier loss: 0.332975; batch adversarial loss: 0.653682\n",
      "epoch 80; iter: 0; batch classifier loss: 0.396386; batch adversarial loss: 0.463203\n",
      "epoch 81; iter: 0; batch classifier loss: 0.382181; batch adversarial loss: 0.526432\n",
      "epoch 82; iter: 0; batch classifier loss: 0.347390; batch adversarial loss: 0.572459\n",
      "epoch 83; iter: 0; batch classifier loss: 0.329148; batch adversarial loss: 0.572382\n",
      "epoch 84; iter: 0; batch classifier loss: 0.404842; batch adversarial loss: 0.544318\n",
      "epoch 85; iter: 0; batch classifier loss: 0.367893; batch adversarial loss: 0.608610\n",
      "epoch 86; iter: 0; batch classifier loss: 0.377281; batch adversarial loss: 0.535665\n",
      "epoch 87; iter: 0; batch classifier loss: 0.363435; batch adversarial loss: 0.544450\n",
      "epoch 88; iter: 0; batch classifier loss: 0.356509; batch adversarial loss: 0.562423\n",
      "epoch 89; iter: 0; batch classifier loss: 0.392215; batch adversarial loss: 0.536065\n",
      "epoch 90; iter: 0; batch classifier loss: 0.434772; batch adversarial loss: 0.517063\n",
      "epoch 91; iter: 0; batch classifier loss: 0.370586; batch adversarial loss: 0.570163\n",
      "epoch 92; iter: 0; batch classifier loss: 0.383184; batch adversarial loss: 0.536555\n",
      "epoch 93; iter: 0; batch classifier loss: 0.366963; batch adversarial loss: 0.489414\n",
      "epoch 94; iter: 0; batch classifier loss: 0.382869; batch adversarial loss: 0.599694\n",
      "epoch 95; iter: 0; batch classifier loss: 0.379577; batch adversarial loss: 0.461777\n",
      "epoch 96; iter: 0; batch classifier loss: 0.383776; batch adversarial loss: 0.507698\n",
      "epoch 97; iter: 0; batch classifier loss: 0.404869; batch adversarial loss: 0.508161\n",
      "epoch 98; iter: 0; batch classifier loss: 0.354816; batch adversarial loss: 0.590215\n",
      "epoch 99; iter: 0; batch classifier loss: 0.408552; batch adversarial loss: 0.553488\n",
      "epoch 100; iter: 0; batch classifier loss: 0.420243; batch adversarial loss: 0.608380\n",
      "epoch 101; iter: 0; batch classifier loss: 0.448888; batch adversarial loss: 0.545059\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 102; iter: 0; batch classifier loss: 0.335439; batch adversarial loss: 0.535838\n",
      "epoch 103; iter: 0; batch classifier loss: 0.347192; batch adversarial loss: 0.553854\n",
      "epoch 104; iter: 0; batch classifier loss: 0.382857; batch adversarial loss: 0.572089\n",
      "epoch 105; iter: 0; batch classifier loss: 0.355709; batch adversarial loss: 0.544694\n",
      "epoch 106; iter: 0; batch classifier loss: 0.331706; batch adversarial loss: 0.581402\n",
      "epoch 107; iter: 0; batch classifier loss: 0.407048; batch adversarial loss: 0.526248\n",
      "epoch 108; iter: 0; batch classifier loss: 0.332190; batch adversarial loss: 0.544757\n",
      "epoch 109; iter: 0; batch classifier loss: 0.388656; batch adversarial loss: 0.580494\n",
      "epoch 110; iter: 0; batch classifier loss: 0.438222; batch adversarial loss: 0.553171\n",
      "epoch 111; iter: 0; batch classifier loss: 0.437903; batch adversarial loss: 0.435603\n",
      "epoch 112; iter: 0; batch classifier loss: 0.403212; batch adversarial loss: 0.571513\n",
      "epoch 113; iter: 0; batch classifier loss: 0.453556; batch adversarial loss: 0.653499\n",
      "epoch 114; iter: 0; batch classifier loss: 0.359244; batch adversarial loss: 0.524556\n",
      "epoch 115; iter: 0; batch classifier loss: 0.423293; batch adversarial loss: 0.525421\n",
      "epoch 116; iter: 0; batch classifier loss: 0.335505; batch adversarial loss: 0.534482\n",
      "epoch 117; iter: 0; batch classifier loss: 0.414354; batch adversarial loss: 0.516170\n",
      "epoch 118; iter: 0; batch classifier loss: 0.338577; batch adversarial loss: 0.618569\n",
      "epoch 119; iter: 0; batch classifier loss: 0.417478; batch adversarial loss: 0.553856\n",
      "epoch 120; iter: 0; batch classifier loss: 0.368683; batch adversarial loss: 0.545078\n",
      "epoch 121; iter: 0; batch classifier loss: 0.442426; batch adversarial loss: 0.609352\n",
      "epoch 122; iter: 0; batch classifier loss: 0.318882; batch adversarial loss: 0.535348\n",
      "epoch 123; iter: 0; batch classifier loss: 0.421361; batch adversarial loss: 0.608616\n",
      "epoch 124; iter: 0; batch classifier loss: 0.358032; batch adversarial loss: 0.570852\n",
      "epoch 125; iter: 0; batch classifier loss: 0.414290; batch adversarial loss: 0.500383\n",
      "epoch 126; iter: 0; batch classifier loss: 0.362907; batch adversarial loss: 0.536247\n",
      "epoch 127; iter: 0; batch classifier loss: 0.350932; batch adversarial loss: 0.489482\n",
      "epoch 128; iter: 0; batch classifier loss: 0.328317; batch adversarial loss: 0.553695\n",
      "epoch 129; iter: 0; batch classifier loss: 0.406474; batch adversarial loss: 0.673215\n",
      "epoch 130; iter: 0; batch classifier loss: 0.359940; batch adversarial loss: 0.480033\n",
      "epoch 131; iter: 0; batch classifier loss: 0.335873; batch adversarial loss: 0.553903\n",
      "epoch 132; iter: 0; batch classifier loss: 0.384282; batch adversarial loss: 0.489638\n",
      "epoch 133; iter: 0; batch classifier loss: 0.306318; batch adversarial loss: 0.498609\n",
      "epoch 134; iter: 0; batch classifier loss: 0.385881; batch adversarial loss: 0.498847\n",
      "epoch 135; iter: 0; batch classifier loss: 0.400027; batch adversarial loss: 0.608742\n",
      "epoch 136; iter: 0; batch classifier loss: 0.378577; batch adversarial loss: 0.580940\n",
      "epoch 137; iter: 0; batch classifier loss: 0.314953; batch adversarial loss: 0.553526\n",
      "epoch 138; iter: 0; batch classifier loss: 0.397818; batch adversarial loss: 0.580916\n",
      "epoch 139; iter: 0; batch classifier loss: 0.313325; batch adversarial loss: 0.526100\n",
      "epoch 140; iter: 0; batch classifier loss: 0.353517; batch adversarial loss: 0.553408\n",
      "epoch 141; iter: 0; batch classifier loss: 0.336029; batch adversarial loss: 0.535679\n",
      "epoch 142; iter: 0; batch classifier loss: 0.351753; batch adversarial loss: 0.608591\n",
      "epoch 143; iter: 0; batch classifier loss: 0.355686; batch adversarial loss: 0.480559\n",
      "epoch 144; iter: 0; batch classifier loss: 0.341310; batch adversarial loss: 0.571571\n",
      "epoch 145; iter: 0; batch classifier loss: 0.256220; batch adversarial loss: 0.572258\n",
      "epoch 146; iter: 0; batch classifier loss: 0.325650; batch adversarial loss: 0.599873\n",
      "epoch 147; iter: 0; batch classifier loss: 0.354744; batch adversarial loss: 0.563088\n",
      "epoch 148; iter: 0; batch classifier loss: 0.387667; batch adversarial loss: 0.636644\n",
      "epoch 149; iter: 0; batch classifier loss: 0.395665; batch adversarial loss: 0.508127\n",
      "epoch 150; iter: 0; batch classifier loss: 0.398678; batch adversarial loss: 0.554068\n",
      "epoch 151; iter: 0; batch classifier loss: 0.353628; batch adversarial loss: 0.572205\n",
      "epoch 152; iter: 0; batch classifier loss: 0.377652; batch adversarial loss: 0.544821\n",
      "epoch 153; iter: 0; batch classifier loss: 0.393330; batch adversarial loss: 0.608673\n",
      "epoch 154; iter: 0; batch classifier loss: 0.390163; batch adversarial loss: 0.526641\n",
      "epoch 155; iter: 0; batch classifier loss: 0.397806; batch adversarial loss: 0.544660\n",
      "epoch 156; iter: 0; batch classifier loss: 0.428015; batch adversarial loss: 0.517193\n",
      "epoch 157; iter: 0; batch classifier loss: 0.409862; batch adversarial loss: 0.517406\n",
      "epoch 158; iter: 0; batch classifier loss: 0.327060; batch adversarial loss: 0.535609\n",
      "epoch 159; iter: 0; batch classifier loss: 0.343953; batch adversarial loss: 0.480479\n",
      "epoch 160; iter: 0; batch classifier loss: 0.373036; batch adversarial loss: 0.544852\n",
      "epoch 161; iter: 0; batch classifier loss: 0.356370; batch adversarial loss: 0.626562\n",
      "epoch 162; iter: 0; batch classifier loss: 0.348539; batch adversarial loss: 0.544666\n",
      "epoch 163; iter: 0; batch classifier loss: 0.349178; batch adversarial loss: 0.535321\n",
      "epoch 164; iter: 0; batch classifier loss: 0.372753; batch adversarial loss: 0.562799\n",
      "epoch 165; iter: 0; batch classifier loss: 0.375584; batch adversarial loss: 0.508824\n",
      "epoch 166; iter: 0; batch classifier loss: 0.346291; batch adversarial loss: 0.553974\n",
      "epoch 167; iter: 0; batch classifier loss: 0.328583; batch adversarial loss: 0.617223\n",
      "epoch 168; iter: 0; batch classifier loss: 0.428713; batch adversarial loss: 0.517003\n",
      "epoch 169; iter: 0; batch classifier loss: 0.298203; batch adversarial loss: 0.535314\n",
      "epoch 170; iter: 0; batch classifier loss: 0.484289; batch adversarial loss: 0.553741\n",
      "epoch 171; iter: 0; batch classifier loss: 0.289815; batch adversarial loss: 0.553714\n",
      "epoch 172; iter: 0; batch classifier loss: 0.324528; batch adversarial loss: 0.535543\n",
      "epoch 173; iter: 0; batch classifier loss: 0.329936; batch adversarial loss: 0.617297\n",
      "epoch 174; iter: 0; batch classifier loss: 0.476038; batch adversarial loss: 0.626223\n",
      "epoch 175; iter: 0; batch classifier loss: 0.409374; batch adversarial loss: 0.553532\n",
      "epoch 176; iter: 0; batch classifier loss: 0.316296; batch adversarial loss: 0.553917\n",
      "epoch 177; iter: 0; batch classifier loss: 0.407635; batch adversarial loss: 0.526237\n",
      "epoch 178; iter: 0; batch classifier loss: 0.334495; batch adversarial loss: 0.526504\n",
      "epoch 179; iter: 0; batch classifier loss: 0.347620; batch adversarial loss: 0.508199\n",
      "epoch 180; iter: 0; batch classifier loss: 0.341787; batch adversarial loss: 0.644628\n",
      "epoch 181; iter: 0; batch classifier loss: 0.343058; batch adversarial loss: 0.626578\n",
      "epoch 182; iter: 0; batch classifier loss: 0.346004; batch adversarial loss: 0.517141\n",
      "epoch 183; iter: 0; batch classifier loss: 0.333409; batch adversarial loss: 0.553886\n",
      "epoch 184; iter: 0; batch classifier loss: 0.286525; batch adversarial loss: 0.480471\n",
      "epoch 185; iter: 0; batch classifier loss: 0.472325; batch adversarial loss: 0.508160\n",
      "epoch 186; iter: 0; batch classifier loss: 0.312917; batch adversarial loss: 0.517047\n",
      "epoch 187; iter: 0; batch classifier loss: 0.394267; batch adversarial loss: 0.517099\n",
      "epoch 188; iter: 0; batch classifier loss: 0.318834; batch adversarial loss: 0.571595\n",
      "epoch 189; iter: 0; batch classifier loss: 0.349081; batch adversarial loss: 0.562668\n",
      "epoch 190; iter: 0; batch classifier loss: 0.244505; batch adversarial loss: 0.535336\n",
      "epoch 191; iter: 0; batch classifier loss: 0.297868; batch adversarial loss: 0.599211\n",
      "epoch 192; iter: 0; batch classifier loss: 0.330006; batch adversarial loss: 0.535654\n",
      "epoch 193; iter: 0; batch classifier loss: 0.284335; batch adversarial loss: 0.535561\n",
      "epoch 194; iter: 0; batch classifier loss: 0.376694; batch adversarial loss: 0.562350\n",
      "epoch 195; iter: 0; batch classifier loss: 0.452664; batch adversarial loss: 0.471521\n",
      "epoch 196; iter: 0; batch classifier loss: 0.337633; batch adversarial loss: 0.562812\n",
      "epoch 197; iter: 0; batch classifier loss: 0.361286; batch adversarial loss: 0.572540\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 198; iter: 0; batch classifier loss: 0.326926; batch adversarial loss: 0.562975\n",
      "epoch 199; iter: 0; batch classifier loss: 0.306480; batch adversarial loss: 0.553870\n",
      "epoch 0; iter: 0; batch classifier loss: 0.677561; batch adversarial loss: 0.648266\n",
      "epoch 1; iter: 0; batch classifier loss: 0.586873; batch adversarial loss: 0.643562\n",
      "epoch 2; iter: 0; batch classifier loss: 0.656622; batch adversarial loss: 0.629779\n",
      "epoch 3; iter: 0; batch classifier loss: 0.503967; batch adversarial loss: 0.621736\n",
      "epoch 4; iter: 0; batch classifier loss: 0.509429; batch adversarial loss: 0.648556\n",
      "epoch 5; iter: 0; batch classifier loss: 0.541552; batch adversarial loss: 0.635745\n",
      "epoch 6; iter: 0; batch classifier loss: 0.547470; batch adversarial loss: 0.627876\n",
      "epoch 7; iter: 0; batch classifier loss: 0.530081; batch adversarial loss: 0.602219\n",
      "epoch 8; iter: 0; batch classifier loss: 0.470117; batch adversarial loss: 0.616230\n",
      "epoch 9; iter: 0; batch classifier loss: 0.561709; batch adversarial loss: 0.612939\n",
      "epoch 10; iter: 0; batch classifier loss: 0.673152; batch adversarial loss: 0.618124\n",
      "epoch 11; iter: 0; batch classifier loss: 0.481404; batch adversarial loss: 0.625095\n",
      "epoch 12; iter: 0; batch classifier loss: 0.522612; batch adversarial loss: 0.592234\n",
      "epoch 13; iter: 0; batch classifier loss: 0.549077; batch adversarial loss: 0.582794\n",
      "epoch 14; iter: 0; batch classifier loss: 0.518277; batch adversarial loss: 0.615532\n",
      "epoch 15; iter: 0; batch classifier loss: 0.522656; batch adversarial loss: 0.624936\n",
      "epoch 16; iter: 0; batch classifier loss: 0.479292; batch adversarial loss: 0.596372\n",
      "epoch 17; iter: 0; batch classifier loss: 0.534795; batch adversarial loss: 0.559804\n",
      "epoch 18; iter: 0; batch classifier loss: 0.449355; batch adversarial loss: 0.587974\n",
      "epoch 19; iter: 0; batch classifier loss: 0.606192; batch adversarial loss: 0.525913\n",
      "epoch 20; iter: 0; batch classifier loss: 0.502649; batch adversarial loss: 0.536874\n",
      "epoch 21; iter: 0; batch classifier loss: 0.464498; batch adversarial loss: 0.526681\n",
      "epoch 22; iter: 0; batch classifier loss: 0.509270; batch adversarial loss: 0.556798\n",
      "epoch 23; iter: 0; batch classifier loss: 0.414144; batch adversarial loss: 0.563473\n",
      "epoch 24; iter: 0; batch classifier loss: 0.504843; batch adversarial loss: 0.563548\n",
      "epoch 25; iter: 0; batch classifier loss: 0.419174; batch adversarial loss: 0.522218\n",
      "epoch 26; iter: 0; batch classifier loss: 0.502515; batch adversarial loss: 0.546261\n",
      "epoch 27; iter: 0; batch classifier loss: 0.519069; batch adversarial loss: 0.562859\n",
      "epoch 28; iter: 0; batch classifier loss: 0.453905; batch adversarial loss: 0.504211\n",
      "epoch 29; iter: 0; batch classifier loss: 0.467692; batch adversarial loss: 0.615286\n",
      "epoch 30; iter: 0; batch classifier loss: 0.465645; batch adversarial loss: 0.613800\n",
      "epoch 31; iter: 0; batch classifier loss: 0.476022; batch adversarial loss: 0.517546\n",
      "epoch 32; iter: 0; batch classifier loss: 0.408247; batch adversarial loss: 0.528083\n",
      "epoch 33; iter: 0; batch classifier loss: 0.451055; batch adversarial loss: 0.596378\n",
      "epoch 34; iter: 0; batch classifier loss: 0.374953; batch adversarial loss: 0.544931\n",
      "epoch 35; iter: 0; batch classifier loss: 0.350848; batch adversarial loss: 0.631015\n",
      "epoch 36; iter: 0; batch classifier loss: 0.461741; batch adversarial loss: 0.570879\n",
      "epoch 37; iter: 0; batch classifier loss: 0.370198; batch adversarial loss: 0.603697\n",
      "epoch 38; iter: 0; batch classifier loss: 0.511150; batch adversarial loss: 0.555142\n",
      "epoch 39; iter: 0; batch classifier loss: 0.439097; batch adversarial loss: 0.507594\n",
      "epoch 40; iter: 0; batch classifier loss: 0.427709; batch adversarial loss: 0.569728\n",
      "epoch 41; iter: 0; batch classifier loss: 0.504761; batch adversarial loss: 0.546937\n",
      "epoch 42; iter: 0; batch classifier loss: 0.502160; batch adversarial loss: 0.571601\n",
      "epoch 43; iter: 0; batch classifier loss: 0.437987; batch adversarial loss: 0.572486\n",
      "epoch 44; iter: 0; batch classifier loss: 0.398876; batch adversarial loss: 0.666624\n",
      "epoch 45; iter: 0; batch classifier loss: 0.340839; batch adversarial loss: 0.475583\n",
      "epoch 46; iter: 0; batch classifier loss: 0.467577; batch adversarial loss: 0.545161\n",
      "epoch 47; iter: 0; batch classifier loss: 0.385770; batch adversarial loss: 0.571110\n",
      "epoch 48; iter: 0; batch classifier loss: 0.351645; batch adversarial loss: 0.579498\n",
      "epoch 49; iter: 0; batch classifier loss: 0.450518; batch adversarial loss: 0.606300\n",
      "epoch 50; iter: 0; batch classifier loss: 0.462220; batch adversarial loss: 0.509438\n",
      "epoch 51; iter: 0; batch classifier loss: 0.375303; batch adversarial loss: 0.465513\n",
      "epoch 52; iter: 0; batch classifier loss: 0.496234; batch adversarial loss: 0.580361\n",
      "epoch 53; iter: 0; batch classifier loss: 0.500679; batch adversarial loss: 0.508304\n",
      "epoch 54; iter: 0; batch classifier loss: 0.476059; batch adversarial loss: 0.553418\n",
      "epoch 55; iter: 0; batch classifier loss: 0.434202; batch adversarial loss: 0.562329\n",
      "epoch 56; iter: 0; batch classifier loss: 0.449268; batch adversarial loss: 0.535609\n",
      "epoch 57; iter: 0; batch classifier loss: 0.480265; batch adversarial loss: 0.482644\n",
      "epoch 58; iter: 0; batch classifier loss: 0.463022; batch adversarial loss: 0.526752\n",
      "epoch 59; iter: 0; batch classifier loss: 0.414518; batch adversarial loss: 0.570821\n",
      "epoch 60; iter: 0; batch classifier loss: 0.414131; batch adversarial loss: 0.536438\n",
      "epoch 61; iter: 0; batch classifier loss: 0.420631; batch adversarial loss: 0.545413\n",
      "epoch 62; iter: 0; batch classifier loss: 0.401880; batch adversarial loss: 0.544509\n",
      "epoch 63; iter: 0; batch classifier loss: 0.422241; batch adversarial loss: 0.607103\n",
      "epoch 64; iter: 0; batch classifier loss: 0.499258; batch adversarial loss: 0.517604\n",
      "epoch 65; iter: 0; batch classifier loss: 0.406472; batch adversarial loss: 0.553520\n",
      "epoch 66; iter: 0; batch classifier loss: 0.446920; batch adversarial loss: 0.607661\n",
      "epoch 67; iter: 0; batch classifier loss: 0.343660; batch adversarial loss: 0.571778\n",
      "epoch 68; iter: 0; batch classifier loss: 0.394714; batch adversarial loss: 0.571313\n",
      "epoch 69; iter: 0; batch classifier loss: 0.369435; batch adversarial loss: 0.571754\n",
      "epoch 70; iter: 0; batch classifier loss: 0.411298; batch adversarial loss: 0.598291\n",
      "epoch 71; iter: 0; batch classifier loss: 0.443787; batch adversarial loss: 0.571655\n",
      "epoch 72; iter: 0; batch classifier loss: 0.442036; batch adversarial loss: 0.509197\n",
      "epoch 73; iter: 0; batch classifier loss: 0.386940; batch adversarial loss: 0.508805\n",
      "epoch 74; iter: 0; batch classifier loss: 0.533767; batch adversarial loss: 0.597900\n",
      "epoch 75; iter: 0; batch classifier loss: 0.393826; batch adversarial loss: 0.625345\n",
      "epoch 76; iter: 0; batch classifier loss: 0.376424; batch adversarial loss: 0.562787\n",
      "epoch 77; iter: 0; batch classifier loss: 0.472398; batch adversarial loss: 0.499480\n",
      "epoch 78; iter: 0; batch classifier loss: 0.366430; batch adversarial loss: 0.562554\n",
      "epoch 79; iter: 0; batch classifier loss: 0.413680; batch adversarial loss: 0.634260\n",
      "epoch 80; iter: 0; batch classifier loss: 0.381071; batch adversarial loss: 0.554009\n",
      "epoch 81; iter: 0; batch classifier loss: 0.367342; batch adversarial loss: 0.633686\n",
      "epoch 82; iter: 0; batch classifier loss: 0.418934; batch adversarial loss: 0.544658\n",
      "epoch 83; iter: 0; batch classifier loss: 0.398544; batch adversarial loss: 0.580402\n",
      "epoch 84; iter: 0; batch classifier loss: 0.439677; batch adversarial loss: 0.499599\n",
      "epoch 85; iter: 0; batch classifier loss: 0.485437; batch adversarial loss: 0.517734\n",
      "epoch 86; iter: 0; batch classifier loss: 0.469758; batch adversarial loss: 0.518313\n",
      "epoch 87; iter: 0; batch classifier loss: 0.429657; batch adversarial loss: 0.579668\n",
      "epoch 88; iter: 0; batch classifier loss: 0.304644; batch adversarial loss: 0.526260\n",
      "epoch 89; iter: 0; batch classifier loss: 0.374140; batch adversarial loss: 0.472923\n",
      "epoch 90; iter: 0; batch classifier loss: 0.347645; batch adversarial loss: 0.562787\n",
      "epoch 91; iter: 0; batch classifier loss: 0.388133; batch adversarial loss: 0.526463\n",
      "epoch 92; iter: 0; batch classifier loss: 0.444876; batch adversarial loss: 0.580046\n",
      "epoch 93; iter: 0; batch classifier loss: 0.408062; batch adversarial loss: 0.634077\n",
      "epoch 94; iter: 0; batch classifier loss: 0.388687; batch adversarial loss: 0.562629\n",
      "epoch 95; iter: 0; batch classifier loss: 0.386268; batch adversarial loss: 0.572463\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 96; iter: 0; batch classifier loss: 0.396693; batch adversarial loss: 0.562690\n",
      "epoch 97; iter: 0; batch classifier loss: 0.410468; batch adversarial loss: 0.544168\n",
      "epoch 98; iter: 0; batch classifier loss: 0.428307; batch adversarial loss: 0.499426\n",
      "epoch 99; iter: 0; batch classifier loss: 0.375984; batch adversarial loss: 0.589311\n",
      "epoch 100; iter: 0; batch classifier loss: 0.377145; batch adversarial loss: 0.490630\n",
      "epoch 101; iter: 0; batch classifier loss: 0.401423; batch adversarial loss: 0.554019\n",
      "epoch 102; iter: 0; batch classifier loss: 0.370440; batch adversarial loss: 0.571023\n",
      "epoch 103; iter: 0; batch classifier loss: 0.386558; batch adversarial loss: 0.642337\n",
      "epoch 104; iter: 0; batch classifier loss: 0.451637; batch adversarial loss: 0.446496\n",
      "epoch 105; iter: 0; batch classifier loss: 0.337963; batch adversarial loss: 0.544859\n",
      "epoch 106; iter: 0; batch classifier loss: 0.323199; batch adversarial loss: 0.500033\n",
      "epoch 107; iter: 0; batch classifier loss: 0.400078; batch adversarial loss: 0.526426\n",
      "epoch 108; iter: 0; batch classifier loss: 0.307533; batch adversarial loss: 0.553923\n",
      "epoch 109; iter: 0; batch classifier loss: 0.445293; batch adversarial loss: 0.580722\n",
      "epoch 110; iter: 0; batch classifier loss: 0.448646; batch adversarial loss: 0.562940\n",
      "epoch 111; iter: 0; batch classifier loss: 0.338941; batch adversarial loss: 0.571529\n",
      "epoch 112; iter: 0; batch classifier loss: 0.374216; batch adversarial loss: 0.634840\n",
      "epoch 113; iter: 0; batch classifier loss: 0.390733; batch adversarial loss: 0.598270\n",
      "epoch 114; iter: 0; batch classifier loss: 0.395461; batch adversarial loss: 0.606716\n",
      "epoch 115; iter: 0; batch classifier loss: 0.363262; batch adversarial loss: 0.580645\n",
      "epoch 116; iter: 0; batch classifier loss: 0.379126; batch adversarial loss: 0.571467\n",
      "epoch 117; iter: 0; batch classifier loss: 0.309431; batch adversarial loss: 0.545320\n",
      "epoch 118; iter: 0; batch classifier loss: 0.357058; batch adversarial loss: 0.571434\n",
      "epoch 119; iter: 0; batch classifier loss: 0.416837; batch adversarial loss: 0.517846\n",
      "epoch 120; iter: 0; batch classifier loss: 0.423138; batch adversarial loss: 0.607260\n",
      "epoch 121; iter: 0; batch classifier loss: 0.363950; batch adversarial loss: 0.527019\n",
      "epoch 122; iter: 0; batch classifier loss: 0.410083; batch adversarial loss: 0.535672\n",
      "epoch 123; iter: 0; batch classifier loss: 0.331367; batch adversarial loss: 0.500598\n",
      "epoch 124; iter: 0; batch classifier loss: 0.358084; batch adversarial loss: 0.607169\n",
      "epoch 125; iter: 0; batch classifier loss: 0.348495; batch adversarial loss: 0.616475\n",
      "epoch 126; iter: 0; batch classifier loss: 0.362868; batch adversarial loss: 0.588617\n",
      "epoch 127; iter: 0; batch classifier loss: 0.358129; batch adversarial loss: 0.553714\n",
      "epoch 128; iter: 0; batch classifier loss: 0.428771; batch adversarial loss: 0.526757\n",
      "epoch 129; iter: 0; batch classifier loss: 0.336335; batch adversarial loss: 0.642742\n",
      "epoch 130; iter: 0; batch classifier loss: 0.352091; batch adversarial loss: 0.490935\n",
      "epoch 131; iter: 0; batch classifier loss: 0.292669; batch adversarial loss: 0.705493\n",
      "epoch 132; iter: 0; batch classifier loss: 0.418980; batch adversarial loss: 0.536055\n",
      "epoch 133; iter: 0; batch classifier loss: 0.354953; batch adversarial loss: 0.516928\n",
      "epoch 134; iter: 0; batch classifier loss: 0.342235; batch adversarial loss: 0.500413\n",
      "epoch 135; iter: 0; batch classifier loss: 0.344471; batch adversarial loss: 0.607546\n",
      "epoch 136; iter: 0; batch classifier loss: 0.337569; batch adversarial loss: 0.589781\n",
      "epoch 137; iter: 0; batch classifier loss: 0.326443; batch adversarial loss: 0.562359\n",
      "epoch 138; iter: 0; batch classifier loss: 0.365172; batch adversarial loss: 0.580787\n",
      "epoch 139; iter: 0; batch classifier loss: 0.342316; batch adversarial loss: 0.580234\n",
      "epoch 140; iter: 0; batch classifier loss: 0.413601; batch adversarial loss: 0.553045\n",
      "epoch 141; iter: 0; batch classifier loss: 0.349562; batch adversarial loss: 0.580071\n",
      "epoch 142; iter: 0; batch classifier loss: 0.357706; batch adversarial loss: 0.625752\n",
      "epoch 143; iter: 0; batch classifier loss: 0.379257; batch adversarial loss: 0.499662\n",
      "epoch 144; iter: 0; batch classifier loss: 0.365583; batch adversarial loss: 0.597695\n",
      "epoch 145; iter: 0; batch classifier loss: 0.353524; batch adversarial loss: 0.545061\n",
      "epoch 146; iter: 0; batch classifier loss: 0.262550; batch adversarial loss: 0.633461\n",
      "epoch 147; iter: 0; batch classifier loss: 0.345828; batch adversarial loss: 0.534941\n",
      "epoch 148; iter: 0; batch classifier loss: 0.353350; batch adversarial loss: 0.598860\n",
      "epoch 149; iter: 0; batch classifier loss: 0.346803; batch adversarial loss: 0.474049\n",
      "epoch 150; iter: 0; batch classifier loss: 0.355968; batch adversarial loss: 0.536518\n",
      "epoch 151; iter: 0; batch classifier loss: 0.432847; batch adversarial loss: 0.500713\n",
      "epoch 152; iter: 0; batch classifier loss: 0.405040; batch adversarial loss: 0.642783\n",
      "epoch 153; iter: 0; batch classifier loss: 0.318573; batch adversarial loss: 0.526129\n",
      "epoch 154; iter: 0; batch classifier loss: 0.365080; batch adversarial loss: 0.650192\n",
      "epoch 155; iter: 0; batch classifier loss: 0.322281; batch adversarial loss: 0.589192\n",
      "epoch 156; iter: 0; batch classifier loss: 0.292759; batch adversarial loss: 0.572147\n",
      "epoch 157; iter: 0; batch classifier loss: 0.351133; batch adversarial loss: 0.562730\n",
      "epoch 158; iter: 0; batch classifier loss: 0.342808; batch adversarial loss: 0.517982\n",
      "epoch 159; iter: 0; batch classifier loss: 0.339651; batch adversarial loss: 0.615814\n",
      "epoch 160; iter: 0; batch classifier loss: 0.356089; batch adversarial loss: 0.545002\n",
      "epoch 161; iter: 0; batch classifier loss: 0.355423; batch adversarial loss: 0.525812\n",
      "epoch 162; iter: 0; batch classifier loss: 0.325157; batch adversarial loss: 0.535898\n",
      "epoch 163; iter: 0; batch classifier loss: 0.339919; batch adversarial loss: 0.534865\n",
      "epoch 164; iter: 0; batch classifier loss: 0.346640; batch adversarial loss: 0.588823\n",
      "epoch 165; iter: 0; batch classifier loss: 0.346370; batch adversarial loss: 0.509171\n",
      "epoch 166; iter: 0; batch classifier loss: 0.301210; batch adversarial loss: 0.491220\n",
      "epoch 167; iter: 0; batch classifier loss: 0.391761; batch adversarial loss: 0.446923\n",
      "epoch 168; iter: 0; batch classifier loss: 0.419226; batch adversarial loss: 0.500449\n",
      "epoch 169; iter: 0; batch classifier loss: 0.318180; batch adversarial loss: 0.696253\n",
      "epoch 170; iter: 0; batch classifier loss: 0.398156; batch adversarial loss: 0.473958\n",
      "epoch 171; iter: 0; batch classifier loss: 0.343512; batch adversarial loss: 0.563700\n",
      "epoch 172; iter: 0; batch classifier loss: 0.350797; batch adversarial loss: 0.580353\n",
      "epoch 173; iter: 0; batch classifier loss: 0.388380; batch adversarial loss: 0.607324\n",
      "epoch 174; iter: 0; batch classifier loss: 0.282746; batch adversarial loss: 0.490795\n",
      "epoch 175; iter: 0; batch classifier loss: 0.296905; batch adversarial loss: 0.588814\n",
      "epoch 176; iter: 0; batch classifier loss: 0.282221; batch adversarial loss: 0.536040\n",
      "epoch 177; iter: 0; batch classifier loss: 0.347326; batch adversarial loss: 0.500025\n",
      "epoch 178; iter: 0; batch classifier loss: 0.336140; batch adversarial loss: 0.563387\n",
      "epoch 179; iter: 0; batch classifier loss: 0.413676; batch adversarial loss: 0.579212\n",
      "epoch 180; iter: 0; batch classifier loss: 0.328373; batch adversarial loss: 0.535863\n",
      "epoch 181; iter: 0; batch classifier loss: 0.373886; batch adversarial loss: 0.553745\n",
      "epoch 182; iter: 0; batch classifier loss: 0.389628; batch adversarial loss: 0.608268\n",
      "epoch 183; iter: 0; batch classifier loss: 0.392285; batch adversarial loss: 0.518051\n",
      "epoch 184; iter: 0; batch classifier loss: 0.391649; batch adversarial loss: 0.625322\n",
      "epoch 185; iter: 0; batch classifier loss: 0.306520; batch adversarial loss: 0.545125\n",
      "epoch 186; iter: 0; batch classifier loss: 0.374679; batch adversarial loss: 0.615987\n",
      "epoch 187; iter: 0; batch classifier loss: 0.384587; batch adversarial loss: 0.500261\n",
      "epoch 188; iter: 0; batch classifier loss: 0.415961; batch adversarial loss: 0.526745\n",
      "epoch 189; iter: 0; batch classifier loss: 0.361471; batch adversarial loss: 0.554706\n",
      "epoch 190; iter: 0; batch classifier loss: 0.358646; batch adversarial loss: 0.580642\n",
      "epoch 191; iter: 0; batch classifier loss: 0.372543; batch adversarial loss: 0.572017\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 192; iter: 0; batch classifier loss: 0.369221; batch adversarial loss: 0.572661\n",
      "epoch 193; iter: 0; batch classifier loss: 0.338157; batch adversarial loss: 0.562832\n",
      "epoch 194; iter: 0; batch classifier loss: 0.351130; batch adversarial loss: 0.544224\n",
      "epoch 195; iter: 0; batch classifier loss: 0.376247; batch adversarial loss: 0.536241\n",
      "epoch 196; iter: 0; batch classifier loss: 0.366861; batch adversarial loss: 0.543625\n",
      "epoch 197; iter: 0; batch classifier loss: 0.375515; batch adversarial loss: 0.553983\n",
      "epoch 198; iter: 0; batch classifier loss: 0.387410; batch adversarial loss: 0.508838\n",
      "epoch 199; iter: 0; batch classifier loss: 0.320317; batch adversarial loss: 0.625419\n",
      "epoch 0; iter: 0; batch classifier loss: 0.802296; batch adversarial loss: 0.722469\n",
      "epoch 1; iter: 0; batch classifier loss: 0.624562; batch adversarial loss: 0.680500\n",
      "epoch 2; iter: 0; batch classifier loss: 0.558584; batch adversarial loss: 0.675631\n",
      "epoch 3; iter: 0; batch classifier loss: 0.617509; batch adversarial loss: 0.632443\n",
      "epoch 4; iter: 0; batch classifier loss: 0.533986; batch adversarial loss: 0.605010\n",
      "epoch 5; iter: 0; batch classifier loss: 0.565554; batch adversarial loss: 0.571991\n",
      "epoch 6; iter: 0; batch classifier loss: 0.570859; batch adversarial loss: 0.550343\n",
      "epoch 7; iter: 0; batch classifier loss: 0.532286; batch adversarial loss: 0.566800\n",
      "epoch 8; iter: 0; batch classifier loss: 0.555152; batch adversarial loss: 0.592073\n",
      "epoch 9; iter: 0; batch classifier loss: 0.554503; batch adversarial loss: 0.548155\n",
      "epoch 10; iter: 0; batch classifier loss: 0.546681; batch adversarial loss: 0.571016\n",
      "epoch 11; iter: 0; batch classifier loss: 0.539224; batch adversarial loss: 0.575929\n",
      "epoch 12; iter: 0; batch classifier loss: 0.542241; batch adversarial loss: 0.576951\n",
      "epoch 13; iter: 0; batch classifier loss: 0.580858; batch adversarial loss: 0.526439\n",
      "epoch 14; iter: 0; batch classifier loss: 0.477310; batch adversarial loss: 0.547976\n",
      "epoch 15; iter: 0; batch classifier loss: 0.514315; batch adversarial loss: 0.556693\n",
      "epoch 16; iter: 0; batch classifier loss: 0.534172; batch adversarial loss: 0.538272\n",
      "epoch 17; iter: 0; batch classifier loss: 0.522868; batch adversarial loss: 0.577369\n",
      "epoch 18; iter: 0; batch classifier loss: 0.522723; batch adversarial loss: 0.576946\n",
      "epoch 19; iter: 0; batch classifier loss: 0.471461; batch adversarial loss: 0.536061\n",
      "epoch 20; iter: 0; batch classifier loss: 0.529657; batch adversarial loss: 0.494177\n",
      "epoch 21; iter: 0; batch classifier loss: 0.511320; batch adversarial loss: 0.556379\n",
      "epoch 22; iter: 0; batch classifier loss: 0.553530; batch adversarial loss: 0.560320\n",
      "epoch 23; iter: 0; batch classifier loss: 0.551660; batch adversarial loss: 0.516765\n",
      "epoch 24; iter: 0; batch classifier loss: 0.461655; batch adversarial loss: 0.578418\n",
      "epoch 25; iter: 0; batch classifier loss: 0.514051; batch adversarial loss: 0.554121\n",
      "epoch 26; iter: 0; batch classifier loss: 0.510850; batch adversarial loss: 0.582773\n",
      "epoch 27; iter: 0; batch classifier loss: 0.506873; batch adversarial loss: 0.524363\n",
      "epoch 28; iter: 0; batch classifier loss: 0.388254; batch adversarial loss: 0.627835\n",
      "epoch 29; iter: 0; batch classifier loss: 0.494224; batch adversarial loss: 0.530551\n",
      "epoch 30; iter: 0; batch classifier loss: 0.442379; batch adversarial loss: 0.488706\n",
      "epoch 31; iter: 0; batch classifier loss: 0.451859; batch adversarial loss: 0.504184\n",
      "epoch 32; iter: 0; batch classifier loss: 0.540165; batch adversarial loss: 0.503049\n",
      "epoch 33; iter: 0; batch classifier loss: 0.460659; batch adversarial loss: 0.550511\n",
      "epoch 34; iter: 0; batch classifier loss: 0.480688; batch adversarial loss: 0.500866\n",
      "epoch 35; iter: 0; batch classifier loss: 0.432609; batch adversarial loss: 0.569790\n",
      "epoch 36; iter: 0; batch classifier loss: 0.541118; batch adversarial loss: 0.535085\n",
      "epoch 37; iter: 0; batch classifier loss: 0.481520; batch adversarial loss: 0.516885\n",
      "epoch 38; iter: 0; batch classifier loss: 0.449192; batch adversarial loss: 0.472783\n",
      "epoch 39; iter: 0; batch classifier loss: 0.420753; batch adversarial loss: 0.572071\n",
      "epoch 40; iter: 0; batch classifier loss: 0.437413; batch adversarial loss: 0.490200\n",
      "epoch 41; iter: 0; batch classifier loss: 0.389395; batch adversarial loss: 0.560452\n",
      "epoch 42; iter: 0; batch classifier loss: 0.476199; batch adversarial loss: 0.561316\n",
      "epoch 43; iter: 0; batch classifier loss: 0.398715; batch adversarial loss: 0.478858\n",
      "epoch 44; iter: 0; batch classifier loss: 0.490230; batch adversarial loss: 0.545724\n",
      "epoch 45; iter: 0; batch classifier loss: 0.350826; batch adversarial loss: 0.610612\n",
      "epoch 46; iter: 0; batch classifier loss: 0.432604; batch adversarial loss: 0.470951\n",
      "epoch 47; iter: 0; batch classifier loss: 0.385675; batch adversarial loss: 0.617523\n",
      "epoch 48; iter: 0; batch classifier loss: 0.451393; batch adversarial loss: 0.562140\n",
      "epoch 49; iter: 0; batch classifier loss: 0.423577; batch adversarial loss: 0.598648\n",
      "epoch 50; iter: 0; batch classifier loss: 0.410151; batch adversarial loss: 0.562986\n",
      "epoch 51; iter: 0; batch classifier loss: 0.361728; batch adversarial loss: 0.555477\n",
      "epoch 52; iter: 0; batch classifier loss: 0.350773; batch adversarial loss: 0.506201\n",
      "epoch 53; iter: 0; batch classifier loss: 0.451191; batch adversarial loss: 0.517444\n",
      "epoch 54; iter: 0; batch classifier loss: 0.419368; batch adversarial loss: 0.507421\n",
      "epoch 55; iter: 0; batch classifier loss: 0.380911; batch adversarial loss: 0.554110\n",
      "epoch 56; iter: 0; batch classifier loss: 0.362426; batch adversarial loss: 0.554443\n",
      "epoch 57; iter: 0; batch classifier loss: 0.442685; batch adversarial loss: 0.525243\n",
      "epoch 58; iter: 0; batch classifier loss: 0.436984; batch adversarial loss: 0.554959\n",
      "epoch 59; iter: 0; batch classifier loss: 0.439477; batch adversarial loss: 0.535025\n",
      "epoch 60; iter: 0; batch classifier loss: 0.414979; batch adversarial loss: 0.555789\n",
      "epoch 61; iter: 0; batch classifier loss: 0.358231; batch adversarial loss: 0.524983\n",
      "epoch 62; iter: 0; batch classifier loss: 0.364887; batch adversarial loss: 0.526917\n",
      "epoch 63; iter: 0; batch classifier loss: 0.402842; batch adversarial loss: 0.554955\n",
      "epoch 64; iter: 0; batch classifier loss: 0.428800; batch adversarial loss: 0.554887\n",
      "epoch 65; iter: 0; batch classifier loss: 0.446984; batch adversarial loss: 0.562020\n",
      "epoch 66; iter: 0; batch classifier loss: 0.432275; batch adversarial loss: 0.507874\n",
      "epoch 67; iter: 0; batch classifier loss: 0.325413; batch adversarial loss: 0.488417\n",
      "epoch 68; iter: 0; batch classifier loss: 0.371882; batch adversarial loss: 0.535527\n",
      "epoch 69; iter: 0; batch classifier loss: 0.447832; batch adversarial loss: 0.525961\n",
      "epoch 70; iter: 0; batch classifier loss: 0.346854; batch adversarial loss: 0.571642\n",
      "epoch 71; iter: 0; batch classifier loss: 0.464226; batch adversarial loss: 0.498538\n",
      "epoch 72; iter: 0; batch classifier loss: 0.393864; batch adversarial loss: 0.507171\n",
      "epoch 73; iter: 0; batch classifier loss: 0.371111; batch adversarial loss: 0.469779\n",
      "epoch 74; iter: 0; batch classifier loss: 0.451486; batch adversarial loss: 0.460679\n",
      "epoch 75; iter: 0; batch classifier loss: 0.384729; batch adversarial loss: 0.498355\n",
      "epoch 76; iter: 0; batch classifier loss: 0.471234; batch adversarial loss: 0.562892\n",
      "epoch 77; iter: 0; batch classifier loss: 0.458510; batch adversarial loss: 0.647414\n",
      "epoch 78; iter: 0; batch classifier loss: 0.389283; batch adversarial loss: 0.505485\n",
      "epoch 79; iter: 0; batch classifier loss: 0.386905; batch adversarial loss: 0.505430\n",
      "epoch 80; iter: 0; batch classifier loss: 0.468961; batch adversarial loss: 0.657610\n",
      "epoch 81; iter: 0; batch classifier loss: 0.410215; batch adversarial loss: 0.583842\n",
      "epoch 82; iter: 0; batch classifier loss: 0.397147; batch adversarial loss: 0.618973\n",
      "epoch 83; iter: 0; batch classifier loss: 0.428544; batch adversarial loss: 0.544600\n",
      "epoch 84; iter: 0; batch classifier loss: 0.396789; batch adversarial loss: 0.628827\n",
      "epoch 85; iter: 0; batch classifier loss: 0.453535; batch adversarial loss: 0.534703\n",
      "epoch 86; iter: 0; batch classifier loss: 0.387095; batch adversarial loss: 0.620906\n",
      "epoch 87; iter: 0; batch classifier loss: 0.368548; batch adversarial loss: 0.527642\n",
      "epoch 88; iter: 0; batch classifier loss: 0.425860; batch adversarial loss: 0.554429\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 89; iter: 0; batch classifier loss: 0.375828; batch adversarial loss: 0.490608\n",
      "epoch 90; iter: 0; batch classifier loss: 0.395368; batch adversarial loss: 0.562324\n",
      "epoch 91; iter: 0; batch classifier loss: 0.362794; batch adversarial loss: 0.554193\n",
      "epoch 92; iter: 0; batch classifier loss: 0.398572; batch adversarial loss: 0.498417\n",
      "epoch 93; iter: 0; batch classifier loss: 0.390055; batch adversarial loss: 0.498356\n",
      "epoch 94; iter: 0; batch classifier loss: 0.405816; batch adversarial loss: 0.578975\n",
      "epoch 95; iter: 0; batch classifier loss: 0.389862; batch adversarial loss: 0.626637\n",
      "epoch 96; iter: 0; batch classifier loss: 0.350343; batch adversarial loss: 0.572582\n",
      "epoch 97; iter: 0; batch classifier loss: 0.383189; batch adversarial loss: 0.508849\n",
      "epoch 98; iter: 0; batch classifier loss: 0.452486; batch adversarial loss: 0.615738\n",
      "epoch 99; iter: 0; batch classifier loss: 0.361540; batch adversarial loss: 0.495482\n",
      "epoch 100; iter: 0; batch classifier loss: 0.345350; batch adversarial loss: 0.589551\n",
      "epoch 101; iter: 0; batch classifier loss: 0.466344; batch adversarial loss: 0.531913\n",
      "epoch 102; iter: 0; batch classifier loss: 0.350932; batch adversarial loss: 0.444814\n",
      "epoch 103; iter: 0; batch classifier loss: 0.337546; batch adversarial loss: 0.544147\n",
      "epoch 104; iter: 0; batch classifier loss: 0.411613; batch adversarial loss: 0.508440\n",
      "epoch 105; iter: 0; batch classifier loss: 0.407146; batch adversarial loss: 0.545532\n",
      "epoch 106; iter: 0; batch classifier loss: 0.417090; batch adversarial loss: 0.535113\n",
      "epoch 107; iter: 0; batch classifier loss: 0.436633; batch adversarial loss: 0.564099\n",
      "epoch 108; iter: 0; batch classifier loss: 0.362209; batch adversarial loss: 0.497646\n",
      "epoch 109; iter: 0; batch classifier loss: 0.398372; batch adversarial loss: 0.543904\n",
      "epoch 110; iter: 0; batch classifier loss: 0.378377; batch adversarial loss: 0.515104\n",
      "epoch 111; iter: 0; batch classifier loss: 0.352451; batch adversarial loss: 0.525721\n",
      "epoch 112; iter: 0; batch classifier loss: 0.367046; batch adversarial loss: 0.516003\n",
      "epoch 113; iter: 0; batch classifier loss: 0.362946; batch adversarial loss: 0.563414\n",
      "epoch 114; iter: 0; batch classifier loss: 0.397877; batch adversarial loss: 0.450276\n",
      "epoch 115; iter: 0; batch classifier loss: 0.397221; batch adversarial loss: 0.479041\n",
      "epoch 116; iter: 0; batch classifier loss: 0.462470; batch adversarial loss: 0.590835\n",
      "epoch 117; iter: 0; batch classifier loss: 0.273751; batch adversarial loss: 0.564261\n",
      "epoch 118; iter: 0; batch classifier loss: 0.319186; batch adversarial loss: 0.422739\n",
      "epoch 119; iter: 0; batch classifier loss: 0.369886; batch adversarial loss: 0.618961\n",
      "epoch 120; iter: 0; batch classifier loss: 0.388269; batch adversarial loss: 0.507936\n",
      "epoch 121; iter: 0; batch classifier loss: 0.364753; batch adversarial loss: 0.507439\n",
      "epoch 122; iter: 0; batch classifier loss: 0.338584; batch adversarial loss: 0.554166\n",
      "epoch 123; iter: 0; batch classifier loss: 0.416970; batch adversarial loss: 0.590602\n",
      "epoch 124; iter: 0; batch classifier loss: 0.345399; batch adversarial loss: 0.516934\n",
      "epoch 125; iter: 0; batch classifier loss: 0.360093; batch adversarial loss: 0.562299\n",
      "epoch 126; iter: 0; batch classifier loss: 0.354782; batch adversarial loss: 0.554104\n",
      "epoch 127; iter: 0; batch classifier loss: 0.370494; batch adversarial loss: 0.619430\n",
      "epoch 128; iter: 0; batch classifier loss: 0.368983; batch adversarial loss: 0.517134\n",
      "epoch 129; iter: 0; batch classifier loss: 0.282261; batch adversarial loss: 0.526264\n",
      "epoch 130; iter: 0; batch classifier loss: 0.328241; batch adversarial loss: 0.609372\n",
      "epoch 131; iter: 0; batch classifier loss: 0.331432; batch adversarial loss: 0.479799\n",
      "epoch 132; iter: 0; batch classifier loss: 0.370471; batch adversarial loss: 0.618636\n",
      "epoch 133; iter: 0; batch classifier loss: 0.298454; batch adversarial loss: 0.572547\n",
      "epoch 134; iter: 0; batch classifier loss: 0.380386; batch adversarial loss: 0.526194\n",
      "epoch 135; iter: 0; batch classifier loss: 0.362911; batch adversarial loss: 0.563979\n",
      "epoch 136; iter: 0; batch classifier loss: 0.425910; batch adversarial loss: 0.572513\n",
      "epoch 137; iter: 0; batch classifier loss: 0.413554; batch adversarial loss: 0.544113\n",
      "epoch 138; iter: 0; batch classifier loss: 0.389808; batch adversarial loss: 0.581261\n",
      "epoch 139; iter: 0; batch classifier loss: 0.388484; batch adversarial loss: 0.552856\n",
      "epoch 140; iter: 0; batch classifier loss: 0.369678; batch adversarial loss: 0.524892\n",
      "epoch 141; iter: 0; batch classifier loss: 0.354734; batch adversarial loss: 0.560904\n",
      "epoch 142; iter: 0; batch classifier loss: 0.421419; batch adversarial loss: 0.543248\n",
      "epoch 143; iter: 0; batch classifier loss: 0.348560; batch adversarial loss: 0.544248\n",
      "epoch 144; iter: 0; batch classifier loss: 0.381012; batch adversarial loss: 0.461792\n",
      "epoch 145; iter: 0; batch classifier loss: 0.359309; batch adversarial loss: 0.516379\n",
      "epoch 146; iter: 0; batch classifier loss: 0.343999; batch adversarial loss: 0.572877\n",
      "epoch 147; iter: 0; batch classifier loss: 0.357491; batch adversarial loss: 0.497495\n",
      "epoch 148; iter: 0; batch classifier loss: 0.296046; batch adversarial loss: 0.496333\n",
      "epoch 149; iter: 0; batch classifier loss: 0.352960; batch adversarial loss: 0.527538\n",
      "epoch 150; iter: 0; batch classifier loss: 0.444293; batch adversarial loss: 0.477929\n",
      "epoch 151; iter: 0; batch classifier loss: 0.411392; batch adversarial loss: 0.469825\n",
      "epoch 152; iter: 0; batch classifier loss: 0.298287; batch adversarial loss: 0.554799\n",
      "epoch 153; iter: 0; batch classifier loss: 0.310639; batch adversarial loss: 0.479023\n",
      "epoch 154; iter: 0; batch classifier loss: 0.349237; batch adversarial loss: 0.533693\n",
      "epoch 155; iter: 0; batch classifier loss: 0.387562; batch adversarial loss: 0.544207\n",
      "epoch 156; iter: 0; batch classifier loss: 0.359513; batch adversarial loss: 0.517034\n",
      "epoch 157; iter: 0; batch classifier loss: 0.405292; batch adversarial loss: 0.526435\n",
      "epoch 158; iter: 0; batch classifier loss: 0.311300; batch adversarial loss: 0.441328\n",
      "epoch 159; iter: 0; batch classifier loss: 0.469021; batch adversarial loss: 0.553538\n",
      "epoch 160; iter: 0; batch classifier loss: 0.348240; batch adversarial loss: 0.618915\n",
      "epoch 161; iter: 0; batch classifier loss: 0.298087; batch adversarial loss: 0.563004\n",
      "epoch 162; iter: 0; batch classifier loss: 0.344409; batch adversarial loss: 0.479331\n",
      "epoch 163; iter: 0; batch classifier loss: 0.307178; batch adversarial loss: 0.488613\n",
      "epoch 164; iter: 0; batch classifier loss: 0.334406; batch adversarial loss: 0.525763\n",
      "epoch 165; iter: 0; batch classifier loss: 0.368075; batch adversarial loss: 0.526043\n",
      "epoch 166; iter: 0; batch classifier loss: 0.369602; batch adversarial loss: 0.544687\n",
      "epoch 167; iter: 0; batch classifier loss: 0.379509; batch adversarial loss: 0.609506\n",
      "epoch 168; iter: 0; batch classifier loss: 0.399658; batch adversarial loss: 0.599663\n",
      "epoch 169; iter: 0; batch classifier loss: 0.343701; batch adversarial loss: 0.581897\n",
      "epoch 170; iter: 0; batch classifier loss: 0.431178; batch adversarial loss: 0.506908\n",
      "epoch 171; iter: 0; batch classifier loss: 0.331507; batch adversarial loss: 0.591722\n",
      "epoch 172; iter: 0; batch classifier loss: 0.423453; batch adversarial loss: 0.535315\n",
      "epoch 173; iter: 0; batch classifier loss: 0.441540; batch adversarial loss: 0.543907\n",
      "epoch 174; iter: 0; batch classifier loss: 0.348552; batch adversarial loss: 0.572391\n",
      "epoch 175; iter: 0; batch classifier loss: 0.390945; batch adversarial loss: 0.507042\n",
      "epoch 176; iter: 0; batch classifier loss: 0.315132; batch adversarial loss: 0.507001\n",
      "epoch 177; iter: 0; batch classifier loss: 0.435085; batch adversarial loss: 0.525881\n",
      "epoch 178; iter: 0; batch classifier loss: 0.333224; batch adversarial loss: 0.497687\n",
      "epoch 179; iter: 0; batch classifier loss: 0.351473; batch adversarial loss: 0.572048\n",
      "epoch 180; iter: 0; batch classifier loss: 0.344082; batch adversarial loss: 0.590934\n",
      "epoch 181; iter: 0; batch classifier loss: 0.354041; batch adversarial loss: 0.543687\n",
      "epoch 182; iter: 0; batch classifier loss: 0.405256; batch adversarial loss: 0.543879\n",
      "epoch 183; iter: 0; batch classifier loss: 0.324557; batch adversarial loss: 0.480357\n",
      "epoch 184; iter: 0; batch classifier loss: 0.338126; batch adversarial loss: 0.609876\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 185; iter: 0; batch classifier loss: 0.422690; batch adversarial loss: 0.581324\n",
      "epoch 186; iter: 0; batch classifier loss: 0.364610; batch adversarial loss: 0.554241\n",
      "epoch 187; iter: 0; batch classifier loss: 0.372872; batch adversarial loss: 0.480155\n",
      "epoch 188; iter: 0; batch classifier loss: 0.378271; batch adversarial loss: 0.507137\n",
      "epoch 189; iter: 0; batch classifier loss: 0.323409; batch adversarial loss: 0.590249\n",
      "epoch 190; iter: 0; batch classifier loss: 0.438455; batch adversarial loss: 0.441705\n",
      "epoch 191; iter: 0; batch classifier loss: 0.335863; batch adversarial loss: 0.554869\n",
      "epoch 192; iter: 0; batch classifier loss: 0.331837; batch adversarial loss: 0.450897\n",
      "epoch 193; iter: 0; batch classifier loss: 0.436376; batch adversarial loss: 0.535355\n",
      "epoch 194; iter: 0; batch classifier loss: 0.347814; batch adversarial loss: 0.479138\n",
      "epoch 195; iter: 0; batch classifier loss: 0.351957; batch adversarial loss: 0.516393\n",
      "epoch 196; iter: 0; batch classifier loss: 0.319116; batch adversarial loss: 0.599855\n",
      "epoch 197; iter: 0; batch classifier loss: 0.387767; batch adversarial loss: 0.590443\n",
      "epoch 198; iter: 0; batch classifier loss: 0.262865; batch adversarial loss: 0.581514\n",
      "epoch 199; iter: 0; batch classifier loss: 0.391699; batch adversarial loss: 0.526103\n",
      "epoch 0; iter: 0; batch classifier loss: 0.642421; batch adversarial loss: 0.871842\n",
      "epoch 1; iter: 0; batch classifier loss: 0.790122; batch adversarial loss: 1.222026\n",
      "epoch 2; iter: 0; batch classifier loss: 0.891946; batch adversarial loss: 1.152474\n",
      "epoch 3; iter: 0; batch classifier loss: 1.005581; batch adversarial loss: 1.050601\n",
      "epoch 4; iter: 0; batch classifier loss: 1.112159; batch adversarial loss: 0.956102\n",
      "epoch 5; iter: 0; batch classifier loss: 0.935247; batch adversarial loss: 0.881610\n",
      "epoch 6; iter: 0; batch classifier loss: 1.002310; batch adversarial loss: 0.809582\n",
      "epoch 7; iter: 0; batch classifier loss: 0.917155; batch adversarial loss: 0.761421\n",
      "epoch 8; iter: 0; batch classifier loss: 0.697276; batch adversarial loss: 0.711611\n",
      "epoch 9; iter: 0; batch classifier loss: 0.687152; batch adversarial loss: 0.674575\n",
      "epoch 10; iter: 0; batch classifier loss: 0.506528; batch adversarial loss: 0.646107\n",
      "epoch 11; iter: 0; batch classifier loss: 0.636606; batch adversarial loss: 0.598535\n",
      "epoch 12; iter: 0; batch classifier loss: 0.484308; batch adversarial loss: 0.589571\n",
      "epoch 13; iter: 0; batch classifier loss: 0.553533; batch adversarial loss: 0.592702\n",
      "epoch 14; iter: 0; batch classifier loss: 0.514496; batch adversarial loss: 0.533367\n",
      "epoch 15; iter: 0; batch classifier loss: 0.529909; batch adversarial loss: 0.583708\n",
      "epoch 16; iter: 0; batch classifier loss: 0.490379; batch adversarial loss: 0.626998\n",
      "epoch 17; iter: 0; batch classifier loss: 0.529054; batch adversarial loss: 0.584809\n",
      "epoch 18; iter: 0; batch classifier loss: 0.505629; batch adversarial loss: 0.490525\n",
      "epoch 19; iter: 0; batch classifier loss: 0.489749; batch adversarial loss: 0.611822\n",
      "epoch 20; iter: 0; batch classifier loss: 0.473115; batch adversarial loss: 0.547435\n",
      "epoch 21; iter: 0; batch classifier loss: 0.507708; batch adversarial loss: 0.577052\n",
      "epoch 22; iter: 0; batch classifier loss: 0.477458; batch adversarial loss: 0.591188\n",
      "epoch 23; iter: 0; batch classifier loss: 0.484969; batch adversarial loss: 0.564468\n",
      "epoch 24; iter: 0; batch classifier loss: 0.565168; batch adversarial loss: 0.600959\n",
      "epoch 25; iter: 0; batch classifier loss: 0.595227; batch adversarial loss: 0.550109\n",
      "epoch 26; iter: 0; batch classifier loss: 0.438001; batch adversarial loss: 0.573909\n",
      "epoch 27; iter: 0; batch classifier loss: 0.398618; batch adversarial loss: 0.490272\n",
      "epoch 28; iter: 0; batch classifier loss: 0.462660; batch adversarial loss: 0.548988\n",
      "epoch 29; iter: 0; batch classifier loss: 0.510006; batch adversarial loss: 0.530400\n",
      "epoch 30; iter: 0; batch classifier loss: 0.415931; batch adversarial loss: 0.563132\n",
      "epoch 31; iter: 0; batch classifier loss: 0.487734; batch adversarial loss: 0.562178\n",
      "epoch 32; iter: 0; batch classifier loss: 0.519792; batch adversarial loss: 0.612050\n",
      "epoch 33; iter: 0; batch classifier loss: 0.494032; batch adversarial loss: 0.503439\n",
      "epoch 34; iter: 0; batch classifier loss: 0.488068; batch adversarial loss: 0.561505\n",
      "epoch 35; iter: 0; batch classifier loss: 0.528855; batch adversarial loss: 0.512438\n",
      "epoch 36; iter: 0; batch classifier loss: 0.410185; batch adversarial loss: 0.552050\n",
      "epoch 37; iter: 0; batch classifier loss: 0.427703; batch adversarial loss: 0.570694\n",
      "epoch 38; iter: 0; batch classifier loss: 0.516859; batch adversarial loss: 0.561700\n",
      "epoch 39; iter: 0; batch classifier loss: 0.459440; batch adversarial loss: 0.578623\n",
      "epoch 40; iter: 0; batch classifier loss: 0.435613; batch adversarial loss: 0.569512\n",
      "epoch 41; iter: 0; batch classifier loss: 0.434735; batch adversarial loss: 0.562046\n",
      "epoch 42; iter: 0; batch classifier loss: 0.441051; batch adversarial loss: 0.471429\n",
      "epoch 43; iter: 0; batch classifier loss: 0.396422; batch adversarial loss: 0.587651\n",
      "epoch 44; iter: 0; batch classifier loss: 0.448975; batch adversarial loss: 0.474434\n",
      "epoch 45; iter: 0; batch classifier loss: 0.429507; batch adversarial loss: 0.526604\n",
      "epoch 46; iter: 0; batch classifier loss: 0.462975; batch adversarial loss: 0.526297\n",
      "epoch 47; iter: 0; batch classifier loss: 0.469142; batch adversarial loss: 0.563957\n",
      "epoch 48; iter: 0; batch classifier loss: 0.413033; batch adversarial loss: 0.597975\n",
      "epoch 49; iter: 0; batch classifier loss: 0.413483; batch adversarial loss: 0.570602\n",
      "epoch 50; iter: 0; batch classifier loss: 0.479689; batch adversarial loss: 0.518736\n",
      "epoch 51; iter: 0; batch classifier loss: 0.417902; batch adversarial loss: 0.580211\n",
      "epoch 52; iter: 0; batch classifier loss: 0.529137; batch adversarial loss: 0.501617\n",
      "epoch 53; iter: 0; batch classifier loss: 0.504762; batch adversarial loss: 0.571459\n",
      "epoch 54; iter: 0; batch classifier loss: 0.343406; batch adversarial loss: 0.500484\n",
      "epoch 55; iter: 0; batch classifier loss: 0.427585; batch adversarial loss: 0.500346\n",
      "epoch 56; iter: 0; batch classifier loss: 0.470320; batch adversarial loss: 0.482504\n",
      "epoch 57; iter: 0; batch classifier loss: 0.461167; batch adversarial loss: 0.580639\n",
      "epoch 58; iter: 0; batch classifier loss: 0.462341; batch adversarial loss: 0.552794\n",
      "epoch 59; iter: 0; batch classifier loss: 0.468818; batch adversarial loss: 0.553839\n",
      "epoch 60; iter: 0; batch classifier loss: 0.361163; batch adversarial loss: 0.553912\n",
      "epoch 61; iter: 0; batch classifier loss: 0.463989; batch adversarial loss: 0.489912\n",
      "epoch 62; iter: 0; batch classifier loss: 0.400967; batch adversarial loss: 0.589799\n",
      "epoch 63; iter: 0; batch classifier loss: 0.442325; batch adversarial loss: 0.517404\n",
      "epoch 64; iter: 0; batch classifier loss: 0.426456; batch adversarial loss: 0.599794\n",
      "epoch 65; iter: 0; batch classifier loss: 0.448916; batch adversarial loss: 0.471265\n",
      "epoch 66; iter: 0; batch classifier loss: 0.423849; batch adversarial loss: 0.536766\n",
      "epoch 67; iter: 0; batch classifier loss: 0.360648; batch adversarial loss: 0.581888\n",
      "epoch 68; iter: 0; batch classifier loss: 0.488474; batch adversarial loss: 0.497551\n",
      "epoch 69; iter: 0; batch classifier loss: 0.362412; batch adversarial loss: 0.523113\n",
      "epoch 70; iter: 0; batch classifier loss: 0.377803; batch adversarial loss: 0.617030\n",
      "epoch 71; iter: 0; batch classifier loss: 0.511933; batch adversarial loss: 0.553691\n",
      "epoch 72; iter: 0; batch classifier loss: 0.387030; batch adversarial loss: 0.535491\n",
      "epoch 73; iter: 0; batch classifier loss: 0.353528; batch adversarial loss: 0.516325\n",
      "epoch 74; iter: 0; batch classifier loss: 0.442733; batch adversarial loss: 0.571296\n",
      "epoch 75; iter: 0; batch classifier loss: 0.337582; batch adversarial loss: 0.642660\n",
      "epoch 76; iter: 0; batch classifier loss: 0.396431; batch adversarial loss: 0.515533\n",
      "epoch 77; iter: 0; batch classifier loss: 0.434007; batch adversarial loss: 0.603225\n",
      "epoch 78; iter: 0; batch classifier loss: 0.355179; batch adversarial loss: 0.607711\n",
      "epoch 79; iter: 0; batch classifier loss: 0.402616; batch adversarial loss: 0.581000\n",
      "epoch 80; iter: 0; batch classifier loss: 0.402278; batch adversarial loss: 0.490335\n",
      "epoch 81; iter: 0; batch classifier loss: 0.350860; batch adversarial loss: 0.574325\n",
      "epoch 82; iter: 0; batch classifier loss: 0.441394; batch adversarial loss: 0.547979\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 83; iter: 0; batch classifier loss: 0.333293; batch adversarial loss: 0.498611\n",
      "epoch 84; iter: 0; batch classifier loss: 0.396241; batch adversarial loss: 0.507636\n",
      "epoch 85; iter: 0; batch classifier loss: 0.382914; batch adversarial loss: 0.528867\n",
      "epoch 86; iter: 0; batch classifier loss: 0.350629; batch adversarial loss: 0.533805\n",
      "epoch 87; iter: 0; batch classifier loss: 0.422062; batch adversarial loss: 0.582710\n",
      "epoch 88; iter: 0; batch classifier loss: 0.411590; batch adversarial loss: 0.517382\n",
      "epoch 89; iter: 0; batch classifier loss: 0.345171; batch adversarial loss: 0.564085\n",
      "epoch 90; iter: 0; batch classifier loss: 0.397222; batch adversarial loss: 0.554556\n",
      "epoch 91; iter: 0; batch classifier loss: 0.348486; batch adversarial loss: 0.484597\n",
      "epoch 92; iter: 0; batch classifier loss: 0.362098; batch adversarial loss: 0.597406\n",
      "epoch 93; iter: 0; batch classifier loss: 0.386200; batch adversarial loss: 0.517601\n",
      "epoch 94; iter: 0; batch classifier loss: 0.376553; batch adversarial loss: 0.571040\n",
      "epoch 95; iter: 0; batch classifier loss: 0.386297; batch adversarial loss: 0.580987\n",
      "epoch 96; iter: 0; batch classifier loss: 0.399618; batch adversarial loss: 0.524122\n",
      "epoch 97; iter: 0; batch classifier loss: 0.374368; batch adversarial loss: 0.555392\n",
      "epoch 98; iter: 0; batch classifier loss: 0.409442; batch adversarial loss: 0.534805\n",
      "epoch 99; iter: 0; batch classifier loss: 0.385759; batch adversarial loss: 0.535438\n",
      "epoch 100; iter: 0; batch classifier loss: 0.347626; batch adversarial loss: 0.589675\n",
      "epoch 101; iter: 0; batch classifier loss: 0.371354; batch adversarial loss: 0.499492\n",
      "epoch 102; iter: 0; batch classifier loss: 0.389752; batch adversarial loss: 0.464931\n",
      "epoch 103; iter: 0; batch classifier loss: 0.409485; batch adversarial loss: 0.543781\n",
      "epoch 104; iter: 0; batch classifier loss: 0.364002; batch adversarial loss: 0.534667\n",
      "epoch 105; iter: 0; batch classifier loss: 0.371255; batch adversarial loss: 0.606749\n",
      "epoch 106; iter: 0; batch classifier loss: 0.472052; batch adversarial loss: 0.624383\n",
      "epoch 107; iter: 0; batch classifier loss: 0.420614; batch adversarial loss: 0.527090\n",
      "epoch 108; iter: 0; batch classifier loss: 0.378429; batch adversarial loss: 0.579522\n",
      "epoch 109; iter: 0; batch classifier loss: 0.310996; batch adversarial loss: 0.607976\n",
      "epoch 110; iter: 0; batch classifier loss: 0.375478; batch adversarial loss: 0.624689\n",
      "epoch 111; iter: 0; batch classifier loss: 0.387700; batch adversarial loss: 0.562476\n",
      "epoch 112; iter: 0; batch classifier loss: 0.393163; batch adversarial loss: 0.598713\n",
      "epoch 113; iter: 0; batch classifier loss: 0.334634; batch adversarial loss: 0.634708\n",
      "epoch 114; iter: 0; batch classifier loss: 0.405570; batch adversarial loss: 0.580894\n",
      "epoch 115; iter: 0; batch classifier loss: 0.323324; batch adversarial loss: 0.498958\n",
      "epoch 116; iter: 0; batch classifier loss: 0.370702; batch adversarial loss: 0.552960\n",
      "epoch 117; iter: 0; batch classifier loss: 0.434208; batch adversarial loss: 0.489923\n",
      "epoch 118; iter: 0; batch classifier loss: 0.393555; batch adversarial loss: 0.599067\n",
      "epoch 119; iter: 0; batch classifier loss: 0.347361; batch adversarial loss: 0.635858\n",
      "epoch 120; iter: 0; batch classifier loss: 0.390467; batch adversarial loss: 0.526047\n",
      "epoch 121; iter: 0; batch classifier loss: 0.420267; batch adversarial loss: 0.546381\n",
      "epoch 122; iter: 0; batch classifier loss: 0.400519; batch adversarial loss: 0.562668\n",
      "epoch 123; iter: 0; batch classifier loss: 0.362093; batch adversarial loss: 0.504936\n",
      "epoch 124; iter: 0; batch classifier loss: 0.399002; batch adversarial loss: 0.578073\n",
      "epoch 125; iter: 0; batch classifier loss: 0.359852; batch adversarial loss: 0.544387\n",
      "epoch 126; iter: 0; batch classifier loss: 0.382975; batch adversarial loss: 0.562663\n",
      "epoch 127; iter: 0; batch classifier loss: 0.348202; batch adversarial loss: 0.550502\n",
      "epoch 128; iter: 0; batch classifier loss: 0.418777; batch adversarial loss: 0.482576\n",
      "epoch 129; iter: 0; batch classifier loss: 0.337329; batch adversarial loss: 0.498621\n",
      "epoch 130; iter: 0; batch classifier loss: 0.313482; batch adversarial loss: 0.607697\n",
      "epoch 131; iter: 0; batch classifier loss: 0.273520; batch adversarial loss: 0.507986\n",
      "epoch 132; iter: 0; batch classifier loss: 0.348279; batch adversarial loss: 0.562770\n",
      "epoch 133; iter: 0; batch classifier loss: 0.325638; batch adversarial loss: 0.552947\n",
      "epoch 134; iter: 0; batch classifier loss: 0.396903; batch adversarial loss: 0.536386\n",
      "epoch 135; iter: 0; batch classifier loss: 0.330621; batch adversarial loss: 0.580683\n",
      "epoch 136; iter: 0; batch classifier loss: 0.381031; batch adversarial loss: 0.606582\n",
      "epoch 137; iter: 0; batch classifier loss: 0.331473; batch adversarial loss: 0.544054\n",
      "epoch 138; iter: 0; batch classifier loss: 0.368599; batch adversarial loss: 0.554762\n",
      "epoch 139; iter: 0; batch classifier loss: 0.321414; batch adversarial loss: 0.517438\n",
      "epoch 140; iter: 0; batch classifier loss: 0.364332; batch adversarial loss: 0.544822\n",
      "epoch 141; iter: 0; batch classifier loss: 0.336894; batch adversarial loss: 0.590038\n",
      "epoch 142; iter: 0; batch classifier loss: 0.344258; batch adversarial loss: 0.544113\n",
      "epoch 143; iter: 0; batch classifier loss: 0.439116; batch adversarial loss: 0.616063\n",
      "epoch 144; iter: 0; batch classifier loss: 0.350331; batch adversarial loss: 0.482097\n",
      "epoch 145; iter: 0; batch classifier loss: 0.337983; batch adversarial loss: 0.462144\n",
      "epoch 146; iter: 0; batch classifier loss: 0.318185; batch adversarial loss: 0.553796\n",
      "epoch 147; iter: 0; batch classifier loss: 0.328843; batch adversarial loss: 0.534735\n",
      "epoch 148; iter: 0; batch classifier loss: 0.373003; batch adversarial loss: 0.579317\n",
      "epoch 149; iter: 0; batch classifier loss: 0.320355; batch adversarial loss: 0.581205\n",
      "epoch 150; iter: 0; batch classifier loss: 0.426971; batch adversarial loss: 0.599345\n",
      "epoch 151; iter: 0; batch classifier loss: 0.296670; batch adversarial loss: 0.543189\n",
      "epoch 152; iter: 0; batch classifier loss: 0.347805; batch adversarial loss: 0.525209\n",
      "epoch 153; iter: 0; batch classifier loss: 0.333464; batch adversarial loss: 0.579063\n",
      "epoch 154; iter: 0; batch classifier loss: 0.424032; batch adversarial loss: 0.593466\n",
      "epoch 155; iter: 0; batch classifier loss: 0.335378; batch adversarial loss: 0.583283\n",
      "epoch 156; iter: 0; batch classifier loss: 0.357517; batch adversarial loss: 0.518719\n",
      "epoch 157; iter: 0; batch classifier loss: 0.318434; batch adversarial loss: 0.525428\n",
      "epoch 158; iter: 0; batch classifier loss: 0.295978; batch adversarial loss: 0.553548\n",
      "epoch 159; iter: 0; batch classifier loss: 0.338347; batch adversarial loss: 0.625588\n",
      "epoch 160; iter: 0; batch classifier loss: 0.363503; batch adversarial loss: 0.544712\n",
      "epoch 161; iter: 0; batch classifier loss: 0.335921; batch adversarial loss: 0.588431\n",
      "epoch 162; iter: 0; batch classifier loss: 0.360700; batch adversarial loss: 0.561642\n",
      "epoch 163; iter: 0; batch classifier loss: 0.349323; batch adversarial loss: 0.580536\n",
      "epoch 164; iter: 0; batch classifier loss: 0.344671; batch adversarial loss: 0.445400\n",
      "epoch 165; iter: 0; batch classifier loss: 0.407856; batch adversarial loss: 0.570904\n",
      "epoch 166; iter: 0; batch classifier loss: 0.342208; batch adversarial loss: 0.597628\n",
      "epoch 167; iter: 0; batch classifier loss: 0.255528; batch adversarial loss: 0.572372\n",
      "epoch 168; iter: 0; batch classifier loss: 0.351702; batch adversarial loss: 0.581573\n",
      "epoch 169; iter: 0; batch classifier loss: 0.322292; batch adversarial loss: 0.580397\n",
      "epoch 170; iter: 0; batch classifier loss: 0.315577; batch adversarial loss: 0.554541\n",
      "epoch 171; iter: 0; batch classifier loss: 0.333138; batch adversarial loss: 0.571890\n",
      "epoch 172; iter: 0; batch classifier loss: 0.459813; batch adversarial loss: 0.516575\n",
      "epoch 173; iter: 0; batch classifier loss: 0.209796; batch adversarial loss: 0.544304\n",
      "epoch 174; iter: 0; batch classifier loss: 0.362788; batch adversarial loss: 0.542297\n",
      "epoch 175; iter: 0; batch classifier loss: 0.326524; batch adversarial loss: 0.545024\n",
      "epoch 176; iter: 0; batch classifier loss: 0.329911; batch adversarial loss: 0.515243\n",
      "epoch 177; iter: 0; batch classifier loss: 0.345336; batch adversarial loss: 0.599897\n",
      "epoch 178; iter: 0; batch classifier loss: 0.394359; batch adversarial loss: 0.498879\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 179; iter: 0; batch classifier loss: 0.381050; batch adversarial loss: 0.591264\n",
      "epoch 180; iter: 0; batch classifier loss: 0.354334; batch adversarial loss: 0.525036\n",
      "epoch 181; iter: 0; batch classifier loss: 0.325494; batch adversarial loss: 0.516595\n",
      "epoch 182; iter: 0; batch classifier loss: 0.346600; batch adversarial loss: 0.544792\n",
      "epoch 183; iter: 0; batch classifier loss: 0.349211; batch adversarial loss: 0.636793\n",
      "epoch 184; iter: 0; batch classifier loss: 0.309369; batch adversarial loss: 0.498810\n",
      "epoch 185; iter: 0; batch classifier loss: 0.328274; batch adversarial loss: 0.523684\n",
      "epoch 186; iter: 0; batch classifier loss: 0.393560; batch adversarial loss: 0.526092\n",
      "epoch 187; iter: 0; batch classifier loss: 0.361666; batch adversarial loss: 0.543555\n",
      "epoch 188; iter: 0; batch classifier loss: 0.343453; batch adversarial loss: 0.617605\n",
      "epoch 189; iter: 0; batch classifier loss: 0.370599; batch adversarial loss: 0.625768\n",
      "epoch 190; iter: 0; batch classifier loss: 0.352274; batch adversarial loss: 0.500726\n",
      "epoch 191; iter: 0; batch classifier loss: 0.265621; batch adversarial loss: 0.534574\n",
      "epoch 192; iter: 0; batch classifier loss: 0.394646; batch adversarial loss: 0.632583\n",
      "epoch 193; iter: 0; batch classifier loss: 0.279260; batch adversarial loss: 0.536261\n",
      "epoch 194; iter: 0; batch classifier loss: 0.339857; batch adversarial loss: 0.601890\n",
      "epoch 195; iter: 0; batch classifier loss: 0.336226; batch adversarial loss: 0.608167\n",
      "epoch 196; iter: 0; batch classifier loss: 0.273341; batch adversarial loss: 0.564505\n",
      "epoch 197; iter: 0; batch classifier loss: 0.357136; batch adversarial loss: 0.552857\n",
      "epoch 198; iter: 0; batch classifier loss: 0.349180; batch adversarial loss: 0.462465\n",
      "epoch 199; iter: 0; batch classifier loss: 0.312415; batch adversarial loss: 0.480127\n",
      "epoch 0; iter: 0; batch classifier loss: 0.690384; batch adversarial loss: 0.669081\n",
      "epoch 1; iter: 0; batch classifier loss: 0.581371; batch adversarial loss: 0.649732\n",
      "epoch 2; iter: 0; batch classifier loss: 0.606830; batch adversarial loss: 0.671157\n",
      "epoch 3; iter: 0; batch classifier loss: 0.583603; batch adversarial loss: 0.648853\n",
      "epoch 4; iter: 0; batch classifier loss: 0.629787; batch adversarial loss: 0.635913\n",
      "epoch 5; iter: 0; batch classifier loss: 0.596053; batch adversarial loss: 0.646572\n",
      "epoch 6; iter: 0; batch classifier loss: 0.611956; batch adversarial loss: 0.623792\n",
      "epoch 7; iter: 0; batch classifier loss: 0.558573; batch adversarial loss: 0.628825\n",
      "epoch 8; iter: 0; batch classifier loss: 0.521561; batch adversarial loss: 0.591280\n",
      "epoch 9; iter: 0; batch classifier loss: 0.564799; batch adversarial loss: 0.596638\n",
      "epoch 10; iter: 0; batch classifier loss: 0.562891; batch adversarial loss: 0.524562\n",
      "epoch 11; iter: 0; batch classifier loss: 0.535903; batch adversarial loss: 0.571297\n",
      "epoch 12; iter: 0; batch classifier loss: 0.457803; batch adversarial loss: 0.556605\n",
      "epoch 13; iter: 0; batch classifier loss: 0.564882; batch adversarial loss: 0.584383\n",
      "epoch 14; iter: 0; batch classifier loss: 0.564578; batch adversarial loss: 0.547847\n",
      "epoch 15; iter: 0; batch classifier loss: 0.523292; batch adversarial loss: 0.528581\n",
      "epoch 16; iter: 0; batch classifier loss: 0.472254; batch adversarial loss: 0.563019\n",
      "epoch 17; iter: 0; batch classifier loss: 0.493897; batch adversarial loss: 0.591045\n",
      "epoch 18; iter: 0; batch classifier loss: 0.470991; batch adversarial loss: 0.564937\n",
      "epoch 19; iter: 0; batch classifier loss: 0.536202; batch adversarial loss: 0.530676\n",
      "epoch 20; iter: 0; batch classifier loss: 0.463844; batch adversarial loss: 0.529347\n",
      "epoch 21; iter: 0; batch classifier loss: 0.437091; batch adversarial loss: 0.566819\n",
      "epoch 22; iter: 0; batch classifier loss: 0.480702; batch adversarial loss: 0.520704\n",
      "epoch 23; iter: 0; batch classifier loss: 0.432251; batch adversarial loss: 0.600436\n",
      "epoch 24; iter: 0; batch classifier loss: 0.460460; batch adversarial loss: 0.553484\n",
      "epoch 25; iter: 0; batch classifier loss: 0.438031; batch adversarial loss: 0.489159\n",
      "epoch 26; iter: 0; batch classifier loss: 0.460065; batch adversarial loss: 0.531399\n",
      "epoch 27; iter: 0; batch classifier loss: 0.471408; batch adversarial loss: 0.546576\n",
      "epoch 28; iter: 0; batch classifier loss: 0.473401; batch adversarial loss: 0.569626\n",
      "epoch 29; iter: 0; batch classifier loss: 0.537604; batch adversarial loss: 0.519522\n",
      "epoch 30; iter: 0; batch classifier loss: 0.435539; batch adversarial loss: 0.500927\n",
      "epoch 31; iter: 0; batch classifier loss: 0.448970; batch adversarial loss: 0.529641\n",
      "epoch 32; iter: 0; batch classifier loss: 0.507434; batch adversarial loss: 0.521089\n",
      "epoch 33; iter: 0; batch classifier loss: 0.469591; batch adversarial loss: 0.545658\n",
      "epoch 34; iter: 0; batch classifier loss: 0.370504; batch adversarial loss: 0.503499\n",
      "epoch 35; iter: 0; batch classifier loss: 0.483393; batch adversarial loss: 0.536103\n",
      "epoch 36; iter: 0; batch classifier loss: 0.425252; batch adversarial loss: 0.570746\n",
      "epoch 37; iter: 0; batch classifier loss: 0.416653; batch adversarial loss: 0.614484\n",
      "epoch 38; iter: 0; batch classifier loss: 0.375683; batch adversarial loss: 0.571382\n",
      "epoch 39; iter: 0; batch classifier loss: 0.433818; batch adversarial loss: 0.606603\n",
      "epoch 40; iter: 0; batch classifier loss: 0.404244; batch adversarial loss: 0.544725\n",
      "epoch 41; iter: 0; batch classifier loss: 0.418069; batch adversarial loss: 0.535875\n",
      "epoch 42; iter: 0; batch classifier loss: 0.472276; batch adversarial loss: 0.607581\n",
      "epoch 43; iter: 0; batch classifier loss: 0.436649; batch adversarial loss: 0.562217\n",
      "epoch 44; iter: 0; batch classifier loss: 0.490784; batch adversarial loss: 0.533899\n",
      "epoch 45; iter: 0; batch classifier loss: 0.478717; batch adversarial loss: 0.572094\n",
      "epoch 46; iter: 0; batch classifier loss: 0.471815; batch adversarial loss: 0.516626\n",
      "epoch 47; iter: 0; batch classifier loss: 0.370651; batch adversarial loss: 0.534872\n",
      "epoch 48; iter: 0; batch classifier loss: 0.381260; batch adversarial loss: 0.561222\n",
      "epoch 49; iter: 0; batch classifier loss: 0.451254; batch adversarial loss: 0.545114\n",
      "epoch 50; iter: 0; batch classifier loss: 0.461714; batch adversarial loss: 0.561533\n",
      "epoch 51; iter: 0; batch classifier loss: 0.427272; batch adversarial loss: 0.572369\n",
      "epoch 52; iter: 0; batch classifier loss: 0.397228; batch adversarial loss: 0.589739\n",
      "epoch 53; iter: 0; batch classifier loss: 0.432440; batch adversarial loss: 0.598357\n",
      "epoch 54; iter: 0; batch classifier loss: 0.385435; batch adversarial loss: 0.534627\n",
      "epoch 55; iter: 0; batch classifier loss: 0.434795; batch adversarial loss: 0.562433\n",
      "epoch 56; iter: 0; batch classifier loss: 0.348776; batch adversarial loss: 0.554255\n",
      "epoch 57; iter: 0; batch classifier loss: 0.431706; batch adversarial loss: 0.626049\n",
      "epoch 58; iter: 0; batch classifier loss: 0.349578; batch adversarial loss: 0.599083\n",
      "epoch 59; iter: 0; batch classifier loss: 0.432983; batch adversarial loss: 0.553340\n",
      "epoch 60; iter: 0; batch classifier loss: 0.389602; batch adversarial loss: 0.544387\n",
      "epoch 61; iter: 0; batch classifier loss: 0.410861; batch adversarial loss: 0.608662\n",
      "epoch 62; iter: 0; batch classifier loss: 0.410553; batch adversarial loss: 0.604420\n",
      "epoch 63; iter: 0; batch classifier loss: 0.398620; batch adversarial loss: 0.552234\n",
      "epoch 64; iter: 0; batch classifier loss: 0.479070; batch adversarial loss: 0.533954\n",
      "epoch 65; iter: 0; batch classifier loss: 0.354946; batch adversarial loss: 0.607267\n",
      "epoch 66; iter: 0; batch classifier loss: 0.412115; batch adversarial loss: 0.536123\n",
      "epoch 67; iter: 0; batch classifier loss: 0.374626; batch adversarial loss: 0.626612\n",
      "epoch 68; iter: 0; batch classifier loss: 0.392661; batch adversarial loss: 0.542643\n",
      "epoch 69; iter: 0; batch classifier loss: 0.448596; batch adversarial loss: 0.535505\n",
      "epoch 70; iter: 0; batch classifier loss: 0.440437; batch adversarial loss: 0.482254\n",
      "epoch 71; iter: 0; batch classifier loss: 0.439994; batch adversarial loss: 0.598651\n",
      "epoch 72; iter: 0; batch classifier loss: 0.435885; batch adversarial loss: 0.554291\n",
      "epoch 73; iter: 0; batch classifier loss: 0.401687; batch adversarial loss: 0.563364\n",
      "epoch 74; iter: 0; batch classifier loss: 0.503978; batch adversarial loss: 0.508104\n",
      "epoch 75; iter: 0; batch classifier loss: 0.352047; batch adversarial loss: 0.562230\n",
      "epoch 76; iter: 0; batch classifier loss: 0.431715; batch adversarial loss: 0.507693\n",
      "epoch 77; iter: 0; batch classifier loss: 0.476152; batch adversarial loss: 0.500199\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 78; iter: 0; batch classifier loss: 0.413692; batch adversarial loss: 0.553477\n",
      "epoch 79; iter: 0; batch classifier loss: 0.375861; batch adversarial loss: 0.616489\n",
      "epoch 80; iter: 0; batch classifier loss: 0.417294; batch adversarial loss: 0.561936\n",
      "epoch 81; iter: 0; batch classifier loss: 0.405407; batch adversarial loss: 0.527923\n",
      "epoch 82; iter: 0; batch classifier loss: 0.485389; batch adversarial loss: 0.573337\n",
      "epoch 83; iter: 0; batch classifier loss: 0.439083; batch adversarial loss: 0.610630\n",
      "epoch 84; iter: 0; batch classifier loss: 0.405033; batch adversarial loss: 0.536428\n",
      "epoch 85; iter: 0; batch classifier loss: 0.376826; batch adversarial loss: 0.644680\n",
      "epoch 86; iter: 0; batch classifier loss: 0.355616; batch adversarial loss: 0.570748\n",
      "epoch 87; iter: 0; batch classifier loss: 0.416399; batch adversarial loss: 0.608256\n",
      "epoch 88; iter: 0; batch classifier loss: 0.365972; batch adversarial loss: 0.543207\n",
      "epoch 89; iter: 0; batch classifier loss: 0.342312; batch adversarial loss: 0.570483\n",
      "epoch 90; iter: 0; batch classifier loss: 0.416702; batch adversarial loss: 0.545580\n",
      "epoch 91; iter: 0; batch classifier loss: 0.388258; batch adversarial loss: 0.525260\n",
      "epoch 92; iter: 0; batch classifier loss: 0.347076; batch adversarial loss: 0.518022\n",
      "epoch 93; iter: 0; batch classifier loss: 0.416526; batch adversarial loss: 0.489031\n",
      "epoch 94; iter: 0; batch classifier loss: 0.422484; batch adversarial loss: 0.425530\n",
      "epoch 95; iter: 0; batch classifier loss: 0.344553; batch adversarial loss: 0.588403\n",
      "epoch 96; iter: 0; batch classifier loss: 0.385321; batch adversarial loss: 0.508061\n",
      "epoch 97; iter: 0; batch classifier loss: 0.336833; batch adversarial loss: 0.579593\n",
      "epoch 98; iter: 0; batch classifier loss: 0.451674; batch adversarial loss: 0.482579\n",
      "epoch 99; iter: 0; batch classifier loss: 0.423876; batch adversarial loss: 0.616759\n",
      "epoch 100; iter: 0; batch classifier loss: 0.353149; batch adversarial loss: 0.533744\n",
      "epoch 101; iter: 0; batch classifier loss: 0.417930; batch adversarial loss: 0.625556\n",
      "epoch 102; iter: 0; batch classifier loss: 0.446101; batch adversarial loss: 0.589105\n",
      "epoch 103; iter: 0; batch classifier loss: 0.360221; batch adversarial loss: 0.518132\n",
      "epoch 104; iter: 0; batch classifier loss: 0.421892; batch adversarial loss: 0.571124\n",
      "epoch 105; iter: 0; batch classifier loss: 0.353175; batch adversarial loss: 0.561196\n",
      "epoch 106; iter: 0; batch classifier loss: 0.383424; batch adversarial loss: 0.562327\n",
      "epoch 107; iter: 0; batch classifier loss: 0.346950; batch adversarial loss: 0.508993\n",
      "epoch 108; iter: 0; batch classifier loss: 0.379843; batch adversarial loss: 0.578963\n",
      "epoch 109; iter: 0; batch classifier loss: 0.407188; batch adversarial loss: 0.588500\n",
      "epoch 110; iter: 0; batch classifier loss: 0.461819; batch adversarial loss: 0.562476\n",
      "epoch 111; iter: 0; batch classifier loss: 0.344337; batch adversarial loss: 0.590889\n",
      "epoch 112; iter: 0; batch classifier loss: 0.374334; batch adversarial loss: 0.534016\n",
      "epoch 113; iter: 0; batch classifier loss: 0.447238; batch adversarial loss: 0.598157\n",
      "epoch 114; iter: 0; batch classifier loss: 0.418284; batch adversarial loss: 0.543544\n",
      "epoch 115; iter: 0; batch classifier loss: 0.412983; batch adversarial loss: 0.526806\n",
      "epoch 116; iter: 0; batch classifier loss: 0.363308; batch adversarial loss: 0.524740\n",
      "epoch 117; iter: 0; batch classifier loss: 0.404076; batch adversarial loss: 0.607310\n",
      "epoch 118; iter: 0; batch classifier loss: 0.439942; batch adversarial loss: 0.580880\n",
      "epoch 119; iter: 0; batch classifier loss: 0.439613; batch adversarial loss: 0.590933\n",
      "epoch 120; iter: 0; batch classifier loss: 0.381846; batch adversarial loss: 0.536158\n",
      "epoch 121; iter: 0; batch classifier loss: 0.370424; batch adversarial loss: 0.526499\n",
      "epoch 122; iter: 0; batch classifier loss: 0.413313; batch adversarial loss: 0.525547\n",
      "epoch 123; iter: 0; batch classifier loss: 0.288942; batch adversarial loss: 0.517142\n",
      "epoch 124; iter: 0; batch classifier loss: 0.404094; batch adversarial loss: 0.490779\n",
      "epoch 125; iter: 0; batch classifier loss: 0.359222; batch adversarial loss: 0.535280\n",
      "epoch 126; iter: 0; batch classifier loss: 0.365341; batch adversarial loss: 0.572253\n",
      "epoch 127; iter: 0; batch classifier loss: 0.397009; batch adversarial loss: 0.500224\n",
      "epoch 128; iter: 0; batch classifier loss: 0.358505; batch adversarial loss: 0.507019\n",
      "epoch 129; iter: 0; batch classifier loss: 0.401869; batch adversarial loss: 0.635933\n",
      "epoch 130; iter: 0; batch classifier loss: 0.326240; batch adversarial loss: 0.545177\n",
      "epoch 131; iter: 0; batch classifier loss: 0.344025; batch adversarial loss: 0.481819\n",
      "epoch 132; iter: 0; batch classifier loss: 0.413885; batch adversarial loss: 0.510969\n",
      "epoch 133; iter: 0; batch classifier loss: 0.429553; batch adversarial loss: 0.597673\n",
      "epoch 134; iter: 0; batch classifier loss: 0.329869; batch adversarial loss: 0.527314\n",
      "epoch 135; iter: 0; batch classifier loss: 0.313018; batch adversarial loss: 0.534209\n",
      "epoch 136; iter: 0; batch classifier loss: 0.376102; batch adversarial loss: 0.544624\n",
      "epoch 137; iter: 0; batch classifier loss: 0.366594; batch adversarial loss: 0.617212\n",
      "epoch 138; iter: 0; batch classifier loss: 0.389215; batch adversarial loss: 0.636378\n",
      "epoch 139; iter: 0; batch classifier loss: 0.389671; batch adversarial loss: 0.571429\n",
      "epoch 140; iter: 0; batch classifier loss: 0.303379; batch adversarial loss: 0.445437\n",
      "epoch 141; iter: 0; batch classifier loss: 0.312864; batch adversarial loss: 0.580756\n",
      "epoch 142; iter: 0; batch classifier loss: 0.312073; batch adversarial loss: 0.572270\n",
      "epoch 143; iter: 0; batch classifier loss: 0.306989; batch adversarial loss: 0.534983\n",
      "epoch 144; iter: 0; batch classifier loss: 0.383059; batch adversarial loss: 0.508762\n",
      "epoch 145; iter: 0; batch classifier loss: 0.342311; batch adversarial loss: 0.535954\n",
      "epoch 146; iter: 0; batch classifier loss: 0.439644; batch adversarial loss: 0.533231\n",
      "epoch 147; iter: 0; batch classifier loss: 0.392872; batch adversarial loss: 0.481998\n",
      "epoch 148; iter: 0; batch classifier loss: 0.447010; batch adversarial loss: 0.554481\n",
      "epoch 149; iter: 0; batch classifier loss: 0.331499; batch adversarial loss: 0.573501\n",
      "epoch 150; iter: 0; batch classifier loss: 0.361312; batch adversarial loss: 0.545326\n",
      "epoch 151; iter: 0; batch classifier loss: 0.387148; batch adversarial loss: 0.517959\n",
      "epoch 152; iter: 0; batch classifier loss: 0.351997; batch adversarial loss: 0.590124\n",
      "epoch 153; iter: 0; batch classifier loss: 0.320449; batch adversarial loss: 0.526416\n",
      "epoch 154; iter: 0; batch classifier loss: 0.339844; batch adversarial loss: 0.463586\n",
      "epoch 155; iter: 0; batch classifier loss: 0.413158; batch adversarial loss: 0.526869\n",
      "epoch 156; iter: 0; batch classifier loss: 0.368706; batch adversarial loss: 0.525146\n",
      "epoch 157; iter: 0; batch classifier loss: 0.349554; batch adversarial loss: 0.510231\n",
      "epoch 158; iter: 0; batch classifier loss: 0.414267; batch adversarial loss: 0.534979\n",
      "epoch 159; iter: 0; batch classifier loss: 0.357934; batch adversarial loss: 0.523313\n",
      "epoch 160; iter: 0; batch classifier loss: 0.397965; batch adversarial loss: 0.607148\n",
      "epoch 161; iter: 0; batch classifier loss: 0.324285; batch adversarial loss: 0.572352\n",
      "epoch 162; iter: 0; batch classifier loss: 0.402697; batch adversarial loss: 0.509252\n",
      "epoch 163; iter: 0; batch classifier loss: 0.312715; batch adversarial loss: 0.554355\n",
      "epoch 164; iter: 0; batch classifier loss: 0.375441; batch adversarial loss: 0.492856\n",
      "epoch 165; iter: 0; batch classifier loss: 0.397489; batch adversarial loss: 0.608123\n",
      "epoch 166; iter: 0; batch classifier loss: 0.367571; batch adversarial loss: 0.563400\n",
      "epoch 167; iter: 0; batch classifier loss: 0.393387; batch adversarial loss: 0.544458\n",
      "epoch 168; iter: 0; batch classifier loss: 0.359736; batch adversarial loss: 0.544003\n",
      "epoch 169; iter: 0; batch classifier loss: 0.395099; batch adversarial loss: 0.535026\n",
      "epoch 170; iter: 0; batch classifier loss: 0.394476; batch adversarial loss: 0.507166\n",
      "epoch 171; iter: 0; batch classifier loss: 0.525955; batch adversarial loss: 0.509762\n",
      "epoch 172; iter: 0; batch classifier loss: 0.322951; batch adversarial loss: 0.543407\n",
      "epoch 173; iter: 0; batch classifier loss: 0.350959; batch adversarial loss: 0.526388\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 174; iter: 0; batch classifier loss: 0.311856; batch adversarial loss: 0.597601\n",
      "epoch 175; iter: 0; batch classifier loss: 0.420203; batch adversarial loss: 0.562973\n",
      "epoch 176; iter: 0; batch classifier loss: 0.415803; batch adversarial loss: 0.608557\n",
      "epoch 177; iter: 0; batch classifier loss: 0.347219; batch adversarial loss: 0.618380\n",
      "epoch 178; iter: 0; batch classifier loss: 0.338952; batch adversarial loss: 0.555281\n",
      "epoch 179; iter: 0; batch classifier loss: 0.368525; batch adversarial loss: 0.536014\n",
      "epoch 180; iter: 0; batch classifier loss: 0.350544; batch adversarial loss: 0.519562\n",
      "epoch 181; iter: 0; batch classifier loss: 0.365284; batch adversarial loss: 0.528018\n",
      "epoch 182; iter: 0; batch classifier loss: 0.404285; batch adversarial loss: 0.562843\n",
      "epoch 183; iter: 0; batch classifier loss: 0.425876; batch adversarial loss: 0.581576\n",
      "epoch 184; iter: 0; batch classifier loss: 0.433382; batch adversarial loss: 0.524270\n",
      "epoch 185; iter: 0; batch classifier loss: 0.357511; batch adversarial loss: 0.510039\n",
      "epoch 186; iter: 0; batch classifier loss: 0.338417; batch adversarial loss: 0.571575\n",
      "epoch 187; iter: 0; batch classifier loss: 0.353622; batch adversarial loss: 0.562336\n",
      "epoch 188; iter: 0; batch classifier loss: 0.332385; batch adversarial loss: 0.563263\n",
      "epoch 189; iter: 0; batch classifier loss: 0.339868; batch adversarial loss: 0.579044\n",
      "epoch 190; iter: 0; batch classifier loss: 0.295075; batch adversarial loss: 0.571139\n",
      "epoch 191; iter: 0; batch classifier loss: 0.391823; batch adversarial loss: 0.633718\n",
      "epoch 192; iter: 0; batch classifier loss: 0.367762; batch adversarial loss: 0.553690\n",
      "epoch 193; iter: 0; batch classifier loss: 0.307102; batch adversarial loss: 0.535412\n",
      "epoch 194; iter: 0; batch classifier loss: 0.379228; batch adversarial loss: 0.627082\n",
      "epoch 195; iter: 0; batch classifier loss: 0.234970; batch adversarial loss: 0.545358\n",
      "epoch 196; iter: 0; batch classifier loss: 0.386928; batch adversarial loss: 0.498717\n",
      "epoch 197; iter: 0; batch classifier loss: 0.357867; batch adversarial loss: 0.553684\n",
      "epoch 198; iter: 0; batch classifier loss: 0.310071; batch adversarial loss: 0.544099\n",
      "epoch 199; iter: 0; batch classifier loss: 0.345630; batch adversarial loss: 0.579970\n",
      "epoch 0; iter: 0; batch classifier loss: 0.697989; batch adversarial loss: 0.671876\n",
      "epoch 1; iter: 0; batch classifier loss: 0.493473; batch adversarial loss: 0.635500\n",
      "epoch 2; iter: 0; batch classifier loss: 0.591181; batch adversarial loss: 0.635832\n",
      "epoch 3; iter: 0; batch classifier loss: 0.525197; batch adversarial loss: 0.584339\n",
      "epoch 4; iter: 0; batch classifier loss: 0.533335; batch adversarial loss: 0.590185\n",
      "epoch 5; iter: 0; batch classifier loss: 0.535329; batch adversarial loss: 0.734997\n",
      "epoch 6; iter: 0; batch classifier loss: 0.504493; batch adversarial loss: 0.657529\n",
      "epoch 7; iter: 0; batch classifier loss: 0.493503; batch adversarial loss: 0.616195\n",
      "epoch 8; iter: 0; batch classifier loss: 0.590549; batch adversarial loss: 0.625722\n",
      "epoch 9; iter: 0; batch classifier loss: 0.494460; batch adversarial loss: 0.583704\n",
      "epoch 10; iter: 0; batch classifier loss: 0.593296; batch adversarial loss: 0.632295\n",
      "epoch 11; iter: 0; batch classifier loss: 0.563009; batch adversarial loss: 0.593823\n",
      "epoch 12; iter: 0; batch classifier loss: 0.467837; batch adversarial loss: 0.562583\n",
      "epoch 13; iter: 0; batch classifier loss: 0.467330; batch adversarial loss: 0.578174\n",
      "epoch 14; iter: 0; batch classifier loss: 0.506599; batch adversarial loss: 0.567990\n",
      "epoch 15; iter: 0; batch classifier loss: 0.545574; batch adversarial loss: 0.560852\n",
      "epoch 16; iter: 0; batch classifier loss: 0.542560; batch adversarial loss: 0.570074\n",
      "epoch 17; iter: 0; batch classifier loss: 0.515193; batch adversarial loss: 0.524355\n",
      "epoch 18; iter: 0; batch classifier loss: 0.519903; batch adversarial loss: 0.535046\n",
      "epoch 19; iter: 0; batch classifier loss: 0.559586; batch adversarial loss: 0.605991\n",
      "epoch 20; iter: 0; batch classifier loss: 0.511693; batch adversarial loss: 0.636905\n",
      "epoch 21; iter: 0; batch classifier loss: 0.565659; batch adversarial loss: 0.556077\n",
      "epoch 22; iter: 0; batch classifier loss: 0.452591; batch adversarial loss: 0.561117\n",
      "epoch 23; iter: 0; batch classifier loss: 0.508351; batch adversarial loss: 0.538225\n",
      "epoch 24; iter: 0; batch classifier loss: 0.496968; batch adversarial loss: 0.543622\n",
      "epoch 25; iter: 0; batch classifier loss: 0.478602; batch adversarial loss: 0.589558\n",
      "epoch 26; iter: 0; batch classifier loss: 0.519155; batch adversarial loss: 0.514689\n",
      "epoch 27; iter: 0; batch classifier loss: 0.461917; batch adversarial loss: 0.573317\n",
      "epoch 28; iter: 0; batch classifier loss: 0.478605; batch adversarial loss: 0.598132\n",
      "epoch 29; iter: 0; batch classifier loss: 0.471408; batch adversarial loss: 0.598427\n",
      "epoch 30; iter: 0; batch classifier loss: 0.504957; batch adversarial loss: 0.543334\n",
      "epoch 31; iter: 0; batch classifier loss: 0.476608; batch adversarial loss: 0.519484\n",
      "epoch 32; iter: 0; batch classifier loss: 0.461255; batch adversarial loss: 0.545958\n",
      "epoch 33; iter: 0; batch classifier loss: 0.417182; batch adversarial loss: 0.520590\n",
      "epoch 34; iter: 0; batch classifier loss: 0.476582; batch adversarial loss: 0.554148\n",
      "epoch 35; iter: 0; batch classifier loss: 0.444188; batch adversarial loss: 0.606356\n",
      "epoch 36; iter: 0; batch classifier loss: 0.462161; batch adversarial loss: 0.483658\n",
      "epoch 37; iter: 0; batch classifier loss: 0.410956; batch adversarial loss: 0.562178\n",
      "epoch 38; iter: 0; batch classifier loss: 0.426845; batch adversarial loss: 0.615007\n",
      "epoch 39; iter: 0; batch classifier loss: 0.427198; batch adversarial loss: 0.589427\n",
      "epoch 40; iter: 0; batch classifier loss: 0.430259; batch adversarial loss: 0.579546\n",
      "epoch 41; iter: 0; batch classifier loss: 0.425972; batch adversarial loss: 0.579557\n",
      "epoch 42; iter: 0; batch classifier loss: 0.438975; batch adversarial loss: 0.553298\n",
      "epoch 43; iter: 0; batch classifier loss: 0.455667; batch adversarial loss: 0.571106\n",
      "epoch 44; iter: 0; batch classifier loss: 0.456396; batch adversarial loss: 0.491528\n",
      "epoch 45; iter: 0; batch classifier loss: 0.418116; batch adversarial loss: 0.581425\n",
      "epoch 46; iter: 0; batch classifier loss: 0.480811; batch adversarial loss: 0.580209\n",
      "epoch 47; iter: 0; batch classifier loss: 0.411755; batch adversarial loss: 0.598408\n",
      "epoch 48; iter: 0; batch classifier loss: 0.396783; batch adversarial loss: 0.599378\n",
      "epoch 49; iter: 0; batch classifier loss: 0.462769; batch adversarial loss: 0.480449\n",
      "epoch 50; iter: 0; batch classifier loss: 0.446262; batch adversarial loss: 0.518899\n",
      "epoch 51; iter: 0; batch classifier loss: 0.442022; batch adversarial loss: 0.517528\n",
      "epoch 52; iter: 0; batch classifier loss: 0.398300; batch adversarial loss: 0.508166\n",
      "epoch 53; iter: 0; batch classifier loss: 0.400512; batch adversarial loss: 0.590268\n",
      "epoch 54; iter: 0; batch classifier loss: 0.368158; batch adversarial loss: 0.517338\n",
      "epoch 55; iter: 0; batch classifier loss: 0.473016; batch adversarial loss: 0.570072\n",
      "epoch 56; iter: 0; batch classifier loss: 0.385492; batch adversarial loss: 0.588432\n",
      "epoch 57; iter: 0; batch classifier loss: 0.403848; batch adversarial loss: 0.517171\n",
      "epoch 58; iter: 0; batch classifier loss: 0.398761; batch adversarial loss: 0.463876\n",
      "epoch 59; iter: 0; batch classifier loss: 0.381700; batch adversarial loss: 0.543257\n",
      "epoch 60; iter: 0; batch classifier loss: 0.429833; batch adversarial loss: 0.579373\n",
      "epoch 61; iter: 0; batch classifier loss: 0.395461; batch adversarial loss: 0.539236\n",
      "epoch 62; iter: 0; batch classifier loss: 0.427158; batch adversarial loss: 0.498793\n",
      "epoch 63; iter: 0; batch classifier loss: 0.375029; batch adversarial loss: 0.453854\n",
      "epoch 64; iter: 0; batch classifier loss: 0.428235; batch adversarial loss: 0.578183\n",
      "epoch 65; iter: 0; batch classifier loss: 0.403247; batch adversarial loss: 0.481419\n",
      "epoch 66; iter: 0; batch classifier loss: 0.451062; batch adversarial loss: 0.500923\n",
      "epoch 67; iter: 0; batch classifier loss: 0.411717; batch adversarial loss: 0.598335\n",
      "epoch 68; iter: 0; batch classifier loss: 0.360303; batch adversarial loss: 0.536782\n",
      "epoch 69; iter: 0; batch classifier loss: 0.428128; batch adversarial loss: 0.599134\n",
      "epoch 70; iter: 0; batch classifier loss: 0.325974; batch adversarial loss: 0.555034\n",
      "epoch 71; iter: 0; batch classifier loss: 0.391383; batch adversarial loss: 0.579863\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 72; iter: 0; batch classifier loss: 0.416249; batch adversarial loss: 0.528804\n",
      "epoch 73; iter: 0; batch classifier loss: 0.398462; batch adversarial loss: 0.580218\n",
      "epoch 74; iter: 0; batch classifier loss: 0.425088; batch adversarial loss: 0.532702\n",
      "epoch 75; iter: 0; batch classifier loss: 0.475751; batch adversarial loss: 0.544825\n",
      "epoch 76; iter: 0; batch classifier loss: 0.455009; batch adversarial loss: 0.545477\n",
      "epoch 77; iter: 0; batch classifier loss: 0.483145; batch adversarial loss: 0.627302\n",
      "epoch 78; iter: 0; batch classifier loss: 0.377245; batch adversarial loss: 0.572014\n",
      "epoch 79; iter: 0; batch classifier loss: 0.418347; batch adversarial loss: 0.571478\n",
      "epoch 80; iter: 0; batch classifier loss: 0.435920; batch adversarial loss: 0.627961\n",
      "epoch 81; iter: 0; batch classifier loss: 0.425144; batch adversarial loss: 0.489321\n",
      "epoch 82; iter: 0; batch classifier loss: 0.331509; batch adversarial loss: 0.608312\n",
      "epoch 83; iter: 0; batch classifier loss: 0.330920; batch adversarial loss: 0.627316\n",
      "epoch 84; iter: 0; batch classifier loss: 0.430213; batch adversarial loss: 0.517240\n",
      "epoch 85; iter: 0; batch classifier loss: 0.426231; batch adversarial loss: 0.554053\n",
      "epoch 86; iter: 0; batch classifier loss: 0.365102; batch adversarial loss: 0.544853\n",
      "epoch 87; iter: 0; batch classifier loss: 0.336250; batch adversarial loss: 0.508242\n",
      "epoch 88; iter: 0; batch classifier loss: 0.396628; batch adversarial loss: 0.526782\n",
      "epoch 89; iter: 0; batch classifier loss: 0.458317; batch adversarial loss: 0.526057\n",
      "epoch 90; iter: 0; batch classifier loss: 0.492745; batch adversarial loss: 0.535731\n",
      "epoch 91; iter: 0; batch classifier loss: 0.385501; batch adversarial loss: 0.536179\n",
      "epoch 92; iter: 0; batch classifier loss: 0.433763; batch adversarial loss: 0.563337\n",
      "epoch 93; iter: 0; batch classifier loss: 0.394691; batch adversarial loss: 0.490947\n",
      "epoch 94; iter: 0; batch classifier loss: 0.467189; batch adversarial loss: 0.562489\n",
      "epoch 95; iter: 0; batch classifier loss: 0.441016; batch adversarial loss: 0.508450\n",
      "epoch 96; iter: 0; batch classifier loss: 0.455700; batch adversarial loss: 0.499436\n",
      "epoch 97; iter: 0; batch classifier loss: 0.346193; batch adversarial loss: 0.527228\n",
      "epoch 98; iter: 0; batch classifier loss: 0.422070; batch adversarial loss: 0.563472\n",
      "epoch 99; iter: 0; batch classifier loss: 0.376879; batch adversarial loss: 0.589877\n",
      "epoch 100; iter: 0; batch classifier loss: 0.445435; batch adversarial loss: 0.671085\n",
      "epoch 101; iter: 0; batch classifier loss: 0.424711; batch adversarial loss: 0.544135\n",
      "epoch 102; iter: 0; batch classifier loss: 0.415535; batch adversarial loss: 0.507860\n",
      "epoch 103; iter: 0; batch classifier loss: 0.420916; batch adversarial loss: 0.599476\n",
      "epoch 104; iter: 0; batch classifier loss: 0.340626; batch adversarial loss: 0.571131\n",
      "epoch 105; iter: 0; batch classifier loss: 0.312562; batch adversarial loss: 0.535952\n",
      "epoch 106; iter: 0; batch classifier loss: 0.428035; batch adversarial loss: 0.553873\n",
      "epoch 107; iter: 0; batch classifier loss: 0.368882; batch adversarial loss: 0.553529\n",
      "epoch 108; iter: 0; batch classifier loss: 0.408592; batch adversarial loss: 0.507678\n",
      "epoch 109; iter: 0; batch classifier loss: 0.382786; batch adversarial loss: 0.554859\n",
      "epoch 110; iter: 0; batch classifier loss: 0.408244; batch adversarial loss: 0.525521\n",
      "epoch 111; iter: 0; batch classifier loss: 0.355078; batch adversarial loss: 0.508054\n",
      "epoch 112; iter: 0; batch classifier loss: 0.323090; batch adversarial loss: 0.598958\n",
      "epoch 113; iter: 0; batch classifier loss: 0.366867; batch adversarial loss: 0.526543\n",
      "epoch 114; iter: 0; batch classifier loss: 0.405661; batch adversarial loss: 0.553973\n",
      "epoch 115; iter: 0; batch classifier loss: 0.347347; batch adversarial loss: 0.553312\n",
      "epoch 116; iter: 0; batch classifier loss: 0.426821; batch adversarial loss: 0.489731\n",
      "epoch 117; iter: 0; batch classifier loss: 0.319677; batch adversarial loss: 0.571524\n",
      "epoch 118; iter: 0; batch classifier loss: 0.299069; batch adversarial loss: 0.553870\n",
      "epoch 119; iter: 0; batch classifier loss: 0.439250; batch adversarial loss: 0.525702\n",
      "epoch 120; iter: 0; batch classifier loss: 0.334164; batch adversarial loss: 0.580958\n",
      "epoch 121; iter: 0; batch classifier loss: 0.316312; batch adversarial loss: 0.517368\n",
      "epoch 122; iter: 0; batch classifier loss: 0.342799; batch adversarial loss: 0.535292\n",
      "epoch 123; iter: 0; batch classifier loss: 0.306612; batch adversarial loss: 0.509270\n",
      "epoch 124; iter: 0; batch classifier loss: 0.415154; batch adversarial loss: 0.472500\n",
      "epoch 125; iter: 0; batch classifier loss: 0.392480; batch adversarial loss: 0.563037\n",
      "epoch 126; iter: 0; batch classifier loss: 0.346885; batch adversarial loss: 0.553349\n",
      "epoch 127; iter: 0; batch classifier loss: 0.404343; batch adversarial loss: 0.544320\n",
      "epoch 128; iter: 0; batch classifier loss: 0.316475; batch adversarial loss: 0.552508\n",
      "epoch 129; iter: 0; batch classifier loss: 0.506352; batch adversarial loss: 0.588210\n",
      "epoch 130; iter: 0; batch classifier loss: 0.375124; batch adversarial loss: 0.643336\n",
      "epoch 131; iter: 0; batch classifier loss: 0.383382; batch adversarial loss: 0.552886\n",
      "epoch 132; iter: 0; batch classifier loss: 0.389003; batch adversarial loss: 0.545073\n",
      "epoch 133; iter: 0; batch classifier loss: 0.349387; batch adversarial loss: 0.590558\n",
      "epoch 134; iter: 0; batch classifier loss: 0.383952; batch adversarial loss: 0.553436\n",
      "epoch 135; iter: 0; batch classifier loss: 0.336444; batch adversarial loss: 0.580235\n",
      "epoch 136; iter: 0; batch classifier loss: 0.264347; batch adversarial loss: 0.561387\n",
      "epoch 137; iter: 0; batch classifier loss: 0.411314; batch adversarial loss: 0.544525\n",
      "epoch 138; iter: 0; batch classifier loss: 0.460419; batch adversarial loss: 0.590726\n",
      "epoch 139; iter: 0; batch classifier loss: 0.305832; batch adversarial loss: 0.534835\n",
      "epoch 140; iter: 0; batch classifier loss: 0.387126; batch adversarial loss: 0.544988\n",
      "epoch 141; iter: 0; batch classifier loss: 0.389945; batch adversarial loss: 0.650328\n",
      "epoch 142; iter: 0; batch classifier loss: 0.298446; batch adversarial loss: 0.591139\n",
      "epoch 143; iter: 0; batch classifier loss: 0.358643; batch adversarial loss: 0.579479\n",
      "epoch 144; iter: 0; batch classifier loss: 0.411444; batch adversarial loss: 0.509054\n",
      "epoch 145; iter: 0; batch classifier loss: 0.416088; batch adversarial loss: 0.562603\n",
      "epoch 146; iter: 0; batch classifier loss: 0.395375; batch adversarial loss: 0.500890\n",
      "epoch 147; iter: 0; batch classifier loss: 0.391826; batch adversarial loss: 0.524867\n",
      "epoch 148; iter: 0; batch classifier loss: 0.332965; batch adversarial loss: 0.517899\n",
      "epoch 149; iter: 0; batch classifier loss: 0.342114; batch adversarial loss: 0.572443\n",
      "epoch 150; iter: 0; batch classifier loss: 0.440939; batch adversarial loss: 0.562756\n",
      "epoch 151; iter: 0; batch classifier loss: 0.291767; batch adversarial loss: 0.572378\n",
      "epoch 152; iter: 0; batch classifier loss: 0.366853; batch adversarial loss: 0.544980\n",
      "epoch 153; iter: 0; batch classifier loss: 0.402703; batch adversarial loss: 0.534767\n",
      "epoch 154; iter: 0; batch classifier loss: 0.357170; batch adversarial loss: 0.555431\n",
      "epoch 155; iter: 0; batch classifier loss: 0.339657; batch adversarial loss: 0.526655\n",
      "epoch 156; iter: 0; batch classifier loss: 0.331621; batch adversarial loss: 0.599645\n",
      "epoch 157; iter: 0; batch classifier loss: 0.401773; batch adversarial loss: 0.498114\n",
      "epoch 158; iter: 0; batch classifier loss: 0.342747; batch adversarial loss: 0.525980\n",
      "epoch 159; iter: 0; batch classifier loss: 0.356206; batch adversarial loss: 0.526010\n",
      "epoch 160; iter: 0; batch classifier loss: 0.424221; batch adversarial loss: 0.507732\n",
      "epoch 161; iter: 0; batch classifier loss: 0.429595; batch adversarial loss: 0.517329\n",
      "epoch 162; iter: 0; batch classifier loss: 0.330125; batch adversarial loss: 0.498866\n",
      "epoch 163; iter: 0; batch classifier loss: 0.350045; batch adversarial loss: 0.572220\n",
      "epoch 164; iter: 0; batch classifier loss: 0.356206; batch adversarial loss: 0.508930\n",
      "epoch 165; iter: 0; batch classifier loss: 0.352872; batch adversarial loss: 0.589722\n",
      "epoch 166; iter: 0; batch classifier loss: 0.390987; batch adversarial loss: 0.491030\n",
      "epoch 167; iter: 0; batch classifier loss: 0.397245; batch adversarial loss: 0.571312\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 168; iter: 0; batch classifier loss: 0.388703; batch adversarial loss: 0.571691\n",
      "epoch 169; iter: 0; batch classifier loss: 0.398319; batch adversarial loss: 0.617134\n",
      "epoch 170; iter: 0; batch classifier loss: 0.382251; batch adversarial loss: 0.598108\n",
      "epoch 171; iter: 0; batch classifier loss: 0.366895; batch adversarial loss: 0.518129\n",
      "epoch 172; iter: 0; batch classifier loss: 0.321240; batch adversarial loss: 0.517646\n",
      "epoch 173; iter: 0; batch classifier loss: 0.434850; batch adversarial loss: 0.588803\n",
      "epoch 174; iter: 0; batch classifier loss: 0.431711; batch adversarial loss: 0.580299\n",
      "epoch 175; iter: 0; batch classifier loss: 0.442089; batch adversarial loss: 0.535421\n",
      "epoch 176; iter: 0; batch classifier loss: 0.283281; batch adversarial loss: 0.553393\n",
      "epoch 177; iter: 0; batch classifier loss: 0.349879; batch adversarial loss: 0.563366\n",
      "epoch 178; iter: 0; batch classifier loss: 0.405319; batch adversarial loss: 0.562372\n",
      "epoch 179; iter: 0; batch classifier loss: 0.454313; batch adversarial loss: 0.571481\n",
      "epoch 180; iter: 0; batch classifier loss: 0.355988; batch adversarial loss: 0.543105\n",
      "epoch 181; iter: 0; batch classifier loss: 0.318544; batch adversarial loss: 0.569386\n",
      "epoch 182; iter: 0; batch classifier loss: 0.414658; batch adversarial loss: 0.552954\n",
      "epoch 183; iter: 0; batch classifier loss: 0.430450; batch adversarial loss: 0.568763\n",
      "epoch 184; iter: 0; batch classifier loss: 0.375374; batch adversarial loss: 0.497663\n",
      "epoch 185; iter: 0; batch classifier loss: 0.383417; batch adversarial loss: 0.550253\n",
      "epoch 186; iter: 0; batch classifier loss: 0.351551; batch adversarial loss: 0.518690\n",
      "epoch 187; iter: 0; batch classifier loss: 0.429559; batch adversarial loss: 0.595926\n",
      "epoch 188; iter: 0; batch classifier loss: 0.416194; batch adversarial loss: 0.509206\n",
      "epoch 189; iter: 0; batch classifier loss: 0.482691; batch adversarial loss: 0.477114\n",
      "epoch 190; iter: 0; batch classifier loss: 0.323954; batch adversarial loss: 0.518061\n",
      "epoch 191; iter: 0; batch classifier loss: 0.374812; batch adversarial loss: 0.547814\n",
      "epoch 192; iter: 0; batch classifier loss: 0.390108; batch adversarial loss: 0.613538\n",
      "epoch 193; iter: 0; batch classifier loss: 0.388964; batch adversarial loss: 0.543995\n",
      "epoch 194; iter: 0; batch classifier loss: 0.389896; batch adversarial loss: 0.527297\n",
      "epoch 195; iter: 0; batch classifier loss: 0.362901; batch adversarial loss: 0.552278\n",
      "epoch 196; iter: 0; batch classifier loss: 0.355454; batch adversarial loss: 0.526384\n",
      "epoch 197; iter: 0; batch classifier loss: 0.291432; batch adversarial loss: 0.507753\n",
      "epoch 198; iter: 0; batch classifier loss: 0.358462; batch adversarial loss: 0.544028\n",
      "epoch 199; iter: 0; batch classifier loss: 0.330122; batch adversarial loss: 0.553853\n",
      "epoch 0; iter: 0; batch classifier loss: 0.732947; batch adversarial loss: 0.614979\n",
      "epoch 1; iter: 0; batch classifier loss: 0.627339; batch adversarial loss: 0.605172\n",
      "epoch 2; iter: 0; batch classifier loss: 0.573792; batch adversarial loss: 0.635739\n",
      "epoch 3; iter: 0; batch classifier loss: 0.566254; batch adversarial loss: 0.651897\n",
      "epoch 4; iter: 0; batch classifier loss: 0.543426; batch adversarial loss: 0.613068\n",
      "epoch 5; iter: 0; batch classifier loss: 0.588653; batch adversarial loss: 0.641924\n",
      "epoch 6; iter: 0; batch classifier loss: 0.513710; batch adversarial loss: 0.624913\n",
      "epoch 7; iter: 0; batch classifier loss: 0.514764; batch adversarial loss: 0.643728\n",
      "epoch 8; iter: 0; batch classifier loss: 0.549850; batch adversarial loss: 0.600590\n",
      "epoch 9; iter: 0; batch classifier loss: 0.528926; batch adversarial loss: 0.625223\n",
      "epoch 10; iter: 0; batch classifier loss: 0.505570; batch adversarial loss: 0.596660\n",
      "epoch 11; iter: 0; batch classifier loss: 0.534118; batch adversarial loss: 0.640192\n",
      "epoch 12; iter: 0; batch classifier loss: 0.535310; batch adversarial loss: 0.623173\n",
      "epoch 13; iter: 0; batch classifier loss: 0.452911; batch adversarial loss: 0.567014\n",
      "epoch 14; iter: 0; batch classifier loss: 0.647343; batch adversarial loss: 0.635904\n",
      "epoch 15; iter: 0; batch classifier loss: 0.518812; batch adversarial loss: 0.566343\n",
      "epoch 16; iter: 0; batch classifier loss: 0.487444; batch adversarial loss: 0.556873\n",
      "epoch 17; iter: 0; batch classifier loss: 0.524221; batch adversarial loss: 0.532453\n",
      "epoch 18; iter: 0; batch classifier loss: 0.434911; batch adversarial loss: 0.574170\n",
      "epoch 19; iter: 0; batch classifier loss: 0.471825; batch adversarial loss: 0.567087\n",
      "epoch 20; iter: 0; batch classifier loss: 0.504904; batch adversarial loss: 0.587479\n",
      "epoch 21; iter: 0; batch classifier loss: 0.540630; batch adversarial loss: 0.549736\n",
      "epoch 22; iter: 0; batch classifier loss: 0.402734; batch adversarial loss: 0.531182\n",
      "epoch 23; iter: 0; batch classifier loss: 0.465482; batch adversarial loss: 0.549129\n",
      "epoch 24; iter: 0; batch classifier loss: 0.455338; batch adversarial loss: 0.569071\n",
      "epoch 25; iter: 0; batch classifier loss: 0.425702; batch adversarial loss: 0.586064\n",
      "epoch 26; iter: 0; batch classifier loss: 0.496805; batch adversarial loss: 0.522782\n",
      "epoch 27; iter: 0; batch classifier loss: 0.453481; batch adversarial loss: 0.540838\n",
      "epoch 28; iter: 0; batch classifier loss: 0.463934; batch adversarial loss: 0.553788\n",
      "epoch 29; iter: 0; batch classifier loss: 0.509262; batch adversarial loss: 0.559510\n",
      "epoch 30; iter: 0; batch classifier loss: 0.447555; batch adversarial loss: 0.534759\n",
      "epoch 31; iter: 0; batch classifier loss: 0.479479; batch adversarial loss: 0.604629\n",
      "epoch 32; iter: 0; batch classifier loss: 0.529813; batch adversarial loss: 0.566082\n",
      "epoch 33; iter: 0; batch classifier loss: 0.461022; batch adversarial loss: 0.511277\n",
      "epoch 34; iter: 0; batch classifier loss: 0.435662; batch adversarial loss: 0.601615\n",
      "epoch 35; iter: 0; batch classifier loss: 0.423177; batch adversarial loss: 0.614321\n",
      "epoch 36; iter: 0; batch classifier loss: 0.462063; batch adversarial loss: 0.568997\n",
      "epoch 37; iter: 0; batch classifier loss: 0.439895; batch adversarial loss: 0.640928\n",
      "epoch 38; iter: 0; batch classifier loss: 0.466049; batch adversarial loss: 0.536810\n",
      "epoch 39; iter: 0; batch classifier loss: 0.439815; batch adversarial loss: 0.598032\n",
      "epoch 40; iter: 0; batch classifier loss: 0.500072; batch adversarial loss: 0.560277\n",
      "epoch 41; iter: 0; batch classifier loss: 0.414674; batch adversarial loss: 0.564057\n",
      "epoch 42; iter: 0; batch classifier loss: 0.443239; batch adversarial loss: 0.603840\n",
      "epoch 43; iter: 0; batch classifier loss: 0.467701; batch adversarial loss: 0.547366\n",
      "epoch 44; iter: 0; batch classifier loss: 0.398555; batch adversarial loss: 0.596833\n",
      "epoch 45; iter: 0; batch classifier loss: 0.454077; batch adversarial loss: 0.529053\n",
      "epoch 46; iter: 0; batch classifier loss: 0.534917; batch adversarial loss: 0.604686\n",
      "epoch 47; iter: 0; batch classifier loss: 0.430286; batch adversarial loss: 0.570855\n",
      "epoch 48; iter: 0; batch classifier loss: 0.418829; batch adversarial loss: 0.528301\n",
      "epoch 49; iter: 0; batch classifier loss: 0.378745; batch adversarial loss: 0.630026\n",
      "epoch 50; iter: 0; batch classifier loss: 0.407334; batch adversarial loss: 0.596287\n",
      "epoch 51; iter: 0; batch classifier loss: 0.468607; batch adversarial loss: 0.528158\n",
      "epoch 52; iter: 0; batch classifier loss: 0.470969; batch adversarial loss: 0.604884\n",
      "epoch 53; iter: 0; batch classifier loss: 0.501431; batch adversarial loss: 0.536660\n",
      "epoch 54; iter: 0; batch classifier loss: 0.489122; batch adversarial loss: 0.587884\n",
      "epoch 55; iter: 0; batch classifier loss: 0.416545; batch adversarial loss: 0.614088\n",
      "epoch 56; iter: 0; batch classifier loss: 0.494997; batch adversarial loss: 0.597242\n",
      "epoch 57; iter: 0; batch classifier loss: 0.453706; batch adversarial loss: 0.597738\n",
      "epoch 58; iter: 0; batch classifier loss: 0.417586; batch adversarial loss: 0.544245\n",
      "epoch 59; iter: 0; batch classifier loss: 0.408439; batch adversarial loss: 0.578925\n",
      "epoch 60; iter: 0; batch classifier loss: 0.382076; batch adversarial loss: 0.640229\n",
      "epoch 61; iter: 0; batch classifier loss: 0.387774; batch adversarial loss: 0.579186\n",
      "epoch 62; iter: 0; batch classifier loss: 0.426299; batch adversarial loss: 0.533365\n",
      "epoch 63; iter: 0; batch classifier loss: 0.391255; batch adversarial loss: 0.499284\n",
      "epoch 64; iter: 0; batch classifier loss: 0.414455; batch adversarial loss: 0.596028\n",
      "epoch 65; iter: 0; batch classifier loss: 0.490456; batch adversarial loss: 0.515554\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 66; iter: 0; batch classifier loss: 0.417100; batch adversarial loss: 0.559962\n",
      "epoch 67; iter: 0; batch classifier loss: 0.372387; batch adversarial loss: 0.548690\n",
      "epoch 68; iter: 0; batch classifier loss: 0.412956; batch adversarial loss: 0.542678\n",
      "epoch 69; iter: 0; batch classifier loss: 0.363588; batch adversarial loss: 0.624342\n",
      "epoch 70; iter: 0; batch classifier loss: 0.470879; batch adversarial loss: 0.547555\n",
      "epoch 71; iter: 0; batch classifier loss: 0.463238; batch adversarial loss: 0.582493\n",
      "epoch 72; iter: 0; batch classifier loss: 0.371577; batch adversarial loss: 0.538359\n",
      "epoch 73; iter: 0; batch classifier loss: 0.302660; batch adversarial loss: 0.556322\n",
      "epoch 74; iter: 0; batch classifier loss: 0.425934; batch adversarial loss: 0.520502\n",
      "epoch 75; iter: 0; batch classifier loss: 0.413522; batch adversarial loss: 0.603302\n",
      "epoch 76; iter: 0; batch classifier loss: 0.335798; batch adversarial loss: 0.562974\n",
      "epoch 77; iter: 0; batch classifier loss: 0.429407; batch adversarial loss: 0.528231\n",
      "epoch 78; iter: 0; batch classifier loss: 0.436755; batch adversarial loss: 0.605430\n",
      "epoch 79; iter: 0; batch classifier loss: 0.412134; batch adversarial loss: 0.495416\n",
      "epoch 80; iter: 0; batch classifier loss: 0.389242; batch adversarial loss: 0.537137\n",
      "epoch 81; iter: 0; batch classifier loss: 0.382769; batch adversarial loss: 0.503336\n",
      "epoch 82; iter: 0; batch classifier loss: 0.355053; batch adversarial loss: 0.605092\n",
      "epoch 83; iter: 0; batch classifier loss: 0.385784; batch adversarial loss: 0.519167\n",
      "epoch 84; iter: 0; batch classifier loss: 0.382798; batch adversarial loss: 0.501241\n",
      "epoch 85; iter: 0; batch classifier loss: 0.438276; batch adversarial loss: 0.582711\n",
      "epoch 86; iter: 0; batch classifier loss: 0.379314; batch adversarial loss: 0.577275\n",
      "epoch 87; iter: 0; batch classifier loss: 0.397142; batch adversarial loss: 0.572819\n",
      "epoch 88; iter: 0; batch classifier loss: 0.397049; batch adversarial loss: 0.501059\n",
      "epoch 89; iter: 0; batch classifier loss: 0.453211; batch adversarial loss: 0.562161\n",
      "epoch 90; iter: 0; batch classifier loss: 0.384844; batch adversarial loss: 0.599808\n",
      "epoch 91; iter: 0; batch classifier loss: 0.347719; batch adversarial loss: 0.508440\n",
      "epoch 92; iter: 0; batch classifier loss: 0.376205; batch adversarial loss: 0.614262\n",
      "epoch 93; iter: 0; batch classifier loss: 0.404744; batch adversarial loss: 0.588678\n",
      "epoch 94; iter: 0; batch classifier loss: 0.428630; batch adversarial loss: 0.466065\n",
      "epoch 95; iter: 0; batch classifier loss: 0.380346; batch adversarial loss: 0.511721\n",
      "epoch 96; iter: 0; batch classifier loss: 0.365298; batch adversarial loss: 0.589283\n",
      "epoch 97; iter: 0; batch classifier loss: 0.437551; batch adversarial loss: 0.580467\n",
      "epoch 98; iter: 0; batch classifier loss: 0.404858; batch adversarial loss: 0.527804\n",
      "epoch 99; iter: 0; batch classifier loss: 0.463800; batch adversarial loss: 0.477565\n",
      "epoch 100; iter: 0; batch classifier loss: 0.411379; batch adversarial loss: 0.571626\n",
      "epoch 101; iter: 0; batch classifier loss: 0.440015; batch adversarial loss: 0.614814\n",
      "epoch 102; iter: 0; batch classifier loss: 0.373560; batch adversarial loss: 0.597163\n",
      "epoch 103; iter: 0; batch classifier loss: 0.372876; batch adversarial loss: 0.545234\n",
      "epoch 104; iter: 0; batch classifier loss: 0.388772; batch adversarial loss: 0.647331\n",
      "epoch 105; iter: 0; batch classifier loss: 0.365207; batch adversarial loss: 0.587845\n",
      "epoch 106; iter: 0; batch classifier loss: 0.341379; batch adversarial loss: 0.553650\n",
      "epoch 107; iter: 0; batch classifier loss: 0.382777; batch adversarial loss: 0.553743\n",
      "epoch 108; iter: 0; batch classifier loss: 0.307248; batch adversarial loss: 0.605406\n",
      "epoch 109; iter: 0; batch classifier loss: 0.378035; batch adversarial loss: 0.613723\n",
      "epoch 110; iter: 0; batch classifier loss: 0.421620; batch adversarial loss: 0.588423\n",
      "epoch 111; iter: 0; batch classifier loss: 0.351568; batch adversarial loss: 0.612453\n",
      "epoch 112; iter: 0; batch classifier loss: 0.371680; batch adversarial loss: 0.544002\n",
      "epoch 113; iter: 0; batch classifier loss: 0.377124; batch adversarial loss: 0.511222\n",
      "epoch 114; iter: 0; batch classifier loss: 0.358142; batch adversarial loss: 0.527041\n",
      "epoch 115; iter: 0; batch classifier loss: 0.407121; batch adversarial loss: 0.562708\n",
      "epoch 116; iter: 0; batch classifier loss: 0.362015; batch adversarial loss: 0.605435\n",
      "epoch 117; iter: 0; batch classifier loss: 0.372697; batch adversarial loss: 0.491671\n",
      "epoch 118; iter: 0; batch classifier loss: 0.421158; batch adversarial loss: 0.621648\n",
      "epoch 119; iter: 0; batch classifier loss: 0.440511; batch adversarial loss: 0.544873\n",
      "epoch 120; iter: 0; batch classifier loss: 0.403471; batch adversarial loss: 0.586860\n",
      "epoch 121; iter: 0; batch classifier loss: 0.361211; batch adversarial loss: 0.639043\n",
      "epoch 122; iter: 0; batch classifier loss: 0.462670; batch adversarial loss: 0.580670\n",
      "epoch 123; iter: 0; batch classifier loss: 0.400330; batch adversarial loss: 0.536011\n",
      "epoch 124; iter: 0; batch classifier loss: 0.346017; batch adversarial loss: 0.571761\n",
      "epoch 125; iter: 0; batch classifier loss: 0.401520; batch adversarial loss: 0.621664\n",
      "epoch 126; iter: 0; batch classifier loss: 0.453679; batch adversarial loss: 0.553210\n",
      "epoch 127; iter: 0; batch classifier loss: 0.366901; batch adversarial loss: 0.536580\n",
      "epoch 128; iter: 0; batch classifier loss: 0.376191; batch adversarial loss: 0.477936\n",
      "epoch 129; iter: 0; batch classifier loss: 0.336765; batch adversarial loss: 0.579313\n",
      "epoch 130; iter: 0; batch classifier loss: 0.401525; batch adversarial loss: 0.528530\n",
      "epoch 131; iter: 0; batch classifier loss: 0.373163; batch adversarial loss: 0.536701\n",
      "epoch 132; iter: 0; batch classifier loss: 0.473560; batch adversarial loss: 0.502165\n",
      "epoch 133; iter: 0; batch classifier loss: 0.505036; batch adversarial loss: 0.553401\n",
      "epoch 134; iter: 0; batch classifier loss: 0.378503; batch adversarial loss: 0.536032\n",
      "epoch 135; iter: 0; batch classifier loss: 0.329641; batch adversarial loss: 0.554736\n",
      "epoch 136; iter: 0; batch classifier loss: 0.326716; batch adversarial loss: 0.579387\n",
      "epoch 137; iter: 0; batch classifier loss: 0.313996; batch adversarial loss: 0.624591\n",
      "epoch 138; iter: 0; batch classifier loss: 0.384706; batch adversarial loss: 0.493848\n",
      "epoch 139; iter: 0; batch classifier loss: 0.437035; batch adversarial loss: 0.604614\n",
      "epoch 140; iter: 0; batch classifier loss: 0.386710; batch adversarial loss: 0.579316\n",
      "epoch 141; iter: 0; batch classifier loss: 0.390088; batch adversarial loss: 0.527925\n",
      "epoch 142; iter: 0; batch classifier loss: 0.362496; batch adversarial loss: 0.570448\n",
      "epoch 143; iter: 0; batch classifier loss: 0.314875; batch adversarial loss: 0.675336\n",
      "epoch 144; iter: 0; batch classifier loss: 0.458527; batch adversarial loss: 0.579402\n",
      "epoch 145; iter: 0; batch classifier loss: 0.432968; batch adversarial loss: 0.571036\n",
      "epoch 146; iter: 0; batch classifier loss: 0.350080; batch adversarial loss: 0.536020\n",
      "epoch 147; iter: 0; batch classifier loss: 0.318680; batch adversarial loss: 0.519411\n",
      "epoch 148; iter: 0; batch classifier loss: 0.407223; batch adversarial loss: 0.614127\n",
      "epoch 149; iter: 0; batch classifier loss: 0.334091; batch adversarial loss: 0.570380\n",
      "epoch 150; iter: 0; batch classifier loss: 0.426326; batch adversarial loss: 0.587818\n",
      "epoch 151; iter: 0; batch classifier loss: 0.345601; batch adversarial loss: 0.580137\n",
      "epoch 152; iter: 0; batch classifier loss: 0.345282; batch adversarial loss: 0.534921\n",
      "epoch 153; iter: 0; batch classifier loss: 0.376142; batch adversarial loss: 0.560734\n",
      "epoch 154; iter: 0; batch classifier loss: 0.397890; batch adversarial loss: 0.615131\n",
      "epoch 155; iter: 0; batch classifier loss: 0.363530; batch adversarial loss: 0.554450\n",
      "epoch 156; iter: 0; batch classifier loss: 0.331902; batch adversarial loss: 0.547087\n",
      "epoch 157; iter: 0; batch classifier loss: 0.438652; batch adversarial loss: 0.519209\n",
      "epoch 158; iter: 0; batch classifier loss: 0.364820; batch adversarial loss: 0.569855\n",
      "epoch 159; iter: 0; batch classifier loss: 0.277301; batch adversarial loss: 0.544721\n",
      "epoch 160; iter: 0; batch classifier loss: 0.372171; batch adversarial loss: 0.536260\n",
      "epoch 161; iter: 0; batch classifier loss: 0.332387; batch adversarial loss: 0.535723\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 162; iter: 0; batch classifier loss: 0.326299; batch adversarial loss: 0.552899\n",
      "epoch 163; iter: 0; batch classifier loss: 0.348290; batch adversarial loss: 0.571643\n",
      "epoch 164; iter: 0; batch classifier loss: 0.354900; batch adversarial loss: 0.579336\n",
      "epoch 165; iter: 0; batch classifier loss: 0.346099; batch adversarial loss: 0.647562\n",
      "epoch 166; iter: 0; batch classifier loss: 0.329418; batch adversarial loss: 0.544849\n",
      "epoch 167; iter: 0; batch classifier loss: 0.367395; batch adversarial loss: 0.579537\n",
      "epoch 168; iter: 0; batch classifier loss: 0.376732; batch adversarial loss: 0.605410\n",
      "epoch 169; iter: 0; batch classifier loss: 0.300858; batch adversarial loss: 0.545208\n",
      "epoch 170; iter: 0; batch classifier loss: 0.318363; batch adversarial loss: 0.511001\n",
      "epoch 171; iter: 0; batch classifier loss: 0.342471; batch adversarial loss: 0.510662\n",
      "epoch 172; iter: 0; batch classifier loss: 0.317299; batch adversarial loss: 0.467627\n",
      "epoch 173; iter: 0; batch classifier loss: 0.370588; batch adversarial loss: 0.527854\n",
      "epoch 174; iter: 0; batch classifier loss: 0.370256; batch adversarial loss: 0.588106\n",
      "epoch 175; iter: 0; batch classifier loss: 0.333753; batch adversarial loss: 0.553874\n",
      "epoch 176; iter: 0; batch classifier loss: 0.330046; batch adversarial loss: 0.570783\n",
      "epoch 177; iter: 0; batch classifier loss: 0.281331; batch adversarial loss: 0.553707\n",
      "epoch 178; iter: 0; batch classifier loss: 0.375444; batch adversarial loss: 0.562522\n",
      "epoch 179; iter: 0; batch classifier loss: 0.348823; batch adversarial loss: 0.553811\n",
      "epoch 180; iter: 0; batch classifier loss: 0.391834; batch adversarial loss: 0.518380\n",
      "epoch 181; iter: 0; batch classifier loss: 0.364432; batch adversarial loss: 0.536312\n",
      "epoch 182; iter: 0; batch classifier loss: 0.322221; batch adversarial loss: 0.527340\n",
      "epoch 183; iter: 0; batch classifier loss: 0.355370; batch adversarial loss: 0.597678\n",
      "epoch 184; iter: 0; batch classifier loss: 0.322352; batch adversarial loss: 0.596283\n",
      "epoch 185; iter: 0; batch classifier loss: 0.313062; batch adversarial loss: 0.590310\n",
      "epoch 186; iter: 0; batch classifier loss: 0.376621; batch adversarial loss: 0.539048\n",
      "epoch 187; iter: 0; batch classifier loss: 0.380494; batch adversarial loss: 0.562135\n",
      "epoch 188; iter: 0; batch classifier loss: 0.348750; batch adversarial loss: 0.579787\n",
      "epoch 189; iter: 0; batch classifier loss: 0.284490; batch adversarial loss: 0.596565\n",
      "epoch 190; iter: 0; batch classifier loss: 0.320137; batch adversarial loss: 0.529864\n",
      "epoch 191; iter: 0; batch classifier loss: 0.348012; batch adversarial loss: 0.536745\n",
      "epoch 192; iter: 0; batch classifier loss: 0.391297; batch adversarial loss: 0.581861\n",
      "epoch 193; iter: 0; batch classifier loss: 0.408004; batch adversarial loss: 0.553806\n",
      "epoch 194; iter: 0; batch classifier loss: 0.330914; batch adversarial loss: 0.588354\n",
      "epoch 195; iter: 0; batch classifier loss: 0.295662; batch adversarial loss: 0.630776\n",
      "epoch 196; iter: 0; batch classifier loss: 0.385949; batch adversarial loss: 0.478043\n",
      "epoch 197; iter: 0; batch classifier loss: 0.420243; batch adversarial loss: 0.536939\n",
      "epoch 198; iter: 0; batch classifier loss: 0.335493; batch adversarial loss: 0.494386\n",
      "epoch 199; iter: 0; batch classifier loss: 0.349915; batch adversarial loss: 0.519328\n",
      "epoch 0; iter: 0; batch classifier loss: 0.666391; batch adversarial loss: 0.555872\n",
      "epoch 1; iter: 0; batch classifier loss: 0.621321; batch adversarial loss: 0.671359\n",
      "epoch 2; iter: 0; batch classifier loss: 0.574365; batch adversarial loss: 0.637510\n",
      "epoch 3; iter: 0; batch classifier loss: 0.558913; batch adversarial loss: 0.626765\n",
      "epoch 4; iter: 0; batch classifier loss: 0.522368; batch adversarial loss: 0.608989\n",
      "epoch 5; iter: 0; batch classifier loss: 0.579185; batch adversarial loss: 0.598202\n",
      "epoch 6; iter: 0; batch classifier loss: 0.520784; batch adversarial loss: 0.551723\n",
      "epoch 7; iter: 0; batch classifier loss: 0.537865; batch adversarial loss: 0.619867\n",
      "epoch 8; iter: 0; batch classifier loss: 0.619946; batch adversarial loss: 0.600252\n",
      "epoch 9; iter: 0; batch classifier loss: 0.559062; batch adversarial loss: 0.647470\n",
      "epoch 10; iter: 0; batch classifier loss: 0.438587; batch adversarial loss: 0.562441\n",
      "epoch 11; iter: 0; batch classifier loss: 0.508945; batch adversarial loss: 0.535552\n",
      "epoch 12; iter: 0; batch classifier loss: 0.522866; batch adversarial loss: 0.613008\n",
      "epoch 13; iter: 0; batch classifier loss: 0.529047; batch adversarial loss: 0.552803\n",
      "epoch 14; iter: 0; batch classifier loss: 0.575043; batch adversarial loss: 0.591574\n",
      "epoch 15; iter: 0; batch classifier loss: 0.541048; batch adversarial loss: 0.573483\n",
      "epoch 16; iter: 0; batch classifier loss: 0.473040; batch adversarial loss: 0.500159\n",
      "epoch 17; iter: 0; batch classifier loss: 0.556110; batch adversarial loss: 0.519508\n",
      "epoch 18; iter: 0; batch classifier loss: 0.429237; batch adversarial loss: 0.544263\n",
      "epoch 19; iter: 0; batch classifier loss: 0.498457; batch adversarial loss: 0.555166\n",
      "epoch 20; iter: 0; batch classifier loss: 0.516358; batch adversarial loss: 0.557374\n",
      "epoch 21; iter: 0; batch classifier loss: 0.473262; batch adversarial loss: 0.463374\n",
      "epoch 22; iter: 0; batch classifier loss: 0.437297; batch adversarial loss: 0.503972\n",
      "epoch 23; iter: 0; batch classifier loss: 0.571332; batch adversarial loss: 0.524770\n",
      "epoch 24; iter: 0; batch classifier loss: 0.477498; batch adversarial loss: 0.508512\n",
      "epoch 25; iter: 0; batch classifier loss: 0.432399; batch adversarial loss: 0.532562\n",
      "epoch 26; iter: 0; batch classifier loss: 0.473417; batch adversarial loss: 0.559563\n",
      "epoch 27; iter: 0; batch classifier loss: 0.502006; batch adversarial loss: 0.539258\n",
      "epoch 28; iter: 0; batch classifier loss: 0.414400; batch adversarial loss: 0.569438\n",
      "epoch 29; iter: 0; batch classifier loss: 0.420652; batch adversarial loss: 0.575062\n",
      "epoch 30; iter: 0; batch classifier loss: 0.486852; batch adversarial loss: 0.510444\n",
      "epoch 31; iter: 0; batch classifier loss: 0.471338; batch adversarial loss: 0.526804\n",
      "epoch 32; iter: 0; batch classifier loss: 0.481463; batch adversarial loss: 0.478846\n",
      "epoch 33; iter: 0; batch classifier loss: 0.384275; batch adversarial loss: 0.594453\n",
      "epoch 34; iter: 0; batch classifier loss: 0.523800; batch adversarial loss: 0.575363\n",
      "epoch 35; iter: 0; batch classifier loss: 0.404449; batch adversarial loss: 0.580415\n",
      "epoch 36; iter: 0; batch classifier loss: 0.422860; batch adversarial loss: 0.509844\n",
      "epoch 37; iter: 0; batch classifier loss: 0.474569; batch adversarial loss: 0.569776\n",
      "epoch 38; iter: 0; batch classifier loss: 0.391195; batch adversarial loss: 0.544359\n",
      "epoch 39; iter: 0; batch classifier loss: 0.412598; batch adversarial loss: 0.538325\n",
      "epoch 40; iter: 0; batch classifier loss: 0.431871; batch adversarial loss: 0.617029\n",
      "epoch 41; iter: 0; batch classifier loss: 0.503303; batch adversarial loss: 0.484551\n",
      "epoch 42; iter: 0; batch classifier loss: 0.413713; batch adversarial loss: 0.527188\n",
      "epoch 43; iter: 0; batch classifier loss: 0.397451; batch adversarial loss: 0.641804\n",
      "epoch 44; iter: 0; batch classifier loss: 0.426878; batch adversarial loss: 0.554427\n",
      "epoch 45; iter: 0; batch classifier loss: 0.440022; batch adversarial loss: 0.544435\n",
      "epoch 46; iter: 0; batch classifier loss: 0.425023; batch adversarial loss: 0.635784\n",
      "epoch 47; iter: 0; batch classifier loss: 0.423005; batch adversarial loss: 0.572245\n",
      "epoch 48; iter: 0; batch classifier loss: 0.420945; batch adversarial loss: 0.545658\n",
      "epoch 49; iter: 0; batch classifier loss: 0.400648; batch adversarial loss: 0.517855\n",
      "epoch 50; iter: 0; batch classifier loss: 0.431568; batch adversarial loss: 0.508954\n",
      "epoch 51; iter: 0; batch classifier loss: 0.453570; batch adversarial loss: 0.517688\n",
      "epoch 52; iter: 0; batch classifier loss: 0.437467; batch adversarial loss: 0.499223\n",
      "epoch 53; iter: 0; batch classifier loss: 0.449129; batch adversarial loss: 0.480862\n",
      "epoch 54; iter: 0; batch classifier loss: 0.395740; batch adversarial loss: 0.543730\n",
      "epoch 55; iter: 0; batch classifier loss: 0.388466; batch adversarial loss: 0.607405\n",
      "epoch 56; iter: 0; batch classifier loss: 0.440852; batch adversarial loss: 0.516478\n",
      "epoch 57; iter: 0; batch classifier loss: 0.405439; batch adversarial loss: 0.617393\n",
      "epoch 58; iter: 0; batch classifier loss: 0.469021; batch adversarial loss: 0.515680\n",
      "epoch 59; iter: 0; batch classifier loss: 0.433622; batch adversarial loss: 0.599597\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 60; iter: 0; batch classifier loss: 0.413265; batch adversarial loss: 0.526444\n",
      "epoch 61; iter: 0; batch classifier loss: 0.442497; batch adversarial loss: 0.545300\n",
      "epoch 62; iter: 0; batch classifier loss: 0.465002; batch adversarial loss: 0.619456\n",
      "epoch 63; iter: 0; batch classifier loss: 0.392206; batch adversarial loss: 0.573431\n",
      "epoch 64; iter: 0; batch classifier loss: 0.489754; batch adversarial loss: 0.481403\n",
      "epoch 65; iter: 0; batch classifier loss: 0.417136; batch adversarial loss: 0.535541\n",
      "epoch 66; iter: 0; batch classifier loss: 0.432369; batch adversarial loss: 0.554031\n",
      "epoch 67; iter: 0; batch classifier loss: 0.434825; batch adversarial loss: 0.580705\n",
      "epoch 68; iter: 0; batch classifier loss: 0.443132; batch adversarial loss: 0.517516\n",
      "epoch 69; iter: 0; batch classifier loss: 0.453608; batch adversarial loss: 0.625453\n",
      "epoch 70; iter: 0; batch classifier loss: 0.422227; batch adversarial loss: 0.562957\n",
      "epoch 71; iter: 0; batch classifier loss: 0.444986; batch adversarial loss: 0.535493\n",
      "epoch 72; iter: 0; batch classifier loss: 0.423172; batch adversarial loss: 0.499701\n",
      "epoch 73; iter: 0; batch classifier loss: 0.439646; batch adversarial loss: 0.616893\n",
      "epoch 74; iter: 0; batch classifier loss: 0.417936; batch adversarial loss: 0.571456\n",
      "epoch 75; iter: 0; batch classifier loss: 0.388032; batch adversarial loss: 0.490511\n",
      "epoch 76; iter: 0; batch classifier loss: 0.470255; batch adversarial loss: 0.588607\n",
      "epoch 77; iter: 0; batch classifier loss: 0.462385; batch adversarial loss: 0.580362\n",
      "epoch 78; iter: 0; batch classifier loss: 0.390326; batch adversarial loss: 0.662934\n",
      "epoch 79; iter: 0; batch classifier loss: 0.388718; batch adversarial loss: 0.462492\n",
      "epoch 80; iter: 0; batch classifier loss: 0.416938; batch adversarial loss: 0.507863\n",
      "epoch 81; iter: 0; batch classifier loss: 0.311020; batch adversarial loss: 0.553363\n",
      "epoch 82; iter: 0; batch classifier loss: 0.383479; batch adversarial loss: 0.562330\n",
      "epoch 83; iter: 0; batch classifier loss: 0.438778; batch adversarial loss: 0.563082\n",
      "epoch 84; iter: 0; batch classifier loss: 0.433986; batch adversarial loss: 0.489603\n",
      "epoch 85; iter: 0; batch classifier loss: 0.369117; batch adversarial loss: 0.600056\n",
      "epoch 86; iter: 0; batch classifier loss: 0.414136; batch adversarial loss: 0.590246\n",
      "epoch 87; iter: 0; batch classifier loss: 0.408041; batch adversarial loss: 0.544561\n",
      "epoch 88; iter: 0; batch classifier loss: 0.445230; batch adversarial loss: 0.561731\n",
      "epoch 89; iter: 0; batch classifier loss: 0.370871; batch adversarial loss: 0.562568\n",
      "epoch 90; iter: 0; batch classifier loss: 0.319260; batch adversarial loss: 0.552783\n",
      "epoch 91; iter: 0; batch classifier loss: 0.309284; batch adversarial loss: 0.571812\n",
      "epoch 92; iter: 0; batch classifier loss: 0.360803; batch adversarial loss: 0.537029\n",
      "epoch 93; iter: 0; batch classifier loss: 0.483911; batch adversarial loss: 0.590300\n",
      "epoch 94; iter: 0; batch classifier loss: 0.373966; batch adversarial loss: 0.535739\n",
      "epoch 95; iter: 0; batch classifier loss: 0.333751; batch adversarial loss: 0.598893\n",
      "epoch 96; iter: 0; batch classifier loss: 0.343542; batch adversarial loss: 0.480959\n",
      "epoch 97; iter: 0; batch classifier loss: 0.390334; batch adversarial loss: 0.499759\n",
      "epoch 98; iter: 0; batch classifier loss: 0.355996; batch adversarial loss: 0.580314\n",
      "epoch 99; iter: 0; batch classifier loss: 0.339312; batch adversarial loss: 0.626445\n",
      "epoch 100; iter: 0; batch classifier loss: 0.382229; batch adversarial loss: 0.553842\n",
      "epoch 101; iter: 0; batch classifier loss: 0.382039; batch adversarial loss: 0.544299\n",
      "epoch 102; iter: 0; batch classifier loss: 0.397954; batch adversarial loss: 0.534655\n",
      "epoch 103; iter: 0; batch classifier loss: 0.350812; batch adversarial loss: 0.509751\n",
      "epoch 104; iter: 0; batch classifier loss: 0.422278; batch adversarial loss: 0.589667\n",
      "epoch 105; iter: 0; batch classifier loss: 0.391049; batch adversarial loss: 0.552904\n",
      "epoch 106; iter: 0; batch classifier loss: 0.364105; batch adversarial loss: 0.525197\n",
      "epoch 107; iter: 0; batch classifier loss: 0.371823; batch adversarial loss: 0.525369\n",
      "epoch 108; iter: 0; batch classifier loss: 0.341664; batch adversarial loss: 0.638675\n",
      "epoch 109; iter: 0; batch classifier loss: 0.380024; batch adversarial loss: 0.563757\n",
      "epoch 110; iter: 0; batch classifier loss: 0.376336; batch adversarial loss: 0.462157\n",
      "epoch 111; iter: 0; batch classifier loss: 0.417866; batch adversarial loss: 0.527551\n",
      "epoch 112; iter: 0; batch classifier loss: 0.290753; batch adversarial loss: 0.544762\n",
      "epoch 113; iter: 0; batch classifier loss: 0.407095; batch adversarial loss: 0.535731\n",
      "epoch 114; iter: 0; batch classifier loss: 0.364776; batch adversarial loss: 0.545026\n",
      "epoch 115; iter: 0; batch classifier loss: 0.362220; batch adversarial loss: 0.471044\n",
      "epoch 116; iter: 0; batch classifier loss: 0.405613; batch adversarial loss: 0.590603\n",
      "epoch 117; iter: 0; batch classifier loss: 0.370852; batch adversarial loss: 0.581397\n",
      "epoch 118; iter: 0; batch classifier loss: 0.359454; batch adversarial loss: 0.534438\n",
      "epoch 119; iter: 0; batch classifier loss: 0.354254; batch adversarial loss: 0.535842\n",
      "epoch 120; iter: 0; batch classifier loss: 0.399046; batch adversarial loss: 0.563279\n",
      "epoch 121; iter: 0; batch classifier loss: 0.376963; batch adversarial loss: 0.573297\n",
      "epoch 122; iter: 0; batch classifier loss: 0.396353; batch adversarial loss: 0.543247\n",
      "epoch 123; iter: 0; batch classifier loss: 0.333830; batch adversarial loss: 0.545265\n",
      "epoch 124; iter: 0; batch classifier loss: 0.416290; batch adversarial loss: 0.608439\n",
      "epoch 125; iter: 0; batch classifier loss: 0.439018; batch adversarial loss: 0.507320\n",
      "epoch 126; iter: 0; batch classifier loss: 0.356725; batch adversarial loss: 0.608799\n",
      "epoch 127; iter: 0; batch classifier loss: 0.436195; batch adversarial loss: 0.554801\n",
      "epoch 128; iter: 0; batch classifier loss: 0.372155; batch adversarial loss: 0.609652\n",
      "epoch 129; iter: 0; batch classifier loss: 0.343303; batch adversarial loss: 0.518705\n",
      "epoch 130; iter: 0; batch classifier loss: 0.348066; batch adversarial loss: 0.580537\n",
      "epoch 131; iter: 0; batch classifier loss: 0.373385; batch adversarial loss: 0.480714\n",
      "epoch 132; iter: 0; batch classifier loss: 0.261121; batch adversarial loss: 0.517774\n",
      "epoch 133; iter: 0; batch classifier loss: 0.319468; batch adversarial loss: 0.488985\n",
      "epoch 134; iter: 0; batch classifier loss: 0.334513; batch adversarial loss: 0.526356\n",
      "epoch 135; iter: 0; batch classifier loss: 0.343705; batch adversarial loss: 0.497697\n",
      "epoch 136; iter: 0; batch classifier loss: 0.412508; batch adversarial loss: 0.525584\n",
      "epoch 137; iter: 0; batch classifier loss: 0.405730; batch adversarial loss: 0.553029\n",
      "epoch 138; iter: 0; batch classifier loss: 0.358349; batch adversarial loss: 0.562300\n",
      "epoch 139; iter: 0; batch classifier loss: 0.366362; batch adversarial loss: 0.581228\n",
      "epoch 140; iter: 0; batch classifier loss: 0.364526; batch adversarial loss: 0.609127\n",
      "epoch 141; iter: 0; batch classifier loss: 0.348695; batch adversarial loss: 0.561761\n",
      "epoch 142; iter: 0; batch classifier loss: 0.408192; batch adversarial loss: 0.562653\n",
      "epoch 143; iter: 0; batch classifier loss: 0.351489; batch adversarial loss: 0.609663\n",
      "epoch 144; iter: 0; batch classifier loss: 0.306614; batch adversarial loss: 0.543459\n",
      "epoch 145; iter: 0; batch classifier loss: 0.446335; batch adversarial loss: 0.487881\n",
      "epoch 146; iter: 0; batch classifier loss: 0.362534; batch adversarial loss: 0.551957\n",
      "epoch 147; iter: 0; batch classifier loss: 0.345413; batch adversarial loss: 0.589934\n",
      "epoch 148; iter: 0; batch classifier loss: 0.327805; batch adversarial loss: 0.544119\n",
      "epoch 149; iter: 0; batch classifier loss: 0.295995; batch adversarial loss: 0.590168\n",
      "epoch 150; iter: 0; batch classifier loss: 0.396909; batch adversarial loss: 0.590171\n",
      "epoch 151; iter: 0; batch classifier loss: 0.324683; batch adversarial loss: 0.562729\n",
      "epoch 152; iter: 0; batch classifier loss: 0.319168; batch adversarial loss: 0.551184\n",
      "epoch 153; iter: 0; batch classifier loss: 0.359535; batch adversarial loss: 0.534403\n",
      "epoch 154; iter: 0; batch classifier loss: 0.313262; batch adversarial loss: 0.497921\n",
      "epoch 155; iter: 0; batch classifier loss: 0.330411; batch adversarial loss: 0.534838\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 156; iter: 0; batch classifier loss: 0.363522; batch adversarial loss: 0.525227\n",
      "epoch 157; iter: 0; batch classifier loss: 0.378112; batch adversarial loss: 0.507346\n",
      "epoch 158; iter: 0; batch classifier loss: 0.361997; batch adversarial loss: 0.497542\n",
      "epoch 159; iter: 0; batch classifier loss: 0.369216; batch adversarial loss: 0.554011\n",
      "epoch 160; iter: 0; batch classifier loss: 0.401526; batch adversarial loss: 0.599386\n",
      "epoch 161; iter: 0; batch classifier loss: 0.373682; batch adversarial loss: 0.451258\n",
      "epoch 162; iter: 0; batch classifier loss: 0.332210; batch adversarial loss: 0.691664\n",
      "epoch 163; iter: 0; batch classifier loss: 0.332631; batch adversarial loss: 0.570765\n",
      "epoch 164; iter: 0; batch classifier loss: 0.421979; batch adversarial loss: 0.605742\n",
      "epoch 165; iter: 0; batch classifier loss: 0.352222; batch adversarial loss: 0.481191\n",
      "epoch 166; iter: 0; batch classifier loss: 0.346375; batch adversarial loss: 0.489584\n",
      "epoch 167; iter: 0; batch classifier loss: 0.444805; batch adversarial loss: 0.589573\n",
      "epoch 168; iter: 0; batch classifier loss: 0.343303; batch adversarial loss: 0.470945\n",
      "epoch 169; iter: 0; batch classifier loss: 0.353708; batch adversarial loss: 0.562875\n",
      "epoch 170; iter: 0; batch classifier loss: 0.338141; batch adversarial loss: 0.525285\n",
      "epoch 171; iter: 0; batch classifier loss: 0.381815; batch adversarial loss: 0.538370\n",
      "epoch 172; iter: 0; batch classifier loss: 0.393299; batch adversarial loss: 0.559435\n",
      "epoch 173; iter: 0; batch classifier loss: 0.439695; batch adversarial loss: 0.589728\n",
      "epoch 174; iter: 0; batch classifier loss: 0.380510; batch adversarial loss: 0.527163\n",
      "epoch 175; iter: 0; batch classifier loss: 0.351405; batch adversarial loss: 0.489544\n",
      "epoch 176; iter: 0; batch classifier loss: 0.406563; batch adversarial loss: 0.636364\n",
      "epoch 177; iter: 0; batch classifier loss: 0.338115; batch adversarial loss: 0.481319\n",
      "epoch 178; iter: 0; batch classifier loss: 0.320224; batch adversarial loss: 0.561958\n",
      "epoch 179; iter: 0; batch classifier loss: 0.329611; batch adversarial loss: 0.527828\n",
      "epoch 180; iter: 0; batch classifier loss: 0.355931; batch adversarial loss: 0.534654\n",
      "epoch 181; iter: 0; batch classifier loss: 0.367706; batch adversarial loss: 0.517983\n",
      "epoch 182; iter: 0; batch classifier loss: 0.365611; batch adversarial loss: 0.581705\n",
      "epoch 183; iter: 0; batch classifier loss: 0.339450; batch adversarial loss: 0.508315\n",
      "epoch 184; iter: 0; batch classifier loss: 0.386358; batch adversarial loss: 0.571684\n",
      "epoch 185; iter: 0; batch classifier loss: 0.389259; batch adversarial loss: 0.471134\n",
      "epoch 186; iter: 0; batch classifier loss: 0.318077; batch adversarial loss: 0.598460\n",
      "epoch 187; iter: 0; batch classifier loss: 0.339596; batch adversarial loss: 0.580550\n",
      "epoch 188; iter: 0; batch classifier loss: 0.397792; batch adversarial loss: 0.570180\n",
      "epoch 189; iter: 0; batch classifier loss: 0.343095; batch adversarial loss: 0.524687\n",
      "epoch 190; iter: 0; batch classifier loss: 0.342696; batch adversarial loss: 0.534997\n",
      "epoch 191; iter: 0; batch classifier loss: 0.305124; batch adversarial loss: 0.572518\n",
      "epoch 192; iter: 0; batch classifier loss: 0.282721; batch adversarial loss: 0.526079\n",
      "epoch 193; iter: 0; batch classifier loss: 0.435852; batch adversarial loss: 0.558088\n",
      "epoch 194; iter: 0; batch classifier loss: 0.344838; batch adversarial loss: 0.544198\n",
      "epoch 195; iter: 0; batch classifier loss: 0.327048; batch adversarial loss: 0.489262\n",
      "epoch 196; iter: 0; batch classifier loss: 0.351497; batch adversarial loss: 0.563741\n",
      "epoch 197; iter: 0; batch classifier loss: 0.356288; batch adversarial loss: 0.516621\n",
      "epoch 198; iter: 0; batch classifier loss: 0.360646; batch adversarial loss: 0.487782\n",
      "epoch 199; iter: 0; batch classifier loss: 0.374711; batch adversarial loss: 0.536591\n",
      "epoch 0; iter: 0; batch classifier loss: 0.772273; batch adversarial loss: 0.684696\n",
      "epoch 1; iter: 0; batch classifier loss: 0.572491; batch adversarial loss: 0.665313\n",
      "epoch 2; iter: 0; batch classifier loss: 0.561169; batch adversarial loss: 0.644720\n",
      "epoch 3; iter: 0; batch classifier loss: 0.497159; batch adversarial loss: 0.645922\n",
      "epoch 4; iter: 0; batch classifier loss: 0.563211; batch adversarial loss: 0.670539\n",
      "epoch 5; iter: 0; batch classifier loss: 0.542867; batch adversarial loss: 0.590140\n",
      "epoch 6; iter: 0; batch classifier loss: 0.571384; batch adversarial loss: 0.645823\n",
      "epoch 7; iter: 0; batch classifier loss: 0.555465; batch adversarial loss: 0.572913\n",
      "epoch 8; iter: 0; batch classifier loss: 0.506239; batch adversarial loss: 0.617596\n",
      "epoch 9; iter: 0; batch classifier loss: 0.519845; batch adversarial loss: 0.620557\n",
      "epoch 10; iter: 0; batch classifier loss: 0.518808; batch adversarial loss: 0.579121\n",
      "epoch 11; iter: 0; batch classifier loss: 0.481009; batch adversarial loss: 0.563945\n",
      "epoch 12; iter: 0; batch classifier loss: 0.516714; batch adversarial loss: 0.563779\n",
      "epoch 13; iter: 0; batch classifier loss: 0.572312; batch adversarial loss: 0.601202\n",
      "epoch 14; iter: 0; batch classifier loss: 0.474933; batch adversarial loss: 0.563292\n",
      "epoch 15; iter: 0; batch classifier loss: 0.582649; batch adversarial loss: 0.630159\n",
      "epoch 16; iter: 0; batch classifier loss: 0.498818; batch adversarial loss: 0.569671\n",
      "epoch 17; iter: 0; batch classifier loss: 0.505540; batch adversarial loss: 0.541005\n",
      "epoch 18; iter: 0; batch classifier loss: 0.488950; batch adversarial loss: 0.564184\n",
      "epoch 19; iter: 0; batch classifier loss: 0.478253; batch adversarial loss: 0.530103\n",
      "epoch 20; iter: 0; batch classifier loss: 0.484615; batch adversarial loss: 0.593488\n",
      "epoch 21; iter: 0; batch classifier loss: 0.441174; batch adversarial loss: 0.541163\n",
      "epoch 22; iter: 0; batch classifier loss: 0.412998; batch adversarial loss: 0.507739\n",
      "epoch 23; iter: 0; batch classifier loss: 0.490579; batch adversarial loss: 0.610731\n",
      "epoch 24; iter: 0; batch classifier loss: 0.477673; batch adversarial loss: 0.580472\n",
      "epoch 25; iter: 0; batch classifier loss: 0.414691; batch adversarial loss: 0.570639\n",
      "epoch 26; iter: 0; batch classifier loss: 0.406325; batch adversarial loss: 0.510125\n",
      "epoch 27; iter: 0; batch classifier loss: 0.552842; batch adversarial loss: 0.539635\n",
      "epoch 28; iter: 0; batch classifier loss: 0.446271; batch adversarial loss: 0.508050\n",
      "epoch 29; iter: 0; batch classifier loss: 0.487311; batch adversarial loss: 0.571324\n",
      "epoch 30; iter: 0; batch classifier loss: 0.538770; batch adversarial loss: 0.585215\n",
      "epoch 31; iter: 0; batch classifier loss: 0.486203; batch adversarial loss: 0.504694\n",
      "epoch 32; iter: 0; batch classifier loss: 0.445037; batch adversarial loss: 0.519994\n",
      "epoch 33; iter: 0; batch classifier loss: 0.415498; batch adversarial loss: 0.630655\n",
      "epoch 34; iter: 0; batch classifier loss: 0.407904; batch adversarial loss: 0.580481\n",
      "epoch 35; iter: 0; batch classifier loss: 0.511601; batch adversarial loss: 0.570914\n",
      "epoch 36; iter: 0; batch classifier loss: 0.459995; batch adversarial loss: 0.605236\n",
      "epoch 37; iter: 0; batch classifier loss: 0.450989; batch adversarial loss: 0.622671\n",
      "epoch 38; iter: 0; batch classifier loss: 0.415982; batch adversarial loss: 0.545226\n",
      "epoch 39; iter: 0; batch classifier loss: 0.417424; batch adversarial loss: 0.597160\n",
      "epoch 40; iter: 0; batch classifier loss: 0.464374; batch adversarial loss: 0.640561\n",
      "epoch 41; iter: 0; batch classifier loss: 0.403763; batch adversarial loss: 0.588204\n",
      "epoch 42; iter: 0; batch classifier loss: 0.408612; batch adversarial loss: 0.527573\n",
      "epoch 43; iter: 0; batch classifier loss: 0.496576; batch adversarial loss: 0.536319\n",
      "epoch 44; iter: 0; batch classifier loss: 0.482293; batch adversarial loss: 0.641627\n",
      "epoch 45; iter: 0; batch classifier loss: 0.436961; batch adversarial loss: 0.588915\n",
      "epoch 46; iter: 0; batch classifier loss: 0.427344; batch adversarial loss: 0.562257\n",
      "epoch 47; iter: 0; batch classifier loss: 0.427987; batch adversarial loss: 0.606868\n",
      "epoch 48; iter: 0; batch classifier loss: 0.385468; batch adversarial loss: 0.578778\n",
      "epoch 49; iter: 0; batch classifier loss: 0.416198; batch adversarial loss: 0.553065\n",
      "epoch 50; iter: 0; batch classifier loss: 0.396163; batch adversarial loss: 0.553407\n",
      "epoch 51; iter: 0; batch classifier loss: 0.536296; batch adversarial loss: 0.538295\n",
      "epoch 52; iter: 0; batch classifier loss: 0.382983; batch adversarial loss: 0.500277\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 53; iter: 0; batch classifier loss: 0.434666; batch adversarial loss: 0.597807\n",
      "epoch 54; iter: 0; batch classifier loss: 0.393615; batch adversarial loss: 0.429383\n",
      "epoch 55; iter: 0; batch classifier loss: 0.401353; batch adversarial loss: 0.518913\n",
      "epoch 56; iter: 0; batch classifier loss: 0.475514; batch adversarial loss: 0.536962\n",
      "epoch 57; iter: 0; batch classifier loss: 0.425937; batch adversarial loss: 0.511140\n",
      "epoch 58; iter: 0; batch classifier loss: 0.447924; batch adversarial loss: 0.561625\n",
      "epoch 59; iter: 0; batch classifier loss: 0.459665; batch adversarial loss: 0.554575\n",
      "epoch 60; iter: 0; batch classifier loss: 0.382859; batch adversarial loss: 0.561267\n",
      "epoch 61; iter: 0; batch classifier loss: 0.408516; batch adversarial loss: 0.616297\n",
      "epoch 62; iter: 0; batch classifier loss: 0.382933; batch adversarial loss: 0.562970\n",
      "epoch 63; iter: 0; batch classifier loss: 0.404699; batch adversarial loss: 0.497414\n",
      "epoch 64; iter: 0; batch classifier loss: 0.472100; batch adversarial loss: 0.557730\n",
      "epoch 65; iter: 0; batch classifier loss: 0.409992; batch adversarial loss: 0.525692\n",
      "epoch 66; iter: 0; batch classifier loss: 0.398064; batch adversarial loss: 0.603930\n",
      "epoch 67; iter: 0; batch classifier loss: 0.443312; batch adversarial loss: 0.605733\n",
      "epoch 68; iter: 0; batch classifier loss: 0.481437; batch adversarial loss: 0.563758\n",
      "epoch 69; iter: 0; batch classifier loss: 0.398002; batch adversarial loss: 0.507460\n",
      "epoch 70; iter: 0; batch classifier loss: 0.480738; batch adversarial loss: 0.564865\n",
      "epoch 71; iter: 0; batch classifier loss: 0.349968; batch adversarial loss: 0.599647\n",
      "epoch 72; iter: 0; batch classifier loss: 0.475780; batch adversarial loss: 0.537578\n",
      "epoch 73; iter: 0; batch classifier loss: 0.417571; batch adversarial loss: 0.563292\n",
      "epoch 74; iter: 0; batch classifier loss: 0.401844; batch adversarial loss: 0.535201\n",
      "epoch 75; iter: 0; batch classifier loss: 0.384643; batch adversarial loss: 0.516393\n",
      "epoch 76; iter: 0; batch classifier loss: 0.349289; batch adversarial loss: 0.589866\n",
      "epoch 77; iter: 0; batch classifier loss: 0.394560; batch adversarial loss: 0.562793\n",
      "epoch 78; iter: 0; batch classifier loss: 0.396310; batch adversarial loss: 0.535614\n",
      "epoch 79; iter: 0; batch classifier loss: 0.447074; batch adversarial loss: 0.552712\n",
      "epoch 80; iter: 0; batch classifier loss: 0.416676; batch adversarial loss: 0.528161\n",
      "epoch 81; iter: 0; batch classifier loss: 0.393315; batch adversarial loss: 0.527232\n",
      "epoch 82; iter: 0; batch classifier loss: 0.428688; batch adversarial loss: 0.588646\n",
      "epoch 83; iter: 0; batch classifier loss: 0.500184; batch adversarial loss: 0.535953\n",
      "epoch 84; iter: 0; batch classifier loss: 0.479891; batch adversarial loss: 0.544197\n",
      "epoch 85; iter: 0; batch classifier loss: 0.469525; batch adversarial loss: 0.588419\n",
      "epoch 86; iter: 0; batch classifier loss: 0.300089; batch adversarial loss: 0.606757\n",
      "epoch 87; iter: 0; batch classifier loss: 0.409650; batch adversarial loss: 0.545614\n",
      "epoch 88; iter: 0; batch classifier loss: 0.361541; batch adversarial loss: 0.537397\n",
      "epoch 89; iter: 0; batch classifier loss: 0.321917; batch adversarial loss: 0.624572\n",
      "epoch 90; iter: 0; batch classifier loss: 0.399385; batch adversarial loss: 0.562656\n",
      "epoch 91; iter: 0; batch classifier loss: 0.432291; batch adversarial loss: 0.544591\n",
      "epoch 92; iter: 0; batch classifier loss: 0.419064; batch adversarial loss: 0.527084\n",
      "epoch 93; iter: 0; batch classifier loss: 0.403635; batch adversarial loss: 0.615383\n",
      "epoch 94; iter: 0; batch classifier loss: 0.410134; batch adversarial loss: 0.581730\n",
      "epoch 95; iter: 0; batch classifier loss: 0.353802; batch adversarial loss: 0.545784\n",
      "epoch 96; iter: 0; batch classifier loss: 0.421774; batch adversarial loss: 0.589082\n",
      "epoch 97; iter: 0; batch classifier loss: 0.368193; batch adversarial loss: 0.552237\n",
      "epoch 98; iter: 0; batch classifier loss: 0.430996; batch adversarial loss: 0.535026\n",
      "epoch 99; iter: 0; batch classifier loss: 0.452147; batch adversarial loss: 0.562716\n",
      "epoch 100; iter: 0; batch classifier loss: 0.455066; batch adversarial loss: 0.583267\n",
      "epoch 101; iter: 0; batch classifier loss: 0.446938; batch adversarial loss: 0.606630\n",
      "epoch 102; iter: 0; batch classifier loss: 0.307911; batch adversarial loss: 0.615861\n",
      "epoch 103; iter: 0; batch classifier loss: 0.365046; batch adversarial loss: 0.642712\n",
      "epoch 104; iter: 0; batch classifier loss: 0.368537; batch adversarial loss: 0.573365\n",
      "epoch 105; iter: 0; batch classifier loss: 0.394481; batch adversarial loss: 0.518281\n",
      "epoch 106; iter: 0; batch classifier loss: 0.436356; batch adversarial loss: 0.553110\n",
      "epoch 107; iter: 0; batch classifier loss: 0.467499; batch adversarial loss: 0.621671\n",
      "epoch 108; iter: 0; batch classifier loss: 0.422413; batch adversarial loss: 0.570368\n",
      "epoch 109; iter: 0; batch classifier loss: 0.369571; batch adversarial loss: 0.519323\n",
      "epoch 110; iter: 0; batch classifier loss: 0.366952; batch adversarial loss: 0.597838\n",
      "epoch 111; iter: 0; batch classifier loss: 0.356901; batch adversarial loss: 0.606073\n",
      "epoch 112; iter: 0; batch classifier loss: 0.448934; batch adversarial loss: 0.617683\n",
      "epoch 113; iter: 0; batch classifier loss: 0.363931; batch adversarial loss: 0.587532\n",
      "epoch 114; iter: 0; batch classifier loss: 0.415620; batch adversarial loss: 0.571064\n",
      "epoch 115; iter: 0; batch classifier loss: 0.372333; batch adversarial loss: 0.518892\n",
      "epoch 116; iter: 0; batch classifier loss: 0.399465; batch adversarial loss: 0.579942\n",
      "epoch 117; iter: 0; batch classifier loss: 0.332054; batch adversarial loss: 0.547510\n",
      "epoch 118; iter: 0; batch classifier loss: 0.350354; batch adversarial loss: 0.551752\n",
      "epoch 119; iter: 0; batch classifier loss: 0.345746; batch adversarial loss: 0.607744\n",
      "epoch 120; iter: 0; batch classifier loss: 0.403119; batch adversarial loss: 0.599073\n",
      "epoch 121; iter: 0; batch classifier loss: 0.402344; batch adversarial loss: 0.621429\n",
      "epoch 122; iter: 0; batch classifier loss: 0.384272; batch adversarial loss: 0.553675\n",
      "epoch 123; iter: 0; batch classifier loss: 0.378962; batch adversarial loss: 0.573955\n",
      "epoch 124; iter: 0; batch classifier loss: 0.364404; batch adversarial loss: 0.527849\n",
      "epoch 125; iter: 0; batch classifier loss: 0.301622; batch adversarial loss: 0.631980\n",
      "epoch 126; iter: 0; batch classifier loss: 0.437059; batch adversarial loss: 0.491357\n",
      "epoch 127; iter: 0; batch classifier loss: 0.370562; batch adversarial loss: 0.491510\n",
      "epoch 128; iter: 0; batch classifier loss: 0.390278; batch adversarial loss: 0.475652\n",
      "epoch 129; iter: 0; batch classifier loss: 0.364447; batch adversarial loss: 0.606275\n",
      "epoch 130; iter: 0; batch classifier loss: 0.365040; batch adversarial loss: 0.552836\n",
      "epoch 131; iter: 0; batch classifier loss: 0.335917; batch adversarial loss: 0.562961\n",
      "epoch 132; iter: 0; batch classifier loss: 0.329387; batch adversarial loss: 0.580672\n",
      "epoch 133; iter: 0; batch classifier loss: 0.407010; batch adversarial loss: 0.500225\n",
      "epoch 134; iter: 0; batch classifier loss: 0.316902; batch adversarial loss: 0.608541\n",
      "epoch 135; iter: 0; batch classifier loss: 0.352350; batch adversarial loss: 0.580495\n",
      "epoch 136; iter: 0; batch classifier loss: 0.402697; batch adversarial loss: 0.490934\n",
      "epoch 137; iter: 0; batch classifier loss: 0.389241; batch adversarial loss: 0.544675\n",
      "epoch 138; iter: 0; batch classifier loss: 0.383360; batch adversarial loss: 0.543108\n",
      "epoch 139; iter: 0; batch classifier loss: 0.367666; batch adversarial loss: 0.563609\n",
      "epoch 140; iter: 0; batch classifier loss: 0.267732; batch adversarial loss: 0.526475\n",
      "epoch 141; iter: 0; batch classifier loss: 0.352522; batch adversarial loss: 0.527591\n",
      "epoch 142; iter: 0; batch classifier loss: 0.432602; batch adversarial loss: 0.598768\n",
      "epoch 143; iter: 0; batch classifier loss: 0.337854; batch adversarial loss: 0.490998\n",
      "epoch 144; iter: 0; batch classifier loss: 0.356415; batch adversarial loss: 0.553095\n",
      "epoch 145; iter: 0; batch classifier loss: 0.313556; batch adversarial loss: 0.533578\n",
      "epoch 146; iter: 0; batch classifier loss: 0.352964; batch adversarial loss: 0.546064\n",
      "epoch 147; iter: 0; batch classifier loss: 0.475945; batch adversarial loss: 0.554529\n",
      "epoch 148; iter: 0; batch classifier loss: 0.336590; batch adversarial loss: 0.572294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 149; iter: 0; batch classifier loss: 0.428666; batch adversarial loss: 0.553263\n",
      "epoch 150; iter: 0; batch classifier loss: 0.389127; batch adversarial loss: 0.537075\n",
      "epoch 151; iter: 0; batch classifier loss: 0.390963; batch adversarial loss: 0.553315\n",
      "epoch 152; iter: 0; batch classifier loss: 0.369384; batch adversarial loss: 0.562768\n",
      "epoch 153; iter: 0; batch classifier loss: 0.317992; batch adversarial loss: 0.564412\n",
      "epoch 154; iter: 0; batch classifier loss: 0.403517; batch adversarial loss: 0.518617\n",
      "epoch 155; iter: 0; batch classifier loss: 0.381629; batch adversarial loss: 0.536850\n",
      "epoch 156; iter: 0; batch classifier loss: 0.407328; batch adversarial loss: 0.534281\n",
      "epoch 157; iter: 0; batch classifier loss: 0.389939; batch adversarial loss: 0.578633\n",
      "epoch 158; iter: 0; batch classifier loss: 0.430359; batch adversarial loss: 0.484043\n",
      "epoch 159; iter: 0; batch classifier loss: 0.372845; batch adversarial loss: 0.598954\n",
      "epoch 160; iter: 0; batch classifier loss: 0.442604; batch adversarial loss: 0.589133\n",
      "epoch 161; iter: 0; batch classifier loss: 0.338419; batch adversarial loss: 0.580238\n",
      "epoch 162; iter: 0; batch classifier loss: 0.318916; batch adversarial loss: 0.516779\n",
      "epoch 163; iter: 0; batch classifier loss: 0.348740; batch adversarial loss: 0.525544\n",
      "epoch 164; iter: 0; batch classifier loss: 0.420024; batch adversarial loss: 0.561663\n",
      "epoch 165; iter: 0; batch classifier loss: 0.417339; batch adversarial loss: 0.569752\n",
      "epoch 166; iter: 0; batch classifier loss: 0.334908; batch adversarial loss: 0.563745\n",
      "epoch 167; iter: 0; batch classifier loss: 0.386992; batch adversarial loss: 0.559838\n",
      "epoch 168; iter: 0; batch classifier loss: 0.456272; batch adversarial loss: 0.535904\n",
      "epoch 169; iter: 0; batch classifier loss: 0.325107; batch adversarial loss: 0.543466\n",
      "epoch 170; iter: 0; batch classifier loss: 0.345068; batch adversarial loss: 0.544984\n",
      "epoch 171; iter: 0; batch classifier loss: 0.305089; batch adversarial loss: 0.595951\n",
      "epoch 172; iter: 0; batch classifier loss: 0.373398; batch adversarial loss: 0.535848\n",
      "epoch 173; iter: 0; batch classifier loss: 0.393526; batch adversarial loss: 0.530138\n",
      "epoch 174; iter: 0; batch classifier loss: 0.385792; batch adversarial loss: 0.564286\n",
      "epoch 175; iter: 0; batch classifier loss: 0.397196; batch adversarial loss: 0.499076\n",
      "epoch 176; iter: 0; batch classifier loss: 0.329062; batch adversarial loss: 0.502837\n",
      "epoch 177; iter: 0; batch classifier loss: 0.403045; batch adversarial loss: 0.535339\n",
      "epoch 178; iter: 0; batch classifier loss: 0.350891; batch adversarial loss: 0.632187\n",
      "epoch 179; iter: 0; batch classifier loss: 0.382411; batch adversarial loss: 0.563084\n",
      "epoch 180; iter: 0; batch classifier loss: 0.349949; batch adversarial loss: 0.570166\n",
      "epoch 181; iter: 0; batch classifier loss: 0.330919; batch adversarial loss: 0.607446\n",
      "epoch 182; iter: 0; batch classifier loss: 0.286427; batch adversarial loss: 0.584248\n",
      "epoch 183; iter: 0; batch classifier loss: 0.398237; batch adversarial loss: 0.607911\n",
      "epoch 184; iter: 0; batch classifier loss: 0.408954; batch adversarial loss: 0.533848\n",
      "epoch 185; iter: 0; batch classifier loss: 0.336493; batch adversarial loss: 0.571810\n",
      "epoch 186; iter: 0; batch classifier loss: 0.317966; batch adversarial loss: 0.553349\n",
      "epoch 187; iter: 0; batch classifier loss: 0.354632; batch adversarial loss: 0.562132\n",
      "epoch 188; iter: 0; batch classifier loss: 0.329155; batch adversarial loss: 0.535335\n",
      "epoch 189; iter: 0; batch classifier loss: 0.395677; batch adversarial loss: 0.538595\n",
      "epoch 190; iter: 0; batch classifier loss: 0.288023; batch adversarial loss: 0.490266\n",
      "epoch 191; iter: 0; batch classifier loss: 0.410536; batch adversarial loss: 0.574785\n",
      "epoch 192; iter: 0; batch classifier loss: 0.419205; batch adversarial loss: 0.536832\n",
      "epoch 193; iter: 0; batch classifier loss: 0.413166; batch adversarial loss: 0.572854\n",
      "epoch 194; iter: 0; batch classifier loss: 0.420656; batch adversarial loss: 0.544643\n",
      "epoch 195; iter: 0; batch classifier loss: 0.406769; batch adversarial loss: 0.536223\n",
      "epoch 196; iter: 0; batch classifier loss: 0.338385; batch adversarial loss: 0.536009\n",
      "epoch 197; iter: 0; batch classifier loss: 0.375003; batch adversarial loss: 0.570456\n",
      "epoch 198; iter: 0; batch classifier loss: 0.440819; batch adversarial loss: 0.430904\n",
      "epoch 199; iter: 0; batch classifier loss: 0.337559; batch adversarial loss: 0.527250\n",
      "epoch 0; iter: 0; batch classifier loss: 0.759371; batch adversarial loss: 0.870823\n",
      "epoch 1; iter: 0; batch classifier loss: 0.747254; batch adversarial loss: 0.919850\n",
      "epoch 2; iter: 0; batch classifier loss: 0.684048; batch adversarial loss: 0.860828\n",
      "epoch 3; iter: 0; batch classifier loss: 0.735825; batch adversarial loss: 0.779725\n",
      "epoch 4; iter: 0; batch classifier loss: 0.587797; batch adversarial loss: 0.721701\n",
      "epoch 5; iter: 0; batch classifier loss: 0.577384; batch adversarial loss: 0.655017\n",
      "epoch 6; iter: 0; batch classifier loss: 0.549960; batch adversarial loss: 0.643456\n",
      "epoch 7; iter: 0; batch classifier loss: 0.547043; batch adversarial loss: 0.629171\n",
      "epoch 8; iter: 0; batch classifier loss: 0.504372; batch adversarial loss: 0.613964\n",
      "epoch 9; iter: 0; batch classifier loss: 0.563191; batch adversarial loss: 0.607359\n",
      "epoch 10; iter: 0; batch classifier loss: 0.627753; batch adversarial loss: 0.605681\n",
      "epoch 11; iter: 0; batch classifier loss: 0.571530; batch adversarial loss: 0.594826\n",
      "epoch 12; iter: 0; batch classifier loss: 0.538798; batch adversarial loss: 0.581800\n",
      "epoch 13; iter: 0; batch classifier loss: 0.501250; batch adversarial loss: 0.659847\n",
      "epoch 14; iter: 0; batch classifier loss: 0.524917; batch adversarial loss: 0.592864\n",
      "epoch 15; iter: 0; batch classifier loss: 0.536008; batch adversarial loss: 0.561042\n",
      "epoch 16; iter: 0; batch classifier loss: 0.526269; batch adversarial loss: 0.568944\n",
      "epoch 17; iter: 0; batch classifier loss: 0.463086; batch adversarial loss: 0.600078\n",
      "epoch 18; iter: 0; batch classifier loss: 0.523488; batch adversarial loss: 0.596661\n",
      "epoch 19; iter: 0; batch classifier loss: 0.508350; batch adversarial loss: 0.589709\n",
      "epoch 20; iter: 0; batch classifier loss: 0.491803; batch adversarial loss: 0.581786\n",
      "epoch 21; iter: 0; batch classifier loss: 0.467679; batch adversarial loss: 0.553493\n",
      "epoch 22; iter: 0; batch classifier loss: 0.456165; batch adversarial loss: 0.551374\n",
      "epoch 23; iter: 0; batch classifier loss: 0.513232; batch adversarial loss: 0.536257\n",
      "epoch 24; iter: 0; batch classifier loss: 0.485175; batch adversarial loss: 0.557918\n",
      "epoch 25; iter: 0; batch classifier loss: 0.506031; batch adversarial loss: 0.594649\n",
      "epoch 26; iter: 0; batch classifier loss: 0.403065; batch adversarial loss: 0.519573\n",
      "epoch 27; iter: 0; batch classifier loss: 0.529945; batch adversarial loss: 0.566713\n",
      "epoch 28; iter: 0; batch classifier loss: 0.438455; batch adversarial loss: 0.591763\n",
      "epoch 29; iter: 0; batch classifier loss: 0.492609; batch adversarial loss: 0.508389\n",
      "epoch 30; iter: 0; batch classifier loss: 0.471717; batch adversarial loss: 0.540931\n",
      "epoch 31; iter: 0; batch classifier loss: 0.400560; batch adversarial loss: 0.628220\n",
      "epoch 32; iter: 0; batch classifier loss: 0.453797; batch adversarial loss: 0.564654\n",
      "epoch 33; iter: 0; batch classifier loss: 0.485370; batch adversarial loss: 0.554093\n",
      "epoch 34; iter: 0; batch classifier loss: 0.461022; batch adversarial loss: 0.594661\n",
      "epoch 35; iter: 0; batch classifier loss: 0.504718; batch adversarial loss: 0.587466\n",
      "epoch 36; iter: 0; batch classifier loss: 0.483851; batch adversarial loss: 0.570714\n",
      "epoch 37; iter: 0; batch classifier loss: 0.460276; batch adversarial loss: 0.580395\n",
      "epoch 38; iter: 0; batch classifier loss: 0.453232; batch adversarial loss: 0.554674\n",
      "epoch 39; iter: 0; batch classifier loss: 0.494847; batch adversarial loss: 0.622959\n",
      "epoch 40; iter: 0; batch classifier loss: 0.441292; batch adversarial loss: 0.510739\n",
      "epoch 41; iter: 0; batch classifier loss: 0.359325; batch adversarial loss: 0.630823\n",
      "epoch 42; iter: 0; batch classifier loss: 0.391244; batch adversarial loss: 0.563099\n",
      "epoch 43; iter: 0; batch classifier loss: 0.396528; batch adversarial loss: 0.571060\n",
      "epoch 44; iter: 0; batch classifier loss: 0.411108; batch adversarial loss: 0.542606\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 45; iter: 0; batch classifier loss: 0.362437; batch adversarial loss: 0.484230\n",
      "epoch 46; iter: 0; batch classifier loss: 0.418311; batch adversarial loss: 0.537675\n",
      "epoch 47; iter: 0; batch classifier loss: 0.492751; batch adversarial loss: 0.563611\n",
      "epoch 48; iter: 0; batch classifier loss: 0.461165; batch adversarial loss: 0.526889\n",
      "epoch 49; iter: 0; batch classifier loss: 0.421643; batch adversarial loss: 0.535742\n",
      "epoch 50; iter: 0; batch classifier loss: 0.471230; batch adversarial loss: 0.580531\n",
      "epoch 51; iter: 0; batch classifier loss: 0.442287; batch adversarial loss: 0.571361\n",
      "epoch 52; iter: 0; batch classifier loss: 0.470066; batch adversarial loss: 0.535931\n",
      "epoch 53; iter: 0; batch classifier loss: 0.442741; batch adversarial loss: 0.614371\n",
      "epoch 54; iter: 0; batch classifier loss: 0.447275; batch adversarial loss: 0.641803\n",
      "epoch 55; iter: 0; batch classifier loss: 0.464890; batch adversarial loss: 0.546581\n",
      "epoch 56; iter: 0; batch classifier loss: 0.458898; batch adversarial loss: 0.561704\n",
      "epoch 57; iter: 0; batch classifier loss: 0.443783; batch adversarial loss: 0.571927\n",
      "epoch 58; iter: 0; batch classifier loss: 0.458780; batch adversarial loss: 0.553240\n",
      "epoch 59; iter: 0; batch classifier loss: 0.399753; batch adversarial loss: 0.544713\n",
      "epoch 60; iter: 0; batch classifier loss: 0.459763; batch adversarial loss: 0.650000\n",
      "epoch 61; iter: 0; batch classifier loss: 0.413261; batch adversarial loss: 0.538107\n",
      "epoch 62; iter: 0; batch classifier loss: 0.452337; batch adversarial loss: 0.571680\n",
      "epoch 63; iter: 0; batch classifier loss: 0.398552; batch adversarial loss: 0.563375\n",
      "epoch 64; iter: 0; batch classifier loss: 0.406155; batch adversarial loss: 0.569037\n",
      "epoch 65; iter: 0; batch classifier loss: 0.351444; batch adversarial loss: 0.632223\n",
      "epoch 66; iter: 0; batch classifier loss: 0.537300; batch adversarial loss: 0.596325\n",
      "epoch 67; iter: 0; batch classifier loss: 0.437271; batch adversarial loss: 0.562148\n",
      "epoch 68; iter: 0; batch classifier loss: 0.363916; batch adversarial loss: 0.580445\n",
      "epoch 69; iter: 0; batch classifier loss: 0.470663; batch adversarial loss: 0.518216\n",
      "epoch 70; iter: 0; batch classifier loss: 0.335245; batch adversarial loss: 0.544212\n",
      "epoch 71; iter: 0; batch classifier loss: 0.357098; batch adversarial loss: 0.606550\n",
      "epoch 72; iter: 0; batch classifier loss: 0.443134; batch adversarial loss: 0.606251\n",
      "epoch 73; iter: 0; batch classifier loss: 0.355156; batch adversarial loss: 0.606001\n",
      "epoch 74; iter: 0; batch classifier loss: 0.438886; batch adversarial loss: 0.667003\n",
      "epoch 75; iter: 0; batch classifier loss: 0.420954; batch adversarial loss: 0.510388\n",
      "epoch 76; iter: 0; batch classifier loss: 0.406269; batch adversarial loss: 0.552505\n",
      "epoch 77; iter: 0; batch classifier loss: 0.343740; batch adversarial loss: 0.588326\n",
      "epoch 78; iter: 0; batch classifier loss: 0.376769; batch adversarial loss: 0.510386\n",
      "epoch 79; iter: 0; batch classifier loss: 0.420913; batch adversarial loss: 0.587574\n",
      "epoch 80; iter: 0; batch classifier loss: 0.393416; batch adversarial loss: 0.544472\n",
      "epoch 81; iter: 0; batch classifier loss: 0.373348; batch adversarial loss: 0.543234\n",
      "epoch 82; iter: 0; batch classifier loss: 0.492088; batch adversarial loss: 0.552473\n",
      "epoch 83; iter: 0; batch classifier loss: 0.356362; batch adversarial loss: 0.536199\n",
      "epoch 84; iter: 0; batch classifier loss: 0.372514; batch adversarial loss: 0.562002\n",
      "epoch 85; iter: 0; batch classifier loss: 0.407254; batch adversarial loss: 0.535127\n",
      "epoch 86; iter: 0; batch classifier loss: 0.393082; batch adversarial loss: 0.570911\n",
      "epoch 87; iter: 0; batch classifier loss: 0.375246; batch adversarial loss: 0.581919\n",
      "epoch 88; iter: 0; batch classifier loss: 0.378022; batch adversarial loss: 0.536416\n",
      "epoch 89; iter: 0; batch classifier loss: 0.316653; batch adversarial loss: 0.518019\n",
      "epoch 90; iter: 0; batch classifier loss: 0.394296; batch adversarial loss: 0.532402\n",
      "epoch 91; iter: 0; batch classifier loss: 0.440640; batch adversarial loss: 0.465293\n",
      "epoch 92; iter: 0; batch classifier loss: 0.431207; batch adversarial loss: 0.569318\n",
      "epoch 93; iter: 0; batch classifier loss: 0.344143; batch adversarial loss: 0.556850\n",
      "epoch 94; iter: 0; batch classifier loss: 0.394020; batch adversarial loss: 0.650589\n",
      "epoch 95; iter: 0; batch classifier loss: 0.400548; batch adversarial loss: 0.500379\n",
      "epoch 96; iter: 0; batch classifier loss: 0.383811; batch adversarial loss: 0.579662\n",
      "epoch 97; iter: 0; batch classifier loss: 0.395895; batch adversarial loss: 0.552420\n",
      "epoch 98; iter: 0; batch classifier loss: 0.394933; batch adversarial loss: 0.570297\n",
      "epoch 99; iter: 0; batch classifier loss: 0.330451; batch adversarial loss: 0.580524\n",
      "epoch 100; iter: 0; batch classifier loss: 0.376417; batch adversarial loss: 0.518140\n",
      "epoch 101; iter: 0; batch classifier loss: 0.378224; batch adversarial loss: 0.509863\n",
      "epoch 102; iter: 0; batch classifier loss: 0.376853; batch adversarial loss: 0.606449\n",
      "epoch 103; iter: 0; batch classifier loss: 0.402528; batch adversarial loss: 0.484458\n",
      "epoch 104; iter: 0; batch classifier loss: 0.420419; batch adversarial loss: 0.554488\n",
      "epoch 105; iter: 0; batch classifier loss: 0.319168; batch adversarial loss: 0.526933\n",
      "epoch 106; iter: 0; batch classifier loss: 0.376529; batch adversarial loss: 0.606246\n",
      "epoch 107; iter: 0; batch classifier loss: 0.322655; batch adversarial loss: 0.588503\n",
      "epoch 108; iter: 0; batch classifier loss: 0.350259; batch adversarial loss: 0.571516\n",
      "epoch 109; iter: 0; batch classifier loss: 0.389374; batch adversarial loss: 0.536016\n",
      "epoch 110; iter: 0; batch classifier loss: 0.495565; batch adversarial loss: 0.535426\n",
      "epoch 111; iter: 0; batch classifier loss: 0.344158; batch adversarial loss: 0.589834\n",
      "epoch 112; iter: 0; batch classifier loss: 0.335473; batch adversarial loss: 0.623545\n",
      "epoch 113; iter: 0; batch classifier loss: 0.416801; batch adversarial loss: 0.509928\n",
      "epoch 114; iter: 0; batch classifier loss: 0.481947; batch adversarial loss: 0.524506\n",
      "epoch 115; iter: 0; batch classifier loss: 0.466587; batch adversarial loss: 0.504632\n",
      "epoch 116; iter: 0; batch classifier loss: 0.355305; batch adversarial loss: 0.630564\n",
      "epoch 117; iter: 0; batch classifier loss: 0.316309; batch adversarial loss: 0.523845\n",
      "epoch 118; iter: 0; batch classifier loss: 0.409521; batch adversarial loss: 0.555572\n",
      "epoch 119; iter: 0; batch classifier loss: 0.314779; batch adversarial loss: 0.481217\n",
      "epoch 120; iter: 0; batch classifier loss: 0.377725; batch adversarial loss: 0.574453\n",
      "epoch 121; iter: 0; batch classifier loss: 0.344506; batch adversarial loss: 0.537830\n",
      "epoch 122; iter: 0; batch classifier loss: 0.326585; batch adversarial loss: 0.527270\n",
      "epoch 123; iter: 0; batch classifier loss: 0.371816; batch adversarial loss: 0.569816\n",
      "epoch 124; iter: 0; batch classifier loss: 0.359432; batch adversarial loss: 0.537038\n",
      "epoch 125; iter: 0; batch classifier loss: 0.349421; batch adversarial loss: 0.641929\n",
      "epoch 126; iter: 0; batch classifier loss: 0.398973; batch adversarial loss: 0.536060\n",
      "epoch 127; iter: 0; batch classifier loss: 0.342774; batch adversarial loss: 0.604574\n",
      "epoch 128; iter: 0; batch classifier loss: 0.356643; batch adversarial loss: 0.528278\n",
      "epoch 129; iter: 0; batch classifier loss: 0.314274; batch adversarial loss: 0.623100\n",
      "epoch 130; iter: 0; batch classifier loss: 0.461261; batch adversarial loss: 0.524960\n",
      "epoch 131; iter: 0; batch classifier loss: 0.363541; batch adversarial loss: 0.586866\n",
      "epoch 132; iter: 0; batch classifier loss: 0.334800; batch adversarial loss: 0.508266\n",
      "epoch 133; iter: 0; batch classifier loss: 0.319845; batch adversarial loss: 0.616227\n",
      "epoch 134; iter: 0; batch classifier loss: 0.403293; batch adversarial loss: 0.508942\n",
      "epoch 135; iter: 0; batch classifier loss: 0.322572; batch adversarial loss: 0.579519\n",
      "epoch 136; iter: 0; batch classifier loss: 0.327512; batch adversarial loss: 0.562082\n",
      "epoch 137; iter: 0; batch classifier loss: 0.354149; batch adversarial loss: 0.550753\n",
      "epoch 138; iter: 0; batch classifier loss: 0.364416; batch adversarial loss: 0.611962\n",
      "epoch 139; iter: 0; batch classifier loss: 0.374475; batch adversarial loss: 0.595645\n",
      "epoch 140; iter: 0; batch classifier loss: 0.376625; batch adversarial loss: 0.675998\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 141; iter: 0; batch classifier loss: 0.370794; batch adversarial loss: 0.616596\n",
      "epoch 142; iter: 0; batch classifier loss: 0.348357; batch adversarial loss: 0.550358\n",
      "epoch 143; iter: 0; batch classifier loss: 0.434198; batch adversarial loss: 0.571185\n",
      "epoch 144; iter: 0; batch classifier loss: 0.372951; batch adversarial loss: 0.544452\n",
      "epoch 145; iter: 0; batch classifier loss: 0.398815; batch adversarial loss: 0.647213\n",
      "epoch 146; iter: 0; batch classifier loss: 0.317376; batch adversarial loss: 0.520163\n",
      "epoch 147; iter: 0; batch classifier loss: 0.398228; batch adversarial loss: 0.554402\n",
      "epoch 148; iter: 0; batch classifier loss: 0.406718; batch adversarial loss: 0.544662\n",
      "epoch 149; iter: 0; batch classifier loss: 0.345280; batch adversarial loss: 0.578823\n",
      "epoch 150; iter: 0; batch classifier loss: 0.300442; batch adversarial loss: 0.536129\n",
      "epoch 151; iter: 0; batch classifier loss: 0.285992; batch adversarial loss: 0.572245\n",
      "epoch 152; iter: 0; batch classifier loss: 0.389097; batch adversarial loss: 0.595651\n",
      "epoch 153; iter: 0; batch classifier loss: 0.304593; batch adversarial loss: 0.544468\n",
      "epoch 154; iter: 0; batch classifier loss: 0.320942; batch adversarial loss: 0.535646\n",
      "epoch 155; iter: 0; batch classifier loss: 0.346135; batch adversarial loss: 0.648376\n",
      "epoch 156; iter: 0; batch classifier loss: 0.332425; batch adversarial loss: 0.589243\n",
      "epoch 157; iter: 0; batch classifier loss: 0.427651; batch adversarial loss: 0.549101\n",
      "epoch 158; iter: 0; batch classifier loss: 0.363426; batch adversarial loss: 0.524273\n",
      "epoch 159; iter: 0; batch classifier loss: 0.340939; batch adversarial loss: 0.620454\n",
      "epoch 160; iter: 0; batch classifier loss: 0.268640; batch adversarial loss: 0.528623\n",
      "epoch 161; iter: 0; batch classifier loss: 0.335812; batch adversarial loss: 0.495181\n",
      "epoch 162; iter: 0; batch classifier loss: 0.347116; batch adversarial loss: 0.543586\n",
      "epoch 163; iter: 0; batch classifier loss: 0.386659; batch adversarial loss: 0.537921\n",
      "epoch 164; iter: 0; batch classifier loss: 0.362939; batch adversarial loss: 0.507818\n",
      "epoch 165; iter: 0; batch classifier loss: 0.341636; batch adversarial loss: 0.535191\n",
      "epoch 166; iter: 0; batch classifier loss: 0.437560; batch adversarial loss: 0.577458\n",
      "epoch 167; iter: 0; batch classifier loss: 0.336198; batch adversarial loss: 0.526814\n",
      "epoch 168; iter: 0; batch classifier loss: 0.316697; batch adversarial loss: 0.553207\n",
      "epoch 169; iter: 0; batch classifier loss: 0.302096; batch adversarial loss: 0.577008\n",
      "epoch 170; iter: 0; batch classifier loss: 0.373649; batch adversarial loss: 0.553279\n",
      "epoch 171; iter: 0; batch classifier loss: 0.385046; batch adversarial loss: 0.642310\n",
      "epoch 172; iter: 0; batch classifier loss: 0.328207; batch adversarial loss: 0.585462\n",
      "epoch 173; iter: 0; batch classifier loss: 0.298304; batch adversarial loss: 0.510955\n",
      "epoch 174; iter: 0; batch classifier loss: 0.338306; batch adversarial loss: 0.562617\n",
      "epoch 175; iter: 0; batch classifier loss: 0.391269; batch adversarial loss: 0.535388\n",
      "epoch 176; iter: 0; batch classifier loss: 0.376403; batch adversarial loss: 0.525359\n",
      "epoch 177; iter: 0; batch classifier loss: 0.339059; batch adversarial loss: 0.597834\n",
      "epoch 178; iter: 0; batch classifier loss: 0.346513; batch adversarial loss: 0.635967\n",
      "epoch 179; iter: 0; batch classifier loss: 0.301019; batch adversarial loss: 0.713633\n",
      "epoch 180; iter: 0; batch classifier loss: 0.338101; batch adversarial loss: 0.569033\n",
      "epoch 181; iter: 0; batch classifier loss: 0.387183; batch adversarial loss: 0.535115\n",
      "epoch 182; iter: 0; batch classifier loss: 0.443245; batch adversarial loss: 0.623725\n",
      "epoch 183; iter: 0; batch classifier loss: 0.332410; batch adversarial loss: 0.544639\n",
      "epoch 184; iter: 0; batch classifier loss: 0.320046; batch adversarial loss: 0.570305\n",
      "epoch 185; iter: 0; batch classifier loss: 0.352570; batch adversarial loss: 0.520453\n",
      "epoch 186; iter: 0; batch classifier loss: 0.435566; batch adversarial loss: 0.529078\n",
      "epoch 187; iter: 0; batch classifier loss: 0.350429; batch adversarial loss: 0.567634\n",
      "epoch 188; iter: 0; batch classifier loss: 0.381047; batch adversarial loss: 0.621271\n",
      "epoch 189; iter: 0; batch classifier loss: 0.366396; batch adversarial loss: 0.578144\n",
      "epoch 190; iter: 0; batch classifier loss: 0.355386; batch adversarial loss: 0.570334\n",
      "epoch 191; iter: 0; batch classifier loss: 0.328175; batch adversarial loss: 0.564685\n",
      "epoch 192; iter: 0; batch classifier loss: 0.384396; batch adversarial loss: 0.553841\n",
      "epoch 193; iter: 0; batch classifier loss: 0.314915; batch adversarial loss: 0.544409\n",
      "epoch 194; iter: 0; batch classifier loss: 0.422645; batch adversarial loss: 0.512251\n",
      "epoch 195; iter: 0; batch classifier loss: 0.393125; batch adversarial loss: 0.561831\n",
      "epoch 196; iter: 0; batch classifier loss: 0.388932; batch adversarial loss: 0.554848\n",
      "epoch 197; iter: 0; batch classifier loss: 0.319551; batch adversarial loss: 0.509455\n",
      "epoch 198; iter: 0; batch classifier loss: 0.389489; batch adversarial loss: 0.552963\n",
      "epoch 199; iter: 0; batch classifier loss: 0.342419; batch adversarial loss: 0.529729\n",
      "epoch 0; iter: 0; batch classifier loss: 0.852398; batch adversarial loss: 0.909969\n",
      "epoch 1; iter: 0; batch classifier loss: 0.896901; batch adversarial loss: 0.956035\n",
      "epoch 2; iter: 0; batch classifier loss: 0.891007; batch adversarial loss: 0.865500\n",
      "epoch 3; iter: 0; batch classifier loss: 0.977189; batch adversarial loss: 0.829099\n",
      "epoch 4; iter: 0; batch classifier loss: 0.936451; batch adversarial loss: 0.755624\n",
      "epoch 5; iter: 0; batch classifier loss: 0.770075; batch adversarial loss: 0.676648\n",
      "epoch 6; iter: 0; batch classifier loss: 0.664194; batch adversarial loss: 0.619798\n",
      "epoch 7; iter: 0; batch classifier loss: 0.579762; batch adversarial loss: 0.609363\n",
      "epoch 8; iter: 0; batch classifier loss: 0.547331; batch adversarial loss: 0.635521\n",
      "epoch 9; iter: 0; batch classifier loss: 0.598441; batch adversarial loss: 0.605112\n",
      "epoch 10; iter: 0; batch classifier loss: 0.485262; batch adversarial loss: 0.605072\n",
      "epoch 11; iter: 0; batch classifier loss: 0.540614; batch adversarial loss: 0.638175\n",
      "epoch 12; iter: 0; batch classifier loss: 0.522300; batch adversarial loss: 0.557664\n",
      "epoch 13; iter: 0; batch classifier loss: 0.491287; batch adversarial loss: 0.536163\n",
      "epoch 14; iter: 0; batch classifier loss: 0.518073; batch adversarial loss: 0.545826\n",
      "epoch 15; iter: 0; batch classifier loss: 0.513722; batch adversarial loss: 0.560056\n",
      "epoch 16; iter: 0; batch classifier loss: 0.556156; batch adversarial loss: 0.604516\n",
      "epoch 17; iter: 0; batch classifier loss: 0.507655; batch adversarial loss: 0.608213\n",
      "epoch 18; iter: 0; batch classifier loss: 0.591645; batch adversarial loss: 0.561051\n",
      "epoch 19; iter: 0; batch classifier loss: 0.543269; batch adversarial loss: 0.633718\n",
      "epoch 20; iter: 0; batch classifier loss: 0.479009; batch adversarial loss: 0.619594\n",
      "epoch 21; iter: 0; batch classifier loss: 0.450399; batch adversarial loss: 0.587895\n",
      "epoch 22; iter: 0; batch classifier loss: 0.525778; batch adversarial loss: 0.569363\n",
      "epoch 23; iter: 0; batch classifier loss: 0.544432; batch adversarial loss: 0.506309\n",
      "epoch 24; iter: 0; batch classifier loss: 0.486331; batch adversarial loss: 0.545197\n",
      "epoch 25; iter: 0; batch classifier loss: 0.520147; batch adversarial loss: 0.510869\n",
      "epoch 26; iter: 0; batch classifier loss: 0.430461; batch adversarial loss: 0.635894\n",
      "epoch 27; iter: 0; batch classifier loss: 0.443286; batch adversarial loss: 0.569016\n",
      "epoch 28; iter: 0; batch classifier loss: 0.506114; batch adversarial loss: 0.507079\n",
      "epoch 29; iter: 0; batch classifier loss: 0.460610; batch adversarial loss: 0.512338\n",
      "epoch 30; iter: 0; batch classifier loss: 0.397772; batch adversarial loss: 0.554436\n",
      "epoch 31; iter: 0; batch classifier loss: 0.435645; batch adversarial loss: 0.589524\n",
      "epoch 32; iter: 0; batch classifier loss: 0.414480; batch adversarial loss: 0.523042\n",
      "epoch 33; iter: 0; batch classifier loss: 0.531705; batch adversarial loss: 0.559719\n",
      "epoch 34; iter: 0; batch classifier loss: 0.515160; batch adversarial loss: 0.529511\n",
      "epoch 35; iter: 0; batch classifier loss: 0.485675; batch adversarial loss: 0.490076\n",
      "epoch 36; iter: 0; batch classifier loss: 0.533924; batch adversarial loss: 0.522193\n",
      "epoch 37; iter: 0; batch classifier loss: 0.468614; batch adversarial loss: 0.504271\n",
      "epoch 38; iter: 0; batch classifier loss: 0.452568; batch adversarial loss: 0.605633\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 39; iter: 0; batch classifier loss: 0.373518; batch adversarial loss: 0.484052\n",
      "epoch 40; iter: 0; batch classifier loss: 0.444187; batch adversarial loss: 0.608723\n",
      "epoch 41; iter: 0; batch classifier loss: 0.452140; batch adversarial loss: 0.599059\n",
      "epoch 42; iter: 0; batch classifier loss: 0.475447; batch adversarial loss: 0.571751\n",
      "epoch 43; iter: 0; batch classifier loss: 0.391066; batch adversarial loss: 0.518559\n",
      "epoch 44; iter: 0; batch classifier loss: 0.399936; batch adversarial loss: 0.463190\n",
      "epoch 45; iter: 0; batch classifier loss: 0.398421; batch adversarial loss: 0.579725\n",
      "epoch 46; iter: 0; batch classifier loss: 0.458003; batch adversarial loss: 0.559870\n",
      "epoch 47; iter: 0; batch classifier loss: 0.440388; batch adversarial loss: 0.574133\n",
      "epoch 48; iter: 0; batch classifier loss: 0.439960; batch adversarial loss: 0.512084\n",
      "epoch 49; iter: 0; batch classifier loss: 0.438438; batch adversarial loss: 0.549320\n",
      "epoch 50; iter: 0; batch classifier loss: 0.503479; batch adversarial loss: 0.560214\n",
      "epoch 51; iter: 0; batch classifier loss: 0.437474; batch adversarial loss: 0.584313\n",
      "epoch 52; iter: 0; batch classifier loss: 0.489692; batch adversarial loss: 0.450132\n",
      "epoch 53; iter: 0; batch classifier loss: 0.500074; batch adversarial loss: 0.535365\n",
      "epoch 54; iter: 0; batch classifier loss: 0.427268; batch adversarial loss: 0.554983\n",
      "epoch 55; iter: 0; batch classifier loss: 0.391038; batch adversarial loss: 0.542865\n",
      "epoch 56; iter: 0; batch classifier loss: 0.389836; batch adversarial loss: 0.509146\n",
      "epoch 57; iter: 0; batch classifier loss: 0.506662; batch adversarial loss: 0.480701\n",
      "epoch 58; iter: 0; batch classifier loss: 0.440741; batch adversarial loss: 0.531971\n",
      "epoch 59; iter: 0; batch classifier loss: 0.395975; batch adversarial loss: 0.509302\n",
      "epoch 60; iter: 0; batch classifier loss: 0.437322; batch adversarial loss: 0.587288\n",
      "epoch 61; iter: 0; batch classifier loss: 0.427233; batch adversarial loss: 0.467043\n",
      "epoch 62; iter: 0; batch classifier loss: 0.425161; batch adversarial loss: 0.478905\n",
      "epoch 63; iter: 0; batch classifier loss: 0.337325; batch adversarial loss: 0.501778\n",
      "epoch 64; iter: 0; batch classifier loss: 0.451431; batch adversarial loss: 0.476778\n",
      "epoch 65; iter: 0; batch classifier loss: 0.427317; batch adversarial loss: 0.502773\n",
      "epoch 66; iter: 0; batch classifier loss: 0.354320; batch adversarial loss: 0.612085\n",
      "epoch 67; iter: 0; batch classifier loss: 0.406293; batch adversarial loss: 0.499619\n",
      "epoch 68; iter: 0; batch classifier loss: 0.447230; batch adversarial loss: 0.585193\n",
      "epoch 69; iter: 0; batch classifier loss: 0.453379; batch adversarial loss: 0.541080\n",
      "epoch 70; iter: 0; batch classifier loss: 0.438155; batch adversarial loss: 0.544540\n",
      "epoch 71; iter: 0; batch classifier loss: 0.408863; batch adversarial loss: 0.475843\n",
      "epoch 72; iter: 0; batch classifier loss: 0.373445; batch adversarial loss: 0.552118\n",
      "epoch 73; iter: 0; batch classifier loss: 0.374654; batch adversarial loss: 0.569106\n",
      "epoch 74; iter: 0; batch classifier loss: 0.470601; batch adversarial loss: 0.495527\n",
      "epoch 75; iter: 0; batch classifier loss: 0.382001; batch adversarial loss: 0.476946\n",
      "epoch 76; iter: 0; batch classifier loss: 0.315249; batch adversarial loss: 0.524417\n",
      "epoch 77; iter: 0; batch classifier loss: 0.365169; batch adversarial loss: 0.546990\n",
      "epoch 78; iter: 0; batch classifier loss: 0.391226; batch adversarial loss: 0.568558\n",
      "epoch 79; iter: 0; batch classifier loss: 0.436825; batch adversarial loss: 0.496222\n",
      "epoch 80; iter: 0; batch classifier loss: 0.377172; batch adversarial loss: 0.543854\n",
      "epoch 81; iter: 0; batch classifier loss: 0.488197; batch adversarial loss: 0.502769\n",
      "epoch 82; iter: 0; batch classifier loss: 0.396616; batch adversarial loss: 0.570139\n",
      "epoch 83; iter: 0; batch classifier loss: 0.398850; batch adversarial loss: 0.505889\n",
      "epoch 84; iter: 0; batch classifier loss: 0.339916; batch adversarial loss: 0.538033\n",
      "epoch 85; iter: 0; batch classifier loss: 0.339002; batch adversarial loss: 0.601135\n",
      "epoch 86; iter: 0; batch classifier loss: 0.378574; batch adversarial loss: 0.534283\n",
      "epoch 87; iter: 0; batch classifier loss: 0.457996; batch adversarial loss: 0.487038\n",
      "epoch 88; iter: 0; batch classifier loss: 0.354843; batch adversarial loss: 0.534396\n",
      "epoch 89; iter: 0; batch classifier loss: 0.315440; batch adversarial loss: 0.515446\n",
      "epoch 90; iter: 0; batch classifier loss: 0.399158; batch adversarial loss: 0.535085\n",
      "epoch 91; iter: 0; batch classifier loss: 0.389481; batch adversarial loss: 0.496807\n",
      "epoch 92; iter: 0; batch classifier loss: 0.427437; batch adversarial loss: 0.460596\n",
      "epoch 93; iter: 0; batch classifier loss: 0.380556; batch adversarial loss: 0.543271\n",
      "epoch 94; iter: 0; batch classifier loss: 0.337993; batch adversarial loss: 0.564848\n",
      "epoch 95; iter: 0; batch classifier loss: 0.302016; batch adversarial loss: 0.534857\n",
      "epoch 96; iter: 0; batch classifier loss: 0.387432; batch adversarial loss: 0.514835\n",
      "epoch 97; iter: 0; batch classifier loss: 0.382920; batch adversarial loss: 0.459683\n",
      "epoch 98; iter: 0; batch classifier loss: 0.375200; batch adversarial loss: 0.597815\n",
      "epoch 99; iter: 0; batch classifier loss: 0.380510; batch adversarial loss: 0.545917\n",
      "epoch 100; iter: 0; batch classifier loss: 0.363039; batch adversarial loss: 0.546421\n",
      "epoch 101; iter: 0; batch classifier loss: 0.377887; batch adversarial loss: 0.411136\n",
      "epoch 102; iter: 0; batch classifier loss: 0.378523; batch adversarial loss: 0.523744\n",
      "epoch 103; iter: 0; batch classifier loss: 0.397404; batch adversarial loss: 0.565504\n",
      "epoch 104; iter: 0; batch classifier loss: 0.380291; batch adversarial loss: 0.566709\n",
      "epoch 105; iter: 0; batch classifier loss: 0.424437; batch adversarial loss: 0.562909\n",
      "epoch 106; iter: 0; batch classifier loss: 0.378988; batch adversarial loss: 0.488624\n",
      "epoch 107; iter: 0; batch classifier loss: 0.344210; batch adversarial loss: 0.544228\n",
      "epoch 108; iter: 0; batch classifier loss: 0.331916; batch adversarial loss: 0.563705\n",
      "epoch 109; iter: 0; batch classifier loss: 0.350405; batch adversarial loss: 0.431990\n",
      "epoch 110; iter: 0; batch classifier loss: 0.368117; batch adversarial loss: 0.497805\n",
      "epoch 111; iter: 0; batch classifier loss: 0.322466; batch adversarial loss: 0.487811\n",
      "epoch 112; iter: 0; batch classifier loss: 0.384333; batch adversarial loss: 0.563921\n",
      "epoch 113; iter: 0; batch classifier loss: 0.353543; batch adversarial loss: 0.601559\n",
      "epoch 114; iter: 0; batch classifier loss: 0.325059; batch adversarial loss: 0.554564\n",
      "epoch 115; iter: 0; batch classifier loss: 0.301104; batch adversarial loss: 0.545163\n",
      "epoch 116; iter: 0; batch classifier loss: 0.325945; batch adversarial loss: 0.580595\n",
      "epoch 117; iter: 0; batch classifier loss: 0.352553; batch adversarial loss: 0.515486\n",
      "epoch 118; iter: 0; batch classifier loss: 0.339835; batch adversarial loss: 0.535258\n",
      "epoch 119; iter: 0; batch classifier loss: 0.408550; batch adversarial loss: 0.469753\n",
      "epoch 120; iter: 0; batch classifier loss: 0.305556; batch adversarial loss: 0.612452\n",
      "epoch 121; iter: 0; batch classifier loss: 0.347489; batch adversarial loss: 0.590564\n",
      "epoch 122; iter: 0; batch classifier loss: 0.335086; batch adversarial loss: 0.564345\n",
      "epoch 123; iter: 0; batch classifier loss: 0.286231; batch adversarial loss: 0.440865\n",
      "epoch 124; iter: 0; batch classifier loss: 0.324740; batch adversarial loss: 0.554307\n",
      "epoch 125; iter: 0; batch classifier loss: 0.328153; batch adversarial loss: 0.553531\n",
      "epoch 126; iter: 0; batch classifier loss: 0.492025; batch adversarial loss: 0.600917\n",
      "epoch 127; iter: 0; batch classifier loss: 0.379431; batch adversarial loss: 0.505715\n",
      "epoch 128; iter: 0; batch classifier loss: 0.409661; batch adversarial loss: 0.591807\n",
      "epoch 129; iter: 0; batch classifier loss: 0.344215; batch adversarial loss: 0.545469\n",
      "epoch 130; iter: 0; batch classifier loss: 0.333685; batch adversarial loss: 0.534889\n",
      "epoch 131; iter: 0; batch classifier loss: 0.331623; batch adversarial loss: 0.489542\n",
      "epoch 132; iter: 0; batch classifier loss: 0.402655; batch adversarial loss: 0.552703\n",
      "epoch 133; iter: 0; batch classifier loss: 0.316487; batch adversarial loss: 0.552525\n",
      "epoch 134; iter: 0; batch classifier loss: 0.297587; batch adversarial loss: 0.478955\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 135; iter: 0; batch classifier loss: 0.334266; batch adversarial loss: 0.515258\n",
      "epoch 136; iter: 0; batch classifier loss: 0.422895; batch adversarial loss: 0.524501\n",
      "epoch 137; iter: 0; batch classifier loss: 0.357758; batch adversarial loss: 0.554556\n",
      "epoch 138; iter: 0; batch classifier loss: 0.304678; batch adversarial loss: 0.507645\n",
      "epoch 139; iter: 0; batch classifier loss: 0.337428; batch adversarial loss: 0.516944\n",
      "epoch 140; iter: 0; batch classifier loss: 0.345632; batch adversarial loss: 0.487599\n",
      "epoch 141; iter: 0; batch classifier loss: 0.361562; batch adversarial loss: 0.478904\n",
      "epoch 142; iter: 0; batch classifier loss: 0.340539; batch adversarial loss: 0.496907\n",
      "epoch 143; iter: 0; batch classifier loss: 0.333207; batch adversarial loss: 0.592443\n",
      "epoch 144; iter: 0; batch classifier loss: 0.330131; batch adversarial loss: 0.582429\n",
      "epoch 145; iter: 0; batch classifier loss: 0.333674; batch adversarial loss: 0.525516\n",
      "epoch 146; iter: 0; batch classifier loss: 0.434388; batch adversarial loss: 0.555534\n",
      "epoch 147; iter: 0; batch classifier loss: 0.300703; batch adversarial loss: 0.527879\n",
      "epoch 148; iter: 0; batch classifier loss: 0.364294; batch adversarial loss: 0.525106\n",
      "epoch 149; iter: 0; batch classifier loss: 0.379019; batch adversarial loss: 0.457109\n",
      "epoch 150; iter: 0; batch classifier loss: 0.293570; batch adversarial loss: 0.545328\n",
      "epoch 151; iter: 0; batch classifier loss: 0.344004; batch adversarial loss: 0.570565\n",
      "epoch 152; iter: 0; batch classifier loss: 0.331928; batch adversarial loss: 0.620260\n",
      "epoch 153; iter: 0; batch classifier loss: 0.321420; batch adversarial loss: 0.525482\n",
      "epoch 154; iter: 0; batch classifier loss: 0.335689; batch adversarial loss: 0.599103\n",
      "epoch 155; iter: 0; batch classifier loss: 0.332122; batch adversarial loss: 0.559329\n",
      "epoch 156; iter: 0; batch classifier loss: 0.349189; batch adversarial loss: 0.533051\n",
      "epoch 157; iter: 0; batch classifier loss: 0.292242; batch adversarial loss: 0.550466\n",
      "epoch 158; iter: 0; batch classifier loss: 0.290717; batch adversarial loss: 0.552093\n",
      "epoch 159; iter: 0; batch classifier loss: 0.328020; batch adversarial loss: 0.641016\n",
      "epoch 160; iter: 0; batch classifier loss: 0.348867; batch adversarial loss: 0.514868\n",
      "epoch 161; iter: 0; batch classifier loss: 0.337902; batch adversarial loss: 0.525812\n",
      "epoch 162; iter: 0; batch classifier loss: 0.328331; batch adversarial loss: 0.562657\n",
      "epoch 163; iter: 0; batch classifier loss: 0.384617; batch adversarial loss: 0.618242\n",
      "epoch 164; iter: 0; batch classifier loss: 0.375884; batch adversarial loss: 0.533934\n",
      "epoch 165; iter: 0; batch classifier loss: 0.430536; batch adversarial loss: 0.619019\n",
      "epoch 166; iter: 0; batch classifier loss: 0.394991; batch adversarial loss: 0.628555\n",
      "epoch 167; iter: 0; batch classifier loss: 0.312658; batch adversarial loss: 0.488727\n",
      "epoch 168; iter: 0; batch classifier loss: 0.486704; batch adversarial loss: 0.543308\n",
      "epoch 169; iter: 0; batch classifier loss: 0.365126; batch adversarial loss: 0.526455\n",
      "epoch 170; iter: 0; batch classifier loss: 0.315516; batch adversarial loss: 0.572011\n",
      "epoch 171; iter: 0; batch classifier loss: 0.249465; batch adversarial loss: 0.573113\n",
      "epoch 172; iter: 0; batch classifier loss: 0.325787; batch adversarial loss: 0.565693\n",
      "epoch 173; iter: 0; batch classifier loss: 0.357550; batch adversarial loss: 0.518181\n",
      "epoch 174; iter: 0; batch classifier loss: 0.345890; batch adversarial loss: 0.487865\n",
      "epoch 175; iter: 0; batch classifier loss: 0.367026; batch adversarial loss: 0.518282\n",
      "epoch 176; iter: 0; batch classifier loss: 0.389318; batch adversarial loss: 0.489216\n",
      "epoch 177; iter: 0; batch classifier loss: 0.365555; batch adversarial loss: 0.572520\n",
      "epoch 178; iter: 0; batch classifier loss: 0.367504; batch adversarial loss: 0.506734\n",
      "epoch 179; iter: 0; batch classifier loss: 0.335330; batch adversarial loss: 0.553589\n",
      "epoch 180; iter: 0; batch classifier loss: 0.346065; batch adversarial loss: 0.638532\n",
      "epoch 181; iter: 0; batch classifier loss: 0.337454; batch adversarial loss: 0.610224\n",
      "epoch 182; iter: 0; batch classifier loss: 0.396201; batch adversarial loss: 0.581755\n",
      "epoch 183; iter: 0; batch classifier loss: 0.367323; batch adversarial loss: 0.593727\n",
      "epoch 184; iter: 0; batch classifier loss: 0.341504; batch adversarial loss: 0.591746\n",
      "epoch 185; iter: 0; batch classifier loss: 0.276297; batch adversarial loss: 0.506854\n",
      "epoch 186; iter: 0; batch classifier loss: 0.327033; batch adversarial loss: 0.667282\n",
      "epoch 187; iter: 0; batch classifier loss: 0.330442; batch adversarial loss: 0.468768\n",
      "epoch 188; iter: 0; batch classifier loss: 0.348959; batch adversarial loss: 0.517036\n",
      "epoch 189; iter: 0; batch classifier loss: 0.335507; batch adversarial loss: 0.460489\n",
      "epoch 190; iter: 0; batch classifier loss: 0.289532; batch adversarial loss: 0.506534\n",
      "epoch 191; iter: 0; batch classifier loss: 0.320607; batch adversarial loss: 0.515759\n",
      "epoch 192; iter: 0; batch classifier loss: 0.340103; batch adversarial loss: 0.565202\n",
      "epoch 193; iter: 0; batch classifier loss: 0.290355; batch adversarial loss: 0.522418\n",
      "epoch 194; iter: 0; batch classifier loss: 0.416197; batch adversarial loss: 0.574123\n",
      "epoch 195; iter: 0; batch classifier loss: 0.320863; batch adversarial loss: 0.525604\n",
      "epoch 196; iter: 0; batch classifier loss: 0.368950; batch adversarial loss: 0.534997\n",
      "epoch 197; iter: 0; batch classifier loss: 0.285056; batch adversarial loss: 0.507083\n",
      "epoch 198; iter: 0; batch classifier loss: 0.338256; batch adversarial loss: 0.507380\n",
      "epoch 199; iter: 0; batch classifier loss: 0.312775; batch adversarial loss: 0.497839\n",
      "epoch 0; iter: 0; batch classifier loss: 0.703479; batch adversarial loss: 0.691303\n",
      "epoch 1; iter: 0; batch classifier loss: 0.586113; batch adversarial loss: 0.663336\n",
      "epoch 2; iter: 0; batch classifier loss: 0.562400; batch adversarial loss: 0.618864\n",
      "epoch 3; iter: 0; batch classifier loss: 0.538323; batch adversarial loss: 0.603911\n",
      "epoch 4; iter: 0; batch classifier loss: 0.594467; batch adversarial loss: 0.605581\n",
      "epoch 5; iter: 0; batch classifier loss: 0.551783; batch adversarial loss: 0.604137\n",
      "epoch 6; iter: 0; batch classifier loss: 0.535636; batch adversarial loss: 0.578428\n",
      "epoch 7; iter: 0; batch classifier loss: 0.562207; batch adversarial loss: 0.588500\n",
      "epoch 8; iter: 0; batch classifier loss: 0.611656; batch adversarial loss: 0.525044\n",
      "epoch 9; iter: 0; batch classifier loss: 0.479981; batch adversarial loss: 0.560996\n",
      "epoch 10; iter: 0; batch classifier loss: 0.558108; batch adversarial loss: 0.666880\n",
      "epoch 11; iter: 0; batch classifier loss: 0.457387; batch adversarial loss: 0.636668\n",
      "epoch 12; iter: 0; batch classifier loss: 0.457553; batch adversarial loss: 0.588467\n",
      "epoch 13; iter: 0; batch classifier loss: 0.480424; batch adversarial loss: 0.582046\n",
      "epoch 14; iter: 0; batch classifier loss: 0.504228; batch adversarial loss: 0.570896\n",
      "epoch 15; iter: 0; batch classifier loss: 0.527630; batch adversarial loss: 0.579876\n",
      "epoch 16; iter: 0; batch classifier loss: 0.597528; batch adversarial loss: 0.640516\n",
      "epoch 17; iter: 0; batch classifier loss: 0.586868; batch adversarial loss: 0.624171\n",
      "epoch 18; iter: 0; batch classifier loss: 0.483024; batch adversarial loss: 0.556462\n",
      "epoch 19; iter: 0; batch classifier loss: 0.564213; batch adversarial loss: 0.555744\n",
      "epoch 20; iter: 0; batch classifier loss: 0.497007; batch adversarial loss: 0.601834\n",
      "epoch 21; iter: 0; batch classifier loss: 0.521697; batch adversarial loss: 0.575197\n",
      "epoch 22; iter: 0; batch classifier loss: 0.490174; batch adversarial loss: 0.551577\n",
      "epoch 23; iter: 0; batch classifier loss: 0.487383; batch adversarial loss: 0.582988\n",
      "epoch 24; iter: 0; batch classifier loss: 0.551345; batch adversarial loss: 0.527170\n",
      "epoch 25; iter: 0; batch classifier loss: 0.445770; batch adversarial loss: 0.564327\n",
      "epoch 26; iter: 0; batch classifier loss: 0.392897; batch adversarial loss: 0.524879\n",
      "epoch 27; iter: 0; batch classifier loss: 0.460324; batch adversarial loss: 0.564203\n",
      "epoch 28; iter: 0; batch classifier loss: 0.475969; batch adversarial loss: 0.517239\n",
      "epoch 29; iter: 0; batch classifier loss: 0.538717; batch adversarial loss: 0.522068\n",
      "epoch 30; iter: 0; batch classifier loss: 0.450402; batch adversarial loss: 0.488684\n",
      "epoch 31; iter: 0; batch classifier loss: 0.496420; batch adversarial loss: 0.554507\n",
      "epoch 32; iter: 0; batch classifier loss: 0.472775; batch adversarial loss: 0.579815\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 33; iter: 0; batch classifier loss: 0.450877; batch adversarial loss: 0.510356\n",
      "epoch 34; iter: 0; batch classifier loss: 0.519120; batch adversarial loss: 0.614817\n",
      "epoch 35; iter: 0; batch classifier loss: 0.509773; batch adversarial loss: 0.509085\n",
      "epoch 36; iter: 0; batch classifier loss: 0.511536; batch adversarial loss: 0.535063\n",
      "epoch 37; iter: 0; batch classifier loss: 0.476213; batch adversarial loss: 0.452683\n",
      "epoch 38; iter: 0; batch classifier loss: 0.503367; batch adversarial loss: 0.563490\n",
      "epoch 39; iter: 0; batch classifier loss: 0.404134; batch adversarial loss: 0.553370\n",
      "epoch 40; iter: 0; batch classifier loss: 0.453725; batch adversarial loss: 0.505801\n",
      "epoch 41; iter: 0; batch classifier loss: 0.395136; batch adversarial loss: 0.499466\n",
      "epoch 42; iter: 0; batch classifier loss: 0.450321; batch adversarial loss: 0.596982\n",
      "epoch 43; iter: 0; batch classifier loss: 0.455927; batch adversarial loss: 0.446559\n",
      "epoch 44; iter: 0; batch classifier loss: 0.416006; batch adversarial loss: 0.591677\n",
      "epoch 45; iter: 0; batch classifier loss: 0.521274; batch adversarial loss: 0.510807\n",
      "epoch 46; iter: 0; batch classifier loss: 0.465356; batch adversarial loss: 0.571003\n",
      "epoch 47; iter: 0; batch classifier loss: 0.413511; batch adversarial loss: 0.562258\n",
      "epoch 48; iter: 0; batch classifier loss: 0.457038; batch adversarial loss: 0.509647\n",
      "epoch 49; iter: 0; batch classifier loss: 0.427724; batch adversarial loss: 0.579833\n",
      "epoch 50; iter: 0; batch classifier loss: 0.339551; batch adversarial loss: 0.570303\n",
      "epoch 51; iter: 0; batch classifier loss: 0.464315; batch adversarial loss: 0.580779\n",
      "epoch 52; iter: 0; batch classifier loss: 0.431265; batch adversarial loss: 0.508117\n",
      "epoch 53; iter: 0; batch classifier loss: 0.471771; batch adversarial loss: 0.544674\n",
      "epoch 54; iter: 0; batch classifier loss: 0.453746; batch adversarial loss: 0.599375\n",
      "epoch 55; iter: 0; batch classifier loss: 0.405184; batch adversarial loss: 0.517305\n",
      "epoch 56; iter: 0; batch classifier loss: 0.350009; batch adversarial loss: 0.508032\n",
      "epoch 57; iter: 0; batch classifier loss: 0.466321; batch adversarial loss: 0.562578\n",
      "epoch 58; iter: 0; batch classifier loss: 0.479010; batch adversarial loss: 0.608335\n",
      "epoch 59; iter: 0; batch classifier loss: 0.471338; batch adversarial loss: 0.562694\n",
      "epoch 60; iter: 0; batch classifier loss: 0.406613; batch adversarial loss: 0.461831\n",
      "epoch 61; iter: 0; batch classifier loss: 0.424409; batch adversarial loss: 0.609859\n",
      "epoch 62; iter: 0; batch classifier loss: 0.463126; batch adversarial loss: 0.472407\n",
      "epoch 63; iter: 0; batch classifier loss: 0.361121; batch adversarial loss: 0.499584\n",
      "epoch 64; iter: 0; batch classifier loss: 0.367537; batch adversarial loss: 0.589645\n",
      "epoch 65; iter: 0; batch classifier loss: 0.441619; batch adversarial loss: 0.526018\n",
      "epoch 66; iter: 0; batch classifier loss: 0.419217; batch adversarial loss: 0.523901\n",
      "epoch 67; iter: 0; batch classifier loss: 0.413227; batch adversarial loss: 0.536115\n",
      "epoch 68; iter: 0; batch classifier loss: 0.460345; batch adversarial loss: 0.555170\n",
      "epoch 69; iter: 0; batch classifier loss: 0.437288; batch adversarial loss: 0.479709\n",
      "epoch 70; iter: 0; batch classifier loss: 0.399209; batch adversarial loss: 0.617539\n",
      "epoch 71; iter: 0; batch classifier loss: 0.395862; batch adversarial loss: 0.563581\n",
      "epoch 72; iter: 0; batch classifier loss: 0.391263; batch adversarial loss: 0.526389\n",
      "epoch 73; iter: 0; batch classifier loss: 0.370125; batch adversarial loss: 0.637011\n",
      "epoch 74; iter: 0; batch classifier loss: 0.440008; batch adversarial loss: 0.516207\n",
      "epoch 75; iter: 0; batch classifier loss: 0.399982; batch adversarial loss: 0.572288\n",
      "epoch 76; iter: 0; batch classifier loss: 0.381129; batch adversarial loss: 0.498704\n",
      "epoch 77; iter: 0; batch classifier loss: 0.332321; batch adversarial loss: 0.535366\n",
      "epoch 78; iter: 0; batch classifier loss: 0.421823; batch adversarial loss: 0.562144\n",
      "epoch 79; iter: 0; batch classifier loss: 0.396435; batch adversarial loss: 0.452616\n",
      "epoch 80; iter: 0; batch classifier loss: 0.381001; batch adversarial loss: 0.516746\n",
      "epoch 81; iter: 0; batch classifier loss: 0.370361; batch adversarial loss: 0.561636\n",
      "epoch 82; iter: 0; batch classifier loss: 0.411766; batch adversarial loss: 0.534372\n",
      "epoch 83; iter: 0; batch classifier loss: 0.445789; batch adversarial loss: 0.537531\n",
      "epoch 84; iter: 0; batch classifier loss: 0.364833; batch adversarial loss: 0.499168\n",
      "epoch 85; iter: 0; batch classifier loss: 0.465584; batch adversarial loss: 0.570889\n",
      "epoch 86; iter: 0; batch classifier loss: 0.345090; batch adversarial loss: 0.571379\n",
      "epoch 87; iter: 0; batch classifier loss: 0.346527; batch adversarial loss: 0.571381\n",
      "epoch 88; iter: 0; batch classifier loss: 0.366854; batch adversarial loss: 0.571306\n",
      "epoch 89; iter: 0; batch classifier loss: 0.377263; batch adversarial loss: 0.533790\n",
      "epoch 90; iter: 0; batch classifier loss: 0.440875; batch adversarial loss: 0.573273\n",
      "epoch 91; iter: 0; batch classifier loss: 0.333138; batch adversarial loss: 0.454883\n",
      "epoch 92; iter: 0; batch classifier loss: 0.410140; batch adversarial loss: 0.536196\n",
      "epoch 93; iter: 0; batch classifier loss: 0.403299; batch adversarial loss: 0.526648\n",
      "epoch 94; iter: 0; batch classifier loss: 0.451668; batch adversarial loss: 0.553126\n",
      "epoch 95; iter: 0; batch classifier loss: 0.361401; batch adversarial loss: 0.617275\n",
      "epoch 96; iter: 0; batch classifier loss: 0.384951; batch adversarial loss: 0.553601\n",
      "epoch 97; iter: 0; batch classifier loss: 0.329137; batch adversarial loss: 0.453603\n",
      "epoch 98; iter: 0; batch classifier loss: 0.411799; batch adversarial loss: 0.526910\n",
      "epoch 99; iter: 0; batch classifier loss: 0.409606; batch adversarial loss: 0.561644\n",
      "epoch 100; iter: 0; batch classifier loss: 0.458748; batch adversarial loss: 0.608409\n",
      "epoch 101; iter: 0; batch classifier loss: 0.334693; batch adversarial loss: 0.607736\n",
      "epoch 102; iter: 0; batch classifier loss: 0.361195; batch adversarial loss: 0.543774\n",
      "epoch 103; iter: 0; batch classifier loss: 0.454794; batch adversarial loss: 0.536651\n",
      "epoch 104; iter: 0; batch classifier loss: 0.404611; batch adversarial loss: 0.472462\n",
      "epoch 105; iter: 0; batch classifier loss: 0.342671; batch adversarial loss: 0.499610\n",
      "epoch 106; iter: 0; batch classifier loss: 0.353868; batch adversarial loss: 0.435899\n",
      "epoch 107; iter: 0; batch classifier loss: 0.321355; batch adversarial loss: 0.598696\n",
      "epoch 108; iter: 0; batch classifier loss: 0.445424; batch adversarial loss: 0.553766\n",
      "epoch 109; iter: 0; batch classifier loss: 0.439128; batch adversarial loss: 0.516598\n",
      "epoch 110; iter: 0; batch classifier loss: 0.448567; batch adversarial loss: 0.516767\n",
      "epoch 111; iter: 0; batch classifier loss: 0.419233; batch adversarial loss: 0.481966\n",
      "epoch 112; iter: 0; batch classifier loss: 0.367090; batch adversarial loss: 0.526221\n",
      "epoch 113; iter: 0; batch classifier loss: 0.362735; batch adversarial loss: 0.645032\n",
      "epoch 114; iter: 0; batch classifier loss: 0.340285; batch adversarial loss: 0.479588\n",
      "epoch 115; iter: 0; batch classifier loss: 0.410058; batch adversarial loss: 0.561378\n",
      "epoch 116; iter: 0; batch classifier loss: 0.389677; batch adversarial loss: 0.536334\n",
      "epoch 117; iter: 0; batch classifier loss: 0.434776; batch adversarial loss: 0.552568\n",
      "epoch 118; iter: 0; batch classifier loss: 0.359225; batch adversarial loss: 0.573897\n",
      "epoch 119; iter: 0; batch classifier loss: 0.398792; batch adversarial loss: 0.571472\n",
      "epoch 120; iter: 0; batch classifier loss: 0.397675; batch adversarial loss: 0.571585\n",
      "epoch 121; iter: 0; batch classifier loss: 0.317571; batch adversarial loss: 0.453297\n",
      "epoch 122; iter: 0; batch classifier loss: 0.378836; batch adversarial loss: 0.573134\n",
      "epoch 123; iter: 0; batch classifier loss: 0.336426; batch adversarial loss: 0.543004\n",
      "epoch 124; iter: 0; batch classifier loss: 0.466901; batch adversarial loss: 0.554544\n",
      "epoch 125; iter: 0; batch classifier loss: 0.353412; batch adversarial loss: 0.526372\n",
      "epoch 126; iter: 0; batch classifier loss: 0.422582; batch adversarial loss: 0.471476\n",
      "epoch 127; iter: 0; batch classifier loss: 0.403188; batch adversarial loss: 0.546332\n",
      "epoch 128; iter: 0; batch classifier loss: 0.375893; batch adversarial loss: 0.517387\n",
      "epoch 129; iter: 0; batch classifier loss: 0.323098; batch adversarial loss: 0.417529\n",
      "epoch 130; iter: 0; batch classifier loss: 0.425284; batch adversarial loss: 0.527281\n",
      "epoch 131; iter: 0; batch classifier loss: 0.468104; batch adversarial loss: 0.625535\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 132; iter: 0; batch classifier loss: 0.368731; batch adversarial loss: 0.498666\n",
      "epoch 133; iter: 0; batch classifier loss: 0.327505; batch adversarial loss: 0.553528\n",
      "epoch 134; iter: 0; batch classifier loss: 0.297831; batch adversarial loss: 0.562534\n",
      "epoch 135; iter: 0; batch classifier loss: 0.325996; batch adversarial loss: 0.506997\n",
      "epoch 136; iter: 0; batch classifier loss: 0.347448; batch adversarial loss: 0.553240\n",
      "epoch 137; iter: 0; batch classifier loss: 0.345844; batch adversarial loss: 0.553366\n",
      "epoch 138; iter: 0; batch classifier loss: 0.332000; batch adversarial loss: 0.606908\n",
      "epoch 139; iter: 0; batch classifier loss: 0.373389; batch adversarial loss: 0.553614\n",
      "epoch 140; iter: 0; batch classifier loss: 0.393276; batch adversarial loss: 0.499207\n",
      "epoch 141; iter: 0; batch classifier loss: 0.294011; batch adversarial loss: 0.508210\n",
      "epoch 142; iter: 0; batch classifier loss: 0.322474; batch adversarial loss: 0.662981\n",
      "epoch 143; iter: 0; batch classifier loss: 0.320649; batch adversarial loss: 0.600193\n",
      "epoch 144; iter: 0; batch classifier loss: 0.332340; batch adversarial loss: 0.571051\n",
      "epoch 145; iter: 0; batch classifier loss: 0.375590; batch adversarial loss: 0.463401\n",
      "epoch 146; iter: 0; batch classifier loss: 0.363828; batch adversarial loss: 0.527329\n",
      "epoch 147; iter: 0; batch classifier loss: 0.400730; batch adversarial loss: 0.490367\n",
      "epoch 148; iter: 0; batch classifier loss: 0.457177; batch adversarial loss: 0.553964\n",
      "epoch 149; iter: 0; batch classifier loss: 0.336313; batch adversarial loss: 0.570899\n",
      "epoch 150; iter: 0; batch classifier loss: 0.355013; batch adversarial loss: 0.526253\n",
      "epoch 151; iter: 0; batch classifier loss: 0.366533; batch adversarial loss: 0.426875\n",
      "epoch 152; iter: 0; batch classifier loss: 0.344004; batch adversarial loss: 0.553440\n",
      "epoch 153; iter: 0; batch classifier loss: 0.313958; batch adversarial loss: 0.552768\n",
      "epoch 154; iter: 0; batch classifier loss: 0.329874; batch adversarial loss: 0.544003\n",
      "epoch 155; iter: 0; batch classifier loss: 0.370813; batch adversarial loss: 0.582063\n",
      "epoch 156; iter: 0; batch classifier loss: 0.410851; batch adversarial loss: 0.553208\n",
      "epoch 157; iter: 0; batch classifier loss: 0.388384; batch adversarial loss: 0.571905\n",
      "epoch 158; iter: 0; batch classifier loss: 0.324464; batch adversarial loss: 0.607319\n",
      "epoch 159; iter: 0; batch classifier loss: 0.356227; batch adversarial loss: 0.452610\n",
      "epoch 160; iter: 0; batch classifier loss: 0.316954; batch adversarial loss: 0.591578\n",
      "epoch 161; iter: 0; batch classifier loss: 0.314905; batch adversarial loss: 0.571572\n",
      "epoch 162; iter: 0; batch classifier loss: 0.397820; batch adversarial loss: 0.527423\n",
      "epoch 163; iter: 0; batch classifier loss: 0.323496; batch adversarial loss: 0.482035\n",
      "epoch 164; iter: 0; batch classifier loss: 0.417498; batch adversarial loss: 0.589653\n",
      "epoch 165; iter: 0; batch classifier loss: 0.428315; batch adversarial loss: 0.554958\n",
      "epoch 166; iter: 0; batch classifier loss: 0.407041; batch adversarial loss: 0.543588\n",
      "epoch 167; iter: 0; batch classifier loss: 0.356800; batch adversarial loss: 0.489415\n",
      "epoch 168; iter: 0; batch classifier loss: 0.374215; batch adversarial loss: 0.555069\n",
      "epoch 169; iter: 0; batch classifier loss: 0.448038; batch adversarial loss: 0.571854\n",
      "epoch 170; iter: 0; batch classifier loss: 0.438304; batch adversarial loss: 0.507843\n",
      "epoch 171; iter: 0; batch classifier loss: 0.454727; batch adversarial loss: 0.589780\n",
      "epoch 172; iter: 0; batch classifier loss: 0.405107; batch adversarial loss: 0.581418\n",
      "epoch 173; iter: 0; batch classifier loss: 0.317561; batch adversarial loss: 0.527503\n",
      "epoch 174; iter: 0; batch classifier loss: 0.297060; batch adversarial loss: 0.543819\n",
      "epoch 175; iter: 0; batch classifier loss: 0.308260; batch adversarial loss: 0.533801\n",
      "epoch 176; iter: 0; batch classifier loss: 0.326430; batch adversarial loss: 0.543350\n",
      "epoch 177; iter: 0; batch classifier loss: 0.303677; batch adversarial loss: 0.662539\n",
      "epoch 178; iter: 0; batch classifier loss: 0.339336; batch adversarial loss: 0.462449\n",
      "epoch 179; iter: 0; batch classifier loss: 0.387476; batch adversarial loss: 0.527085\n",
      "epoch 180; iter: 0; batch classifier loss: 0.392305; batch adversarial loss: 0.472727\n",
      "epoch 181; iter: 0; batch classifier loss: 0.345928; batch adversarial loss: 0.580710\n",
      "epoch 182; iter: 0; batch classifier loss: 0.349320; batch adversarial loss: 0.464088\n",
      "epoch 183; iter: 0; batch classifier loss: 0.386839; batch adversarial loss: 0.609909\n",
      "epoch 184; iter: 0; batch classifier loss: 0.307292; batch adversarial loss: 0.579250\n",
      "epoch 185; iter: 0; batch classifier loss: 0.331650; batch adversarial loss: 0.527042\n",
      "epoch 186; iter: 0; batch classifier loss: 0.398857; batch adversarial loss: 0.626241\n",
      "epoch 187; iter: 0; batch classifier loss: 0.326810; batch adversarial loss: 0.490112\n",
      "epoch 188; iter: 0; batch classifier loss: 0.341216; batch adversarial loss: 0.543721\n",
      "epoch 189; iter: 0; batch classifier loss: 0.406487; batch adversarial loss: 0.589078\n",
      "epoch 190; iter: 0; batch classifier loss: 0.371973; batch adversarial loss: 0.526930\n",
      "epoch 191; iter: 0; batch classifier loss: 0.341246; batch adversarial loss: 0.489776\n",
      "epoch 192; iter: 0; batch classifier loss: 0.308035; batch adversarial loss: 0.573580\n",
      "epoch 193; iter: 0; batch classifier loss: 0.317466; batch adversarial loss: 0.536853\n",
      "epoch 194; iter: 0; batch classifier loss: 0.350517; batch adversarial loss: 0.580726\n",
      "epoch 195; iter: 0; batch classifier loss: 0.299005; batch adversarial loss: 0.535548\n",
      "epoch 196; iter: 0; batch classifier loss: 0.307520; batch adversarial loss: 0.554286\n",
      "epoch 197; iter: 0; batch classifier loss: 0.439099; batch adversarial loss: 0.654715\n",
      "epoch 198; iter: 0; batch classifier loss: 0.331100; batch adversarial loss: 0.533806\n",
      "epoch 199; iter: 0; batch classifier loss: 0.480794; batch adversarial loss: 0.581056\n",
      "epoch 0; iter: 0; batch classifier loss: 0.702670; batch adversarial loss: 0.977119\n",
      "epoch 1; iter: 0; batch classifier loss: 0.791053; batch adversarial loss: 1.108734\n",
      "epoch 2; iter: 0; batch classifier loss: 0.958380; batch adversarial loss: 1.138950\n",
      "epoch 3; iter: 0; batch classifier loss: 1.087136; batch adversarial loss: 1.026077\n",
      "epoch 4; iter: 0; batch classifier loss: 1.189227; batch adversarial loss: 0.953334\n",
      "epoch 5; iter: 0; batch classifier loss: 1.291848; batch adversarial loss: 0.887335\n",
      "epoch 6; iter: 0; batch classifier loss: 1.043675; batch adversarial loss: 0.811007\n",
      "epoch 7; iter: 0; batch classifier loss: 1.125423; batch adversarial loss: 0.760036\n",
      "epoch 8; iter: 0; batch classifier loss: 0.996333; batch adversarial loss: 0.680165\n",
      "epoch 9; iter: 0; batch classifier loss: 0.839957; batch adversarial loss: 0.642343\n",
      "epoch 10; iter: 0; batch classifier loss: 0.707567; batch adversarial loss: 0.589912\n",
      "epoch 11; iter: 0; batch classifier loss: 0.687324; batch adversarial loss: 0.616190\n",
      "epoch 12; iter: 0; batch classifier loss: 0.560461; batch adversarial loss: 0.580727\n",
      "epoch 13; iter: 0; batch classifier loss: 0.554026; batch adversarial loss: 0.595787\n",
      "epoch 14; iter: 0; batch classifier loss: 0.528868; batch adversarial loss: 0.571148\n",
      "epoch 15; iter: 0; batch classifier loss: 0.565121; batch adversarial loss: 0.628235\n",
      "epoch 16; iter: 0; batch classifier loss: 0.492717; batch adversarial loss: 0.577407\n",
      "epoch 17; iter: 0; batch classifier loss: 0.527016; batch adversarial loss: 0.562373\n",
      "epoch 18; iter: 0; batch classifier loss: 0.548568; batch adversarial loss: 0.556218\n",
      "epoch 19; iter: 0; batch classifier loss: 0.516799; batch adversarial loss: 0.537997\n",
      "epoch 20; iter: 0; batch classifier loss: 0.502214; batch adversarial loss: 0.570278\n",
      "epoch 21; iter: 0; batch classifier loss: 0.523751; batch adversarial loss: 0.545604\n",
      "epoch 22; iter: 0; batch classifier loss: 0.491978; batch adversarial loss: 0.538954\n",
      "epoch 23; iter: 0; batch classifier loss: 0.420922; batch adversarial loss: 0.642847\n",
      "epoch 24; iter: 0; batch classifier loss: 0.421743; batch adversarial loss: 0.572145\n",
      "epoch 25; iter: 0; batch classifier loss: 0.428582; batch adversarial loss: 0.564588\n",
      "epoch 26; iter: 0; batch classifier loss: 0.480676; batch adversarial loss: 0.505439\n",
      "epoch 27; iter: 0; batch classifier loss: 0.484677; batch adversarial loss: 0.606630\n",
      "epoch 28; iter: 0; batch classifier loss: 0.510442; batch adversarial loss: 0.538462\n",
      "epoch 29; iter: 0; batch classifier loss: 0.471746; batch adversarial loss: 0.529701\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30; iter: 0; batch classifier loss: 0.461553; batch adversarial loss: 0.493081\n",
      "epoch 31; iter: 0; batch classifier loss: 0.462756; batch adversarial loss: 0.531666\n",
      "epoch 32; iter: 0; batch classifier loss: 0.478182; batch adversarial loss: 0.555280\n",
      "epoch 33; iter: 0; batch classifier loss: 0.476711; batch adversarial loss: 0.592593\n",
      "epoch 34; iter: 0; batch classifier loss: 0.534233; batch adversarial loss: 0.501348\n",
      "epoch 35; iter: 0; batch classifier loss: 0.476919; batch adversarial loss: 0.498988\n",
      "epoch 36; iter: 0; batch classifier loss: 0.406584; batch adversarial loss: 0.525427\n",
      "epoch 37; iter: 0; batch classifier loss: 0.364066; batch adversarial loss: 0.556511\n",
      "epoch 38; iter: 0; batch classifier loss: 0.459980; batch adversarial loss: 0.553778\n",
      "epoch 39; iter: 0; batch classifier loss: 0.408418; batch adversarial loss: 0.614052\n",
      "epoch 40; iter: 0; batch classifier loss: 0.426013; batch adversarial loss: 0.594989\n",
      "epoch 41; iter: 0; batch classifier loss: 0.441009; batch adversarial loss: 0.587298\n",
      "epoch 42; iter: 0; batch classifier loss: 0.339381; batch adversarial loss: 0.475912\n",
      "epoch 43; iter: 0; batch classifier loss: 0.490251; batch adversarial loss: 0.568954\n",
      "epoch 44; iter: 0; batch classifier loss: 0.406276; batch adversarial loss: 0.538247\n",
      "epoch 45; iter: 0; batch classifier loss: 0.463315; batch adversarial loss: 0.553500\n",
      "epoch 46; iter: 0; batch classifier loss: 0.368040; batch adversarial loss: 0.602422\n",
      "epoch 47; iter: 0; batch classifier loss: 0.325665; batch adversarial loss: 0.621451\n",
      "epoch 48; iter: 0; batch classifier loss: 0.447651; batch adversarial loss: 0.527782\n",
      "epoch 49; iter: 0; batch classifier loss: 0.436114; batch adversarial loss: 0.535618\n",
      "epoch 50; iter: 0; batch classifier loss: 0.422405; batch adversarial loss: 0.512870\n",
      "epoch 51; iter: 0; batch classifier loss: 0.379191; batch adversarial loss: 0.539235\n",
      "epoch 52; iter: 0; batch classifier loss: 0.367244; batch adversarial loss: 0.523625\n",
      "epoch 53; iter: 0; batch classifier loss: 0.421318; batch adversarial loss: 0.586983\n",
      "epoch 54; iter: 0; batch classifier loss: 0.431157; batch adversarial loss: 0.571789\n",
      "epoch 55; iter: 0; batch classifier loss: 0.430998; batch adversarial loss: 0.555761\n",
      "epoch 56; iter: 0; batch classifier loss: 0.361549; batch adversarial loss: 0.529754\n",
      "epoch 57; iter: 0; batch classifier loss: 0.357240; batch adversarial loss: 0.533185\n",
      "epoch 58; iter: 0; batch classifier loss: 0.468745; batch adversarial loss: 0.528380\n",
      "epoch 59; iter: 0; batch classifier loss: 0.331333; batch adversarial loss: 0.585589\n",
      "epoch 60; iter: 0; batch classifier loss: 0.430998; batch adversarial loss: 0.554357\n",
      "epoch 61; iter: 0; batch classifier loss: 0.414921; batch adversarial loss: 0.545155\n",
      "epoch 62; iter: 0; batch classifier loss: 0.395857; batch adversarial loss: 0.535520\n",
      "epoch 63; iter: 0; batch classifier loss: 0.343444; batch adversarial loss: 0.618640\n",
      "epoch 64; iter: 0; batch classifier loss: 0.444550; batch adversarial loss: 0.541207\n",
      "epoch 65; iter: 0; batch classifier loss: 0.348383; batch adversarial loss: 0.591579\n",
      "epoch 66; iter: 0; batch classifier loss: 0.323391; batch adversarial loss: 0.489373\n",
      "epoch 67; iter: 0; batch classifier loss: 0.411705; batch adversarial loss: 0.470553\n",
      "epoch 68; iter: 0; batch classifier loss: 0.390849; batch adversarial loss: 0.528183\n",
      "epoch 69; iter: 0; batch classifier loss: 0.386804; batch adversarial loss: 0.477707\n",
      "epoch 70; iter: 0; batch classifier loss: 0.332713; batch adversarial loss: 0.515394\n",
      "epoch 71; iter: 0; batch classifier loss: 0.427322; batch adversarial loss: 0.551668\n",
      "epoch 72; iter: 0; batch classifier loss: 0.327764; batch adversarial loss: 0.534242\n",
      "epoch 73; iter: 0; batch classifier loss: 0.421838; batch adversarial loss: 0.542305\n",
      "epoch 74; iter: 0; batch classifier loss: 0.306821; batch adversarial loss: 0.487583\n",
      "epoch 75; iter: 0; batch classifier loss: 0.335259; batch adversarial loss: 0.564940\n",
      "epoch 76; iter: 0; batch classifier loss: 0.409218; batch adversarial loss: 0.591041\n",
      "epoch 77; iter: 0; batch classifier loss: 0.427891; batch adversarial loss: 0.636978\n",
      "epoch 78; iter: 0; batch classifier loss: 0.400832; batch adversarial loss: 0.482689\n",
      "epoch 79; iter: 0; batch classifier loss: 0.354677; batch adversarial loss: 0.581059\n",
      "epoch 80; iter: 0; batch classifier loss: 0.426859; batch adversarial loss: 0.481145\n",
      "epoch 81; iter: 0; batch classifier loss: 0.448006; batch adversarial loss: 0.462449\n",
      "epoch 82; iter: 0; batch classifier loss: 0.418175; batch adversarial loss: 0.582092\n",
      "epoch 83; iter: 0; batch classifier loss: 0.367807; batch adversarial loss: 0.608449\n",
      "epoch 84; iter: 0; batch classifier loss: 0.340305; batch adversarial loss: 0.526811\n",
      "epoch 85; iter: 0; batch classifier loss: 0.345976; batch adversarial loss: 0.535392\n",
      "epoch 86; iter: 0; batch classifier loss: 0.367301; batch adversarial loss: 0.608242\n",
      "epoch 87; iter: 0; batch classifier loss: 0.339591; batch adversarial loss: 0.580869\n",
      "epoch 88; iter: 0; batch classifier loss: 0.376030; batch adversarial loss: 0.489753\n",
      "epoch 89; iter: 0; batch classifier loss: 0.403367; batch adversarial loss: 0.581303\n",
      "epoch 90; iter: 0; batch classifier loss: 0.356152; batch adversarial loss: 0.525152\n",
      "epoch 91; iter: 0; batch classifier loss: 0.325087; batch adversarial loss: 0.635929\n",
      "epoch 92; iter: 0; batch classifier loss: 0.409740; batch adversarial loss: 0.535630\n",
      "epoch 93; iter: 0; batch classifier loss: 0.438221; batch adversarial loss: 0.608531\n",
      "epoch 94; iter: 0; batch classifier loss: 0.384451; batch adversarial loss: 0.507350\n",
      "epoch 95; iter: 0; batch classifier loss: 0.381005; batch adversarial loss: 0.618155\n",
      "epoch 96; iter: 0; batch classifier loss: 0.383701; batch adversarial loss: 0.553049\n",
      "epoch 97; iter: 0; batch classifier loss: 0.429877; batch adversarial loss: 0.636207\n",
      "epoch 98; iter: 0; batch classifier loss: 0.322326; batch adversarial loss: 0.636379\n",
      "epoch 99; iter: 0; batch classifier loss: 0.357406; batch adversarial loss: 0.571455\n",
      "epoch 100; iter: 0; batch classifier loss: 0.365539; batch adversarial loss: 0.507957\n",
      "epoch 101; iter: 0; batch classifier loss: 0.403499; batch adversarial loss: 0.498643\n",
      "epoch 102; iter: 0; batch classifier loss: 0.393558; batch adversarial loss: 0.498454\n",
      "epoch 103; iter: 0; batch classifier loss: 0.419004; batch adversarial loss: 0.516726\n",
      "epoch 104; iter: 0; batch classifier loss: 0.307546; batch adversarial loss: 0.571295\n",
      "epoch 105; iter: 0; batch classifier loss: 0.368089; batch adversarial loss: 0.498303\n",
      "epoch 106; iter: 0; batch classifier loss: 0.270608; batch adversarial loss: 0.433738\n",
      "epoch 107; iter: 0; batch classifier loss: 0.327008; batch adversarial loss: 0.563757\n",
      "epoch 108; iter: 0; batch classifier loss: 0.355773; batch adversarial loss: 0.480296\n",
      "epoch 109; iter: 0; batch classifier loss: 0.346502; batch adversarial loss: 0.545291\n",
      "epoch 110; iter: 0; batch classifier loss: 0.333692; batch adversarial loss: 0.627603\n",
      "epoch 111; iter: 0; batch classifier loss: 0.372027; batch adversarial loss: 0.581660\n",
      "epoch 112; iter: 0; batch classifier loss: 0.305425; batch adversarial loss: 0.563338\n",
      "epoch 113; iter: 0; batch classifier loss: 0.415564; batch adversarial loss: 0.571891\n",
      "epoch 114; iter: 0; batch classifier loss: 0.390028; batch adversarial loss: 0.516496\n",
      "epoch 115; iter: 0; batch classifier loss: 0.284092; batch adversarial loss: 0.562227\n",
      "epoch 116; iter: 0; batch classifier loss: 0.300186; batch adversarial loss: 0.627569\n",
      "epoch 117; iter: 0; batch classifier loss: 0.312818; batch adversarial loss: 0.535131\n",
      "epoch 118; iter: 0; batch classifier loss: 0.245202; batch adversarial loss: 0.554747\n",
      "epoch 119; iter: 0; batch classifier loss: 0.305643; batch adversarial loss: 0.554025\n",
      "epoch 120; iter: 0; batch classifier loss: 0.378794; batch adversarial loss: 0.507611\n",
      "epoch 121; iter: 0; batch classifier loss: 0.365387; batch adversarial loss: 0.479600\n",
      "epoch 122; iter: 0; batch classifier loss: 0.379176; batch adversarial loss: 0.489236\n",
      "epoch 123; iter: 0; batch classifier loss: 0.384872; batch adversarial loss: 0.489420\n",
      "epoch 124; iter: 0; batch classifier loss: 0.288437; batch adversarial loss: 0.479865\n",
      "epoch 125; iter: 0; batch classifier loss: 0.389143; batch adversarial loss: 0.508889\n",
      "epoch 126; iter: 0; batch classifier loss: 0.291027; batch adversarial loss: 0.553733\n",
      "epoch 127; iter: 0; batch classifier loss: 0.323391; batch adversarial loss: 0.590205\n",
      "epoch 128; iter: 0; batch classifier loss: 0.254555; batch adversarial loss: 0.526335\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 129; iter: 0; batch classifier loss: 0.360368; batch adversarial loss: 0.684013\n",
      "epoch 130; iter: 0; batch classifier loss: 0.290103; batch adversarial loss: 0.563181\n",
      "epoch 131; iter: 0; batch classifier loss: 0.342128; batch adversarial loss: 0.498599\n",
      "epoch 132; iter: 0; batch classifier loss: 0.306024; batch adversarial loss: 0.452770\n",
      "epoch 133; iter: 0; batch classifier loss: 0.285029; batch adversarial loss: 0.599372\n",
      "epoch 134; iter: 0; batch classifier loss: 0.340832; batch adversarial loss: 0.581862\n",
      "epoch 135; iter: 0; batch classifier loss: 0.320410; batch adversarial loss: 0.552846\n",
      "epoch 136; iter: 0; batch classifier loss: 0.318644; batch adversarial loss: 0.554023\n",
      "epoch 137; iter: 0; batch classifier loss: 0.322133; batch adversarial loss: 0.563852\n",
      "epoch 138; iter: 0; batch classifier loss: 0.342064; batch adversarial loss: 0.554133\n",
      "epoch 139; iter: 0; batch classifier loss: 0.236659; batch adversarial loss: 0.636142\n",
      "epoch 140; iter: 0; batch classifier loss: 0.328860; batch adversarial loss: 0.525998\n",
      "epoch 141; iter: 0; batch classifier loss: 0.335191; batch adversarial loss: 0.544482\n",
      "epoch 142; iter: 0; batch classifier loss: 0.275970; batch adversarial loss: 0.498554\n",
      "epoch 143; iter: 0; batch classifier loss: 0.385657; batch adversarial loss: 0.526282\n",
      "epoch 144; iter: 0; batch classifier loss: 0.311350; batch adversarial loss: 0.443150\n",
      "epoch 145; iter: 0; batch classifier loss: 0.316230; batch adversarial loss: 0.497961\n",
      "epoch 146; iter: 0; batch classifier loss: 0.431626; batch adversarial loss: 0.627036\n",
      "epoch 147; iter: 0; batch classifier loss: 0.394893; batch adversarial loss: 0.590129\n",
      "epoch 148; iter: 0; batch classifier loss: 0.314362; batch adversarial loss: 0.525815\n",
      "epoch 149; iter: 0; batch classifier loss: 0.341303; batch adversarial loss: 0.563303\n",
      "epoch 150; iter: 0; batch classifier loss: 0.341428; batch adversarial loss: 0.562577\n",
      "epoch 151; iter: 0; batch classifier loss: 0.357114; batch adversarial loss: 0.600580\n",
      "epoch 152; iter: 0; batch classifier loss: 0.289679; batch adversarial loss: 0.525218\n",
      "epoch 153; iter: 0; batch classifier loss: 0.308201; batch adversarial loss: 0.534759\n",
      "epoch 154; iter: 0; batch classifier loss: 0.309348; batch adversarial loss: 0.526528\n",
      "epoch 155; iter: 0; batch classifier loss: 0.284503; batch adversarial loss: 0.471235\n",
      "epoch 156; iter: 0; batch classifier loss: 0.392972; batch adversarial loss: 0.534151\n",
      "epoch 157; iter: 0; batch classifier loss: 0.308469; batch adversarial loss: 0.526860\n",
      "epoch 158; iter: 0; batch classifier loss: 0.302709; batch adversarial loss: 0.571044\n",
      "epoch 159; iter: 0; batch classifier loss: 0.348234; batch adversarial loss: 0.544556\n",
      "epoch 160; iter: 0; batch classifier loss: 0.331678; batch adversarial loss: 0.535173\n",
      "epoch 161; iter: 0; batch classifier loss: 0.300636; batch adversarial loss: 0.489287\n",
      "epoch 162; iter: 0; batch classifier loss: 0.306911; batch adversarial loss: 0.572585\n",
      "epoch 163; iter: 0; batch classifier loss: 0.258846; batch adversarial loss: 0.489339\n",
      "epoch 164; iter: 0; batch classifier loss: 0.320740; batch adversarial loss: 0.507468\n",
      "epoch 165; iter: 0; batch classifier loss: 0.342710; batch adversarial loss: 0.489195\n",
      "epoch 166; iter: 0; batch classifier loss: 0.335580; batch adversarial loss: 0.571573\n",
      "epoch 167; iter: 0; batch classifier loss: 0.296719; batch adversarial loss: 0.563189\n",
      "epoch 168; iter: 0; batch classifier loss: 0.358379; batch adversarial loss: 0.544671\n",
      "epoch 169; iter: 0; batch classifier loss: 0.301428; batch adversarial loss: 0.435197\n",
      "epoch 170; iter: 0; batch classifier loss: 0.344980; batch adversarial loss: 0.544884\n",
      "epoch 171; iter: 0; batch classifier loss: 0.295225; batch adversarial loss: 0.480738\n",
      "epoch 172; iter: 0; batch classifier loss: 0.317325; batch adversarial loss: 0.563213\n",
      "epoch 173; iter: 0; batch classifier loss: 0.280682; batch adversarial loss: 0.544011\n",
      "epoch 174; iter: 0; batch classifier loss: 0.293626; batch adversarial loss: 0.626845\n",
      "epoch 175; iter: 0; batch classifier loss: 0.276119; batch adversarial loss: 0.597302\n",
      "epoch 176; iter: 0; batch classifier loss: 0.311863; batch adversarial loss: 0.562548\n",
      "epoch 177; iter: 0; batch classifier loss: 0.315192; batch adversarial loss: 0.599050\n",
      "epoch 178; iter: 0; batch classifier loss: 0.265966; batch adversarial loss: 0.571807\n",
      "epoch 179; iter: 0; batch classifier loss: 0.338324; batch adversarial loss: 0.636442\n",
      "epoch 180; iter: 0; batch classifier loss: 0.303940; batch adversarial loss: 0.607306\n",
      "epoch 181; iter: 0; batch classifier loss: 0.334510; batch adversarial loss: 0.553866\n",
      "epoch 182; iter: 0; batch classifier loss: 0.274874; batch adversarial loss: 0.525898\n",
      "epoch 183; iter: 0; batch classifier loss: 0.277058; batch adversarial loss: 0.609037\n",
      "epoch 184; iter: 0; batch classifier loss: 0.339551; batch adversarial loss: 0.599442\n",
      "epoch 185; iter: 0; batch classifier loss: 0.280102; batch adversarial loss: 0.609532\n",
      "epoch 186; iter: 0; batch classifier loss: 0.354189; batch adversarial loss: 0.526442\n",
      "epoch 187; iter: 0; batch classifier loss: 0.263140; batch adversarial loss: 0.525846\n",
      "epoch 188; iter: 0; batch classifier loss: 0.353329; batch adversarial loss: 0.562595\n",
      "epoch 189; iter: 0; batch classifier loss: 0.332631; batch adversarial loss: 0.543503\n",
      "epoch 190; iter: 0; batch classifier loss: 0.223660; batch adversarial loss: 0.498682\n",
      "epoch 191; iter: 0; batch classifier loss: 0.281908; batch adversarial loss: 0.525780\n",
      "epoch 192; iter: 0; batch classifier loss: 0.287550; batch adversarial loss: 0.535927\n",
      "epoch 193; iter: 0; batch classifier loss: 0.297848; batch adversarial loss: 0.635440\n",
      "epoch 194; iter: 0; batch classifier loss: 0.334093; batch adversarial loss: 0.617749\n",
      "epoch 195; iter: 0; batch classifier loss: 0.280483; batch adversarial loss: 0.562805\n",
      "epoch 196; iter: 0; batch classifier loss: 0.306820; batch adversarial loss: 0.571885\n",
      "epoch 197; iter: 0; batch classifier loss: 0.329252; batch adversarial loss: 0.479856\n",
      "epoch 198; iter: 0; batch classifier loss: 0.234934; batch adversarial loss: 0.545470\n",
      "epoch 199; iter: 0; batch classifier loss: 0.301489; batch adversarial loss: 0.507535\n",
      "epoch 0; iter: 0; batch classifier loss: 0.642315; batch adversarial loss: 0.785488\n",
      "epoch 1; iter: 0; batch classifier loss: 0.735718; batch adversarial loss: 0.985485\n",
      "epoch 2; iter: 0; batch classifier loss: 0.776717; batch adversarial loss: 0.904584\n",
      "epoch 3; iter: 0; batch classifier loss: 0.773150; batch adversarial loss: 0.860885\n",
      "epoch 4; iter: 0; batch classifier loss: 0.644547; batch adversarial loss: 0.798203\n",
      "epoch 5; iter: 0; batch classifier loss: 0.577378; batch adversarial loss: 0.728838\n",
      "epoch 6; iter: 0; batch classifier loss: 0.529719; batch adversarial loss: 0.658012\n",
      "epoch 7; iter: 0; batch classifier loss: 0.501493; batch adversarial loss: 0.628643\n",
      "epoch 8; iter: 0; batch classifier loss: 0.582953; batch adversarial loss: 0.605002\n",
      "epoch 9; iter: 0; batch classifier loss: 0.602097; batch adversarial loss: 0.607758\n",
      "epoch 10; iter: 0; batch classifier loss: 0.631262; batch adversarial loss: 0.608399\n",
      "epoch 11; iter: 0; batch classifier loss: 0.528546; batch adversarial loss: 0.607445\n",
      "epoch 12; iter: 0; batch classifier loss: 0.549479; batch adversarial loss: 0.582108\n",
      "epoch 13; iter: 0; batch classifier loss: 0.522768; batch adversarial loss: 0.572346\n",
      "epoch 14; iter: 0; batch classifier loss: 0.572223; batch adversarial loss: 0.577902\n",
      "epoch 15; iter: 0; batch classifier loss: 0.411424; batch adversarial loss: 0.537447\n",
      "epoch 16; iter: 0; batch classifier loss: 0.453208; batch adversarial loss: 0.552855\n",
      "epoch 17; iter: 0; batch classifier loss: 0.579072; batch adversarial loss: 0.562450\n",
      "epoch 18; iter: 0; batch classifier loss: 0.504838; batch adversarial loss: 0.538510\n",
      "epoch 19; iter: 0; batch classifier loss: 0.533413; batch adversarial loss: 0.596084\n",
      "epoch 20; iter: 0; batch classifier loss: 0.485038; batch adversarial loss: 0.543093\n",
      "epoch 21; iter: 0; batch classifier loss: 0.408368; batch adversarial loss: 0.543517\n",
      "epoch 22; iter: 0; batch classifier loss: 0.446059; batch adversarial loss: 0.526849\n",
      "epoch 23; iter: 0; batch classifier loss: 0.486837; batch adversarial loss: 0.559378\n",
      "epoch 24; iter: 0; batch classifier loss: 0.475525; batch adversarial loss: 0.609802\n",
      "epoch 25; iter: 0; batch classifier loss: 0.492486; batch adversarial loss: 0.532601\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 26; iter: 0; batch classifier loss: 0.525871; batch adversarial loss: 0.645565\n",
      "epoch 27; iter: 0; batch classifier loss: 0.501845; batch adversarial loss: 0.464941\n",
      "epoch 28; iter: 0; batch classifier loss: 0.464775; batch adversarial loss: 0.544582\n",
      "epoch 29; iter: 0; batch classifier loss: 0.462599; batch adversarial loss: 0.564543\n",
      "epoch 30; iter: 0; batch classifier loss: 0.482489; batch adversarial loss: 0.530501\n",
      "epoch 31; iter: 0; batch classifier loss: 0.438951; batch adversarial loss: 0.584022\n",
      "epoch 32; iter: 0; batch classifier loss: 0.429585; batch adversarial loss: 0.427979\n",
      "epoch 33; iter: 0; batch classifier loss: 0.499175; batch adversarial loss: 0.484984\n",
      "epoch 34; iter: 0; batch classifier loss: 0.466398; batch adversarial loss: 0.512348\n",
      "epoch 35; iter: 0; batch classifier loss: 0.365018; batch adversarial loss: 0.520491\n",
      "epoch 36; iter: 0; batch classifier loss: 0.441635; batch adversarial loss: 0.616890\n",
      "epoch 37; iter: 0; batch classifier loss: 0.455071; batch adversarial loss: 0.519818\n",
      "epoch 38; iter: 0; batch classifier loss: 0.484164; batch adversarial loss: 0.528075\n",
      "epoch 39; iter: 0; batch classifier loss: 0.442819; batch adversarial loss: 0.536651\n",
      "epoch 40; iter: 0; batch classifier loss: 0.414238; batch adversarial loss: 0.527965\n",
      "epoch 41; iter: 0; batch classifier loss: 0.371341; batch adversarial loss: 0.510268\n",
      "epoch 42; iter: 0; batch classifier loss: 0.376000; batch adversarial loss: 0.580481\n",
      "epoch 43; iter: 0; batch classifier loss: 0.460929; batch adversarial loss: 0.544739\n",
      "epoch 44; iter: 0; batch classifier loss: 0.414242; batch adversarial loss: 0.482318\n",
      "epoch 45; iter: 0; batch classifier loss: 0.383544; batch adversarial loss: 0.526416\n",
      "epoch 46; iter: 0; batch classifier loss: 0.416809; batch adversarial loss: 0.589421\n",
      "epoch 47; iter: 0; batch classifier loss: 0.387762; batch adversarial loss: 0.545803\n",
      "epoch 48; iter: 0; batch classifier loss: 0.419677; batch adversarial loss: 0.535729\n",
      "epoch 49; iter: 0; batch classifier loss: 0.394905; batch adversarial loss: 0.471724\n",
      "epoch 50; iter: 0; batch classifier loss: 0.491520; batch adversarial loss: 0.561152\n",
      "epoch 51; iter: 0; batch classifier loss: 0.440891; batch adversarial loss: 0.515428\n",
      "epoch 52; iter: 0; batch classifier loss: 0.383003; batch adversarial loss: 0.558439\n",
      "epoch 53; iter: 0; batch classifier loss: 0.330756; batch adversarial loss: 0.597054\n",
      "epoch 54; iter: 0; batch classifier loss: 0.366621; batch adversarial loss: 0.565061\n",
      "epoch 55; iter: 0; batch classifier loss: 0.369582; batch adversarial loss: 0.590054\n",
      "epoch 56; iter: 0; batch classifier loss: 0.353883; batch adversarial loss: 0.563666\n",
      "epoch 57; iter: 0; batch classifier loss: 0.363752; batch adversarial loss: 0.568466\n",
      "epoch 58; iter: 0; batch classifier loss: 0.361889; batch adversarial loss: 0.570869\n",
      "epoch 59; iter: 0; batch classifier loss: 0.391403; batch adversarial loss: 0.526508\n",
      "epoch 60; iter: 0; batch classifier loss: 0.487202; batch adversarial loss: 0.599654\n",
      "epoch 61; iter: 0; batch classifier loss: 0.407411; batch adversarial loss: 0.582967\n",
      "epoch 62; iter: 0; batch classifier loss: 0.407270; batch adversarial loss: 0.522003\n",
      "epoch 63; iter: 0; batch classifier loss: 0.400191; batch adversarial loss: 0.505906\n",
      "epoch 64; iter: 0; batch classifier loss: 0.408338; batch adversarial loss: 0.560542\n",
      "epoch 65; iter: 0; batch classifier loss: 0.371589; batch adversarial loss: 0.516295\n",
      "epoch 66; iter: 0; batch classifier loss: 0.449447; batch adversarial loss: 0.516089\n",
      "epoch 67; iter: 0; batch classifier loss: 0.411027; batch adversarial loss: 0.517977\n",
      "epoch 68; iter: 0; batch classifier loss: 0.401264; batch adversarial loss: 0.589826\n",
      "epoch 69; iter: 0; batch classifier loss: 0.396343; batch adversarial loss: 0.565280\n",
      "epoch 70; iter: 0; batch classifier loss: 0.350990; batch adversarial loss: 0.472125\n",
      "epoch 71; iter: 0; batch classifier loss: 0.418352; batch adversarial loss: 0.541806\n",
      "epoch 72; iter: 0; batch classifier loss: 0.440623; batch adversarial loss: 0.517310\n",
      "epoch 73; iter: 0; batch classifier loss: 0.431244; batch adversarial loss: 0.516313\n",
      "epoch 74; iter: 0; batch classifier loss: 0.387964; batch adversarial loss: 0.535983\n",
      "epoch 75; iter: 0; batch classifier loss: 0.451936; batch adversarial loss: 0.610703\n",
      "epoch 76; iter: 0; batch classifier loss: 0.434894; batch adversarial loss: 0.542920\n",
      "epoch 77; iter: 0; batch classifier loss: 0.304334; batch adversarial loss: 0.590110\n",
      "epoch 78; iter: 0; batch classifier loss: 0.337558; batch adversarial loss: 0.562742\n",
      "epoch 79; iter: 0; batch classifier loss: 0.434136; batch adversarial loss: 0.505220\n",
      "epoch 80; iter: 0; batch classifier loss: 0.458411; batch adversarial loss: 0.626793\n",
      "epoch 81; iter: 0; batch classifier loss: 0.313682; batch adversarial loss: 0.599051\n",
      "epoch 82; iter: 0; batch classifier loss: 0.389924; batch adversarial loss: 0.597167\n",
      "epoch 83; iter: 0; batch classifier loss: 0.350046; batch adversarial loss: 0.488770\n",
      "epoch 84; iter: 0; batch classifier loss: 0.333471; batch adversarial loss: 0.520716\n",
      "epoch 85; iter: 0; batch classifier loss: 0.418034; batch adversarial loss: 0.489482\n",
      "epoch 86; iter: 0; batch classifier loss: 0.381201; batch adversarial loss: 0.546836\n",
      "epoch 87; iter: 0; batch classifier loss: 0.337019; batch adversarial loss: 0.598567\n",
      "epoch 88; iter: 0; batch classifier loss: 0.421251; batch adversarial loss: 0.530218\n",
      "epoch 89; iter: 0; batch classifier loss: 0.425140; batch adversarial loss: 0.584186\n",
      "epoch 90; iter: 0; batch classifier loss: 0.355240; batch adversarial loss: 0.488489\n",
      "epoch 91; iter: 0; batch classifier loss: 0.404098; batch adversarial loss: 0.614267\n",
      "epoch 92; iter: 0; batch classifier loss: 0.483022; batch adversarial loss: 0.608482\n",
      "epoch 93; iter: 0; batch classifier loss: 0.401632; batch adversarial loss: 0.546484\n",
      "epoch 94; iter: 0; batch classifier loss: 0.358177; batch adversarial loss: 0.532927\n",
      "epoch 95; iter: 0; batch classifier loss: 0.394576; batch adversarial loss: 0.527098\n",
      "epoch 96; iter: 0; batch classifier loss: 0.332641; batch adversarial loss: 0.490536\n",
      "epoch 97; iter: 0; batch classifier loss: 0.404928; batch adversarial loss: 0.573776\n",
      "epoch 98; iter: 0; batch classifier loss: 0.345436; batch adversarial loss: 0.556940\n",
      "epoch 99; iter: 0; batch classifier loss: 0.423199; batch adversarial loss: 0.496637\n",
      "epoch 100; iter: 0; batch classifier loss: 0.402540; batch adversarial loss: 0.571678\n",
      "epoch 101; iter: 0; batch classifier loss: 0.385035; batch adversarial loss: 0.579852\n",
      "epoch 102; iter: 0; batch classifier loss: 0.431256; batch adversarial loss: 0.544750\n",
      "epoch 103; iter: 0; batch classifier loss: 0.374692; batch adversarial loss: 0.587086\n",
      "epoch 104; iter: 0; batch classifier loss: 0.421819; batch adversarial loss: 0.497576\n",
      "epoch 105; iter: 0; batch classifier loss: 0.369904; batch adversarial loss: 0.589046\n",
      "epoch 106; iter: 0; batch classifier loss: 0.381619; batch adversarial loss: 0.516686\n",
      "epoch 107; iter: 0; batch classifier loss: 0.347684; batch adversarial loss: 0.580535\n",
      "epoch 108; iter: 0; batch classifier loss: 0.355052; batch adversarial loss: 0.533152\n",
      "epoch 109; iter: 0; batch classifier loss: 0.386144; batch adversarial loss: 0.553270\n",
      "epoch 110; iter: 0; batch classifier loss: 0.326897; batch adversarial loss: 0.498108\n",
      "epoch 111; iter: 0; batch classifier loss: 0.363724; batch adversarial loss: 0.537059\n",
      "epoch 112; iter: 0; batch classifier loss: 0.350082; batch adversarial loss: 0.535267\n",
      "epoch 113; iter: 0; batch classifier loss: 0.360829; batch adversarial loss: 0.573422\n",
      "epoch 114; iter: 0; batch classifier loss: 0.401336; batch adversarial loss: 0.526924\n",
      "epoch 115; iter: 0; batch classifier loss: 0.413700; batch adversarial loss: 0.514452\n",
      "epoch 116; iter: 0; batch classifier loss: 0.455164; batch adversarial loss: 0.590473\n",
      "epoch 117; iter: 0; batch classifier loss: 0.314977; batch adversarial loss: 0.571216\n",
      "epoch 118; iter: 0; batch classifier loss: 0.365925; batch adversarial loss: 0.616603\n",
      "epoch 119; iter: 0; batch classifier loss: 0.394735; batch adversarial loss: 0.509154\n",
      "epoch 120; iter: 0; batch classifier loss: 0.311417; batch adversarial loss: 0.573639\n",
      "epoch 121; iter: 0; batch classifier loss: 0.326429; batch adversarial loss: 0.510622\n",
      "epoch 122; iter: 0; batch classifier loss: 0.411377; batch adversarial loss: 0.554459\n",
      "epoch 123; iter: 0; batch classifier loss: 0.329154; batch adversarial loss: 0.510382\n",
      "epoch 124; iter: 0; batch classifier loss: 0.459106; batch adversarial loss: 0.572059\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 125; iter: 0; batch classifier loss: 0.326455; batch adversarial loss: 0.634543\n",
      "epoch 126; iter: 0; batch classifier loss: 0.319500; batch adversarial loss: 0.517213\n",
      "epoch 127; iter: 0; batch classifier loss: 0.362650; batch adversarial loss: 0.571579\n",
      "epoch 128; iter: 0; batch classifier loss: 0.397880; batch adversarial loss: 0.561897\n",
      "epoch 129; iter: 0; batch classifier loss: 0.344972; batch adversarial loss: 0.562649\n",
      "epoch 130; iter: 0; batch classifier loss: 0.353119; batch adversarial loss: 0.566803\n",
      "epoch 131; iter: 0; batch classifier loss: 0.360312; batch adversarial loss: 0.542588\n",
      "epoch 132; iter: 0; batch classifier loss: 0.429506; batch adversarial loss: 0.562709\n",
      "epoch 133; iter: 0; batch classifier loss: 0.335999; batch adversarial loss: 0.547411\n",
      "epoch 134; iter: 0; batch classifier loss: 0.340376; batch adversarial loss: 0.591773\n",
      "epoch 135; iter: 0; batch classifier loss: 0.404747; batch adversarial loss: 0.534347\n",
      "epoch 136; iter: 0; batch classifier loss: 0.403558; batch adversarial loss: 0.571473\n",
      "epoch 137; iter: 0; batch classifier loss: 0.374227; batch adversarial loss: 0.590520\n",
      "epoch 138; iter: 0; batch classifier loss: 0.309670; batch adversarial loss: 0.585236\n",
      "epoch 139; iter: 0; batch classifier loss: 0.336242; batch adversarial loss: 0.582068\n",
      "epoch 140; iter: 0; batch classifier loss: 0.309703; batch adversarial loss: 0.654562\n",
      "epoch 141; iter: 0; batch classifier loss: 0.400873; batch adversarial loss: 0.562938\n",
      "epoch 142; iter: 0; batch classifier loss: 0.314482; batch adversarial loss: 0.554347\n",
      "epoch 143; iter: 0; batch classifier loss: 0.326871; batch adversarial loss: 0.529989\n",
      "epoch 144; iter: 0; batch classifier loss: 0.356694; batch adversarial loss: 0.571445\n",
      "epoch 145; iter: 0; batch classifier loss: 0.378738; batch adversarial loss: 0.579357\n",
      "epoch 146; iter: 0; batch classifier loss: 0.332999; batch adversarial loss: 0.544186\n",
      "epoch 147; iter: 0; batch classifier loss: 0.373520; batch adversarial loss: 0.525952\n",
      "epoch 148; iter: 0; batch classifier loss: 0.417176; batch adversarial loss: 0.451234\n",
      "epoch 149; iter: 0; batch classifier loss: 0.283852; batch adversarial loss: 0.509358\n",
      "epoch 150; iter: 0; batch classifier loss: 0.300881; batch adversarial loss: 0.451413\n",
      "epoch 151; iter: 0; batch classifier loss: 0.383560; batch adversarial loss: 0.564611\n",
      "epoch 152; iter: 0; batch classifier loss: 0.449714; batch adversarial loss: 0.545037\n",
      "epoch 153; iter: 0; batch classifier loss: 0.376686; batch adversarial loss: 0.580924\n",
      "epoch 154; iter: 0; batch classifier loss: 0.417956; batch adversarial loss: 0.589810\n",
      "epoch 155; iter: 0; batch classifier loss: 0.361848; batch adversarial loss: 0.550672\n",
      "epoch 156; iter: 0; batch classifier loss: 0.302057; batch adversarial loss: 0.533733\n",
      "epoch 157; iter: 0; batch classifier loss: 0.373891; batch adversarial loss: 0.481375\n",
      "epoch 158; iter: 0; batch classifier loss: 0.394847; batch adversarial loss: 0.490155\n",
      "epoch 159; iter: 0; batch classifier loss: 0.338139; batch adversarial loss: 0.542230\n",
      "epoch 160; iter: 0; batch classifier loss: 0.282258; batch adversarial loss: 0.508297\n",
      "epoch 161; iter: 0; batch classifier loss: 0.289206; batch adversarial loss: 0.605680\n",
      "epoch 162; iter: 0; batch classifier loss: 0.292376; batch adversarial loss: 0.479702\n",
      "epoch 163; iter: 0; batch classifier loss: 0.349393; batch adversarial loss: 0.645494\n",
      "epoch 164; iter: 0; batch classifier loss: 0.354137; batch adversarial loss: 0.499833\n",
      "epoch 165; iter: 0; batch classifier loss: 0.394257; batch adversarial loss: 0.535188\n",
      "epoch 166; iter: 0; batch classifier loss: 0.444863; batch adversarial loss: 0.526115\n",
      "epoch 167; iter: 0; batch classifier loss: 0.308176; batch adversarial loss: 0.506623\n",
      "epoch 168; iter: 0; batch classifier loss: 0.393981; batch adversarial loss: 0.614474\n",
      "epoch 169; iter: 0; batch classifier loss: 0.411908; batch adversarial loss: 0.624662\n",
      "epoch 170; iter: 0; batch classifier loss: 0.347413; batch adversarial loss: 0.478943\n",
      "epoch 171; iter: 0; batch classifier loss: 0.327473; batch adversarial loss: 0.617673\n",
      "epoch 172; iter: 0; batch classifier loss: 0.266533; batch adversarial loss: 0.592948\n",
      "epoch 173; iter: 0; batch classifier loss: 0.343195; batch adversarial loss: 0.595003\n",
      "epoch 174; iter: 0; batch classifier loss: 0.213316; batch adversarial loss: 0.504161\n",
      "epoch 175; iter: 0; batch classifier loss: 0.276306; batch adversarial loss: 0.555886\n",
      "epoch 176; iter: 0; batch classifier loss: 0.304860; batch adversarial loss: 0.488120\n",
      "epoch 177; iter: 0; batch classifier loss: 0.280727; batch adversarial loss: 0.571321\n",
      "epoch 178; iter: 0; batch classifier loss: 0.271329; batch adversarial loss: 0.571439\n",
      "epoch 179; iter: 0; batch classifier loss: 0.384579; batch adversarial loss: 0.525499\n",
      "epoch 180; iter: 0; batch classifier loss: 0.333622; batch adversarial loss: 0.579026\n",
      "epoch 181; iter: 0; batch classifier loss: 0.345693; batch adversarial loss: 0.518697\n",
      "epoch 182; iter: 0; batch classifier loss: 0.297907; batch adversarial loss: 0.526118\n",
      "epoch 183; iter: 0; batch classifier loss: 0.336634; batch adversarial loss: 0.515569\n",
      "epoch 184; iter: 0; batch classifier loss: 0.300083; batch adversarial loss: 0.534404\n",
      "epoch 185; iter: 0; batch classifier loss: 0.379253; batch adversarial loss: 0.561743\n",
      "epoch 186; iter: 0; batch classifier loss: 0.283038; batch adversarial loss: 0.554525\n",
      "epoch 187; iter: 0; batch classifier loss: 0.312738; batch adversarial loss: 0.524245\n",
      "epoch 188; iter: 0; batch classifier loss: 0.329998; batch adversarial loss: 0.599396\n",
      "epoch 189; iter: 0; batch classifier loss: 0.380205; batch adversarial loss: 0.544728\n",
      "epoch 190; iter: 0; batch classifier loss: 0.282507; batch adversarial loss: 0.526004\n",
      "epoch 191; iter: 0; batch classifier loss: 0.293403; batch adversarial loss: 0.572706\n",
      "epoch 192; iter: 0; batch classifier loss: 0.332273; batch adversarial loss: 0.462222\n",
      "epoch 193; iter: 0; batch classifier loss: 0.327957; batch adversarial loss: 0.560923\n",
      "epoch 194; iter: 0; batch classifier loss: 0.362997; batch adversarial loss: 0.636520\n",
      "epoch 195; iter: 0; batch classifier loss: 0.350928; batch adversarial loss: 0.542793\n",
      "epoch 196; iter: 0; batch classifier loss: 0.329957; batch adversarial loss: 0.565310\n",
      "epoch 197; iter: 0; batch classifier loss: 0.342346; batch adversarial loss: 0.452830\n",
      "epoch 198; iter: 0; batch classifier loss: 0.300589; batch adversarial loss: 0.553915\n",
      "epoch 199; iter: 0; batch classifier loss: 0.370839; batch adversarial loss: 0.715438\n",
      "epoch 0; iter: 0; batch classifier loss: 0.710239; batch adversarial loss: 0.775744\n",
      "epoch 1; iter: 0; batch classifier loss: 0.638587; batch adversarial loss: 1.068336\n",
      "epoch 2; iter: 0; batch classifier loss: 0.642848; batch adversarial loss: 0.886414\n",
      "epoch 3; iter: 0; batch classifier loss: 0.598761; batch adversarial loss: 0.823108\n",
      "epoch 4; iter: 0; batch classifier loss: 0.543801; batch adversarial loss: 0.820331\n",
      "epoch 5; iter: 0; batch classifier loss: 0.509373; batch adversarial loss: 0.718480\n",
      "epoch 6; iter: 0; batch classifier loss: 0.547390; batch adversarial loss: 0.710365\n",
      "epoch 7; iter: 0; batch classifier loss: 0.579437; batch adversarial loss: 0.634654\n",
      "epoch 8; iter: 0; batch classifier loss: 0.552850; batch adversarial loss: 0.625396\n",
      "epoch 9; iter: 0; batch classifier loss: 0.507710; batch adversarial loss: 0.627961\n",
      "epoch 10; iter: 0; batch classifier loss: 0.531266; batch adversarial loss: 0.601062\n",
      "epoch 11; iter: 0; batch classifier loss: 0.535992; batch adversarial loss: 0.614062\n",
      "epoch 12; iter: 0; batch classifier loss: 0.504315; batch adversarial loss: 0.590591\n",
      "epoch 13; iter: 0; batch classifier loss: 0.462634; batch adversarial loss: 0.576323\n",
      "epoch 14; iter: 0; batch classifier loss: 0.502384; batch adversarial loss: 0.562122\n",
      "epoch 15; iter: 0; batch classifier loss: 0.503212; batch adversarial loss: 0.552802\n",
      "epoch 16; iter: 0; batch classifier loss: 0.545825; batch adversarial loss: 0.575258\n",
      "epoch 17; iter: 0; batch classifier loss: 0.528974; batch adversarial loss: 0.568698\n",
      "epoch 18; iter: 0; batch classifier loss: 0.478900; batch adversarial loss: 0.532220\n",
      "epoch 19; iter: 0; batch classifier loss: 0.512702; batch adversarial loss: 0.602537\n",
      "epoch 20; iter: 0; batch classifier loss: 0.493925; batch adversarial loss: 0.591604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 21; iter: 0; batch classifier loss: 0.507665; batch adversarial loss: 0.555687\n",
      "epoch 22; iter: 0; batch classifier loss: 0.451741; batch adversarial loss: 0.546878\n",
      "epoch 23; iter: 0; batch classifier loss: 0.430758; batch adversarial loss: 0.583677\n",
      "epoch 24; iter: 0; batch classifier loss: 0.508740; batch adversarial loss: 0.507460\n",
      "epoch 25; iter: 0; batch classifier loss: 0.508025; batch adversarial loss: 0.604077\n",
      "epoch 26; iter: 0; batch classifier loss: 0.478495; batch adversarial loss: 0.561677\n",
      "epoch 27; iter: 0; batch classifier loss: 0.521461; batch adversarial loss: 0.513572\n",
      "epoch 28; iter: 0; batch classifier loss: 0.445651; batch adversarial loss: 0.563655\n",
      "epoch 29; iter: 0; batch classifier loss: 0.428017; batch adversarial loss: 0.610605\n",
      "epoch 30; iter: 0; batch classifier loss: 0.439802; batch adversarial loss: 0.511506\n",
      "epoch 31; iter: 0; batch classifier loss: 0.435299; batch adversarial loss: 0.600348\n",
      "epoch 32; iter: 0; batch classifier loss: 0.491626; batch adversarial loss: 0.563019\n",
      "epoch 33; iter: 0; batch classifier loss: 0.517666; batch adversarial loss: 0.552690\n",
      "epoch 34; iter: 0; batch classifier loss: 0.450534; batch adversarial loss: 0.536280\n",
      "epoch 35; iter: 0; batch classifier loss: 0.451602; batch adversarial loss: 0.592429\n",
      "epoch 36; iter: 0; batch classifier loss: 0.501143; batch adversarial loss: 0.489538\n",
      "epoch 37; iter: 0; batch classifier loss: 0.436232; batch adversarial loss: 0.598207\n",
      "epoch 38; iter: 0; batch classifier loss: 0.453675; batch adversarial loss: 0.591248\n",
      "epoch 39; iter: 0; batch classifier loss: 0.413735; batch adversarial loss: 0.603252\n",
      "epoch 40; iter: 0; batch classifier loss: 0.409021; batch adversarial loss: 0.552325\n",
      "epoch 41; iter: 0; batch classifier loss: 0.457354; batch adversarial loss: 0.535800\n",
      "epoch 42; iter: 0; batch classifier loss: 0.392147; batch adversarial loss: 0.500983\n",
      "epoch 43; iter: 0; batch classifier loss: 0.477832; batch adversarial loss: 0.598006\n",
      "epoch 44; iter: 0; batch classifier loss: 0.451804; batch adversarial loss: 0.606000\n",
      "epoch 45; iter: 0; batch classifier loss: 0.413781; batch adversarial loss: 0.548833\n",
      "epoch 46; iter: 0; batch classifier loss: 0.593488; batch adversarial loss: 0.511045\n",
      "epoch 47; iter: 0; batch classifier loss: 0.389934; batch adversarial loss: 0.636369\n",
      "epoch 48; iter: 0; batch classifier loss: 0.529166; batch adversarial loss: 0.537737\n",
      "epoch 49; iter: 0; batch classifier loss: 0.412432; batch adversarial loss: 0.598396\n",
      "epoch 50; iter: 0; batch classifier loss: 0.534383; batch adversarial loss: 0.505472\n",
      "epoch 51; iter: 0; batch classifier loss: 0.456239; batch adversarial loss: 0.545741\n",
      "epoch 52; iter: 0; batch classifier loss: 0.433543; batch adversarial loss: 0.501507\n",
      "epoch 53; iter: 0; batch classifier loss: 0.439606; batch adversarial loss: 0.599157\n",
      "epoch 54; iter: 0; batch classifier loss: 0.473546; batch adversarial loss: 0.565536\n",
      "epoch 55; iter: 0; batch classifier loss: 0.485539; batch adversarial loss: 0.569889\n",
      "epoch 56; iter: 0; batch classifier loss: 0.422873; batch adversarial loss: 0.615270\n",
      "epoch 57; iter: 0; batch classifier loss: 0.423092; batch adversarial loss: 0.494675\n",
      "epoch 58; iter: 0; batch classifier loss: 0.486610; batch adversarial loss: 0.555499\n",
      "epoch 59; iter: 0; batch classifier loss: 0.447551; batch adversarial loss: 0.493670\n",
      "epoch 60; iter: 0; batch classifier loss: 0.352707; batch adversarial loss: 0.542853\n",
      "epoch 61; iter: 0; batch classifier loss: 0.357447; batch adversarial loss: 0.582460\n",
      "epoch 62; iter: 0; batch classifier loss: 0.416312; batch adversarial loss: 0.508041\n",
      "epoch 63; iter: 0; batch classifier loss: 0.371992; batch adversarial loss: 0.491516\n",
      "epoch 64; iter: 0; batch classifier loss: 0.387925; batch adversarial loss: 0.489073\n",
      "epoch 65; iter: 0; batch classifier loss: 0.408092; batch adversarial loss: 0.499496\n",
      "epoch 66; iter: 0; batch classifier loss: 0.354099; batch adversarial loss: 0.609067\n",
      "epoch 67; iter: 0; batch classifier loss: 0.429716; batch adversarial loss: 0.490122\n",
      "epoch 68; iter: 0; batch classifier loss: 0.436172; batch adversarial loss: 0.497533\n",
      "epoch 69; iter: 0; batch classifier loss: 0.459420; batch adversarial loss: 0.527140\n",
      "epoch 70; iter: 0; batch classifier loss: 0.339095; batch adversarial loss: 0.610336\n",
      "epoch 71; iter: 0; batch classifier loss: 0.380533; batch adversarial loss: 0.591147\n",
      "epoch 72; iter: 0; batch classifier loss: 0.515288; batch adversarial loss: 0.643476\n",
      "epoch 73; iter: 0; batch classifier loss: 0.341028; batch adversarial loss: 0.534060\n",
      "epoch 74; iter: 0; batch classifier loss: 0.420838; batch adversarial loss: 0.535645\n",
      "epoch 75; iter: 0; batch classifier loss: 0.457840; batch adversarial loss: 0.545148\n",
      "epoch 76; iter: 0; batch classifier loss: 0.441981; batch adversarial loss: 0.607414\n",
      "epoch 77; iter: 0; batch classifier loss: 0.360890; batch adversarial loss: 0.516727\n",
      "epoch 78; iter: 0; batch classifier loss: 0.444025; batch adversarial loss: 0.500187\n",
      "epoch 79; iter: 0; batch classifier loss: 0.361527; batch adversarial loss: 0.516670\n",
      "epoch 80; iter: 0; batch classifier loss: 0.358861; batch adversarial loss: 0.554280\n",
      "epoch 81; iter: 0; batch classifier loss: 0.377427; batch adversarial loss: 0.498594\n",
      "epoch 82; iter: 0; batch classifier loss: 0.356210; batch adversarial loss: 0.519172\n",
      "epoch 83; iter: 0; batch classifier loss: 0.419681; batch adversarial loss: 0.608263\n",
      "epoch 84; iter: 0; batch classifier loss: 0.386522; batch adversarial loss: 0.580838\n",
      "epoch 85; iter: 0; batch classifier loss: 0.415641; batch adversarial loss: 0.616007\n",
      "epoch 86; iter: 0; batch classifier loss: 0.384545; batch adversarial loss: 0.499053\n",
      "epoch 87; iter: 0; batch classifier loss: 0.420614; batch adversarial loss: 0.535641\n",
      "epoch 88; iter: 0; batch classifier loss: 0.399673; batch adversarial loss: 0.589950\n",
      "epoch 89; iter: 0; batch classifier loss: 0.397278; batch adversarial loss: 0.472571\n",
      "epoch 90; iter: 0; batch classifier loss: 0.411685; batch adversarial loss: 0.527086\n",
      "epoch 91; iter: 0; batch classifier loss: 0.404713; batch adversarial loss: 0.543917\n",
      "epoch 92; iter: 0; batch classifier loss: 0.449832; batch adversarial loss: 0.499744\n",
      "epoch 93; iter: 0; batch classifier loss: 0.399327; batch adversarial loss: 0.526644\n",
      "epoch 94; iter: 0; batch classifier loss: 0.369168; batch adversarial loss: 0.472391\n",
      "epoch 95; iter: 0; batch classifier loss: 0.342728; batch adversarial loss: 0.445629\n",
      "epoch 96; iter: 0; batch classifier loss: 0.380501; batch adversarial loss: 0.553514\n",
      "epoch 97; iter: 0; batch classifier loss: 0.397195; batch adversarial loss: 0.553312\n",
      "epoch 98; iter: 0; batch classifier loss: 0.387990; batch adversarial loss: 0.571574\n",
      "epoch 99; iter: 0; batch classifier loss: 0.454144; batch adversarial loss: 0.598342\n",
      "epoch 100; iter: 0; batch classifier loss: 0.387459; batch adversarial loss: 0.615815\n",
      "epoch 101; iter: 0; batch classifier loss: 0.437878; batch adversarial loss: 0.581266\n",
      "epoch 102; iter: 0; batch classifier loss: 0.352147; batch adversarial loss: 0.535228\n",
      "epoch 103; iter: 0; batch classifier loss: 0.401610; batch adversarial loss: 0.599080\n",
      "epoch 104; iter: 0; batch classifier loss: 0.436123; batch adversarial loss: 0.562424\n",
      "epoch 105; iter: 0; batch classifier loss: 0.446162; batch adversarial loss: 0.535330\n",
      "epoch 106; iter: 0; batch classifier loss: 0.299053; batch adversarial loss: 0.517975\n",
      "epoch 107; iter: 0; batch classifier loss: 0.473404; batch adversarial loss: 0.544581\n",
      "epoch 108; iter: 0; batch classifier loss: 0.378534; batch adversarial loss: 0.563451\n",
      "epoch 109; iter: 0; batch classifier loss: 0.346264; batch adversarial loss: 0.572693\n",
      "epoch 110; iter: 0; batch classifier loss: 0.393203; batch adversarial loss: 0.518015\n",
      "epoch 111; iter: 0; batch classifier loss: 0.324830; batch adversarial loss: 0.507936\n",
      "epoch 112; iter: 0; batch classifier loss: 0.374681; batch adversarial loss: 0.551822\n",
      "epoch 113; iter: 0; batch classifier loss: 0.299423; batch adversarial loss: 0.517284\n",
      "epoch 114; iter: 0; batch classifier loss: 0.423328; batch adversarial loss: 0.526261\n",
      "epoch 115; iter: 0; batch classifier loss: 0.379046; batch adversarial loss: 0.570995\n",
      "epoch 116; iter: 0; batch classifier loss: 0.401554; batch adversarial loss: 0.554001\n",
      "epoch 117; iter: 0; batch classifier loss: 0.329682; batch adversarial loss: 0.535439\n",
      "epoch 118; iter: 0; batch classifier loss: 0.375750; batch adversarial loss: 0.544626\n",
      "epoch 119; iter: 0; batch classifier loss: 0.370726; batch adversarial loss: 0.644742\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 120; iter: 0; batch classifier loss: 0.345106; batch adversarial loss: 0.545775\n",
      "epoch 121; iter: 0; batch classifier loss: 0.405023; batch adversarial loss: 0.499511\n",
      "epoch 122; iter: 0; batch classifier loss: 0.359999; batch adversarial loss: 0.571085\n",
      "epoch 123; iter: 0; batch classifier loss: 0.415483; batch adversarial loss: 0.491574\n",
      "epoch 124; iter: 0; batch classifier loss: 0.313057; batch adversarial loss: 0.525832\n",
      "epoch 125; iter: 0; batch classifier loss: 0.353303; batch adversarial loss: 0.553653\n",
      "epoch 126; iter: 0; batch classifier loss: 0.388133; batch adversarial loss: 0.536149\n",
      "epoch 127; iter: 0; batch classifier loss: 0.411437; batch adversarial loss: 0.606982\n",
      "epoch 128; iter: 0; batch classifier loss: 0.340818; batch adversarial loss: 0.634399\n",
      "epoch 129; iter: 0; batch classifier loss: 0.307977; batch adversarial loss: 0.552916\n",
      "epoch 130; iter: 0; batch classifier loss: 0.372556; batch adversarial loss: 0.527205\n",
      "epoch 131; iter: 0; batch classifier loss: 0.354943; batch adversarial loss: 0.544779\n",
      "epoch 132; iter: 0; batch classifier loss: 0.296562; batch adversarial loss: 0.607778\n",
      "epoch 133; iter: 0; batch classifier loss: 0.344546; batch adversarial loss: 0.562544\n",
      "epoch 134; iter: 0; batch classifier loss: 0.419204; batch adversarial loss: 0.544767\n",
      "epoch 135; iter: 0; batch classifier loss: 0.468439; batch adversarial loss: 0.542839\n",
      "epoch 136; iter: 0; batch classifier loss: 0.411687; batch adversarial loss: 0.606610\n",
      "epoch 137; iter: 0; batch classifier loss: 0.281613; batch adversarial loss: 0.561722\n",
      "epoch 138; iter: 0; batch classifier loss: 0.400199; batch adversarial loss: 0.526102\n",
      "epoch 139; iter: 0; batch classifier loss: 0.384129; batch adversarial loss: 0.517648\n",
      "epoch 140; iter: 0; batch classifier loss: 0.340231; batch adversarial loss: 0.537340\n",
      "epoch 141; iter: 0; batch classifier loss: 0.400914; batch adversarial loss: 0.509072\n",
      "epoch 142; iter: 0; batch classifier loss: 0.318272; batch adversarial loss: 0.580798\n",
      "epoch 143; iter: 0; batch classifier loss: 0.499882; batch adversarial loss: 0.527164\n",
      "epoch 144; iter: 0; batch classifier loss: 0.331852; batch adversarial loss: 0.563146\n",
      "epoch 145; iter: 0; batch classifier loss: 0.345646; batch adversarial loss: 0.517091\n",
      "epoch 146; iter: 0; batch classifier loss: 0.384564; batch adversarial loss: 0.543383\n",
      "epoch 147; iter: 0; batch classifier loss: 0.350497; batch adversarial loss: 0.554208\n",
      "epoch 148; iter: 0; batch classifier loss: 0.347930; batch adversarial loss: 0.608734\n",
      "epoch 149; iter: 0; batch classifier loss: 0.383749; batch adversarial loss: 0.473914\n",
      "epoch 150; iter: 0; batch classifier loss: 0.422149; batch adversarial loss: 0.561793\n",
      "epoch 151; iter: 0; batch classifier loss: 0.456687; batch adversarial loss: 0.580577\n",
      "epoch 152; iter: 0; batch classifier loss: 0.342141; batch adversarial loss: 0.535834\n",
      "epoch 153; iter: 0; batch classifier loss: 0.336453; batch adversarial loss: 0.482264\n",
      "epoch 154; iter: 0; batch classifier loss: 0.344235; batch adversarial loss: 0.599426\n",
      "epoch 155; iter: 0; batch classifier loss: 0.352036; batch adversarial loss: 0.579494\n",
      "epoch 156; iter: 0; batch classifier loss: 0.306943; batch adversarial loss: 0.572134\n",
      "epoch 157; iter: 0; batch classifier loss: 0.359997; batch adversarial loss: 0.517574\n",
      "epoch 158; iter: 0; batch classifier loss: 0.365048; batch adversarial loss: 0.544337\n",
      "epoch 159; iter: 0; batch classifier loss: 0.380800; batch adversarial loss: 0.581012\n",
      "epoch 160; iter: 0; batch classifier loss: 0.327040; batch adversarial loss: 0.588659\n",
      "epoch 161; iter: 0; batch classifier loss: 0.350523; batch adversarial loss: 0.508152\n",
      "epoch 162; iter: 0; batch classifier loss: 0.337686; batch adversarial loss: 0.589514\n",
      "epoch 163; iter: 0; batch classifier loss: 0.329476; batch adversarial loss: 0.553237\n",
      "epoch 164; iter: 0; batch classifier loss: 0.401341; batch adversarial loss: 0.555108\n",
      "epoch 165; iter: 0; batch classifier loss: 0.319750; batch adversarial loss: 0.571810\n",
      "epoch 166; iter: 0; batch classifier loss: 0.459665; batch adversarial loss: 0.489712\n",
      "epoch 167; iter: 0; batch classifier loss: 0.336060; batch adversarial loss: 0.535338\n",
      "epoch 168; iter: 0; batch classifier loss: 0.356879; batch adversarial loss: 0.554004\n",
      "epoch 169; iter: 0; batch classifier loss: 0.330968; batch adversarial loss: 0.499734\n",
      "epoch 170; iter: 0; batch classifier loss: 0.359546; batch adversarial loss: 0.580410\n",
      "epoch 171; iter: 0; batch classifier loss: 0.307631; batch adversarial loss: 0.606924\n",
      "epoch 172; iter: 0; batch classifier loss: 0.316813; batch adversarial loss: 0.572203\n",
      "epoch 173; iter: 0; batch classifier loss: 0.375817; batch adversarial loss: 0.562737\n",
      "epoch 174; iter: 0; batch classifier loss: 0.396657; batch adversarial loss: 0.525599\n",
      "epoch 175; iter: 0; batch classifier loss: 0.396807; batch adversarial loss: 0.491015\n",
      "epoch 176; iter: 0; batch classifier loss: 0.366490; batch adversarial loss: 0.616549\n",
      "epoch 177; iter: 0; batch classifier loss: 0.316679; batch adversarial loss: 0.617230\n",
      "epoch 178; iter: 0; batch classifier loss: 0.368935; batch adversarial loss: 0.500338\n",
      "epoch 179; iter: 0; batch classifier loss: 0.372541; batch adversarial loss: 0.563403\n",
      "epoch 180; iter: 0; batch classifier loss: 0.308068; batch adversarial loss: 0.508715\n",
      "epoch 181; iter: 0; batch classifier loss: 0.321057; batch adversarial loss: 0.527364\n",
      "epoch 182; iter: 0; batch classifier loss: 0.454548; batch adversarial loss: 0.463200\n",
      "epoch 183; iter: 0; batch classifier loss: 0.300911; batch adversarial loss: 0.472753\n",
      "epoch 184; iter: 0; batch classifier loss: 0.347841; batch adversarial loss: 0.608241\n",
      "epoch 185; iter: 0; batch classifier loss: 0.424114; batch adversarial loss: 0.625270\n",
      "epoch 186; iter: 0; batch classifier loss: 0.404179; batch adversarial loss: 0.589613\n",
      "epoch 187; iter: 0; batch classifier loss: 0.380270; batch adversarial loss: 0.544260\n",
      "epoch 188; iter: 0; batch classifier loss: 0.245206; batch adversarial loss: 0.589923\n",
      "epoch 189; iter: 0; batch classifier loss: 0.366874; batch adversarial loss: 0.509292\n",
      "epoch 190; iter: 0; batch classifier loss: 0.380779; batch adversarial loss: 0.508709\n",
      "epoch 191; iter: 0; batch classifier loss: 0.396682; batch adversarial loss: 0.553183\n",
      "epoch 192; iter: 0; batch classifier loss: 0.320533; batch adversarial loss: 0.571805\n",
      "epoch 193; iter: 0; batch classifier loss: 0.306421; batch adversarial loss: 0.552376\n",
      "epoch 194; iter: 0; batch classifier loss: 0.279963; batch adversarial loss: 0.562427\n",
      "epoch 195; iter: 0; batch classifier loss: 0.354434; batch adversarial loss: 0.589113\n",
      "epoch 196; iter: 0; batch classifier loss: 0.305976; batch adversarial loss: 0.616764\n",
      "epoch 197; iter: 0; batch classifier loss: 0.388046; batch adversarial loss: 0.561319\n",
      "epoch 198; iter: 0; batch classifier loss: 0.379590; batch adversarial loss: 0.527177\n",
      "epoch 199; iter: 0; batch classifier loss: 0.424459; batch adversarial loss: 0.472724\n",
      "epoch 0; iter: 0; batch classifier loss: 0.772911; batch adversarial loss: 0.679249\n",
      "epoch 1; iter: 0; batch classifier loss: 0.574725; batch adversarial loss: 0.675773\n",
      "epoch 2; iter: 0; batch classifier loss: 0.615947; batch adversarial loss: 0.626600\n",
      "epoch 3; iter: 0; batch classifier loss: 0.564985; batch adversarial loss: 0.648308\n",
      "epoch 4; iter: 0; batch classifier loss: 0.586865; batch adversarial loss: 0.607199\n",
      "epoch 5; iter: 0; batch classifier loss: 0.546729; batch adversarial loss: 0.587599\n",
      "epoch 6; iter: 0; batch classifier loss: 0.605002; batch adversarial loss: 0.600556\n",
      "epoch 7; iter: 0; batch classifier loss: 0.496223; batch adversarial loss: 0.625826\n",
      "epoch 8; iter: 0; batch classifier loss: 0.575238; batch adversarial loss: 0.597986\n",
      "epoch 9; iter: 0; batch classifier loss: 0.562511; batch adversarial loss: 0.609499\n",
      "epoch 10; iter: 0; batch classifier loss: 0.560055; batch adversarial loss: 0.584431\n",
      "epoch 11; iter: 0; batch classifier loss: 0.502099; batch adversarial loss: 0.600712\n",
      "epoch 12; iter: 0; batch classifier loss: 0.536703; batch adversarial loss: 0.650924\n",
      "epoch 13; iter: 0; batch classifier loss: 0.522310; batch adversarial loss: 0.611437\n",
      "epoch 14; iter: 0; batch classifier loss: 0.551516; batch adversarial loss: 0.628670\n",
      "epoch 15; iter: 0; batch classifier loss: 0.573198; batch adversarial loss: 0.522725\n",
      "epoch 16; iter: 0; batch classifier loss: 0.543052; batch adversarial loss: 0.587843\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 17; iter: 0; batch classifier loss: 0.393878; batch adversarial loss: 0.583623\n",
      "epoch 18; iter: 0; batch classifier loss: 0.466583; batch adversarial loss: 0.562622\n",
      "epoch 19; iter: 0; batch classifier loss: 0.468571; batch adversarial loss: 0.539961\n",
      "epoch 20; iter: 0; batch classifier loss: 0.543402; batch adversarial loss: 0.613139\n",
      "epoch 21; iter: 0; batch classifier loss: 0.432845; batch adversarial loss: 0.578083\n",
      "epoch 22; iter: 0; batch classifier loss: 0.485941; batch adversarial loss: 0.573420\n",
      "epoch 23; iter: 0; batch classifier loss: 0.488047; batch adversarial loss: 0.635988\n",
      "epoch 24; iter: 0; batch classifier loss: 0.528330; batch adversarial loss: 0.511739\n",
      "epoch 25; iter: 0; batch classifier loss: 0.495307; batch adversarial loss: 0.565404\n",
      "epoch 26; iter: 0; batch classifier loss: 0.468400; batch adversarial loss: 0.559209\n",
      "epoch 27; iter: 0; batch classifier loss: 0.481655; batch adversarial loss: 0.564976\n",
      "epoch 28; iter: 0; batch classifier loss: 0.483963; batch adversarial loss: 0.492281\n",
      "epoch 29; iter: 0; batch classifier loss: 0.415641; batch adversarial loss: 0.500832\n",
      "epoch 30; iter: 0; batch classifier loss: 0.481346; batch adversarial loss: 0.529457\n",
      "epoch 31; iter: 0; batch classifier loss: 0.420225; batch adversarial loss: 0.510847\n",
      "epoch 32; iter: 0; batch classifier loss: 0.493716; batch adversarial loss: 0.502590\n",
      "epoch 33; iter: 0; batch classifier loss: 0.453200; batch adversarial loss: 0.543223\n",
      "epoch 34; iter: 0; batch classifier loss: 0.414384; batch adversarial loss: 0.527506\n",
      "epoch 35; iter: 0; batch classifier loss: 0.489669; batch adversarial loss: 0.554827\n",
      "epoch 36; iter: 0; batch classifier loss: 0.523117; batch adversarial loss: 0.571858\n",
      "epoch 37; iter: 0; batch classifier loss: 0.537157; batch adversarial loss: 0.528581\n",
      "epoch 38; iter: 0; batch classifier loss: 0.512480; batch adversarial loss: 0.623601\n",
      "epoch 39; iter: 0; batch classifier loss: 0.487533; batch adversarial loss: 0.527024\n",
      "epoch 40; iter: 0; batch classifier loss: 0.506472; batch adversarial loss: 0.635425\n",
      "epoch 41; iter: 0; batch classifier loss: 0.410355; batch adversarial loss: 0.535736\n",
      "epoch 42; iter: 0; batch classifier loss: 0.424805; batch adversarial loss: 0.472904\n",
      "epoch 43; iter: 0; batch classifier loss: 0.465697; batch adversarial loss: 0.590610\n",
      "epoch 44; iter: 0; batch classifier loss: 0.446997; batch adversarial loss: 0.535102\n",
      "epoch 45; iter: 0; batch classifier loss: 0.432157; batch adversarial loss: 0.444741\n",
      "epoch 46; iter: 0; batch classifier loss: 0.435476; batch adversarial loss: 0.561461\n",
      "epoch 47; iter: 0; batch classifier loss: 0.462929; batch adversarial loss: 0.491971\n",
      "epoch 48; iter: 0; batch classifier loss: 0.454229; batch adversarial loss: 0.570947\n",
      "epoch 49; iter: 0; batch classifier loss: 0.430247; batch adversarial loss: 0.573317\n",
      "epoch 50; iter: 0; batch classifier loss: 0.391480; batch adversarial loss: 0.524682\n",
      "epoch 51; iter: 0; batch classifier loss: 0.426724; batch adversarial loss: 0.535559\n",
      "epoch 52; iter: 0; batch classifier loss: 0.423103; batch adversarial loss: 0.571923\n",
      "epoch 53; iter: 0; batch classifier loss: 0.444073; batch adversarial loss: 0.534714\n",
      "epoch 54; iter: 0; batch classifier loss: 0.473619; batch adversarial loss: 0.599381\n",
      "epoch 55; iter: 0; batch classifier loss: 0.412583; batch adversarial loss: 0.618478\n",
      "epoch 56; iter: 0; batch classifier loss: 0.429807; batch adversarial loss: 0.542373\n",
      "epoch 57; iter: 0; batch classifier loss: 0.461828; batch adversarial loss: 0.597376\n",
      "epoch 58; iter: 0; batch classifier loss: 0.345987; batch adversarial loss: 0.542889\n",
      "epoch 59; iter: 0; batch classifier loss: 0.442188; batch adversarial loss: 0.562110\n",
      "epoch 60; iter: 0; batch classifier loss: 0.485460; batch adversarial loss: 0.554760\n",
      "epoch 61; iter: 0; batch classifier loss: 0.395611; batch adversarial loss: 0.572315\n",
      "epoch 62; iter: 0; batch classifier loss: 0.439552; batch adversarial loss: 0.452646\n",
      "epoch 63; iter: 0; batch classifier loss: 0.393398; batch adversarial loss: 0.542925\n",
      "epoch 64; iter: 0; batch classifier loss: 0.426331; batch adversarial loss: 0.542366\n",
      "epoch 65; iter: 0; batch classifier loss: 0.404553; batch adversarial loss: 0.545412\n",
      "epoch 66; iter: 0; batch classifier loss: 0.454144; batch adversarial loss: 0.479182\n",
      "epoch 67; iter: 0; batch classifier loss: 0.472502; batch adversarial loss: 0.526628\n",
      "epoch 68; iter: 0; batch classifier loss: 0.429106; batch adversarial loss: 0.506934\n",
      "epoch 69; iter: 0; batch classifier loss: 0.425655; batch adversarial loss: 0.506632\n",
      "epoch 70; iter: 0; batch classifier loss: 0.462197; batch adversarial loss: 0.601341\n",
      "epoch 71; iter: 0; batch classifier loss: 0.392294; batch adversarial loss: 0.547283\n",
      "epoch 72; iter: 0; batch classifier loss: 0.374680; batch adversarial loss: 0.503327\n",
      "epoch 73; iter: 0; batch classifier loss: 0.457988; batch adversarial loss: 0.570555\n",
      "epoch 74; iter: 0; batch classifier loss: 0.434009; batch adversarial loss: 0.587930\n",
      "epoch 75; iter: 0; batch classifier loss: 0.394024; batch adversarial loss: 0.554882\n",
      "epoch 76; iter: 0; batch classifier loss: 0.398827; batch adversarial loss: 0.553669\n",
      "epoch 77; iter: 0; batch classifier loss: 0.390107; batch adversarial loss: 0.553928\n",
      "epoch 78; iter: 0; batch classifier loss: 0.416049; batch adversarial loss: 0.568877\n",
      "epoch 79; iter: 0; batch classifier loss: 0.492929; batch adversarial loss: 0.616100\n",
      "epoch 80; iter: 0; batch classifier loss: 0.451115; batch adversarial loss: 0.551364\n",
      "epoch 81; iter: 0; batch classifier loss: 0.356512; batch adversarial loss: 0.517663\n",
      "epoch 82; iter: 0; batch classifier loss: 0.444436; batch adversarial loss: 0.580418\n",
      "epoch 83; iter: 0; batch classifier loss: 0.359648; batch adversarial loss: 0.588299\n",
      "epoch 84; iter: 0; batch classifier loss: 0.459078; batch adversarial loss: 0.544743\n",
      "epoch 85; iter: 0; batch classifier loss: 0.568802; batch adversarial loss: 0.508954\n",
      "epoch 86; iter: 0; batch classifier loss: 0.466339; batch adversarial loss: 0.580819\n",
      "epoch 87; iter: 0; batch classifier loss: 0.429611; batch adversarial loss: 0.555880\n",
      "epoch 88; iter: 0; batch classifier loss: 0.401868; batch adversarial loss: 0.609075\n",
      "epoch 89; iter: 0; batch classifier loss: 0.360478; batch adversarial loss: 0.598275\n",
      "epoch 90; iter: 0; batch classifier loss: 0.386730; batch adversarial loss: 0.515533\n",
      "epoch 91; iter: 0; batch classifier loss: 0.413654; batch adversarial loss: 0.516866\n",
      "epoch 92; iter: 0; batch classifier loss: 0.341424; batch adversarial loss: 0.573609\n",
      "epoch 93; iter: 0; batch classifier loss: 0.387486; batch adversarial loss: 0.556847\n",
      "epoch 94; iter: 0; batch classifier loss: 0.354630; batch adversarial loss: 0.599996\n",
      "epoch 95; iter: 0; batch classifier loss: 0.393116; batch adversarial loss: 0.489182\n",
      "epoch 96; iter: 0; batch classifier loss: 0.484292; batch adversarial loss: 0.590019\n",
      "epoch 97; iter: 0; batch classifier loss: 0.441647; batch adversarial loss: 0.453093\n",
      "epoch 98; iter: 0; batch classifier loss: 0.354254; batch adversarial loss: 0.618153\n",
      "epoch 99; iter: 0; batch classifier loss: 0.395662; batch adversarial loss: 0.544715\n",
      "epoch 100; iter: 0; batch classifier loss: 0.438069; batch adversarial loss: 0.561483\n",
      "epoch 101; iter: 0; batch classifier loss: 0.383359; batch adversarial loss: 0.500290\n",
      "epoch 102; iter: 0; batch classifier loss: 0.401798; batch adversarial loss: 0.525443\n",
      "epoch 103; iter: 0; batch classifier loss: 0.369026; batch adversarial loss: 0.526621\n",
      "epoch 104; iter: 0; batch classifier loss: 0.364216; batch adversarial loss: 0.533526\n",
      "epoch 105; iter: 0; batch classifier loss: 0.293098; batch adversarial loss: 0.553077\n",
      "epoch 106; iter: 0; batch classifier loss: 0.428874; batch adversarial loss: 0.563489\n",
      "epoch 107; iter: 0; batch classifier loss: 0.406091; batch adversarial loss: 0.552104\n",
      "epoch 108; iter: 0; batch classifier loss: 0.448229; batch adversarial loss: 0.518572\n",
      "epoch 109; iter: 0; batch classifier loss: 0.423791; batch adversarial loss: 0.491024\n",
      "epoch 110; iter: 0; batch classifier loss: 0.453056; batch adversarial loss: 0.542653\n",
      "epoch 111; iter: 0; batch classifier loss: 0.395651; batch adversarial loss: 0.559564\n",
      "epoch 112; iter: 0; batch classifier loss: 0.339025; batch adversarial loss: 0.554468\n",
      "epoch 113; iter: 0; batch classifier loss: 0.340800; batch adversarial loss: 0.442859\n",
      "epoch 114; iter: 0; batch classifier loss: 0.440412; batch adversarial loss: 0.516993\n",
      "epoch 115; iter: 0; batch classifier loss: 0.394873; batch adversarial loss: 0.500361\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 116; iter: 0; batch classifier loss: 0.409138; batch adversarial loss: 0.533656\n",
      "epoch 117; iter: 0; batch classifier loss: 0.406587; batch adversarial loss: 0.433783\n",
      "epoch 118; iter: 0; batch classifier loss: 0.435907; batch adversarial loss: 0.542097\n",
      "epoch 119; iter: 0; batch classifier loss: 0.467714; batch adversarial loss: 0.564556\n",
      "epoch 120; iter: 0; batch classifier loss: 0.420005; batch adversarial loss: 0.553283\n",
      "epoch 121; iter: 0; batch classifier loss: 0.428631; batch adversarial loss: 0.615652\n",
      "epoch 122; iter: 0; batch classifier loss: 0.453717; batch adversarial loss: 0.538136\n",
      "epoch 123; iter: 0; batch classifier loss: 0.359011; batch adversarial loss: 0.570409\n",
      "epoch 124; iter: 0; batch classifier loss: 0.386617; batch adversarial loss: 0.563898\n",
      "epoch 125; iter: 0; batch classifier loss: 0.417999; batch adversarial loss: 0.549586\n",
      "epoch 126; iter: 0; batch classifier loss: 0.342176; batch adversarial loss: 0.553414\n",
      "epoch 127; iter: 0; batch classifier loss: 0.368661; batch adversarial loss: 0.534846\n",
      "epoch 128; iter: 0; batch classifier loss: 0.397547; batch adversarial loss: 0.545430\n",
      "epoch 129; iter: 0; batch classifier loss: 0.435933; batch adversarial loss: 0.542604\n",
      "epoch 130; iter: 0; batch classifier loss: 0.357340; batch adversarial loss: 0.517611\n",
      "epoch 131; iter: 0; batch classifier loss: 0.361012; batch adversarial loss: 0.552177\n",
      "epoch 132; iter: 0; batch classifier loss: 0.441614; batch adversarial loss: 0.478536\n",
      "epoch 133; iter: 0; batch classifier loss: 0.388044; batch adversarial loss: 0.591980\n",
      "epoch 134; iter: 0; batch classifier loss: 0.219286; batch adversarial loss: 0.559093\n",
      "epoch 135; iter: 0; batch classifier loss: 0.356445; batch adversarial loss: 0.580245\n",
      "epoch 136; iter: 0; batch classifier loss: 0.336911; batch adversarial loss: 0.560888\n",
      "epoch 137; iter: 0; batch classifier loss: 0.425431; batch adversarial loss: 0.623253\n",
      "epoch 138; iter: 0; batch classifier loss: 0.379063; batch adversarial loss: 0.472684\n",
      "epoch 139; iter: 0; batch classifier loss: 0.379522; batch adversarial loss: 0.579989\n",
      "epoch 140; iter: 0; batch classifier loss: 0.378447; batch adversarial loss: 0.460098\n",
      "epoch 141; iter: 0; batch classifier loss: 0.363156; batch adversarial loss: 0.545728\n",
      "epoch 142; iter: 0; batch classifier loss: 0.395356; batch adversarial loss: 0.498271\n",
      "epoch 143; iter: 0; batch classifier loss: 0.306006; batch adversarial loss: 0.518289\n",
      "epoch 144; iter: 0; batch classifier loss: 0.313581; batch adversarial loss: 0.619546\n",
      "epoch 145; iter: 0; batch classifier loss: 0.353270; batch adversarial loss: 0.525457\n",
      "epoch 146; iter: 0; batch classifier loss: 0.329426; batch adversarial loss: 0.647794\n",
      "epoch 147; iter: 0; batch classifier loss: 0.413869; batch adversarial loss: 0.509060\n",
      "epoch 148; iter: 0; batch classifier loss: 0.411988; batch adversarial loss: 0.541990\n",
      "epoch 149; iter: 0; batch classifier loss: 0.338549; batch adversarial loss: 0.542285\n",
      "epoch 150; iter: 0; batch classifier loss: 0.393113; batch adversarial loss: 0.606339\n",
      "epoch 151; iter: 0; batch classifier loss: 0.510643; batch adversarial loss: 0.581979\n",
      "epoch 152; iter: 0; batch classifier loss: 0.500897; batch adversarial loss: 0.616498\n",
      "epoch 153; iter: 0; batch classifier loss: 0.403924; batch adversarial loss: 0.517827\n",
      "epoch 154; iter: 0; batch classifier loss: 0.441213; batch adversarial loss: 0.609340\n",
      "epoch 155; iter: 0; batch classifier loss: 0.398768; batch adversarial loss: 0.568456\n",
      "epoch 156; iter: 0; batch classifier loss: 0.415277; batch adversarial loss: 0.505858\n",
      "epoch 157; iter: 0; batch classifier loss: 0.269645; batch adversarial loss: 0.517828\n",
      "epoch 158; iter: 0; batch classifier loss: 0.498287; batch adversarial loss: 0.516590\n",
      "epoch 159; iter: 0; batch classifier loss: 0.417062; batch adversarial loss: 0.608297\n",
      "epoch 160; iter: 0; batch classifier loss: 0.455642; batch adversarial loss: 0.474204\n",
      "epoch 161; iter: 0; batch classifier loss: 0.335300; batch adversarial loss: 0.549618\n",
      "epoch 162; iter: 0; batch classifier loss: 0.313653; batch adversarial loss: 0.533803\n",
      "epoch 163; iter: 0; batch classifier loss: 0.365106; batch adversarial loss: 0.608800\n",
      "epoch 164; iter: 0; batch classifier loss: 0.366725; batch adversarial loss: 0.579716\n",
      "epoch 165; iter: 0; batch classifier loss: 0.381325; batch adversarial loss: 0.479604\n",
      "epoch 166; iter: 0; batch classifier loss: 0.368659; batch adversarial loss: 0.583814\n",
      "epoch 167; iter: 0; batch classifier loss: 0.321531; batch adversarial loss: 0.515778\n",
      "epoch 168; iter: 0; batch classifier loss: 0.356541; batch adversarial loss: 0.581245\n",
      "epoch 169; iter: 0; batch classifier loss: 0.442360; batch adversarial loss: 0.572620\n",
      "epoch 170; iter: 0; batch classifier loss: 0.359035; batch adversarial loss: 0.495647\n",
      "epoch 171; iter: 0; batch classifier loss: 0.380423; batch adversarial loss: 0.536781\n",
      "epoch 172; iter: 0; batch classifier loss: 0.376835; batch adversarial loss: 0.569421\n",
      "epoch 173; iter: 0; batch classifier loss: 0.372951; batch adversarial loss: 0.654183\n",
      "epoch 174; iter: 0; batch classifier loss: 0.358809; batch adversarial loss: 0.606066\n",
      "epoch 175; iter: 0; batch classifier loss: 0.389110; batch adversarial loss: 0.553305\n",
      "epoch 176; iter: 0; batch classifier loss: 0.329228; batch adversarial loss: 0.571161\n",
      "epoch 177; iter: 0; batch classifier loss: 0.336675; batch adversarial loss: 0.510267\n",
      "epoch 178; iter: 0; batch classifier loss: 0.355229; batch adversarial loss: 0.552914\n",
      "epoch 179; iter: 0; batch classifier loss: 0.401663; batch adversarial loss: 0.584323\n",
      "epoch 180; iter: 0; batch classifier loss: 0.376759; batch adversarial loss: 0.553884\n",
      "epoch 181; iter: 0; batch classifier loss: 0.474687; batch adversarial loss: 0.579780\n",
      "epoch 182; iter: 0; batch classifier loss: 0.363125; batch adversarial loss: 0.639025\n",
      "epoch 183; iter: 0; batch classifier loss: 0.371502; batch adversarial loss: 0.562320\n",
      "epoch 184; iter: 0; batch classifier loss: 0.354816; batch adversarial loss: 0.530849\n",
      "epoch 185; iter: 0; batch classifier loss: 0.322463; batch adversarial loss: 0.542044\n",
      "epoch 186; iter: 0; batch classifier loss: 0.312592; batch adversarial loss: 0.608361\n",
      "epoch 187; iter: 0; batch classifier loss: 0.360877; batch adversarial loss: 0.586986\n",
      "epoch 188; iter: 0; batch classifier loss: 0.437794; batch adversarial loss: 0.472560\n",
      "epoch 189; iter: 0; batch classifier loss: 0.309447; batch adversarial loss: 0.480301\n",
      "epoch 190; iter: 0; batch classifier loss: 0.362296; batch adversarial loss: 0.587831\n",
      "epoch 191; iter: 0; batch classifier loss: 0.379999; batch adversarial loss: 0.515899\n",
      "epoch 192; iter: 0; batch classifier loss: 0.444135; batch adversarial loss: 0.574358\n",
      "epoch 193; iter: 0; batch classifier loss: 0.337745; batch adversarial loss: 0.535984\n",
      "epoch 194; iter: 0; batch classifier loss: 0.346975; batch adversarial loss: 0.577781\n",
      "epoch 195; iter: 0; batch classifier loss: 0.401254; batch adversarial loss: 0.536207\n",
      "epoch 196; iter: 0; batch classifier loss: 0.350194; batch adversarial loss: 0.534545\n",
      "epoch 197; iter: 0; batch classifier loss: 0.318085; batch adversarial loss: 0.546089\n",
      "epoch 198; iter: 0; batch classifier loss: 0.329772; batch adversarial loss: 0.508806\n",
      "epoch 199; iter: 0; batch classifier loss: 0.505404; batch adversarial loss: 0.488260\n",
      "epoch 0; iter: 0; batch classifier loss: 0.697314; batch adversarial loss: 0.857414\n",
      "epoch 1; iter: 0; batch classifier loss: 0.726771; batch adversarial loss: 0.905686\n",
      "epoch 2; iter: 0; batch classifier loss: 0.814754; batch adversarial loss: 0.885734\n",
      "epoch 3; iter: 0; batch classifier loss: 0.972523; batch adversarial loss: 0.823589\n",
      "epoch 4; iter: 0; batch classifier loss: 0.989951; batch adversarial loss: 0.757056\n",
      "epoch 5; iter: 0; batch classifier loss: 0.873643; batch adversarial loss: 0.703389\n",
      "epoch 6; iter: 0; batch classifier loss: 0.814020; batch adversarial loss: 0.659907\n",
      "epoch 7; iter: 0; batch classifier loss: 0.687281; batch adversarial loss: 0.633059\n",
      "epoch 8; iter: 0; batch classifier loss: 0.558060; batch adversarial loss: 0.623587\n",
      "epoch 9; iter: 0; batch classifier loss: 0.582483; batch adversarial loss: 0.623175\n",
      "epoch 10; iter: 0; batch classifier loss: 0.623801; batch adversarial loss: 0.588778\n",
      "epoch 11; iter: 0; batch classifier loss: 0.638194; batch adversarial loss: 0.575237\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12; iter: 0; batch classifier loss: 0.651633; batch adversarial loss: 0.546276\n",
      "epoch 13; iter: 0; batch classifier loss: 0.553041; batch adversarial loss: 0.540455\n",
      "epoch 14; iter: 0; batch classifier loss: 0.513198; batch adversarial loss: 0.526538\n",
      "epoch 15; iter: 0; batch classifier loss: 0.482876; batch adversarial loss: 0.525696\n",
      "epoch 16; iter: 0; batch classifier loss: 0.540500; batch adversarial loss: 0.537129\n",
      "epoch 17; iter: 0; batch classifier loss: 0.463529; batch adversarial loss: 0.548039\n",
      "epoch 18; iter: 0; batch classifier loss: 0.596234; batch adversarial loss: 0.518765\n",
      "epoch 19; iter: 0; batch classifier loss: 0.535781; batch adversarial loss: 0.516976\n",
      "epoch 20; iter: 0; batch classifier loss: 0.514321; batch adversarial loss: 0.512266\n",
      "epoch 21; iter: 0; batch classifier loss: 0.510984; batch adversarial loss: 0.564960\n",
      "epoch 22; iter: 0; batch classifier loss: 0.566455; batch adversarial loss: 0.580803\n",
      "epoch 23; iter: 0; batch classifier loss: 0.506601; batch adversarial loss: 0.498749\n",
      "epoch 24; iter: 0; batch classifier loss: 0.439459; batch adversarial loss: 0.554536\n",
      "epoch 25; iter: 0; batch classifier loss: 0.490220; batch adversarial loss: 0.589603\n",
      "epoch 26; iter: 0; batch classifier loss: 0.416507; batch adversarial loss: 0.582335\n",
      "epoch 27; iter: 0; batch classifier loss: 0.479804; batch adversarial loss: 0.643874\n",
      "epoch 28; iter: 0; batch classifier loss: 0.426207; batch adversarial loss: 0.555310\n",
      "epoch 29; iter: 0; batch classifier loss: 0.483012; batch adversarial loss: 0.651645\n",
      "epoch 30; iter: 0; batch classifier loss: 0.521944; batch adversarial loss: 0.612853\n",
      "epoch 31; iter: 0; batch classifier loss: 0.505096; batch adversarial loss: 0.533398\n",
      "epoch 32; iter: 0; batch classifier loss: 0.425500; batch adversarial loss: 0.543630\n",
      "epoch 33; iter: 0; batch classifier loss: 0.441722; batch adversarial loss: 0.506451\n",
      "epoch 34; iter: 0; batch classifier loss: 0.505548; batch adversarial loss: 0.472026\n",
      "epoch 35; iter: 0; batch classifier loss: 0.440948; batch adversarial loss: 0.571346\n",
      "epoch 36; iter: 0; batch classifier loss: 0.420556; batch adversarial loss: 0.560996\n",
      "epoch 37; iter: 0; batch classifier loss: 0.406851; batch adversarial loss: 0.520988\n",
      "epoch 38; iter: 0; batch classifier loss: 0.481396; batch adversarial loss: 0.582663\n",
      "epoch 39; iter: 0; batch classifier loss: 0.485946; batch adversarial loss: 0.583174\n",
      "epoch 40; iter: 0; batch classifier loss: 0.506261; batch adversarial loss: 0.572544\n",
      "epoch 41; iter: 0; batch classifier loss: 0.470509; batch adversarial loss: 0.512203\n",
      "epoch 42; iter: 0; batch classifier loss: 0.477614; batch adversarial loss: 0.613077\n",
      "epoch 43; iter: 0; batch classifier loss: 0.367622; batch adversarial loss: 0.562181\n",
      "epoch 44; iter: 0; batch classifier loss: 0.420760; batch adversarial loss: 0.501888\n",
      "epoch 45; iter: 0; batch classifier loss: 0.365885; batch adversarial loss: 0.631287\n",
      "epoch 46; iter: 0; batch classifier loss: 0.451538; batch adversarial loss: 0.553431\n",
      "epoch 47; iter: 0; batch classifier loss: 0.445250; batch adversarial loss: 0.499351\n",
      "epoch 48; iter: 0; batch classifier loss: 0.515151; batch adversarial loss: 0.603837\n",
      "epoch 49; iter: 0; batch classifier loss: 0.413270; batch adversarial loss: 0.484114\n",
      "epoch 50; iter: 0; batch classifier loss: 0.396124; batch adversarial loss: 0.579776\n",
      "epoch 51; iter: 0; batch classifier loss: 0.424097; batch adversarial loss: 0.606832\n",
      "epoch 52; iter: 0; batch classifier loss: 0.500977; batch adversarial loss: 0.617446\n",
      "epoch 53; iter: 0; batch classifier loss: 0.425898; batch adversarial loss: 0.491850\n",
      "epoch 54; iter: 0; batch classifier loss: 0.370188; batch adversarial loss: 0.509666\n",
      "epoch 55; iter: 0; batch classifier loss: 0.442953; batch adversarial loss: 0.562146\n",
      "epoch 56; iter: 0; batch classifier loss: 0.456816; batch adversarial loss: 0.552077\n",
      "epoch 57; iter: 0; batch classifier loss: 0.470076; batch adversarial loss: 0.610237\n",
      "epoch 58; iter: 0; batch classifier loss: 0.388040; batch adversarial loss: 0.661962\n",
      "epoch 59; iter: 0; batch classifier loss: 0.476796; batch adversarial loss: 0.516803\n",
      "epoch 60; iter: 0; batch classifier loss: 0.451837; batch adversarial loss: 0.497601\n",
      "epoch 61; iter: 0; batch classifier loss: 0.347328; batch adversarial loss: 0.663211\n",
      "epoch 62; iter: 0; batch classifier loss: 0.449109; batch adversarial loss: 0.600698\n",
      "epoch 63; iter: 0; batch classifier loss: 0.412040; batch adversarial loss: 0.581720\n",
      "epoch 64; iter: 0; batch classifier loss: 0.420530; batch adversarial loss: 0.507912\n",
      "epoch 65; iter: 0; batch classifier loss: 0.354771; batch adversarial loss: 0.526318\n",
      "epoch 66; iter: 0; batch classifier loss: 0.369738; batch adversarial loss: 0.618771\n",
      "epoch 67; iter: 0; batch classifier loss: 0.405243; batch adversarial loss: 0.535392\n",
      "epoch 68; iter: 0; batch classifier loss: 0.416228; batch adversarial loss: 0.563357\n",
      "epoch 69; iter: 0; batch classifier loss: 0.431518; batch adversarial loss: 0.470535\n",
      "epoch 70; iter: 0; batch classifier loss: 0.434348; batch adversarial loss: 0.535149\n",
      "epoch 71; iter: 0; batch classifier loss: 0.457790; batch adversarial loss: 0.526116\n",
      "epoch 72; iter: 0; batch classifier loss: 0.352908; batch adversarial loss: 0.516901\n",
      "epoch 73; iter: 0; batch classifier loss: 0.496632; batch adversarial loss: 0.544523\n",
      "epoch 74; iter: 0; batch classifier loss: 0.410238; batch adversarial loss: 0.535359\n",
      "epoch 75; iter: 0; batch classifier loss: 0.411035; batch adversarial loss: 0.590461\n",
      "epoch 76; iter: 0; batch classifier loss: 0.352402; batch adversarial loss: 0.526024\n",
      "epoch 77; iter: 0; batch classifier loss: 0.390960; batch adversarial loss: 0.553895\n",
      "epoch 78; iter: 0; batch classifier loss: 0.381643; batch adversarial loss: 0.553077\n",
      "epoch 79; iter: 0; batch classifier loss: 0.369175; batch adversarial loss: 0.508000\n",
      "epoch 80; iter: 0; batch classifier loss: 0.378837; batch adversarial loss: 0.508417\n",
      "epoch 81; iter: 0; batch classifier loss: 0.383592; batch adversarial loss: 0.535452\n",
      "epoch 82; iter: 0; batch classifier loss: 0.443140; batch adversarial loss: 0.617090\n",
      "epoch 83; iter: 0; batch classifier loss: 0.388273; batch adversarial loss: 0.517304\n",
      "epoch 84; iter: 0; batch classifier loss: 0.369244; batch adversarial loss: 0.499694\n",
      "epoch 85; iter: 0; batch classifier loss: 0.370702; batch adversarial loss: 0.553818\n",
      "epoch 86; iter: 0; batch classifier loss: 0.436621; batch adversarial loss: 0.526516\n",
      "epoch 87; iter: 0; batch classifier loss: 0.405488; batch adversarial loss: 0.526802\n",
      "epoch 88; iter: 0; batch classifier loss: 0.387915; batch adversarial loss: 0.554032\n",
      "epoch 89; iter: 0; batch classifier loss: 0.376990; batch adversarial loss: 0.581088\n",
      "epoch 90; iter: 0; batch classifier loss: 0.396656; batch adversarial loss: 0.544552\n",
      "epoch 91; iter: 0; batch classifier loss: 0.423959; batch adversarial loss: 0.435368\n",
      "epoch 92; iter: 0; batch classifier loss: 0.377661; batch adversarial loss: 0.526270\n",
      "epoch 93; iter: 0; batch classifier loss: 0.341179; batch adversarial loss: 0.553078\n",
      "epoch 94; iter: 0; batch classifier loss: 0.366773; batch adversarial loss: 0.517301\n",
      "epoch 95; iter: 0; batch classifier loss: 0.336321; batch adversarial loss: 0.535572\n",
      "epoch 96; iter: 0; batch classifier loss: 0.348383; batch adversarial loss: 0.589871\n",
      "epoch 97; iter: 0; batch classifier loss: 0.360609; batch adversarial loss: 0.599323\n",
      "epoch 98; iter: 0; batch classifier loss: 0.366027; batch adversarial loss: 0.526220\n",
      "epoch 99; iter: 0; batch classifier loss: 0.398441; batch adversarial loss: 0.544615\n",
      "epoch 100; iter: 0; batch classifier loss: 0.371373; batch adversarial loss: 0.516676\n",
      "epoch 101; iter: 0; batch classifier loss: 0.408818; batch adversarial loss: 0.563007\n",
      "epoch 102; iter: 0; batch classifier loss: 0.365986; batch adversarial loss: 0.553504\n",
      "epoch 103; iter: 0; batch classifier loss: 0.313480; batch adversarial loss: 0.590248\n",
      "epoch 104; iter: 0; batch classifier loss: 0.373974; batch adversarial loss: 0.480139\n",
      "epoch 105; iter: 0; batch classifier loss: 0.398946; batch adversarial loss: 0.544874\n",
      "epoch 106; iter: 0; batch classifier loss: 0.360857; batch adversarial loss: 0.581126\n",
      "epoch 107; iter: 0; batch classifier loss: 0.377397; batch adversarial loss: 0.526168\n",
      "epoch 108; iter: 0; batch classifier loss: 0.407966; batch adversarial loss: 0.598831\n",
      "epoch 109; iter: 0; batch classifier loss: 0.287951; batch adversarial loss: 0.544653\n",
      "epoch 110; iter: 0; batch classifier loss: 0.286726; batch adversarial loss: 0.563373\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 111; iter: 0; batch classifier loss: 0.426303; batch adversarial loss: 0.572087\n",
      "epoch 112; iter: 0; batch classifier loss: 0.389619; batch adversarial loss: 0.499234\n",
      "epoch 113; iter: 0; batch classifier loss: 0.362054; batch adversarial loss: 0.471366\n",
      "epoch 114; iter: 0; batch classifier loss: 0.361191; batch adversarial loss: 0.499234\n",
      "epoch 115; iter: 0; batch classifier loss: 0.328301; batch adversarial loss: 0.471345\n",
      "epoch 116; iter: 0; batch classifier loss: 0.415552; batch adversarial loss: 0.581044\n",
      "epoch 117; iter: 0; batch classifier loss: 0.421182; batch adversarial loss: 0.535354\n",
      "epoch 118; iter: 0; batch classifier loss: 0.350996; batch adversarial loss: 0.507636\n",
      "epoch 119; iter: 0; batch classifier loss: 0.384288; batch adversarial loss: 0.508451\n",
      "epoch 120; iter: 0; batch classifier loss: 0.355922; batch adversarial loss: 0.499230\n",
      "epoch 121; iter: 0; batch classifier loss: 0.378039; batch adversarial loss: 0.553852\n",
      "epoch 122; iter: 0; batch classifier loss: 0.415917; batch adversarial loss: 0.572858\n",
      "epoch 123; iter: 0; batch classifier loss: 0.377763; batch adversarial loss: 0.517609\n",
      "epoch 124; iter: 0; batch classifier loss: 0.343743; batch adversarial loss: 0.563022\n",
      "epoch 125; iter: 0; batch classifier loss: 0.295222; batch adversarial loss: 0.617597\n",
      "epoch 126; iter: 0; batch classifier loss: 0.368723; batch adversarial loss: 0.517335\n",
      "epoch 127; iter: 0; batch classifier loss: 0.345735; batch adversarial loss: 0.489266\n",
      "epoch 128; iter: 0; batch classifier loss: 0.415378; batch adversarial loss: 0.544177\n",
      "epoch 129; iter: 0; batch classifier loss: 0.295483; batch adversarial loss: 0.607986\n",
      "epoch 130; iter: 0; batch classifier loss: 0.443976; batch adversarial loss: 0.553067\n",
      "epoch 131; iter: 0; batch classifier loss: 0.349039; batch adversarial loss: 0.499777\n",
      "epoch 132; iter: 0; batch classifier loss: 0.375868; batch adversarial loss: 0.581510\n",
      "epoch 133; iter: 0; batch classifier loss: 0.335660; batch adversarial loss: 0.617038\n",
      "epoch 134; iter: 0; batch classifier loss: 0.331153; batch adversarial loss: 0.663071\n",
      "epoch 135; iter: 0; batch classifier loss: 0.319828; batch adversarial loss: 0.572191\n",
      "epoch 136; iter: 0; batch classifier loss: 0.351308; batch adversarial loss: 0.617020\n",
      "epoch 137; iter: 0; batch classifier loss: 0.396935; batch adversarial loss: 0.552373\n",
      "epoch 138; iter: 0; batch classifier loss: 0.403393; batch adversarial loss: 0.499564\n",
      "epoch 139; iter: 0; batch classifier loss: 0.325627; batch adversarial loss: 0.535490\n",
      "epoch 140; iter: 0; batch classifier loss: 0.394868; batch adversarial loss: 0.552754\n",
      "epoch 141; iter: 0; batch classifier loss: 0.351186; batch adversarial loss: 0.581173\n",
      "epoch 142; iter: 0; batch classifier loss: 0.351505; batch adversarial loss: 0.508267\n",
      "epoch 143; iter: 0; batch classifier loss: 0.370926; batch adversarial loss: 0.545024\n",
      "epoch 144; iter: 0; batch classifier loss: 0.346986; batch adversarial loss: 0.598821\n",
      "epoch 145; iter: 0; batch classifier loss: 0.380429; batch adversarial loss: 0.481406\n",
      "epoch 146; iter: 0; batch classifier loss: 0.404395; batch adversarial loss: 0.627240\n",
      "epoch 147; iter: 0; batch classifier loss: 0.338992; batch adversarial loss: 0.508801\n",
      "epoch 148; iter: 0; batch classifier loss: 0.411748; batch adversarial loss: 0.498175\n",
      "epoch 149; iter: 0; batch classifier loss: 0.267124; batch adversarial loss: 0.553417\n",
      "epoch 150; iter: 0; batch classifier loss: 0.309701; batch adversarial loss: 0.554323\n",
      "epoch 151; iter: 0; batch classifier loss: 0.448398; batch adversarial loss: 0.544238\n",
      "epoch 152; iter: 0; batch classifier loss: 0.348516; batch adversarial loss: 0.516348\n",
      "epoch 153; iter: 0; batch classifier loss: 0.407387; batch adversarial loss: 0.590250\n",
      "epoch 154; iter: 0; batch classifier loss: 0.404069; batch adversarial loss: 0.516239\n",
      "epoch 155; iter: 0; batch classifier loss: 0.335948; batch adversarial loss: 0.554044\n",
      "epoch 156; iter: 0; batch classifier loss: 0.330170; batch adversarial loss: 0.571430\n",
      "epoch 157; iter: 0; batch classifier loss: 0.359603; batch adversarial loss: 0.481101\n",
      "epoch 158; iter: 0; batch classifier loss: 0.375590; batch adversarial loss: 0.561754\n",
      "epoch 159; iter: 0; batch classifier loss: 0.319845; batch adversarial loss: 0.571492\n",
      "epoch 160; iter: 0; batch classifier loss: 0.299201; batch adversarial loss: 0.599394\n",
      "epoch 161; iter: 0; batch classifier loss: 0.261721; batch adversarial loss: 0.544754\n",
      "epoch 162; iter: 0; batch classifier loss: 0.410032; batch adversarial loss: 0.552772\n",
      "epoch 163; iter: 0; batch classifier loss: 0.380039; batch adversarial loss: 0.545558\n",
      "epoch 164; iter: 0; batch classifier loss: 0.333150; batch adversarial loss: 0.681084\n",
      "epoch 165; iter: 0; batch classifier loss: 0.324937; batch adversarial loss: 0.590380\n",
      "epoch 166; iter: 0; batch classifier loss: 0.347190; batch adversarial loss: 0.489285\n",
      "epoch 167; iter: 0; batch classifier loss: 0.337467; batch adversarial loss: 0.535071\n",
      "epoch 168; iter: 0; batch classifier loss: 0.363424; batch adversarial loss: 0.517207\n",
      "epoch 169; iter: 0; batch classifier loss: 0.351250; batch adversarial loss: 0.553284\n",
      "epoch 170; iter: 0; batch classifier loss: 0.366391; batch adversarial loss: 0.517639\n",
      "epoch 171; iter: 0; batch classifier loss: 0.345560; batch adversarial loss: 0.499118\n",
      "epoch 172; iter: 0; batch classifier loss: 0.359552; batch adversarial loss: 0.535286\n",
      "epoch 173; iter: 0; batch classifier loss: 0.235985; batch adversarial loss: 0.453142\n",
      "epoch 174; iter: 0; batch classifier loss: 0.305009; batch adversarial loss: 0.526549\n",
      "epoch 175; iter: 0; batch classifier loss: 0.364677; batch adversarial loss: 0.562747\n",
      "epoch 176; iter: 0; batch classifier loss: 0.270912; batch adversarial loss: 0.554642\n",
      "epoch 177; iter: 0; batch classifier loss: 0.344463; batch adversarial loss: 0.571144\n",
      "epoch 178; iter: 0; batch classifier loss: 0.368088; batch adversarial loss: 0.526441\n",
      "epoch 179; iter: 0; batch classifier loss: 0.324348; batch adversarial loss: 0.464238\n",
      "epoch 180; iter: 0; batch classifier loss: 0.323568; batch adversarial loss: 0.591594\n",
      "epoch 181; iter: 0; batch classifier loss: 0.356385; batch adversarial loss: 0.544058\n",
      "epoch 182; iter: 0; batch classifier loss: 0.299012; batch adversarial loss: 0.489627\n",
      "epoch 183; iter: 0; batch classifier loss: 0.349308; batch adversarial loss: 0.491051\n",
      "epoch 184; iter: 0; batch classifier loss: 0.417651; batch adversarial loss: 0.563013\n",
      "epoch 185; iter: 0; batch classifier loss: 0.371492; batch adversarial loss: 0.544944\n",
      "epoch 186; iter: 0; batch classifier loss: 0.404548; batch adversarial loss: 0.480582\n",
      "epoch 187; iter: 0; batch classifier loss: 0.294442; batch adversarial loss: 0.517453\n",
      "epoch 188; iter: 0; batch classifier loss: 0.388602; batch adversarial loss: 0.544886\n",
      "epoch 189; iter: 0; batch classifier loss: 0.397240; batch adversarial loss: 0.507628\n",
      "epoch 190; iter: 0; batch classifier loss: 0.263878; batch adversarial loss: 0.598543\n",
      "epoch 191; iter: 0; batch classifier loss: 0.328831; batch adversarial loss: 0.617836\n",
      "epoch 192; iter: 0; batch classifier loss: 0.385793; batch adversarial loss: 0.563009\n",
      "epoch 193; iter: 0; batch classifier loss: 0.309861; batch adversarial loss: 0.608294\n",
      "epoch 194; iter: 0; batch classifier loss: 0.256992; batch adversarial loss: 0.553862\n",
      "epoch 195; iter: 0; batch classifier loss: 0.368877; batch adversarial loss: 0.571764\n",
      "epoch 196; iter: 0; batch classifier loss: 0.326844; batch adversarial loss: 0.525495\n",
      "epoch 197; iter: 0; batch classifier loss: 0.378751; batch adversarial loss: 0.571492\n",
      "epoch 198; iter: 0; batch classifier loss: 0.383767; batch adversarial loss: 0.581922\n",
      "epoch 199; iter: 0; batch classifier loss: 0.337513; batch adversarial loss: 0.564169\n",
      "epoch 0; iter: 0; batch classifier loss: 0.687208; batch adversarial loss: 0.725672\n",
      "epoch 1; iter: 0; batch classifier loss: 0.628862; batch adversarial loss: 0.676365\n",
      "epoch 2; iter: 0; batch classifier loss: 0.485329; batch adversarial loss: 0.663878\n",
      "epoch 3; iter: 0; batch classifier loss: 0.542854; batch adversarial loss: 0.664654\n",
      "epoch 4; iter: 0; batch classifier loss: 0.523590; batch adversarial loss: 0.629972\n",
      "epoch 5; iter: 0; batch classifier loss: 0.569229; batch adversarial loss: 0.686121\n",
      "epoch 6; iter: 0; batch classifier loss: 0.465359; batch adversarial loss: 0.596021\n",
      "epoch 7; iter: 0; batch classifier loss: 0.472604; batch adversarial loss: 0.624110\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8; iter: 0; batch classifier loss: 0.521479; batch adversarial loss: 0.567979\n",
      "epoch 9; iter: 0; batch classifier loss: 0.504254; batch adversarial loss: 0.519016\n",
      "epoch 10; iter: 0; batch classifier loss: 0.516714; batch adversarial loss: 0.545009\n",
      "epoch 11; iter: 0; batch classifier loss: 0.518702; batch adversarial loss: 0.602798\n",
      "epoch 12; iter: 0; batch classifier loss: 0.536348; batch adversarial loss: 0.512891\n",
      "epoch 13; iter: 0; batch classifier loss: 0.500104; batch adversarial loss: 0.538118\n",
      "epoch 14; iter: 0; batch classifier loss: 0.465894; batch adversarial loss: 0.514107\n",
      "epoch 15; iter: 0; batch classifier loss: 0.414514; batch adversarial loss: 0.549844\n",
      "epoch 16; iter: 0; batch classifier loss: 0.432880; batch adversarial loss: 0.536522\n",
      "epoch 17; iter: 0; batch classifier loss: 0.409281; batch adversarial loss: 0.567986\n",
      "epoch 18; iter: 0; batch classifier loss: 0.526003; batch adversarial loss: 0.537993\n",
      "epoch 19; iter: 0; batch classifier loss: 0.474022; batch adversarial loss: 0.531998\n",
      "epoch 20; iter: 0; batch classifier loss: 0.539905; batch adversarial loss: 0.537483\n",
      "epoch 21; iter: 0; batch classifier loss: 0.452457; batch adversarial loss: 0.538256\n",
      "epoch 22; iter: 0; batch classifier loss: 0.425129; batch adversarial loss: 0.604456\n",
      "epoch 23; iter: 0; batch classifier loss: 0.468767; batch adversarial loss: 0.505529\n",
      "epoch 24; iter: 0; batch classifier loss: 0.397401; batch adversarial loss: 0.575140\n",
      "epoch 25; iter: 0; batch classifier loss: 0.435395; batch adversarial loss: 0.568356\n",
      "epoch 26; iter: 0; batch classifier loss: 0.564484; batch adversarial loss: 0.537976\n",
      "epoch 27; iter: 0; batch classifier loss: 0.483582; batch adversarial loss: 0.494322\n",
      "epoch 28; iter: 0; batch classifier loss: 0.451155; batch adversarial loss: 0.619424\n",
      "epoch 29; iter: 0; batch classifier loss: 0.402184; batch adversarial loss: 0.565079\n",
      "epoch 30; iter: 0; batch classifier loss: 0.456468; batch adversarial loss: 0.582216\n",
      "epoch 31; iter: 0; batch classifier loss: 0.422523; batch adversarial loss: 0.564873\n",
      "epoch 32; iter: 0; batch classifier loss: 0.495035; batch adversarial loss: 0.528212\n",
      "epoch 33; iter: 0; batch classifier loss: 0.500373; batch adversarial loss: 0.538539\n",
      "epoch 34; iter: 0; batch classifier loss: 0.427562; batch adversarial loss: 0.524708\n",
      "epoch 35; iter: 0; batch classifier loss: 0.468066; batch adversarial loss: 0.622146\n",
      "epoch 36; iter: 0; batch classifier loss: 0.469398; batch adversarial loss: 0.546480\n",
      "epoch 37; iter: 0; batch classifier loss: 0.482858; batch adversarial loss: 0.571596\n",
      "epoch 38; iter: 0; batch classifier loss: 0.448907; batch adversarial loss: 0.563051\n",
      "epoch 39; iter: 0; batch classifier loss: 0.425798; batch adversarial loss: 0.499183\n",
      "epoch 40; iter: 0; batch classifier loss: 0.406414; batch adversarial loss: 0.482004\n",
      "epoch 41; iter: 0; batch classifier loss: 0.460589; batch adversarial loss: 0.490357\n",
      "epoch 42; iter: 0; batch classifier loss: 0.468410; batch adversarial loss: 0.699339\n",
      "epoch 43; iter: 0; batch classifier loss: 0.427514; batch adversarial loss: 0.526365\n",
      "epoch 44; iter: 0; batch classifier loss: 0.375294; batch adversarial loss: 0.544458\n",
      "epoch 45; iter: 0; batch classifier loss: 0.426062; batch adversarial loss: 0.654321\n",
      "epoch 46; iter: 0; batch classifier loss: 0.422056; batch adversarial loss: 0.553685\n",
      "epoch 47; iter: 0; batch classifier loss: 0.407996; batch adversarial loss: 0.544346\n",
      "epoch 48; iter: 0; batch classifier loss: 0.409237; batch adversarial loss: 0.497199\n",
      "epoch 49; iter: 0; batch classifier loss: 0.333841; batch adversarial loss: 0.554139\n",
      "epoch 50; iter: 0; batch classifier loss: 0.406738; batch adversarial loss: 0.553098\n",
      "epoch 51; iter: 0; batch classifier loss: 0.404481; batch adversarial loss: 0.590019\n",
      "epoch 52; iter: 0; batch classifier loss: 0.474773; batch adversarial loss: 0.535938\n",
      "epoch 53; iter: 0; batch classifier loss: 0.409927; batch adversarial loss: 0.601320\n",
      "epoch 54; iter: 0; batch classifier loss: 0.347848; batch adversarial loss: 0.498372\n",
      "epoch 55; iter: 0; batch classifier loss: 0.426512; batch adversarial loss: 0.480425\n",
      "epoch 56; iter: 0; batch classifier loss: 0.449124; batch adversarial loss: 0.553405\n",
      "epoch 57; iter: 0; batch classifier loss: 0.410253; batch adversarial loss: 0.581592\n",
      "epoch 58; iter: 0; batch classifier loss: 0.497878; batch adversarial loss: 0.508211\n",
      "epoch 59; iter: 0; batch classifier loss: 0.356114; batch adversarial loss: 0.413432\n",
      "epoch 60; iter: 0; batch classifier loss: 0.444892; batch adversarial loss: 0.543973\n",
      "epoch 61; iter: 0; batch classifier loss: 0.441558; batch adversarial loss: 0.571579\n",
      "epoch 62; iter: 0; batch classifier loss: 0.429518; batch adversarial loss: 0.571933\n",
      "epoch 63; iter: 0; batch classifier loss: 0.420860; batch adversarial loss: 0.545572\n",
      "epoch 64; iter: 0; batch classifier loss: 0.350505; batch adversarial loss: 0.638056\n",
      "epoch 65; iter: 0; batch classifier loss: 0.366271; batch adversarial loss: 0.590358\n",
      "epoch 66; iter: 0; batch classifier loss: 0.409140; batch adversarial loss: 0.573393\n",
      "epoch 67; iter: 0; batch classifier loss: 0.423162; batch adversarial loss: 0.554481\n",
      "epoch 68; iter: 0; batch classifier loss: 0.348504; batch adversarial loss: 0.516193\n",
      "epoch 69; iter: 0; batch classifier loss: 0.452850; batch adversarial loss: 0.563809\n",
      "epoch 70; iter: 0; batch classifier loss: 0.468909; batch adversarial loss: 0.562869\n",
      "epoch 71; iter: 0; batch classifier loss: 0.433023; batch adversarial loss: 0.468624\n",
      "epoch 72; iter: 0; batch classifier loss: 0.381284; batch adversarial loss: 0.498060\n",
      "epoch 73; iter: 0; batch classifier loss: 0.461949; batch adversarial loss: 0.479603\n",
      "epoch 74; iter: 0; batch classifier loss: 0.346533; batch adversarial loss: 0.535735\n",
      "epoch 75; iter: 0; batch classifier loss: 0.442873; batch adversarial loss: 0.517032\n",
      "epoch 76; iter: 0; batch classifier loss: 0.336946; batch adversarial loss: 0.620351\n",
      "epoch 77; iter: 0; batch classifier loss: 0.367528; batch adversarial loss: 0.656757\n",
      "epoch 78; iter: 0; batch classifier loss: 0.407046; batch adversarial loss: 0.544747\n",
      "epoch 79; iter: 0; batch classifier loss: 0.418502; batch adversarial loss: 0.515837\n",
      "epoch 80; iter: 0; batch classifier loss: 0.384901; batch adversarial loss: 0.535366\n",
      "epoch 81; iter: 0; batch classifier loss: 0.353384; batch adversarial loss: 0.544262\n",
      "epoch 82; iter: 0; batch classifier loss: 0.457360; batch adversarial loss: 0.553809\n",
      "epoch 83; iter: 0; batch classifier loss: 0.387026; batch adversarial loss: 0.628411\n",
      "epoch 84; iter: 0; batch classifier loss: 0.299588; batch adversarial loss: 0.571936\n",
      "epoch 85; iter: 0; batch classifier loss: 0.323819; batch adversarial loss: 0.581105\n",
      "epoch 86; iter: 0; batch classifier loss: 0.322358; batch adversarial loss: 0.554218\n",
      "epoch 87; iter: 0; batch classifier loss: 0.395093; batch adversarial loss: 0.506984\n",
      "epoch 88; iter: 0; batch classifier loss: 0.460577; batch adversarial loss: 0.535500\n",
      "epoch 89; iter: 0; batch classifier loss: 0.432612; batch adversarial loss: 0.497038\n",
      "epoch 90; iter: 0; batch classifier loss: 0.381326; batch adversarial loss: 0.609745\n",
      "epoch 91; iter: 0; batch classifier loss: 0.407481; batch adversarial loss: 0.525493\n",
      "epoch 92; iter: 0; batch classifier loss: 0.356403; batch adversarial loss: 0.581369\n",
      "epoch 93; iter: 0; batch classifier loss: 0.438612; batch adversarial loss: 0.533267\n",
      "epoch 94; iter: 0; batch classifier loss: 0.373400; batch adversarial loss: 0.542733\n",
      "epoch 95; iter: 0; batch classifier loss: 0.417430; batch adversarial loss: 0.507763\n",
      "epoch 96; iter: 0; batch classifier loss: 0.389216; batch adversarial loss: 0.535328\n",
      "epoch 97; iter: 0; batch classifier loss: 0.402071; batch adversarial loss: 0.526615\n",
      "epoch 98; iter: 0; batch classifier loss: 0.406033; batch adversarial loss: 0.544520\n",
      "epoch 99; iter: 0; batch classifier loss: 0.358330; batch adversarial loss: 0.554635\n",
      "epoch 100; iter: 0; batch classifier loss: 0.375777; batch adversarial loss: 0.507301\n",
      "epoch 101; iter: 0; batch classifier loss: 0.420421; batch adversarial loss: 0.505969\n",
      "epoch 102; iter: 0; batch classifier loss: 0.398396; batch adversarial loss: 0.525986\n",
      "epoch 103; iter: 0; batch classifier loss: 0.398008; batch adversarial loss: 0.618222\n",
      "epoch 104; iter: 0; batch classifier loss: 0.382900; batch adversarial loss: 0.516042\n",
      "epoch 105; iter: 0; batch classifier loss: 0.396077; batch adversarial loss: 0.507439\n",
      "epoch 106; iter: 0; batch classifier loss: 0.338765; batch adversarial loss: 0.544536\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 107; iter: 0; batch classifier loss: 0.344370; batch adversarial loss: 0.451887\n",
      "epoch 108; iter: 0; batch classifier loss: 0.420686; batch adversarial loss: 0.573946\n",
      "epoch 109; iter: 0; batch classifier loss: 0.419806; batch adversarial loss: 0.563919\n",
      "epoch 110; iter: 0; batch classifier loss: 0.459783; batch adversarial loss: 0.563118\n",
      "epoch 111; iter: 0; batch classifier loss: 0.341023; batch adversarial loss: 0.534737\n",
      "epoch 112; iter: 0; batch classifier loss: 0.344653; batch adversarial loss: 0.543399\n",
      "epoch 113; iter: 0; batch classifier loss: 0.324495; batch adversarial loss: 0.535644\n",
      "epoch 114; iter: 0; batch classifier loss: 0.366366; batch adversarial loss: 0.551628\n",
      "epoch 115; iter: 0; batch classifier loss: 0.417034; batch adversarial loss: 0.544648\n",
      "epoch 116; iter: 0; batch classifier loss: 0.278701; batch adversarial loss: 0.581713\n",
      "epoch 117; iter: 0; batch classifier loss: 0.308235; batch adversarial loss: 0.526046\n",
      "epoch 118; iter: 0; batch classifier loss: 0.386806; batch adversarial loss: 0.453587\n",
      "epoch 119; iter: 0; batch classifier loss: 0.307797; batch adversarial loss: 0.581027\n",
      "epoch 120; iter: 0; batch classifier loss: 0.337015; batch adversarial loss: 0.535547\n",
      "epoch 121; iter: 0; batch classifier loss: 0.403456; batch adversarial loss: 0.572421\n",
      "epoch 122; iter: 0; batch classifier loss: 0.387998; batch adversarial loss: 0.590014\n",
      "epoch 123; iter: 0; batch classifier loss: 0.411338; batch adversarial loss: 0.479444\n",
      "epoch 124; iter: 0; batch classifier loss: 0.331324; batch adversarial loss: 0.572288\n",
      "epoch 125; iter: 0; batch classifier loss: 0.371933; batch adversarial loss: 0.544201\n",
      "epoch 126; iter: 0; batch classifier loss: 0.375316; batch adversarial loss: 0.486889\n",
      "epoch 127; iter: 0; batch classifier loss: 0.361010; batch adversarial loss: 0.518241\n",
      "epoch 128; iter: 0; batch classifier loss: 0.321462; batch adversarial loss: 0.657402\n",
      "epoch 129; iter: 0; batch classifier loss: 0.307569; batch adversarial loss: 0.590572\n",
      "epoch 130; iter: 0; batch classifier loss: 0.494314; batch adversarial loss: 0.600907\n",
      "epoch 131; iter: 0; batch classifier loss: 0.369710; batch adversarial loss: 0.554045\n",
      "epoch 132; iter: 0; batch classifier loss: 0.395867; batch adversarial loss: 0.478614\n",
      "epoch 133; iter: 0; batch classifier loss: 0.353951; batch adversarial loss: 0.478027\n",
      "epoch 134; iter: 0; batch classifier loss: 0.363054; batch adversarial loss: 0.478232\n",
      "epoch 135; iter: 0; batch classifier loss: 0.438229; batch adversarial loss: 0.517030\n",
      "epoch 136; iter: 0; batch classifier loss: 0.306963; batch adversarial loss: 0.486875\n",
      "epoch 137; iter: 0; batch classifier loss: 0.363596; batch adversarial loss: 0.589634\n",
      "epoch 138; iter: 0; batch classifier loss: 0.294829; batch adversarial loss: 0.525666\n",
      "epoch 139; iter: 0; batch classifier loss: 0.408526; batch adversarial loss: 0.543783\n",
      "epoch 140; iter: 0; batch classifier loss: 0.350108; batch adversarial loss: 0.507650\n",
      "epoch 141; iter: 0; batch classifier loss: 0.297499; batch adversarial loss: 0.534637\n",
      "epoch 142; iter: 0; batch classifier loss: 0.426151; batch adversarial loss: 0.583089\n",
      "epoch 143; iter: 0; batch classifier loss: 0.414006; batch adversarial loss: 0.498073\n",
      "epoch 144; iter: 0; batch classifier loss: 0.340215; batch adversarial loss: 0.498013\n",
      "epoch 145; iter: 0; batch classifier loss: 0.240211; batch adversarial loss: 0.629227\n",
      "epoch 146; iter: 0; batch classifier loss: 0.425542; batch adversarial loss: 0.526182\n",
      "epoch 147; iter: 0; batch classifier loss: 0.269413; batch adversarial loss: 0.516020\n",
      "epoch 148; iter: 0; batch classifier loss: 0.339644; batch adversarial loss: 0.526001\n",
      "epoch 149; iter: 0; batch classifier loss: 0.366068; batch adversarial loss: 0.572029\n",
      "epoch 150; iter: 0; batch classifier loss: 0.365671; batch adversarial loss: 0.488448\n",
      "epoch 151; iter: 0; batch classifier loss: 0.254444; batch adversarial loss: 0.581480\n",
      "epoch 152; iter: 0; batch classifier loss: 0.326053; batch adversarial loss: 0.592116\n",
      "epoch 153; iter: 0; batch classifier loss: 0.357463; batch adversarial loss: 0.516227\n",
      "epoch 154; iter: 0; batch classifier loss: 0.421249; batch adversarial loss: 0.534615\n",
      "epoch 155; iter: 0; batch classifier loss: 0.307883; batch adversarial loss: 0.618768\n",
      "epoch 156; iter: 0; batch classifier loss: 0.376192; batch adversarial loss: 0.573446\n",
      "epoch 157; iter: 0; batch classifier loss: 0.416253; batch adversarial loss: 0.544142\n",
      "epoch 158; iter: 0; batch classifier loss: 0.361532; batch adversarial loss: 0.544108\n",
      "epoch 159; iter: 0; batch classifier loss: 0.394442; batch adversarial loss: 0.544026\n",
      "epoch 160; iter: 0; batch classifier loss: 0.320695; batch adversarial loss: 0.506933\n",
      "epoch 161; iter: 0; batch classifier loss: 0.344146; batch adversarial loss: 0.479409\n",
      "epoch 162; iter: 0; batch classifier loss: 0.408385; batch adversarial loss: 0.497672\n",
      "epoch 163; iter: 0; batch classifier loss: 0.344647; batch adversarial loss: 0.609988\n",
      "epoch 164; iter: 0; batch classifier loss: 0.316454; batch adversarial loss: 0.610317\n",
      "epoch 165; iter: 0; batch classifier loss: 0.334951; batch adversarial loss: 0.543976\n",
      "epoch 166; iter: 0; batch classifier loss: 0.277523; batch adversarial loss: 0.601010\n",
      "epoch 167; iter: 0; batch classifier loss: 0.432205; batch adversarial loss: 0.581369\n",
      "epoch 168; iter: 0; batch classifier loss: 0.385273; batch adversarial loss: 0.544978\n",
      "epoch 169; iter: 0; batch classifier loss: 0.417792; batch adversarial loss: 0.554518\n",
      "epoch 170; iter: 0; batch classifier loss: 0.303381; batch adversarial loss: 0.554901\n",
      "epoch 171; iter: 0; batch classifier loss: 0.457808; batch adversarial loss: 0.599333\n",
      "epoch 172; iter: 0; batch classifier loss: 0.307974; batch adversarial loss: 0.442285\n",
      "epoch 173; iter: 0; batch classifier loss: 0.337945; batch adversarial loss: 0.618752\n",
      "epoch 174; iter: 0; batch classifier loss: 0.357683; batch adversarial loss: 0.497323\n",
      "epoch 175; iter: 0; batch classifier loss: 0.341411; batch adversarial loss: 0.553827\n",
      "epoch 176; iter: 0; batch classifier loss: 0.338513; batch adversarial loss: 0.554677\n",
      "epoch 177; iter: 0; batch classifier loss: 0.395135; batch adversarial loss: 0.507533\n",
      "epoch 178; iter: 0; batch classifier loss: 0.328433; batch adversarial loss: 0.580570\n",
      "epoch 179; iter: 0; batch classifier loss: 0.329750; batch adversarial loss: 0.599367\n",
      "epoch 180; iter: 0; batch classifier loss: 0.367109; batch adversarial loss: 0.535142\n",
      "epoch 181; iter: 0; batch classifier loss: 0.352095; batch adversarial loss: 0.598750\n",
      "epoch 182; iter: 0; batch classifier loss: 0.372634; batch adversarial loss: 0.572559\n",
      "epoch 183; iter: 0; batch classifier loss: 0.340436; batch adversarial loss: 0.535424\n",
      "epoch 184; iter: 0; batch classifier loss: 0.328090; batch adversarial loss: 0.516106\n",
      "epoch 185; iter: 0; batch classifier loss: 0.436275; batch adversarial loss: 0.536640\n",
      "epoch 186; iter: 0; batch classifier loss: 0.340813; batch adversarial loss: 0.544236\n",
      "epoch 187; iter: 0; batch classifier loss: 0.321228; batch adversarial loss: 0.535746\n",
      "epoch 188; iter: 0; batch classifier loss: 0.371101; batch adversarial loss: 0.656856\n",
      "epoch 189; iter: 0; batch classifier loss: 0.311160; batch adversarial loss: 0.582636\n",
      "epoch 190; iter: 0; batch classifier loss: 0.306279; batch adversarial loss: 0.581022\n",
      "epoch 191; iter: 0; batch classifier loss: 0.366666; batch adversarial loss: 0.572778\n",
      "epoch 192; iter: 0; batch classifier loss: 0.371026; batch adversarial loss: 0.497165\n",
      "epoch 193; iter: 0; batch classifier loss: 0.383892; batch adversarial loss: 0.563332\n",
      "epoch 194; iter: 0; batch classifier loss: 0.297923; batch adversarial loss: 0.506763\n",
      "epoch 195; iter: 0; batch classifier loss: 0.354260; batch adversarial loss: 0.545377\n",
      "epoch 196; iter: 0; batch classifier loss: 0.344367; batch adversarial loss: 0.534521\n",
      "epoch 197; iter: 0; batch classifier loss: 0.358201; batch adversarial loss: 0.582359\n",
      "epoch 198; iter: 0; batch classifier loss: 0.274920; batch adversarial loss: 0.516148\n",
      "epoch 199; iter: 0; batch classifier loss: 0.386875; batch adversarial loss: 0.535102\n",
      "epoch 0; iter: 0; batch classifier loss: 0.818776; batch adversarial loss: 0.977205\n",
      "epoch 1; iter: 0; batch classifier loss: 0.684726; batch adversarial loss: 0.991457\n",
      "epoch 2; iter: 0; batch classifier loss: 0.776839; batch adversarial loss: 0.963447\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3; iter: 0; batch classifier loss: 0.741388; batch adversarial loss: 0.917165\n",
      "epoch 4; iter: 0; batch classifier loss: 0.803384; batch adversarial loss: 0.807355\n",
      "epoch 5; iter: 0; batch classifier loss: 0.628977; batch adversarial loss: 0.734825\n",
      "epoch 6; iter: 0; batch classifier loss: 0.622994; batch adversarial loss: 0.688774\n",
      "epoch 7; iter: 0; batch classifier loss: 0.539851; batch adversarial loss: 0.657563\n",
      "epoch 8; iter: 0; batch classifier loss: 0.559632; batch adversarial loss: 0.623000\n",
      "epoch 9; iter: 0; batch classifier loss: 0.589808; batch adversarial loss: 0.597735\n",
      "epoch 10; iter: 0; batch classifier loss: 0.486705; batch adversarial loss: 0.628078\n",
      "epoch 11; iter: 0; batch classifier loss: 0.530483; batch adversarial loss: 0.588166\n",
      "epoch 12; iter: 0; batch classifier loss: 0.484517; batch adversarial loss: 0.592304\n",
      "epoch 13; iter: 0; batch classifier loss: 0.571042; batch adversarial loss: 0.563890\n",
      "epoch 14; iter: 0; batch classifier loss: 0.431704; batch adversarial loss: 0.668051\n",
      "epoch 15; iter: 0; batch classifier loss: 0.556920; batch adversarial loss: 0.586609\n",
      "epoch 16; iter: 0; batch classifier loss: 0.519343; batch adversarial loss: 0.581142\n",
      "epoch 17; iter: 0; batch classifier loss: 0.479679; batch adversarial loss: 0.545052\n",
      "epoch 18; iter: 0; batch classifier loss: 0.450454; batch adversarial loss: 0.546699\n",
      "epoch 19; iter: 0; batch classifier loss: 0.450487; batch adversarial loss: 0.599588\n",
      "epoch 20; iter: 0; batch classifier loss: 0.596837; batch adversarial loss: 0.552274\n",
      "epoch 21; iter: 0; batch classifier loss: 0.551884; batch adversarial loss: 0.583239\n",
      "epoch 22; iter: 0; batch classifier loss: 0.498791; batch adversarial loss: 0.662670\n",
      "epoch 23; iter: 0; batch classifier loss: 0.474816; batch adversarial loss: 0.545230\n",
      "epoch 24; iter: 0; batch classifier loss: 0.507963; batch adversarial loss: 0.572501\n",
      "epoch 25; iter: 0; batch classifier loss: 0.490219; batch adversarial loss: 0.621383\n",
      "epoch 26; iter: 0; batch classifier loss: 0.526245; batch adversarial loss: 0.539540\n",
      "epoch 27; iter: 0; batch classifier loss: 0.574926; batch adversarial loss: 0.534961\n",
      "epoch 28; iter: 0; batch classifier loss: 0.428724; batch adversarial loss: 0.572601\n",
      "epoch 29; iter: 0; batch classifier loss: 0.452787; batch adversarial loss: 0.526269\n",
      "epoch 30; iter: 0; batch classifier loss: 0.485927; batch adversarial loss: 0.616645\n",
      "epoch 31; iter: 0; batch classifier loss: 0.509055; batch adversarial loss: 0.561804\n",
      "epoch 32; iter: 0; batch classifier loss: 0.470026; batch adversarial loss: 0.547739\n",
      "epoch 33; iter: 0; batch classifier loss: 0.450610; batch adversarial loss: 0.469403\n",
      "epoch 34; iter: 0; batch classifier loss: 0.517811; batch adversarial loss: 0.544799\n",
      "epoch 35; iter: 0; batch classifier loss: 0.439521; batch adversarial loss: 0.490482\n",
      "epoch 36; iter: 0; batch classifier loss: 0.432462; batch adversarial loss: 0.560257\n",
      "epoch 37; iter: 0; batch classifier loss: 0.559357; batch adversarial loss: 0.528471\n",
      "epoch 38; iter: 0; batch classifier loss: 0.420315; batch adversarial loss: 0.619415\n",
      "epoch 39; iter: 0; batch classifier loss: 0.493778; batch adversarial loss: 0.541623\n",
      "epoch 40; iter: 0; batch classifier loss: 0.443380; batch adversarial loss: 0.560754\n",
      "epoch 41; iter: 0; batch classifier loss: 0.422151; batch adversarial loss: 0.568833\n",
      "epoch 42; iter: 0; batch classifier loss: 0.462197; batch adversarial loss: 0.515927\n",
      "epoch 43; iter: 0; batch classifier loss: 0.477865; batch adversarial loss: 0.638681\n",
      "epoch 44; iter: 0; batch classifier loss: 0.414450; batch adversarial loss: 0.570337\n",
      "epoch 45; iter: 0; batch classifier loss: 0.373082; batch adversarial loss: 0.615265\n",
      "epoch 46; iter: 0; batch classifier loss: 0.477521; batch adversarial loss: 0.566858\n",
      "epoch 47; iter: 0; batch classifier loss: 0.406669; batch adversarial loss: 0.552793\n",
      "epoch 48; iter: 0; batch classifier loss: 0.403006; batch adversarial loss: 0.537341\n",
      "epoch 49; iter: 0; batch classifier loss: 0.411641; batch adversarial loss: 0.584233\n",
      "epoch 50; iter: 0; batch classifier loss: 0.431072; batch adversarial loss: 0.547437\n",
      "epoch 51; iter: 0; batch classifier loss: 0.403263; batch adversarial loss: 0.622625\n",
      "epoch 52; iter: 0; batch classifier loss: 0.416582; batch adversarial loss: 0.473667\n",
      "epoch 53; iter: 0; batch classifier loss: 0.380582; batch adversarial loss: 0.499983\n",
      "epoch 54; iter: 0; batch classifier loss: 0.427793; batch adversarial loss: 0.499301\n",
      "epoch 55; iter: 0; batch classifier loss: 0.445271; batch adversarial loss: 0.533952\n",
      "epoch 56; iter: 0; batch classifier loss: 0.394684; batch adversarial loss: 0.546033\n",
      "epoch 57; iter: 0; batch classifier loss: 0.471613; batch adversarial loss: 0.519795\n",
      "epoch 58; iter: 0; batch classifier loss: 0.391059; batch adversarial loss: 0.499742\n",
      "epoch 59; iter: 0; batch classifier loss: 0.410139; batch adversarial loss: 0.597030\n",
      "epoch 60; iter: 0; batch classifier loss: 0.436129; batch adversarial loss: 0.554478\n",
      "epoch 61; iter: 0; batch classifier loss: 0.411077; batch adversarial loss: 0.542562\n",
      "epoch 62; iter: 0; batch classifier loss: 0.334485; batch adversarial loss: 0.497096\n",
      "epoch 63; iter: 0; batch classifier loss: 0.435561; batch adversarial loss: 0.589047\n",
      "epoch 64; iter: 0; batch classifier loss: 0.423582; batch adversarial loss: 0.615668\n",
      "epoch 65; iter: 0; batch classifier loss: 0.354419; batch adversarial loss: 0.515940\n",
      "epoch 66; iter: 0; batch classifier loss: 0.457035; batch adversarial loss: 0.556060\n",
      "epoch 67; iter: 0; batch classifier loss: 0.334899; batch adversarial loss: 0.536865\n",
      "epoch 68; iter: 0; batch classifier loss: 0.367164; batch adversarial loss: 0.527811\n",
      "epoch 69; iter: 0; batch classifier loss: 0.374925; batch adversarial loss: 0.526406\n",
      "epoch 70; iter: 0; batch classifier loss: 0.483637; batch adversarial loss: 0.536222\n",
      "epoch 71; iter: 0; batch classifier loss: 0.326636; batch adversarial loss: 0.633846\n",
      "epoch 72; iter: 0; batch classifier loss: 0.371145; batch adversarial loss: 0.599711\n",
      "epoch 73; iter: 0; batch classifier loss: 0.419643; batch adversarial loss: 0.464561\n",
      "epoch 74; iter: 0; batch classifier loss: 0.340661; batch adversarial loss: 0.589127\n",
      "epoch 75; iter: 0; batch classifier loss: 0.348321; batch adversarial loss: 0.535829\n",
      "epoch 76; iter: 0; batch classifier loss: 0.355358; batch adversarial loss: 0.535470\n",
      "epoch 77; iter: 0; batch classifier loss: 0.501184; batch adversarial loss: 0.553406\n",
      "epoch 78; iter: 0; batch classifier loss: 0.394168; batch adversarial loss: 0.526591\n",
      "epoch 79; iter: 0; batch classifier loss: 0.332039; batch adversarial loss: 0.517625\n",
      "epoch 80; iter: 0; batch classifier loss: 0.378941; batch adversarial loss: 0.608128\n",
      "epoch 81; iter: 0; batch classifier loss: 0.473636; batch adversarial loss: 0.599674\n",
      "epoch 82; iter: 0; batch classifier loss: 0.363103; batch adversarial loss: 0.553457\n",
      "epoch 83; iter: 0; batch classifier loss: 0.369738; batch adversarial loss: 0.617576\n",
      "epoch 84; iter: 0; batch classifier loss: 0.393219; batch adversarial loss: 0.507129\n",
      "epoch 85; iter: 0; batch classifier loss: 0.363655; batch adversarial loss: 0.543385\n",
      "epoch 86; iter: 0; batch classifier loss: 0.422265; batch adversarial loss: 0.517545\n",
      "epoch 87; iter: 0; batch classifier loss: 0.335478; batch adversarial loss: 0.562901\n",
      "epoch 88; iter: 0; batch classifier loss: 0.351005; batch adversarial loss: 0.525759\n",
      "epoch 89; iter: 0; batch classifier loss: 0.415572; batch adversarial loss: 0.562809\n",
      "epoch 90; iter: 0; batch classifier loss: 0.388077; batch adversarial loss: 0.590468\n",
      "epoch 91; iter: 0; batch classifier loss: 0.410974; batch adversarial loss: 0.599886\n",
      "epoch 92; iter: 0; batch classifier loss: 0.435027; batch adversarial loss: 0.489602\n",
      "epoch 93; iter: 0; batch classifier loss: 0.330830; batch adversarial loss: 0.590228\n",
      "epoch 94; iter: 0; batch classifier loss: 0.461194; batch adversarial loss: 0.472264\n",
      "epoch 95; iter: 0; batch classifier loss: 0.292873; batch adversarial loss: 0.582056\n",
      "epoch 96; iter: 0; batch classifier loss: 0.438232; batch adversarial loss: 0.544093\n",
      "epoch 97; iter: 0; batch classifier loss: 0.327452; batch adversarial loss: 0.507987\n",
      "epoch 98; iter: 0; batch classifier loss: 0.317161; batch adversarial loss: 0.579962\n",
      "epoch 99; iter: 0; batch classifier loss: 0.541182; batch adversarial loss: 0.562439\n",
      "epoch 100; iter: 0; batch classifier loss: 0.417770; batch adversarial loss: 0.535998\n",
      "epoch 101; iter: 0; batch classifier loss: 0.390675; batch adversarial loss: 0.453949\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 102; iter: 0; batch classifier loss: 0.328367; batch adversarial loss: 0.580931\n",
      "epoch 103; iter: 0; batch classifier loss: 0.336597; batch adversarial loss: 0.554002\n",
      "epoch 104; iter: 0; batch classifier loss: 0.365808; batch adversarial loss: 0.552900\n",
      "epoch 105; iter: 0; batch classifier loss: 0.306655; batch adversarial loss: 0.600504\n",
      "epoch 106; iter: 0; batch classifier loss: 0.333841; batch adversarial loss: 0.518094\n",
      "epoch 107; iter: 0; batch classifier loss: 0.436053; batch adversarial loss: 0.507702\n",
      "epoch 108; iter: 0; batch classifier loss: 0.384207; batch adversarial loss: 0.572523\n",
      "epoch 109; iter: 0; batch classifier loss: 0.401098; batch adversarial loss: 0.552511\n",
      "epoch 110; iter: 0; batch classifier loss: 0.421273; batch adversarial loss: 0.518629\n",
      "epoch 111; iter: 0; batch classifier loss: 0.352982; batch adversarial loss: 0.499247\n",
      "epoch 112; iter: 0; batch classifier loss: 0.317904; batch adversarial loss: 0.653256\n",
      "epoch 113; iter: 0; batch classifier loss: 0.434885; batch adversarial loss: 0.588300\n",
      "epoch 114; iter: 0; batch classifier loss: 0.393731; batch adversarial loss: 0.498443\n",
      "epoch 115; iter: 0; batch classifier loss: 0.462186; batch adversarial loss: 0.589833\n",
      "epoch 116; iter: 0; batch classifier loss: 0.384677; batch adversarial loss: 0.580438\n",
      "epoch 117; iter: 0; batch classifier loss: 0.405624; batch adversarial loss: 0.535090\n",
      "epoch 118; iter: 0; batch classifier loss: 0.360881; batch adversarial loss: 0.526387\n",
      "epoch 119; iter: 0; batch classifier loss: 0.363587; batch adversarial loss: 0.508574\n",
      "epoch 120; iter: 0; batch classifier loss: 0.300762; batch adversarial loss: 0.543860\n",
      "epoch 121; iter: 0; batch classifier loss: 0.367029; batch adversarial loss: 0.491175\n",
      "epoch 122; iter: 0; batch classifier loss: 0.326792; batch adversarial loss: 0.607143\n",
      "epoch 123; iter: 0; batch classifier loss: 0.362204; batch adversarial loss: 0.535560\n",
      "epoch 124; iter: 0; batch classifier loss: 0.411580; batch adversarial loss: 0.507705\n",
      "epoch 125; iter: 0; batch classifier loss: 0.440058; batch adversarial loss: 0.536521\n",
      "epoch 126; iter: 0; batch classifier loss: 0.419975; batch adversarial loss: 0.544382\n",
      "epoch 127; iter: 0; batch classifier loss: 0.334459; batch adversarial loss: 0.562159\n",
      "epoch 128; iter: 0; batch classifier loss: 0.350082; batch adversarial loss: 0.507854\n",
      "epoch 129; iter: 0; batch classifier loss: 0.301072; batch adversarial loss: 0.563679\n",
      "epoch 130; iter: 0; batch classifier loss: 0.389903; batch adversarial loss: 0.509006\n",
      "epoch 131; iter: 0; batch classifier loss: 0.366785; batch adversarial loss: 0.545318\n",
      "epoch 132; iter: 0; batch classifier loss: 0.353756; batch adversarial loss: 0.535647\n",
      "epoch 133; iter: 0; batch classifier loss: 0.341590; batch adversarial loss: 0.571397\n",
      "epoch 134; iter: 0; batch classifier loss: 0.394847; batch adversarial loss: 0.508685\n",
      "epoch 135; iter: 0; batch classifier loss: 0.400643; batch adversarial loss: 0.545901\n",
      "epoch 136; iter: 0; batch classifier loss: 0.332741; batch adversarial loss: 0.653386\n",
      "epoch 137; iter: 0; batch classifier loss: 0.379915; batch adversarial loss: 0.571696\n",
      "epoch 138; iter: 0; batch classifier loss: 0.287476; batch adversarial loss: 0.544395\n",
      "epoch 139; iter: 0; batch classifier loss: 0.293808; batch adversarial loss: 0.626065\n",
      "epoch 140; iter: 0; batch classifier loss: 0.390425; batch adversarial loss: 0.516690\n",
      "epoch 141; iter: 0; batch classifier loss: 0.345420; batch adversarial loss: 0.617668\n",
      "epoch 142; iter: 0; batch classifier loss: 0.397990; batch adversarial loss: 0.509073\n",
      "epoch 143; iter: 0; batch classifier loss: 0.387094; batch adversarial loss: 0.616593\n",
      "epoch 144; iter: 0; batch classifier loss: 0.500547; batch adversarial loss: 0.599802\n",
      "epoch 145; iter: 0; batch classifier loss: 0.356080; batch adversarial loss: 0.546057\n",
      "epoch 146; iter: 0; batch classifier loss: 0.369890; batch adversarial loss: 0.582754\n",
      "epoch 147; iter: 0; batch classifier loss: 0.301751; batch adversarial loss: 0.545932\n",
      "epoch 148; iter: 0; batch classifier loss: 0.303495; batch adversarial loss: 0.489924\n",
      "epoch 149; iter: 0; batch classifier loss: 0.371145; batch adversarial loss: 0.598082\n",
      "epoch 150; iter: 0; batch classifier loss: 0.369601; batch adversarial loss: 0.590094\n",
      "epoch 151; iter: 0; batch classifier loss: 0.357445; batch adversarial loss: 0.562890\n",
      "epoch 152; iter: 0; batch classifier loss: 0.374225; batch adversarial loss: 0.625606\n",
      "epoch 153; iter: 0; batch classifier loss: 0.348502; batch adversarial loss: 0.544693\n",
      "epoch 154; iter: 0; batch classifier loss: 0.354185; batch adversarial loss: 0.471193\n",
      "epoch 155; iter: 0; batch classifier loss: 0.321287; batch adversarial loss: 0.616703\n",
      "epoch 156; iter: 0; batch classifier loss: 0.396286; batch adversarial loss: 0.590631\n",
      "epoch 157; iter: 0; batch classifier loss: 0.365631; batch adversarial loss: 0.516058\n",
      "epoch 158; iter: 0; batch classifier loss: 0.366932; batch adversarial loss: 0.489317\n",
      "epoch 159; iter: 0; batch classifier loss: 0.319013; batch adversarial loss: 0.562462\n",
      "epoch 160; iter: 0; batch classifier loss: 0.349476; batch adversarial loss: 0.489216\n",
      "epoch 161; iter: 0; batch classifier loss: 0.399327; batch adversarial loss: 0.544320\n",
      "epoch 162; iter: 0; batch classifier loss: 0.295891; batch adversarial loss: 0.526223\n",
      "epoch 163; iter: 0; batch classifier loss: 0.388585; batch adversarial loss: 0.634205\n",
      "epoch 164; iter: 0; batch classifier loss: 0.361050; batch adversarial loss: 0.608761\n",
      "epoch 165; iter: 0; batch classifier loss: 0.388405; batch adversarial loss: 0.589217\n",
      "epoch 166; iter: 0; batch classifier loss: 0.338530; batch adversarial loss: 0.526582\n",
      "epoch 167; iter: 0; batch classifier loss: 0.401997; batch adversarial loss: 0.535451\n",
      "epoch 168; iter: 0; batch classifier loss: 0.346326; batch adversarial loss: 0.580034\n",
      "epoch 169; iter: 0; batch classifier loss: 0.361635; batch adversarial loss: 0.554942\n",
      "epoch 170; iter: 0; batch classifier loss: 0.305304; batch adversarial loss: 0.508751\n",
      "epoch 171; iter: 0; batch classifier loss: 0.382103; batch adversarial loss: 0.527164\n",
      "epoch 172; iter: 0; batch classifier loss: 0.292923; batch adversarial loss: 0.498612\n",
      "epoch 173; iter: 0; batch classifier loss: 0.344289; batch adversarial loss: 0.490383\n",
      "epoch 174; iter: 0; batch classifier loss: 0.359421; batch adversarial loss: 0.607682\n",
      "epoch 175; iter: 0; batch classifier loss: 0.295010; batch adversarial loss: 0.471622\n",
      "epoch 176; iter: 0; batch classifier loss: 0.312332; batch adversarial loss: 0.581671\n",
      "epoch 177; iter: 0; batch classifier loss: 0.370411; batch adversarial loss: 0.599138\n",
      "epoch 178; iter: 0; batch classifier loss: 0.320627; batch adversarial loss: 0.526693\n",
      "epoch 179; iter: 0; batch classifier loss: 0.425225; batch adversarial loss: 0.454126\n",
      "epoch 180; iter: 0; batch classifier loss: 0.382913; batch adversarial loss: 0.526983\n",
      "epoch 181; iter: 0; batch classifier loss: 0.298076; batch adversarial loss: 0.579839\n",
      "epoch 182; iter: 0; batch classifier loss: 0.318303; batch adversarial loss: 0.607749\n",
      "epoch 183; iter: 0; batch classifier loss: 0.287612; batch adversarial loss: 0.590055\n",
      "epoch 184; iter: 0; batch classifier loss: 0.357281; batch adversarial loss: 0.508012\n",
      "epoch 185; iter: 0; batch classifier loss: 0.346905; batch adversarial loss: 0.562858\n",
      "epoch 186; iter: 0; batch classifier loss: 0.363512; batch adversarial loss: 0.608308\n",
      "epoch 187; iter: 0; batch classifier loss: 0.259342; batch adversarial loss: 0.535772\n",
      "epoch 188; iter: 0; batch classifier loss: 0.364740; batch adversarial loss: 0.554020\n",
      "epoch 189; iter: 0; batch classifier loss: 0.404838; batch adversarial loss: 0.480592\n",
      "epoch 190; iter: 0; batch classifier loss: 0.344127; batch adversarial loss: 0.580458\n",
      "epoch 191; iter: 0; batch classifier loss: 0.325780; batch adversarial loss: 0.589714\n",
      "epoch 192; iter: 0; batch classifier loss: 0.373347; batch adversarial loss: 0.535253\n",
      "epoch 193; iter: 0; batch classifier loss: 0.316867; batch adversarial loss: 0.598838\n",
      "epoch 194; iter: 0; batch classifier loss: 0.351047; batch adversarial loss: 0.526154\n",
      "epoch 195; iter: 0; batch classifier loss: 0.332039; batch adversarial loss: 0.598851\n",
      "epoch 196; iter: 0; batch classifier loss: 0.341627; batch adversarial loss: 0.635684\n",
      "epoch 197; iter: 0; batch classifier loss: 0.436998; batch adversarial loss: 0.589891\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 198; iter: 0; batch classifier loss: 0.311983; batch adversarial loss: 0.508636\n",
      "epoch 199; iter: 0; batch classifier loss: 0.365266; batch adversarial loss: 0.526722\n",
      "epoch 0; iter: 0; batch classifier loss: 0.689118; batch adversarial loss: 0.631257\n",
      "epoch 1; iter: 0; batch classifier loss: 0.622316; batch adversarial loss: 0.652418\n",
      "epoch 2; iter: 0; batch classifier loss: 0.553529; batch adversarial loss: 0.630245\n",
      "epoch 3; iter: 0; batch classifier loss: 0.576510; batch adversarial loss: 0.621156\n",
      "epoch 4; iter: 0; batch classifier loss: 0.602735; batch adversarial loss: 0.612135\n",
      "epoch 5; iter: 0; batch classifier loss: 0.653449; batch adversarial loss: 0.607316\n",
      "epoch 6; iter: 0; batch classifier loss: 0.578243; batch adversarial loss: 0.561318\n",
      "epoch 7; iter: 0; batch classifier loss: 0.622899; batch adversarial loss: 0.616921\n",
      "epoch 8; iter: 0; batch classifier loss: 0.571327; batch adversarial loss: 0.561813\n",
      "epoch 9; iter: 0; batch classifier loss: 0.460044; batch adversarial loss: 0.620948\n",
      "epoch 10; iter: 0; batch classifier loss: 0.533824; batch adversarial loss: 0.525975\n",
      "epoch 11; iter: 0; batch classifier loss: 0.525648; batch adversarial loss: 0.613670\n",
      "epoch 12; iter: 0; batch classifier loss: 0.486436; batch adversarial loss: 0.596501\n",
      "epoch 13; iter: 0; batch classifier loss: 0.538135; batch adversarial loss: 0.562010\n",
      "epoch 14; iter: 0; batch classifier loss: 0.471625; batch adversarial loss: 0.584948\n",
      "epoch 15; iter: 0; batch classifier loss: 0.451624; batch adversarial loss: 0.533880\n",
      "epoch 16; iter: 0; batch classifier loss: 0.511233; batch adversarial loss: 0.556937\n",
      "epoch 17; iter: 0; batch classifier loss: 0.508269; batch adversarial loss: 0.531705\n",
      "epoch 18; iter: 0; batch classifier loss: 0.507198; batch adversarial loss: 0.525921\n",
      "epoch 19; iter: 0; batch classifier loss: 0.512918; batch adversarial loss: 0.603773\n",
      "epoch 20; iter: 0; batch classifier loss: 0.477181; batch adversarial loss: 0.509501\n",
      "epoch 21; iter: 0; batch classifier loss: 0.464357; batch adversarial loss: 0.574727\n",
      "epoch 22; iter: 0; batch classifier loss: 0.397764; batch adversarial loss: 0.625960\n",
      "epoch 23; iter: 0; batch classifier loss: 0.502129; batch adversarial loss: 0.568682\n",
      "epoch 24; iter: 0; batch classifier loss: 0.502017; batch adversarial loss: 0.541551\n",
      "epoch 25; iter: 0; batch classifier loss: 0.428630; batch adversarial loss: 0.417095\n",
      "epoch 26; iter: 0; batch classifier loss: 0.513209; batch adversarial loss: 0.490091\n",
      "epoch 27; iter: 0; batch classifier loss: 0.464492; batch adversarial loss: 0.564176\n",
      "epoch 28; iter: 0; batch classifier loss: 0.486052; batch adversarial loss: 0.520520\n",
      "epoch 29; iter: 0; batch classifier loss: 0.494743; batch adversarial loss: 0.476568\n",
      "epoch 30; iter: 0; batch classifier loss: 0.508728; batch adversarial loss: 0.500255\n",
      "epoch 31; iter: 0; batch classifier loss: 0.507290; batch adversarial loss: 0.552450\n",
      "epoch 32; iter: 0; batch classifier loss: 0.479012; batch adversarial loss: 0.494415\n",
      "epoch 33; iter: 0; batch classifier loss: 0.536368; batch adversarial loss: 0.544279\n",
      "epoch 34; iter: 0; batch classifier loss: 0.462913; batch adversarial loss: 0.554718\n",
      "epoch 35; iter: 0; batch classifier loss: 0.442103; batch adversarial loss: 0.481568\n",
      "epoch 36; iter: 0; batch classifier loss: 0.429219; batch adversarial loss: 0.526839\n",
      "epoch 37; iter: 0; batch classifier loss: 0.465877; batch adversarial loss: 0.563063\n",
      "epoch 38; iter: 0; batch classifier loss: 0.414566; batch adversarial loss: 0.536745\n",
      "epoch 39; iter: 0; batch classifier loss: 0.429762; batch adversarial loss: 0.544762\n",
      "epoch 40; iter: 0; batch classifier loss: 0.433479; batch adversarial loss: 0.527679\n",
      "epoch 41; iter: 0; batch classifier loss: 0.395627; batch adversarial loss: 0.517434\n",
      "epoch 42; iter: 0; batch classifier loss: 0.444628; batch adversarial loss: 0.544081\n",
      "epoch 43; iter: 0; batch classifier loss: 0.430520; batch adversarial loss: 0.615874\n",
      "epoch 44; iter: 0; batch classifier loss: 0.392408; batch adversarial loss: 0.536157\n",
      "epoch 45; iter: 0; batch classifier loss: 0.449599; batch adversarial loss: 0.590659\n",
      "epoch 46; iter: 0; batch classifier loss: 0.446333; batch adversarial loss: 0.562791\n",
      "epoch 47; iter: 0; batch classifier loss: 0.391241; batch adversarial loss: 0.545211\n",
      "epoch 48; iter: 0; batch classifier loss: 0.406528; batch adversarial loss: 0.607678\n",
      "epoch 49; iter: 0; batch classifier loss: 0.433926; batch adversarial loss: 0.489965\n",
      "epoch 50; iter: 0; batch classifier loss: 0.436872; batch adversarial loss: 0.490692\n",
      "epoch 51; iter: 0; batch classifier loss: 0.416159; batch adversarial loss: 0.516226\n",
      "epoch 52; iter: 0; batch classifier loss: 0.370655; batch adversarial loss: 0.535232\n",
      "epoch 53; iter: 0; batch classifier loss: 0.361417; batch adversarial loss: 0.562294\n",
      "epoch 54; iter: 0; batch classifier loss: 0.488400; batch adversarial loss: 0.544672\n",
      "epoch 55; iter: 0; batch classifier loss: 0.526453; batch adversarial loss: 0.526424\n",
      "epoch 56; iter: 0; batch classifier loss: 0.487986; batch adversarial loss: 0.571791\n",
      "epoch 57; iter: 0; batch classifier loss: 0.486024; batch adversarial loss: 0.571782\n",
      "epoch 58; iter: 0; batch classifier loss: 0.388883; batch adversarial loss: 0.571851\n",
      "epoch 59; iter: 0; batch classifier loss: 0.344491; batch adversarial loss: 0.626560\n",
      "epoch 60; iter: 0; batch classifier loss: 0.400151; batch adversarial loss: 0.535188\n",
      "epoch 61; iter: 0; batch classifier loss: 0.358633; batch adversarial loss: 0.673141\n",
      "epoch 62; iter: 0; batch classifier loss: 0.474655; batch adversarial loss: 0.526140\n",
      "epoch 63; iter: 0; batch classifier loss: 0.522759; batch adversarial loss: 0.554010\n",
      "epoch 64; iter: 0; batch classifier loss: 0.485913; batch adversarial loss: 0.581164\n",
      "epoch 65; iter: 0; batch classifier loss: 0.415346; batch adversarial loss: 0.535409\n",
      "epoch 66; iter: 0; batch classifier loss: 0.400519; batch adversarial loss: 0.581034\n",
      "epoch 67; iter: 0; batch classifier loss: 0.444722; batch adversarial loss: 0.489731\n",
      "epoch 68; iter: 0; batch classifier loss: 0.471178; batch adversarial loss: 0.562728\n",
      "epoch 69; iter: 0; batch classifier loss: 0.515627; batch adversarial loss: 0.508088\n",
      "epoch 70; iter: 0; batch classifier loss: 0.353865; batch adversarial loss: 0.553645\n",
      "epoch 71; iter: 0; batch classifier loss: 0.377142; batch adversarial loss: 0.535651\n",
      "epoch 72; iter: 0; batch classifier loss: 0.327460; batch adversarial loss: 0.606567\n",
      "epoch 73; iter: 0; batch classifier loss: 0.398495; batch adversarial loss: 0.572130\n",
      "epoch 74; iter: 0; batch classifier loss: 0.381960; batch adversarial loss: 0.581646\n",
      "epoch 75; iter: 0; batch classifier loss: 0.351946; batch adversarial loss: 0.570705\n",
      "epoch 76; iter: 0; batch classifier loss: 0.296147; batch adversarial loss: 0.707588\n",
      "epoch 77; iter: 0; batch classifier loss: 0.381687; batch adversarial loss: 0.562671\n",
      "epoch 78; iter: 0; batch classifier loss: 0.380017; batch adversarial loss: 0.645072\n",
      "epoch 79; iter: 0; batch classifier loss: 0.398128; batch adversarial loss: 0.552198\n",
      "epoch 80; iter: 0; batch classifier loss: 0.334509; batch adversarial loss: 0.672610\n",
      "epoch 81; iter: 0; batch classifier loss: 0.338782; batch adversarial loss: 0.526249\n",
      "epoch 82; iter: 0; batch classifier loss: 0.438410; batch adversarial loss: 0.601019\n",
      "epoch 83; iter: 0; batch classifier loss: 0.455157; batch adversarial loss: 0.543936\n",
      "epoch 84; iter: 0; batch classifier loss: 0.349963; batch adversarial loss: 0.572495\n",
      "epoch 85; iter: 0; batch classifier loss: 0.349772; batch adversarial loss: 0.553404\n",
      "epoch 86; iter: 0; batch classifier loss: 0.400206; batch adversarial loss: 0.591146\n",
      "epoch 87; iter: 0; batch classifier loss: 0.320903; batch adversarial loss: 0.591162\n",
      "epoch 88; iter: 0; batch classifier loss: 0.407667; batch adversarial loss: 0.581442\n",
      "epoch 89; iter: 0; batch classifier loss: 0.403260; batch adversarial loss: 0.581114\n",
      "epoch 90; iter: 0; batch classifier loss: 0.420090; batch adversarial loss: 0.618482\n",
      "epoch 91; iter: 0; batch classifier loss: 0.388061; batch adversarial loss: 0.516843\n",
      "epoch 92; iter: 0; batch classifier loss: 0.392583; batch adversarial loss: 0.488929\n",
      "epoch 93; iter: 0; batch classifier loss: 0.371737; batch adversarial loss: 0.581395\n",
      "epoch 94; iter: 0; batch classifier loss: 0.353839; batch adversarial loss: 0.553259\n",
      "epoch 95; iter: 0; batch classifier loss: 0.491698; batch adversarial loss: 0.581979\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 96; iter: 0; batch classifier loss: 0.410100; batch adversarial loss: 0.571432\n",
      "epoch 97; iter: 0; batch classifier loss: 0.423178; batch adversarial loss: 0.517677\n",
      "epoch 98; iter: 0; batch classifier loss: 0.389326; batch adversarial loss: 0.554156\n",
      "epoch 99; iter: 0; batch classifier loss: 0.341074; batch adversarial loss: 0.480628\n",
      "epoch 100; iter: 0; batch classifier loss: 0.376187; batch adversarial loss: 0.689584\n",
      "epoch 101; iter: 0; batch classifier loss: 0.346351; batch adversarial loss: 0.618764\n",
      "epoch 102; iter: 0; batch classifier loss: 0.412669; batch adversarial loss: 0.553885\n",
      "epoch 103; iter: 0; batch classifier loss: 0.401247; batch adversarial loss: 0.527075\n",
      "epoch 104; iter: 0; batch classifier loss: 0.350585; batch adversarial loss: 0.526221\n",
      "epoch 105; iter: 0; batch classifier loss: 0.418605; batch adversarial loss: 0.534561\n",
      "epoch 106; iter: 0; batch classifier loss: 0.466132; batch adversarial loss: 0.562262\n",
      "epoch 107; iter: 0; batch classifier loss: 0.385425; batch adversarial loss: 0.647140\n",
      "epoch 108; iter: 0; batch classifier loss: 0.422638; batch adversarial loss: 0.580054\n",
      "epoch 109; iter: 0; batch classifier loss: 0.373172; batch adversarial loss: 0.618438\n",
      "epoch 110; iter: 0; batch classifier loss: 0.380348; batch adversarial loss: 0.635106\n",
      "epoch 111; iter: 0; batch classifier loss: 0.381288; batch adversarial loss: 0.544269\n",
      "epoch 112; iter: 0; batch classifier loss: 0.326772; batch adversarial loss: 0.543121\n",
      "epoch 113; iter: 0; batch classifier loss: 0.361650; batch adversarial loss: 0.498166\n",
      "epoch 114; iter: 0; batch classifier loss: 0.412738; batch adversarial loss: 0.527599\n",
      "epoch 115; iter: 0; batch classifier loss: 0.373940; batch adversarial loss: 0.537429\n",
      "epoch 116; iter: 0; batch classifier loss: 0.306402; batch adversarial loss: 0.571191\n",
      "epoch 117; iter: 0; batch classifier loss: 0.394946; batch adversarial loss: 0.562325\n",
      "epoch 118; iter: 0; batch classifier loss: 0.419427; batch adversarial loss: 0.562323\n",
      "epoch 119; iter: 0; batch classifier loss: 0.372652; batch adversarial loss: 0.589331\n",
      "epoch 120; iter: 0; batch classifier loss: 0.380577; batch adversarial loss: 0.481058\n",
      "epoch 121; iter: 0; batch classifier loss: 0.358103; batch adversarial loss: 0.524547\n",
      "epoch 122; iter: 0; batch classifier loss: 0.325055; batch adversarial loss: 0.533365\n",
      "epoch 123; iter: 0; batch classifier loss: 0.404397; batch adversarial loss: 0.472738\n",
      "epoch 124; iter: 0; batch classifier loss: 0.398351; batch adversarial loss: 0.608166\n",
      "epoch 125; iter: 0; batch classifier loss: 0.444159; batch adversarial loss: 0.543781\n",
      "epoch 126; iter: 0; batch classifier loss: 0.412522; batch adversarial loss: 0.526439\n",
      "epoch 127; iter: 0; batch classifier loss: 0.435901; batch adversarial loss: 0.553553\n",
      "epoch 128; iter: 0; batch classifier loss: 0.436885; batch adversarial loss: 0.562769\n",
      "epoch 129; iter: 0; batch classifier loss: 0.451387; batch adversarial loss: 0.589979\n",
      "epoch 130; iter: 0; batch classifier loss: 0.393915; batch adversarial loss: 0.553399\n",
      "epoch 131; iter: 0; batch classifier loss: 0.368419; batch adversarial loss: 0.517334\n",
      "epoch 132; iter: 0; batch classifier loss: 0.349217; batch adversarial loss: 0.543400\n",
      "epoch 133; iter: 0; batch classifier loss: 0.368230; batch adversarial loss: 0.544087\n",
      "epoch 134; iter: 0; batch classifier loss: 0.387577; batch adversarial loss: 0.507671\n",
      "epoch 135; iter: 0; batch classifier loss: 0.420757; batch adversarial loss: 0.479702\n",
      "epoch 136; iter: 0; batch classifier loss: 0.437961; batch adversarial loss: 0.546105\n",
      "epoch 137; iter: 0; batch classifier loss: 0.346744; batch adversarial loss: 0.535418\n",
      "epoch 138; iter: 0; batch classifier loss: 0.370179; batch adversarial loss: 0.526614\n",
      "epoch 139; iter: 0; batch classifier loss: 0.386729; batch adversarial loss: 0.580987\n",
      "epoch 140; iter: 0; batch classifier loss: 0.315983; batch adversarial loss: 0.580891\n",
      "epoch 141; iter: 0; batch classifier loss: 0.369974; batch adversarial loss: 0.525990\n",
      "epoch 142; iter: 0; batch classifier loss: 0.408223; batch adversarial loss: 0.583031\n",
      "epoch 143; iter: 0; batch classifier loss: 0.330000; batch adversarial loss: 0.572007\n",
      "epoch 144; iter: 0; batch classifier loss: 0.307694; batch adversarial loss: 0.526288\n",
      "epoch 145; iter: 0; batch classifier loss: 0.372599; batch adversarial loss: 0.599386\n",
      "epoch 146; iter: 0; batch classifier loss: 0.334442; batch adversarial loss: 0.496613\n",
      "epoch 147; iter: 0; batch classifier loss: 0.356984; batch adversarial loss: 0.552730\n",
      "epoch 148; iter: 0; batch classifier loss: 0.356419; batch adversarial loss: 0.524784\n",
      "epoch 149; iter: 0; batch classifier loss: 0.378352; batch adversarial loss: 0.501052\n",
      "epoch 150; iter: 0; batch classifier loss: 0.410826; batch adversarial loss: 0.498937\n",
      "epoch 151; iter: 0; batch classifier loss: 0.411600; batch adversarial loss: 0.517094\n",
      "epoch 152; iter: 0; batch classifier loss: 0.369027; batch adversarial loss: 0.591710\n",
      "epoch 153; iter: 0; batch classifier loss: 0.379687; batch adversarial loss: 0.499674\n",
      "epoch 154; iter: 0; batch classifier loss: 0.385161; batch adversarial loss: 0.472617\n",
      "epoch 155; iter: 0; batch classifier loss: 0.360925; batch adversarial loss: 0.553604\n",
      "epoch 156; iter: 0; batch classifier loss: 0.439232; batch adversarial loss: 0.590257\n",
      "epoch 157; iter: 0; batch classifier loss: 0.353993; batch adversarial loss: 0.489585\n",
      "epoch 158; iter: 0; batch classifier loss: 0.363234; batch adversarial loss: 0.525522\n",
      "epoch 159; iter: 0; batch classifier loss: 0.437739; batch adversarial loss: 0.628274\n",
      "epoch 160; iter: 0; batch classifier loss: 0.367782; batch adversarial loss: 0.570358\n",
      "epoch 161; iter: 0; batch classifier loss: 0.414219; batch adversarial loss: 0.557858\n",
      "epoch 162; iter: 0; batch classifier loss: 0.419172; batch adversarial loss: 0.545900\n",
      "epoch 163; iter: 0; batch classifier loss: 0.312840; batch adversarial loss: 0.543376\n",
      "epoch 164; iter: 0; batch classifier loss: 0.355252; batch adversarial loss: 0.525721\n",
      "epoch 165; iter: 0; batch classifier loss: 0.352710; batch adversarial loss: 0.526678\n",
      "epoch 166; iter: 0; batch classifier loss: 0.396136; batch adversarial loss: 0.580834\n",
      "epoch 167; iter: 0; batch classifier loss: 0.317568; batch adversarial loss: 0.489664\n",
      "epoch 168; iter: 0; batch classifier loss: 0.330082; batch adversarial loss: 0.510833\n",
      "epoch 169; iter: 0; batch classifier loss: 0.381002; batch adversarial loss: 0.535424\n",
      "epoch 170; iter: 0; batch classifier loss: 0.474016; batch adversarial loss: 0.547880\n",
      "epoch 171; iter: 0; batch classifier loss: 0.443959; batch adversarial loss: 0.523849\n",
      "epoch 172; iter: 0; batch classifier loss: 0.347172; batch adversarial loss: 0.552903\n",
      "epoch 173; iter: 0; batch classifier loss: 0.374810; batch adversarial loss: 0.490555\n",
      "epoch 174; iter: 0; batch classifier loss: 0.385128; batch adversarial loss: 0.517064\n",
      "epoch 175; iter: 0; batch classifier loss: 0.387754; batch adversarial loss: 0.562034\n",
      "epoch 176; iter: 0; batch classifier loss: 0.418514; batch adversarial loss: 0.509222\n",
      "epoch 177; iter: 0; batch classifier loss: 0.417018; batch adversarial loss: 0.588707\n",
      "epoch 178; iter: 0; batch classifier loss: 0.320025; batch adversarial loss: 0.634419\n",
      "epoch 179; iter: 0; batch classifier loss: 0.362697; batch adversarial loss: 0.498872\n",
      "epoch 180; iter: 0; batch classifier loss: 0.337215; batch adversarial loss: 0.508159\n",
      "epoch 181; iter: 0; batch classifier loss: 0.409403; batch adversarial loss: 0.527205\n",
      "epoch 182; iter: 0; batch classifier loss: 0.346967; batch adversarial loss: 0.544010\n",
      "epoch 183; iter: 0; batch classifier loss: 0.400861; batch adversarial loss: 0.489706\n",
      "epoch 184; iter: 0; batch classifier loss: 0.376813; batch adversarial loss: 0.580772\n",
      "epoch 185; iter: 0; batch classifier loss: 0.362916; batch adversarial loss: 0.554092\n",
      "epoch 186; iter: 0; batch classifier loss: 0.412516; batch adversarial loss: 0.525598\n",
      "epoch 187; iter: 0; batch classifier loss: 0.394020; batch adversarial loss: 0.527553\n",
      "epoch 188; iter: 0; batch classifier loss: 0.359761; batch adversarial loss: 0.526595\n",
      "epoch 189; iter: 0; batch classifier loss: 0.480970; batch adversarial loss: 0.488427\n",
      "epoch 190; iter: 0; batch classifier loss: 0.314603; batch adversarial loss: 0.490226\n",
      "epoch 191; iter: 0; batch classifier loss: 0.366048; batch adversarial loss: 0.525787\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 192; iter: 0; batch classifier loss: 0.370878; batch adversarial loss: 0.535730\n",
      "epoch 193; iter: 0; batch classifier loss: 0.313168; batch adversarial loss: 0.581339\n",
      "epoch 194; iter: 0; batch classifier loss: 0.326998; batch adversarial loss: 0.589440\n",
      "epoch 195; iter: 0; batch classifier loss: 0.293808; batch adversarial loss: 0.534959\n",
      "epoch 196; iter: 0; batch classifier loss: 0.452490; batch adversarial loss: 0.562264\n",
      "epoch 197; iter: 0; batch classifier loss: 0.373720; batch adversarial loss: 0.480965\n",
      "epoch 198; iter: 0; batch classifier loss: 0.285632; batch adversarial loss: 0.498982\n",
      "epoch 199; iter: 0; batch classifier loss: 0.339784; batch adversarial loss: 0.571370\n",
      "epoch 0; iter: 0; batch classifier loss: 0.698513; batch adversarial loss: 0.678460\n",
      "epoch 1; iter: 0; batch classifier loss: 0.602316; batch adversarial loss: 0.647671\n",
      "epoch 2; iter: 0; batch classifier loss: 0.561426; batch adversarial loss: 0.643588\n",
      "epoch 3; iter: 0; batch classifier loss: 0.624056; batch adversarial loss: 0.632060\n",
      "epoch 4; iter: 0; batch classifier loss: 0.545279; batch adversarial loss: 0.601547\n",
      "epoch 5; iter: 0; batch classifier loss: 0.588336; batch adversarial loss: 0.620970\n",
      "epoch 6; iter: 0; batch classifier loss: 0.473488; batch adversarial loss: 0.600836\n",
      "epoch 7; iter: 0; batch classifier loss: 0.503626; batch adversarial loss: 0.598202\n",
      "epoch 8; iter: 0; batch classifier loss: 0.430800; batch adversarial loss: 0.614216\n",
      "epoch 9; iter: 0; batch classifier loss: 0.487287; batch adversarial loss: 0.555419\n",
      "epoch 10; iter: 0; batch classifier loss: 0.457091; batch adversarial loss: 0.605467\n",
      "epoch 11; iter: 0; batch classifier loss: 0.505859; batch adversarial loss: 0.588285\n",
      "epoch 12; iter: 0; batch classifier loss: 0.509613; batch adversarial loss: 0.631260\n",
      "epoch 13; iter: 0; batch classifier loss: 0.471365; batch adversarial loss: 0.544365\n",
      "epoch 14; iter: 0; batch classifier loss: 0.605221; batch adversarial loss: 0.596928\n",
      "epoch 15; iter: 0; batch classifier loss: 0.510317; batch adversarial loss: 0.566356\n",
      "epoch 16; iter: 0; batch classifier loss: 0.507918; batch adversarial loss: 0.529084\n",
      "epoch 17; iter: 0; batch classifier loss: 0.501488; batch adversarial loss: 0.529510\n",
      "epoch 18; iter: 0; batch classifier loss: 0.545652; batch adversarial loss: 0.514646\n",
      "epoch 19; iter: 0; batch classifier loss: 0.535158; batch adversarial loss: 0.581030\n",
      "epoch 20; iter: 0; batch classifier loss: 0.445460; batch adversarial loss: 0.569873\n",
      "epoch 21; iter: 0; batch classifier loss: 0.555434; batch adversarial loss: 0.560960\n",
      "epoch 22; iter: 0; batch classifier loss: 0.486449; batch adversarial loss: 0.605687\n",
      "epoch 23; iter: 0; batch classifier loss: 0.461334; batch adversarial loss: 0.570053\n",
      "epoch 24; iter: 0; batch classifier loss: 0.494716; batch adversarial loss: 0.562974\n",
      "epoch 25; iter: 0; batch classifier loss: 0.498704; batch adversarial loss: 0.569298\n",
      "epoch 26; iter: 0; batch classifier loss: 0.475115; batch adversarial loss: 0.526382\n",
      "epoch 27; iter: 0; batch classifier loss: 0.440095; batch adversarial loss: 0.538516\n",
      "epoch 28; iter: 0; batch classifier loss: 0.423970; batch adversarial loss: 0.531161\n",
      "epoch 29; iter: 0; batch classifier loss: 0.394917; batch adversarial loss: 0.553163\n",
      "epoch 30; iter: 0; batch classifier loss: 0.445548; batch adversarial loss: 0.563235\n",
      "epoch 31; iter: 0; batch classifier loss: 0.479414; batch adversarial loss: 0.503156\n",
      "epoch 32; iter: 0; batch classifier loss: 0.491149; batch adversarial loss: 0.622221\n",
      "epoch 33; iter: 0; batch classifier loss: 0.468648; batch adversarial loss: 0.503413\n",
      "epoch 34; iter: 0; batch classifier loss: 0.444602; batch adversarial loss: 0.459159\n",
      "epoch 35; iter: 0; batch classifier loss: 0.362305; batch adversarial loss: 0.562407\n",
      "epoch 36; iter: 0; batch classifier loss: 0.471252; batch adversarial loss: 0.597296\n",
      "epoch 37; iter: 0; batch classifier loss: 0.404725; batch adversarial loss: 0.598085\n",
      "epoch 38; iter: 0; batch classifier loss: 0.442709; batch adversarial loss: 0.500046\n",
      "epoch 39; iter: 0; batch classifier loss: 0.424197; batch adversarial loss: 0.526892\n",
      "epoch 40; iter: 0; batch classifier loss: 0.483830; batch adversarial loss: 0.642880\n",
      "epoch 41; iter: 0; batch classifier loss: 0.396589; batch adversarial loss: 0.535621\n",
      "epoch 42; iter: 0; batch classifier loss: 0.492715; batch adversarial loss: 0.490434\n",
      "epoch 43; iter: 0; batch classifier loss: 0.466658; batch adversarial loss: 0.589117\n",
      "epoch 44; iter: 0; batch classifier loss: 0.479107; batch adversarial loss: 0.581628\n",
      "epoch 45; iter: 0; batch classifier loss: 0.423384; batch adversarial loss: 0.552837\n",
      "epoch 46; iter: 0; batch classifier loss: 0.432541; batch adversarial loss: 0.509149\n",
      "epoch 47; iter: 0; batch classifier loss: 0.396746; batch adversarial loss: 0.462442\n",
      "epoch 48; iter: 0; batch classifier loss: 0.491852; batch adversarial loss: 0.516675\n",
      "epoch 49; iter: 0; batch classifier loss: 0.442735; batch adversarial loss: 0.537021\n",
      "epoch 50; iter: 0; batch classifier loss: 0.412181; batch adversarial loss: 0.527043\n",
      "epoch 51; iter: 0; batch classifier loss: 0.461055; batch adversarial loss: 0.554357\n",
      "epoch 52; iter: 0; batch classifier loss: 0.468566; batch adversarial loss: 0.545496\n",
      "epoch 53; iter: 0; batch classifier loss: 0.422233; batch adversarial loss: 0.589549\n",
      "epoch 54; iter: 0; batch classifier loss: 0.497688; batch adversarial loss: 0.518040\n",
      "epoch 55; iter: 0; batch classifier loss: 0.389935; batch adversarial loss: 0.578327\n",
      "epoch 56; iter: 0; batch classifier loss: 0.378301; batch adversarial loss: 0.555113\n",
      "epoch 57; iter: 0; batch classifier loss: 0.448930; batch adversarial loss: 0.554389\n",
      "epoch 58; iter: 0; batch classifier loss: 0.425992; batch adversarial loss: 0.553737\n",
      "epoch 59; iter: 0; batch classifier loss: 0.407633; batch adversarial loss: 0.644802\n",
      "epoch 60; iter: 0; batch classifier loss: 0.471826; batch adversarial loss: 0.543700\n",
      "epoch 61; iter: 0; batch classifier loss: 0.419675; batch adversarial loss: 0.597803\n",
      "epoch 62; iter: 0; batch classifier loss: 0.389960; batch adversarial loss: 0.555338\n",
      "epoch 63; iter: 0; batch classifier loss: 0.392853; batch adversarial loss: 0.599235\n",
      "epoch 64; iter: 0; batch classifier loss: 0.442791; batch adversarial loss: 0.572173\n",
      "epoch 65; iter: 0; batch classifier loss: 0.398762; batch adversarial loss: 0.579083\n",
      "epoch 66; iter: 0; batch classifier loss: 0.368750; batch adversarial loss: 0.464619\n",
      "epoch 67; iter: 0; batch classifier loss: 0.398549; batch adversarial loss: 0.481005\n",
      "epoch 68; iter: 0; batch classifier loss: 0.377760; batch adversarial loss: 0.562068\n",
      "epoch 69; iter: 0; batch classifier loss: 0.310672; batch adversarial loss: 0.672016\n",
      "epoch 70; iter: 0; batch classifier loss: 0.396235; batch adversarial loss: 0.535241\n",
      "epoch 71; iter: 0; batch classifier loss: 0.372883; batch adversarial loss: 0.526274\n",
      "epoch 72; iter: 0; batch classifier loss: 0.340249; batch adversarial loss: 0.535363\n",
      "epoch 73; iter: 0; batch classifier loss: 0.410319; batch adversarial loss: 0.528064\n",
      "epoch 74; iter: 0; batch classifier loss: 0.400816; batch adversarial loss: 0.543502\n",
      "epoch 75; iter: 0; batch classifier loss: 0.431101; batch adversarial loss: 0.526269\n",
      "epoch 76; iter: 0; batch classifier loss: 0.388941; batch adversarial loss: 0.609263\n",
      "epoch 77; iter: 0; batch classifier loss: 0.381305; batch adversarial loss: 0.580542\n",
      "epoch 78; iter: 0; batch classifier loss: 0.354408; batch adversarial loss: 0.573112\n",
      "epoch 79; iter: 0; batch classifier loss: 0.412189; batch adversarial loss: 0.583127\n",
      "epoch 80; iter: 0; batch classifier loss: 0.383045; batch adversarial loss: 0.544059\n",
      "epoch 81; iter: 0; batch classifier loss: 0.377149; batch adversarial loss: 0.562848\n",
      "epoch 82; iter: 0; batch classifier loss: 0.357587; batch adversarial loss: 0.580948\n",
      "epoch 83; iter: 0; batch classifier loss: 0.392948; batch adversarial loss: 0.545593\n",
      "epoch 84; iter: 0; batch classifier loss: 0.421837; batch adversarial loss: 0.570151\n",
      "epoch 85; iter: 0; batch classifier loss: 0.477317; batch adversarial loss: 0.553331\n",
      "epoch 86; iter: 0; batch classifier loss: 0.368526; batch adversarial loss: 0.517191\n",
      "epoch 87; iter: 0; batch classifier loss: 0.378855; batch adversarial loss: 0.518297\n",
      "epoch 88; iter: 0; batch classifier loss: 0.439459; batch adversarial loss: 0.617451\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 89; iter: 0; batch classifier loss: 0.405917; batch adversarial loss: 0.599427\n",
      "epoch 90; iter: 0; batch classifier loss: 0.355241; batch adversarial loss: 0.518790\n",
      "epoch 91; iter: 0; batch classifier loss: 0.378180; batch adversarial loss: 0.580025\n",
      "epoch 92; iter: 0; batch classifier loss: 0.360535; batch adversarial loss: 0.589663\n",
      "epoch 93; iter: 0; batch classifier loss: 0.423939; batch adversarial loss: 0.498269\n",
      "epoch 94; iter: 0; batch classifier loss: 0.356389; batch adversarial loss: 0.580309\n",
      "epoch 95; iter: 0; batch classifier loss: 0.442388; batch adversarial loss: 0.571798\n",
      "epoch 96; iter: 0; batch classifier loss: 0.328585; batch adversarial loss: 0.553499\n",
      "epoch 97; iter: 0; batch classifier loss: 0.370394; batch adversarial loss: 0.615903\n",
      "epoch 98; iter: 0; batch classifier loss: 0.333258; batch adversarial loss: 0.497971\n",
      "epoch 99; iter: 0; batch classifier loss: 0.326492; batch adversarial loss: 0.616793\n",
      "epoch 100; iter: 0; batch classifier loss: 0.466448; batch adversarial loss: 0.572259\n",
      "epoch 101; iter: 0; batch classifier loss: 0.440560; batch adversarial loss: 0.489954\n",
      "epoch 102; iter: 0; batch classifier loss: 0.356673; batch adversarial loss: 0.536004\n",
      "epoch 103; iter: 0; batch classifier loss: 0.435629; batch adversarial loss: 0.481251\n",
      "epoch 104; iter: 0; batch classifier loss: 0.368431; batch adversarial loss: 0.552769\n",
      "epoch 105; iter: 0; batch classifier loss: 0.369728; batch adversarial loss: 0.536385\n",
      "epoch 106; iter: 0; batch classifier loss: 0.382193; batch adversarial loss: 0.561485\n",
      "epoch 107; iter: 0; batch classifier loss: 0.428887; batch adversarial loss: 0.517046\n",
      "epoch 108; iter: 0; batch classifier loss: 0.391392; batch adversarial loss: 0.562405\n",
      "epoch 109; iter: 0; batch classifier loss: 0.430996; batch adversarial loss: 0.652057\n",
      "epoch 110; iter: 0; batch classifier loss: 0.445339; batch adversarial loss: 0.508147\n",
      "epoch 111; iter: 0; batch classifier loss: 0.325254; batch adversarial loss: 0.490406\n",
      "epoch 112; iter: 0; batch classifier loss: 0.351773; batch adversarial loss: 0.626266\n",
      "epoch 113; iter: 0; batch classifier loss: 0.382464; batch adversarial loss: 0.490348\n",
      "epoch 114; iter: 0; batch classifier loss: 0.432496; batch adversarial loss: 0.600649\n",
      "epoch 115; iter: 0; batch classifier loss: 0.338514; batch adversarial loss: 0.571339\n",
      "epoch 116; iter: 0; batch classifier loss: 0.325913; batch adversarial loss: 0.569977\n",
      "epoch 117; iter: 0; batch classifier loss: 0.376168; batch adversarial loss: 0.509175\n",
      "epoch 118; iter: 0; batch classifier loss: 0.422246; batch adversarial loss: 0.581211\n",
      "epoch 119; iter: 0; batch classifier loss: 0.408844; batch adversarial loss: 0.436253\n",
      "epoch 120; iter: 0; batch classifier loss: 0.354366; batch adversarial loss: 0.526456\n",
      "epoch 121; iter: 0; batch classifier loss: 0.271612; batch adversarial loss: 0.562648\n",
      "epoch 122; iter: 0; batch classifier loss: 0.321815; batch adversarial loss: 0.680147\n",
      "epoch 123; iter: 0; batch classifier loss: 0.333906; batch adversarial loss: 0.606207\n",
      "epoch 124; iter: 0; batch classifier loss: 0.373690; batch adversarial loss: 0.616504\n",
      "epoch 125; iter: 0; batch classifier loss: 0.409368; batch adversarial loss: 0.481056\n",
      "epoch 126; iter: 0; batch classifier loss: 0.409247; batch adversarial loss: 0.562069\n",
      "epoch 127; iter: 0; batch classifier loss: 0.419752; batch adversarial loss: 0.553582\n",
      "epoch 128; iter: 0; batch classifier loss: 0.299853; batch adversarial loss: 0.544792\n",
      "epoch 129; iter: 0; batch classifier loss: 0.363939; batch adversarial loss: 0.544661\n",
      "epoch 130; iter: 0; batch classifier loss: 0.444432; batch adversarial loss: 0.508603\n",
      "epoch 131; iter: 0; batch classifier loss: 0.379385; batch adversarial loss: 0.580035\n",
      "epoch 132; iter: 0; batch classifier loss: 0.353442; batch adversarial loss: 0.526034\n",
      "epoch 133; iter: 0; batch classifier loss: 0.334141; batch adversarial loss: 0.537019\n",
      "epoch 134; iter: 0; batch classifier loss: 0.353800; batch adversarial loss: 0.554065\n",
      "epoch 135; iter: 0; batch classifier loss: 0.273682; batch adversarial loss: 0.581141\n",
      "epoch 136; iter: 0; batch classifier loss: 0.383407; batch adversarial loss: 0.559678\n",
      "epoch 137; iter: 0; batch classifier loss: 0.405369; batch adversarial loss: 0.472021\n",
      "epoch 138; iter: 0; batch classifier loss: 0.277762; batch adversarial loss: 0.544965\n",
      "epoch 139; iter: 0; batch classifier loss: 0.316072; batch adversarial loss: 0.489635\n",
      "epoch 140; iter: 0; batch classifier loss: 0.368513; batch adversarial loss: 0.598191\n",
      "epoch 141; iter: 0; batch classifier loss: 0.428666; batch adversarial loss: 0.525823\n",
      "epoch 142; iter: 0; batch classifier loss: 0.395937; batch adversarial loss: 0.508247\n",
      "epoch 143; iter: 0; batch classifier loss: 0.397225; batch adversarial loss: 0.507335\n",
      "epoch 144; iter: 0; batch classifier loss: 0.401983; batch adversarial loss: 0.598620\n",
      "epoch 145; iter: 0; batch classifier loss: 0.271033; batch adversarial loss: 0.544000\n",
      "epoch 146; iter: 0; batch classifier loss: 0.383143; batch adversarial loss: 0.526255\n",
      "epoch 147; iter: 0; batch classifier loss: 0.319950; batch adversarial loss: 0.535272\n",
      "epoch 148; iter: 0; batch classifier loss: 0.355020; batch adversarial loss: 0.653885\n",
      "epoch 149; iter: 0; batch classifier loss: 0.344594; batch adversarial loss: 0.507456\n",
      "epoch 150; iter: 0; batch classifier loss: 0.365082; batch adversarial loss: 0.553708\n",
      "epoch 151; iter: 0; batch classifier loss: 0.313709; batch adversarial loss: 0.562905\n",
      "epoch 152; iter: 0; batch classifier loss: 0.279904; batch adversarial loss: 0.572911\n",
      "epoch 153; iter: 0; batch classifier loss: 0.325071; batch adversarial loss: 0.568728\n",
      "epoch 154; iter: 0; batch classifier loss: 0.295347; batch adversarial loss: 0.536337\n",
      "epoch 155; iter: 0; batch classifier loss: 0.285832; batch adversarial loss: 0.471898\n",
      "epoch 156; iter: 0; batch classifier loss: 0.344300; batch adversarial loss: 0.535687\n",
      "epoch 157; iter: 0; batch classifier loss: 0.416699; batch adversarial loss: 0.607643\n",
      "epoch 158; iter: 0; batch classifier loss: 0.296163; batch adversarial loss: 0.608204\n",
      "epoch 159; iter: 0; batch classifier loss: 0.324886; batch adversarial loss: 0.518191\n",
      "epoch 160; iter: 0; batch classifier loss: 0.376006; batch adversarial loss: 0.618186\n",
      "epoch 161; iter: 0; batch classifier loss: 0.299638; batch adversarial loss: 0.571384\n",
      "epoch 162; iter: 0; batch classifier loss: 0.285891; batch adversarial loss: 0.526022\n",
      "epoch 163; iter: 0; batch classifier loss: 0.345148; batch adversarial loss: 0.654165\n",
      "epoch 164; iter: 0; batch classifier loss: 0.400212; batch adversarial loss: 0.580734\n",
      "epoch 165; iter: 0; batch classifier loss: 0.335184; batch adversarial loss: 0.471018\n",
      "epoch 166; iter: 0; batch classifier loss: 0.339314; batch adversarial loss: 0.526228\n",
      "epoch 167; iter: 0; batch classifier loss: 0.362904; batch adversarial loss: 0.544537\n",
      "epoch 168; iter: 0; batch classifier loss: 0.389080; batch adversarial loss: 0.591946\n",
      "epoch 169; iter: 0; batch classifier loss: 0.341612; batch adversarial loss: 0.491216\n",
      "epoch 170; iter: 0; batch classifier loss: 0.325711; batch adversarial loss: 0.533720\n",
      "epoch 171; iter: 0; batch classifier loss: 0.297132; batch adversarial loss: 0.516114\n",
      "epoch 172; iter: 0; batch classifier loss: 0.421026; batch adversarial loss: 0.608672\n",
      "epoch 173; iter: 0; batch classifier loss: 0.343643; batch adversarial loss: 0.526363\n",
      "epoch 174; iter: 0; batch classifier loss: 0.341761; batch adversarial loss: 0.572590\n",
      "epoch 175; iter: 0; batch classifier loss: 0.313971; batch adversarial loss: 0.472442\n",
      "epoch 176; iter: 0; batch classifier loss: 0.362452; batch adversarial loss: 0.534725\n",
      "epoch 177; iter: 0; batch classifier loss: 0.265433; batch adversarial loss: 0.480818\n",
      "epoch 178; iter: 0; batch classifier loss: 0.370880; batch adversarial loss: 0.580397\n",
      "epoch 179; iter: 0; batch classifier loss: 0.354390; batch adversarial loss: 0.508039\n",
      "epoch 180; iter: 0; batch classifier loss: 0.412346; batch adversarial loss: 0.500400\n",
      "epoch 181; iter: 0; batch classifier loss: 0.286379; batch adversarial loss: 0.543956\n",
      "epoch 182; iter: 0; batch classifier loss: 0.390848; batch adversarial loss: 0.563698\n",
      "epoch 183; iter: 0; batch classifier loss: 0.333943; batch adversarial loss: 0.572962\n",
      "epoch 184; iter: 0; batch classifier loss: 0.333983; batch adversarial loss: 0.562460\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 185; iter: 0; batch classifier loss: 0.336193; batch adversarial loss: 0.553666\n",
      "epoch 186; iter: 0; batch classifier loss: 0.270164; batch adversarial loss: 0.644521\n",
      "epoch 187; iter: 0; batch classifier loss: 0.431244; batch adversarial loss: 0.634413\n",
      "epoch 188; iter: 0; batch classifier loss: 0.352312; batch adversarial loss: 0.544760\n",
      "epoch 189; iter: 0; batch classifier loss: 0.387027; batch adversarial loss: 0.507852\n",
      "epoch 190; iter: 0; batch classifier loss: 0.391436; batch adversarial loss: 0.598782\n",
      "epoch 191; iter: 0; batch classifier loss: 0.342550; batch adversarial loss: 0.571924\n",
      "epoch 192; iter: 0; batch classifier loss: 0.455651; batch adversarial loss: 0.570763\n",
      "epoch 193; iter: 0; batch classifier loss: 0.323203; batch adversarial loss: 0.553293\n",
      "epoch 194; iter: 0; batch classifier loss: 0.311826; batch adversarial loss: 0.563103\n",
      "epoch 195; iter: 0; batch classifier loss: 0.292281; batch adversarial loss: 0.581479\n",
      "epoch 196; iter: 0; batch classifier loss: 0.305376; batch adversarial loss: 0.552240\n",
      "epoch 197; iter: 0; batch classifier loss: 0.374273; batch adversarial loss: 0.526421\n",
      "epoch 198; iter: 0; batch classifier loss: 0.376522; batch adversarial loss: 0.599859\n",
      "epoch 199; iter: 0; batch classifier loss: 0.399782; batch adversarial loss: 0.535710\n",
      "epoch 0; iter: 0; batch classifier loss: 0.782201; batch adversarial loss: 0.648796\n",
      "epoch 1; iter: 0; batch classifier loss: 0.536769; batch adversarial loss: 0.644661\n",
      "epoch 2; iter: 0; batch classifier loss: 0.565226; batch adversarial loss: 0.658446\n",
      "epoch 3; iter: 0; batch classifier loss: 0.565056; batch adversarial loss: 0.626228\n",
      "epoch 4; iter: 0; batch classifier loss: 0.516286; batch adversarial loss: 0.585226\n",
      "epoch 5; iter: 0; batch classifier loss: 0.531624; batch adversarial loss: 0.618208\n",
      "epoch 6; iter: 0; batch classifier loss: 0.595224; batch adversarial loss: 0.629591\n",
      "epoch 7; iter: 0; batch classifier loss: 0.488653; batch adversarial loss: 0.594066\n",
      "epoch 8; iter: 0; batch classifier loss: 0.519945; batch adversarial loss: 0.577153\n",
      "epoch 9; iter: 0; batch classifier loss: 0.588093; batch adversarial loss: 0.621173\n",
      "epoch 10; iter: 0; batch classifier loss: 0.539819; batch adversarial loss: 0.613098\n",
      "epoch 11; iter: 0; batch classifier loss: 0.562913; batch adversarial loss: 0.593010\n",
      "epoch 12; iter: 0; batch classifier loss: 0.539298; batch adversarial loss: 0.630023\n",
      "epoch 13; iter: 0; batch classifier loss: 0.559411; batch adversarial loss: 0.592592\n",
      "epoch 14; iter: 0; batch classifier loss: 0.547321; batch adversarial loss: 0.559624\n",
      "epoch 15; iter: 0; batch classifier loss: 0.509656; batch adversarial loss: 0.575674\n",
      "epoch 16; iter: 0; batch classifier loss: 0.506461; batch adversarial loss: 0.590305\n",
      "epoch 17; iter: 0; batch classifier loss: 0.508308; batch adversarial loss: 0.572837\n",
      "epoch 18; iter: 0; batch classifier loss: 0.552966; batch adversarial loss: 0.575487\n",
      "epoch 19; iter: 0; batch classifier loss: 0.509137; batch adversarial loss: 0.559085\n",
      "epoch 20; iter: 0; batch classifier loss: 0.420668; batch adversarial loss: 0.608892\n",
      "epoch 21; iter: 0; batch classifier loss: 0.493266; batch adversarial loss: 0.584553\n",
      "epoch 22; iter: 0; batch classifier loss: 0.527668; batch adversarial loss: 0.565906\n",
      "epoch 23; iter: 0; batch classifier loss: 0.455821; batch adversarial loss: 0.540913\n",
      "epoch 24; iter: 0; batch classifier loss: 0.563541; batch adversarial loss: 0.593311\n",
      "epoch 25; iter: 0; batch classifier loss: 0.439561; batch adversarial loss: 0.567809\n",
      "epoch 26; iter: 0; batch classifier loss: 0.416149; batch adversarial loss: 0.570774\n",
      "epoch 27; iter: 0; batch classifier loss: 0.461318; batch adversarial loss: 0.543113\n",
      "epoch 28; iter: 0; batch classifier loss: 0.515739; batch adversarial loss: 0.553554\n",
      "epoch 29; iter: 0; batch classifier loss: 0.370029; batch adversarial loss: 0.539101\n",
      "epoch 30; iter: 0; batch classifier loss: 0.463282; batch adversarial loss: 0.562181\n",
      "epoch 31; iter: 0; batch classifier loss: 0.520237; batch adversarial loss: 0.564429\n",
      "epoch 32; iter: 0; batch classifier loss: 0.478923; batch adversarial loss: 0.543538\n",
      "epoch 33; iter: 0; batch classifier loss: 0.474483; batch adversarial loss: 0.544436\n",
      "epoch 34; iter: 0; batch classifier loss: 0.475851; batch adversarial loss: 0.528258\n",
      "epoch 35; iter: 0; batch classifier loss: 0.454379; batch adversarial loss: 0.545256\n",
      "epoch 36; iter: 0; batch classifier loss: 0.496388; batch adversarial loss: 0.572713\n",
      "epoch 37; iter: 0; batch classifier loss: 0.436672; batch adversarial loss: 0.482492\n",
      "epoch 38; iter: 0; batch classifier loss: 0.454871; batch adversarial loss: 0.589065\n",
      "epoch 39; iter: 0; batch classifier loss: 0.484093; batch adversarial loss: 0.488693\n",
      "epoch 40; iter: 0; batch classifier loss: 0.402042; batch adversarial loss: 0.535698\n",
      "epoch 41; iter: 0; batch classifier loss: 0.392331; batch adversarial loss: 0.582687\n",
      "epoch 42; iter: 0; batch classifier loss: 0.410688; batch adversarial loss: 0.506992\n",
      "epoch 43; iter: 0; batch classifier loss: 0.497861; batch adversarial loss: 0.633103\n",
      "epoch 44; iter: 0; batch classifier loss: 0.422963; batch adversarial loss: 0.670198\n",
      "epoch 45; iter: 0; batch classifier loss: 0.508922; batch adversarial loss: 0.508375\n",
      "epoch 46; iter: 0; batch classifier loss: 0.424155; batch adversarial loss: 0.570581\n",
      "epoch 47; iter: 0; batch classifier loss: 0.458894; batch adversarial loss: 0.571117\n",
      "epoch 48; iter: 0; batch classifier loss: 0.516779; batch adversarial loss: 0.544781\n",
      "epoch 49; iter: 0; batch classifier loss: 0.372903; batch adversarial loss: 0.635791\n",
      "epoch 50; iter: 0; batch classifier loss: 0.424883; batch adversarial loss: 0.582431\n",
      "epoch 51; iter: 0; batch classifier loss: 0.364276; batch adversarial loss: 0.497117\n",
      "epoch 52; iter: 0; batch classifier loss: 0.497665; batch adversarial loss: 0.516083\n",
      "epoch 53; iter: 0; batch classifier loss: 0.423719; batch adversarial loss: 0.508488\n",
      "epoch 54; iter: 0; batch classifier loss: 0.452394; batch adversarial loss: 0.534287\n",
      "epoch 55; iter: 0; batch classifier loss: 0.498223; batch adversarial loss: 0.572143\n",
      "epoch 56; iter: 0; batch classifier loss: 0.412408; batch adversarial loss: 0.509769\n",
      "epoch 57; iter: 0; batch classifier loss: 0.347134; batch adversarial loss: 0.519092\n",
      "epoch 58; iter: 0; batch classifier loss: 0.453368; batch adversarial loss: 0.534783\n",
      "epoch 59; iter: 0; batch classifier loss: 0.401204; batch adversarial loss: 0.563582\n",
      "epoch 60; iter: 0; batch classifier loss: 0.414020; batch adversarial loss: 0.534542\n",
      "epoch 61; iter: 0; batch classifier loss: 0.382423; batch adversarial loss: 0.599163\n",
      "epoch 62; iter: 0; batch classifier loss: 0.426248; batch adversarial loss: 0.488370\n",
      "epoch 63; iter: 0; batch classifier loss: 0.442841; batch adversarial loss: 0.625642\n",
      "epoch 64; iter: 0; batch classifier loss: 0.433498; batch adversarial loss: 0.489319\n",
      "epoch 65; iter: 0; batch classifier loss: 0.454548; batch adversarial loss: 0.525342\n",
      "epoch 66; iter: 0; batch classifier loss: 0.396795; batch adversarial loss: 0.516237\n",
      "epoch 67; iter: 0; batch classifier loss: 0.446597; batch adversarial loss: 0.544396\n",
      "epoch 68; iter: 0; batch classifier loss: 0.475463; batch adversarial loss: 0.442949\n",
      "epoch 69; iter: 0; batch classifier loss: 0.356354; batch adversarial loss: 0.580023\n",
      "epoch 70; iter: 0; batch classifier loss: 0.396201; batch adversarial loss: 0.591593\n",
      "epoch 71; iter: 0; batch classifier loss: 0.399252; batch adversarial loss: 0.518731\n",
      "epoch 72; iter: 0; batch classifier loss: 0.419396; batch adversarial loss: 0.589216\n",
      "epoch 73; iter: 0; batch classifier loss: 0.446698; batch adversarial loss: 0.572377\n",
      "epoch 74; iter: 0; batch classifier loss: 0.426207; batch adversarial loss: 0.489499\n",
      "epoch 75; iter: 0; batch classifier loss: 0.417365; batch adversarial loss: 0.574830\n",
      "epoch 76; iter: 0; batch classifier loss: 0.371788; batch adversarial loss: 0.579997\n",
      "epoch 77; iter: 0; batch classifier loss: 0.434177; batch adversarial loss: 0.597574\n",
      "epoch 78; iter: 0; batch classifier loss: 0.357542; batch adversarial loss: 0.498075\n",
      "epoch 79; iter: 0; batch classifier loss: 0.347960; batch adversarial loss: 0.543316\n",
      "epoch 80; iter: 0; batch classifier loss: 0.369476; batch adversarial loss: 0.572230\n",
      "epoch 81; iter: 0; batch classifier loss: 0.433394; batch adversarial loss: 0.526851\n",
      "epoch 82; iter: 0; batch classifier loss: 0.374578; batch adversarial loss: 0.554021\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 83; iter: 0; batch classifier loss: 0.341104; batch adversarial loss: 0.571543\n",
      "epoch 84; iter: 0; batch classifier loss: 0.395912; batch adversarial loss: 0.526102\n",
      "epoch 85; iter: 0; batch classifier loss: 0.417225; batch adversarial loss: 0.509016\n",
      "epoch 86; iter: 0; batch classifier loss: 0.358577; batch adversarial loss: 0.589911\n",
      "epoch 87; iter: 0; batch classifier loss: 0.455322; batch adversarial loss: 0.517627\n",
      "epoch 88; iter: 0; batch classifier loss: 0.440646; batch adversarial loss: 0.517213\n",
      "epoch 89; iter: 0; batch classifier loss: 0.419719; batch adversarial loss: 0.507711\n",
      "epoch 90; iter: 0; batch classifier loss: 0.443006; batch adversarial loss: 0.554704\n",
      "epoch 91; iter: 0; batch classifier loss: 0.363756; batch adversarial loss: 0.572350\n",
      "epoch 92; iter: 0; batch classifier loss: 0.371084; batch adversarial loss: 0.580270\n",
      "epoch 93; iter: 0; batch classifier loss: 0.402495; batch adversarial loss: 0.580224\n",
      "epoch 94; iter: 0; batch classifier loss: 0.379438; batch adversarial loss: 0.591772\n",
      "epoch 95; iter: 0; batch classifier loss: 0.394029; batch adversarial loss: 0.543633\n",
      "epoch 96; iter: 0; batch classifier loss: 0.385966; batch adversarial loss: 0.580106\n",
      "epoch 97; iter: 0; batch classifier loss: 0.392758; batch adversarial loss: 0.563157\n",
      "epoch 98; iter: 0; batch classifier loss: 0.350851; batch adversarial loss: 0.525463\n",
      "epoch 99; iter: 0; batch classifier loss: 0.425814; batch adversarial loss: 0.489682\n",
      "epoch 100; iter: 0; batch classifier loss: 0.372203; batch adversarial loss: 0.488976\n",
      "epoch 101; iter: 0; batch classifier loss: 0.399133; batch adversarial loss: 0.571031\n",
      "epoch 102; iter: 0; batch classifier loss: 0.410605; batch adversarial loss: 0.499805\n",
      "epoch 103; iter: 0; batch classifier loss: 0.339582; batch adversarial loss: 0.526634\n",
      "epoch 104; iter: 0; batch classifier loss: 0.375875; batch adversarial loss: 0.516276\n",
      "epoch 105; iter: 0; batch classifier loss: 0.482843; batch adversarial loss: 0.453448\n",
      "epoch 106; iter: 0; batch classifier loss: 0.335372; batch adversarial loss: 0.627574\n",
      "epoch 107; iter: 0; batch classifier loss: 0.341633; batch adversarial loss: 0.562385\n",
      "epoch 108; iter: 0; batch classifier loss: 0.471033; batch adversarial loss: 0.499902\n",
      "epoch 109; iter: 0; batch classifier loss: 0.396465; batch adversarial loss: 0.534828\n",
      "epoch 110; iter: 0; batch classifier loss: 0.456245; batch adversarial loss: 0.544701\n",
      "epoch 111; iter: 0; batch classifier loss: 0.385928; batch adversarial loss: 0.588851\n",
      "epoch 112; iter: 0; batch classifier loss: 0.398912; batch adversarial loss: 0.508352\n",
      "epoch 113; iter: 0; batch classifier loss: 0.438802; batch adversarial loss: 0.544245\n",
      "epoch 114; iter: 0; batch classifier loss: 0.410048; batch adversarial loss: 0.644372\n",
      "epoch 115; iter: 0; batch classifier loss: 0.378992; batch adversarial loss: 0.517098\n",
      "epoch 116; iter: 0; batch classifier loss: 0.441160; batch adversarial loss: 0.535051\n",
      "epoch 117; iter: 0; batch classifier loss: 0.449888; batch adversarial loss: 0.526906\n",
      "epoch 118; iter: 0; batch classifier loss: 0.302985; batch adversarial loss: 0.617659\n",
      "epoch 119; iter: 0; batch classifier loss: 0.423266; batch adversarial loss: 0.526322\n",
      "epoch 120; iter: 0; batch classifier loss: 0.423923; batch adversarial loss: 0.526444\n",
      "epoch 121; iter: 0; batch classifier loss: 0.375022; batch adversarial loss: 0.545513\n",
      "epoch 122; iter: 0; batch classifier loss: 0.344426; batch adversarial loss: 0.636003\n",
      "epoch 123; iter: 0; batch classifier loss: 0.344898; batch adversarial loss: 0.544246\n",
      "epoch 124; iter: 0; batch classifier loss: 0.370147; batch adversarial loss: 0.517045\n",
      "epoch 125; iter: 0; batch classifier loss: 0.332950; batch adversarial loss: 0.581266\n",
      "epoch 126; iter: 0; batch classifier loss: 0.556777; batch adversarial loss: 0.490176\n",
      "epoch 127; iter: 0; batch classifier loss: 0.397326; batch adversarial loss: 0.581089\n",
      "epoch 128; iter: 0; batch classifier loss: 0.399589; batch adversarial loss: 0.563506\n",
      "epoch 129; iter: 0; batch classifier loss: 0.373025; batch adversarial loss: 0.498678\n",
      "epoch 130; iter: 0; batch classifier loss: 0.409154; batch adversarial loss: 0.535918\n",
      "epoch 131; iter: 0; batch classifier loss: 0.355086; batch adversarial loss: 0.517280\n",
      "epoch 132; iter: 0; batch classifier loss: 0.443015; batch adversarial loss: 0.545398\n",
      "epoch 133; iter: 0; batch classifier loss: 0.391517; batch adversarial loss: 0.453056\n",
      "epoch 134; iter: 0; batch classifier loss: 0.381750; batch adversarial loss: 0.553364\n",
      "epoch 135; iter: 0; batch classifier loss: 0.368919; batch adversarial loss: 0.525648\n",
      "epoch 136; iter: 0; batch classifier loss: 0.488872; batch adversarial loss: 0.517704\n",
      "epoch 137; iter: 0; batch classifier loss: 0.307789; batch adversarial loss: 0.562813\n",
      "epoch 138; iter: 0; batch classifier loss: 0.348767; batch adversarial loss: 0.562210\n",
      "epoch 139; iter: 0; batch classifier loss: 0.419393; batch adversarial loss: 0.507771\n",
      "epoch 140; iter: 0; batch classifier loss: 0.357658; batch adversarial loss: 0.553279\n",
      "epoch 141; iter: 0; batch classifier loss: 0.452147; batch adversarial loss: 0.462154\n",
      "epoch 142; iter: 0; batch classifier loss: 0.460042; batch adversarial loss: 0.581128\n",
      "epoch 143; iter: 0; batch classifier loss: 0.382025; batch adversarial loss: 0.617794\n",
      "epoch 144; iter: 0; batch classifier loss: 0.410014; batch adversarial loss: 0.626524\n",
      "epoch 145; iter: 0; batch classifier loss: 0.357903; batch adversarial loss: 0.535338\n",
      "epoch 146; iter: 0; batch classifier loss: 0.411428; batch adversarial loss: 0.527021\n",
      "epoch 147; iter: 0; batch classifier loss: 0.332951; batch adversarial loss: 0.480721\n",
      "epoch 148; iter: 0; batch classifier loss: 0.341539; batch adversarial loss: 0.599710\n",
      "epoch 149; iter: 0; batch classifier loss: 0.454690; batch adversarial loss: 0.490266\n",
      "epoch 150; iter: 0; batch classifier loss: 0.445750; batch adversarial loss: 0.580946\n",
      "epoch 151; iter: 0; batch classifier loss: 0.380699; batch adversarial loss: 0.526239\n",
      "epoch 152; iter: 0; batch classifier loss: 0.355607; batch adversarial loss: 0.525938\n",
      "epoch 153; iter: 0; batch classifier loss: 0.328025; batch adversarial loss: 0.543923\n",
      "epoch 154; iter: 0; batch classifier loss: 0.361200; batch adversarial loss: 0.645774\n",
      "epoch 155; iter: 0; batch classifier loss: 0.286214; batch adversarial loss: 0.563730\n",
      "epoch 156; iter: 0; batch classifier loss: 0.381906; batch adversarial loss: 0.563095\n",
      "epoch 157; iter: 0; batch classifier loss: 0.367473; batch adversarial loss: 0.572038\n",
      "epoch 158; iter: 0; batch classifier loss: 0.297680; batch adversarial loss: 0.507900\n",
      "epoch 159; iter: 0; batch classifier loss: 0.391669; batch adversarial loss: 0.635584\n",
      "epoch 160; iter: 0; batch classifier loss: 0.433673; batch adversarial loss: 0.517386\n",
      "epoch 161; iter: 0; batch classifier loss: 0.325089; batch adversarial loss: 0.553628\n",
      "epoch 162; iter: 0; batch classifier loss: 0.343331; batch adversarial loss: 0.499015\n",
      "epoch 163; iter: 0; batch classifier loss: 0.373320; batch adversarial loss: 0.608638\n",
      "epoch 164; iter: 0; batch classifier loss: 0.333281; batch adversarial loss: 0.580951\n",
      "epoch 165; iter: 0; batch classifier loss: 0.306744; batch adversarial loss: 0.581118\n",
      "epoch 166; iter: 0; batch classifier loss: 0.346775; batch adversarial loss: 0.599166\n",
      "epoch 167; iter: 0; batch classifier loss: 0.400257; batch adversarial loss: 0.563237\n",
      "epoch 168; iter: 0; batch classifier loss: 0.341980; batch adversarial loss: 0.580634\n",
      "epoch 169; iter: 0; batch classifier loss: 0.357168; batch adversarial loss: 0.516934\n",
      "epoch 170; iter: 0; batch classifier loss: 0.345539; batch adversarial loss: 0.553788\n",
      "epoch 171; iter: 0; batch classifier loss: 0.416651; batch adversarial loss: 0.517250\n",
      "epoch 172; iter: 0; batch classifier loss: 0.326364; batch adversarial loss: 0.526109\n",
      "epoch 173; iter: 0; batch classifier loss: 0.440390; batch adversarial loss: 0.507850\n",
      "epoch 174; iter: 0; batch classifier loss: 0.348559; batch adversarial loss: 0.571800\n",
      "epoch 175; iter: 0; batch classifier loss: 0.271563; batch adversarial loss: 0.535488\n",
      "epoch 176; iter: 0; batch classifier loss: 0.339652; batch adversarial loss: 0.581011\n",
      "epoch 177; iter: 0; batch classifier loss: 0.394959; batch adversarial loss: 0.581078\n",
      "epoch 178; iter: 0; batch classifier loss: 0.368313; batch adversarial loss: 0.498648\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 179; iter: 0; batch classifier loss: 0.383403; batch adversarial loss: 0.553546\n",
      "epoch 180; iter: 0; batch classifier loss: 0.238576; batch adversarial loss: 0.571959\n",
      "epoch 181; iter: 0; batch classifier loss: 0.383688; batch adversarial loss: 0.498952\n",
      "epoch 182; iter: 0; batch classifier loss: 0.334612; batch adversarial loss: 0.553684\n",
      "epoch 183; iter: 0; batch classifier loss: 0.304797; batch adversarial loss: 0.453308\n",
      "epoch 184; iter: 0; batch classifier loss: 0.325581; batch adversarial loss: 0.517260\n",
      "epoch 185; iter: 0; batch classifier loss: 0.418407; batch adversarial loss: 0.544793\n",
      "epoch 186; iter: 0; batch classifier loss: 0.393299; batch adversarial loss: 0.544358\n",
      "epoch 187; iter: 0; batch classifier loss: 0.358809; batch adversarial loss: 0.608414\n",
      "epoch 188; iter: 0; batch classifier loss: 0.377174; batch adversarial loss: 0.535154\n",
      "epoch 189; iter: 0; batch classifier loss: 0.239442; batch adversarial loss: 0.553065\n",
      "epoch 190; iter: 0; batch classifier loss: 0.307792; batch adversarial loss: 0.553734\n",
      "epoch 191; iter: 0; batch classifier loss: 0.322155; batch adversarial loss: 0.581226\n",
      "epoch 192; iter: 0; batch classifier loss: 0.317721; batch adversarial loss: 0.507864\n",
      "epoch 193; iter: 0; batch classifier loss: 0.308112; batch adversarial loss: 0.489864\n",
      "epoch 194; iter: 0; batch classifier loss: 0.453976; batch adversarial loss: 0.562711\n",
      "epoch 195; iter: 0; batch classifier loss: 0.324484; batch adversarial loss: 0.562444\n",
      "epoch 196; iter: 0; batch classifier loss: 0.382261; batch adversarial loss: 0.517038\n",
      "epoch 197; iter: 0; batch classifier loss: 0.396495; batch adversarial loss: 0.589695\n",
      "epoch 198; iter: 0; batch classifier loss: 0.326089; batch adversarial loss: 0.599837\n",
      "epoch 199; iter: 0; batch classifier loss: 0.370014; batch adversarial loss: 0.517080\n",
      "epoch 0; iter: 0; batch classifier loss: 0.725396; batch adversarial loss: 0.676931\n",
      "epoch 1; iter: 0; batch classifier loss: 0.585687; batch adversarial loss: 0.643223\n",
      "epoch 2; iter: 0; batch classifier loss: 0.604506; batch adversarial loss: 0.613570\n",
      "epoch 3; iter: 0; batch classifier loss: 0.651004; batch adversarial loss: 0.611132\n",
      "epoch 4; iter: 0; batch classifier loss: 0.621198; batch adversarial loss: 0.634391\n",
      "epoch 5; iter: 0; batch classifier loss: 0.554901; batch adversarial loss: 0.601917\n",
      "epoch 6; iter: 0; batch classifier loss: 0.557036; batch adversarial loss: 0.604797\n",
      "epoch 7; iter: 0; batch classifier loss: 0.519795; batch adversarial loss: 0.574000\n",
      "epoch 8; iter: 0; batch classifier loss: 0.539649; batch adversarial loss: 0.568396\n",
      "epoch 9; iter: 0; batch classifier loss: 0.487240; batch adversarial loss: 0.656985\n",
      "epoch 10; iter: 0; batch classifier loss: 0.567764; batch adversarial loss: 0.588291\n",
      "epoch 11; iter: 0; batch classifier loss: 0.468429; batch adversarial loss: 0.537627\n",
      "epoch 12; iter: 0; batch classifier loss: 0.594487; batch adversarial loss: 0.643031\n",
      "epoch 13; iter: 0; batch classifier loss: 0.558383; batch adversarial loss: 0.590619\n",
      "epoch 14; iter: 0; batch classifier loss: 0.552617; batch adversarial loss: 0.593090\n",
      "epoch 15; iter: 0; batch classifier loss: 0.494874; batch adversarial loss: 0.622922\n",
      "epoch 16; iter: 0; batch classifier loss: 0.501776; batch adversarial loss: 0.602942\n",
      "epoch 17; iter: 0; batch classifier loss: 0.540561; batch adversarial loss: 0.566634\n",
      "epoch 18; iter: 0; batch classifier loss: 0.531572; batch adversarial loss: 0.571243\n",
      "epoch 19; iter: 0; batch classifier loss: 0.461734; batch adversarial loss: 0.531489\n",
      "epoch 20; iter: 0; batch classifier loss: 0.509110; batch adversarial loss: 0.587414\n",
      "epoch 21; iter: 0; batch classifier loss: 0.527070; batch adversarial loss: 0.528219\n",
      "epoch 22; iter: 0; batch classifier loss: 0.509929; batch adversarial loss: 0.553071\n",
      "epoch 23; iter: 0; batch classifier loss: 0.552647; batch adversarial loss: 0.505073\n",
      "epoch 24; iter: 0; batch classifier loss: 0.510408; batch adversarial loss: 0.516112\n",
      "epoch 25; iter: 0; batch classifier loss: 0.471352; batch adversarial loss: 0.567729\n",
      "epoch 26; iter: 0; batch classifier loss: 0.469352; batch adversarial loss: 0.475093\n",
      "epoch 27; iter: 0; batch classifier loss: 0.500892; batch adversarial loss: 0.513763\n",
      "epoch 28; iter: 0; batch classifier loss: 0.514075; batch adversarial loss: 0.550056\n",
      "epoch 29; iter: 0; batch classifier loss: 0.440399; batch adversarial loss: 0.530263\n",
      "epoch 30; iter: 0; batch classifier loss: 0.460148; batch adversarial loss: 0.515369\n",
      "epoch 31; iter: 0; batch classifier loss: 0.470704; batch adversarial loss: 0.630939\n",
      "epoch 32; iter: 0; batch classifier loss: 0.460310; batch adversarial loss: 0.535368\n",
      "epoch 33; iter: 0; batch classifier loss: 0.532859; batch adversarial loss: 0.599896\n",
      "epoch 34; iter: 0; batch classifier loss: 0.419904; batch adversarial loss: 0.609065\n",
      "epoch 35; iter: 0; batch classifier loss: 0.454544; batch adversarial loss: 0.537115\n",
      "epoch 36; iter: 0; batch classifier loss: 0.415337; batch adversarial loss: 0.573105\n",
      "epoch 37; iter: 0; batch classifier loss: 0.461383; batch adversarial loss: 0.543125\n",
      "epoch 38; iter: 0; batch classifier loss: 0.492511; batch adversarial loss: 0.598734\n",
      "epoch 39; iter: 0; batch classifier loss: 0.513760; batch adversarial loss: 0.516386\n",
      "epoch 40; iter: 0; batch classifier loss: 0.461603; batch adversarial loss: 0.580793\n",
      "epoch 41; iter: 0; batch classifier loss: 0.470908; batch adversarial loss: 0.580979\n",
      "epoch 42; iter: 0; batch classifier loss: 0.475437; batch adversarial loss: 0.534911\n",
      "epoch 43; iter: 0; batch classifier loss: 0.394103; batch adversarial loss: 0.535912\n",
      "epoch 44; iter: 0; batch classifier loss: 0.517230; batch adversarial loss: 0.536169\n",
      "epoch 45; iter: 0; batch classifier loss: 0.460600; batch adversarial loss: 0.545089\n",
      "epoch 46; iter: 0; batch classifier loss: 0.391230; batch adversarial loss: 0.508815\n",
      "epoch 47; iter: 0; batch classifier loss: 0.458966; batch adversarial loss: 0.597667\n",
      "epoch 48; iter: 0; batch classifier loss: 0.432634; batch adversarial loss: 0.498930\n",
      "epoch 49; iter: 0; batch classifier loss: 0.389975; batch adversarial loss: 0.433735\n",
      "epoch 50; iter: 0; batch classifier loss: 0.416070; batch adversarial loss: 0.499327\n",
      "epoch 51; iter: 0; batch classifier loss: 0.472520; batch adversarial loss: 0.509093\n",
      "epoch 52; iter: 0; batch classifier loss: 0.489033; batch adversarial loss: 0.582562\n",
      "epoch 53; iter: 0; batch classifier loss: 0.415439; batch adversarial loss: 0.561146\n",
      "epoch 54; iter: 0; batch classifier loss: 0.429533; batch adversarial loss: 0.500270\n",
      "epoch 55; iter: 0; batch classifier loss: 0.392291; batch adversarial loss: 0.525524\n",
      "epoch 56; iter: 0; batch classifier loss: 0.419352; batch adversarial loss: 0.617580\n",
      "epoch 57; iter: 0; batch classifier loss: 0.463306; batch adversarial loss: 0.672582\n",
      "epoch 58; iter: 0; batch classifier loss: 0.423346; batch adversarial loss: 0.508792\n",
      "epoch 59; iter: 0; batch classifier loss: 0.384305; batch adversarial loss: 0.554486\n",
      "epoch 60; iter: 0; batch classifier loss: 0.425694; batch adversarial loss: 0.552397\n",
      "epoch 61; iter: 0; batch classifier loss: 0.401328; batch adversarial loss: 0.553575\n",
      "epoch 62; iter: 0; batch classifier loss: 0.409828; batch adversarial loss: 0.515345\n",
      "epoch 63; iter: 0; batch classifier loss: 0.382557; batch adversarial loss: 0.499377\n",
      "epoch 64; iter: 0; batch classifier loss: 0.377899; batch adversarial loss: 0.545524\n",
      "epoch 65; iter: 0; batch classifier loss: 0.420523; batch adversarial loss: 0.543915\n",
      "epoch 66; iter: 0; batch classifier loss: 0.396615; batch adversarial loss: 0.517542\n",
      "epoch 67; iter: 0; batch classifier loss: 0.346603; batch adversarial loss: 0.525470\n",
      "epoch 68; iter: 0; batch classifier loss: 0.367718; batch adversarial loss: 0.526480\n",
      "epoch 69; iter: 0; batch classifier loss: 0.359430; batch adversarial loss: 0.471105\n",
      "epoch 70; iter: 0; batch classifier loss: 0.468286; batch adversarial loss: 0.433589\n",
      "epoch 71; iter: 0; batch classifier loss: 0.438501; batch adversarial loss: 0.525669\n",
      "epoch 72; iter: 0; batch classifier loss: 0.410868; batch adversarial loss: 0.509343\n",
      "epoch 73; iter: 0; batch classifier loss: 0.382219; batch adversarial loss: 0.535331\n",
      "epoch 74; iter: 0; batch classifier loss: 0.465406; batch adversarial loss: 0.574907\n",
      "epoch 75; iter: 0; batch classifier loss: 0.405592; batch adversarial loss: 0.514732\n",
      "epoch 76; iter: 0; batch classifier loss: 0.433542; batch adversarial loss: 0.570956\n",
      "epoch 77; iter: 0; batch classifier loss: 0.369699; batch adversarial loss: 0.633848\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 78; iter: 0; batch classifier loss: 0.403495; batch adversarial loss: 0.560150\n",
      "epoch 79; iter: 0; batch classifier loss: 0.500340; batch adversarial loss: 0.489014\n",
      "epoch 80; iter: 0; batch classifier loss: 0.395032; batch adversarial loss: 0.490696\n",
      "epoch 81; iter: 0; batch classifier loss: 0.419592; batch adversarial loss: 0.514609\n",
      "epoch 82; iter: 0; batch classifier loss: 0.324973; batch adversarial loss: 0.504858\n",
      "epoch 83; iter: 0; batch classifier loss: 0.436793; batch adversarial loss: 0.487144\n",
      "epoch 84; iter: 0; batch classifier loss: 0.372689; batch adversarial loss: 0.607893\n",
      "epoch 85; iter: 0; batch classifier loss: 0.442338; batch adversarial loss: 0.482794\n",
      "epoch 86; iter: 0; batch classifier loss: 0.380192; batch adversarial loss: 0.517343\n",
      "epoch 87; iter: 0; batch classifier loss: 0.486848; batch adversarial loss: 0.553938\n",
      "epoch 88; iter: 0; batch classifier loss: 0.439652; batch adversarial loss: 0.581414\n",
      "epoch 89; iter: 0; batch classifier loss: 0.460581; batch adversarial loss: 0.599691\n",
      "epoch 90; iter: 0; batch classifier loss: 0.419735; batch adversarial loss: 0.524869\n",
      "epoch 91; iter: 0; batch classifier loss: 0.344548; batch adversarial loss: 0.462778\n",
      "epoch 92; iter: 0; batch classifier loss: 0.326897; batch adversarial loss: 0.534156\n",
      "epoch 93; iter: 0; batch classifier loss: 0.426545; batch adversarial loss: 0.480789\n",
      "epoch 94; iter: 0; batch classifier loss: 0.364637; batch adversarial loss: 0.581043\n",
      "epoch 95; iter: 0; batch classifier loss: 0.368765; batch adversarial loss: 0.590882\n",
      "epoch 96; iter: 0; batch classifier loss: 0.351494; batch adversarial loss: 0.610520\n",
      "epoch 97; iter: 0; batch classifier loss: 0.426503; batch adversarial loss: 0.506654\n",
      "epoch 98; iter: 0; batch classifier loss: 0.402370; batch adversarial loss: 0.555127\n",
      "epoch 99; iter: 0; batch classifier loss: 0.341240; batch adversarial loss: 0.479246\n",
      "epoch 100; iter: 0; batch classifier loss: 0.372687; batch adversarial loss: 0.553099\n",
      "epoch 101; iter: 0; batch classifier loss: 0.429226; batch adversarial loss: 0.572590\n",
      "epoch 102; iter: 0; batch classifier loss: 0.399516; batch adversarial loss: 0.536282\n",
      "epoch 103; iter: 0; batch classifier loss: 0.398025; batch adversarial loss: 0.663950\n",
      "epoch 104; iter: 0; batch classifier loss: 0.351907; batch adversarial loss: 0.583980\n",
      "epoch 105; iter: 0; batch classifier loss: 0.393707; batch adversarial loss: 0.517259\n",
      "epoch 106; iter: 0; batch classifier loss: 0.450941; batch adversarial loss: 0.516750\n",
      "epoch 107; iter: 0; batch classifier loss: 0.347919; batch adversarial loss: 0.605099\n",
      "epoch 108; iter: 0; batch classifier loss: 0.338873; batch adversarial loss: 0.488071\n",
      "epoch 109; iter: 0; batch classifier loss: 0.400313; batch adversarial loss: 0.556363\n",
      "epoch 110; iter: 0; batch classifier loss: 0.476266; batch adversarial loss: 0.540475\n",
      "epoch 111; iter: 0; batch classifier loss: 0.386594; batch adversarial loss: 0.533830\n",
      "epoch 112; iter: 0; batch classifier loss: 0.376837; batch adversarial loss: 0.534068\n",
      "epoch 113; iter: 0; batch classifier loss: 0.372432; batch adversarial loss: 0.573225\n",
      "epoch 114; iter: 0; batch classifier loss: 0.447346; batch adversarial loss: 0.546074\n",
      "epoch 115; iter: 0; batch classifier loss: 0.364000; batch adversarial loss: 0.571649\n",
      "epoch 116; iter: 0; batch classifier loss: 0.409154; batch adversarial loss: 0.518908\n",
      "epoch 117; iter: 0; batch classifier loss: 0.323616; batch adversarial loss: 0.554349\n",
      "epoch 118; iter: 0; batch classifier loss: 0.437133; batch adversarial loss: 0.582590\n",
      "epoch 119; iter: 0; batch classifier loss: 0.378682; batch adversarial loss: 0.534459\n",
      "epoch 120; iter: 0; batch classifier loss: 0.423403; batch adversarial loss: 0.510911\n",
      "epoch 121; iter: 0; batch classifier loss: 0.397825; batch adversarial loss: 0.504631\n",
      "epoch 122; iter: 0; batch classifier loss: 0.454322; batch adversarial loss: 0.534976\n",
      "epoch 123; iter: 0; batch classifier loss: 0.414757; batch adversarial loss: 0.578632\n",
      "epoch 124; iter: 0; batch classifier loss: 0.382114; batch adversarial loss: 0.592910\n",
      "epoch 125; iter: 0; batch classifier loss: 0.392174; batch adversarial loss: 0.460390\n",
      "epoch 126; iter: 0; batch classifier loss: 0.409456; batch adversarial loss: 0.552995\n",
      "epoch 127; iter: 0; batch classifier loss: 0.378398; batch adversarial loss: 0.517346\n",
      "epoch 128; iter: 0; batch classifier loss: 0.376969; batch adversarial loss: 0.527965\n",
      "epoch 129; iter: 0; batch classifier loss: 0.494770; batch adversarial loss: 0.507668\n",
      "epoch 130; iter: 0; batch classifier loss: 0.438801; batch adversarial loss: 0.545292\n",
      "epoch 131; iter: 0; batch classifier loss: 0.372600; batch adversarial loss: 0.525318\n",
      "epoch 132; iter: 0; batch classifier loss: 0.331979; batch adversarial loss: 0.491239\n",
      "epoch 133; iter: 0; batch classifier loss: 0.397534; batch adversarial loss: 0.513140\n",
      "epoch 134; iter: 0; batch classifier loss: 0.299384; batch adversarial loss: 0.498705\n",
      "epoch 135; iter: 0; batch classifier loss: 0.326966; batch adversarial loss: 0.644959\n",
      "epoch 136; iter: 0; batch classifier loss: 0.399218; batch adversarial loss: 0.579653\n",
      "epoch 137; iter: 0; batch classifier loss: 0.407044; batch adversarial loss: 0.607962\n",
      "epoch 138; iter: 0; batch classifier loss: 0.349196; batch adversarial loss: 0.487414\n",
      "epoch 139; iter: 0; batch classifier loss: 0.351927; batch adversarial loss: 0.574449\n",
      "epoch 140; iter: 0; batch classifier loss: 0.325614; batch adversarial loss: 0.451469\n",
      "epoch 141; iter: 0; batch classifier loss: 0.363642; batch adversarial loss: 0.532351\n",
      "epoch 142; iter: 0; batch classifier loss: 0.347716; batch adversarial loss: 0.487992\n",
      "epoch 143; iter: 0; batch classifier loss: 0.313811; batch adversarial loss: 0.536121\n",
      "epoch 144; iter: 0; batch classifier loss: 0.363755; batch adversarial loss: 0.582530\n",
      "epoch 145; iter: 0; batch classifier loss: 0.437415; batch adversarial loss: 0.525375\n",
      "epoch 146; iter: 0; batch classifier loss: 0.381532; batch adversarial loss: 0.543502\n",
      "epoch 147; iter: 0; batch classifier loss: 0.306385; batch adversarial loss: 0.534533\n",
      "epoch 148; iter: 0; batch classifier loss: 0.381620; batch adversarial loss: 0.535775\n",
      "epoch 149; iter: 0; batch classifier loss: 0.377483; batch adversarial loss: 0.573252\n",
      "epoch 150; iter: 0; batch classifier loss: 0.400974; batch adversarial loss: 0.562001\n",
      "epoch 151; iter: 0; batch classifier loss: 0.363886; batch adversarial loss: 0.551835\n",
      "epoch 152; iter: 0; batch classifier loss: 0.313196; batch adversarial loss: 0.524166\n",
      "epoch 153; iter: 0; batch classifier loss: 0.402100; batch adversarial loss: 0.590411\n",
      "epoch 154; iter: 0; batch classifier loss: 0.352326; batch adversarial loss: 0.608942\n",
      "epoch 155; iter: 0; batch classifier loss: 0.431295; batch adversarial loss: 0.561987\n",
      "epoch 156; iter: 0; batch classifier loss: 0.379886; batch adversarial loss: 0.519014\n",
      "epoch 157; iter: 0; batch classifier loss: 0.396178; batch adversarial loss: 0.579347\n",
      "epoch 158; iter: 0; batch classifier loss: 0.488808; batch adversarial loss: 0.534075\n",
      "epoch 159; iter: 0; batch classifier loss: 0.309044; batch adversarial loss: 0.662069\n",
      "epoch 160; iter: 0; batch classifier loss: 0.422807; batch adversarial loss: 0.590189\n",
      "epoch 161; iter: 0; batch classifier loss: 0.410912; batch adversarial loss: 0.563164\n",
      "epoch 162; iter: 0; batch classifier loss: 0.368775; batch adversarial loss: 0.570081\n",
      "epoch 163; iter: 0; batch classifier loss: 0.399252; batch adversarial loss: 0.626501\n",
      "epoch 164; iter: 0; batch classifier loss: 0.344771; batch adversarial loss: 0.537335\n",
      "epoch 165; iter: 0; batch classifier loss: 0.300306; batch adversarial loss: 0.513768\n",
      "epoch 166; iter: 0; batch classifier loss: 0.346491; batch adversarial loss: 0.452258\n",
      "epoch 167; iter: 0; batch classifier loss: 0.438621; batch adversarial loss: 0.516914\n",
      "epoch 168; iter: 0; batch classifier loss: 0.369260; batch adversarial loss: 0.559892\n",
      "epoch 169; iter: 0; batch classifier loss: 0.353462; batch adversarial loss: 0.470690\n",
      "epoch 170; iter: 0; batch classifier loss: 0.369064; batch adversarial loss: 0.589265\n",
      "epoch 171; iter: 0; batch classifier loss: 0.396402; batch adversarial loss: 0.581147\n",
      "epoch 172; iter: 0; batch classifier loss: 0.378675; batch adversarial loss: 0.579848\n",
      "epoch 173; iter: 0; batch classifier loss: 0.329061; batch adversarial loss: 0.562996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 174; iter: 0; batch classifier loss: 0.339039; batch adversarial loss: 0.507933\n",
      "epoch 175; iter: 0; batch classifier loss: 0.415324; batch adversarial loss: 0.572762\n",
      "epoch 176; iter: 0; batch classifier loss: 0.363605; batch adversarial loss: 0.476700\n",
      "epoch 177; iter: 0; batch classifier loss: 0.349410; batch adversarial loss: 0.515170\n",
      "epoch 178; iter: 0; batch classifier loss: 0.440495; batch adversarial loss: 0.553853\n",
      "epoch 179; iter: 0; batch classifier loss: 0.351683; batch adversarial loss: 0.599944\n",
      "epoch 180; iter: 0; batch classifier loss: 0.402935; batch adversarial loss: 0.514389\n",
      "epoch 181; iter: 0; batch classifier loss: 0.365368; batch adversarial loss: 0.527026\n",
      "epoch 182; iter: 0; batch classifier loss: 0.384055; batch adversarial loss: 0.554716\n",
      "epoch 183; iter: 0; batch classifier loss: 0.292269; batch adversarial loss: 0.485959\n",
      "epoch 184; iter: 0; batch classifier loss: 0.327440; batch adversarial loss: 0.517238\n",
      "epoch 185; iter: 0; batch classifier loss: 0.463039; batch adversarial loss: 0.534970\n",
      "epoch 186; iter: 0; batch classifier loss: 0.332878; batch adversarial loss: 0.561085\n",
      "epoch 187; iter: 0; batch classifier loss: 0.343814; batch adversarial loss: 0.533668\n",
      "epoch 188; iter: 0; batch classifier loss: 0.379431; batch adversarial loss: 0.489484\n",
      "epoch 189; iter: 0; batch classifier loss: 0.336455; batch adversarial loss: 0.658131\n",
      "epoch 190; iter: 0; batch classifier loss: 0.376615; batch adversarial loss: 0.450997\n",
      "epoch 191; iter: 0; batch classifier loss: 0.348620; batch adversarial loss: 0.599321\n",
      "epoch 192; iter: 0; batch classifier loss: 0.397612; batch adversarial loss: 0.569525\n",
      "epoch 193; iter: 0; batch classifier loss: 0.343939; batch adversarial loss: 0.590927\n",
      "epoch 194; iter: 0; batch classifier loss: 0.296625; batch adversarial loss: 0.553112\n",
      "epoch 195; iter: 0; batch classifier loss: 0.443377; batch adversarial loss: 0.536266\n",
      "epoch 196; iter: 0; batch classifier loss: 0.395354; batch adversarial loss: 0.553297\n",
      "epoch 197; iter: 0; batch classifier loss: 0.346459; batch adversarial loss: 0.635876\n",
      "epoch 198; iter: 0; batch classifier loss: 0.301210; batch adversarial loss: 0.526809\n",
      "epoch 199; iter: 0; batch classifier loss: 0.398941; batch adversarial loss: 0.481237\n",
      "epoch 0; iter: 0; batch classifier loss: 0.656796; batch adversarial loss: 0.633221\n",
      "epoch 1; iter: 0; batch classifier loss: 0.564856; batch adversarial loss: 0.650438\n",
      "epoch 2; iter: 0; batch classifier loss: 0.636147; batch adversarial loss: 0.611394\n",
      "epoch 3; iter: 0; batch classifier loss: 0.598418; batch adversarial loss: 0.607159\n",
      "epoch 4; iter: 0; batch classifier loss: 0.550585; batch adversarial loss: 0.622545\n",
      "epoch 5; iter: 0; batch classifier loss: 0.512647; batch adversarial loss: 0.615551\n",
      "epoch 6; iter: 0; batch classifier loss: 0.540461; batch adversarial loss: 0.642857\n",
      "epoch 7; iter: 0; batch classifier loss: 0.520687; batch adversarial loss: 0.637286\n",
      "epoch 8; iter: 0; batch classifier loss: 0.557973; batch adversarial loss: 0.660933\n",
      "epoch 9; iter: 0; batch classifier loss: 0.579765; batch adversarial loss: 0.642801\n",
      "epoch 10; iter: 0; batch classifier loss: 0.560481; batch adversarial loss: 0.640483\n",
      "epoch 11; iter: 0; batch classifier loss: 0.554886; batch adversarial loss: 0.576054\n",
      "epoch 12; iter: 0; batch classifier loss: 0.518024; batch adversarial loss: 0.572633\n",
      "epoch 13; iter: 0; batch classifier loss: 0.504462; batch adversarial loss: 0.624336\n",
      "epoch 14; iter: 0; batch classifier loss: 0.534256; batch adversarial loss: 0.521687\n",
      "epoch 15; iter: 0; batch classifier loss: 0.700360; batch adversarial loss: 0.618448\n",
      "epoch 16; iter: 0; batch classifier loss: 0.587802; batch adversarial loss: 0.564836\n",
      "epoch 17; iter: 0; batch classifier loss: 0.528745; batch adversarial loss: 0.602332\n",
      "epoch 18; iter: 0; batch classifier loss: 0.396776; batch adversarial loss: 0.585735\n",
      "epoch 19; iter: 0; batch classifier loss: 0.560332; batch adversarial loss: 0.510720\n",
      "epoch 20; iter: 0; batch classifier loss: 0.479936; batch adversarial loss: 0.600312\n",
      "epoch 21; iter: 0; batch classifier loss: 0.464359; batch adversarial loss: 0.595989\n",
      "epoch 22; iter: 0; batch classifier loss: 0.503375; batch adversarial loss: 0.474431\n",
      "epoch 23; iter: 0; batch classifier loss: 0.489101; batch adversarial loss: 0.574476\n",
      "epoch 24; iter: 0; batch classifier loss: 0.474253; batch adversarial loss: 0.565012\n",
      "epoch 25; iter: 0; batch classifier loss: 0.427851; batch adversarial loss: 0.626990\n",
      "epoch 26; iter: 0; batch classifier loss: 0.378960; batch adversarial loss: 0.581263\n",
      "epoch 27; iter: 0; batch classifier loss: 0.511193; batch adversarial loss: 0.515729\n",
      "epoch 28; iter: 0; batch classifier loss: 0.499452; batch adversarial loss: 0.534811\n",
      "epoch 29; iter: 0; batch classifier loss: 0.497133; batch adversarial loss: 0.537643\n",
      "epoch 30; iter: 0; batch classifier loss: 0.513257; batch adversarial loss: 0.554953\n",
      "epoch 31; iter: 0; batch classifier loss: 0.425924; batch adversarial loss: 0.494465\n",
      "epoch 32; iter: 0; batch classifier loss: 0.506938; batch adversarial loss: 0.546175\n",
      "epoch 33; iter: 0; batch classifier loss: 0.403604; batch adversarial loss: 0.526067\n",
      "epoch 34; iter: 0; batch classifier loss: 0.467663; batch adversarial loss: 0.546357\n",
      "epoch 35; iter: 0; batch classifier loss: 0.424664; batch adversarial loss: 0.570255\n",
      "epoch 36; iter: 0; batch classifier loss: 0.431122; batch adversarial loss: 0.517808\n",
      "epoch 37; iter: 0; batch classifier loss: 0.414158; batch adversarial loss: 0.544809\n",
      "epoch 38; iter: 0; batch classifier loss: 0.435359; batch adversarial loss: 0.562825\n",
      "epoch 39; iter: 0; batch classifier loss: 0.427318; batch adversarial loss: 0.536282\n",
      "epoch 40; iter: 0; batch classifier loss: 0.458541; batch adversarial loss: 0.517783\n",
      "epoch 41; iter: 0; batch classifier loss: 0.403630; batch adversarial loss: 0.490568\n",
      "epoch 42; iter: 0; batch classifier loss: 0.413761; batch adversarial loss: 0.562634\n",
      "epoch 43; iter: 0; batch classifier loss: 0.449325; batch adversarial loss: 0.553520\n",
      "epoch 44; iter: 0; batch classifier loss: 0.470647; batch adversarial loss: 0.544745\n",
      "epoch 45; iter: 0; batch classifier loss: 0.408417; batch adversarial loss: 0.553392\n",
      "epoch 46; iter: 0; batch classifier loss: 0.438850; batch adversarial loss: 0.535232\n",
      "epoch 47; iter: 0; batch classifier loss: 0.395516; batch adversarial loss: 0.443536\n",
      "epoch 48; iter: 0; batch classifier loss: 0.450316; batch adversarial loss: 0.535550\n",
      "epoch 49; iter: 0; batch classifier loss: 0.462449; batch adversarial loss: 0.508038\n",
      "epoch 50; iter: 0; batch classifier loss: 0.448436; batch adversarial loss: 0.562931\n",
      "epoch 51; iter: 0; batch classifier loss: 0.455396; batch adversarial loss: 0.581384\n",
      "epoch 52; iter: 0; batch classifier loss: 0.410620; batch adversarial loss: 0.617796\n",
      "epoch 53; iter: 0; batch classifier loss: 0.486862; batch adversarial loss: 0.517123\n",
      "epoch 54; iter: 0; batch classifier loss: 0.467774; batch adversarial loss: 0.535265\n",
      "epoch 55; iter: 0; batch classifier loss: 0.454320; batch adversarial loss: 0.499168\n",
      "epoch 56; iter: 0; batch classifier loss: 0.435396; batch adversarial loss: 0.553364\n",
      "epoch 57; iter: 0; batch classifier loss: 0.394367; batch adversarial loss: 0.498334\n",
      "epoch 58; iter: 0; batch classifier loss: 0.392945; batch adversarial loss: 0.562393\n",
      "epoch 59; iter: 0; batch classifier loss: 0.397653; batch adversarial loss: 0.452709\n",
      "epoch 60; iter: 0; batch classifier loss: 0.513376; batch adversarial loss: 0.507320\n",
      "epoch 61; iter: 0; batch classifier loss: 0.483672; batch adversarial loss: 0.590606\n",
      "epoch 62; iter: 0; batch classifier loss: 0.390999; batch adversarial loss: 0.663201\n",
      "epoch 63; iter: 0; batch classifier loss: 0.456914; batch adversarial loss: 0.535277\n",
      "epoch 64; iter: 0; batch classifier loss: 0.435087; batch adversarial loss: 0.471436\n",
      "epoch 65; iter: 0; batch classifier loss: 0.416425; batch adversarial loss: 0.554367\n",
      "epoch 66; iter: 0; batch classifier loss: 0.349622; batch adversarial loss: 0.499111\n",
      "epoch 67; iter: 0; batch classifier loss: 0.423245; batch adversarial loss: 0.553472\n",
      "epoch 68; iter: 0; batch classifier loss: 0.468794; batch adversarial loss: 0.526397\n",
      "epoch 69; iter: 0; batch classifier loss: 0.400502; batch adversarial loss: 0.462086\n",
      "epoch 70; iter: 0; batch classifier loss: 0.427615; batch adversarial loss: 0.452974\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 71; iter: 0; batch classifier loss: 0.389770; batch adversarial loss: 0.498419\n",
      "epoch 72; iter: 0; batch classifier loss: 0.447761; batch adversarial loss: 0.517529\n",
      "epoch 73; iter: 0; batch classifier loss: 0.479266; batch adversarial loss: 0.571717\n",
      "epoch 74; iter: 0; batch classifier loss: 0.387703; batch adversarial loss: 0.508116\n",
      "epoch 75; iter: 0; batch classifier loss: 0.393400; batch adversarial loss: 0.562456\n",
      "epoch 76; iter: 0; batch classifier loss: 0.453741; batch adversarial loss: 0.535191\n",
      "epoch 77; iter: 0; batch classifier loss: 0.408972; batch adversarial loss: 0.562024\n",
      "epoch 78; iter: 0; batch classifier loss: 0.424581; batch adversarial loss: 0.534674\n",
      "epoch 79; iter: 0; batch classifier loss: 0.491101; batch adversarial loss: 0.545026\n",
      "epoch 80; iter: 0; batch classifier loss: 0.395835; batch adversarial loss: 0.470386\n",
      "epoch 81; iter: 0; batch classifier loss: 0.348366; batch adversarial loss: 0.554186\n",
      "epoch 82; iter: 0; batch classifier loss: 0.388979; batch adversarial loss: 0.608100\n",
      "epoch 83; iter: 0; batch classifier loss: 0.450546; batch adversarial loss: 0.608571\n",
      "epoch 84; iter: 0; batch classifier loss: 0.405549; batch adversarial loss: 0.535402\n",
      "epoch 85; iter: 0; batch classifier loss: 0.472993; batch adversarial loss: 0.571940\n",
      "epoch 86; iter: 0; batch classifier loss: 0.353787; batch adversarial loss: 0.562826\n",
      "epoch 87; iter: 0; batch classifier loss: 0.428731; batch adversarial loss: 0.571893\n",
      "epoch 88; iter: 0; batch classifier loss: 0.363360; batch adversarial loss: 0.535369\n",
      "epoch 89; iter: 0; batch classifier loss: 0.476988; batch adversarial loss: 0.526320\n",
      "epoch 90; iter: 0; batch classifier loss: 0.377715; batch adversarial loss: 0.599312\n",
      "epoch 91; iter: 0; batch classifier loss: 0.376533; batch adversarial loss: 0.516981\n",
      "epoch 92; iter: 0; batch classifier loss: 0.384991; batch adversarial loss: 0.618094\n",
      "epoch 93; iter: 0; batch classifier loss: 0.368613; batch adversarial loss: 0.563111\n",
      "epoch 94; iter: 0; batch classifier loss: 0.373061; batch adversarial loss: 0.435001\n",
      "epoch 95; iter: 0; batch classifier loss: 0.442346; batch adversarial loss: 0.480486\n",
      "epoch 96; iter: 0; batch classifier loss: 0.413122; batch adversarial loss: 0.571895\n",
      "epoch 97; iter: 0; batch classifier loss: 0.418955; batch adversarial loss: 0.635745\n",
      "epoch 98; iter: 0; batch classifier loss: 0.412648; batch adversarial loss: 0.526241\n",
      "epoch 99; iter: 0; batch classifier loss: 0.368360; batch adversarial loss: 0.553561\n",
      "epoch 100; iter: 0; batch classifier loss: 0.431057; batch adversarial loss: 0.462243\n",
      "epoch 101; iter: 0; batch classifier loss: 0.400803; batch adversarial loss: 0.562786\n",
      "epoch 102; iter: 0; batch classifier loss: 0.347978; batch adversarial loss: 0.581082\n",
      "epoch 103; iter: 0; batch classifier loss: 0.360353; batch adversarial loss: 0.535859\n",
      "epoch 104; iter: 0; batch classifier loss: 0.452832; batch adversarial loss: 0.572051\n",
      "epoch 105; iter: 0; batch classifier loss: 0.397838; batch adversarial loss: 0.489480\n",
      "epoch 106; iter: 0; batch classifier loss: 0.329766; batch adversarial loss: 0.571377\n",
      "epoch 107; iter: 0; batch classifier loss: 0.408776; batch adversarial loss: 0.508166\n",
      "epoch 108; iter: 0; batch classifier loss: 0.470009; batch adversarial loss: 0.435592\n",
      "epoch 109; iter: 0; batch classifier loss: 0.385204; batch adversarial loss: 0.589435\n",
      "epoch 110; iter: 0; batch classifier loss: 0.353663; batch adversarial loss: 0.462997\n",
      "epoch 111; iter: 0; batch classifier loss: 0.412887; batch adversarial loss: 0.498553\n",
      "epoch 112; iter: 0; batch classifier loss: 0.395834; batch adversarial loss: 0.507038\n",
      "epoch 113; iter: 0; batch classifier loss: 0.340880; batch adversarial loss: 0.600232\n",
      "epoch 114; iter: 0; batch classifier loss: 0.389449; batch adversarial loss: 0.553778\n",
      "epoch 115; iter: 0; batch classifier loss: 0.396088; batch adversarial loss: 0.609832\n",
      "epoch 116; iter: 0; batch classifier loss: 0.387906; batch adversarial loss: 0.581713\n",
      "epoch 117; iter: 0; batch classifier loss: 0.476678; batch adversarial loss: 0.590583\n",
      "epoch 118; iter: 0; batch classifier loss: 0.370984; batch adversarial loss: 0.544419\n",
      "epoch 119; iter: 0; batch classifier loss: 0.409543; batch adversarial loss: 0.480910\n",
      "epoch 120; iter: 0; batch classifier loss: 0.469902; batch adversarial loss: 0.563032\n",
      "epoch 121; iter: 0; batch classifier loss: 0.402248; batch adversarial loss: 0.635913\n",
      "epoch 122; iter: 0; batch classifier loss: 0.351755; batch adversarial loss: 0.544298\n",
      "epoch 123; iter: 0; batch classifier loss: 0.328622; batch adversarial loss: 0.580312\n",
      "epoch 124; iter: 0; batch classifier loss: 0.411009; batch adversarial loss: 0.553457\n",
      "epoch 125; iter: 0; batch classifier loss: 0.338620; batch adversarial loss: 0.498505\n",
      "epoch 126; iter: 0; batch classifier loss: 0.406141; batch adversarial loss: 0.572502\n",
      "epoch 127; iter: 0; batch classifier loss: 0.367615; batch adversarial loss: 0.590411\n",
      "epoch 128; iter: 0; batch classifier loss: 0.351290; batch adversarial loss: 0.489503\n",
      "epoch 129; iter: 0; batch classifier loss: 0.332070; batch adversarial loss: 0.589452\n",
      "epoch 130; iter: 0; batch classifier loss: 0.410111; batch adversarial loss: 0.481416\n",
      "epoch 131; iter: 0; batch classifier loss: 0.384908; batch adversarial loss: 0.589615\n",
      "epoch 132; iter: 0; batch classifier loss: 0.419714; batch adversarial loss: 0.507956\n",
      "epoch 133; iter: 0; batch classifier loss: 0.310769; batch adversarial loss: 0.526387\n",
      "epoch 134; iter: 0; batch classifier loss: 0.355073; batch adversarial loss: 0.544502\n",
      "epoch 135; iter: 0; batch classifier loss: 0.421363; batch adversarial loss: 0.544879\n",
      "epoch 136; iter: 0; batch classifier loss: 0.309368; batch adversarial loss: 0.591016\n",
      "epoch 137; iter: 0; batch classifier loss: 0.281031; batch adversarial loss: 0.599268\n",
      "epoch 138; iter: 0; batch classifier loss: 0.400723; batch adversarial loss: 0.517413\n",
      "epoch 139; iter: 0; batch classifier loss: 0.428466; batch adversarial loss: 0.589735\n",
      "epoch 140; iter: 0; batch classifier loss: 0.369625; batch adversarial loss: 0.581418\n",
      "epoch 141; iter: 0; batch classifier loss: 0.442989; batch adversarial loss: 0.516785\n",
      "epoch 142; iter: 0; batch classifier loss: 0.415526; batch adversarial loss: 0.535917\n",
      "epoch 143; iter: 0; batch classifier loss: 0.399335; batch adversarial loss: 0.526927\n",
      "epoch 144; iter: 0; batch classifier loss: 0.415311; batch adversarial loss: 0.488812\n",
      "epoch 145; iter: 0; batch classifier loss: 0.362393; batch adversarial loss: 0.480308\n",
      "epoch 146; iter: 0; batch classifier loss: 0.416419; batch adversarial loss: 0.545016\n",
      "epoch 147; iter: 0; batch classifier loss: 0.426001; batch adversarial loss: 0.498739\n",
      "epoch 148; iter: 0; batch classifier loss: 0.419120; batch adversarial loss: 0.507976\n",
      "epoch 149; iter: 0; batch classifier loss: 0.438562; batch adversarial loss: 0.508048\n",
      "epoch 150; iter: 0; batch classifier loss: 0.368722; batch adversarial loss: 0.535296\n",
      "epoch 151; iter: 0; batch classifier loss: 0.307515; batch adversarial loss: 0.581048\n",
      "epoch 152; iter: 0; batch classifier loss: 0.387417; batch adversarial loss: 0.571866\n",
      "epoch 153; iter: 0; batch classifier loss: 0.391510; batch adversarial loss: 0.572027\n",
      "epoch 154; iter: 0; batch classifier loss: 0.412438; batch adversarial loss: 0.571963\n",
      "epoch 155; iter: 0; batch classifier loss: 0.346839; batch adversarial loss: 0.526004\n",
      "epoch 156; iter: 0; batch classifier loss: 0.432025; batch adversarial loss: 0.516984\n",
      "epoch 157; iter: 0; batch classifier loss: 0.392099; batch adversarial loss: 0.535351\n",
      "epoch 158; iter: 0; batch classifier loss: 0.347951; batch adversarial loss: 0.600392\n",
      "epoch 159; iter: 0; batch classifier loss: 0.344119; batch adversarial loss: 0.599420\n",
      "epoch 160; iter: 0; batch classifier loss: 0.343872; batch adversarial loss: 0.481042\n",
      "epoch 161; iter: 0; batch classifier loss: 0.329789; batch adversarial loss: 0.498180\n",
      "epoch 162; iter: 0; batch classifier loss: 0.401033; batch adversarial loss: 0.498768\n",
      "epoch 163; iter: 0; batch classifier loss: 0.406940; batch adversarial loss: 0.590224\n",
      "epoch 164; iter: 0; batch classifier loss: 0.346321; batch adversarial loss: 0.498828\n",
      "epoch 165; iter: 0; batch classifier loss: 0.374479; batch adversarial loss: 0.607983\n",
      "epoch 166; iter: 0; batch classifier loss: 0.392208; batch adversarial loss: 0.581013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 167; iter: 0; batch classifier loss: 0.283079; batch adversarial loss: 0.480164\n",
      "epoch 168; iter: 0; batch classifier loss: 0.345678; batch adversarial loss: 0.535161\n",
      "epoch 169; iter: 0; batch classifier loss: 0.303283; batch adversarial loss: 0.508021\n",
      "epoch 170; iter: 0; batch classifier loss: 0.436411; batch adversarial loss: 0.573007\n",
      "epoch 171; iter: 0; batch classifier loss: 0.358728; batch adversarial loss: 0.581553\n",
      "epoch 172; iter: 0; batch classifier loss: 0.400500; batch adversarial loss: 0.507764\n",
      "epoch 173; iter: 0; batch classifier loss: 0.315785; batch adversarial loss: 0.562303\n",
      "epoch 174; iter: 0; batch classifier loss: 0.318538; batch adversarial loss: 0.536164\n",
      "epoch 175; iter: 0; batch classifier loss: 0.387331; batch adversarial loss: 0.572168\n",
      "epoch 176; iter: 0; batch classifier loss: 0.388662; batch adversarial loss: 0.526130\n",
      "epoch 177; iter: 0; batch classifier loss: 0.389609; batch adversarial loss: 0.535171\n",
      "epoch 178; iter: 0; batch classifier loss: 0.419382; batch adversarial loss: 0.507895\n",
      "epoch 179; iter: 0; batch classifier loss: 0.347823; batch adversarial loss: 0.608824\n",
      "epoch 180; iter: 0; batch classifier loss: 0.338185; batch adversarial loss: 0.653778\n",
      "epoch 181; iter: 0; batch classifier loss: 0.349690; batch adversarial loss: 0.617842\n",
      "epoch 182; iter: 0; batch classifier loss: 0.370500; batch adversarial loss: 0.544256\n",
      "epoch 183; iter: 0; batch classifier loss: 0.389507; batch adversarial loss: 0.507243\n",
      "epoch 184; iter: 0; batch classifier loss: 0.332559; batch adversarial loss: 0.534983\n",
      "epoch 185; iter: 0; batch classifier loss: 0.396854; batch adversarial loss: 0.527697\n",
      "epoch 186; iter: 0; batch classifier loss: 0.384175; batch adversarial loss: 0.561587\n",
      "epoch 187; iter: 0; batch classifier loss: 0.327883; batch adversarial loss: 0.562489\n",
      "epoch 188; iter: 0; batch classifier loss: 0.463258; batch adversarial loss: 0.581249\n",
      "epoch 189; iter: 0; batch classifier loss: 0.322129; batch adversarial loss: 0.590756\n",
      "epoch 190; iter: 0; batch classifier loss: 0.341742; batch adversarial loss: 0.544222\n",
      "epoch 191; iter: 0; batch classifier loss: 0.415875; batch adversarial loss: 0.534707\n",
      "epoch 192; iter: 0; batch classifier loss: 0.316095; batch adversarial loss: 0.571267\n",
      "epoch 193; iter: 0; batch classifier loss: 0.326780; batch adversarial loss: 0.499234\n",
      "epoch 194; iter: 0; batch classifier loss: 0.388729; batch adversarial loss: 0.535023\n",
      "epoch 195; iter: 0; batch classifier loss: 0.311519; batch adversarial loss: 0.589678\n",
      "epoch 196; iter: 0; batch classifier loss: 0.392076; batch adversarial loss: 0.527162\n",
      "epoch 197; iter: 0; batch classifier loss: 0.314729; batch adversarial loss: 0.526806\n",
      "epoch 198; iter: 0; batch classifier loss: 0.386495; batch adversarial loss: 0.579317\n",
      "epoch 199; iter: 0; batch classifier loss: 0.328853; batch adversarial loss: 0.498636\n",
      "epoch 0; iter: 0; batch classifier loss: 0.817694; batch adversarial loss: 0.778483\n",
      "epoch 1; iter: 0; batch classifier loss: 0.674630; batch adversarial loss: 0.748217\n",
      "epoch 2; iter: 0; batch classifier loss: 0.760268; batch adversarial loss: 0.709072\n",
      "epoch 3; iter: 0; batch classifier loss: 0.693501; batch adversarial loss: 0.651006\n",
      "epoch 4; iter: 0; batch classifier loss: 0.649921; batch adversarial loss: 0.633325\n",
      "epoch 5; iter: 0; batch classifier loss: 0.614756; batch adversarial loss: 0.609420\n",
      "epoch 6; iter: 0; batch classifier loss: 0.500295; batch adversarial loss: 0.614313\n",
      "epoch 7; iter: 0; batch classifier loss: 0.556585; batch adversarial loss: 0.589476\n",
      "epoch 8; iter: 0; batch classifier loss: 0.518060; batch adversarial loss: 0.612472\n",
      "epoch 9; iter: 0; batch classifier loss: 0.573510; batch adversarial loss: 0.619893\n",
      "epoch 10; iter: 0; batch classifier loss: 0.474765; batch adversarial loss: 0.595042\n",
      "epoch 11; iter: 0; batch classifier loss: 0.500744; batch adversarial loss: 0.574147\n",
      "epoch 12; iter: 0; batch classifier loss: 0.525125; batch adversarial loss: 0.599463\n",
      "epoch 13; iter: 0; batch classifier loss: 0.559031; batch adversarial loss: 0.610947\n",
      "epoch 14; iter: 0; batch classifier loss: 0.478379; batch adversarial loss: 0.575913\n",
      "epoch 15; iter: 0; batch classifier loss: 0.508003; batch adversarial loss: 0.534064\n",
      "epoch 16; iter: 0; batch classifier loss: 0.483631; batch adversarial loss: 0.556412\n",
      "epoch 17; iter: 0; batch classifier loss: 0.480074; batch adversarial loss: 0.593428\n",
      "epoch 18; iter: 0; batch classifier loss: 0.503443; batch adversarial loss: 0.589941\n",
      "epoch 19; iter: 0; batch classifier loss: 0.490503; batch adversarial loss: 0.524715\n",
      "epoch 20; iter: 0; batch classifier loss: 0.510009; batch adversarial loss: 0.561838\n",
      "epoch 21; iter: 0; batch classifier loss: 0.403231; batch adversarial loss: 0.616856\n",
      "epoch 22; iter: 0; batch classifier loss: 0.434554; batch adversarial loss: 0.599768\n",
      "epoch 23; iter: 0; batch classifier loss: 0.468373; batch adversarial loss: 0.542868\n",
      "epoch 24; iter: 0; batch classifier loss: 0.474496; batch adversarial loss: 0.555049\n",
      "epoch 25; iter: 0; batch classifier loss: 0.523750; batch adversarial loss: 0.620437\n",
      "epoch 26; iter: 0; batch classifier loss: 0.431989; batch adversarial loss: 0.516307\n",
      "epoch 27; iter: 0; batch classifier loss: 0.486651; batch adversarial loss: 0.530625\n",
      "epoch 28; iter: 0; batch classifier loss: 0.484867; batch adversarial loss: 0.576386\n",
      "epoch 29; iter: 0; batch classifier loss: 0.452470; batch adversarial loss: 0.566335\n",
      "epoch 30; iter: 0; batch classifier loss: 0.495559; batch adversarial loss: 0.607546\n",
      "epoch 31; iter: 0; batch classifier loss: 0.405330; batch adversarial loss: 0.625581\n",
      "epoch 32; iter: 0; batch classifier loss: 0.405702; batch adversarial loss: 0.515363\n",
      "epoch 33; iter: 0; batch classifier loss: 0.466345; batch adversarial loss: 0.582430\n",
      "epoch 34; iter: 0; batch classifier loss: 0.494575; batch adversarial loss: 0.621987\n",
      "epoch 35; iter: 0; batch classifier loss: 0.465654; batch adversarial loss: 0.464532\n",
      "epoch 36; iter: 0; batch classifier loss: 0.414799; batch adversarial loss: 0.571678\n",
      "epoch 37; iter: 0; batch classifier loss: 0.471508; batch adversarial loss: 0.579800\n",
      "epoch 38; iter: 0; batch classifier loss: 0.380358; batch adversarial loss: 0.514167\n",
      "epoch 39; iter: 0; batch classifier loss: 0.414851; batch adversarial loss: 0.530035\n",
      "epoch 40; iter: 0; batch classifier loss: 0.499278; batch adversarial loss: 0.545877\n",
      "epoch 41; iter: 0; batch classifier loss: 0.465503; batch adversarial loss: 0.545574\n",
      "epoch 42; iter: 0; batch classifier loss: 0.458516; batch adversarial loss: 0.503734\n",
      "epoch 43; iter: 0; batch classifier loss: 0.469280; batch adversarial loss: 0.562316\n",
      "epoch 44; iter: 0; batch classifier loss: 0.344787; batch adversarial loss: 0.587406\n",
      "epoch 45; iter: 0; batch classifier loss: 0.441460; batch adversarial loss: 0.553697\n",
      "epoch 46; iter: 0; batch classifier loss: 0.383473; batch adversarial loss: 0.570521\n",
      "epoch 47; iter: 0; batch classifier loss: 0.423283; batch adversarial loss: 0.595931\n",
      "epoch 48; iter: 0; batch classifier loss: 0.392686; batch adversarial loss: 0.578622\n",
      "epoch 49; iter: 0; batch classifier loss: 0.482084; batch adversarial loss: 0.503401\n",
      "epoch 50; iter: 0; batch classifier loss: 0.566403; batch adversarial loss: 0.544807\n",
      "epoch 51; iter: 0; batch classifier loss: 0.454543; batch adversarial loss: 0.544568\n",
      "epoch 52; iter: 0; batch classifier loss: 0.459289; batch adversarial loss: 0.561743\n",
      "epoch 53; iter: 0; batch classifier loss: 0.415579; batch adversarial loss: 0.536323\n",
      "epoch 54; iter: 0; batch classifier loss: 0.416097; batch adversarial loss: 0.544550\n",
      "epoch 55; iter: 0; batch classifier loss: 0.398276; batch adversarial loss: 0.552904\n",
      "epoch 56; iter: 0; batch classifier loss: 0.458752; batch adversarial loss: 0.571125\n",
      "epoch 57; iter: 0; batch classifier loss: 0.454369; batch adversarial loss: 0.569902\n",
      "epoch 58; iter: 0; batch classifier loss: 0.467584; batch adversarial loss: 0.502215\n",
      "epoch 59; iter: 0; batch classifier loss: 0.458801; batch adversarial loss: 0.570663\n",
      "epoch 60; iter: 0; batch classifier loss: 0.380680; batch adversarial loss: 0.543886\n",
      "epoch 61; iter: 0; batch classifier loss: 0.459206; batch adversarial loss: 0.509756\n",
      "epoch 62; iter: 0; batch classifier loss: 0.353866; batch adversarial loss: 0.631124\n",
      "epoch 63; iter: 0; batch classifier loss: 0.400150; batch adversarial loss: 0.596174\n",
      "epoch 64; iter: 0; batch classifier loss: 0.356327; batch adversarial loss: 0.565004\n",
      "epoch 65; iter: 0; batch classifier loss: 0.382654; batch adversarial loss: 0.607416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 66; iter: 0; batch classifier loss: 0.498182; batch adversarial loss: 0.594647\n",
      "epoch 67; iter: 0; batch classifier loss: 0.389681; batch adversarial loss: 0.572426\n",
      "epoch 68; iter: 0; batch classifier loss: 0.342525; batch adversarial loss: 0.562463\n",
      "epoch 69; iter: 0; batch classifier loss: 0.374532; batch adversarial loss: 0.578069\n",
      "epoch 70; iter: 0; batch classifier loss: 0.477607; batch adversarial loss: 0.560271\n",
      "epoch 71; iter: 0; batch classifier loss: 0.392078; batch adversarial loss: 0.535737\n",
      "epoch 72; iter: 0; batch classifier loss: 0.379520; batch adversarial loss: 0.561912\n",
      "epoch 73; iter: 0; batch classifier loss: 0.333561; batch adversarial loss: 0.623916\n",
      "epoch 74; iter: 0; batch classifier loss: 0.413894; batch adversarial loss: 0.599506\n",
      "epoch 75; iter: 0; batch classifier loss: 0.361480; batch adversarial loss: 0.545788\n",
      "epoch 76; iter: 0; batch classifier loss: 0.476135; batch adversarial loss: 0.562959\n",
      "epoch 77; iter: 0; batch classifier loss: 0.416596; batch adversarial loss: 0.518675\n",
      "epoch 78; iter: 0; batch classifier loss: 0.397244; batch adversarial loss: 0.563489\n",
      "epoch 79; iter: 0; batch classifier loss: 0.365732; batch adversarial loss: 0.563478\n",
      "epoch 80; iter: 0; batch classifier loss: 0.312192; batch adversarial loss: 0.519629\n",
      "epoch 81; iter: 0; batch classifier loss: 0.431576; batch adversarial loss: 0.468450\n",
      "epoch 82; iter: 0; batch classifier loss: 0.354661; batch adversarial loss: 0.588804\n",
      "epoch 83; iter: 0; batch classifier loss: 0.315234; batch adversarial loss: 0.536634\n",
      "epoch 84; iter: 0; batch classifier loss: 0.354416; batch adversarial loss: 0.572379\n",
      "epoch 85; iter: 0; batch classifier loss: 0.367233; batch adversarial loss: 0.652935\n",
      "epoch 86; iter: 0; batch classifier loss: 0.321227; batch adversarial loss: 0.562085\n",
      "epoch 87; iter: 0; batch classifier loss: 0.337006; batch adversarial loss: 0.581955\n",
      "epoch 88; iter: 0; batch classifier loss: 0.392794; batch adversarial loss: 0.577260\n",
      "epoch 89; iter: 0; batch classifier loss: 0.386303; batch adversarial loss: 0.515865\n",
      "epoch 90; iter: 0; batch classifier loss: 0.382112; batch adversarial loss: 0.651030\n",
      "epoch 91; iter: 0; batch classifier loss: 0.329372; batch adversarial loss: 0.588878\n",
      "epoch 92; iter: 0; batch classifier loss: 0.426822; batch adversarial loss: 0.555360\n",
      "epoch 93; iter: 0; batch classifier loss: 0.371172; batch adversarial loss: 0.537877\n",
      "epoch 94; iter: 0; batch classifier loss: 0.326500; batch adversarial loss: 0.648801\n",
      "epoch 95; iter: 0; batch classifier loss: 0.396194; batch adversarial loss: 0.534384\n",
      "epoch 96; iter: 0; batch classifier loss: 0.341820; batch adversarial loss: 0.647682\n",
      "epoch 97; iter: 0; batch classifier loss: 0.356251; batch adversarial loss: 0.589922\n",
      "epoch 98; iter: 0; batch classifier loss: 0.318379; batch adversarial loss: 0.536427\n",
      "epoch 99; iter: 0; batch classifier loss: 0.373407; batch adversarial loss: 0.554149\n",
      "epoch 100; iter: 0; batch classifier loss: 0.326471; batch adversarial loss: 0.579790\n",
      "epoch 101; iter: 0; batch classifier loss: 0.394842; batch adversarial loss: 0.569431\n",
      "epoch 102; iter: 0; batch classifier loss: 0.372473; batch adversarial loss: 0.500490\n",
      "epoch 103; iter: 0; batch classifier loss: 0.356522; batch adversarial loss: 0.587847\n",
      "epoch 104; iter: 0; batch classifier loss: 0.387974; batch adversarial loss: 0.580140\n",
      "epoch 105; iter: 0; batch classifier loss: 0.330918; batch adversarial loss: 0.605777\n",
      "epoch 106; iter: 0; batch classifier loss: 0.314747; batch adversarial loss: 0.538682\n",
      "epoch 107; iter: 0; batch classifier loss: 0.363355; batch adversarial loss: 0.504921\n",
      "epoch 108; iter: 0; batch classifier loss: 0.352430; batch adversarial loss: 0.676737\n",
      "epoch 109; iter: 0; batch classifier loss: 0.336228; batch adversarial loss: 0.579291\n",
      "epoch 110; iter: 0; batch classifier loss: 0.267445; batch adversarial loss: 0.570720\n",
      "epoch 111; iter: 0; batch classifier loss: 0.274132; batch adversarial loss: 0.553364\n",
      "epoch 112; iter: 0; batch classifier loss: 0.382301; batch adversarial loss: 0.589208\n",
      "epoch 113; iter: 0; batch classifier loss: 0.374068; batch adversarial loss: 0.614162\n",
      "epoch 114; iter: 0; batch classifier loss: 0.332419; batch adversarial loss: 0.624773\n",
      "epoch 115; iter: 0; batch classifier loss: 0.444892; batch adversarial loss: 0.536662\n",
      "epoch 116; iter: 0; batch classifier loss: 0.423885; batch adversarial loss: 0.521907\n",
      "epoch 117; iter: 0; batch classifier loss: 0.402166; batch adversarial loss: 0.608330\n",
      "epoch 118; iter: 0; batch classifier loss: 0.324230; batch adversarial loss: 0.554910\n",
      "epoch 119; iter: 0; batch classifier loss: 0.381885; batch adversarial loss: 0.510702\n",
      "epoch 120; iter: 0; batch classifier loss: 0.434974; batch adversarial loss: 0.511029\n",
      "epoch 121; iter: 0; batch classifier loss: 0.307460; batch adversarial loss: 0.592485\n",
      "epoch 122; iter: 0; batch classifier loss: 0.445623; batch adversarial loss: 0.597580\n",
      "epoch 123; iter: 0; batch classifier loss: 0.368586; batch adversarial loss: 0.544731\n",
      "epoch 124; iter: 0; batch classifier loss: 0.325423; batch adversarial loss: 0.519343\n",
      "epoch 125; iter: 0; batch classifier loss: 0.387935; batch adversarial loss: 0.550991\n",
      "epoch 126; iter: 0; batch classifier loss: 0.382318; batch adversarial loss: 0.554644\n",
      "epoch 127; iter: 0; batch classifier loss: 0.324036; batch adversarial loss: 0.576829\n",
      "epoch 128; iter: 0; batch classifier loss: 0.297548; batch adversarial loss: 0.536561\n",
      "epoch 129; iter: 0; batch classifier loss: 0.314295; batch adversarial loss: 0.509486\n",
      "epoch 130; iter: 0; batch classifier loss: 0.377904; batch adversarial loss: 0.501625\n",
      "epoch 131; iter: 0; batch classifier loss: 0.339681; batch adversarial loss: 0.544596\n",
      "epoch 132; iter: 0; batch classifier loss: 0.303756; batch adversarial loss: 0.459197\n",
      "epoch 133; iter: 0; batch classifier loss: 0.345469; batch adversarial loss: 0.562816\n",
      "epoch 134; iter: 0; batch classifier loss: 0.404087; batch adversarial loss: 0.554981\n",
      "epoch 135; iter: 0; batch classifier loss: 0.405203; batch adversarial loss: 0.588711\n",
      "epoch 136; iter: 0; batch classifier loss: 0.394172; batch adversarial loss: 0.561526\n",
      "epoch 137; iter: 0; batch classifier loss: 0.358503; batch adversarial loss: 0.552824\n",
      "epoch 138; iter: 0; batch classifier loss: 0.384093; batch adversarial loss: 0.544232\n",
      "epoch 139; iter: 0; batch classifier loss: 0.467295; batch adversarial loss: 0.579509\n",
      "epoch 140; iter: 0; batch classifier loss: 0.366843; batch adversarial loss: 0.492092\n",
      "epoch 141; iter: 0; batch classifier loss: 0.305018; batch adversarial loss: 0.577880\n",
      "epoch 142; iter: 0; batch classifier loss: 0.396450; batch adversarial loss: 0.519808\n",
      "epoch 143; iter: 0; batch classifier loss: 0.289735; batch adversarial loss: 0.516302\n",
      "epoch 144; iter: 0; batch classifier loss: 0.376543; batch adversarial loss: 0.519976\n",
      "epoch 145; iter: 0; batch classifier loss: 0.366859; batch adversarial loss: 0.503397\n",
      "epoch 146; iter: 0; batch classifier loss: 0.371472; batch adversarial loss: 0.551402\n",
      "epoch 147; iter: 0; batch classifier loss: 0.343256; batch adversarial loss: 0.580664\n",
      "epoch 148; iter: 0; batch classifier loss: 0.379826; batch adversarial loss: 0.544471\n",
      "epoch 149; iter: 0; batch classifier loss: 0.334518; batch adversarial loss: 0.552739\n",
      "epoch 150; iter: 0; batch classifier loss: 0.281510; batch adversarial loss: 0.577854\n",
      "epoch 151; iter: 0; batch classifier loss: 0.426920; batch adversarial loss: 0.534036\n",
      "epoch 152; iter: 0; batch classifier loss: 0.323221; batch adversarial loss: 0.485519\n",
      "epoch 153; iter: 0; batch classifier loss: 0.293934; batch adversarial loss: 0.484836\n",
      "epoch 154; iter: 0; batch classifier loss: 0.331964; batch adversarial loss: 0.563838\n",
      "epoch 155; iter: 0; batch classifier loss: 0.370894; batch adversarial loss: 0.609362\n",
      "epoch 156; iter: 0; batch classifier loss: 0.391746; batch adversarial loss: 0.587547\n",
      "epoch 157; iter: 0; batch classifier loss: 0.352584; batch adversarial loss: 0.509276\n",
      "epoch 158; iter: 0; batch classifier loss: 0.382556; batch adversarial loss: 0.467686\n",
      "epoch 159; iter: 0; batch classifier loss: 0.311595; batch adversarial loss: 0.579448\n",
      "epoch 160; iter: 0; batch classifier loss: 0.372824; batch adversarial loss: 0.570186\n",
      "epoch 161; iter: 0; batch classifier loss: 0.288063; batch adversarial loss: 0.625213\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 162; iter: 0; batch classifier loss: 0.295618; batch adversarial loss: 0.552787\n",
      "epoch 163; iter: 0; batch classifier loss: 0.362449; batch adversarial loss: 0.552949\n",
      "epoch 164; iter: 0; batch classifier loss: 0.346502; batch adversarial loss: 0.534093\n",
      "epoch 165; iter: 0; batch classifier loss: 0.284448; batch adversarial loss: 0.593613\n",
      "epoch 166; iter: 0; batch classifier loss: 0.308986; batch adversarial loss: 0.526743\n",
      "epoch 167; iter: 0; batch classifier loss: 0.444810; batch adversarial loss: 0.509252\n",
      "epoch 168; iter: 0; batch classifier loss: 0.425752; batch adversarial loss: 0.538737\n",
      "epoch 169; iter: 0; batch classifier loss: 0.298133; batch adversarial loss: 0.578607\n",
      "epoch 170; iter: 0; batch classifier loss: 0.315859; batch adversarial loss: 0.477214\n",
      "epoch 171; iter: 0; batch classifier loss: 0.373260; batch adversarial loss: 0.544259\n",
      "epoch 172; iter: 0; batch classifier loss: 0.412871; batch adversarial loss: 0.546370\n",
      "epoch 173; iter: 0; batch classifier loss: 0.336907; batch adversarial loss: 0.553590\n",
      "epoch 174; iter: 0; batch classifier loss: 0.343758; batch adversarial loss: 0.561497\n",
      "epoch 175; iter: 0; batch classifier loss: 0.363564; batch adversarial loss: 0.581501\n",
      "epoch 176; iter: 0; batch classifier loss: 0.416918; batch adversarial loss: 0.598250\n",
      "epoch 177; iter: 0; batch classifier loss: 0.273332; batch adversarial loss: 0.629083\n",
      "epoch 178; iter: 0; batch classifier loss: 0.372213; batch adversarial loss: 0.620297\n",
      "epoch 179; iter: 0; batch classifier loss: 0.404412; batch adversarial loss: 0.492443\n",
      "epoch 180; iter: 0; batch classifier loss: 0.339238; batch adversarial loss: 0.613047\n",
      "epoch 181; iter: 0; batch classifier loss: 0.323791; batch adversarial loss: 0.552536\n",
      "epoch 182; iter: 0; batch classifier loss: 0.244380; batch adversarial loss: 0.553619\n",
      "epoch 183; iter: 0; batch classifier loss: 0.380310; batch adversarial loss: 0.547237\n",
      "epoch 184; iter: 0; batch classifier loss: 0.359316; batch adversarial loss: 0.587331\n",
      "epoch 185; iter: 0; batch classifier loss: 0.389698; batch adversarial loss: 0.578041\n",
      "epoch 186; iter: 0; batch classifier loss: 0.340302; batch adversarial loss: 0.520651\n",
      "epoch 187; iter: 0; batch classifier loss: 0.320724; batch adversarial loss: 0.595887\n",
      "epoch 188; iter: 0; batch classifier loss: 0.278232; batch adversarial loss: 0.532026\n",
      "epoch 189; iter: 0; batch classifier loss: 0.354987; batch adversarial loss: 0.580807\n",
      "epoch 190; iter: 0; batch classifier loss: 0.342146; batch adversarial loss: 0.542854\n",
      "epoch 191; iter: 0; batch classifier loss: 0.337032; batch adversarial loss: 0.510192\n",
      "epoch 192; iter: 0; batch classifier loss: 0.446139; batch adversarial loss: 0.562761\n",
      "epoch 193; iter: 0; batch classifier loss: 0.393209; batch adversarial loss: 0.570896\n",
      "epoch 194; iter: 0; batch classifier loss: 0.381077; batch adversarial loss: 0.639094\n",
      "epoch 195; iter: 0; batch classifier loss: 0.310867; batch adversarial loss: 0.519477\n",
      "epoch 196; iter: 0; batch classifier loss: 0.273025; batch adversarial loss: 0.510125\n",
      "epoch 197; iter: 0; batch classifier loss: 0.298420; batch adversarial loss: 0.517388\n",
      "epoch 198; iter: 0; batch classifier loss: 0.321645; batch adversarial loss: 0.544453\n",
      "epoch 199; iter: 0; batch classifier loss: 0.290130; batch adversarial loss: 0.561701\n",
      "epoch 0; iter: 0; batch classifier loss: 0.678290; batch adversarial loss: 0.965135\n",
      "epoch 1; iter: 0; batch classifier loss: 0.848170; batch adversarial loss: 1.224332\n",
      "epoch 2; iter: 0; batch classifier loss: 1.107405; batch adversarial loss: 1.233425\n",
      "epoch 3; iter: 0; batch classifier loss: 1.107754; batch adversarial loss: 1.147749\n",
      "epoch 4; iter: 0; batch classifier loss: 1.237440; batch adversarial loss: 1.038013\n",
      "epoch 5; iter: 0; batch classifier loss: 1.201298; batch adversarial loss: 0.962183\n",
      "epoch 6; iter: 0; batch classifier loss: 1.127901; batch adversarial loss: 0.869756\n",
      "epoch 7; iter: 0; batch classifier loss: 1.069085; batch adversarial loss: 0.835825\n",
      "epoch 8; iter: 0; batch classifier loss: 0.805192; batch adversarial loss: 0.738836\n",
      "epoch 9; iter: 0; batch classifier loss: 0.891015; batch adversarial loss: 0.695944\n",
      "epoch 10; iter: 0; batch classifier loss: 0.742420; batch adversarial loss: 0.651118\n",
      "epoch 11; iter: 0; batch classifier loss: 0.603022; batch adversarial loss: 0.616404\n",
      "epoch 12; iter: 0; batch classifier loss: 0.579360; batch adversarial loss: 0.605902\n",
      "epoch 13; iter: 0; batch classifier loss: 0.557374; batch adversarial loss: 0.592152\n",
      "epoch 14; iter: 0; batch classifier loss: 0.565046; batch adversarial loss: 0.566126\n",
      "epoch 15; iter: 0; batch classifier loss: 0.570411; batch adversarial loss: 0.577742\n",
      "epoch 16; iter: 0; batch classifier loss: 0.571879; batch adversarial loss: 0.584754\n",
      "epoch 17; iter: 0; batch classifier loss: 0.505911; batch adversarial loss: 0.557363\n",
      "epoch 18; iter: 0; batch classifier loss: 0.483377; batch adversarial loss: 0.572447\n",
      "epoch 19; iter: 0; batch classifier loss: 0.510145; batch adversarial loss: 0.587820\n",
      "epoch 20; iter: 0; batch classifier loss: 0.511582; batch adversarial loss: 0.528046\n",
      "epoch 21; iter: 0; batch classifier loss: 0.577863; batch adversarial loss: 0.556068\n",
      "epoch 22; iter: 0; batch classifier loss: 0.549508; batch adversarial loss: 0.528970\n",
      "epoch 23; iter: 0; batch classifier loss: 0.463106; batch adversarial loss: 0.546143\n",
      "epoch 24; iter: 0; batch classifier loss: 0.458738; batch adversarial loss: 0.512293\n",
      "epoch 25; iter: 0; batch classifier loss: 0.498888; batch adversarial loss: 0.630961\n",
      "epoch 26; iter: 0; batch classifier loss: 0.445236; batch adversarial loss: 0.529052\n",
      "epoch 27; iter: 0; batch classifier loss: 0.427486; batch adversarial loss: 0.611293\n",
      "epoch 28; iter: 0; batch classifier loss: 0.492633; batch adversarial loss: 0.513583\n",
      "epoch 29; iter: 0; batch classifier loss: 0.479158; batch adversarial loss: 0.517328\n",
      "epoch 30; iter: 0; batch classifier loss: 0.443979; batch adversarial loss: 0.495142\n",
      "epoch 31; iter: 0; batch classifier loss: 0.545377; batch adversarial loss: 0.499968\n",
      "epoch 32; iter: 0; batch classifier loss: 0.455681; batch adversarial loss: 0.514623\n",
      "epoch 33; iter: 0; batch classifier loss: 0.471350; batch adversarial loss: 0.483576\n",
      "epoch 34; iter: 0; batch classifier loss: 0.450080; batch adversarial loss: 0.519432\n",
      "epoch 35; iter: 0; batch classifier loss: 0.500082; batch adversarial loss: 0.565344\n",
      "epoch 36; iter: 0; batch classifier loss: 0.453411; batch adversarial loss: 0.580569\n",
      "epoch 37; iter: 0; batch classifier loss: 0.485870; batch adversarial loss: 0.600200\n",
      "epoch 38; iter: 0; batch classifier loss: 0.433893; batch adversarial loss: 0.556039\n",
      "epoch 39; iter: 0; batch classifier loss: 0.551613; batch adversarial loss: 0.518741\n",
      "epoch 40; iter: 0; batch classifier loss: 0.400757; batch adversarial loss: 0.601207\n",
      "epoch 41; iter: 0; batch classifier loss: 0.366554; batch adversarial loss: 0.526177\n",
      "epoch 42; iter: 0; batch classifier loss: 0.396402; batch adversarial loss: 0.582747\n",
      "epoch 43; iter: 0; batch classifier loss: 0.488001; batch adversarial loss: 0.481353\n",
      "epoch 44; iter: 0; batch classifier loss: 0.418116; batch adversarial loss: 0.515766\n",
      "epoch 45; iter: 0; batch classifier loss: 0.386669; batch adversarial loss: 0.531965\n",
      "epoch 46; iter: 0; batch classifier loss: 0.453093; batch adversarial loss: 0.597914\n",
      "epoch 47; iter: 0; batch classifier loss: 0.462572; batch adversarial loss: 0.497236\n",
      "epoch 48; iter: 0; batch classifier loss: 0.422091; batch adversarial loss: 0.534740\n",
      "epoch 49; iter: 0; batch classifier loss: 0.458059; batch adversarial loss: 0.532321\n",
      "epoch 50; iter: 0; batch classifier loss: 0.464676; batch adversarial loss: 0.594167\n",
      "epoch 51; iter: 0; batch classifier loss: 0.406331; batch adversarial loss: 0.545038\n",
      "epoch 52; iter: 0; batch classifier loss: 0.483307; batch adversarial loss: 0.543796\n",
      "epoch 53; iter: 0; batch classifier loss: 0.458618; batch adversarial loss: 0.489822\n",
      "epoch 54; iter: 0; batch classifier loss: 0.406932; batch adversarial loss: 0.575109\n",
      "epoch 55; iter: 0; batch classifier loss: 0.435953; batch adversarial loss: 0.581675\n",
      "epoch 56; iter: 0; batch classifier loss: 0.428157; batch adversarial loss: 0.520492\n",
      "epoch 57; iter: 0; batch classifier loss: 0.461806; batch adversarial loss: 0.529157\n",
      "epoch 58; iter: 0; batch classifier loss: 0.377755; batch adversarial loss: 0.529315\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 59; iter: 0; batch classifier loss: 0.338249; batch adversarial loss: 0.518241\n",
      "epoch 60; iter: 0; batch classifier loss: 0.362510; batch adversarial loss: 0.482225\n",
      "epoch 61; iter: 0; batch classifier loss: 0.423624; batch adversarial loss: 0.545701\n",
      "epoch 62; iter: 0; batch classifier loss: 0.377449; batch adversarial loss: 0.580256\n",
      "epoch 63; iter: 0; batch classifier loss: 0.427030; batch adversarial loss: 0.515981\n",
      "epoch 64; iter: 0; batch classifier loss: 0.363703; batch adversarial loss: 0.543719\n",
      "epoch 65; iter: 0; batch classifier loss: 0.449938; batch adversarial loss: 0.471644\n",
      "epoch 66; iter: 0; batch classifier loss: 0.422503; batch adversarial loss: 0.535396\n",
      "epoch 67; iter: 0; batch classifier loss: 0.451568; batch adversarial loss: 0.562394\n",
      "epoch 68; iter: 0; batch classifier loss: 0.377913; batch adversarial loss: 0.605246\n",
      "epoch 69; iter: 0; batch classifier loss: 0.514238; batch adversarial loss: 0.581493\n",
      "epoch 70; iter: 0; batch classifier loss: 0.475552; batch adversarial loss: 0.515167\n",
      "epoch 71; iter: 0; batch classifier loss: 0.401766; batch adversarial loss: 0.606972\n",
      "epoch 72; iter: 0; batch classifier loss: 0.399324; batch adversarial loss: 0.507178\n",
      "epoch 73; iter: 0; batch classifier loss: 0.386491; batch adversarial loss: 0.540415\n",
      "epoch 74; iter: 0; batch classifier loss: 0.369330; batch adversarial loss: 0.561481\n",
      "epoch 75; iter: 0; batch classifier loss: 0.399188; batch adversarial loss: 0.558384\n",
      "epoch 76; iter: 0; batch classifier loss: 0.349196; batch adversarial loss: 0.523480\n",
      "epoch 77; iter: 0; batch classifier loss: 0.422484; batch adversarial loss: 0.525935\n",
      "epoch 78; iter: 0; batch classifier loss: 0.398840; batch adversarial loss: 0.519248\n",
      "epoch 79; iter: 0; batch classifier loss: 0.363504; batch adversarial loss: 0.525199\n",
      "epoch 80; iter: 0; batch classifier loss: 0.338748; batch adversarial loss: 0.622917\n",
      "epoch 81; iter: 0; batch classifier loss: 0.383170; batch adversarial loss: 0.485552\n",
      "epoch 82; iter: 0; batch classifier loss: 0.395498; batch adversarial loss: 0.550966\n",
      "epoch 83; iter: 0; batch classifier loss: 0.296307; batch adversarial loss: 0.476776\n",
      "epoch 84; iter: 0; batch classifier loss: 0.412550; batch adversarial loss: 0.526008\n",
      "epoch 85; iter: 0; batch classifier loss: 0.366570; batch adversarial loss: 0.580215\n",
      "epoch 86; iter: 0; batch classifier loss: 0.427296; batch adversarial loss: 0.591633\n",
      "epoch 87; iter: 0; batch classifier loss: 0.352044; batch adversarial loss: 0.551694\n",
      "epoch 88; iter: 0; batch classifier loss: 0.405888; batch adversarial loss: 0.577437\n",
      "epoch 89; iter: 0; batch classifier loss: 0.407192; batch adversarial loss: 0.494245\n",
      "epoch 90; iter: 0; batch classifier loss: 0.325355; batch adversarial loss: 0.539108\n",
      "epoch 91; iter: 0; batch classifier loss: 0.354102; batch adversarial loss: 0.490957\n",
      "epoch 92; iter: 0; batch classifier loss: 0.436577; batch adversarial loss: 0.598420\n",
      "epoch 93; iter: 0; batch classifier loss: 0.479809; batch adversarial loss: 0.463068\n",
      "epoch 94; iter: 0; batch classifier loss: 0.338033; batch adversarial loss: 0.566714\n",
      "epoch 95; iter: 0; batch classifier loss: 0.403516; batch adversarial loss: 0.543996\n",
      "epoch 96; iter: 0; batch classifier loss: 0.412511; batch adversarial loss: 0.636402\n",
      "epoch 97; iter: 0; batch classifier loss: 0.415289; batch adversarial loss: 0.557525\n",
      "epoch 98; iter: 0; batch classifier loss: 0.375666; batch adversarial loss: 0.481544\n",
      "epoch 99; iter: 0; batch classifier loss: 0.386188; batch adversarial loss: 0.497092\n",
      "epoch 100; iter: 0; batch classifier loss: 0.373768; batch adversarial loss: 0.555192\n",
      "epoch 101; iter: 0; batch classifier loss: 0.391264; batch adversarial loss: 0.578671\n",
      "epoch 102; iter: 0; batch classifier loss: 0.323342; batch adversarial loss: 0.557444\n",
      "epoch 103; iter: 0; batch classifier loss: 0.450228; batch adversarial loss: 0.499757\n",
      "epoch 104; iter: 0; batch classifier loss: 0.367270; batch adversarial loss: 0.535016\n",
      "epoch 105; iter: 0; batch classifier loss: 0.424755; batch adversarial loss: 0.545369\n",
      "epoch 106; iter: 0; batch classifier loss: 0.410388; batch adversarial loss: 0.609489\n",
      "epoch 107; iter: 0; batch classifier loss: 0.353452; batch adversarial loss: 0.582099\n",
      "epoch 108; iter: 0; batch classifier loss: 0.380415; batch adversarial loss: 0.562646\n",
      "epoch 109; iter: 0; batch classifier loss: 0.443022; batch adversarial loss: 0.543932\n",
      "epoch 110; iter: 0; batch classifier loss: 0.363436; batch adversarial loss: 0.616420\n",
      "epoch 111; iter: 0; batch classifier loss: 0.388432; batch adversarial loss: 0.562180\n",
      "epoch 112; iter: 0; batch classifier loss: 0.381223; batch adversarial loss: 0.560444\n",
      "epoch 113; iter: 0; batch classifier loss: 0.406144; batch adversarial loss: 0.506883\n",
      "epoch 114; iter: 0; batch classifier loss: 0.340600; batch adversarial loss: 0.555189\n",
      "epoch 115; iter: 0; batch classifier loss: 0.346269; batch adversarial loss: 0.534888\n",
      "epoch 116; iter: 0; batch classifier loss: 0.364983; batch adversarial loss: 0.563441\n",
      "epoch 117; iter: 0; batch classifier loss: 0.248646; batch adversarial loss: 0.566113\n",
      "epoch 118; iter: 0; batch classifier loss: 0.417166; batch adversarial loss: 0.525685\n",
      "epoch 119; iter: 0; batch classifier loss: 0.269660; batch adversarial loss: 0.617831\n",
      "epoch 120; iter: 0; batch classifier loss: 0.389564; batch adversarial loss: 0.583473\n",
      "epoch 121; iter: 0; batch classifier loss: 0.385596; batch adversarial loss: 0.454697\n",
      "epoch 122; iter: 0; batch classifier loss: 0.305660; batch adversarial loss: 0.540861\n",
      "epoch 123; iter: 0; batch classifier loss: 0.425792; batch adversarial loss: 0.542944\n",
      "epoch 124; iter: 0; batch classifier loss: 0.362605; batch adversarial loss: 0.509773\n",
      "epoch 125; iter: 0; batch classifier loss: 0.294806; batch adversarial loss: 0.506311\n",
      "epoch 126; iter: 0; batch classifier loss: 0.294350; batch adversarial loss: 0.524190\n",
      "epoch 127; iter: 0; batch classifier loss: 0.355581; batch adversarial loss: 0.551343\n",
      "epoch 128; iter: 0; batch classifier loss: 0.328552; batch adversarial loss: 0.526847\n",
      "epoch 129; iter: 0; batch classifier loss: 0.393880; batch adversarial loss: 0.591009\n",
      "epoch 130; iter: 0; batch classifier loss: 0.358611; batch adversarial loss: 0.626091\n",
      "epoch 131; iter: 0; batch classifier loss: 0.423473; batch adversarial loss: 0.499682\n",
      "epoch 132; iter: 0; batch classifier loss: 0.327871; batch adversarial loss: 0.509670\n",
      "epoch 133; iter: 0; batch classifier loss: 0.248038; batch adversarial loss: 0.590039\n",
      "epoch 134; iter: 0; batch classifier loss: 0.292505; batch adversarial loss: 0.479770\n",
      "epoch 135; iter: 0; batch classifier loss: 0.331494; batch adversarial loss: 0.574762\n",
      "epoch 136; iter: 0; batch classifier loss: 0.337644; batch adversarial loss: 0.525599\n",
      "epoch 137; iter: 0; batch classifier loss: 0.333084; batch adversarial loss: 0.572121\n",
      "epoch 138; iter: 0; batch classifier loss: 0.306089; batch adversarial loss: 0.561662\n",
      "epoch 139; iter: 0; batch classifier loss: 0.313938; batch adversarial loss: 0.523922\n",
      "epoch 140; iter: 0; batch classifier loss: 0.336232; batch adversarial loss: 0.482119\n",
      "epoch 141; iter: 0; batch classifier loss: 0.306318; batch adversarial loss: 0.452960\n",
      "epoch 142; iter: 0; batch classifier loss: 0.364220; batch adversarial loss: 0.571891\n",
      "epoch 143; iter: 0; batch classifier loss: 0.340416; batch adversarial loss: 0.517627\n",
      "epoch 144; iter: 0; batch classifier loss: 0.334862; batch adversarial loss: 0.527856\n",
      "epoch 145; iter: 0; batch classifier loss: 0.385180; batch adversarial loss: 0.537117\n",
      "epoch 146; iter: 0; batch classifier loss: 0.376556; batch adversarial loss: 0.525077\n",
      "epoch 147; iter: 0; batch classifier loss: 0.301336; batch adversarial loss: 0.443921\n",
      "epoch 148; iter: 0; batch classifier loss: 0.324357; batch adversarial loss: 0.553621\n",
      "epoch 149; iter: 0; batch classifier loss: 0.421488; batch adversarial loss: 0.518176\n",
      "epoch 150; iter: 0; batch classifier loss: 0.361999; batch adversarial loss: 0.610837\n",
      "epoch 151; iter: 0; batch classifier loss: 0.293785; batch adversarial loss: 0.635095\n",
      "epoch 152; iter: 0; batch classifier loss: 0.355217; batch adversarial loss: 0.536617\n",
      "epoch 153; iter: 0; batch classifier loss: 0.334037; batch adversarial loss: 0.545963\n",
      "epoch 154; iter: 0; batch classifier loss: 0.312865; batch adversarial loss: 0.525585\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 155; iter: 0; batch classifier loss: 0.292001; batch adversarial loss: 0.492393\n",
      "epoch 156; iter: 0; batch classifier loss: 0.328750; batch adversarial loss: 0.578653\n",
      "epoch 157; iter: 0; batch classifier loss: 0.305198; batch adversarial loss: 0.591665\n",
      "epoch 158; iter: 0; batch classifier loss: 0.324429; batch adversarial loss: 0.537799\n",
      "epoch 159; iter: 0; batch classifier loss: 0.318892; batch adversarial loss: 0.546108\n",
      "epoch 160; iter: 0; batch classifier loss: 0.307703; batch adversarial loss: 0.472308\n",
      "epoch 161; iter: 0; batch classifier loss: 0.294203; batch adversarial loss: 0.515182\n",
      "epoch 162; iter: 0; batch classifier loss: 0.325211; batch adversarial loss: 0.472272\n",
      "epoch 163; iter: 0; batch classifier loss: 0.325260; batch adversarial loss: 0.526223\n",
      "epoch 164; iter: 0; batch classifier loss: 0.341206; batch adversarial loss: 0.601247\n",
      "epoch 165; iter: 0; batch classifier loss: 0.374030; batch adversarial loss: 0.610663\n",
      "epoch 166; iter: 0; batch classifier loss: 0.322449; batch adversarial loss: 0.525627\n",
      "epoch 167; iter: 0; batch classifier loss: 0.290124; batch adversarial loss: 0.510517\n",
      "epoch 168; iter: 0; batch classifier loss: 0.378367; batch adversarial loss: 0.682457\n",
      "epoch 169; iter: 0; batch classifier loss: 0.397932; batch adversarial loss: 0.526365\n",
      "epoch 170; iter: 0; batch classifier loss: 0.323359; batch adversarial loss: 0.496875\n",
      "epoch 171; iter: 0; batch classifier loss: 0.335999; batch adversarial loss: 0.469372\n",
      "epoch 172; iter: 0; batch classifier loss: 0.293129; batch adversarial loss: 0.535683\n",
      "epoch 173; iter: 0; batch classifier loss: 0.303484; batch adversarial loss: 0.555421\n",
      "epoch 174; iter: 0; batch classifier loss: 0.414794; batch adversarial loss: 0.543828\n",
      "epoch 175; iter: 0; batch classifier loss: 0.304109; batch adversarial loss: 0.498992\n",
      "epoch 176; iter: 0; batch classifier loss: 0.313855; batch adversarial loss: 0.480660\n",
      "epoch 177; iter: 0; batch classifier loss: 0.289890; batch adversarial loss: 0.598566\n",
      "epoch 178; iter: 0; batch classifier loss: 0.293980; batch adversarial loss: 0.480386\n",
      "epoch 179; iter: 0; batch classifier loss: 0.269071; batch adversarial loss: 0.564450\n",
      "epoch 180; iter: 0; batch classifier loss: 0.390123; batch adversarial loss: 0.519765\n",
      "epoch 181; iter: 0; batch classifier loss: 0.370936; batch adversarial loss: 0.559721\n",
      "epoch 182; iter: 0; batch classifier loss: 0.366901; batch adversarial loss: 0.544679\n",
      "epoch 183; iter: 0; batch classifier loss: 0.255581; batch adversarial loss: 0.644124\n",
      "epoch 184; iter: 0; batch classifier loss: 0.290295; batch adversarial loss: 0.580256\n",
      "epoch 185; iter: 0; batch classifier loss: 0.323781; batch adversarial loss: 0.561229\n",
      "epoch 186; iter: 0; batch classifier loss: 0.293943; batch adversarial loss: 0.496926\n",
      "epoch 187; iter: 0; batch classifier loss: 0.317789; batch adversarial loss: 0.538706\n",
      "epoch 188; iter: 0; batch classifier loss: 0.348537; batch adversarial loss: 0.551728\n",
      "epoch 189; iter: 0; batch classifier loss: 0.370329; batch adversarial loss: 0.507539\n",
      "epoch 190; iter: 0; batch classifier loss: 0.281526; batch adversarial loss: 0.534152\n",
      "epoch 191; iter: 0; batch classifier loss: 0.245008; batch adversarial loss: 0.553189\n",
      "epoch 192; iter: 0; batch classifier loss: 0.345869; batch adversarial loss: 0.542872\n",
      "epoch 193; iter: 0; batch classifier loss: 0.305783; batch adversarial loss: 0.581936\n",
      "epoch 194; iter: 0; batch classifier loss: 0.244269; batch adversarial loss: 0.498450\n",
      "epoch 195; iter: 0; batch classifier loss: 0.271371; batch adversarial loss: 0.545725\n",
      "epoch 196; iter: 0; batch classifier loss: 0.351532; batch adversarial loss: 0.618777\n",
      "epoch 197; iter: 0; batch classifier loss: 0.290990; batch adversarial loss: 0.500144\n",
      "epoch 198; iter: 0; batch classifier loss: 0.367425; batch adversarial loss: 0.536429\n",
      "epoch 199; iter: 0; batch classifier loss: 0.214143; batch adversarial loss: 0.545457\n",
      "epoch 0; iter: 0; batch classifier loss: 0.790994; batch adversarial loss: 0.690743\n",
      "epoch 1; iter: 0; batch classifier loss: 0.621558; batch adversarial loss: 0.678716\n",
      "epoch 2; iter: 0; batch classifier loss: 0.527631; batch adversarial loss: 0.638634\n",
      "epoch 3; iter: 0; batch classifier loss: 0.581465; batch adversarial loss: 0.599497\n",
      "epoch 4; iter: 0; batch classifier loss: 0.570468; batch adversarial loss: 0.599990\n",
      "epoch 5; iter: 0; batch classifier loss: 0.558833; batch adversarial loss: 0.582196\n",
      "epoch 6; iter: 0; batch classifier loss: 0.555713; batch adversarial loss: 0.572687\n",
      "epoch 7; iter: 0; batch classifier loss: 0.593120; batch adversarial loss: 0.586918\n",
      "epoch 8; iter: 0; batch classifier loss: 0.593662; batch adversarial loss: 0.562840\n",
      "epoch 9; iter: 0; batch classifier loss: 0.492548; batch adversarial loss: 0.591762\n",
      "epoch 10; iter: 0; batch classifier loss: 0.423043; batch adversarial loss: 0.539947\n",
      "epoch 11; iter: 0; batch classifier loss: 0.576031; batch adversarial loss: 0.574437\n",
      "epoch 12; iter: 0; batch classifier loss: 0.432274; batch adversarial loss: 0.576188\n",
      "epoch 13; iter: 0; batch classifier loss: 0.548725; batch adversarial loss: 0.535317\n",
      "epoch 14; iter: 0; batch classifier loss: 0.487785; batch adversarial loss: 0.540487\n",
      "epoch 15; iter: 0; batch classifier loss: 0.516415; batch adversarial loss: 0.580283\n",
      "epoch 16; iter: 0; batch classifier loss: 0.613773; batch adversarial loss: 0.622712\n",
      "epoch 17; iter: 0; batch classifier loss: 0.534476; batch adversarial loss: 0.551365\n",
      "epoch 18; iter: 0; batch classifier loss: 0.497984; batch adversarial loss: 0.596453\n",
      "epoch 19; iter: 0; batch classifier loss: 0.483346; batch adversarial loss: 0.509913\n",
      "epoch 20; iter: 0; batch classifier loss: 0.561643; batch adversarial loss: 0.623370\n",
      "epoch 21; iter: 0; batch classifier loss: 0.469587; batch adversarial loss: 0.585076\n",
      "epoch 22; iter: 0; batch classifier loss: 0.465536; batch adversarial loss: 0.586022\n",
      "epoch 23; iter: 0; batch classifier loss: 0.442294; batch adversarial loss: 0.568930\n",
      "epoch 24; iter: 0; batch classifier loss: 0.579475; batch adversarial loss: 0.538029\n",
      "epoch 25; iter: 0; batch classifier loss: 0.503864; batch adversarial loss: 0.649652\n",
      "epoch 26; iter: 0; batch classifier loss: 0.471141; batch adversarial loss: 0.596599\n",
      "epoch 27; iter: 0; batch classifier loss: 0.597350; batch adversarial loss: 0.595601\n",
      "epoch 28; iter: 0; batch classifier loss: 0.486404; batch adversarial loss: 0.554387\n",
      "epoch 29; iter: 0; batch classifier loss: 0.473402; batch adversarial loss: 0.537493\n",
      "epoch 30; iter: 0; batch classifier loss: 0.469850; batch adversarial loss: 0.546074\n",
      "epoch 31; iter: 0; batch classifier loss: 0.482296; batch adversarial loss: 0.570749\n",
      "epoch 32; iter: 0; batch classifier loss: 0.420206; batch adversarial loss: 0.579452\n",
      "epoch 33; iter: 0; batch classifier loss: 0.416814; batch adversarial loss: 0.580183\n",
      "epoch 34; iter: 0; batch classifier loss: 0.447768; batch adversarial loss: 0.544931\n",
      "epoch 35; iter: 0; batch classifier loss: 0.481708; batch adversarial loss: 0.535900\n",
      "epoch 36; iter: 0; batch classifier loss: 0.453823; batch adversarial loss: 0.589890\n",
      "epoch 37; iter: 0; batch classifier loss: 0.481106; batch adversarial loss: 0.571123\n",
      "epoch 38; iter: 0; batch classifier loss: 0.385203; batch adversarial loss: 0.471140\n",
      "epoch 39; iter: 0; batch classifier loss: 0.438900; batch adversarial loss: 0.571962\n",
      "epoch 40; iter: 0; batch classifier loss: 0.471284; batch adversarial loss: 0.507263\n",
      "epoch 41; iter: 0; batch classifier loss: 0.421485; batch adversarial loss: 0.489472\n",
      "epoch 42; iter: 0; batch classifier loss: 0.366696; batch adversarial loss: 0.461244\n",
      "epoch 43; iter: 0; batch classifier loss: 0.455717; batch adversarial loss: 0.507481\n",
      "epoch 44; iter: 0; batch classifier loss: 0.389691; batch adversarial loss: 0.479697\n",
      "epoch 45; iter: 0; batch classifier loss: 0.401730; batch adversarial loss: 0.516554\n",
      "epoch 46; iter: 0; batch classifier loss: 0.372083; batch adversarial loss: 0.563005\n",
      "epoch 47; iter: 0; batch classifier loss: 0.312567; batch adversarial loss: 0.525939\n",
      "epoch 48; iter: 0; batch classifier loss: 0.353140; batch adversarial loss: 0.507306\n",
      "epoch 49; iter: 0; batch classifier loss: 0.448304; batch adversarial loss: 0.535449\n",
      "epoch 50; iter: 0; batch classifier loss: 0.413206; batch adversarial loss: 0.497854\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 51; iter: 0; batch classifier loss: 0.458366; batch adversarial loss: 0.553648\n",
      "epoch 52; iter: 0; batch classifier loss: 0.395628; batch adversarial loss: 0.563070\n",
      "epoch 53; iter: 0; batch classifier loss: 0.507186; batch adversarial loss: 0.553655\n",
      "epoch 54; iter: 0; batch classifier loss: 0.439975; batch adversarial loss: 0.544461\n",
      "epoch 55; iter: 0; batch classifier loss: 0.383600; batch adversarial loss: 0.600408\n",
      "epoch 56; iter: 0; batch classifier loss: 0.442813; batch adversarial loss: 0.516527\n",
      "epoch 57; iter: 0; batch classifier loss: 0.330051; batch adversarial loss: 0.516530\n",
      "epoch 58; iter: 0; batch classifier loss: 0.434614; batch adversarial loss: 0.506772\n",
      "epoch 59; iter: 0; batch classifier loss: 0.474593; batch adversarial loss: 0.553794\n",
      "epoch 60; iter: 0; batch classifier loss: 0.363224; batch adversarial loss: 0.591739\n",
      "epoch 61; iter: 0; batch classifier loss: 0.543865; batch adversarial loss: 0.542402\n",
      "epoch 62; iter: 0; batch classifier loss: 0.346719; batch adversarial loss: 0.573250\n",
      "epoch 63; iter: 0; batch classifier loss: 0.431281; batch adversarial loss: 0.485688\n",
      "epoch 64; iter: 0; batch classifier loss: 0.370243; batch adversarial loss: 0.488123\n",
      "epoch 65; iter: 0; batch classifier loss: 0.362460; batch adversarial loss: 0.563241\n",
      "epoch 66; iter: 0; batch classifier loss: 0.326870; batch adversarial loss: 0.526336\n",
      "epoch 67; iter: 0; batch classifier loss: 0.379996; batch adversarial loss: 0.526146\n",
      "epoch 68; iter: 0; batch classifier loss: 0.449732; batch adversarial loss: 0.553614\n",
      "epoch 69; iter: 0; batch classifier loss: 0.355365; batch adversarial loss: 0.507777\n",
      "epoch 70; iter: 0; batch classifier loss: 0.410356; batch adversarial loss: 0.563535\n",
      "epoch 71; iter: 0; batch classifier loss: 0.525292; batch adversarial loss: 0.572351\n",
      "epoch 72; iter: 0; batch classifier loss: 0.411500; batch adversarial loss: 0.497827\n",
      "epoch 73; iter: 0; batch classifier loss: 0.362919; batch adversarial loss: 0.480158\n",
      "epoch 74; iter: 0; batch classifier loss: 0.467852; batch adversarial loss: 0.589914\n",
      "epoch 75; iter: 0; batch classifier loss: 0.385513; batch adversarial loss: 0.525398\n",
      "epoch 76; iter: 0; batch classifier loss: 0.371536; batch adversarial loss: 0.589845\n",
      "epoch 77; iter: 0; batch classifier loss: 0.335570; batch adversarial loss: 0.479077\n",
      "epoch 78; iter: 0; batch classifier loss: 0.332380; batch adversarial loss: 0.544540\n",
      "epoch 79; iter: 0; batch classifier loss: 0.383271; batch adversarial loss: 0.554309\n",
      "epoch 80; iter: 0; batch classifier loss: 0.383046; batch adversarial loss: 0.582470\n",
      "epoch 81; iter: 0; batch classifier loss: 0.392417; batch adversarial loss: 0.572456\n",
      "epoch 82; iter: 0; batch classifier loss: 0.342557; batch adversarial loss: 0.544558\n",
      "epoch 83; iter: 0; batch classifier loss: 0.450688; batch adversarial loss: 0.581509\n",
      "epoch 84; iter: 0; batch classifier loss: 0.420643; batch adversarial loss: 0.460506\n",
      "epoch 85; iter: 0; batch classifier loss: 0.487089; batch adversarial loss: 0.582463\n",
      "epoch 86; iter: 0; batch classifier loss: 0.318906; batch adversarial loss: 0.525877\n",
      "epoch 87; iter: 0; batch classifier loss: 0.430078; batch adversarial loss: 0.609644\n",
      "epoch 88; iter: 0; batch classifier loss: 0.363325; batch adversarial loss: 0.564118\n",
      "epoch 89; iter: 0; batch classifier loss: 0.421572; batch adversarial loss: 0.479301\n",
      "epoch 90; iter: 0; batch classifier loss: 0.342848; batch adversarial loss: 0.525855\n",
      "epoch 91; iter: 0; batch classifier loss: 0.387031; batch adversarial loss: 0.536210\n",
      "epoch 92; iter: 0; batch classifier loss: 0.344419; batch adversarial loss: 0.516942\n",
      "epoch 93; iter: 0; batch classifier loss: 0.358780; batch adversarial loss: 0.562777\n",
      "epoch 94; iter: 0; batch classifier loss: 0.429909; batch adversarial loss: 0.572530\n",
      "epoch 95; iter: 0; batch classifier loss: 0.333653; batch adversarial loss: 0.600668\n",
      "epoch 96; iter: 0; batch classifier loss: 0.399898; batch adversarial loss: 0.516641\n",
      "epoch 97; iter: 0; batch classifier loss: 0.420436; batch adversarial loss: 0.573243\n",
      "epoch 98; iter: 0; batch classifier loss: 0.416700; batch adversarial loss: 0.431613\n",
      "epoch 99; iter: 0; batch classifier loss: 0.342076; batch adversarial loss: 0.516982\n",
      "epoch 100; iter: 0; batch classifier loss: 0.392998; batch adversarial loss: 0.506804\n",
      "epoch 101; iter: 0; batch classifier loss: 0.344390; batch adversarial loss: 0.562968\n",
      "epoch 102; iter: 0; batch classifier loss: 0.330744; batch adversarial loss: 0.507071\n",
      "epoch 103; iter: 0; batch classifier loss: 0.402008; batch adversarial loss: 0.526095\n",
      "epoch 104; iter: 0; batch classifier loss: 0.366887; batch adversarial loss: 0.516884\n",
      "epoch 105; iter: 0; batch classifier loss: 0.374368; batch adversarial loss: 0.478780\n",
      "epoch 106; iter: 0; batch classifier loss: 0.328788; batch adversarial loss: 0.535027\n",
      "epoch 107; iter: 0; batch classifier loss: 0.343713; batch adversarial loss: 0.579525\n",
      "epoch 108; iter: 0; batch classifier loss: 0.350238; batch adversarial loss: 0.598226\n",
      "epoch 109; iter: 0; batch classifier loss: 0.367957; batch adversarial loss: 0.598671\n",
      "epoch 110; iter: 0; batch classifier loss: 0.337853; batch adversarial loss: 0.644436\n",
      "epoch 111; iter: 0; batch classifier loss: 0.426020; batch adversarial loss: 0.507939\n",
      "epoch 112; iter: 0; batch classifier loss: 0.474867; batch adversarial loss: 0.449516\n",
      "epoch 113; iter: 0; batch classifier loss: 0.440389; batch adversarial loss: 0.524827\n",
      "epoch 114; iter: 0; batch classifier loss: 0.354880; batch adversarial loss: 0.524531\n",
      "epoch 115; iter: 0; batch classifier loss: 0.321668; batch adversarial loss: 0.537301\n",
      "epoch 116; iter: 0; batch classifier loss: 0.379004; batch adversarial loss: 0.497688\n",
      "epoch 117; iter: 0; batch classifier loss: 0.414189; batch adversarial loss: 0.485466\n",
      "epoch 118; iter: 0; batch classifier loss: 0.333757; batch adversarial loss: 0.528203\n",
      "epoch 119; iter: 0; batch classifier loss: 0.413541; batch adversarial loss: 0.581977\n",
      "epoch 120; iter: 0; batch classifier loss: 0.310173; batch adversarial loss: 0.612179\n",
      "epoch 121; iter: 0; batch classifier loss: 0.344020; batch adversarial loss: 0.496574\n",
      "epoch 122; iter: 0; batch classifier loss: 0.391563; batch adversarial loss: 0.526981\n",
      "epoch 123; iter: 0; batch classifier loss: 0.366053; batch adversarial loss: 0.515213\n",
      "epoch 124; iter: 0; batch classifier loss: 0.301334; batch adversarial loss: 0.508092\n",
      "epoch 125; iter: 0; batch classifier loss: 0.339541; batch adversarial loss: 0.515441\n",
      "epoch 126; iter: 0; batch classifier loss: 0.307550; batch adversarial loss: 0.517555\n",
      "epoch 127; iter: 0; batch classifier loss: 0.339351; batch adversarial loss: 0.544473\n",
      "epoch 128; iter: 0; batch classifier loss: 0.419326; batch adversarial loss: 0.589211\n",
      "epoch 129; iter: 0; batch classifier loss: 0.293935; batch adversarial loss: 0.552329\n",
      "epoch 130; iter: 0; batch classifier loss: 0.390515; batch adversarial loss: 0.525863\n",
      "epoch 131; iter: 0; batch classifier loss: 0.315015; batch adversarial loss: 0.572388\n",
      "epoch 132; iter: 0; batch classifier loss: 0.319701; batch adversarial loss: 0.515623\n",
      "epoch 133; iter: 0; batch classifier loss: 0.458049; batch adversarial loss: 0.524986\n",
      "epoch 134; iter: 0; batch classifier loss: 0.324212; batch adversarial loss: 0.516174\n",
      "epoch 135; iter: 0; batch classifier loss: 0.271767; batch adversarial loss: 0.601968\n",
      "epoch 136; iter: 0; batch classifier loss: 0.371705; batch adversarial loss: 0.525636\n",
      "epoch 137; iter: 0; batch classifier loss: 0.342816; batch adversarial loss: 0.469034\n",
      "epoch 138; iter: 0; batch classifier loss: 0.395230; batch adversarial loss: 0.526098\n",
      "epoch 139; iter: 0; batch classifier loss: 0.390611; batch adversarial loss: 0.573232\n",
      "epoch 140; iter: 0; batch classifier loss: 0.298608; batch adversarial loss: 0.544457\n",
      "epoch 141; iter: 0; batch classifier loss: 0.487543; batch adversarial loss: 0.552805\n",
      "epoch 142; iter: 0; batch classifier loss: 0.360323; batch adversarial loss: 0.507486\n",
      "epoch 143; iter: 0; batch classifier loss: 0.377237; batch adversarial loss: 0.553305\n",
      "epoch 144; iter: 0; batch classifier loss: 0.386743; batch adversarial loss: 0.600650\n",
      "epoch 145; iter: 0; batch classifier loss: 0.318093; batch adversarial loss: 0.545018\n",
      "epoch 146; iter: 0; batch classifier loss: 0.464742; batch adversarial loss: 0.609508\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 147; iter: 0; batch classifier loss: 0.400874; batch adversarial loss: 0.581821\n",
      "epoch 148; iter: 0; batch classifier loss: 0.298819; batch adversarial loss: 0.582124\n",
      "epoch 149; iter: 0; batch classifier loss: 0.273259; batch adversarial loss: 0.534905\n",
      "epoch 150; iter: 0; batch classifier loss: 0.413399; batch adversarial loss: 0.496716\n",
      "epoch 151; iter: 0; batch classifier loss: 0.420556; batch adversarial loss: 0.535067\n",
      "epoch 152; iter: 0; batch classifier loss: 0.422325; batch adversarial loss: 0.553723\n",
      "epoch 153; iter: 0; batch classifier loss: 0.387258; batch adversarial loss: 0.488323\n",
      "epoch 154; iter: 0; batch classifier loss: 0.389530; batch adversarial loss: 0.545128\n",
      "epoch 155; iter: 0; batch classifier loss: 0.370386; batch adversarial loss: 0.545740\n",
      "epoch 156; iter: 0; batch classifier loss: 0.422553; batch adversarial loss: 0.507220\n",
      "epoch 157; iter: 0; batch classifier loss: 0.249376; batch adversarial loss: 0.581531\n",
      "epoch 158; iter: 0; batch classifier loss: 0.366462; batch adversarial loss: 0.543935\n",
      "epoch 159; iter: 0; batch classifier loss: 0.338454; batch adversarial loss: 0.517253\n",
      "epoch 160; iter: 0; batch classifier loss: 0.378543; batch adversarial loss: 0.628702\n",
      "epoch 161; iter: 0; batch classifier loss: 0.319575; batch adversarial loss: 0.506727\n",
      "epoch 162; iter: 0; batch classifier loss: 0.352560; batch adversarial loss: 0.572804\n",
      "epoch 163; iter: 0; batch classifier loss: 0.342475; batch adversarial loss: 0.581862\n",
      "epoch 164; iter: 0; batch classifier loss: 0.348973; batch adversarial loss: 0.507456\n",
      "epoch 165; iter: 0; batch classifier loss: 0.401238; batch adversarial loss: 0.553340\n",
      "epoch 166; iter: 0; batch classifier loss: 0.382290; batch adversarial loss: 0.517400\n",
      "epoch 167; iter: 0; batch classifier loss: 0.339788; batch adversarial loss: 0.544608\n",
      "epoch 168; iter: 0; batch classifier loss: 0.356606; batch adversarial loss: 0.570214\n",
      "epoch 169; iter: 0; batch classifier loss: 0.305499; batch adversarial loss: 0.582601\n",
      "epoch 170; iter: 0; batch classifier loss: 0.429468; batch adversarial loss: 0.506212\n",
      "epoch 171; iter: 0; batch classifier loss: 0.357375; batch adversarial loss: 0.545049\n",
      "epoch 172; iter: 0; batch classifier loss: 0.432163; batch adversarial loss: 0.488003\n",
      "epoch 173; iter: 0; batch classifier loss: 0.414669; batch adversarial loss: 0.497691\n",
      "epoch 174; iter: 0; batch classifier loss: 0.392067; batch adversarial loss: 0.497307\n",
      "epoch 175; iter: 0; batch classifier loss: 0.425336; batch adversarial loss: 0.497735\n",
      "epoch 176; iter: 0; batch classifier loss: 0.364644; batch adversarial loss: 0.591588\n",
      "epoch 177; iter: 0; batch classifier loss: 0.399260; batch adversarial loss: 0.582515\n",
      "epoch 178; iter: 0; batch classifier loss: 0.374188; batch adversarial loss: 0.469663\n",
      "epoch 179; iter: 0; batch classifier loss: 0.333292; batch adversarial loss: 0.656561\n",
      "epoch 180; iter: 0; batch classifier loss: 0.380887; batch adversarial loss: 0.581815\n",
      "epoch 181; iter: 0; batch classifier loss: 0.284050; batch adversarial loss: 0.507026\n",
      "epoch 182; iter: 0; batch classifier loss: 0.314023; batch adversarial loss: 0.525663\n",
      "epoch 183; iter: 0; batch classifier loss: 0.326550; batch adversarial loss: 0.544758\n",
      "epoch 184; iter: 0; batch classifier loss: 0.298949; batch adversarial loss: 0.564038\n",
      "epoch 185; iter: 0; batch classifier loss: 0.351064; batch adversarial loss: 0.572490\n",
      "epoch 186; iter: 0; batch classifier loss: 0.342777; batch adversarial loss: 0.667441\n",
      "epoch 187; iter: 0; batch classifier loss: 0.400300; batch adversarial loss: 0.553263\n",
      "epoch 188; iter: 0; batch classifier loss: 0.369444; batch adversarial loss: 0.515141\n",
      "epoch 189; iter: 0; batch classifier loss: 0.301667; batch adversarial loss: 0.469840\n",
      "epoch 190; iter: 0; batch classifier loss: 0.397735; batch adversarial loss: 0.497287\n",
      "epoch 191; iter: 0; batch classifier loss: 0.338115; batch adversarial loss: 0.591008\n",
      "epoch 192; iter: 0; batch classifier loss: 0.386308; batch adversarial loss: 0.518028\n",
      "epoch 193; iter: 0; batch classifier loss: 0.294273; batch adversarial loss: 0.499012\n",
      "epoch 194; iter: 0; batch classifier loss: 0.433816; batch adversarial loss: 0.590790\n",
      "epoch 195; iter: 0; batch classifier loss: 0.375895; batch adversarial loss: 0.487836\n",
      "epoch 196; iter: 0; batch classifier loss: 0.309015; batch adversarial loss: 0.591036\n",
      "epoch 197; iter: 0; batch classifier loss: 0.321906; batch adversarial loss: 0.553132\n",
      "epoch 198; iter: 0; batch classifier loss: 0.386375; batch adversarial loss: 0.599424\n",
      "epoch 199; iter: 0; batch classifier loss: 0.338724; batch adversarial loss: 0.525451\n",
      "epoch 0; iter: 0; batch classifier loss: 0.739669; batch adversarial loss: 0.601489\n",
      "epoch 1; iter: 0; batch classifier loss: 0.570570; batch adversarial loss: 0.623934\n",
      "epoch 2; iter: 0; batch classifier loss: 0.576359; batch adversarial loss: 0.608238\n",
      "epoch 3; iter: 0; batch classifier loss: 0.561136; batch adversarial loss: 0.568381\n",
      "epoch 4; iter: 0; batch classifier loss: 0.520709; batch adversarial loss: 0.647829\n",
      "epoch 5; iter: 0; batch classifier loss: 0.590431; batch adversarial loss: 0.614500\n",
      "epoch 6; iter: 0; batch classifier loss: 0.551364; batch adversarial loss: 0.614026\n",
      "epoch 7; iter: 0; batch classifier loss: 0.504640; batch adversarial loss: 0.613987\n",
      "epoch 8; iter: 0; batch classifier loss: 0.523965; batch adversarial loss: 0.572794\n",
      "epoch 9; iter: 0; batch classifier loss: 0.534657; batch adversarial loss: 0.606980\n",
      "epoch 10; iter: 0; batch classifier loss: 0.592188; batch adversarial loss: 0.627400\n",
      "epoch 11; iter: 0; batch classifier loss: 0.523634; batch adversarial loss: 0.512068\n",
      "epoch 12; iter: 0; batch classifier loss: 0.532927; batch adversarial loss: 0.615808\n",
      "epoch 13; iter: 0; batch classifier loss: 0.503019; batch adversarial loss: 0.541674\n",
      "epoch 14; iter: 0; batch classifier loss: 0.480113; batch adversarial loss: 0.618458\n",
      "epoch 15; iter: 0; batch classifier loss: 0.551947; batch adversarial loss: 0.633833\n",
      "epoch 16; iter: 0; batch classifier loss: 0.515925; batch adversarial loss: 0.598126\n",
      "epoch 17; iter: 0; batch classifier loss: 0.571742; batch adversarial loss: 0.603601\n",
      "epoch 18; iter: 0; batch classifier loss: 0.536691; batch adversarial loss: 0.605402\n",
      "epoch 19; iter: 0; batch classifier loss: 0.513568; batch adversarial loss: 0.529296\n",
      "epoch 20; iter: 0; batch classifier loss: 0.553031; batch adversarial loss: 0.525854\n",
      "epoch 21; iter: 0; batch classifier loss: 0.650303; batch adversarial loss: 0.567268\n",
      "epoch 22; iter: 0; batch classifier loss: 0.556049; batch adversarial loss: 0.572511\n",
      "epoch 23; iter: 0; batch classifier loss: 0.462446; batch adversarial loss: 0.563198\n",
      "epoch 24; iter: 0; batch classifier loss: 0.503526; batch adversarial loss: 0.554554\n",
      "epoch 25; iter: 0; batch classifier loss: 0.537863; batch adversarial loss: 0.567129\n",
      "epoch 26; iter: 0; batch classifier loss: 0.450300; batch adversarial loss: 0.511958\n",
      "epoch 27; iter: 0; batch classifier loss: 0.521021; batch adversarial loss: 0.546526\n",
      "epoch 28; iter: 0; batch classifier loss: 0.519861; batch adversarial loss: 0.579573\n",
      "epoch 29; iter: 0; batch classifier loss: 0.463855; batch adversarial loss: 0.485462\n",
      "epoch 30; iter: 0; batch classifier loss: 0.404706; batch adversarial loss: 0.553919\n",
      "epoch 31; iter: 0; batch classifier loss: 0.466622; batch adversarial loss: 0.552097\n",
      "epoch 32; iter: 0; batch classifier loss: 0.460923; batch adversarial loss: 0.571000\n",
      "epoch 33; iter: 0; batch classifier loss: 0.460830; batch adversarial loss: 0.590233\n",
      "epoch 34; iter: 0; batch classifier loss: 0.537765; batch adversarial loss: 0.605583\n",
      "epoch 35; iter: 0; batch classifier loss: 0.476119; batch adversarial loss: 0.480297\n",
      "epoch 36; iter: 0; batch classifier loss: 0.510637; batch adversarial loss: 0.544640\n",
      "epoch 37; iter: 0; batch classifier loss: 0.436772; batch adversarial loss: 0.526325\n",
      "epoch 38; iter: 0; batch classifier loss: 0.443962; batch adversarial loss: 0.516997\n",
      "epoch 39; iter: 0; batch classifier loss: 0.453133; batch adversarial loss: 0.598122\n",
      "epoch 40; iter: 0; batch classifier loss: 0.393119; batch adversarial loss: 0.542500\n",
      "epoch 41; iter: 0; batch classifier loss: 0.431136; batch adversarial loss: 0.548741\n",
      "epoch 42; iter: 0; batch classifier loss: 0.517249; batch adversarial loss: 0.515871\n",
      "epoch 43; iter: 0; batch classifier loss: 0.480313; batch adversarial loss: 0.539254\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 44; iter: 0; batch classifier loss: 0.456206; batch adversarial loss: 0.589685\n",
      "epoch 45; iter: 0; batch classifier loss: 0.447311; batch adversarial loss: 0.523303\n",
      "epoch 46; iter: 0; batch classifier loss: 0.455895; batch adversarial loss: 0.618379\n",
      "epoch 47; iter: 0; batch classifier loss: 0.399980; batch adversarial loss: 0.606230\n",
      "epoch 48; iter: 0; batch classifier loss: 0.452378; batch adversarial loss: 0.546960\n",
      "epoch 49; iter: 0; batch classifier loss: 0.446801; batch adversarial loss: 0.489351\n",
      "epoch 50; iter: 0; batch classifier loss: 0.393716; batch adversarial loss: 0.602121\n",
      "epoch 51; iter: 0; batch classifier loss: 0.463256; batch adversarial loss: 0.487856\n",
      "epoch 52; iter: 0; batch classifier loss: 0.552098; batch adversarial loss: 0.538246\n",
      "epoch 53; iter: 0; batch classifier loss: 0.442987; batch adversarial loss: 0.516778\n",
      "epoch 54; iter: 0; batch classifier loss: 0.365665; batch adversarial loss: 0.490445\n",
      "epoch 55; iter: 0; batch classifier loss: 0.368126; batch adversarial loss: 0.572225\n",
      "epoch 56; iter: 0; batch classifier loss: 0.432005; batch adversarial loss: 0.580570\n",
      "epoch 57; iter: 0; batch classifier loss: 0.479793; batch adversarial loss: 0.544823\n",
      "epoch 58; iter: 0; batch classifier loss: 0.389993; batch adversarial loss: 0.488992\n",
      "epoch 59; iter: 0; batch classifier loss: 0.444474; batch adversarial loss: 0.508310\n",
      "epoch 60; iter: 0; batch classifier loss: 0.442438; batch adversarial loss: 0.618442\n",
      "epoch 61; iter: 0; batch classifier loss: 0.433537; batch adversarial loss: 0.469122\n",
      "epoch 62; iter: 0; batch classifier loss: 0.460127; batch adversarial loss: 0.489025\n",
      "epoch 63; iter: 0; batch classifier loss: 0.386764; batch adversarial loss: 0.552699\n",
      "epoch 64; iter: 0; batch classifier loss: 0.507549; batch adversarial loss: 0.507665\n",
      "epoch 65; iter: 0; batch classifier loss: 0.389070; batch adversarial loss: 0.498912\n",
      "epoch 66; iter: 0; batch classifier loss: 0.318123; batch adversarial loss: 0.535099\n",
      "epoch 67; iter: 0; batch classifier loss: 0.400119; batch adversarial loss: 0.460561\n",
      "epoch 68; iter: 0; batch classifier loss: 0.472788; batch adversarial loss: 0.485894\n",
      "epoch 69; iter: 0; batch classifier loss: 0.406041; batch adversarial loss: 0.485286\n",
      "epoch 70; iter: 0; batch classifier loss: 0.463016; batch adversarial loss: 0.515609\n",
      "epoch 71; iter: 0; batch classifier loss: 0.429712; batch adversarial loss: 0.533492\n",
      "epoch 72; iter: 0; batch classifier loss: 0.378414; batch adversarial loss: 0.516008\n",
      "epoch 73; iter: 0; batch classifier loss: 0.361069; batch adversarial loss: 0.570941\n",
      "epoch 74; iter: 0; batch classifier loss: 0.390457; batch adversarial loss: 0.534594\n",
      "epoch 75; iter: 0; batch classifier loss: 0.420186; batch adversarial loss: 0.593220\n",
      "epoch 76; iter: 0; batch classifier loss: 0.425022; batch adversarial loss: 0.589698\n",
      "epoch 77; iter: 0; batch classifier loss: 0.376761; batch adversarial loss: 0.561031\n",
      "epoch 78; iter: 0; batch classifier loss: 0.398195; batch adversarial loss: 0.505834\n",
      "epoch 79; iter: 0; batch classifier loss: 0.356295; batch adversarial loss: 0.556215\n",
      "epoch 80; iter: 0; batch classifier loss: 0.451485; batch adversarial loss: 0.506258\n",
      "epoch 81; iter: 0; batch classifier loss: 0.427205; batch adversarial loss: 0.573035\n",
      "epoch 82; iter: 0; batch classifier loss: 0.365936; batch adversarial loss: 0.509203\n",
      "epoch 83; iter: 0; batch classifier loss: 0.416782; batch adversarial loss: 0.518048\n",
      "epoch 84; iter: 0; batch classifier loss: 0.459471; batch adversarial loss: 0.517846\n",
      "epoch 85; iter: 0; batch classifier loss: 0.399944; batch adversarial loss: 0.554378\n",
      "epoch 86; iter: 0; batch classifier loss: 0.459433; batch adversarial loss: 0.644827\n",
      "epoch 87; iter: 0; batch classifier loss: 0.450965; batch adversarial loss: 0.535175\n",
      "epoch 88; iter: 0; batch classifier loss: 0.400906; batch adversarial loss: 0.615400\n",
      "epoch 89; iter: 0; batch classifier loss: 0.412699; batch adversarial loss: 0.571716\n",
      "epoch 90; iter: 0; batch classifier loss: 0.391759; batch adversarial loss: 0.590720\n",
      "epoch 91; iter: 0; batch classifier loss: 0.465157; batch adversarial loss: 0.601139\n",
      "epoch 92; iter: 0; batch classifier loss: 0.383281; batch adversarial loss: 0.498868\n",
      "epoch 93; iter: 0; batch classifier loss: 0.389507; batch adversarial loss: 0.565111\n",
      "epoch 94; iter: 0; batch classifier loss: 0.408535; batch adversarial loss: 0.534683\n",
      "epoch 95; iter: 0; batch classifier loss: 0.437101; batch adversarial loss: 0.461157\n",
      "epoch 96; iter: 0; batch classifier loss: 0.336964; batch adversarial loss: 0.593456\n",
      "epoch 97; iter: 0; batch classifier loss: 0.426968; batch adversarial loss: 0.524784\n",
      "epoch 98; iter: 0; batch classifier loss: 0.347081; batch adversarial loss: 0.589436\n",
      "epoch 99; iter: 0; batch classifier loss: 0.405174; batch adversarial loss: 0.554488\n",
      "epoch 100; iter: 0; batch classifier loss: 0.355195; batch adversarial loss: 0.526167\n",
      "epoch 101; iter: 0; batch classifier loss: 0.385583; batch adversarial loss: 0.469805\n",
      "epoch 102; iter: 0; batch classifier loss: 0.361318; batch adversarial loss: 0.505018\n",
      "epoch 103; iter: 0; batch classifier loss: 0.458010; batch adversarial loss: 0.542724\n",
      "epoch 104; iter: 0; batch classifier loss: 0.355081; batch adversarial loss: 0.496059\n",
      "epoch 105; iter: 0; batch classifier loss: 0.371556; batch adversarial loss: 0.562474\n",
      "epoch 106; iter: 0; batch classifier loss: 0.362749; batch adversarial loss: 0.581978\n",
      "epoch 107; iter: 0; batch classifier loss: 0.452167; batch adversarial loss: 0.583848\n",
      "epoch 108; iter: 0; batch classifier loss: 0.366238; batch adversarial loss: 0.555915\n",
      "epoch 109; iter: 0; batch classifier loss: 0.480851; batch adversarial loss: 0.538089\n",
      "epoch 110; iter: 0; batch classifier loss: 0.484001; batch adversarial loss: 0.480518\n",
      "epoch 111; iter: 0; batch classifier loss: 0.411017; batch adversarial loss: 0.454630\n",
      "epoch 112; iter: 0; batch classifier loss: 0.367279; batch adversarial loss: 0.545776\n",
      "epoch 113; iter: 0; batch classifier loss: 0.385737; batch adversarial loss: 0.518101\n",
      "epoch 114; iter: 0; batch classifier loss: 0.384461; batch adversarial loss: 0.589597\n",
      "epoch 115; iter: 0; batch classifier loss: 0.409358; batch adversarial loss: 0.480176\n",
      "epoch 116; iter: 0; batch classifier loss: 0.381731; batch adversarial loss: 0.489004\n",
      "epoch 117; iter: 0; batch classifier loss: 0.358055; batch adversarial loss: 0.488431\n",
      "epoch 118; iter: 0; batch classifier loss: 0.371900; batch adversarial loss: 0.534559\n",
      "epoch 119; iter: 0; batch classifier loss: 0.398859; batch adversarial loss: 0.490022\n",
      "epoch 120; iter: 0; batch classifier loss: 0.362214; batch adversarial loss: 0.498687\n",
      "epoch 121; iter: 0; batch classifier loss: 0.430005; batch adversarial loss: 0.526066\n",
      "epoch 122; iter: 0; batch classifier loss: 0.427600; batch adversarial loss: 0.489502\n",
      "epoch 123; iter: 0; batch classifier loss: 0.429490; batch adversarial loss: 0.544146\n",
      "epoch 124; iter: 0; batch classifier loss: 0.387280; batch adversarial loss: 0.581694\n",
      "epoch 125; iter: 0; batch classifier loss: 0.317296; batch adversarial loss: 0.525580\n",
      "epoch 126; iter: 0; batch classifier loss: 0.319259; batch adversarial loss: 0.526562\n",
      "epoch 127; iter: 0; batch classifier loss: 0.408104; batch adversarial loss: 0.543335\n",
      "epoch 128; iter: 0; batch classifier loss: 0.391796; batch adversarial loss: 0.517438\n",
      "epoch 129; iter: 0; batch classifier loss: 0.454077; batch adversarial loss: 0.516581\n",
      "epoch 130; iter: 0; batch classifier loss: 0.332338; batch adversarial loss: 0.562391\n",
      "epoch 131; iter: 0; batch classifier loss: 0.435852; batch adversarial loss: 0.506334\n",
      "epoch 132; iter: 0; batch classifier loss: 0.393464; batch adversarial loss: 0.543576\n",
      "epoch 133; iter: 0; batch classifier loss: 0.468206; batch adversarial loss: 0.507743\n",
      "epoch 134; iter: 0; batch classifier loss: 0.383888; batch adversarial loss: 0.590041\n",
      "epoch 135; iter: 0; batch classifier loss: 0.328394; batch adversarial loss: 0.571993\n",
      "epoch 136; iter: 0; batch classifier loss: 0.439644; batch adversarial loss: 0.544107\n",
      "epoch 137; iter: 0; batch classifier loss: 0.397870; batch adversarial loss: 0.582058\n",
      "epoch 138; iter: 0; batch classifier loss: 0.446409; batch adversarial loss: 0.508698\n",
      "epoch 139; iter: 0; batch classifier loss: 0.331519; batch adversarial loss: 0.545081\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 140; iter: 0; batch classifier loss: 0.393557; batch adversarial loss: 0.610133\n",
      "epoch 141; iter: 0; batch classifier loss: 0.309635; batch adversarial loss: 0.581411\n",
      "epoch 142; iter: 0; batch classifier loss: 0.303940; batch adversarial loss: 0.591021\n",
      "epoch 143; iter: 0; batch classifier loss: 0.272898; batch adversarial loss: 0.589838\n",
      "epoch 144; iter: 0; batch classifier loss: 0.362785; batch adversarial loss: 0.571896\n",
      "epoch 145; iter: 0; batch classifier loss: 0.384339; batch adversarial loss: 0.543951\n",
      "epoch 146; iter: 0; batch classifier loss: 0.411651; batch adversarial loss: 0.571631\n",
      "epoch 147; iter: 0; batch classifier loss: 0.438835; batch adversarial loss: 0.525458\n",
      "epoch 148; iter: 0; batch classifier loss: 0.398821; batch adversarial loss: 0.487147\n",
      "epoch 149; iter: 0; batch classifier loss: 0.347788; batch adversarial loss: 0.589910\n",
      "epoch 150; iter: 0; batch classifier loss: 0.396754; batch adversarial loss: 0.564156\n",
      "epoch 151; iter: 0; batch classifier loss: 0.370088; batch adversarial loss: 0.610744\n",
      "epoch 152; iter: 0; batch classifier loss: 0.342416; batch adversarial loss: 0.479943\n",
      "epoch 153; iter: 0; batch classifier loss: 0.426700; batch adversarial loss: 0.653495\n",
      "epoch 154; iter: 0; batch classifier loss: 0.424003; batch adversarial loss: 0.499616\n",
      "epoch 155; iter: 0; batch classifier loss: 0.437620; batch adversarial loss: 0.599201\n",
      "epoch 156; iter: 0; batch classifier loss: 0.313744; batch adversarial loss: 0.506716\n",
      "epoch 157; iter: 0; batch classifier loss: 0.364701; batch adversarial loss: 0.462404\n",
      "epoch 158; iter: 0; batch classifier loss: 0.370640; batch adversarial loss: 0.524667\n",
      "epoch 159; iter: 0; batch classifier loss: 0.372485; batch adversarial loss: 0.580396\n",
      "epoch 160; iter: 0; batch classifier loss: 0.361321; batch adversarial loss: 0.525960\n",
      "epoch 161; iter: 0; batch classifier loss: 0.450513; batch adversarial loss: 0.590190\n",
      "epoch 162; iter: 0; batch classifier loss: 0.352196; batch adversarial loss: 0.517807\n",
      "epoch 163; iter: 0; batch classifier loss: 0.332489; batch adversarial loss: 0.561701\n",
      "epoch 164; iter: 0; batch classifier loss: 0.363046; batch adversarial loss: 0.535327\n",
      "epoch 165; iter: 0; batch classifier loss: 0.376220; batch adversarial loss: 0.581140\n",
      "epoch 166; iter: 0; batch classifier loss: 0.340922; batch adversarial loss: 0.609058\n",
      "epoch 167; iter: 0; batch classifier loss: 0.394910; batch adversarial loss: 0.609515\n",
      "epoch 168; iter: 0; batch classifier loss: 0.426514; batch adversarial loss: 0.608789\n",
      "epoch 169; iter: 0; batch classifier loss: 0.350206; batch adversarial loss: 0.552580\n",
      "epoch 170; iter: 0; batch classifier loss: 0.353201; batch adversarial loss: 0.553330\n",
      "epoch 171; iter: 0; batch classifier loss: 0.393183; batch adversarial loss: 0.553092\n",
      "epoch 172; iter: 0; batch classifier loss: 0.402626; batch adversarial loss: 0.488258\n",
      "epoch 173; iter: 0; batch classifier loss: 0.480065; batch adversarial loss: 0.562332\n",
      "epoch 174; iter: 0; batch classifier loss: 0.311341; batch adversarial loss: 0.581083\n",
      "epoch 175; iter: 0; batch classifier loss: 0.338206; batch adversarial loss: 0.638772\n",
      "epoch 176; iter: 0; batch classifier loss: 0.407880; batch adversarial loss: 0.554386\n",
      "epoch 177; iter: 0; batch classifier loss: 0.371311; batch adversarial loss: 0.535399\n",
      "epoch 178; iter: 0; batch classifier loss: 0.316604; batch adversarial loss: 0.582483\n",
      "epoch 179; iter: 0; batch classifier loss: 0.379078; batch adversarial loss: 0.480045\n",
      "epoch 180; iter: 0; batch classifier loss: 0.423598; batch adversarial loss: 0.544344\n",
      "epoch 181; iter: 0; batch classifier loss: 0.344755; batch adversarial loss: 0.553455\n",
      "epoch 182; iter: 0; batch classifier loss: 0.346166; batch adversarial loss: 0.544703\n",
      "epoch 183; iter: 0; batch classifier loss: 0.389223; batch adversarial loss: 0.553542\n",
      "epoch 184; iter: 0; batch classifier loss: 0.351593; batch adversarial loss: 0.535310\n",
      "epoch 185; iter: 0; batch classifier loss: 0.357628; batch adversarial loss: 0.617654\n",
      "epoch 186; iter: 0; batch classifier loss: 0.415332; batch adversarial loss: 0.617473\n",
      "epoch 187; iter: 0; batch classifier loss: 0.274836; batch adversarial loss: 0.515846\n",
      "epoch 188; iter: 0; batch classifier loss: 0.316460; batch adversarial loss: 0.544861\n",
      "epoch 189; iter: 0; batch classifier loss: 0.281460; batch adversarial loss: 0.469718\n",
      "epoch 190; iter: 0; batch classifier loss: 0.343640; batch adversarial loss: 0.582180\n",
      "epoch 191; iter: 0; batch classifier loss: 0.339644; batch adversarial loss: 0.544814\n",
      "epoch 192; iter: 0; batch classifier loss: 0.327453; batch adversarial loss: 0.461852\n",
      "epoch 193; iter: 0; batch classifier loss: 0.227019; batch adversarial loss: 0.462555\n",
      "epoch 194; iter: 0; batch classifier loss: 0.379046; batch adversarial loss: 0.470357\n",
      "epoch 195; iter: 0; batch classifier loss: 0.345308; batch adversarial loss: 0.590457\n",
      "epoch 196; iter: 0; batch classifier loss: 0.393702; batch adversarial loss: 0.572171\n",
      "epoch 197; iter: 0; batch classifier loss: 0.395176; batch adversarial loss: 0.525696\n",
      "epoch 198; iter: 0; batch classifier loss: 0.360305; batch adversarial loss: 0.534093\n",
      "epoch 199; iter: 0; batch classifier loss: 0.320455; batch adversarial loss: 0.469832\n",
      "epoch 0; iter: 0; batch classifier loss: 0.768581; batch adversarial loss: 1.128034\n",
      "epoch 1; iter: 0; batch classifier loss: 0.897258; batch adversarial loss: 1.347251\n",
      "epoch 2; iter: 0; batch classifier loss: 1.023787; batch adversarial loss: 1.303458\n",
      "epoch 3; iter: 0; batch classifier loss: 1.200549; batch adversarial loss: 1.254749\n",
      "epoch 4; iter: 0; batch classifier loss: 1.343737; batch adversarial loss: 1.171738\n",
      "epoch 5; iter: 0; batch classifier loss: 1.164938; batch adversarial loss: 1.060732\n",
      "epoch 6; iter: 0; batch classifier loss: 1.312051; batch adversarial loss: 0.982677\n",
      "epoch 7; iter: 0; batch classifier loss: 1.225986; batch adversarial loss: 0.901084\n",
      "epoch 8; iter: 0; batch classifier loss: 1.275976; batch adversarial loss: 0.829186\n",
      "epoch 9; iter: 0; batch classifier loss: 1.048609; batch adversarial loss: 0.786472\n",
      "epoch 10; iter: 0; batch classifier loss: 1.244016; batch adversarial loss: 0.741111\n",
      "epoch 11; iter: 0; batch classifier loss: 1.229044; batch adversarial loss: 0.674434\n",
      "epoch 12; iter: 0; batch classifier loss: 1.193364; batch adversarial loss: 0.650921\n",
      "epoch 13; iter: 0; batch classifier loss: 1.285937; batch adversarial loss: 0.662669\n",
      "epoch 14; iter: 0; batch classifier loss: 1.126079; batch adversarial loss: 0.567010\n",
      "epoch 15; iter: 0; batch classifier loss: 0.892622; batch adversarial loss: 0.603126\n",
      "epoch 16; iter: 0; batch classifier loss: 0.558020; batch adversarial loss: 0.616222\n",
      "epoch 17; iter: 0; batch classifier loss: 0.530426; batch adversarial loss: 0.556717\n",
      "epoch 18; iter: 0; batch classifier loss: 0.505628; batch adversarial loss: 0.558843\n",
      "epoch 19; iter: 0; batch classifier loss: 0.520881; batch adversarial loss: 0.581334\n",
      "epoch 20; iter: 0; batch classifier loss: 0.606512; batch adversarial loss: 0.562824\n",
      "epoch 21; iter: 0; batch classifier loss: 0.469695; batch adversarial loss: 0.590239\n",
      "epoch 22; iter: 0; batch classifier loss: 0.529258; batch adversarial loss: 0.565088\n",
      "epoch 23; iter: 0; batch classifier loss: 0.455043; batch adversarial loss: 0.541975\n",
      "epoch 24; iter: 0; batch classifier loss: 0.483097; batch adversarial loss: 0.570571\n",
      "epoch 25; iter: 0; batch classifier loss: 0.552566; batch adversarial loss: 0.516300\n",
      "epoch 26; iter: 0; batch classifier loss: 0.509529; batch adversarial loss: 0.594949\n",
      "epoch 27; iter: 0; batch classifier loss: 0.500470; batch adversarial loss: 0.540202\n",
      "epoch 28; iter: 0; batch classifier loss: 0.510583; batch adversarial loss: 0.535225\n",
      "epoch 29; iter: 0; batch classifier loss: 0.468019; batch adversarial loss: 0.510797\n",
      "epoch 30; iter: 0; batch classifier loss: 0.455558; batch adversarial loss: 0.571582\n",
      "epoch 31; iter: 0; batch classifier loss: 0.496453; batch adversarial loss: 0.594642\n",
      "epoch 32; iter: 0; batch classifier loss: 0.498887; batch adversarial loss: 0.521899\n",
      "epoch 33; iter: 0; batch classifier loss: 0.473690; batch adversarial loss: 0.544818\n",
      "epoch 34; iter: 0; batch classifier loss: 0.504492; batch adversarial loss: 0.590902\n",
      "epoch 35; iter: 0; batch classifier loss: 0.453271; batch adversarial loss: 0.479207\n",
      "epoch 36; iter: 0; batch classifier loss: 0.414283; batch adversarial loss: 0.590778\n",
      "epoch 37; iter: 0; batch classifier loss: 0.434420; batch adversarial loss: 0.537857\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 38; iter: 0; batch classifier loss: 0.456435; batch adversarial loss: 0.522328\n",
      "epoch 39; iter: 0; batch classifier loss: 0.465136; batch adversarial loss: 0.549853\n",
      "epoch 40; iter: 0; batch classifier loss: 0.450034; batch adversarial loss: 0.556529\n",
      "epoch 41; iter: 0; batch classifier loss: 0.452502; batch adversarial loss: 0.584573\n",
      "epoch 42; iter: 0; batch classifier loss: 0.466196; batch adversarial loss: 0.558611\n",
      "epoch 43; iter: 0; batch classifier loss: 0.394161; batch adversarial loss: 0.630251\n",
      "epoch 44; iter: 0; batch classifier loss: 0.455238; batch adversarial loss: 0.604525\n",
      "epoch 45; iter: 0; batch classifier loss: 0.416184; batch adversarial loss: 0.507633\n",
      "epoch 46; iter: 0; batch classifier loss: 0.516056; batch adversarial loss: 0.478980\n",
      "epoch 47; iter: 0; batch classifier loss: 0.497848; batch adversarial loss: 0.603326\n",
      "epoch 48; iter: 0; batch classifier loss: 0.407620; batch adversarial loss: 0.629158\n",
      "epoch 49; iter: 0; batch classifier loss: 0.337985; batch adversarial loss: 0.542931\n",
      "epoch 50; iter: 0; batch classifier loss: 0.434450; batch adversarial loss: 0.546800\n",
      "epoch 51; iter: 0; batch classifier loss: 0.479770; batch adversarial loss: 0.549139\n",
      "epoch 52; iter: 0; batch classifier loss: 0.438202; batch adversarial loss: 0.606649\n",
      "epoch 53; iter: 0; batch classifier loss: 0.462985; batch adversarial loss: 0.521829\n",
      "epoch 54; iter: 0; batch classifier loss: 0.451691; batch adversarial loss: 0.507800\n",
      "epoch 55; iter: 0; batch classifier loss: 0.485839; batch adversarial loss: 0.563007\n",
      "epoch 56; iter: 0; batch classifier loss: 0.436607; batch adversarial loss: 0.494507\n",
      "epoch 57; iter: 0; batch classifier loss: 0.427720; batch adversarial loss: 0.561889\n",
      "epoch 58; iter: 0; batch classifier loss: 0.446201; batch adversarial loss: 0.494131\n",
      "epoch 59; iter: 0; batch classifier loss: 0.391251; batch adversarial loss: 0.513703\n",
      "epoch 60; iter: 0; batch classifier loss: 0.480405; batch adversarial loss: 0.521904\n",
      "epoch 61; iter: 0; batch classifier loss: 0.355703; batch adversarial loss: 0.603041\n",
      "epoch 62; iter: 0; batch classifier loss: 0.368749; batch adversarial loss: 0.569514\n",
      "epoch 63; iter: 0; batch classifier loss: 0.401016; batch adversarial loss: 0.476168\n",
      "epoch 64; iter: 0; batch classifier loss: 0.326417; batch adversarial loss: 0.553414\n",
      "epoch 65; iter: 0; batch classifier loss: 0.467914; batch adversarial loss: 0.556715\n",
      "epoch 66; iter: 0; batch classifier loss: 0.385036; batch adversarial loss: 0.488375\n",
      "epoch 67; iter: 0; batch classifier loss: 0.389699; batch adversarial loss: 0.563863\n",
      "epoch 68; iter: 0; batch classifier loss: 0.392233; batch adversarial loss: 0.567864\n",
      "epoch 69; iter: 0; batch classifier loss: 0.399402; batch adversarial loss: 0.581991\n",
      "epoch 70; iter: 0; batch classifier loss: 0.512670; batch adversarial loss: 0.508071\n",
      "epoch 71; iter: 0; batch classifier loss: 0.406054; batch adversarial loss: 0.595616\n",
      "epoch 72; iter: 0; batch classifier loss: 0.468805; batch adversarial loss: 0.556759\n",
      "epoch 73; iter: 0; batch classifier loss: 0.425551; batch adversarial loss: 0.530134\n",
      "epoch 74; iter: 0; batch classifier loss: 0.441065; batch adversarial loss: 0.487005\n",
      "epoch 75; iter: 0; batch classifier loss: 0.347141; batch adversarial loss: 0.603079\n",
      "epoch 76; iter: 0; batch classifier loss: 0.400813; batch adversarial loss: 0.527609\n",
      "epoch 77; iter: 0; batch classifier loss: 0.475180; batch adversarial loss: 0.501845\n",
      "epoch 78; iter: 0; batch classifier loss: 0.470914; batch adversarial loss: 0.599247\n",
      "epoch 79; iter: 0; batch classifier loss: 0.343172; batch adversarial loss: 0.502239\n",
      "epoch 80; iter: 0; batch classifier loss: 0.398238; batch adversarial loss: 0.522545\n",
      "epoch 81; iter: 0; batch classifier loss: 0.351916; batch adversarial loss: 0.517558\n",
      "epoch 82; iter: 0; batch classifier loss: 0.390118; batch adversarial loss: 0.519089\n",
      "epoch 83; iter: 0; batch classifier loss: 0.429870; batch adversarial loss: 0.551062\n",
      "epoch 84; iter: 0; batch classifier loss: 0.397630; batch adversarial loss: 0.538513\n",
      "epoch 85; iter: 0; batch classifier loss: 0.413402; batch adversarial loss: 0.584608\n",
      "epoch 86; iter: 0; batch classifier loss: 0.396853; batch adversarial loss: 0.468411\n",
      "epoch 87; iter: 0; batch classifier loss: 0.343835; batch adversarial loss: 0.551689\n",
      "epoch 88; iter: 0; batch classifier loss: 0.417846; batch adversarial loss: 0.512377\n",
      "epoch 89; iter: 0; batch classifier loss: 0.378888; batch adversarial loss: 0.492285\n",
      "epoch 90; iter: 0; batch classifier loss: 0.448835; batch adversarial loss: 0.542167\n",
      "epoch 91; iter: 0; batch classifier loss: 0.372550; batch adversarial loss: 0.588879\n",
      "epoch 92; iter: 0; batch classifier loss: 0.344504; batch adversarial loss: 0.592736\n",
      "epoch 93; iter: 0; batch classifier loss: 0.381505; batch adversarial loss: 0.607415\n",
      "epoch 94; iter: 0; batch classifier loss: 0.425289; batch adversarial loss: 0.533777\n",
      "epoch 95; iter: 0; batch classifier loss: 0.472992; batch adversarial loss: 0.587614\n",
      "epoch 96; iter: 0; batch classifier loss: 0.386050; batch adversarial loss: 0.536853\n",
      "epoch 97; iter: 0; batch classifier loss: 0.390552; batch adversarial loss: 0.588358\n",
      "epoch 98; iter: 0; batch classifier loss: 0.385464; batch adversarial loss: 0.597134\n",
      "epoch 99; iter: 0; batch classifier loss: 0.414434; batch adversarial loss: 0.676172\n",
      "epoch 100; iter: 0; batch classifier loss: 0.370926; batch adversarial loss: 0.543824\n",
      "epoch 101; iter: 0; batch classifier loss: 0.421375; batch adversarial loss: 0.564146\n",
      "epoch 102; iter: 0; batch classifier loss: 0.458533; batch adversarial loss: 0.544457\n",
      "epoch 103; iter: 0; batch classifier loss: 0.519933; batch adversarial loss: 0.483395\n",
      "epoch 104; iter: 0; batch classifier loss: 0.262505; batch adversarial loss: 0.525797\n",
      "epoch 105; iter: 0; batch classifier loss: 0.328298; batch adversarial loss: 0.591597\n",
      "epoch 106; iter: 0; batch classifier loss: 0.369324; batch adversarial loss: 0.560397\n",
      "epoch 107; iter: 0; batch classifier loss: 0.330319; batch adversarial loss: 0.544119\n",
      "epoch 108; iter: 0; batch classifier loss: 0.346240; batch adversarial loss: 0.563533\n",
      "epoch 109; iter: 0; batch classifier loss: 0.330304; batch adversarial loss: 0.529434\n",
      "epoch 110; iter: 0; batch classifier loss: 0.339752; batch adversarial loss: 0.533051\n",
      "epoch 111; iter: 0; batch classifier loss: 0.334294; batch adversarial loss: 0.649204\n",
      "epoch 112; iter: 0; batch classifier loss: 0.379224; batch adversarial loss: 0.544095\n",
      "epoch 113; iter: 0; batch classifier loss: 0.387555; batch adversarial loss: 0.516184\n",
      "epoch 114; iter: 0; batch classifier loss: 0.398207; batch adversarial loss: 0.516010\n",
      "epoch 115; iter: 0; batch classifier loss: 0.271658; batch adversarial loss: 0.585324\n",
      "epoch 116; iter: 0; batch classifier loss: 0.398179; batch adversarial loss: 0.571748\n",
      "epoch 117; iter: 0; batch classifier loss: 0.309784; batch adversarial loss: 0.567647\n",
      "epoch 118; iter: 0; batch classifier loss: 0.389814; batch adversarial loss: 0.550677\n",
      "epoch 119; iter: 0; batch classifier loss: 0.426322; batch adversarial loss: 0.589409\n",
      "epoch 120; iter: 0; batch classifier loss: 0.344287; batch adversarial loss: 0.586782\n",
      "epoch 121; iter: 0; batch classifier loss: 0.430911; batch adversarial loss: 0.524870\n",
      "epoch 122; iter: 0; batch classifier loss: 0.306374; batch adversarial loss: 0.535125\n",
      "epoch 123; iter: 0; batch classifier loss: 0.358952; batch adversarial loss: 0.563083\n",
      "epoch 124; iter: 0; batch classifier loss: 0.352604; batch adversarial loss: 0.560087\n",
      "epoch 125; iter: 0; batch classifier loss: 0.304950; batch adversarial loss: 0.579827\n",
      "epoch 126; iter: 0; batch classifier loss: 0.438228; batch adversarial loss: 0.615778\n",
      "epoch 127; iter: 0; batch classifier loss: 0.406300; batch adversarial loss: 0.588434\n",
      "epoch 128; iter: 0; batch classifier loss: 0.400386; batch adversarial loss: 0.519484\n",
      "epoch 129; iter: 0; batch classifier loss: 0.354979; batch adversarial loss: 0.509749\n",
      "epoch 130; iter: 0; batch classifier loss: 0.328191; batch adversarial loss: 0.443758\n",
      "epoch 131; iter: 0; batch classifier loss: 0.323862; batch adversarial loss: 0.590748\n",
      "epoch 132; iter: 0; batch classifier loss: 0.323742; batch adversarial loss: 0.546410\n",
      "epoch 133; iter: 0; batch classifier loss: 0.351386; batch adversarial loss: 0.546574\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 134; iter: 0; batch classifier loss: 0.348670; batch adversarial loss: 0.589489\n",
      "epoch 135; iter: 0; batch classifier loss: 0.403528; batch adversarial loss: 0.554043\n",
      "epoch 136; iter: 0; batch classifier loss: 0.316953; batch adversarial loss: 0.554455\n",
      "epoch 137; iter: 0; batch classifier loss: 0.346207; batch adversarial loss: 0.550754\n",
      "epoch 138; iter: 0; batch classifier loss: 0.377527; batch adversarial loss: 0.549035\n",
      "epoch 139; iter: 0; batch classifier loss: 0.248037; batch adversarial loss: 0.498374\n",
      "epoch 140; iter: 0; batch classifier loss: 0.389741; batch adversarial loss: 0.573769\n",
      "epoch 141; iter: 0; batch classifier loss: 0.363954; batch adversarial loss: 0.590171\n",
      "epoch 142; iter: 0; batch classifier loss: 0.307057; batch adversarial loss: 0.553791\n",
      "epoch 143; iter: 0; batch classifier loss: 0.292580; batch adversarial loss: 0.508875\n",
      "epoch 144; iter: 0; batch classifier loss: 0.301949; batch adversarial loss: 0.550843\n",
      "epoch 145; iter: 0; batch classifier loss: 0.364792; batch adversarial loss: 0.582945\n",
      "epoch 146; iter: 0; batch classifier loss: 0.328156; batch adversarial loss: 0.550403\n",
      "epoch 147; iter: 0; batch classifier loss: 0.382524; batch adversarial loss: 0.606814\n",
      "epoch 148; iter: 0; batch classifier loss: 0.400195; batch adversarial loss: 0.537224\n",
      "epoch 149; iter: 0; batch classifier loss: 0.369770; batch adversarial loss: 0.473478\n",
      "epoch 150; iter: 0; batch classifier loss: 0.326468; batch adversarial loss: 0.652898\n",
      "epoch 151; iter: 0; batch classifier loss: 0.273922; batch adversarial loss: 0.527505\n",
      "epoch 152; iter: 0; batch classifier loss: 0.377090; batch adversarial loss: 0.517395\n",
      "epoch 153; iter: 0; batch classifier loss: 0.302359; batch adversarial loss: 0.512823\n",
      "epoch 154; iter: 0; batch classifier loss: 0.335529; batch adversarial loss: 0.570826\n",
      "epoch 155; iter: 0; batch classifier loss: 0.303754; batch adversarial loss: 0.518964\n",
      "epoch 156; iter: 0; batch classifier loss: 0.321516; batch adversarial loss: 0.574195\n",
      "epoch 157; iter: 0; batch classifier loss: 0.320000; batch adversarial loss: 0.552065\n",
      "epoch 158; iter: 0; batch classifier loss: 0.394479; batch adversarial loss: 0.571118\n",
      "epoch 159; iter: 0; batch classifier loss: 0.332931; batch adversarial loss: 0.553159\n",
      "epoch 160; iter: 0; batch classifier loss: 0.276897; batch adversarial loss: 0.535717\n",
      "epoch 161; iter: 0; batch classifier loss: 0.354807; batch adversarial loss: 0.579602\n",
      "epoch 162; iter: 0; batch classifier loss: 0.286015; batch adversarial loss: 0.545707\n",
      "epoch 163; iter: 0; batch classifier loss: 0.416737; batch adversarial loss: 0.518847\n",
      "epoch 164; iter: 0; batch classifier loss: 0.392470; batch adversarial loss: 0.509471\n",
      "epoch 165; iter: 0; batch classifier loss: 0.368888; batch adversarial loss: 0.484752\n",
      "epoch 166; iter: 0; batch classifier loss: 0.381792; batch adversarial loss: 0.563038\n",
      "epoch 167; iter: 0; batch classifier loss: 0.367937; batch adversarial loss: 0.576504\n",
      "epoch 168; iter: 0; batch classifier loss: 0.302802; batch adversarial loss: 0.536220\n",
      "epoch 169; iter: 0; batch classifier loss: 0.364024; batch adversarial loss: 0.634225\n",
      "epoch 170; iter: 0; batch classifier loss: 0.323114; batch adversarial loss: 0.552453\n",
      "epoch 171; iter: 0; batch classifier loss: 0.297807; batch adversarial loss: 0.569818\n",
      "epoch 172; iter: 0; batch classifier loss: 0.447881; batch adversarial loss: 0.526886\n",
      "epoch 173; iter: 0; batch classifier loss: 0.301525; batch adversarial loss: 0.575798\n",
      "epoch 174; iter: 0; batch classifier loss: 0.329424; batch adversarial loss: 0.646278\n",
      "epoch 175; iter: 0; batch classifier loss: 0.353254; batch adversarial loss: 0.625889\n",
      "epoch 176; iter: 0; batch classifier loss: 0.297963; batch adversarial loss: 0.573775\n",
      "epoch 177; iter: 0; batch classifier loss: 0.362552; batch adversarial loss: 0.529675\n",
      "epoch 178; iter: 0; batch classifier loss: 0.288158; batch adversarial loss: 0.551870\n",
      "epoch 179; iter: 0; batch classifier loss: 0.347860; batch adversarial loss: 0.595208\n",
      "epoch 180; iter: 0; batch classifier loss: 0.351587; batch adversarial loss: 0.596315\n",
      "epoch 181; iter: 0; batch classifier loss: 0.303694; batch adversarial loss: 0.518263\n",
      "epoch 182; iter: 0; batch classifier loss: 0.389254; batch adversarial loss: 0.596473\n",
      "epoch 183; iter: 0; batch classifier loss: 0.279477; batch adversarial loss: 0.680241\n",
      "epoch 184; iter: 0; batch classifier loss: 0.323061; batch adversarial loss: 0.517240\n",
      "epoch 185; iter: 0; batch classifier loss: 0.271327; batch adversarial loss: 0.570489\n",
      "epoch 186; iter: 0; batch classifier loss: 0.327002; batch adversarial loss: 0.606675\n",
      "epoch 187; iter: 0; batch classifier loss: 0.339733; batch adversarial loss: 0.546797\n",
      "epoch 188; iter: 0; batch classifier loss: 0.333894; batch adversarial loss: 0.544424\n",
      "epoch 189; iter: 0; batch classifier loss: 0.328838; batch adversarial loss: 0.614323\n",
      "epoch 190; iter: 0; batch classifier loss: 0.360604; batch adversarial loss: 0.591503\n",
      "epoch 191; iter: 0; batch classifier loss: 0.337322; batch adversarial loss: 0.498705\n",
      "epoch 192; iter: 0; batch classifier loss: 0.318402; batch adversarial loss: 0.586762\n",
      "epoch 193; iter: 0; batch classifier loss: 0.341258; batch adversarial loss: 0.499616\n",
      "epoch 194; iter: 0; batch classifier loss: 0.318943; batch adversarial loss: 0.560124\n",
      "epoch 195; iter: 0; batch classifier loss: 0.310017; batch adversarial loss: 0.491035\n",
      "epoch 196; iter: 0; batch classifier loss: 0.257746; batch adversarial loss: 0.552211\n",
      "epoch 197; iter: 0; batch classifier loss: 0.370130; batch adversarial loss: 0.523796\n",
      "epoch 198; iter: 0; batch classifier loss: 0.292230; batch adversarial loss: 0.562203\n",
      "epoch 199; iter: 0; batch classifier loss: 0.346445; batch adversarial loss: 0.540442\n",
      "epoch 0; iter: 0; batch classifier loss: 0.732522; batch adversarial loss: 0.621858\n",
      "epoch 1; iter: 0; batch classifier loss: 0.569460; batch adversarial loss: 0.655587\n",
      "epoch 2; iter: 0; batch classifier loss: 0.583224; batch adversarial loss: 0.649489\n",
      "epoch 3; iter: 0; batch classifier loss: 0.580376; batch adversarial loss: 0.629341\n",
      "epoch 4; iter: 0; batch classifier loss: 0.496532; batch adversarial loss: 0.595314\n",
      "epoch 5; iter: 0; batch classifier loss: 0.602018; batch adversarial loss: 0.616211\n",
      "epoch 6; iter: 0; batch classifier loss: 0.691679; batch adversarial loss: 0.605575\n",
      "epoch 7; iter: 0; batch classifier loss: 0.507440; batch adversarial loss: 0.624221\n",
      "epoch 8; iter: 0; batch classifier loss: 0.541773; batch adversarial loss: 0.614776\n",
      "epoch 9; iter: 0; batch classifier loss: 0.595346; batch adversarial loss: 0.585564\n",
      "epoch 10; iter: 0; batch classifier loss: 0.546589; batch adversarial loss: 0.623446\n",
      "epoch 11; iter: 0; batch classifier loss: 0.596510; batch adversarial loss: 0.627099\n",
      "epoch 12; iter: 0; batch classifier loss: 0.587174; batch adversarial loss: 0.563261\n",
      "epoch 13; iter: 0; batch classifier loss: 0.570622; batch adversarial loss: 0.549141\n",
      "epoch 14; iter: 0; batch classifier loss: 0.493935; batch adversarial loss: 0.575959\n",
      "epoch 15; iter: 0; batch classifier loss: 0.553342; batch adversarial loss: 0.502604\n",
      "epoch 16; iter: 0; batch classifier loss: 0.538948; batch adversarial loss: 0.555139\n",
      "epoch 17; iter: 0; batch classifier loss: 0.557093; batch adversarial loss: 0.544218\n",
      "epoch 18; iter: 0; batch classifier loss: 0.471042; batch adversarial loss: 0.609661\n",
      "epoch 19; iter: 0; batch classifier loss: 0.537615; batch adversarial loss: 0.542561\n",
      "epoch 20; iter: 0; batch classifier loss: 0.533300; batch adversarial loss: 0.493693\n",
      "epoch 21; iter: 0; batch classifier loss: 0.570117; batch adversarial loss: 0.548387\n",
      "epoch 22; iter: 0; batch classifier loss: 0.556598; batch adversarial loss: 0.499358\n",
      "epoch 23; iter: 0; batch classifier loss: 0.514176; batch adversarial loss: 0.571263\n",
      "epoch 24; iter: 0; batch classifier loss: 0.464870; batch adversarial loss: 0.467243\n",
      "epoch 25; iter: 0; batch classifier loss: 0.520646; batch adversarial loss: 0.548990\n",
      "epoch 26; iter: 0; batch classifier loss: 0.478493; batch adversarial loss: 0.495721\n",
      "epoch 27; iter: 0; batch classifier loss: 0.466609; batch adversarial loss: 0.512453\n",
      "epoch 28; iter: 0; batch classifier loss: 0.468373; batch adversarial loss: 0.636861\n",
      "epoch 29; iter: 0; batch classifier loss: 0.491628; batch adversarial loss: 0.600896\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30; iter: 0; batch classifier loss: 0.519395; batch adversarial loss: 0.580531\n",
      "epoch 31; iter: 0; batch classifier loss: 0.461074; batch adversarial loss: 0.474663\n",
      "epoch 32; iter: 0; batch classifier loss: 0.450071; batch adversarial loss: 0.480730\n",
      "epoch 33; iter: 0; batch classifier loss: 0.497160; batch adversarial loss: 0.489455\n",
      "epoch 34; iter: 0; batch classifier loss: 0.527155; batch adversarial loss: 0.534415\n",
      "epoch 35; iter: 0; batch classifier loss: 0.481276; batch adversarial loss: 0.608862\n",
      "epoch 36; iter: 0; batch classifier loss: 0.472378; batch adversarial loss: 0.489217\n",
      "epoch 37; iter: 0; batch classifier loss: 0.431066; batch adversarial loss: 0.501239\n",
      "epoch 38; iter: 0; batch classifier loss: 0.467401; batch adversarial loss: 0.488372\n",
      "epoch 39; iter: 0; batch classifier loss: 0.465363; batch adversarial loss: 0.487293\n",
      "epoch 40; iter: 0; batch classifier loss: 0.523853; batch adversarial loss: 0.535442\n",
      "epoch 41; iter: 0; batch classifier loss: 0.382246; batch adversarial loss: 0.535133\n",
      "epoch 42; iter: 0; batch classifier loss: 0.385500; batch adversarial loss: 0.488026\n",
      "epoch 43; iter: 0; batch classifier loss: 0.398312; batch adversarial loss: 0.554727\n",
      "epoch 44; iter: 0; batch classifier loss: 0.430350; batch adversarial loss: 0.478416\n",
      "epoch 45; iter: 0; batch classifier loss: 0.457927; batch adversarial loss: 0.620453\n",
      "epoch 46; iter: 0; batch classifier loss: 0.407156; batch adversarial loss: 0.516118\n",
      "epoch 47; iter: 0; batch classifier loss: 0.499412; batch adversarial loss: 0.535100\n",
      "epoch 48; iter: 0; batch classifier loss: 0.395543; batch adversarial loss: 0.507202\n",
      "epoch 49; iter: 0; batch classifier loss: 0.514862; batch adversarial loss: 0.506429\n",
      "epoch 50; iter: 0; batch classifier loss: 0.397168; batch adversarial loss: 0.553680\n",
      "epoch 51; iter: 0; batch classifier loss: 0.446147; batch adversarial loss: 0.572502\n",
      "epoch 52; iter: 0; batch classifier loss: 0.409121; batch adversarial loss: 0.620587\n",
      "epoch 53; iter: 0; batch classifier loss: 0.414767; batch adversarial loss: 0.487612\n",
      "epoch 54; iter: 0; batch classifier loss: 0.387092; batch adversarial loss: 0.468659\n",
      "epoch 55; iter: 0; batch classifier loss: 0.497766; batch adversarial loss: 0.573856\n",
      "epoch 56; iter: 0; batch classifier loss: 0.383391; batch adversarial loss: 0.507277\n",
      "epoch 57; iter: 0; batch classifier loss: 0.466945; batch adversarial loss: 0.591431\n",
      "epoch 58; iter: 0; batch classifier loss: 0.405477; batch adversarial loss: 0.611283\n",
      "epoch 59; iter: 0; batch classifier loss: 0.369842; batch adversarial loss: 0.506364\n",
      "epoch 60; iter: 0; batch classifier loss: 0.385413; batch adversarial loss: 0.515965\n",
      "epoch 61; iter: 0; batch classifier loss: 0.468894; batch adversarial loss: 0.591933\n",
      "epoch 62; iter: 0; batch classifier loss: 0.402193; batch adversarial loss: 0.487684\n",
      "epoch 63; iter: 0; batch classifier loss: 0.423385; batch adversarial loss: 0.629657\n",
      "epoch 64; iter: 0; batch classifier loss: 0.410241; batch adversarial loss: 0.544058\n",
      "epoch 65; iter: 0; batch classifier loss: 0.420316; batch adversarial loss: 0.544592\n",
      "epoch 66; iter: 0; batch classifier loss: 0.409098; batch adversarial loss: 0.544405\n",
      "epoch 67; iter: 0; batch classifier loss: 0.420786; batch adversarial loss: 0.563906\n",
      "epoch 68; iter: 0; batch classifier loss: 0.420687; batch adversarial loss: 0.572956\n",
      "epoch 69; iter: 0; batch classifier loss: 0.498858; batch adversarial loss: 0.515636\n",
      "epoch 70; iter: 0; batch classifier loss: 0.411442; batch adversarial loss: 0.505989\n",
      "epoch 71; iter: 0; batch classifier loss: 0.396088; batch adversarial loss: 0.544410\n",
      "epoch 72; iter: 0; batch classifier loss: 0.397342; batch adversarial loss: 0.516276\n",
      "epoch 73; iter: 0; batch classifier loss: 0.412962; batch adversarial loss: 0.601297\n",
      "epoch 74; iter: 0; batch classifier loss: 0.384158; batch adversarial loss: 0.525680\n",
      "epoch 75; iter: 0; batch classifier loss: 0.402476; batch adversarial loss: 0.553968\n",
      "epoch 76; iter: 0; batch classifier loss: 0.449945; batch adversarial loss: 0.592045\n",
      "epoch 77; iter: 0; batch classifier loss: 0.440251; batch adversarial loss: 0.534903\n",
      "epoch 78; iter: 0; batch classifier loss: 0.419157; batch adversarial loss: 0.620538\n",
      "epoch 79; iter: 0; batch classifier loss: 0.425243; batch adversarial loss: 0.535303\n",
      "epoch 80; iter: 0; batch classifier loss: 0.389738; batch adversarial loss: 0.573380\n",
      "epoch 81; iter: 0; batch classifier loss: 0.443002; batch adversarial loss: 0.506786\n",
      "epoch 82; iter: 0; batch classifier loss: 0.459886; batch adversarial loss: 0.515874\n",
      "epoch 83; iter: 0; batch classifier loss: 0.392258; batch adversarial loss: 0.525735\n",
      "epoch 84; iter: 0; batch classifier loss: 0.426871; batch adversarial loss: 0.610771\n",
      "epoch 85; iter: 0; batch classifier loss: 0.390522; batch adversarial loss: 0.544660\n",
      "epoch 86; iter: 0; batch classifier loss: 0.476369; batch adversarial loss: 0.553189\n",
      "epoch 87; iter: 0; batch classifier loss: 0.388470; batch adversarial loss: 0.611543\n",
      "epoch 88; iter: 0; batch classifier loss: 0.345142; batch adversarial loss: 0.524958\n",
      "epoch 89; iter: 0; batch classifier loss: 0.329060; batch adversarial loss: 0.554012\n",
      "epoch 90; iter: 0; batch classifier loss: 0.426345; batch adversarial loss: 0.544715\n",
      "epoch 91; iter: 0; batch classifier loss: 0.364805; batch adversarial loss: 0.487686\n",
      "epoch 92; iter: 0; batch classifier loss: 0.348824; batch adversarial loss: 0.535211\n",
      "epoch 93; iter: 0; batch classifier loss: 0.473322; batch adversarial loss: 0.563496\n",
      "epoch 94; iter: 0; batch classifier loss: 0.335569; batch adversarial loss: 0.572742\n",
      "epoch 95; iter: 0; batch classifier loss: 0.423574; batch adversarial loss: 0.620117\n",
      "epoch 96; iter: 0; batch classifier loss: 0.349417; batch adversarial loss: 0.496675\n",
      "epoch 97; iter: 0; batch classifier loss: 0.351731; batch adversarial loss: 0.553910\n",
      "epoch 98; iter: 0; batch classifier loss: 0.468019; batch adversarial loss: 0.582199\n",
      "epoch 99; iter: 0; batch classifier loss: 0.405000; batch adversarial loss: 0.516340\n",
      "epoch 100; iter: 0; batch classifier loss: 0.454173; batch adversarial loss: 0.506268\n",
      "epoch 101; iter: 0; batch classifier loss: 0.421840; batch adversarial loss: 0.553780\n",
      "epoch 102; iter: 0; batch classifier loss: 0.373866; batch adversarial loss: 0.544823\n",
      "epoch 103; iter: 0; batch classifier loss: 0.454535; batch adversarial loss: 0.544616\n",
      "epoch 104; iter: 0; batch classifier loss: 0.395454; batch adversarial loss: 0.525607\n",
      "epoch 105; iter: 0; batch classifier loss: 0.365672; batch adversarial loss: 0.591514\n",
      "epoch 106; iter: 0; batch classifier loss: 0.384785; batch adversarial loss: 0.516032\n",
      "epoch 107; iter: 0; batch classifier loss: 0.380803; batch adversarial loss: 0.563677\n",
      "epoch 108; iter: 0; batch classifier loss: 0.404561; batch adversarial loss: 0.516035\n",
      "epoch 109; iter: 0; batch classifier loss: 0.355977; batch adversarial loss: 0.506663\n",
      "epoch 110; iter: 0; batch classifier loss: 0.403454; batch adversarial loss: 0.554256\n",
      "epoch 111; iter: 0; batch classifier loss: 0.347256; batch adversarial loss: 0.487262\n",
      "epoch 112; iter: 0; batch classifier loss: 0.390357; batch adversarial loss: 0.553991\n",
      "epoch 113; iter: 0; batch classifier loss: 0.328438; batch adversarial loss: 0.535053\n",
      "epoch 114; iter: 0; batch classifier loss: 0.388386; batch adversarial loss: 0.497278\n",
      "epoch 115; iter: 0; batch classifier loss: 0.379881; batch adversarial loss: 0.487925\n",
      "epoch 116; iter: 0; batch classifier loss: 0.428921; batch adversarial loss: 0.534859\n",
      "epoch 117; iter: 0; batch classifier loss: 0.425810; batch adversarial loss: 0.639493\n",
      "epoch 118; iter: 0; batch classifier loss: 0.427421; batch adversarial loss: 0.582779\n",
      "epoch 119; iter: 0; batch classifier loss: 0.415309; batch adversarial loss: 0.468509\n",
      "epoch 120; iter: 0; batch classifier loss: 0.382632; batch adversarial loss: 0.544599\n",
      "epoch 121; iter: 0; batch classifier loss: 0.370659; batch adversarial loss: 0.592162\n",
      "epoch 122; iter: 0; batch classifier loss: 0.391511; batch adversarial loss: 0.554044\n",
      "epoch 123; iter: 0; batch classifier loss: 0.399048; batch adversarial loss: 0.525631\n",
      "epoch 124; iter: 0; batch classifier loss: 0.375645; batch adversarial loss: 0.592243\n",
      "epoch 125; iter: 0; batch classifier loss: 0.390670; batch adversarial loss: 0.554172\n",
      "epoch 126; iter: 0; batch classifier loss: 0.377971; batch adversarial loss: 0.506555\n",
      "epoch 127; iter: 0; batch classifier loss: 0.374163; batch adversarial loss: 0.468841\n",
      "epoch 128; iter: 0; batch classifier loss: 0.362850; batch adversarial loss: 0.554053\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 129; iter: 0; batch classifier loss: 0.403149; batch adversarial loss: 0.477934\n",
      "epoch 130; iter: 0; batch classifier loss: 0.352602; batch adversarial loss: 0.630003\n",
      "epoch 131; iter: 0; batch classifier loss: 0.343042; batch adversarial loss: 0.506573\n",
      "epoch 132; iter: 0; batch classifier loss: 0.384846; batch adversarial loss: 0.487529\n",
      "epoch 133; iter: 0; batch classifier loss: 0.362557; batch adversarial loss: 0.563567\n",
      "epoch 134; iter: 0; batch classifier loss: 0.376726; batch adversarial loss: 0.525701\n",
      "epoch 135; iter: 0; batch classifier loss: 0.372771; batch adversarial loss: 0.525401\n",
      "epoch 136; iter: 0; batch classifier loss: 0.429815; batch adversarial loss: 0.592407\n",
      "epoch 137; iter: 0; batch classifier loss: 0.399212; batch adversarial loss: 0.554099\n",
      "epoch 138; iter: 0; batch classifier loss: 0.353670; batch adversarial loss: 0.515928\n",
      "epoch 139; iter: 0; batch classifier loss: 0.319701; batch adversarial loss: 0.487576\n",
      "epoch 140; iter: 0; batch classifier loss: 0.434639; batch adversarial loss: 0.525533\n",
      "epoch 141; iter: 0; batch classifier loss: 0.383657; batch adversarial loss: 0.554032\n",
      "epoch 142; iter: 0; batch classifier loss: 0.302693; batch adversarial loss: 0.525594\n",
      "epoch 143; iter: 0; batch classifier loss: 0.428324; batch adversarial loss: 0.525639\n",
      "epoch 144; iter: 0; batch classifier loss: 0.407790; batch adversarial loss: 0.582524\n",
      "epoch 145; iter: 0; batch classifier loss: 0.298123; batch adversarial loss: 0.563590\n",
      "epoch 146; iter: 0; batch classifier loss: 0.389603; batch adversarial loss: 0.544484\n",
      "epoch 147; iter: 0; batch classifier loss: 0.358519; batch adversarial loss: 0.469268\n",
      "epoch 148; iter: 0; batch classifier loss: 0.367464; batch adversarial loss: 0.468652\n",
      "epoch 149; iter: 0; batch classifier loss: 0.423492; batch adversarial loss: 0.497229\n",
      "epoch 150; iter: 0; batch classifier loss: 0.336089; batch adversarial loss: 0.582642\n",
      "epoch 151; iter: 0; batch classifier loss: 0.391553; batch adversarial loss: 0.516031\n",
      "epoch 152; iter: 0; batch classifier loss: 0.461720; batch adversarial loss: 0.496567\n",
      "epoch 153; iter: 0; batch classifier loss: 0.384576; batch adversarial loss: 0.506059\n",
      "epoch 154; iter: 0; batch classifier loss: 0.333331; batch adversarial loss: 0.496906\n",
      "epoch 155; iter: 0; batch classifier loss: 0.366101; batch adversarial loss: 0.573434\n",
      "epoch 156; iter: 0; batch classifier loss: 0.342234; batch adversarial loss: 0.534579\n",
      "epoch 157; iter: 0; batch classifier loss: 0.374078; batch adversarial loss: 0.535035\n",
      "epoch 158; iter: 0; batch classifier loss: 0.389974; batch adversarial loss: 0.525555\n",
      "epoch 159; iter: 0; batch classifier loss: 0.399028; batch adversarial loss: 0.554360\n",
      "epoch 160; iter: 0; batch classifier loss: 0.401258; batch adversarial loss: 0.459280\n",
      "epoch 161; iter: 0; batch classifier loss: 0.342076; batch adversarial loss: 0.583262\n",
      "epoch 162; iter: 0; batch classifier loss: 0.414945; batch adversarial loss: 0.487567\n",
      "epoch 163; iter: 0; batch classifier loss: 0.311421; batch adversarial loss: 0.496764\n",
      "epoch 164; iter: 0; batch classifier loss: 0.386282; batch adversarial loss: 0.458804\n",
      "epoch 165; iter: 0; batch classifier loss: 0.383888; batch adversarial loss: 0.544113\n",
      "epoch 166; iter: 0; batch classifier loss: 0.375830; batch adversarial loss: 0.515334\n",
      "epoch 167; iter: 0; batch classifier loss: 0.352940; batch adversarial loss: 0.639736\n",
      "epoch 168; iter: 0; batch classifier loss: 0.356169; batch adversarial loss: 0.506728\n",
      "epoch 169; iter: 0; batch classifier loss: 0.428457; batch adversarial loss: 0.506577\n",
      "epoch 170; iter: 0; batch classifier loss: 0.375785; batch adversarial loss: 0.525225\n",
      "epoch 171; iter: 0; batch classifier loss: 0.414833; batch adversarial loss: 0.525431\n",
      "epoch 172; iter: 0; batch classifier loss: 0.458964; batch adversarial loss: 0.467996\n",
      "epoch 173; iter: 0; batch classifier loss: 0.436153; batch adversarial loss: 0.496900\n",
      "epoch 174; iter: 0; batch classifier loss: 0.411774; batch adversarial loss: 0.488058\n",
      "epoch 175; iter: 0; batch classifier loss: 0.346523; batch adversarial loss: 0.497242\n",
      "epoch 176; iter: 0; batch classifier loss: 0.387401; batch adversarial loss: 0.639469\n",
      "epoch 177; iter: 0; batch classifier loss: 0.300655; batch adversarial loss: 0.554756\n",
      "epoch 178; iter: 0; batch classifier loss: 0.355485; batch adversarial loss: 0.620117\n",
      "epoch 179; iter: 0; batch classifier loss: 0.346440; batch adversarial loss: 0.506375\n",
      "epoch 180; iter: 0; batch classifier loss: 0.329259; batch adversarial loss: 0.496703\n",
      "epoch 181; iter: 0; batch classifier loss: 0.427712; batch adversarial loss: 0.496644\n",
      "epoch 182; iter: 0; batch classifier loss: 0.392658; batch adversarial loss: 0.563871\n",
      "epoch 183; iter: 0; batch classifier loss: 0.353720; batch adversarial loss: 0.516037\n",
      "epoch 184; iter: 0; batch classifier loss: 0.382431; batch adversarial loss: 0.572520\n",
      "epoch 185; iter: 0; batch classifier loss: 0.399198; batch adversarial loss: 0.572873\n",
      "epoch 186; iter: 0; batch classifier loss: 0.395128; batch adversarial loss: 0.478152\n",
      "epoch 187; iter: 0; batch classifier loss: 0.424823; batch adversarial loss: 0.554969\n",
      "epoch 188; iter: 0; batch classifier loss: 0.423317; batch adversarial loss: 0.467892\n",
      "epoch 189; iter: 0; batch classifier loss: 0.327034; batch adversarial loss: 0.600391\n",
      "epoch 190; iter: 0; batch classifier loss: 0.357957; batch adversarial loss: 0.555088\n",
      "epoch 191; iter: 0; batch classifier loss: 0.387235; batch adversarial loss: 0.563153\n",
      "epoch 192; iter: 0; batch classifier loss: 0.360498; batch adversarial loss: 0.525461\n",
      "epoch 193; iter: 0; batch classifier loss: 0.349463; batch adversarial loss: 0.525467\n",
      "epoch 194; iter: 0; batch classifier loss: 0.382151; batch adversarial loss: 0.525813\n",
      "epoch 195; iter: 0; batch classifier loss: 0.422373; batch adversarial loss: 0.497586\n",
      "epoch 196; iter: 0; batch classifier loss: 0.413228; batch adversarial loss: 0.478635\n",
      "epoch 197; iter: 0; batch classifier loss: 0.411440; batch adversarial loss: 0.516275\n",
      "epoch 198; iter: 0; batch classifier loss: 0.460189; batch adversarial loss: 0.544725\n",
      "epoch 199; iter: 0; batch classifier loss: 0.386215; batch adversarial loss: 0.563307\n",
      "epoch 0; iter: 0; batch classifier loss: 0.731518; batch adversarial loss: 0.713887\n",
      "epoch 1; iter: 0; batch classifier loss: 0.673226; batch adversarial loss: 0.676868\n",
      "epoch 2; iter: 0; batch classifier loss: 0.595456; batch adversarial loss: 0.651915\n",
      "epoch 3; iter: 0; batch classifier loss: 0.550972; batch adversarial loss: 0.642688\n",
      "epoch 4; iter: 0; batch classifier loss: 0.633494; batch adversarial loss: 0.623918\n",
      "epoch 5; iter: 0; batch classifier loss: 0.553156; batch adversarial loss: 0.639530\n",
      "epoch 6; iter: 0; batch classifier loss: 0.479640; batch adversarial loss: 0.591944\n",
      "epoch 7; iter: 0; batch classifier loss: 0.586958; batch adversarial loss: 0.574650\n",
      "epoch 8; iter: 0; batch classifier loss: 0.522534; batch adversarial loss: 0.591630\n",
      "epoch 9; iter: 0; batch classifier loss: 0.539453; batch adversarial loss: 0.608963\n",
      "epoch 10; iter: 0; batch classifier loss: 0.529062; batch adversarial loss: 0.565493\n",
      "epoch 11; iter: 0; batch classifier loss: 0.482895; batch adversarial loss: 0.580721\n",
      "epoch 12; iter: 0; batch classifier loss: 0.483541; batch adversarial loss: 0.521963\n",
      "epoch 13; iter: 0; batch classifier loss: 0.557889; batch adversarial loss: 0.579545\n",
      "epoch 14; iter: 0; batch classifier loss: 0.555939; batch adversarial loss: 0.541628\n",
      "epoch 15; iter: 0; batch classifier loss: 0.575213; batch adversarial loss: 0.529206\n",
      "epoch 16; iter: 0; batch classifier loss: 0.484677; batch adversarial loss: 0.504602\n",
      "epoch 17; iter: 0; batch classifier loss: 0.534851; batch adversarial loss: 0.560436\n",
      "epoch 18; iter: 0; batch classifier loss: 0.508584; batch adversarial loss: 0.594142\n",
      "epoch 19; iter: 0; batch classifier loss: 0.448559; batch adversarial loss: 0.577569\n",
      "epoch 20; iter: 0; batch classifier loss: 0.516153; batch adversarial loss: 0.578397\n",
      "epoch 21; iter: 0; batch classifier loss: 0.470416; batch adversarial loss: 0.570057\n",
      "epoch 22; iter: 0; batch classifier loss: 0.551382; batch adversarial loss: 0.574887\n",
      "epoch 23; iter: 0; batch classifier loss: 0.488683; batch adversarial loss: 0.486888\n",
      "epoch 24; iter: 0; batch classifier loss: 0.406371; batch adversarial loss: 0.589647\n",
      "epoch 25; iter: 0; batch classifier loss: 0.526151; batch adversarial loss: 0.530198\n",
      "epoch 26; iter: 0; batch classifier loss: 0.475152; batch adversarial loss: 0.539330\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 27; iter: 0; batch classifier loss: 0.418956; batch adversarial loss: 0.538718\n",
      "epoch 28; iter: 0; batch classifier loss: 0.445080; batch adversarial loss: 0.529891\n",
      "epoch 29; iter: 0; batch classifier loss: 0.501728; batch adversarial loss: 0.540951\n",
      "epoch 30; iter: 0; batch classifier loss: 0.487836; batch adversarial loss: 0.496699\n",
      "epoch 31; iter: 0; batch classifier loss: 0.482231; batch adversarial loss: 0.520811\n",
      "epoch 32; iter: 0; batch classifier loss: 0.493650; batch adversarial loss: 0.529663\n",
      "epoch 33; iter: 0; batch classifier loss: 0.388429; batch adversarial loss: 0.495072\n",
      "epoch 34; iter: 0; batch classifier loss: 0.521914; batch adversarial loss: 0.640297\n",
      "epoch 35; iter: 0; batch classifier loss: 0.417754; batch adversarial loss: 0.536817\n",
      "epoch 36; iter: 0; batch classifier loss: 0.406020; batch adversarial loss: 0.536326\n",
      "epoch 37; iter: 0; batch classifier loss: 0.503913; batch adversarial loss: 0.562690\n",
      "epoch 38; iter: 0; batch classifier loss: 0.458602; batch adversarial loss: 0.509849\n",
      "epoch 39; iter: 0; batch classifier loss: 0.439611; batch adversarial loss: 0.587506\n",
      "epoch 40; iter: 0; batch classifier loss: 0.445636; batch adversarial loss: 0.577818\n",
      "epoch 41; iter: 0; batch classifier loss: 0.384075; batch adversarial loss: 0.506119\n",
      "epoch 42; iter: 0; batch classifier loss: 0.392104; batch adversarial loss: 0.566330\n",
      "epoch 43; iter: 0; batch classifier loss: 0.471698; batch adversarial loss: 0.582166\n",
      "epoch 44; iter: 0; batch classifier loss: 0.385437; batch adversarial loss: 0.535424\n",
      "epoch 45; iter: 0; batch classifier loss: 0.444923; batch adversarial loss: 0.622122\n",
      "epoch 46; iter: 0; batch classifier loss: 0.377135; batch adversarial loss: 0.493068\n",
      "epoch 47; iter: 0; batch classifier loss: 0.476016; batch adversarial loss: 0.531715\n",
      "epoch 48; iter: 0; batch classifier loss: 0.456670; batch adversarial loss: 0.583818\n",
      "epoch 49; iter: 0; batch classifier loss: 0.402624; batch adversarial loss: 0.548550\n",
      "epoch 50; iter: 0; batch classifier loss: 0.385558; batch adversarial loss: 0.519869\n",
      "epoch 51; iter: 0; batch classifier loss: 0.326600; batch adversarial loss: 0.491960\n",
      "epoch 52; iter: 0; batch classifier loss: 0.464754; batch adversarial loss: 0.552584\n",
      "epoch 53; iter: 0; batch classifier loss: 0.531157; batch adversarial loss: 0.518094\n",
      "epoch 54; iter: 0; batch classifier loss: 0.407654; batch adversarial loss: 0.462345\n",
      "epoch 55; iter: 0; batch classifier loss: 0.448112; batch adversarial loss: 0.508049\n",
      "epoch 56; iter: 0; batch classifier loss: 0.388216; batch adversarial loss: 0.534525\n",
      "epoch 57; iter: 0; batch classifier loss: 0.314492; batch adversarial loss: 0.582237\n",
      "epoch 58; iter: 0; batch classifier loss: 0.407342; batch adversarial loss: 0.582866\n",
      "epoch 59; iter: 0; batch classifier loss: 0.425303; batch adversarial loss: 0.451941\n",
      "epoch 60; iter: 0; batch classifier loss: 0.441759; batch adversarial loss: 0.507043\n",
      "epoch 61; iter: 0; batch classifier loss: 0.340764; batch adversarial loss: 0.525712\n",
      "epoch 62; iter: 0; batch classifier loss: 0.410705; batch adversarial loss: 0.534369\n",
      "epoch 63; iter: 0; batch classifier loss: 0.457178; batch adversarial loss: 0.563088\n",
      "epoch 64; iter: 0; batch classifier loss: 0.341098; batch adversarial loss: 0.553250\n",
      "epoch 65; iter: 0; batch classifier loss: 0.417937; batch adversarial loss: 0.545702\n",
      "epoch 66; iter: 0; batch classifier loss: 0.460555; batch adversarial loss: 0.554542\n",
      "epoch 67; iter: 0; batch classifier loss: 0.384402; batch adversarial loss: 0.507481\n",
      "epoch 68; iter: 0; batch classifier loss: 0.470906; batch adversarial loss: 0.507216\n",
      "epoch 69; iter: 0; batch classifier loss: 0.411330; batch adversarial loss: 0.527985\n",
      "epoch 70; iter: 0; batch classifier loss: 0.423496; batch adversarial loss: 0.553667\n",
      "epoch 71; iter: 0; batch classifier loss: 0.446467; batch adversarial loss: 0.488938\n",
      "epoch 72; iter: 0; batch classifier loss: 0.458052; batch adversarial loss: 0.508538\n",
      "epoch 73; iter: 0; batch classifier loss: 0.390667; batch adversarial loss: 0.553630\n",
      "epoch 74; iter: 0; batch classifier loss: 0.396852; batch adversarial loss: 0.542442\n",
      "epoch 75; iter: 0; batch classifier loss: 0.441845; batch adversarial loss: 0.517790\n",
      "epoch 76; iter: 0; batch classifier loss: 0.470563; batch adversarial loss: 0.597615\n",
      "epoch 77; iter: 0; batch classifier loss: 0.387708; batch adversarial loss: 0.490849\n",
      "epoch 78; iter: 0; batch classifier loss: 0.337887; batch adversarial loss: 0.560209\n",
      "epoch 79; iter: 0; batch classifier loss: 0.357882; batch adversarial loss: 0.545513\n",
      "epoch 80; iter: 0; batch classifier loss: 0.437733; batch adversarial loss: 0.543650\n",
      "epoch 81; iter: 0; batch classifier loss: 0.356936; batch adversarial loss: 0.480098\n",
      "epoch 82; iter: 0; batch classifier loss: 0.379051; batch adversarial loss: 0.524206\n",
      "epoch 83; iter: 0; batch classifier loss: 0.428205; batch adversarial loss: 0.563915\n",
      "epoch 84; iter: 0; batch classifier loss: 0.449935; batch adversarial loss: 0.483316\n",
      "epoch 85; iter: 0; batch classifier loss: 0.367926; batch adversarial loss: 0.571358\n",
      "epoch 86; iter: 0; batch classifier loss: 0.316646; batch adversarial loss: 0.472630\n",
      "epoch 87; iter: 0; batch classifier loss: 0.367330; batch adversarial loss: 0.516962\n",
      "epoch 88; iter: 0; batch classifier loss: 0.340284; batch adversarial loss: 0.616244\n",
      "epoch 89; iter: 0; batch classifier loss: 0.451417; batch adversarial loss: 0.527790\n",
      "epoch 90; iter: 0; batch classifier loss: 0.376087; batch adversarial loss: 0.552700\n",
      "epoch 91; iter: 0; batch classifier loss: 0.374622; batch adversarial loss: 0.570616\n",
      "epoch 92; iter: 0; batch classifier loss: 0.447948; batch adversarial loss: 0.597986\n",
      "epoch 93; iter: 0; batch classifier loss: 0.369543; batch adversarial loss: 0.490271\n",
      "epoch 94; iter: 0; batch classifier loss: 0.397394; batch adversarial loss: 0.561256\n",
      "epoch 95; iter: 0; batch classifier loss: 0.325254; batch adversarial loss: 0.597620\n",
      "epoch 96; iter: 0; batch classifier loss: 0.405241; batch adversarial loss: 0.509449\n",
      "epoch 97; iter: 0; batch classifier loss: 0.440176; batch adversarial loss: 0.582498\n",
      "epoch 98; iter: 0; batch classifier loss: 0.357732; batch adversarial loss: 0.542846\n",
      "epoch 99; iter: 0; batch classifier loss: 0.344930; batch adversarial loss: 0.636723\n",
      "epoch 100; iter: 0; batch classifier loss: 0.446864; batch adversarial loss: 0.543619\n",
      "epoch 101; iter: 0; batch classifier loss: 0.397525; batch adversarial loss: 0.598316\n",
      "epoch 102; iter: 0; batch classifier loss: 0.302902; batch adversarial loss: 0.561036\n",
      "epoch 103; iter: 0; batch classifier loss: 0.407459; batch adversarial loss: 0.507001\n",
      "epoch 104; iter: 0; batch classifier loss: 0.348826; batch adversarial loss: 0.506382\n",
      "epoch 105; iter: 0; batch classifier loss: 0.354958; batch adversarial loss: 0.573773\n",
      "epoch 106; iter: 0; batch classifier loss: 0.393585; batch adversarial loss: 0.580616\n",
      "epoch 107; iter: 0; batch classifier loss: 0.396743; batch adversarial loss: 0.482344\n",
      "epoch 108; iter: 0; batch classifier loss: 0.388339; batch adversarial loss: 0.609237\n",
      "epoch 109; iter: 0; batch classifier loss: 0.333269; batch adversarial loss: 0.570580\n",
      "epoch 110; iter: 0; batch classifier loss: 0.378453; batch adversarial loss: 0.545102\n",
      "epoch 111; iter: 0; batch classifier loss: 0.325430; batch adversarial loss: 0.545646\n",
      "epoch 112; iter: 0; batch classifier loss: 0.350811; batch adversarial loss: 0.551611\n",
      "epoch 113; iter: 0; batch classifier loss: 0.419467; batch adversarial loss: 0.583983\n",
      "epoch 114; iter: 0; batch classifier loss: 0.426020; batch adversarial loss: 0.517184\n",
      "epoch 115; iter: 0; batch classifier loss: 0.395366; batch adversarial loss: 0.573424\n",
      "epoch 116; iter: 0; batch classifier loss: 0.357553; batch adversarial loss: 0.545520\n",
      "epoch 117; iter: 0; batch classifier loss: 0.412925; batch adversarial loss: 0.553661\n",
      "epoch 118; iter: 0; batch classifier loss: 0.305050; batch adversarial loss: 0.562566\n",
      "epoch 119; iter: 0; batch classifier loss: 0.341878; batch adversarial loss: 0.618853\n",
      "epoch 120; iter: 0; batch classifier loss: 0.449984; batch adversarial loss: 0.551851\n",
      "epoch 121; iter: 0; batch classifier loss: 0.298668; batch adversarial loss: 0.516625\n",
      "epoch 122; iter: 0; batch classifier loss: 0.365022; batch adversarial loss: 0.563096\n",
      "epoch 123; iter: 0; batch classifier loss: 0.425382; batch adversarial loss: 0.526797\n",
      "epoch 124; iter: 0; batch classifier loss: 0.443271; batch adversarial loss: 0.589137\n",
      "epoch 125; iter: 0; batch classifier loss: 0.375604; batch adversarial loss: 0.570992\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 126; iter: 0; batch classifier loss: 0.383273; batch adversarial loss: 0.590272\n",
      "epoch 127; iter: 0; batch classifier loss: 0.352525; batch adversarial loss: 0.471711\n",
      "epoch 128; iter: 0; batch classifier loss: 0.372226; batch adversarial loss: 0.626468\n",
      "epoch 129; iter: 0; batch classifier loss: 0.401512; batch adversarial loss: 0.545524\n",
      "epoch 130; iter: 0; batch classifier loss: 0.386593; batch adversarial loss: 0.610116\n",
      "epoch 131; iter: 0; batch classifier loss: 0.345036; batch adversarial loss: 0.490777\n",
      "epoch 132; iter: 0; batch classifier loss: 0.336476; batch adversarial loss: 0.571668\n",
      "epoch 133; iter: 0; batch classifier loss: 0.340897; batch adversarial loss: 0.470549\n",
      "epoch 134; iter: 0; batch classifier loss: 0.383063; batch adversarial loss: 0.581003\n",
      "epoch 135; iter: 0; batch classifier loss: 0.314557; batch adversarial loss: 0.553360\n",
      "epoch 136; iter: 0; batch classifier loss: 0.432534; batch adversarial loss: 0.536129\n",
      "epoch 137; iter: 0; batch classifier loss: 0.328578; batch adversarial loss: 0.598739\n",
      "epoch 138; iter: 0; batch classifier loss: 0.390901; batch adversarial loss: 0.573441\n",
      "epoch 139; iter: 0; batch classifier loss: 0.334962; batch adversarial loss: 0.563608\n",
      "epoch 140; iter: 0; batch classifier loss: 0.415348; batch adversarial loss: 0.535509\n",
      "epoch 141; iter: 0; batch classifier loss: 0.383124; batch adversarial loss: 0.572536\n",
      "epoch 142; iter: 0; batch classifier loss: 0.410673; batch adversarial loss: 0.606643\n",
      "epoch 143; iter: 0; batch classifier loss: 0.391598; batch adversarial loss: 0.572089\n",
      "epoch 144; iter: 0; batch classifier loss: 0.308589; batch adversarial loss: 0.489252\n",
      "epoch 145; iter: 0; batch classifier loss: 0.346753; batch adversarial loss: 0.552531\n",
      "epoch 146; iter: 0; batch classifier loss: 0.425637; batch adversarial loss: 0.444954\n",
      "epoch 147; iter: 0; batch classifier loss: 0.338598; batch adversarial loss: 0.563118\n",
      "epoch 148; iter: 0; batch classifier loss: 0.301551; batch adversarial loss: 0.473276\n",
      "epoch 149; iter: 0; batch classifier loss: 0.267969; batch adversarial loss: 0.534020\n",
      "epoch 150; iter: 0; batch classifier loss: 0.343237; batch adversarial loss: 0.516130\n",
      "epoch 151; iter: 0; batch classifier loss: 0.454697; batch adversarial loss: 0.590451\n",
      "epoch 152; iter: 0; batch classifier loss: 0.281393; batch adversarial loss: 0.571836\n",
      "epoch 153; iter: 0; batch classifier loss: 0.369920; batch adversarial loss: 0.562705\n",
      "epoch 154; iter: 0; batch classifier loss: 0.328207; batch adversarial loss: 0.499143\n",
      "epoch 155; iter: 0; batch classifier loss: 0.318353; batch adversarial loss: 0.544080\n",
      "epoch 156; iter: 0; batch classifier loss: 0.349746; batch adversarial loss: 0.538096\n",
      "epoch 157; iter: 0; batch classifier loss: 0.409835; batch adversarial loss: 0.527611\n",
      "epoch 158; iter: 0; batch classifier loss: 0.399675; batch adversarial loss: 0.571646\n",
      "epoch 159; iter: 0; batch classifier loss: 0.390252; batch adversarial loss: 0.507877\n",
      "epoch 160; iter: 0; batch classifier loss: 0.293541; batch adversarial loss: 0.589041\n",
      "epoch 161; iter: 0; batch classifier loss: 0.320345; batch adversarial loss: 0.592121\n",
      "epoch 162; iter: 0; batch classifier loss: 0.447597; batch adversarial loss: 0.519104\n",
      "epoch 163; iter: 0; batch classifier loss: 0.343586; batch adversarial loss: 0.606972\n",
      "epoch 164; iter: 0; batch classifier loss: 0.323008; batch adversarial loss: 0.517186\n",
      "epoch 165; iter: 0; batch classifier loss: 0.349277; batch adversarial loss: 0.607753\n",
      "epoch 166; iter: 0; batch classifier loss: 0.384307; batch adversarial loss: 0.536535\n",
      "epoch 167; iter: 0; batch classifier loss: 0.274222; batch adversarial loss: 0.588763\n",
      "epoch 168; iter: 0; batch classifier loss: 0.395931; batch adversarial loss: 0.517449\n",
      "epoch 169; iter: 0; batch classifier loss: 0.370765; batch adversarial loss: 0.489647\n",
      "epoch 170; iter: 0; batch classifier loss: 0.412414; batch adversarial loss: 0.436933\n",
      "epoch 171; iter: 0; batch classifier loss: 0.380279; batch adversarial loss: 0.581383\n",
      "epoch 172; iter: 0; batch classifier loss: 0.407625; batch adversarial loss: 0.480842\n",
      "epoch 173; iter: 0; batch classifier loss: 0.373495; batch adversarial loss: 0.551240\n",
      "epoch 174; iter: 0; batch classifier loss: 0.387353; batch adversarial loss: 0.618097\n",
      "epoch 175; iter: 0; batch classifier loss: 0.325648; batch adversarial loss: 0.507392\n",
      "epoch 176; iter: 0; batch classifier loss: 0.335401; batch adversarial loss: 0.633275\n",
      "epoch 177; iter: 0; batch classifier loss: 0.296274; batch adversarial loss: 0.580825\n",
      "epoch 178; iter: 0; batch classifier loss: 0.351459; batch adversarial loss: 0.574266\n",
      "epoch 179; iter: 0; batch classifier loss: 0.406462; batch adversarial loss: 0.534219\n",
      "epoch 180; iter: 0; batch classifier loss: 0.276222; batch adversarial loss: 0.525981\n",
      "epoch 181; iter: 0; batch classifier loss: 0.357727; batch adversarial loss: 0.526290\n",
      "epoch 182; iter: 0; batch classifier loss: 0.348769; batch adversarial loss: 0.488840\n",
      "epoch 183; iter: 0; batch classifier loss: 0.343190; batch adversarial loss: 0.590662\n",
      "epoch 184; iter: 0; batch classifier loss: 0.318462; batch adversarial loss: 0.526447\n",
      "epoch 185; iter: 0; batch classifier loss: 0.421317; batch adversarial loss: 0.564364\n",
      "epoch 186; iter: 0; batch classifier loss: 0.353474; batch adversarial loss: 0.507388\n",
      "epoch 187; iter: 0; batch classifier loss: 0.382383; batch adversarial loss: 0.601684\n",
      "epoch 188; iter: 0; batch classifier loss: 0.359945; batch adversarial loss: 0.573401\n",
      "epoch 189; iter: 0; batch classifier loss: 0.347557; batch adversarial loss: 0.607363\n",
      "epoch 190; iter: 0; batch classifier loss: 0.264110; batch adversarial loss: 0.663010\n",
      "epoch 191; iter: 0; batch classifier loss: 0.355811; batch adversarial loss: 0.617737\n",
      "epoch 192; iter: 0; batch classifier loss: 0.436140; batch adversarial loss: 0.488631\n",
      "epoch 193; iter: 0; batch classifier loss: 0.340200; batch adversarial loss: 0.517434\n",
      "epoch 194; iter: 0; batch classifier loss: 0.396497; batch adversarial loss: 0.545448\n",
      "epoch 195; iter: 0; batch classifier loss: 0.235284; batch adversarial loss: 0.515066\n",
      "epoch 196; iter: 0; batch classifier loss: 0.407744; batch adversarial loss: 0.624042\n",
      "epoch 197; iter: 0; batch classifier loss: 0.301201; batch adversarial loss: 0.563624\n",
      "epoch 198; iter: 0; batch classifier loss: 0.333441; batch adversarial loss: 0.518633\n",
      "epoch 199; iter: 0; batch classifier loss: 0.401544; batch adversarial loss: 0.518138\n",
      "epoch 0; iter: 0; batch classifier loss: 0.795131; batch adversarial loss: 0.612432\n",
      "epoch 1; iter: 0; batch classifier loss: 0.559256; batch adversarial loss: 0.645578\n",
      "epoch 2; iter: 0; batch classifier loss: 0.577056; batch adversarial loss: 0.642802\n",
      "epoch 3; iter: 0; batch classifier loss: 0.535749; batch adversarial loss: 0.627292\n",
      "epoch 4; iter: 0; batch classifier loss: 0.643452; batch adversarial loss: 0.617729\n",
      "epoch 5; iter: 0; batch classifier loss: 0.626175; batch adversarial loss: 0.641497\n",
      "epoch 6; iter: 0; batch classifier loss: 0.583533; batch adversarial loss: 0.586581\n",
      "epoch 7; iter: 0; batch classifier loss: 0.594954; batch adversarial loss: 0.600191\n",
      "epoch 8; iter: 0; batch classifier loss: 0.513987; batch adversarial loss: 0.609412\n",
      "epoch 9; iter: 0; batch classifier loss: 0.626298; batch adversarial loss: 0.629930\n",
      "epoch 10; iter: 0; batch classifier loss: 0.614281; batch adversarial loss: 0.562557\n",
      "epoch 11; iter: 0; batch classifier loss: 0.501938; batch adversarial loss: 0.570659\n",
      "epoch 12; iter: 0; batch classifier loss: 0.540093; batch adversarial loss: 0.609241\n",
      "epoch 13; iter: 0; batch classifier loss: 0.591180; batch adversarial loss: 0.572501\n",
      "epoch 14; iter: 0; batch classifier loss: 0.564245; batch adversarial loss: 0.564835\n",
      "epoch 15; iter: 0; batch classifier loss: 0.533885; batch adversarial loss: 0.568217\n",
      "epoch 16; iter: 0; batch classifier loss: 0.483032; batch adversarial loss: 0.586298\n",
      "epoch 17; iter: 0; batch classifier loss: 0.493826; batch adversarial loss: 0.570326\n",
      "epoch 18; iter: 0; batch classifier loss: 0.509839; batch adversarial loss: 0.564280\n",
      "epoch 19; iter: 0; batch classifier loss: 0.451832; batch adversarial loss: 0.559070\n",
      "epoch 20; iter: 0; batch classifier loss: 0.584193; batch adversarial loss: 0.508369\n",
      "epoch 21; iter: 0; batch classifier loss: 0.516639; batch adversarial loss: 0.569857\n",
      "epoch 22; iter: 0; batch classifier loss: 0.481194; batch adversarial loss: 0.613162\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 23; iter: 0; batch classifier loss: 0.456103; batch adversarial loss: 0.578694\n",
      "epoch 24; iter: 0; batch classifier loss: 0.490393; batch adversarial loss: 0.511478\n",
      "epoch 25; iter: 0; batch classifier loss: 0.491504; batch adversarial loss: 0.521015\n",
      "epoch 26; iter: 0; batch classifier loss: 0.492578; batch adversarial loss: 0.579863\n",
      "epoch 27; iter: 0; batch classifier loss: 0.508188; batch adversarial loss: 0.640275\n",
      "epoch 28; iter: 0; batch classifier loss: 0.487300; batch adversarial loss: 0.554738\n",
      "epoch 29; iter: 0; batch classifier loss: 0.501125; batch adversarial loss: 0.569846\n",
      "epoch 30; iter: 0; batch classifier loss: 0.515749; batch adversarial loss: 0.535895\n",
      "epoch 31; iter: 0; batch classifier loss: 0.498735; batch adversarial loss: 0.547342\n",
      "epoch 32; iter: 0; batch classifier loss: 0.537072; batch adversarial loss: 0.506437\n",
      "epoch 33; iter: 0; batch classifier loss: 0.413299; batch adversarial loss: 0.656154\n",
      "epoch 34; iter: 0; batch classifier loss: 0.480609; batch adversarial loss: 0.578543\n",
      "epoch 35; iter: 0; batch classifier loss: 0.500392; batch adversarial loss: 0.492025\n",
      "epoch 36; iter: 0; batch classifier loss: 0.494856; batch adversarial loss: 0.552056\n",
      "epoch 37; iter: 0; batch classifier loss: 0.524256; batch adversarial loss: 0.551114\n",
      "epoch 38; iter: 0; batch classifier loss: 0.449852; batch adversarial loss: 0.518289\n",
      "epoch 39; iter: 0; batch classifier loss: 0.435684; batch adversarial loss: 0.588070\n",
      "epoch 40; iter: 0; batch classifier loss: 0.467103; batch adversarial loss: 0.556175\n",
      "epoch 41; iter: 0; batch classifier loss: 0.415240; batch adversarial loss: 0.585598\n",
      "epoch 42; iter: 0; batch classifier loss: 0.501818; batch adversarial loss: 0.557379\n",
      "epoch 43; iter: 0; batch classifier loss: 0.479289; batch adversarial loss: 0.565529\n",
      "epoch 44; iter: 0; batch classifier loss: 0.423725; batch adversarial loss: 0.539064\n",
      "epoch 45; iter: 0; batch classifier loss: 0.453562; batch adversarial loss: 0.563324\n",
      "epoch 46; iter: 0; batch classifier loss: 0.500282; batch adversarial loss: 0.502586\n",
      "epoch 47; iter: 0; batch classifier loss: 0.452694; batch adversarial loss: 0.484926\n",
      "epoch 48; iter: 0; batch classifier loss: 0.465664; batch adversarial loss: 0.535660\n",
      "epoch 49; iter: 0; batch classifier loss: 0.544435; batch adversarial loss: 0.598292\n",
      "epoch 50; iter: 0; batch classifier loss: 0.401570; batch adversarial loss: 0.527221\n",
      "epoch 51; iter: 0; batch classifier loss: 0.443556; batch adversarial loss: 0.545329\n",
      "epoch 52; iter: 0; batch classifier loss: 0.436201; batch adversarial loss: 0.525236\n",
      "epoch 53; iter: 0; batch classifier loss: 0.417051; batch adversarial loss: 0.500304\n",
      "epoch 54; iter: 0; batch classifier loss: 0.457130; batch adversarial loss: 0.524996\n",
      "epoch 55; iter: 0; batch classifier loss: 0.359951; batch adversarial loss: 0.579289\n",
      "epoch 56; iter: 0; batch classifier loss: 0.408311; batch adversarial loss: 0.518104\n",
      "epoch 57; iter: 0; batch classifier loss: 0.441885; batch adversarial loss: 0.517041\n",
      "epoch 58; iter: 0; batch classifier loss: 0.432462; batch adversarial loss: 0.500931\n",
      "epoch 59; iter: 0; batch classifier loss: 0.462037; batch adversarial loss: 0.536228\n",
      "epoch 60; iter: 0; batch classifier loss: 0.459915; batch adversarial loss: 0.616803\n",
      "epoch 61; iter: 0; batch classifier loss: 0.478309; batch adversarial loss: 0.463245\n",
      "epoch 62; iter: 0; batch classifier loss: 0.406282; batch adversarial loss: 0.517233\n",
      "epoch 63; iter: 0; batch classifier loss: 0.460087; batch adversarial loss: 0.578918\n",
      "epoch 64; iter: 0; batch classifier loss: 0.461344; batch adversarial loss: 0.580591\n",
      "epoch 65; iter: 0; batch classifier loss: 0.444930; batch adversarial loss: 0.536126\n",
      "epoch 66; iter: 0; batch classifier loss: 0.410548; batch adversarial loss: 0.579332\n",
      "epoch 67; iter: 0; batch classifier loss: 0.415626; batch adversarial loss: 0.553340\n",
      "epoch 68; iter: 0; batch classifier loss: 0.412530; batch adversarial loss: 0.580676\n",
      "epoch 69; iter: 0; batch classifier loss: 0.475391; batch adversarial loss: 0.562567\n",
      "epoch 70; iter: 0; batch classifier loss: 0.464799; batch adversarial loss: 0.615532\n",
      "epoch 71; iter: 0; batch classifier loss: 0.389793; batch adversarial loss: 0.606958\n",
      "epoch 72; iter: 0; batch classifier loss: 0.411307; batch adversarial loss: 0.526973\n",
      "epoch 73; iter: 0; batch classifier loss: 0.512434; batch adversarial loss: 0.500045\n",
      "epoch 74; iter: 0; batch classifier loss: 0.382211; batch adversarial loss: 0.517458\n",
      "epoch 75; iter: 0; batch classifier loss: 0.435011; batch adversarial loss: 0.607113\n",
      "epoch 76; iter: 0; batch classifier loss: 0.384773; batch adversarial loss: 0.607124\n",
      "epoch 77; iter: 0; batch classifier loss: 0.522759; batch adversarial loss: 0.617312\n",
      "epoch 78; iter: 0; batch classifier loss: 0.390172; batch adversarial loss: 0.571776\n",
      "epoch 79; iter: 0; batch classifier loss: 0.461215; batch adversarial loss: 0.570673\n",
      "epoch 80; iter: 0; batch classifier loss: 0.504272; batch adversarial loss: 0.551580\n",
      "epoch 81; iter: 0; batch classifier loss: 0.449498; batch adversarial loss: 0.563014\n",
      "epoch 82; iter: 0; batch classifier loss: 0.376317; batch adversarial loss: 0.520672\n",
      "epoch 83; iter: 0; batch classifier loss: 0.422377; batch adversarial loss: 0.512311\n",
      "epoch 84; iter: 0; batch classifier loss: 0.444052; batch adversarial loss: 0.488338\n",
      "epoch 85; iter: 0; batch classifier loss: 0.352638; batch adversarial loss: 0.571235\n",
      "epoch 86; iter: 0; batch classifier loss: 0.367181; batch adversarial loss: 0.559280\n",
      "epoch 87; iter: 0; batch classifier loss: 0.371084; batch adversarial loss: 0.498489\n",
      "epoch 88; iter: 0; batch classifier loss: 0.465701; batch adversarial loss: 0.572648\n",
      "epoch 89; iter: 0; batch classifier loss: 0.412651; batch adversarial loss: 0.514921\n",
      "epoch 90; iter: 0; batch classifier loss: 0.466813; batch adversarial loss: 0.605617\n",
      "epoch 91; iter: 0; batch classifier loss: 0.388664; batch adversarial loss: 0.572274\n",
      "epoch 92; iter: 0; batch classifier loss: 0.483418; batch adversarial loss: 0.502283\n",
      "epoch 93; iter: 0; batch classifier loss: 0.442617; batch adversarial loss: 0.580160\n",
      "epoch 94; iter: 0; batch classifier loss: 0.367155; batch adversarial loss: 0.608258\n",
      "epoch 95; iter: 0; batch classifier loss: 0.518957; batch adversarial loss: 0.526710\n",
      "epoch 96; iter: 0; batch classifier loss: 0.436079; batch adversarial loss: 0.528404\n",
      "epoch 97; iter: 0; batch classifier loss: 0.397244; batch adversarial loss: 0.571161\n",
      "epoch 98; iter: 0; batch classifier loss: 0.407781; batch adversarial loss: 0.553074\n",
      "epoch 99; iter: 0; batch classifier loss: 0.296398; batch adversarial loss: 0.632800\n",
      "epoch 100; iter: 0; batch classifier loss: 0.457171; batch adversarial loss: 0.536166\n",
      "epoch 101; iter: 0; batch classifier loss: 0.458878; batch adversarial loss: 0.661458\n",
      "epoch 102; iter: 0; batch classifier loss: 0.453415; batch adversarial loss: 0.563174\n",
      "epoch 103; iter: 0; batch classifier loss: 0.435561; batch adversarial loss: 0.553853\n",
      "epoch 104; iter: 0; batch classifier loss: 0.390830; batch adversarial loss: 0.579319\n",
      "epoch 105; iter: 0; batch classifier loss: 0.400794; batch adversarial loss: 0.587923\n",
      "epoch 106; iter: 0; batch classifier loss: 0.340463; batch adversarial loss: 0.560534\n",
      "epoch 107; iter: 0; batch classifier loss: 0.363403; batch adversarial loss: 0.562633\n",
      "epoch 108; iter: 0; batch classifier loss: 0.406887; batch adversarial loss: 0.527120\n",
      "epoch 109; iter: 0; batch classifier loss: 0.460921; batch adversarial loss: 0.518314\n",
      "epoch 110; iter: 0; batch classifier loss: 0.398810; batch adversarial loss: 0.526215\n",
      "epoch 111; iter: 0; batch classifier loss: 0.455264; batch adversarial loss: 0.545100\n",
      "epoch 112; iter: 0; batch classifier loss: 0.351156; batch adversarial loss: 0.571303\n",
      "epoch 113; iter: 0; batch classifier loss: 0.441190; batch adversarial loss: 0.553867\n",
      "epoch 114; iter: 0; batch classifier loss: 0.340676; batch adversarial loss: 0.507833\n",
      "epoch 115; iter: 0; batch classifier loss: 0.374964; batch adversarial loss: 0.535274\n",
      "epoch 116; iter: 0; batch classifier loss: 0.289727; batch adversarial loss: 0.553433\n",
      "epoch 117; iter: 0; batch classifier loss: 0.455261; batch adversarial loss: 0.562092\n",
      "epoch 118; iter: 0; batch classifier loss: 0.356772; batch adversarial loss: 0.517089\n",
      "epoch 119; iter: 0; batch classifier loss: 0.414970; batch adversarial loss: 0.516559\n",
      "epoch 120; iter: 0; batch classifier loss: 0.383768; batch adversarial loss: 0.553504\n",
      "epoch 121; iter: 0; batch classifier loss: 0.394869; batch adversarial loss: 0.553717\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 122; iter: 0; batch classifier loss: 0.312977; batch adversarial loss: 0.553397\n",
      "epoch 123; iter: 0; batch classifier loss: 0.329364; batch adversarial loss: 0.518051\n",
      "epoch 124; iter: 0; batch classifier loss: 0.457953; batch adversarial loss: 0.535186\n",
      "epoch 125; iter: 0; batch classifier loss: 0.379674; batch adversarial loss: 0.542873\n",
      "epoch 126; iter: 0; batch classifier loss: 0.439980; batch adversarial loss: 0.573072\n",
      "epoch 127; iter: 0; batch classifier loss: 0.516101; batch adversarial loss: 0.507704\n",
      "epoch 128; iter: 0; batch classifier loss: 0.321503; batch adversarial loss: 0.561974\n",
      "epoch 129; iter: 0; batch classifier loss: 0.363588; batch adversarial loss: 0.534791\n",
      "epoch 130; iter: 0; batch classifier loss: 0.360589; batch adversarial loss: 0.597877\n",
      "epoch 131; iter: 0; batch classifier loss: 0.471455; batch adversarial loss: 0.490528\n",
      "epoch 132; iter: 0; batch classifier loss: 0.402318; batch adversarial loss: 0.500469\n",
      "epoch 133; iter: 0; batch classifier loss: 0.362236; batch adversarial loss: 0.536371\n",
      "epoch 134; iter: 0; batch classifier loss: 0.392023; batch adversarial loss: 0.535771\n",
      "epoch 135; iter: 0; batch classifier loss: 0.317207; batch adversarial loss: 0.589490\n",
      "epoch 136; iter: 0; batch classifier loss: 0.381731; batch adversarial loss: 0.642701\n",
      "epoch 137; iter: 0; batch classifier loss: 0.371456; batch adversarial loss: 0.597728\n",
      "epoch 138; iter: 0; batch classifier loss: 0.391102; batch adversarial loss: 0.562650\n",
      "epoch 139; iter: 0; batch classifier loss: 0.324456; batch adversarial loss: 0.544873\n",
      "epoch 140; iter: 0; batch classifier loss: 0.397429; batch adversarial loss: 0.598525\n",
      "epoch 141; iter: 0; batch classifier loss: 0.419796; batch adversarial loss: 0.562345\n",
      "epoch 142; iter: 0; batch classifier loss: 0.386362; batch adversarial loss: 0.598030\n",
      "epoch 143; iter: 0; batch classifier loss: 0.429423; batch adversarial loss: 0.473416\n",
      "epoch 144; iter: 0; batch classifier loss: 0.394484; batch adversarial loss: 0.544407\n",
      "epoch 145; iter: 0; batch classifier loss: 0.408621; batch adversarial loss: 0.535437\n",
      "epoch 146; iter: 0; batch classifier loss: 0.376819; batch adversarial loss: 0.490977\n",
      "epoch 147; iter: 0; batch classifier loss: 0.410666; batch adversarial loss: 0.553662\n",
      "epoch 148; iter: 0; batch classifier loss: 0.381020; batch adversarial loss: 0.544402\n",
      "epoch 149; iter: 0; batch classifier loss: 0.340918; batch adversarial loss: 0.544778\n",
      "epoch 150; iter: 0; batch classifier loss: 0.369005; batch adversarial loss: 0.544407\n",
      "epoch 151; iter: 0; batch classifier loss: 0.549986; batch adversarial loss: 0.634141\n",
      "epoch 152; iter: 0; batch classifier loss: 0.363526; batch adversarial loss: 0.580354\n",
      "epoch 153; iter: 0; batch classifier loss: 0.355107; batch adversarial loss: 0.589996\n",
      "epoch 154; iter: 0; batch classifier loss: 0.418784; batch adversarial loss: 0.526427\n",
      "epoch 155; iter: 0; batch classifier loss: 0.376406; batch adversarial loss: 0.536313\n",
      "epoch 156; iter: 0; batch classifier loss: 0.419853; batch adversarial loss: 0.535453\n",
      "epoch 157; iter: 0; batch classifier loss: 0.359960; batch adversarial loss: 0.572167\n",
      "epoch 158; iter: 0; batch classifier loss: 0.392567; batch adversarial loss: 0.526067\n",
      "epoch 159; iter: 0; batch classifier loss: 0.325181; batch adversarial loss: 0.552381\n",
      "epoch 160; iter: 0; batch classifier loss: 0.368590; batch adversarial loss: 0.555122\n",
      "epoch 161; iter: 0; batch classifier loss: 0.444283; batch adversarial loss: 0.579041\n",
      "epoch 162; iter: 0; batch classifier loss: 0.491886; batch adversarial loss: 0.570600\n",
      "epoch 163; iter: 0; batch classifier loss: 0.339779; batch adversarial loss: 0.564844\n",
      "epoch 164; iter: 0; batch classifier loss: 0.416677; batch adversarial loss: 0.552486\n",
      "epoch 165; iter: 0; batch classifier loss: 0.292335; batch adversarial loss: 0.663032\n",
      "epoch 166; iter: 0; batch classifier loss: 0.440117; batch adversarial loss: 0.581487\n",
      "epoch 167; iter: 0; batch classifier loss: 0.433386; batch adversarial loss: 0.464006\n",
      "epoch 168; iter: 0; batch classifier loss: 0.393278; batch adversarial loss: 0.517642\n",
      "epoch 169; iter: 0; batch classifier loss: 0.366956; batch adversarial loss: 0.552850\n",
      "epoch 170; iter: 0; batch classifier loss: 0.410311; batch adversarial loss: 0.543251\n",
      "epoch 171; iter: 0; batch classifier loss: 0.348193; batch adversarial loss: 0.499001\n",
      "epoch 172; iter: 0; batch classifier loss: 0.393051; batch adversarial loss: 0.582024\n",
      "epoch 173; iter: 0; batch classifier loss: 0.414154; batch adversarial loss: 0.528105\n",
      "epoch 174; iter: 0; batch classifier loss: 0.400131; batch adversarial loss: 0.525980\n",
      "epoch 175; iter: 0; batch classifier loss: 0.415954; batch adversarial loss: 0.634311\n",
      "epoch 176; iter: 0; batch classifier loss: 0.343231; batch adversarial loss: 0.661520\n",
      "epoch 177; iter: 0; batch classifier loss: 0.444083; batch adversarial loss: 0.508957\n",
      "epoch 178; iter: 0; batch classifier loss: 0.409718; batch adversarial loss: 0.517613\n",
      "epoch 179; iter: 0; batch classifier loss: 0.394407; batch adversarial loss: 0.543607\n",
      "epoch 180; iter: 0; batch classifier loss: 0.313159; batch adversarial loss: 0.553066\n",
      "epoch 181; iter: 0; batch classifier loss: 0.451089; batch adversarial loss: 0.516994\n",
      "epoch 182; iter: 0; batch classifier loss: 0.350616; batch adversarial loss: 0.544768\n",
      "epoch 183; iter: 0; batch classifier loss: 0.307288; batch adversarial loss: 0.562632\n",
      "epoch 184; iter: 0; batch classifier loss: 0.367352; batch adversarial loss: 0.553792\n",
      "epoch 185; iter: 0; batch classifier loss: 0.275531; batch adversarial loss: 0.583413\n",
      "epoch 186; iter: 0; batch classifier loss: 0.443612; batch adversarial loss: 0.544958\n",
      "epoch 187; iter: 0; batch classifier loss: 0.323872; batch adversarial loss: 0.526264\n",
      "epoch 188; iter: 0; batch classifier loss: 0.438515; batch adversarial loss: 0.600191\n",
      "epoch 189; iter: 0; batch classifier loss: 0.363517; batch adversarial loss: 0.564954\n",
      "epoch 190; iter: 0; batch classifier loss: 0.410724; batch adversarial loss: 0.642410\n",
      "epoch 191; iter: 0; batch classifier loss: 0.425274; batch adversarial loss: 0.582151\n",
      "epoch 192; iter: 0; batch classifier loss: 0.464326; batch adversarial loss: 0.553607\n",
      "epoch 193; iter: 0; batch classifier loss: 0.313984; batch adversarial loss: 0.518310\n",
      "epoch 194; iter: 0; batch classifier loss: 0.339478; batch adversarial loss: 0.527084\n",
      "epoch 195; iter: 0; batch classifier loss: 0.450911; batch adversarial loss: 0.579995\n",
      "epoch 196; iter: 0; batch classifier loss: 0.352166; batch adversarial loss: 0.499746\n",
      "epoch 197; iter: 0; batch classifier loss: 0.341844; batch adversarial loss: 0.446584\n",
      "epoch 198; iter: 0; batch classifier loss: 0.375691; batch adversarial loss: 0.588698\n",
      "epoch 199; iter: 0; batch classifier loss: 0.428125; batch adversarial loss: 0.571583\n",
      "epoch 0; iter: 0; batch classifier loss: 0.779169; batch adversarial loss: 0.642245\n",
      "epoch 1; iter: 0; batch classifier loss: 0.619280; batch adversarial loss: 0.649604\n",
      "epoch 2; iter: 0; batch classifier loss: 0.611429; batch adversarial loss: 0.627565\n",
      "epoch 3; iter: 0; batch classifier loss: 0.626355; batch adversarial loss: 0.581109\n",
      "epoch 4; iter: 0; batch classifier loss: 0.567219; batch adversarial loss: 0.598900\n",
      "epoch 5; iter: 0; batch classifier loss: 0.556542; batch adversarial loss: 0.616054\n",
      "epoch 6; iter: 0; batch classifier loss: 0.536195; batch adversarial loss: 0.576847\n",
      "epoch 7; iter: 0; batch classifier loss: 0.592246; batch adversarial loss: 0.663468\n",
      "epoch 8; iter: 0; batch classifier loss: 0.628596; batch adversarial loss: 0.625091\n",
      "epoch 9; iter: 0; batch classifier loss: 0.554350; batch adversarial loss: 0.663747\n",
      "epoch 10; iter: 0; batch classifier loss: 0.522500; batch adversarial loss: 0.594730\n",
      "epoch 11; iter: 0; batch classifier loss: 0.635551; batch adversarial loss: 0.591435\n",
      "epoch 12; iter: 0; batch classifier loss: 0.574759; batch adversarial loss: 0.604200\n",
      "epoch 13; iter: 0; batch classifier loss: 0.500115; batch adversarial loss: 0.633199\n",
      "epoch 14; iter: 0; batch classifier loss: 0.565864; batch adversarial loss: 0.607899\n",
      "epoch 15; iter: 0; batch classifier loss: 0.562932; batch adversarial loss: 0.554949\n",
      "epoch 16; iter: 0; batch classifier loss: 0.563832; batch adversarial loss: 0.535901\n",
      "epoch 17; iter: 0; batch classifier loss: 0.525294; batch adversarial loss: 0.636988\n",
      "epoch 18; iter: 0; batch classifier loss: 0.460160; batch adversarial loss: 0.558896\n",
      "epoch 19; iter: 0; batch classifier loss: 0.476153; batch adversarial loss: 0.607808\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20; iter: 0; batch classifier loss: 0.491556; batch adversarial loss: 0.621034\n",
      "epoch 21; iter: 0; batch classifier loss: 0.556998; batch adversarial loss: 0.584648\n",
      "epoch 22; iter: 0; batch classifier loss: 0.506569; batch adversarial loss: 0.546102\n",
      "epoch 23; iter: 0; batch classifier loss: 0.522804; batch adversarial loss: 0.589164\n",
      "epoch 24; iter: 0; batch classifier loss: 0.451131; batch adversarial loss: 0.506860\n",
      "epoch 25; iter: 0; batch classifier loss: 0.523326; batch adversarial loss: 0.563252\n",
      "epoch 26; iter: 0; batch classifier loss: 0.482422; batch adversarial loss: 0.504576\n",
      "epoch 27; iter: 0; batch classifier loss: 0.585300; batch adversarial loss: 0.489736\n",
      "epoch 28; iter: 0; batch classifier loss: 0.457690; batch adversarial loss: 0.564274\n",
      "epoch 29; iter: 0; batch classifier loss: 0.453239; batch adversarial loss: 0.553442\n",
      "epoch 30; iter: 0; batch classifier loss: 0.482310; batch adversarial loss: 0.575200\n",
      "epoch 31; iter: 0; batch classifier loss: 0.402680; batch adversarial loss: 0.597911\n",
      "epoch 32; iter: 0; batch classifier loss: 0.472703; batch adversarial loss: 0.484469\n",
      "epoch 33; iter: 0; batch classifier loss: 0.452998; batch adversarial loss: 0.570795\n",
      "epoch 34; iter: 0; batch classifier loss: 0.437191; batch adversarial loss: 0.554382\n",
      "epoch 35; iter: 0; batch classifier loss: 0.445733; batch adversarial loss: 0.555682\n",
      "epoch 36; iter: 0; batch classifier loss: 0.521039; batch adversarial loss: 0.572449\n",
      "epoch 37; iter: 0; batch classifier loss: 0.394680; batch adversarial loss: 0.526564\n",
      "epoch 38; iter: 0; batch classifier loss: 0.516841; batch adversarial loss: 0.622073\n",
      "epoch 39; iter: 0; batch classifier loss: 0.504153; batch adversarial loss: 0.481139\n",
      "epoch 40; iter: 0; batch classifier loss: 0.399243; batch adversarial loss: 0.592018\n",
      "epoch 41; iter: 0; batch classifier loss: 0.417351; batch adversarial loss: 0.552070\n",
      "epoch 42; iter: 0; batch classifier loss: 0.431064; batch adversarial loss: 0.555541\n",
      "epoch 43; iter: 0; batch classifier loss: 0.409414; batch adversarial loss: 0.517932\n",
      "epoch 44; iter: 0; batch classifier loss: 0.412893; batch adversarial loss: 0.498910\n",
      "epoch 45; iter: 0; batch classifier loss: 0.463531; batch adversarial loss: 0.562929\n",
      "epoch 46; iter: 0; batch classifier loss: 0.440017; batch adversarial loss: 0.535343\n",
      "epoch 47; iter: 0; batch classifier loss: 0.401658; batch adversarial loss: 0.508678\n",
      "epoch 48; iter: 0; batch classifier loss: 0.482078; batch adversarial loss: 0.564510\n",
      "epoch 49; iter: 0; batch classifier loss: 0.497415; batch adversarial loss: 0.480526\n",
      "epoch 50; iter: 0; batch classifier loss: 0.451454; batch adversarial loss: 0.609349\n",
      "epoch 51; iter: 0; batch classifier loss: 0.398221; batch adversarial loss: 0.544162\n",
      "epoch 52; iter: 0; batch classifier loss: 0.434311; batch adversarial loss: 0.498401\n",
      "epoch 53; iter: 0; batch classifier loss: 0.396379; batch adversarial loss: 0.590604\n",
      "epoch 54; iter: 0; batch classifier loss: 0.370304; batch adversarial loss: 0.562812\n",
      "epoch 55; iter: 0; batch classifier loss: 0.407504; batch adversarial loss: 0.498494\n",
      "epoch 56; iter: 0; batch classifier loss: 0.462309; batch adversarial loss: 0.525889\n",
      "epoch 57; iter: 0; batch classifier loss: 0.458506; batch adversarial loss: 0.600513\n",
      "epoch 58; iter: 0; batch classifier loss: 0.430777; batch adversarial loss: 0.563825\n",
      "epoch 59; iter: 0; batch classifier loss: 0.393734; batch adversarial loss: 0.394637\n",
      "epoch 60; iter: 0; batch classifier loss: 0.424030; batch adversarial loss: 0.562847\n",
      "epoch 61; iter: 0; batch classifier loss: 0.422387; batch adversarial loss: 0.562610\n",
      "epoch 62; iter: 0; batch classifier loss: 0.375377; batch adversarial loss: 0.553941\n",
      "epoch 63; iter: 0; batch classifier loss: 0.465611; batch adversarial loss: 0.591645\n",
      "epoch 64; iter: 0; batch classifier loss: 0.390799; batch adversarial loss: 0.515784\n",
      "epoch 65; iter: 0; batch classifier loss: 0.419266; batch adversarial loss: 0.572852\n",
      "epoch 66; iter: 0; batch classifier loss: 0.456584; batch adversarial loss: 0.563726\n",
      "epoch 67; iter: 0; batch classifier loss: 0.385274; batch adversarial loss: 0.469644\n",
      "epoch 68; iter: 0; batch classifier loss: 0.391248; batch adversarial loss: 0.516387\n",
      "epoch 69; iter: 0; batch classifier loss: 0.458781; batch adversarial loss: 0.469907\n",
      "epoch 70; iter: 0; batch classifier loss: 0.384819; batch adversarial loss: 0.581799\n",
      "epoch 71; iter: 0; batch classifier loss: 0.451393; batch adversarial loss: 0.562115\n",
      "epoch 72; iter: 0; batch classifier loss: 0.405581; batch adversarial loss: 0.535521\n",
      "epoch 73; iter: 0; batch classifier loss: 0.403883; batch adversarial loss: 0.507227\n",
      "epoch 74; iter: 0; batch classifier loss: 0.395864; batch adversarial loss: 0.526072\n",
      "epoch 75; iter: 0; batch classifier loss: 0.400293; batch adversarial loss: 0.636948\n",
      "epoch 76; iter: 0; batch classifier loss: 0.503096; batch adversarial loss: 0.590303\n",
      "epoch 77; iter: 0; batch classifier loss: 0.387026; batch adversarial loss: 0.553017\n",
      "epoch 78; iter: 0; batch classifier loss: 0.384387; batch adversarial loss: 0.526208\n",
      "epoch 79; iter: 0; batch classifier loss: 0.425388; batch adversarial loss: 0.526422\n",
      "epoch 80; iter: 0; batch classifier loss: 0.444804; batch adversarial loss: 0.582229\n",
      "epoch 81; iter: 0; batch classifier loss: 0.463615; batch adversarial loss: 0.593749\n",
      "epoch 82; iter: 0; batch classifier loss: 0.348507; batch adversarial loss: 0.497295\n",
      "epoch 83; iter: 0; batch classifier loss: 0.428627; batch adversarial loss: 0.544544\n",
      "epoch 84; iter: 0; batch classifier loss: 0.408784; batch adversarial loss: 0.554158\n",
      "epoch 85; iter: 0; batch classifier loss: 0.417841; batch adversarial loss: 0.591547\n",
      "epoch 86; iter: 0; batch classifier loss: 0.425222; batch adversarial loss: 0.507054\n",
      "epoch 87; iter: 0; batch classifier loss: 0.383135; batch adversarial loss: 0.516950\n",
      "epoch 88; iter: 0; batch classifier loss: 0.336612; batch adversarial loss: 0.478181\n",
      "epoch 89; iter: 0; batch classifier loss: 0.297941; batch adversarial loss: 0.583319\n",
      "epoch 90; iter: 0; batch classifier loss: 0.391371; batch adversarial loss: 0.516682\n",
      "epoch 91; iter: 0; batch classifier loss: 0.467306; batch adversarial loss: 0.555251\n",
      "epoch 92; iter: 0; batch classifier loss: 0.396922; batch adversarial loss: 0.517246\n",
      "epoch 93; iter: 0; batch classifier loss: 0.329159; batch adversarial loss: 0.499810\n",
      "epoch 94; iter: 0; batch classifier loss: 0.380941; batch adversarial loss: 0.574153\n",
      "epoch 95; iter: 0; batch classifier loss: 0.437873; batch adversarial loss: 0.516670\n",
      "epoch 96; iter: 0; batch classifier loss: 0.456421; batch adversarial loss: 0.413720\n",
      "epoch 97; iter: 0; batch classifier loss: 0.428471; batch adversarial loss: 0.545454\n",
      "epoch 98; iter: 0; batch classifier loss: 0.362498; batch adversarial loss: 0.515847\n",
      "epoch 99; iter: 0; batch classifier loss: 0.353360; batch adversarial loss: 0.629365\n",
      "epoch 100; iter: 0; batch classifier loss: 0.402749; batch adversarial loss: 0.620110\n",
      "epoch 101; iter: 0; batch classifier loss: 0.386558; batch adversarial loss: 0.593570\n",
      "epoch 102; iter: 0; batch classifier loss: 0.373405; batch adversarial loss: 0.563121\n",
      "epoch 103; iter: 0; batch classifier loss: 0.404194; batch adversarial loss: 0.562990\n",
      "epoch 104; iter: 0; batch classifier loss: 0.402304; batch adversarial loss: 0.581584\n",
      "epoch 105; iter: 0; batch classifier loss: 0.414498; batch adversarial loss: 0.526690\n",
      "epoch 106; iter: 0; batch classifier loss: 0.359185; batch adversarial loss: 0.477570\n",
      "epoch 107; iter: 0; batch classifier loss: 0.472428; batch adversarial loss: 0.590763\n",
      "epoch 108; iter: 0; batch classifier loss: 0.388934; batch adversarial loss: 0.564154\n",
      "epoch 109; iter: 0; batch classifier loss: 0.367255; batch adversarial loss: 0.497345\n",
      "epoch 110; iter: 0; batch classifier loss: 0.382334; batch adversarial loss: 0.515880\n",
      "epoch 111; iter: 0; batch classifier loss: 0.330892; batch adversarial loss: 0.571135\n",
      "epoch 112; iter: 0; batch classifier loss: 0.387538; batch adversarial loss: 0.525896\n",
      "epoch 113; iter: 0; batch classifier loss: 0.469174; batch adversarial loss: 0.507147\n",
      "epoch 114; iter: 0; batch classifier loss: 0.376263; batch adversarial loss: 0.545751\n",
      "epoch 115; iter: 0; batch classifier loss: 0.426672; batch adversarial loss: 0.544798\n",
      "epoch 116; iter: 0; batch classifier loss: 0.389789; batch adversarial loss: 0.498527\n",
      "epoch 117; iter: 0; batch classifier loss: 0.412065; batch adversarial loss: 0.516872\n",
      "epoch 118; iter: 0; batch classifier loss: 0.434134; batch adversarial loss: 0.561035\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 119; iter: 0; batch classifier loss: 0.431883; batch adversarial loss: 0.534723\n",
      "epoch 120; iter: 0; batch classifier loss: 0.366738; batch adversarial loss: 0.534788\n",
      "epoch 121; iter: 0; batch classifier loss: 0.346905; batch adversarial loss: 0.581923\n",
      "epoch 122; iter: 0; batch classifier loss: 0.413544; batch adversarial loss: 0.528244\n",
      "epoch 123; iter: 0; batch classifier loss: 0.448390; batch adversarial loss: 0.592436\n",
      "epoch 124; iter: 0; batch classifier loss: 0.403172; batch adversarial loss: 0.534932\n",
      "epoch 125; iter: 0; batch classifier loss: 0.437767; batch adversarial loss: 0.497046\n",
      "epoch 126; iter: 0; batch classifier loss: 0.393025; batch adversarial loss: 0.534292\n",
      "epoch 127; iter: 0; batch classifier loss: 0.462363; batch adversarial loss: 0.533528\n",
      "epoch 128; iter: 0; batch classifier loss: 0.455483; batch adversarial loss: 0.563653\n",
      "epoch 129; iter: 0; batch classifier loss: 0.372203; batch adversarial loss: 0.534977\n",
      "epoch 130; iter: 0; batch classifier loss: 0.445303; batch adversarial loss: 0.486896\n",
      "epoch 131; iter: 0; batch classifier loss: 0.374911; batch adversarial loss: 0.593010\n",
      "epoch 132; iter: 0; batch classifier loss: 0.363554; batch adversarial loss: 0.564876\n",
      "epoch 133; iter: 0; batch classifier loss: 0.327556; batch adversarial loss: 0.496890\n",
      "epoch 134; iter: 0; batch classifier loss: 0.413741; batch adversarial loss: 0.430163\n",
      "epoch 135; iter: 0; batch classifier loss: 0.336805; batch adversarial loss: 0.554857\n",
      "epoch 136; iter: 0; batch classifier loss: 0.366055; batch adversarial loss: 0.572037\n",
      "epoch 137; iter: 0; batch classifier loss: 0.431946; batch adversarial loss: 0.486468\n",
      "epoch 138; iter: 0; batch classifier loss: 0.339651; batch adversarial loss: 0.544327\n",
      "epoch 139; iter: 0; batch classifier loss: 0.453888; batch adversarial loss: 0.516298\n",
      "epoch 140; iter: 0; batch classifier loss: 0.395207; batch adversarial loss: 0.497396\n",
      "epoch 141; iter: 0; batch classifier loss: 0.390126; batch adversarial loss: 0.488122\n",
      "epoch 142; iter: 0; batch classifier loss: 0.358193; batch adversarial loss: 0.535141\n",
      "epoch 143; iter: 0; batch classifier loss: 0.448648; batch adversarial loss: 0.612529\n",
      "epoch 144; iter: 0; batch classifier loss: 0.443368; batch adversarial loss: 0.448786\n",
      "epoch 145; iter: 0; batch classifier loss: 0.403156; batch adversarial loss: 0.572450\n",
      "epoch 146; iter: 0; batch classifier loss: 0.400813; batch adversarial loss: 0.487428\n",
      "epoch 147; iter: 0; batch classifier loss: 0.336255; batch adversarial loss: 0.640998\n",
      "epoch 148; iter: 0; batch classifier loss: 0.376702; batch adversarial loss: 0.581491\n",
      "epoch 149; iter: 0; batch classifier loss: 0.498789; batch adversarial loss: 0.505918\n",
      "epoch 150; iter: 0; batch classifier loss: 0.341258; batch adversarial loss: 0.517730\n",
      "epoch 151; iter: 0; batch classifier loss: 0.462217; batch adversarial loss: 0.525290\n",
      "epoch 152; iter: 0; batch classifier loss: 0.471606; batch adversarial loss: 0.468778\n",
      "epoch 153; iter: 0; batch classifier loss: 0.372453; batch adversarial loss: 0.523305\n",
      "epoch 154; iter: 0; batch classifier loss: 0.439409; batch adversarial loss: 0.542976\n",
      "epoch 155; iter: 0; batch classifier loss: 0.334762; batch adversarial loss: 0.525022\n",
      "epoch 156; iter: 0; batch classifier loss: 0.379799; batch adversarial loss: 0.485254\n",
      "epoch 157; iter: 0; batch classifier loss: 0.463578; batch adversarial loss: 0.506644\n",
      "epoch 158; iter: 0; batch classifier loss: 0.336181; batch adversarial loss: 0.553582\n",
      "epoch 159; iter: 0; batch classifier loss: 0.360301; batch adversarial loss: 0.543594\n",
      "epoch 160; iter: 0; batch classifier loss: 0.376373; batch adversarial loss: 0.543645\n",
      "epoch 161; iter: 0; batch classifier loss: 0.361315; batch adversarial loss: 0.440547\n",
      "epoch 162; iter: 0; batch classifier loss: 0.367429; batch adversarial loss: 0.489270\n",
      "epoch 163; iter: 0; batch classifier loss: 0.448799; batch adversarial loss: 0.582154\n",
      "epoch 164; iter: 0; batch classifier loss: 0.491510; batch adversarial loss: 0.469841\n",
      "epoch 165; iter: 0; batch classifier loss: 0.359832; batch adversarial loss: 0.553970\n",
      "epoch 166; iter: 0; batch classifier loss: 0.360062; batch adversarial loss: 0.496104\n",
      "epoch 167; iter: 0; batch classifier loss: 0.358367; batch adversarial loss: 0.544262\n",
      "epoch 168; iter: 0; batch classifier loss: 0.395789; batch adversarial loss: 0.553839\n",
      "epoch 169; iter: 0; batch classifier loss: 0.392711; batch adversarial loss: 0.506256\n",
      "epoch 170; iter: 0; batch classifier loss: 0.370389; batch adversarial loss: 0.545843\n",
      "epoch 171; iter: 0; batch classifier loss: 0.341431; batch adversarial loss: 0.543820\n",
      "epoch 172; iter: 0; batch classifier loss: 0.357625; batch adversarial loss: 0.545619\n",
      "epoch 173; iter: 0; batch classifier loss: 0.364299; batch adversarial loss: 0.677122\n",
      "epoch 174; iter: 0; batch classifier loss: 0.369884; batch adversarial loss: 0.450809\n",
      "epoch 175; iter: 0; batch classifier loss: 0.340200; batch adversarial loss: 0.564207\n",
      "epoch 176; iter: 0; batch classifier loss: 0.298618; batch adversarial loss: 0.591617\n",
      "epoch 177; iter: 0; batch classifier loss: 0.371581; batch adversarial loss: 0.506795\n",
      "epoch 178; iter: 0; batch classifier loss: 0.287152; batch adversarial loss: 0.488942\n",
      "epoch 179; iter: 0; batch classifier loss: 0.398418; batch adversarial loss: 0.562278\n",
      "epoch 180; iter: 0; batch classifier loss: 0.357390; batch adversarial loss: 0.545419\n",
      "epoch 181; iter: 0; batch classifier loss: 0.371902; batch adversarial loss: 0.524121\n",
      "epoch 182; iter: 0; batch classifier loss: 0.375708; batch adversarial loss: 0.563598\n",
      "epoch 183; iter: 0; batch classifier loss: 0.349556; batch adversarial loss: 0.582714\n",
      "epoch 184; iter: 0; batch classifier loss: 0.281677; batch adversarial loss: 0.516071\n",
      "epoch 185; iter: 0; batch classifier loss: 0.354755; batch adversarial loss: 0.534706\n",
      "epoch 186; iter: 0; batch classifier loss: 0.348832; batch adversarial loss: 0.525925\n",
      "epoch 187; iter: 0; batch classifier loss: 0.323459; batch adversarial loss: 0.527545\n",
      "epoch 188; iter: 0; batch classifier loss: 0.379441; batch adversarial loss: 0.551867\n",
      "epoch 189; iter: 0; batch classifier loss: 0.321711; batch adversarial loss: 0.617351\n",
      "epoch 190; iter: 0; batch classifier loss: 0.349670; batch adversarial loss: 0.458510\n",
      "epoch 191; iter: 0; batch classifier loss: 0.398527; batch adversarial loss: 0.655870\n",
      "epoch 192; iter: 0; batch classifier loss: 0.322336; batch adversarial loss: 0.515813\n",
      "epoch 193; iter: 0; batch classifier loss: 0.342200; batch adversarial loss: 0.553616\n",
      "epoch 194; iter: 0; batch classifier loss: 0.348655; batch adversarial loss: 0.555142\n",
      "epoch 195; iter: 0; batch classifier loss: 0.253458; batch adversarial loss: 0.649496\n",
      "epoch 196; iter: 0; batch classifier loss: 0.320464; batch adversarial loss: 0.618368\n",
      "epoch 197; iter: 0; batch classifier loss: 0.375606; batch adversarial loss: 0.570409\n",
      "epoch 198; iter: 0; batch classifier loss: 0.409653; batch adversarial loss: 0.589270\n",
      "epoch 199; iter: 0; batch classifier loss: 0.305953; batch adversarial loss: 0.535703\n",
      "epoch 0; iter: 0; batch classifier loss: 0.763961; batch adversarial loss: 0.659256\n",
      "epoch 1; iter: 0; batch classifier loss: 0.613363; batch adversarial loss: 0.651309\n",
      "epoch 2; iter: 0; batch classifier loss: 0.608152; batch adversarial loss: 0.627029\n",
      "epoch 3; iter: 0; batch classifier loss: 0.550238; batch adversarial loss: 0.615503\n",
      "epoch 4; iter: 0; batch classifier loss: 0.531837; batch adversarial loss: 0.597281\n",
      "epoch 5; iter: 0; batch classifier loss: 0.546010; batch adversarial loss: 0.567934\n",
      "epoch 6; iter: 0; batch classifier loss: 0.538615; batch adversarial loss: 0.614560\n",
      "epoch 7; iter: 0; batch classifier loss: 0.563715; batch adversarial loss: 0.590724\n",
      "epoch 8; iter: 0; batch classifier loss: 0.535562; batch adversarial loss: 0.637486\n",
      "epoch 9; iter: 0; batch classifier loss: 0.543156; batch adversarial loss: 0.578775\n",
      "epoch 10; iter: 0; batch classifier loss: 0.578594; batch adversarial loss: 0.609807\n",
      "epoch 11; iter: 0; batch classifier loss: 0.503840; batch adversarial loss: 0.540615\n",
      "epoch 12; iter: 0; batch classifier loss: 0.499505; batch adversarial loss: 0.543599\n",
      "epoch 13; iter: 0; batch classifier loss: 0.561580; batch adversarial loss: 0.586545\n",
      "epoch 14; iter: 0; batch classifier loss: 0.553494; batch adversarial loss: 0.589882\n",
      "epoch 15; iter: 0; batch classifier loss: 0.549197; batch adversarial loss: 0.553975\n",
      "epoch 16; iter: 0; batch classifier loss: 0.447247; batch adversarial loss: 0.538439\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 17; iter: 0; batch classifier loss: 0.502179; batch adversarial loss: 0.566926\n",
      "epoch 18; iter: 0; batch classifier loss: 0.511823; batch adversarial loss: 0.555331\n",
      "epoch 19; iter: 0; batch classifier loss: 0.554921; batch adversarial loss: 0.566775\n",
      "epoch 20; iter: 0; batch classifier loss: 0.581161; batch adversarial loss: 0.578947\n",
      "epoch 21; iter: 0; batch classifier loss: 0.476923; batch adversarial loss: 0.612827\n",
      "epoch 22; iter: 0; batch classifier loss: 0.449031; batch adversarial loss: 0.510904\n",
      "epoch 23; iter: 0; batch classifier loss: 0.439978; batch adversarial loss: 0.583583\n",
      "epoch 24; iter: 0; batch classifier loss: 0.487603; batch adversarial loss: 0.497213\n",
      "epoch 25; iter: 0; batch classifier loss: 0.492186; batch adversarial loss: 0.618394\n",
      "epoch 26; iter: 0; batch classifier loss: 0.511742; batch adversarial loss: 0.556054\n",
      "epoch 27; iter: 0; batch classifier loss: 0.443229; batch adversarial loss: 0.571183\n",
      "epoch 28; iter: 0; batch classifier loss: 0.418524; batch adversarial loss: 0.538297\n",
      "epoch 29; iter: 0; batch classifier loss: 0.409530; batch adversarial loss: 0.562083\n",
      "epoch 30; iter: 0; batch classifier loss: 0.504609; batch adversarial loss: 0.428377\n",
      "epoch 31; iter: 0; batch classifier loss: 0.498470; batch adversarial loss: 0.612905\n",
      "epoch 32; iter: 0; batch classifier loss: 0.401497; batch adversarial loss: 0.528433\n",
      "epoch 33; iter: 0; batch classifier loss: 0.524895; batch adversarial loss: 0.588871\n",
      "epoch 34; iter: 0; batch classifier loss: 0.461832; batch adversarial loss: 0.554078\n",
      "epoch 35; iter: 0; batch classifier loss: 0.461877; batch adversarial loss: 0.500593\n",
      "epoch 36; iter: 0; batch classifier loss: 0.463030; batch adversarial loss: 0.562012\n",
      "epoch 37; iter: 0; batch classifier loss: 0.456113; batch adversarial loss: 0.579930\n",
      "epoch 38; iter: 0; batch classifier loss: 0.446716; batch adversarial loss: 0.509764\n",
      "epoch 39; iter: 0; batch classifier loss: 0.511687; batch adversarial loss: 0.606883\n",
      "epoch 40; iter: 0; batch classifier loss: 0.417292; batch adversarial loss: 0.500618\n",
      "epoch 41; iter: 0; batch classifier loss: 0.383827; batch adversarial loss: 0.606623\n",
      "epoch 42; iter: 0; batch classifier loss: 0.447832; batch adversarial loss: 0.597507\n",
      "epoch 43; iter: 0; batch classifier loss: 0.403192; batch adversarial loss: 0.500981\n",
      "epoch 44; iter: 0; batch classifier loss: 0.429476; batch adversarial loss: 0.482756\n",
      "epoch 45; iter: 0; batch classifier loss: 0.397797; batch adversarial loss: 0.552762\n",
      "epoch 46; iter: 0; batch classifier loss: 0.471417; batch adversarial loss: 0.552976\n",
      "epoch 47; iter: 0; batch classifier loss: 0.438727; batch adversarial loss: 0.500135\n",
      "epoch 48; iter: 0; batch classifier loss: 0.502319; batch adversarial loss: 0.598293\n",
      "epoch 49; iter: 0; batch classifier loss: 0.476398; batch adversarial loss: 0.473094\n",
      "epoch 50; iter: 0; batch classifier loss: 0.406085; batch adversarial loss: 0.562660\n",
      "epoch 51; iter: 0; batch classifier loss: 0.392471; batch adversarial loss: 0.500514\n",
      "epoch 52; iter: 0; batch classifier loss: 0.505187; batch adversarial loss: 0.553550\n",
      "epoch 53; iter: 0; batch classifier loss: 0.415772; batch adversarial loss: 0.464807\n",
      "epoch 54; iter: 0; batch classifier loss: 0.455153; batch adversarial loss: 0.562342\n",
      "epoch 55; iter: 0; batch classifier loss: 0.439066; batch adversarial loss: 0.544529\n",
      "epoch 56; iter: 0; batch classifier loss: 0.467597; batch adversarial loss: 0.607006\n",
      "epoch 57; iter: 0; batch classifier loss: 0.466486; batch adversarial loss: 0.571485\n",
      "epoch 58; iter: 0; batch classifier loss: 0.429505; batch adversarial loss: 0.518467\n",
      "epoch 59; iter: 0; batch classifier loss: 0.451307; batch adversarial loss: 0.650535\n",
      "epoch 60; iter: 0; batch classifier loss: 0.371763; batch adversarial loss: 0.508831\n",
      "epoch 61; iter: 0; batch classifier loss: 0.398473; batch adversarial loss: 0.553535\n",
      "epoch 62; iter: 0; batch classifier loss: 0.433873; batch adversarial loss: 0.544262\n",
      "epoch 63; iter: 0; batch classifier loss: 0.404157; batch adversarial loss: 0.508345\n",
      "epoch 64; iter: 0; batch classifier loss: 0.395478; batch adversarial loss: 0.535508\n",
      "epoch 65; iter: 0; batch classifier loss: 0.423828; batch adversarial loss: 0.589752\n",
      "epoch 66; iter: 0; batch classifier loss: 0.413637; batch adversarial loss: 0.499167\n",
      "epoch 67; iter: 0; batch classifier loss: 0.423539; batch adversarial loss: 0.508350\n",
      "epoch 68; iter: 0; batch classifier loss: 0.360023; batch adversarial loss: 0.590009\n",
      "epoch 69; iter: 0; batch classifier loss: 0.403551; batch adversarial loss: 0.571794\n",
      "epoch 70; iter: 0; batch classifier loss: 0.367605; batch adversarial loss: 0.580826\n",
      "epoch 71; iter: 0; batch classifier loss: 0.417917; batch adversarial loss: 0.508796\n",
      "epoch 72; iter: 0; batch classifier loss: 0.389220; batch adversarial loss: 0.589053\n",
      "epoch 73; iter: 0; batch classifier loss: 0.421529; batch adversarial loss: 0.616070\n",
      "epoch 74; iter: 0; batch classifier loss: 0.361345; batch adversarial loss: 0.571135\n",
      "epoch 75; iter: 0; batch classifier loss: 0.395493; batch adversarial loss: 0.526745\n",
      "epoch 76; iter: 0; batch classifier loss: 0.450895; batch adversarial loss: 0.499936\n",
      "epoch 77; iter: 0; batch classifier loss: 0.376607; batch adversarial loss: 0.535592\n",
      "epoch 78; iter: 0; batch classifier loss: 0.412006; batch adversarial loss: 0.634937\n",
      "epoch 79; iter: 0; batch classifier loss: 0.394290; batch adversarial loss: 0.553001\n",
      "epoch 80; iter: 0; batch classifier loss: 0.401078; batch adversarial loss: 0.598929\n",
      "epoch 81; iter: 0; batch classifier loss: 0.496777; batch adversarial loss: 0.542640\n",
      "epoch 82; iter: 0; batch classifier loss: 0.415266; batch adversarial loss: 0.483380\n",
      "epoch 83; iter: 0; batch classifier loss: 0.414947; batch adversarial loss: 0.580856\n",
      "epoch 84; iter: 0; batch classifier loss: 0.405977; batch adversarial loss: 0.569620\n",
      "epoch 85; iter: 0; batch classifier loss: 0.342214; batch adversarial loss: 0.575663\n",
      "epoch 86; iter: 0; batch classifier loss: 0.362410; batch adversarial loss: 0.544079\n",
      "epoch 87; iter: 0; batch classifier loss: 0.335884; batch adversarial loss: 0.545808\n",
      "epoch 88; iter: 0; batch classifier loss: 0.356613; batch adversarial loss: 0.519226\n",
      "epoch 89; iter: 0; batch classifier loss: 0.357977; batch adversarial loss: 0.536615\n",
      "epoch 90; iter: 0; batch classifier loss: 0.349791; batch adversarial loss: 0.545287\n",
      "epoch 91; iter: 0; batch classifier loss: 0.337283; batch adversarial loss: 0.440153\n",
      "epoch 92; iter: 0; batch classifier loss: 0.418853; batch adversarial loss: 0.545392\n",
      "epoch 93; iter: 0; batch classifier loss: 0.455142; batch adversarial loss: 0.501498\n",
      "epoch 94; iter: 0; batch classifier loss: 0.416544; batch adversarial loss: 0.552915\n",
      "epoch 95; iter: 0; batch classifier loss: 0.406939; batch adversarial loss: 0.633492\n",
      "epoch 96; iter: 0; batch classifier loss: 0.444367; batch adversarial loss: 0.571068\n",
      "epoch 97; iter: 0; batch classifier loss: 0.336708; batch adversarial loss: 0.625148\n",
      "epoch 98; iter: 0; batch classifier loss: 0.381084; batch adversarial loss: 0.589201\n",
      "epoch 99; iter: 0; batch classifier loss: 0.426531; batch adversarial loss: 0.571590\n",
      "epoch 100; iter: 0; batch classifier loss: 0.362706; batch adversarial loss: 0.615671\n",
      "epoch 101; iter: 0; batch classifier loss: 0.291899; batch adversarial loss: 0.500351\n",
      "epoch 102; iter: 0; batch classifier loss: 0.415341; batch adversarial loss: 0.526781\n",
      "epoch 103; iter: 0; batch classifier loss: 0.429777; batch adversarial loss: 0.562366\n",
      "epoch 104; iter: 0; batch classifier loss: 0.351616; batch adversarial loss: 0.571572\n",
      "epoch 105; iter: 0; batch classifier loss: 0.385547; batch adversarial loss: 0.562760\n",
      "epoch 106; iter: 0; batch classifier loss: 0.387034; batch adversarial loss: 0.553939\n",
      "epoch 107; iter: 0; batch classifier loss: 0.355687; batch adversarial loss: 0.518021\n",
      "epoch 108; iter: 0; batch classifier loss: 0.475333; batch adversarial loss: 0.535564\n",
      "epoch 109; iter: 0; batch classifier loss: 0.406475; batch adversarial loss: 0.481909\n",
      "epoch 110; iter: 0; batch classifier loss: 0.472884; batch adversarial loss: 0.544583\n",
      "epoch 111; iter: 0; batch classifier loss: 0.439190; batch adversarial loss: 0.553681\n",
      "epoch 112; iter: 0; batch classifier loss: 0.435706; batch adversarial loss: 0.634293\n",
      "epoch 113; iter: 0; batch classifier loss: 0.335349; batch adversarial loss: 0.580369\n",
      "epoch 114; iter: 0; batch classifier loss: 0.321422; batch adversarial loss: 0.544599\n",
      "epoch 115; iter: 0; batch classifier loss: 0.334659; batch adversarial loss: 0.589366\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 116; iter: 0; batch classifier loss: 0.425534; batch adversarial loss: 0.553636\n",
      "epoch 117; iter: 0; batch classifier loss: 0.408427; batch adversarial loss: 0.571401\n",
      "epoch 118; iter: 0; batch classifier loss: 0.381371; batch adversarial loss: 0.552950\n",
      "epoch 119; iter: 0; batch classifier loss: 0.405060; batch adversarial loss: 0.526908\n",
      "epoch 120; iter: 0; batch classifier loss: 0.348758; batch adversarial loss: 0.571751\n",
      "epoch 121; iter: 0; batch classifier loss: 0.389952; batch adversarial loss: 0.535726\n",
      "epoch 122; iter: 0; batch classifier loss: 0.297347; batch adversarial loss: 0.580004\n",
      "epoch 123; iter: 0; batch classifier loss: 0.357138; batch adversarial loss: 0.562680\n",
      "epoch 124; iter: 0; batch classifier loss: 0.429669; batch adversarial loss: 0.616574\n",
      "epoch 125; iter: 0; batch classifier loss: 0.406088; batch adversarial loss: 0.473427\n",
      "epoch 126; iter: 0; batch classifier loss: 0.374027; batch adversarial loss: 0.526366\n",
      "epoch 127; iter: 0; batch classifier loss: 0.441652; batch adversarial loss: 0.509197\n",
      "epoch 128; iter: 0; batch classifier loss: 0.286567; batch adversarial loss: 0.544961\n",
      "epoch 129; iter: 0; batch classifier loss: 0.365669; batch adversarial loss: 0.572147\n",
      "epoch 130; iter: 0; batch classifier loss: 0.387222; batch adversarial loss: 0.554255\n",
      "epoch 131; iter: 0; batch classifier loss: 0.400889; batch adversarial loss: 0.544551\n",
      "epoch 132; iter: 0; batch classifier loss: 0.402643; batch adversarial loss: 0.606830\n",
      "epoch 133; iter: 0; batch classifier loss: 0.358742; batch adversarial loss: 0.553534\n",
      "epoch 134; iter: 0; batch classifier loss: 0.366361; batch adversarial loss: 0.598876\n",
      "epoch 135; iter: 0; batch classifier loss: 0.304784; batch adversarial loss: 0.508773\n",
      "epoch 136; iter: 0; batch classifier loss: 0.399522; batch adversarial loss: 0.544915\n",
      "epoch 137; iter: 0; batch classifier loss: 0.377632; batch adversarial loss: 0.527843\n",
      "epoch 138; iter: 0; batch classifier loss: 0.280259; batch adversarial loss: 0.526245\n",
      "epoch 139; iter: 0; batch classifier loss: 0.403427; batch adversarial loss: 0.580649\n",
      "epoch 140; iter: 0; batch classifier loss: 0.480828; batch adversarial loss: 0.509757\n",
      "epoch 141; iter: 0; batch classifier loss: 0.318665; batch adversarial loss: 0.499992\n",
      "epoch 142; iter: 0; batch classifier loss: 0.434835; batch adversarial loss: 0.579938\n",
      "epoch 143; iter: 0; batch classifier loss: 0.415386; batch adversarial loss: 0.500124\n",
      "epoch 144; iter: 0; batch classifier loss: 0.313426; batch adversarial loss: 0.553575\n",
      "epoch 145; iter: 0; batch classifier loss: 0.341800; batch adversarial loss: 0.509127\n",
      "epoch 146; iter: 0; batch classifier loss: 0.378900; batch adversarial loss: 0.535364\n",
      "epoch 147; iter: 0; batch classifier loss: 0.384919; batch adversarial loss: 0.553233\n",
      "epoch 148; iter: 0; batch classifier loss: 0.371650; batch adversarial loss: 0.625101\n",
      "epoch 149; iter: 0; batch classifier loss: 0.458657; batch adversarial loss: 0.589192\n",
      "epoch 150; iter: 0; batch classifier loss: 0.438039; batch adversarial loss: 0.509537\n",
      "epoch 151; iter: 0; batch classifier loss: 0.337916; batch adversarial loss: 0.571802\n",
      "epoch 152; iter: 0; batch classifier loss: 0.341421; batch adversarial loss: 0.571325\n",
      "epoch 153; iter: 0; batch classifier loss: 0.334698; batch adversarial loss: 0.553046\n",
      "epoch 154; iter: 0; batch classifier loss: 0.367709; batch adversarial loss: 0.563097\n",
      "epoch 155; iter: 0; batch classifier loss: 0.330986; batch adversarial loss: 0.535474\n",
      "epoch 156; iter: 0; batch classifier loss: 0.410101; batch adversarial loss: 0.553845\n",
      "epoch 157; iter: 0; batch classifier loss: 0.356449; batch adversarial loss: 0.491296\n",
      "epoch 158; iter: 0; batch classifier loss: 0.421342; batch adversarial loss: 0.571424\n",
      "epoch 159; iter: 0; batch classifier loss: 0.410969; batch adversarial loss: 0.642986\n",
      "epoch 160; iter: 0; batch classifier loss: 0.408432; batch adversarial loss: 0.580442\n",
      "epoch 161; iter: 0; batch classifier loss: 0.445362; batch adversarial loss: 0.553666\n",
      "epoch 162; iter: 0; batch classifier loss: 0.440199; batch adversarial loss: 0.517390\n",
      "epoch 163; iter: 0; batch classifier loss: 0.423304; batch adversarial loss: 0.535971\n",
      "epoch 164; iter: 0; batch classifier loss: 0.404234; batch adversarial loss: 0.634141\n",
      "epoch 165; iter: 0; batch classifier loss: 0.405907; batch adversarial loss: 0.562186\n",
      "epoch 166; iter: 0; batch classifier loss: 0.405786; batch adversarial loss: 0.571207\n",
      "epoch 167; iter: 0; batch classifier loss: 0.404727; batch adversarial loss: 0.553339\n",
      "epoch 168; iter: 0; batch classifier loss: 0.389652; batch adversarial loss: 0.500200\n",
      "epoch 169; iter: 0; batch classifier loss: 0.407432; batch adversarial loss: 0.544786\n",
      "epoch 170; iter: 0; batch classifier loss: 0.373831; batch adversarial loss: 0.589501\n",
      "epoch 171; iter: 0; batch classifier loss: 0.403378; batch adversarial loss: 0.526603\n",
      "epoch 172; iter: 0; batch classifier loss: 0.422659; batch adversarial loss: 0.500070\n",
      "epoch 173; iter: 0; batch classifier loss: 0.338766; batch adversarial loss: 0.580475\n",
      "epoch 174; iter: 0; batch classifier loss: 0.418635; batch adversarial loss: 0.553497\n",
      "epoch 175; iter: 0; batch classifier loss: 0.344869; batch adversarial loss: 0.499621\n",
      "epoch 176; iter: 0; batch classifier loss: 0.358767; batch adversarial loss: 0.553670\n",
      "epoch 177; iter: 0; batch classifier loss: 0.336265; batch adversarial loss: 0.544583\n",
      "epoch 178; iter: 0; batch classifier loss: 0.344655; batch adversarial loss: 0.455441\n",
      "epoch 179; iter: 0; batch classifier loss: 0.342626; batch adversarial loss: 0.572034\n",
      "epoch 180; iter: 0; batch classifier loss: 0.299365; batch adversarial loss: 0.517620\n",
      "epoch 181; iter: 0; batch classifier loss: 0.417635; batch adversarial loss: 0.579550\n",
      "epoch 182; iter: 0; batch classifier loss: 0.262478; batch adversarial loss: 0.589138\n",
      "epoch 183; iter: 0; batch classifier loss: 0.293163; batch adversarial loss: 0.580992\n",
      "epoch 184; iter: 0; batch classifier loss: 0.410257; batch adversarial loss: 0.509310\n",
      "epoch 185; iter: 0; batch classifier loss: 0.404342; batch adversarial loss: 0.526381\n",
      "epoch 186; iter: 0; batch classifier loss: 0.414238; batch adversarial loss: 0.562356\n",
      "epoch 187; iter: 0; batch classifier loss: 0.371045; batch adversarial loss: 0.499787\n",
      "epoch 188; iter: 0; batch classifier loss: 0.395003; batch adversarial loss: 0.606718\n",
      "epoch 189; iter: 0; batch classifier loss: 0.335907; batch adversarial loss: 0.589025\n",
      "epoch 190; iter: 0; batch classifier loss: 0.391835; batch adversarial loss: 0.534106\n",
      "epoch 191; iter: 0; batch classifier loss: 0.333794; batch adversarial loss: 0.571062\n",
      "epoch 192; iter: 0; batch classifier loss: 0.315151; batch adversarial loss: 0.617055\n",
      "epoch 193; iter: 0; batch classifier loss: 0.296064; batch adversarial loss: 0.581232\n",
      "epoch 194; iter: 0; batch classifier loss: 0.341234; batch adversarial loss: 0.571209\n",
      "epoch 195; iter: 0; batch classifier loss: 0.383823; batch adversarial loss: 0.571443\n",
      "epoch 196; iter: 0; batch classifier loss: 0.323416; batch adversarial loss: 0.597787\n",
      "epoch 197; iter: 0; batch classifier loss: 0.333279; batch adversarial loss: 0.571263\n",
      "epoch 198; iter: 0; batch classifier loss: 0.373391; batch adversarial loss: 0.544506\n",
      "epoch 199; iter: 0; batch classifier loss: 0.337308; batch adversarial loss: 0.634714\n",
      "epoch 0; iter: 0; batch classifier loss: 0.661081; batch adversarial loss: 0.637800\n",
      "epoch 1; iter: 0; batch classifier loss: 0.526077; batch adversarial loss: 0.642057\n",
      "epoch 2; iter: 0; batch classifier loss: 0.575117; batch adversarial loss: 0.635769\n",
      "epoch 3; iter: 0; batch classifier loss: 0.585559; batch adversarial loss: 0.663868\n",
      "epoch 4; iter: 0; batch classifier loss: 0.602279; batch adversarial loss: 0.611674\n",
      "epoch 5; iter: 0; batch classifier loss: 0.532624; batch adversarial loss: 0.626487\n",
      "epoch 6; iter: 0; batch classifier loss: 0.598936; batch adversarial loss: 0.627336\n",
      "epoch 7; iter: 0; batch classifier loss: 0.532293; batch adversarial loss: 0.566163\n",
      "epoch 8; iter: 0; batch classifier loss: 0.552273; batch adversarial loss: 0.635337\n",
      "epoch 9; iter: 0; batch classifier loss: 0.533381; batch adversarial loss: 0.606067\n",
      "epoch 10; iter: 0; batch classifier loss: 0.572424; batch adversarial loss: 0.643907\n",
      "epoch 11; iter: 0; batch classifier loss: 0.574971; batch adversarial loss: 0.570834\n",
      "epoch 12; iter: 0; batch classifier loss: 0.583484; batch adversarial loss: 0.597404\n",
      "epoch 13; iter: 0; batch classifier loss: 0.519854; batch adversarial loss: 0.537102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14; iter: 0; batch classifier loss: 0.488536; batch adversarial loss: 0.573078\n",
      "epoch 15; iter: 0; batch classifier loss: 0.476369; batch adversarial loss: 0.580480\n",
      "epoch 16; iter: 0; batch classifier loss: 0.467735; batch adversarial loss: 0.574144\n",
      "epoch 17; iter: 0; batch classifier loss: 0.538946; batch adversarial loss: 0.543332\n",
      "epoch 18; iter: 0; batch classifier loss: 0.466686; batch adversarial loss: 0.537824\n",
      "epoch 19; iter: 0; batch classifier loss: 0.424430; batch adversarial loss: 0.551446\n",
      "epoch 20; iter: 0; batch classifier loss: 0.521771; batch adversarial loss: 0.550074\n",
      "epoch 21; iter: 0; batch classifier loss: 0.482325; batch adversarial loss: 0.556495\n",
      "epoch 22; iter: 0; batch classifier loss: 0.497031; batch adversarial loss: 0.567234\n",
      "epoch 23; iter: 0; batch classifier loss: 0.505057; batch adversarial loss: 0.505314\n",
      "epoch 24; iter: 0; batch classifier loss: 0.515892; batch adversarial loss: 0.563512\n",
      "epoch 25; iter: 0; batch classifier loss: 0.463662; batch adversarial loss: 0.582723\n",
      "epoch 26; iter: 0; batch classifier loss: 0.476447; batch adversarial loss: 0.494474\n",
      "epoch 27; iter: 0; batch classifier loss: 0.457130; batch adversarial loss: 0.588784\n",
      "epoch 28; iter: 0; batch classifier loss: 0.472119; batch adversarial loss: 0.503850\n",
      "epoch 29; iter: 0; batch classifier loss: 0.451491; batch adversarial loss: 0.523272\n",
      "epoch 30; iter: 0; batch classifier loss: 0.449511; batch adversarial loss: 0.546770\n",
      "epoch 31; iter: 0; batch classifier loss: 0.501586; batch adversarial loss: 0.537239\n",
      "epoch 32; iter: 0; batch classifier loss: 0.483688; batch adversarial loss: 0.598345\n",
      "epoch 33; iter: 0; batch classifier loss: 0.426129; batch adversarial loss: 0.530684\n",
      "epoch 34; iter: 0; batch classifier loss: 0.408280; batch adversarial loss: 0.536026\n",
      "epoch 35; iter: 0; batch classifier loss: 0.443366; batch adversarial loss: 0.559765\n",
      "epoch 36; iter: 0; batch classifier loss: 0.402991; batch adversarial loss: 0.543405\n",
      "epoch 37; iter: 0; batch classifier loss: 0.401072; batch adversarial loss: 0.537577\n",
      "epoch 38; iter: 0; batch classifier loss: 0.503670; batch adversarial loss: 0.596882\n",
      "epoch 39; iter: 0; batch classifier loss: 0.438982; batch adversarial loss: 0.597893\n",
      "epoch 40; iter: 0; batch classifier loss: 0.448563; batch adversarial loss: 0.653474\n",
      "epoch 41; iter: 0; batch classifier loss: 0.476359; batch adversarial loss: 0.533425\n",
      "epoch 42; iter: 0; batch classifier loss: 0.397821; batch adversarial loss: 0.483297\n",
      "epoch 43; iter: 0; batch classifier loss: 0.455138; batch adversarial loss: 0.623541\n",
      "epoch 44; iter: 0; batch classifier loss: 0.428375; batch adversarial loss: 0.455373\n",
      "epoch 45; iter: 0; batch classifier loss: 0.385051; batch adversarial loss: 0.570469\n",
      "epoch 46; iter: 0; batch classifier loss: 0.461503; batch adversarial loss: 0.498780\n",
      "epoch 47; iter: 0; batch classifier loss: 0.479655; batch adversarial loss: 0.551645\n",
      "epoch 48; iter: 0; batch classifier loss: 0.461561; batch adversarial loss: 0.545225\n",
      "epoch 49; iter: 0; batch classifier loss: 0.467699; batch adversarial loss: 0.535100\n",
      "epoch 50; iter: 0; batch classifier loss: 0.400845; batch adversarial loss: 0.570839\n",
      "epoch 51; iter: 0; batch classifier loss: 0.440788; batch adversarial loss: 0.545757\n",
      "epoch 52; iter: 0; batch classifier loss: 0.437411; batch adversarial loss: 0.616777\n",
      "epoch 53; iter: 0; batch classifier loss: 0.514788; batch adversarial loss: 0.500399\n",
      "epoch 54; iter: 0; batch classifier loss: 0.421257; batch adversarial loss: 0.544658\n",
      "epoch 55; iter: 0; batch classifier loss: 0.349044; batch adversarial loss: 0.465034\n",
      "epoch 56; iter: 0; batch classifier loss: 0.470069; batch adversarial loss: 0.563296\n",
      "epoch 57; iter: 0; batch classifier loss: 0.448306; batch adversarial loss: 0.516327\n",
      "epoch 58; iter: 0; batch classifier loss: 0.341672; batch adversarial loss: 0.590195\n",
      "epoch 59; iter: 0; batch classifier loss: 0.468647; batch adversarial loss: 0.562328\n",
      "epoch 60; iter: 0; batch classifier loss: 0.381413; batch adversarial loss: 0.525748\n",
      "epoch 61; iter: 0; batch classifier loss: 0.373188; batch adversarial loss: 0.561794\n",
      "epoch 62; iter: 0; batch classifier loss: 0.427571; batch adversarial loss: 0.489209\n",
      "epoch 63; iter: 0; batch classifier loss: 0.379357; batch adversarial loss: 0.545143\n",
      "epoch 64; iter: 0; batch classifier loss: 0.432580; batch adversarial loss: 0.571913\n",
      "epoch 65; iter: 0; batch classifier loss: 0.406884; batch adversarial loss: 0.535248\n",
      "epoch 66; iter: 0; batch classifier loss: 0.488037; batch adversarial loss: 0.525537\n",
      "epoch 67; iter: 0; batch classifier loss: 0.484807; batch adversarial loss: 0.545026\n",
      "epoch 68; iter: 0; batch classifier loss: 0.354935; batch adversarial loss: 0.561770\n",
      "epoch 69; iter: 0; batch classifier loss: 0.360671; batch adversarial loss: 0.489198\n",
      "epoch 70; iter: 0; batch classifier loss: 0.392246; batch adversarial loss: 0.535586\n",
      "epoch 71; iter: 0; batch classifier loss: 0.385857; batch adversarial loss: 0.571120\n",
      "epoch 72; iter: 0; batch classifier loss: 0.404441; batch adversarial loss: 0.553248\n",
      "epoch 73; iter: 0; batch classifier loss: 0.407468; batch adversarial loss: 0.508476\n",
      "epoch 74; iter: 0; batch classifier loss: 0.413541; batch adversarial loss: 0.499991\n",
      "epoch 75; iter: 0; batch classifier loss: 0.426325; batch adversarial loss: 0.562415\n",
      "epoch 76; iter: 0; batch classifier loss: 0.393029; batch adversarial loss: 0.536256\n",
      "epoch 77; iter: 0; batch classifier loss: 0.418797; batch adversarial loss: 0.435719\n",
      "epoch 78; iter: 0; batch classifier loss: 0.359594; batch adversarial loss: 0.534493\n",
      "epoch 79; iter: 0; batch classifier loss: 0.329232; batch adversarial loss: 0.552962\n",
      "epoch 80; iter: 0; batch classifier loss: 0.371103; batch adversarial loss: 0.561497\n",
      "epoch 81; iter: 0; batch classifier loss: 0.388811; batch adversarial loss: 0.518341\n",
      "epoch 82; iter: 0; batch classifier loss: 0.369419; batch adversarial loss: 0.508198\n",
      "epoch 83; iter: 0; batch classifier loss: 0.384257; batch adversarial loss: 0.517046\n",
      "epoch 84; iter: 0; batch classifier loss: 0.353041; batch adversarial loss: 0.553316\n",
      "epoch 85; iter: 0; batch classifier loss: 0.378289; batch adversarial loss: 0.535266\n",
      "epoch 86; iter: 0; batch classifier loss: 0.452263; batch adversarial loss: 0.599215\n",
      "epoch 87; iter: 0; batch classifier loss: 0.356357; batch adversarial loss: 0.562381\n",
      "epoch 88; iter: 0; batch classifier loss: 0.357948; batch adversarial loss: 0.544234\n",
      "epoch 89; iter: 0; batch classifier loss: 0.374612; batch adversarial loss: 0.543636\n",
      "epoch 90; iter: 0; batch classifier loss: 0.376494; batch adversarial loss: 0.571664\n",
      "epoch 91; iter: 0; batch classifier loss: 0.317349; batch adversarial loss: 0.553738\n",
      "epoch 92; iter: 0; batch classifier loss: 0.464898; batch adversarial loss: 0.561963\n",
      "epoch 93; iter: 0; batch classifier loss: 0.398514; batch adversarial loss: 0.526316\n",
      "epoch 94; iter: 0; batch classifier loss: 0.391639; batch adversarial loss: 0.509099\n",
      "epoch 95; iter: 0; batch classifier loss: 0.393453; batch adversarial loss: 0.545142\n",
      "epoch 96; iter: 0; batch classifier loss: 0.372928; batch adversarial loss: 0.526206\n",
      "epoch 97; iter: 0; batch classifier loss: 0.386798; batch adversarial loss: 0.571715\n",
      "epoch 98; iter: 0; batch classifier loss: 0.357204; batch adversarial loss: 0.590094\n",
      "epoch 99; iter: 0; batch classifier loss: 0.293652; batch adversarial loss: 0.553496\n",
      "epoch 100; iter: 0; batch classifier loss: 0.387242; batch adversarial loss: 0.535122\n",
      "epoch 101; iter: 0; batch classifier loss: 0.277578; batch adversarial loss: 0.590499\n",
      "epoch 102; iter: 0; batch classifier loss: 0.348858; batch adversarial loss: 0.562930\n",
      "epoch 103; iter: 0; batch classifier loss: 0.352070; batch adversarial loss: 0.517706\n",
      "epoch 104; iter: 0; batch classifier loss: 0.379095; batch adversarial loss: 0.580820\n",
      "epoch 105; iter: 0; batch classifier loss: 0.332842; batch adversarial loss: 0.615840\n",
      "epoch 106; iter: 0; batch classifier loss: 0.379420; batch adversarial loss: 0.580812\n",
      "epoch 107; iter: 0; batch classifier loss: 0.447913; batch adversarial loss: 0.617334\n",
      "epoch 108; iter: 0; batch classifier loss: 0.479249; batch adversarial loss: 0.572159\n",
      "epoch 109; iter: 0; batch classifier loss: 0.458325; batch adversarial loss: 0.643553\n",
      "epoch 110; iter: 0; batch classifier loss: 0.389471; batch adversarial loss: 0.536443\n",
      "epoch 111; iter: 0; batch classifier loss: 0.345276; batch adversarial loss: 0.562203\n",
      "epoch 112; iter: 0; batch classifier loss: 0.410802; batch adversarial loss: 0.553272\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 113; iter: 0; batch classifier loss: 0.368203; batch adversarial loss: 0.472639\n",
      "epoch 114; iter: 0; batch classifier loss: 0.324730; batch adversarial loss: 0.463986\n",
      "epoch 115; iter: 0; batch classifier loss: 0.334152; batch adversarial loss: 0.562461\n",
      "epoch 116; iter: 0; batch classifier loss: 0.372769; batch adversarial loss: 0.581071\n",
      "epoch 117; iter: 0; batch classifier loss: 0.396979; batch adversarial loss: 0.581192\n",
      "epoch 118; iter: 0; batch classifier loss: 0.424766; batch adversarial loss: 0.562228\n",
      "epoch 119; iter: 0; batch classifier loss: 0.458619; batch adversarial loss: 0.562269\n",
      "epoch 120; iter: 0; batch classifier loss: 0.317009; batch adversarial loss: 0.607208\n",
      "epoch 121; iter: 0; batch classifier loss: 0.371926; batch adversarial loss: 0.553152\n",
      "epoch 122; iter: 0; batch classifier loss: 0.442780; batch adversarial loss: 0.580515\n",
      "epoch 123; iter: 0; batch classifier loss: 0.292805; batch adversarial loss: 0.599550\n",
      "epoch 124; iter: 0; batch classifier loss: 0.347878; batch adversarial loss: 0.481590\n",
      "epoch 125; iter: 0; batch classifier loss: 0.247004; batch adversarial loss: 0.580070\n",
      "epoch 126; iter: 0; batch classifier loss: 0.433609; batch adversarial loss: 0.500098\n",
      "epoch 127; iter: 0; batch classifier loss: 0.397518; batch adversarial loss: 0.562320\n",
      "epoch 128; iter: 0; batch classifier loss: 0.385785; batch adversarial loss: 0.517165\n",
      "epoch 129; iter: 0; batch classifier loss: 0.410199; batch adversarial loss: 0.563207\n",
      "epoch 130; iter: 0; batch classifier loss: 0.290370; batch adversarial loss: 0.500085\n",
      "epoch 131; iter: 0; batch classifier loss: 0.367843; batch adversarial loss: 0.562675\n",
      "epoch 132; iter: 0; batch classifier loss: 0.353052; batch adversarial loss: 0.616339\n",
      "epoch 133; iter: 0; batch classifier loss: 0.408763; batch adversarial loss: 0.553073\n",
      "epoch 134; iter: 0; batch classifier loss: 0.425827; batch adversarial loss: 0.545012\n",
      "epoch 135; iter: 0; batch classifier loss: 0.378061; batch adversarial loss: 0.572706\n",
      "epoch 136; iter: 0; batch classifier loss: 0.337552; batch adversarial loss: 0.544056\n",
      "epoch 137; iter: 0; batch classifier loss: 0.323208; batch adversarial loss: 0.572095\n",
      "epoch 138; iter: 0; batch classifier loss: 0.353338; batch adversarial loss: 0.490645\n",
      "epoch 139; iter: 0; batch classifier loss: 0.407449; batch adversarial loss: 0.553588\n",
      "epoch 140; iter: 0; batch classifier loss: 0.377868; batch adversarial loss: 0.535158\n",
      "epoch 141; iter: 0; batch classifier loss: 0.383833; batch adversarial loss: 0.508775\n",
      "epoch 142; iter: 0; batch classifier loss: 0.352744; batch adversarial loss: 0.544435\n",
      "epoch 143; iter: 0; batch classifier loss: 0.379437; batch adversarial loss: 0.537037\n",
      "epoch 144; iter: 0; batch classifier loss: 0.491102; batch adversarial loss: 0.579770\n",
      "epoch 145; iter: 0; batch classifier loss: 0.326897; batch adversarial loss: 0.562437\n",
      "epoch 146; iter: 0; batch classifier loss: 0.357202; batch adversarial loss: 0.670570\n",
      "epoch 147; iter: 0; batch classifier loss: 0.399703; batch adversarial loss: 0.517105\n",
      "epoch 148; iter: 0; batch classifier loss: 0.356504; batch adversarial loss: 0.562227\n",
      "epoch 149; iter: 0; batch classifier loss: 0.318053; batch adversarial loss: 0.581173\n",
      "epoch 150; iter: 0; batch classifier loss: 0.412657; batch adversarial loss: 0.481890\n",
      "epoch 151; iter: 0; batch classifier loss: 0.391061; batch adversarial loss: 0.527176\n",
      "epoch 152; iter: 0; batch classifier loss: 0.379269; batch adversarial loss: 0.517245\n",
      "epoch 153; iter: 0; batch classifier loss: 0.356909; batch adversarial loss: 0.553015\n",
      "epoch 154; iter: 0; batch classifier loss: 0.340934; batch adversarial loss: 0.570851\n",
      "epoch 155; iter: 0; batch classifier loss: 0.455726; batch adversarial loss: 0.553222\n",
      "epoch 156; iter: 0; batch classifier loss: 0.367361; batch adversarial loss: 0.507852\n",
      "epoch 157; iter: 0; batch classifier loss: 0.324929; batch adversarial loss: 0.598448\n",
      "epoch 158; iter: 0; batch classifier loss: 0.422209; batch adversarial loss: 0.616289\n",
      "epoch 159; iter: 0; batch classifier loss: 0.325693; batch adversarial loss: 0.553910\n",
      "epoch 160; iter: 0; batch classifier loss: 0.377457; batch adversarial loss: 0.616171\n",
      "epoch 161; iter: 0; batch classifier loss: 0.330981; batch adversarial loss: 0.525996\n",
      "epoch 162; iter: 0; batch classifier loss: 0.381396; batch adversarial loss: 0.598428\n",
      "epoch 163; iter: 0; batch classifier loss: 0.368632; batch adversarial loss: 0.544079\n",
      "epoch 164; iter: 0; batch classifier loss: 0.342529; batch adversarial loss: 0.508977\n",
      "epoch 165; iter: 0; batch classifier loss: 0.375570; batch adversarial loss: 0.535601\n",
      "epoch 166; iter: 0; batch classifier loss: 0.375001; batch adversarial loss: 0.552815\n",
      "epoch 167; iter: 0; batch classifier loss: 0.291464; batch adversarial loss: 0.545311\n",
      "epoch 168; iter: 0; batch classifier loss: 0.311338; batch adversarial loss: 0.661662\n",
      "epoch 169; iter: 0; batch classifier loss: 0.437575; batch adversarial loss: 0.490399\n",
      "epoch 170; iter: 0; batch classifier loss: 0.393098; batch adversarial loss: 0.508449\n",
      "epoch 171; iter: 0; batch classifier loss: 0.303630; batch adversarial loss: 0.535367\n",
      "epoch 172; iter: 0; batch classifier loss: 0.334573; batch adversarial loss: 0.473013\n",
      "epoch 173; iter: 0; batch classifier loss: 0.350761; batch adversarial loss: 0.499337\n",
      "epoch 174; iter: 0; batch classifier loss: 0.297985; batch adversarial loss: 0.652708\n",
      "epoch 175; iter: 0; batch classifier loss: 0.455940; batch adversarial loss: 0.562243\n",
      "epoch 176; iter: 0; batch classifier loss: 0.333912; batch adversarial loss: 0.535886\n",
      "epoch 177; iter: 0; batch classifier loss: 0.337546; batch adversarial loss: 0.580303\n",
      "epoch 178; iter: 0; batch classifier loss: 0.298173; batch adversarial loss: 0.535242\n",
      "epoch 179; iter: 0; batch classifier loss: 0.315869; batch adversarial loss: 0.643688\n",
      "epoch 180; iter: 0; batch classifier loss: 0.339388; batch adversarial loss: 0.526708\n",
      "epoch 181; iter: 0; batch classifier loss: 0.413391; batch adversarial loss: 0.490199\n",
      "epoch 182; iter: 0; batch classifier loss: 0.318129; batch adversarial loss: 0.571575\n",
      "epoch 183; iter: 0; batch classifier loss: 0.329984; batch adversarial loss: 0.481266\n",
      "epoch 184; iter: 0; batch classifier loss: 0.343187; batch adversarial loss: 0.535475\n",
      "epoch 185; iter: 0; batch classifier loss: 0.319078; batch adversarial loss: 0.597881\n",
      "epoch 186; iter: 0; batch classifier loss: 0.371724; batch adversarial loss: 0.571772\n",
      "epoch 187; iter: 0; batch classifier loss: 0.271720; batch adversarial loss: 0.562360\n",
      "epoch 188; iter: 0; batch classifier loss: 0.311114; batch adversarial loss: 0.472713\n",
      "epoch 189; iter: 0; batch classifier loss: 0.336771; batch adversarial loss: 0.535780\n",
      "epoch 190; iter: 0; batch classifier loss: 0.312669; batch adversarial loss: 0.482082\n",
      "epoch 191; iter: 0; batch classifier loss: 0.386776; batch adversarial loss: 0.652388\n",
      "epoch 192; iter: 0; batch classifier loss: 0.490076; batch adversarial loss: 0.517281\n",
      "epoch 193; iter: 0; batch classifier loss: 0.434163; batch adversarial loss: 0.526155\n",
      "epoch 194; iter: 0; batch classifier loss: 0.325633; batch adversarial loss: 0.625207\n",
      "epoch 195; iter: 0; batch classifier loss: 0.287882; batch adversarial loss: 0.472723\n",
      "epoch 196; iter: 0; batch classifier loss: 0.333764; batch adversarial loss: 0.571415\n",
      "epoch 197; iter: 0; batch classifier loss: 0.323123; batch adversarial loss: 0.509716\n",
      "epoch 198; iter: 0; batch classifier loss: 0.335294; batch adversarial loss: 0.445949\n",
      "epoch 199; iter: 0; batch classifier loss: 0.284262; batch adversarial loss: 0.508406\n",
      "epoch 0; iter: 0; batch classifier loss: 0.777965; batch adversarial loss: 0.754457\n",
      "epoch 1; iter: 0; batch classifier loss: 0.543654; batch adversarial loss: 0.692305\n",
      "epoch 2; iter: 0; batch classifier loss: 0.572047; batch adversarial loss: 0.655925\n",
      "epoch 3; iter: 0; batch classifier loss: 0.525828; batch adversarial loss: 0.659583\n",
      "epoch 4; iter: 0; batch classifier loss: 0.568618; batch adversarial loss: 0.617818\n",
      "epoch 5; iter: 0; batch classifier loss: 0.541517; batch adversarial loss: 0.624649\n",
      "epoch 6; iter: 0; batch classifier loss: 0.523632; batch adversarial loss: 0.585031\n",
      "epoch 7; iter: 0; batch classifier loss: 0.500753; batch adversarial loss: 0.574140\n",
      "epoch 8; iter: 0; batch classifier loss: 0.522552; batch adversarial loss: 0.593041\n",
      "epoch 9; iter: 0; batch classifier loss: 0.545622; batch adversarial loss: 0.567592\n",
      "epoch 10; iter: 0; batch classifier loss: 0.547414; batch adversarial loss: 0.560120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11; iter: 0; batch classifier loss: 0.497677; batch adversarial loss: 0.542931\n",
      "epoch 12; iter: 0; batch classifier loss: 0.432915; batch adversarial loss: 0.506990\n",
      "epoch 13; iter: 0; batch classifier loss: 0.598317; batch adversarial loss: 0.581977\n",
      "epoch 14; iter: 0; batch classifier loss: 0.472144; batch adversarial loss: 0.573194\n",
      "epoch 15; iter: 0; batch classifier loss: 0.505153; batch adversarial loss: 0.555627\n",
      "epoch 16; iter: 0; batch classifier loss: 0.539870; batch adversarial loss: 0.675116\n",
      "epoch 17; iter: 0; batch classifier loss: 0.535911; batch adversarial loss: 0.541409\n",
      "epoch 18; iter: 0; batch classifier loss: 0.504204; batch adversarial loss: 0.602454\n",
      "epoch 19; iter: 0; batch classifier loss: 0.507880; batch adversarial loss: 0.590677\n",
      "epoch 20; iter: 0; batch classifier loss: 0.522529; batch adversarial loss: 0.656642\n",
      "epoch 21; iter: 0; batch classifier loss: 0.522224; batch adversarial loss: 0.566675\n",
      "epoch 22; iter: 0; batch classifier loss: 0.566652; batch adversarial loss: 0.617992\n",
      "epoch 23; iter: 0; batch classifier loss: 0.424733; batch adversarial loss: 0.542464\n",
      "epoch 24; iter: 0; batch classifier loss: 0.438772; batch adversarial loss: 0.539678\n",
      "epoch 25; iter: 0; batch classifier loss: 0.465950; batch adversarial loss: 0.600379\n",
      "epoch 26; iter: 0; batch classifier loss: 0.492149; batch adversarial loss: 0.536334\n",
      "epoch 27; iter: 0; batch classifier loss: 0.525661; batch adversarial loss: 0.582371\n",
      "epoch 28; iter: 0; batch classifier loss: 0.485891; batch adversarial loss: 0.566279\n",
      "epoch 29; iter: 0; batch classifier loss: 0.498055; batch adversarial loss: 0.539407\n",
      "epoch 30; iter: 0; batch classifier loss: 0.486987; batch adversarial loss: 0.553723\n",
      "epoch 31; iter: 0; batch classifier loss: 0.520270; batch adversarial loss: 0.598203\n",
      "epoch 32; iter: 0; batch classifier loss: 0.460505; batch adversarial loss: 0.528650\n",
      "epoch 33; iter: 0; batch classifier loss: 0.459485; batch adversarial loss: 0.511102\n",
      "epoch 34; iter: 0; batch classifier loss: 0.485063; batch adversarial loss: 0.511232\n",
      "epoch 35; iter: 0; batch classifier loss: 0.577434; batch adversarial loss: 0.527491\n",
      "epoch 36; iter: 0; batch classifier loss: 0.449012; batch adversarial loss: 0.553566\n",
      "epoch 37; iter: 0; batch classifier loss: 0.339904; batch adversarial loss: 0.526967\n",
      "epoch 38; iter: 0; batch classifier loss: 0.399184; batch adversarial loss: 0.571037\n",
      "epoch 39; iter: 0; batch classifier loss: 0.445975; batch adversarial loss: 0.499596\n",
      "epoch 40; iter: 0; batch classifier loss: 0.458655; batch adversarial loss: 0.580941\n",
      "epoch 41; iter: 0; batch classifier loss: 0.470566; batch adversarial loss: 0.654630\n",
      "epoch 42; iter: 0; batch classifier loss: 0.463450; batch adversarial loss: 0.590333\n",
      "epoch 43; iter: 0; batch classifier loss: 0.434062; batch adversarial loss: 0.535154\n",
      "epoch 44; iter: 0; batch classifier loss: 0.397256; batch adversarial loss: 0.470740\n",
      "epoch 45; iter: 0; batch classifier loss: 0.378353; batch adversarial loss: 0.451947\n",
      "epoch 46; iter: 0; batch classifier loss: 0.564656; batch adversarial loss: 0.608913\n",
      "epoch 47; iter: 0; batch classifier loss: 0.457357; batch adversarial loss: 0.525522\n",
      "epoch 48; iter: 0; batch classifier loss: 0.414871; batch adversarial loss: 0.589655\n",
      "epoch 49; iter: 0; batch classifier loss: 0.497884; batch adversarial loss: 0.517087\n",
      "epoch 50; iter: 0; batch classifier loss: 0.468284; batch adversarial loss: 0.451486\n",
      "epoch 51; iter: 0; batch classifier loss: 0.432516; batch adversarial loss: 0.515291\n",
      "epoch 52; iter: 0; batch classifier loss: 0.481162; batch adversarial loss: 0.517173\n",
      "epoch 53; iter: 0; batch classifier loss: 0.359362; batch adversarial loss: 0.561101\n",
      "epoch 54; iter: 0; batch classifier loss: 0.466497; batch adversarial loss: 0.646204\n",
      "epoch 55; iter: 0; batch classifier loss: 0.384519; batch adversarial loss: 0.554566\n",
      "epoch 56; iter: 0; batch classifier loss: 0.436546; batch adversarial loss: 0.505696\n",
      "epoch 57; iter: 0; batch classifier loss: 0.327452; batch adversarial loss: 0.552767\n",
      "epoch 58; iter: 0; batch classifier loss: 0.389492; batch adversarial loss: 0.607382\n",
      "epoch 59; iter: 0; batch classifier loss: 0.433929; batch adversarial loss: 0.530458\n",
      "epoch 60; iter: 0; batch classifier loss: 0.351300; batch adversarial loss: 0.553477\n",
      "epoch 61; iter: 0; batch classifier loss: 0.373031; batch adversarial loss: 0.603162\n",
      "epoch 62; iter: 0; batch classifier loss: 0.414877; batch adversarial loss: 0.585434\n",
      "epoch 63; iter: 0; batch classifier loss: 0.463304; batch adversarial loss: 0.535563\n",
      "epoch 64; iter: 0; batch classifier loss: 0.406721; batch adversarial loss: 0.563886\n",
      "epoch 65; iter: 0; batch classifier loss: 0.407272; batch adversarial loss: 0.563686\n",
      "epoch 66; iter: 0; batch classifier loss: 0.494064; batch adversarial loss: 0.573174\n",
      "epoch 67; iter: 0; batch classifier loss: 0.420724; batch adversarial loss: 0.601790\n",
      "epoch 68; iter: 0; batch classifier loss: 0.386462; batch adversarial loss: 0.544459\n",
      "epoch 69; iter: 0; batch classifier loss: 0.375152; batch adversarial loss: 0.544181\n",
      "epoch 70; iter: 0; batch classifier loss: 0.453662; batch adversarial loss: 0.581458\n",
      "epoch 71; iter: 0; batch classifier loss: 0.449427; batch adversarial loss: 0.572864\n",
      "epoch 72; iter: 0; batch classifier loss: 0.406420; batch adversarial loss: 0.516907\n",
      "epoch 73; iter: 0; batch classifier loss: 0.378375; batch adversarial loss: 0.547395\n",
      "epoch 74; iter: 0; batch classifier loss: 0.415477; batch adversarial loss: 0.525388\n",
      "epoch 75; iter: 0; batch classifier loss: 0.364429; batch adversarial loss: 0.507828\n",
      "epoch 76; iter: 0; batch classifier loss: 0.359223; batch adversarial loss: 0.563477\n",
      "epoch 77; iter: 0; batch classifier loss: 0.444106; batch adversarial loss: 0.527241\n",
      "epoch 78; iter: 0; batch classifier loss: 0.377886; batch adversarial loss: 0.536883\n",
      "epoch 79; iter: 0; batch classifier loss: 0.469044; batch adversarial loss: 0.571811\n",
      "epoch 80; iter: 0; batch classifier loss: 0.394469; batch adversarial loss: 0.600870\n",
      "epoch 81; iter: 0; batch classifier loss: 0.445334; batch adversarial loss: 0.608465\n",
      "epoch 82; iter: 0; batch classifier loss: 0.418038; batch adversarial loss: 0.506936\n",
      "epoch 83; iter: 0; batch classifier loss: 0.386658; batch adversarial loss: 0.496079\n",
      "epoch 84; iter: 0; batch classifier loss: 0.418662; batch adversarial loss: 0.574969\n",
      "epoch 85; iter: 0; batch classifier loss: 0.419556; batch adversarial loss: 0.581415\n",
      "epoch 86; iter: 0; batch classifier loss: 0.446130; batch adversarial loss: 0.600029\n",
      "epoch 87; iter: 0; batch classifier loss: 0.379146; batch adversarial loss: 0.582083\n",
      "epoch 88; iter: 0; batch classifier loss: 0.318116; batch adversarial loss: 0.545900\n",
      "epoch 89; iter: 0; batch classifier loss: 0.523909; batch adversarial loss: 0.571916\n",
      "epoch 90; iter: 0; batch classifier loss: 0.426393; batch adversarial loss: 0.601787\n",
      "epoch 91; iter: 0; batch classifier loss: 0.390014; batch adversarial loss: 0.516252\n",
      "epoch 92; iter: 0; batch classifier loss: 0.375535; batch adversarial loss: 0.517432\n",
      "epoch 93; iter: 0; batch classifier loss: 0.356494; batch adversarial loss: 0.533877\n",
      "epoch 94; iter: 0; batch classifier loss: 0.365097; batch adversarial loss: 0.545600\n",
      "epoch 95; iter: 0; batch classifier loss: 0.379971; batch adversarial loss: 0.555086\n",
      "epoch 96; iter: 0; batch classifier loss: 0.389906; batch adversarial loss: 0.506575\n",
      "epoch 97; iter: 0; batch classifier loss: 0.350204; batch adversarial loss: 0.450317\n",
      "epoch 98; iter: 0; batch classifier loss: 0.438119; batch adversarial loss: 0.525837\n",
      "epoch 99; iter: 0; batch classifier loss: 0.339064; batch adversarial loss: 0.646774\n",
      "epoch 100; iter: 0; batch classifier loss: 0.333099; batch adversarial loss: 0.489304\n",
      "epoch 101; iter: 0; batch classifier loss: 0.430075; batch adversarial loss: 0.572456\n",
      "epoch 102; iter: 0; batch classifier loss: 0.337432; batch adversarial loss: 0.666403\n",
      "epoch 103; iter: 0; batch classifier loss: 0.361509; batch adversarial loss: 0.590685\n",
      "epoch 104; iter: 0; batch classifier loss: 0.278950; batch adversarial loss: 0.536149\n",
      "epoch 105; iter: 0; batch classifier loss: 0.397133; batch adversarial loss: 0.553257\n",
      "epoch 106; iter: 0; batch classifier loss: 0.327167; batch adversarial loss: 0.601395\n",
      "epoch 107; iter: 0; batch classifier loss: 0.363951; batch adversarial loss: 0.497460\n",
      "epoch 108; iter: 0; batch classifier loss: 0.395641; batch adversarial loss: 0.480111\n",
      "epoch 109; iter: 0; batch classifier loss: 0.374333; batch adversarial loss: 0.563925\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 110; iter: 0; batch classifier loss: 0.359207; batch adversarial loss: 0.449709\n",
      "epoch 111; iter: 0; batch classifier loss: 0.354527; batch adversarial loss: 0.506563\n",
      "epoch 112; iter: 0; batch classifier loss: 0.405643; batch adversarial loss: 0.516037\n",
      "epoch 113; iter: 0; batch classifier loss: 0.397288; batch adversarial loss: 0.494612\n",
      "epoch 114; iter: 0; batch classifier loss: 0.358656; batch adversarial loss: 0.527073\n",
      "epoch 115; iter: 0; batch classifier loss: 0.345531; batch adversarial loss: 0.497819\n",
      "epoch 116; iter: 0; batch classifier loss: 0.427692; batch adversarial loss: 0.564027\n",
      "epoch 117; iter: 0; batch classifier loss: 0.425539; batch adversarial loss: 0.537717\n",
      "epoch 118; iter: 0; batch classifier loss: 0.423748; batch adversarial loss: 0.501396\n",
      "epoch 119; iter: 0; batch classifier loss: 0.384071; batch adversarial loss: 0.558258\n",
      "epoch 120; iter: 0; batch classifier loss: 0.418611; batch adversarial loss: 0.507645\n",
      "epoch 121; iter: 0; batch classifier loss: 0.392641; batch adversarial loss: 0.470852\n",
      "epoch 122; iter: 0; batch classifier loss: 0.417736; batch adversarial loss: 0.481975\n",
      "epoch 123; iter: 0; batch classifier loss: 0.380422; batch adversarial loss: 0.573396\n",
      "epoch 124; iter: 0; batch classifier loss: 0.384422; batch adversarial loss: 0.502071\n",
      "epoch 125; iter: 0; batch classifier loss: 0.410359; batch adversarial loss: 0.596140\n",
      "epoch 126; iter: 0; batch classifier loss: 0.366826; batch adversarial loss: 0.587531\n",
      "epoch 127; iter: 0; batch classifier loss: 0.452924; batch adversarial loss: 0.517266\n",
      "epoch 128; iter: 0; batch classifier loss: 0.432274; batch adversarial loss: 0.627547\n",
      "epoch 129; iter: 0; batch classifier loss: 0.335695; batch adversarial loss: 0.536285\n",
      "epoch 130; iter: 0; batch classifier loss: 0.394059; batch adversarial loss: 0.526916\n",
      "epoch 131; iter: 0; batch classifier loss: 0.405877; batch adversarial loss: 0.580437\n",
      "epoch 132; iter: 0; batch classifier loss: 0.357663; batch adversarial loss: 0.466065\n",
      "epoch 133; iter: 0; batch classifier loss: 0.338000; batch adversarial loss: 0.562722\n",
      "epoch 134; iter: 0; batch classifier loss: 0.405539; batch adversarial loss: 0.572272\n",
      "epoch 135; iter: 0; batch classifier loss: 0.349182; batch adversarial loss: 0.545543\n",
      "epoch 136; iter: 0; batch classifier loss: 0.380551; batch adversarial loss: 0.572604\n",
      "epoch 137; iter: 0; batch classifier loss: 0.342272; batch adversarial loss: 0.650134\n",
      "epoch 138; iter: 0; batch classifier loss: 0.345293; batch adversarial loss: 0.561273\n",
      "epoch 139; iter: 0; batch classifier loss: 0.320675; batch adversarial loss: 0.571989\n",
      "epoch 140; iter: 0; batch classifier loss: 0.325533; batch adversarial loss: 0.496815\n",
      "epoch 141; iter: 0; batch classifier loss: 0.368438; batch adversarial loss: 0.527436\n",
      "epoch 142; iter: 0; batch classifier loss: 0.409432; batch adversarial loss: 0.545269\n",
      "epoch 143; iter: 0; batch classifier loss: 0.450412; batch adversarial loss: 0.515577\n",
      "epoch 144; iter: 0; batch classifier loss: 0.352941; batch adversarial loss: 0.515250\n",
      "epoch 145; iter: 0; batch classifier loss: 0.291671; batch adversarial loss: 0.440404\n",
      "epoch 146; iter: 0; batch classifier loss: 0.336695; batch adversarial loss: 0.565448\n",
      "epoch 147; iter: 0; batch classifier loss: 0.310051; batch adversarial loss: 0.450389\n",
      "epoch 148; iter: 0; batch classifier loss: 0.336602; batch adversarial loss: 0.571749\n",
      "epoch 149; iter: 0; batch classifier loss: 0.344214; batch adversarial loss: 0.518227\n",
      "epoch 150; iter: 0; batch classifier loss: 0.338324; batch adversarial loss: 0.591886\n",
      "epoch 151; iter: 0; batch classifier loss: 0.334416; batch adversarial loss: 0.479900\n",
      "epoch 152; iter: 0; batch classifier loss: 0.325176; batch adversarial loss: 0.574640\n",
      "epoch 153; iter: 0; batch classifier loss: 0.335058; batch adversarial loss: 0.451237\n",
      "epoch 154; iter: 0; batch classifier loss: 0.418659; batch adversarial loss: 0.542971\n",
      "epoch 155; iter: 0; batch classifier loss: 0.380210; batch adversarial loss: 0.551955\n",
      "epoch 156; iter: 0; batch classifier loss: 0.385188; batch adversarial loss: 0.572882\n",
      "epoch 157; iter: 0; batch classifier loss: 0.385582; batch adversarial loss: 0.552424\n",
      "epoch 158; iter: 0; batch classifier loss: 0.339094; batch adversarial loss: 0.546536\n",
      "epoch 159; iter: 0; batch classifier loss: 0.316541; batch adversarial loss: 0.490054\n",
      "epoch 160; iter: 0; batch classifier loss: 0.339015; batch adversarial loss: 0.496760\n",
      "epoch 161; iter: 0; batch classifier loss: 0.349837; batch adversarial loss: 0.546192\n",
      "epoch 162; iter: 0; batch classifier loss: 0.373335; batch adversarial loss: 0.486842\n",
      "epoch 163; iter: 0; batch classifier loss: 0.299371; batch adversarial loss: 0.573564\n",
      "epoch 164; iter: 0; batch classifier loss: 0.422651; batch adversarial loss: 0.564737\n",
      "epoch 165; iter: 0; batch classifier loss: 0.350213; batch adversarial loss: 0.570370\n",
      "epoch 166; iter: 0; batch classifier loss: 0.319233; batch adversarial loss: 0.560366\n",
      "epoch 167; iter: 0; batch classifier loss: 0.393278; batch adversarial loss: 0.563908\n",
      "epoch 168; iter: 0; batch classifier loss: 0.342686; batch adversarial loss: 0.535221\n",
      "epoch 169; iter: 0; batch classifier loss: 0.392045; batch adversarial loss: 0.620285\n",
      "epoch 170; iter: 0; batch classifier loss: 0.364001; batch adversarial loss: 0.516432\n",
      "epoch 171; iter: 0; batch classifier loss: 0.392319; batch adversarial loss: 0.525863\n",
      "epoch 172; iter: 0; batch classifier loss: 0.334724; batch adversarial loss: 0.582811\n",
      "epoch 173; iter: 0; batch classifier loss: 0.364036; batch adversarial loss: 0.571143\n",
      "epoch 174; iter: 0; batch classifier loss: 0.385885; batch adversarial loss: 0.515781\n",
      "epoch 175; iter: 0; batch classifier loss: 0.337273; batch adversarial loss: 0.507834\n",
      "epoch 176; iter: 0; batch classifier loss: 0.384821; batch adversarial loss: 0.498077\n",
      "epoch 177; iter: 0; batch classifier loss: 0.344895; batch adversarial loss: 0.516567\n",
      "epoch 178; iter: 0; batch classifier loss: 0.412227; batch adversarial loss: 0.533049\n",
      "epoch 179; iter: 0; batch classifier loss: 0.354338; batch adversarial loss: 0.518365\n",
      "epoch 180; iter: 0; batch classifier loss: 0.461474; batch adversarial loss: 0.579940\n",
      "epoch 181; iter: 0; batch classifier loss: 0.317894; batch adversarial loss: 0.460963\n",
      "epoch 182; iter: 0; batch classifier loss: 0.322718; batch adversarial loss: 0.514717\n",
      "epoch 183; iter: 0; batch classifier loss: 0.446303; batch adversarial loss: 0.507619\n",
      "epoch 184; iter: 0; batch classifier loss: 0.373071; batch adversarial loss: 0.548743\n",
      "epoch 185; iter: 0; batch classifier loss: 0.305297; batch adversarial loss: 0.514200\n",
      "epoch 186; iter: 0; batch classifier loss: 0.379467; batch adversarial loss: 0.564152\n",
      "epoch 187; iter: 0; batch classifier loss: 0.425324; batch adversarial loss: 0.545787\n",
      "epoch 188; iter: 0; batch classifier loss: 0.413031; batch adversarial loss: 0.575541\n",
      "epoch 189; iter: 0; batch classifier loss: 0.380717; batch adversarial loss: 0.591694\n",
      "epoch 190; iter: 0; batch classifier loss: 0.297902; batch adversarial loss: 0.498715\n",
      "epoch 191; iter: 0; batch classifier loss: 0.362742; batch adversarial loss: 0.571885\n",
      "epoch 192; iter: 0; batch classifier loss: 0.447906; batch adversarial loss: 0.514212\n",
      "epoch 193; iter: 0; batch classifier loss: 0.377616; batch adversarial loss: 0.504263\n",
      "epoch 194; iter: 0; batch classifier loss: 0.313377; batch adversarial loss: 0.642591\n",
      "epoch 195; iter: 0; batch classifier loss: 0.310599; batch adversarial loss: 0.616105\n",
      "epoch 196; iter: 0; batch classifier loss: 0.381588; batch adversarial loss: 0.460410\n",
      "epoch 197; iter: 0; batch classifier loss: 0.291667; batch adversarial loss: 0.552140\n",
      "epoch 198; iter: 0; batch classifier loss: 0.311057; batch adversarial loss: 0.573486\n",
      "epoch 199; iter: 0; batch classifier loss: 0.345949; batch adversarial loss: 0.507013\n",
      "epoch 0; iter: 0; batch classifier loss: 0.740764; batch adversarial loss: 0.579714\n",
      "epoch 1; iter: 0; batch classifier loss: 0.560604; batch adversarial loss: 0.677963\n",
      "epoch 2; iter: 0; batch classifier loss: 0.555234; batch adversarial loss: 0.620379\n",
      "epoch 3; iter: 0; batch classifier loss: 0.522201; batch adversarial loss: 0.617808\n",
      "epoch 4; iter: 0; batch classifier loss: 0.610252; batch adversarial loss: 0.589666\n",
      "epoch 5; iter: 0; batch classifier loss: 0.540440; batch adversarial loss: 0.580176\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6; iter: 0; batch classifier loss: 0.577026; batch adversarial loss: 0.597842\n",
      "epoch 7; iter: 0; batch classifier loss: 0.531154; batch adversarial loss: 0.519386\n",
      "epoch 8; iter: 0; batch classifier loss: 0.509667; batch adversarial loss: 0.596398\n",
      "epoch 9; iter: 0; batch classifier loss: 0.546164; batch adversarial loss: 0.624864\n",
      "epoch 10; iter: 0; batch classifier loss: 0.548599; batch adversarial loss: 0.601079\n",
      "epoch 11; iter: 0; batch classifier loss: 0.568464; batch adversarial loss: 0.577300\n",
      "epoch 12; iter: 0; batch classifier loss: 0.504533; batch adversarial loss: 0.568223\n",
      "epoch 13; iter: 0; batch classifier loss: 0.500742; batch adversarial loss: 0.644840\n",
      "epoch 14; iter: 0; batch classifier loss: 0.567937; batch adversarial loss: 0.564325\n",
      "epoch 15; iter: 0; batch classifier loss: 0.503324; batch adversarial loss: 0.553676\n",
      "epoch 16; iter: 0; batch classifier loss: 0.477886; batch adversarial loss: 0.602821\n",
      "epoch 17; iter: 0; batch classifier loss: 0.465328; batch adversarial loss: 0.605114\n",
      "epoch 18; iter: 0; batch classifier loss: 0.455520; batch adversarial loss: 0.551458\n",
      "epoch 19; iter: 0; batch classifier loss: 0.453408; batch adversarial loss: 0.554277\n",
      "epoch 20; iter: 0; batch classifier loss: 0.547978; batch adversarial loss: 0.580930\n",
      "epoch 21; iter: 0; batch classifier loss: 0.565882; batch adversarial loss: 0.489480\n",
      "epoch 22; iter: 0; batch classifier loss: 0.474182; batch adversarial loss: 0.500570\n",
      "epoch 23; iter: 0; batch classifier loss: 0.518453; batch adversarial loss: 0.616227\n",
      "epoch 24; iter: 0; batch classifier loss: 0.405177; batch adversarial loss: 0.492129\n",
      "epoch 25; iter: 0; batch classifier loss: 0.505233; batch adversarial loss: 0.508601\n",
      "epoch 26; iter: 0; batch classifier loss: 0.393724; batch adversarial loss: 0.553825\n",
      "epoch 27; iter: 0; batch classifier loss: 0.484204; batch adversarial loss: 0.498254\n",
      "epoch 28; iter: 0; batch classifier loss: 0.495747; batch adversarial loss: 0.537699\n",
      "epoch 29; iter: 0; batch classifier loss: 0.446019; batch adversarial loss: 0.644709\n",
      "epoch 30; iter: 0; batch classifier loss: 0.396976; batch adversarial loss: 0.513601\n",
      "epoch 31; iter: 0; batch classifier loss: 0.625540; batch adversarial loss: 0.580252\n",
      "epoch 32; iter: 0; batch classifier loss: 0.478756; batch adversarial loss: 0.608125\n",
      "epoch 33; iter: 0; batch classifier loss: 0.394370; batch adversarial loss: 0.471037\n",
      "epoch 34; iter: 0; batch classifier loss: 0.423151; batch adversarial loss: 0.545031\n",
      "epoch 35; iter: 0; batch classifier loss: 0.424385; batch adversarial loss: 0.581749\n",
      "epoch 36; iter: 0; batch classifier loss: 0.448196; batch adversarial loss: 0.506870\n",
      "epoch 37; iter: 0; batch classifier loss: 0.385635; batch adversarial loss: 0.580351\n",
      "epoch 38; iter: 0; batch classifier loss: 0.399042; batch adversarial loss: 0.541559\n",
      "epoch 39; iter: 0; batch classifier loss: 0.409063; batch adversarial loss: 0.499910\n",
      "epoch 40; iter: 0; batch classifier loss: 0.408632; batch adversarial loss: 0.507256\n",
      "epoch 41; iter: 0; batch classifier loss: 0.403419; batch adversarial loss: 0.571356\n",
      "epoch 42; iter: 0; batch classifier loss: 0.502232; batch adversarial loss: 0.535818\n",
      "epoch 43; iter: 0; batch classifier loss: 0.419240; batch adversarial loss: 0.618812\n",
      "epoch 44; iter: 0; batch classifier loss: 0.469375; batch adversarial loss: 0.517003\n",
      "epoch 45; iter: 0; batch classifier loss: 0.427356; batch adversarial loss: 0.518671\n",
      "epoch 46; iter: 0; batch classifier loss: 0.411628; batch adversarial loss: 0.553652\n",
      "epoch 47; iter: 0; batch classifier loss: 0.441085; batch adversarial loss: 0.580310\n",
      "epoch 48; iter: 0; batch classifier loss: 0.406805; batch adversarial loss: 0.534827\n",
      "epoch 49; iter: 0; batch classifier loss: 0.503774; batch adversarial loss: 0.496008\n",
      "epoch 50; iter: 0; batch classifier loss: 0.504157; batch adversarial loss: 0.521929\n",
      "epoch 51; iter: 0; batch classifier loss: 0.470292; batch adversarial loss: 0.605465\n",
      "epoch 52; iter: 0; batch classifier loss: 0.364132; batch adversarial loss: 0.524507\n",
      "epoch 53; iter: 0; batch classifier loss: 0.350752; batch adversarial loss: 0.509645\n",
      "epoch 54; iter: 0; batch classifier loss: 0.394167; batch adversarial loss: 0.487488\n",
      "epoch 55; iter: 0; batch classifier loss: 0.367335; batch adversarial loss: 0.557510\n",
      "epoch 56; iter: 0; batch classifier loss: 0.390497; batch adversarial loss: 0.580170\n",
      "epoch 57; iter: 0; batch classifier loss: 0.355922; batch adversarial loss: 0.629124\n",
      "epoch 58; iter: 0; batch classifier loss: 0.372081; batch adversarial loss: 0.545998\n",
      "epoch 59; iter: 0; batch classifier loss: 0.378901; batch adversarial loss: 0.492506\n",
      "epoch 60; iter: 0; batch classifier loss: 0.474635; batch adversarial loss: 0.609218\n",
      "epoch 61; iter: 0; batch classifier loss: 0.447887; batch adversarial loss: 0.527994\n",
      "epoch 62; iter: 0; batch classifier loss: 0.412424; batch adversarial loss: 0.526161\n",
      "epoch 63; iter: 0; batch classifier loss: 0.442476; batch adversarial loss: 0.553840\n",
      "epoch 64; iter: 0; batch classifier loss: 0.436194; batch adversarial loss: 0.544805\n",
      "epoch 65; iter: 0; batch classifier loss: 0.411726; batch adversarial loss: 0.572227\n",
      "epoch 66; iter: 0; batch classifier loss: 0.409864; batch adversarial loss: 0.535297\n",
      "epoch 67; iter: 0; batch classifier loss: 0.448859; batch adversarial loss: 0.579403\n",
      "epoch 68; iter: 0; batch classifier loss: 0.419372; batch adversarial loss: 0.617330\n",
      "epoch 69; iter: 0; batch classifier loss: 0.385518; batch adversarial loss: 0.616057\n",
      "epoch 70; iter: 0; batch classifier loss: 0.333186; batch adversarial loss: 0.571977\n",
      "epoch 71; iter: 0; batch classifier loss: 0.386663; batch adversarial loss: 0.508120\n",
      "epoch 72; iter: 0; batch classifier loss: 0.424082; batch adversarial loss: 0.545332\n",
      "epoch 73; iter: 0; batch classifier loss: 0.363813; batch adversarial loss: 0.462511\n",
      "epoch 74; iter: 0; batch classifier loss: 0.359303; batch adversarial loss: 0.480606\n",
      "epoch 75; iter: 0; batch classifier loss: 0.425616; batch adversarial loss: 0.544694\n",
      "epoch 76; iter: 0; batch classifier loss: 0.362495; batch adversarial loss: 0.463581\n",
      "epoch 77; iter: 0; batch classifier loss: 0.449185; batch adversarial loss: 0.462654\n",
      "epoch 78; iter: 0; batch classifier loss: 0.404974; batch adversarial loss: 0.544855\n",
      "epoch 79; iter: 0; batch classifier loss: 0.353397; batch adversarial loss: 0.562218\n",
      "epoch 80; iter: 0; batch classifier loss: 0.371948; batch adversarial loss: 0.627096\n",
      "epoch 81; iter: 0; batch classifier loss: 0.441109; batch adversarial loss: 0.516953\n",
      "epoch 82; iter: 0; batch classifier loss: 0.343281; batch adversarial loss: 0.508543\n",
      "epoch 83; iter: 0; batch classifier loss: 0.419572; batch adversarial loss: 0.562624\n",
      "epoch 84; iter: 0; batch classifier loss: 0.360431; batch adversarial loss: 0.581303\n",
      "epoch 85; iter: 0; batch classifier loss: 0.450133; batch adversarial loss: 0.461480\n",
      "epoch 86; iter: 0; batch classifier loss: 0.446181; batch adversarial loss: 0.562676\n",
      "epoch 87; iter: 0; batch classifier loss: 0.389701; batch adversarial loss: 0.590761\n",
      "epoch 88; iter: 0; batch classifier loss: 0.420431; batch adversarial loss: 0.545160\n",
      "epoch 89; iter: 0; batch classifier loss: 0.367178; batch adversarial loss: 0.590864\n",
      "epoch 90; iter: 0; batch classifier loss: 0.335999; batch adversarial loss: 0.655472\n",
      "epoch 91; iter: 0; batch classifier loss: 0.315991; batch adversarial loss: 0.498987\n",
      "epoch 92; iter: 0; batch classifier loss: 0.403851; batch adversarial loss: 0.563209\n",
      "epoch 93; iter: 0; batch classifier loss: 0.375746; batch adversarial loss: 0.617722\n",
      "epoch 94; iter: 0; batch classifier loss: 0.347383; batch adversarial loss: 0.562983\n",
      "epoch 95; iter: 0; batch classifier loss: 0.415451; batch adversarial loss: 0.609112\n",
      "epoch 96; iter: 0; batch classifier loss: 0.403582; batch adversarial loss: 0.527378\n",
      "epoch 97; iter: 0; batch classifier loss: 0.364465; batch adversarial loss: 0.590122\n",
      "epoch 98; iter: 0; batch classifier loss: 0.434717; batch adversarial loss: 0.581242\n",
      "epoch 99; iter: 0; batch classifier loss: 0.316818; batch adversarial loss: 0.608762\n",
      "epoch 100; iter: 0; batch classifier loss: 0.357977; batch adversarial loss: 0.535079\n",
      "epoch 101; iter: 0; batch classifier loss: 0.312280; batch adversarial loss: 0.572350\n",
      "epoch 102; iter: 0; batch classifier loss: 0.396119; batch adversarial loss: 0.617562\n",
      "epoch 103; iter: 0; batch classifier loss: 0.311117; batch adversarial loss: 0.544087\n",
      "epoch 104; iter: 0; batch classifier loss: 0.370705; batch adversarial loss: 0.553185\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 105; iter: 0; batch classifier loss: 0.354375; batch adversarial loss: 0.553198\n",
      "epoch 106; iter: 0; batch classifier loss: 0.460154; batch adversarial loss: 0.553596\n",
      "epoch 107; iter: 0; batch classifier loss: 0.387518; batch adversarial loss: 0.480698\n",
      "epoch 108; iter: 0; batch classifier loss: 0.353754; batch adversarial loss: 0.526536\n",
      "epoch 109; iter: 0; batch classifier loss: 0.367973; batch adversarial loss: 0.526303\n",
      "epoch 110; iter: 0; batch classifier loss: 0.440982; batch adversarial loss: 0.489840\n",
      "epoch 111; iter: 0; batch classifier loss: 0.441951; batch adversarial loss: 0.498530\n",
      "epoch 112; iter: 0; batch classifier loss: 0.360394; batch adversarial loss: 0.517290\n",
      "epoch 113; iter: 0; batch classifier loss: 0.389306; batch adversarial loss: 0.535942\n",
      "epoch 114; iter: 0; batch classifier loss: 0.359451; batch adversarial loss: 0.516656\n",
      "epoch 115; iter: 0; batch classifier loss: 0.413692; batch adversarial loss: 0.590190\n",
      "epoch 116; iter: 0; batch classifier loss: 0.289660; batch adversarial loss: 0.562974\n",
      "epoch 117; iter: 0; batch classifier loss: 0.409166; batch adversarial loss: 0.534761\n",
      "epoch 118; iter: 0; batch classifier loss: 0.324465; batch adversarial loss: 0.608770\n",
      "epoch 119; iter: 0; batch classifier loss: 0.394009; batch adversarial loss: 0.470657\n",
      "epoch 120; iter: 0; batch classifier loss: 0.289016; batch adversarial loss: 0.471652\n",
      "epoch 121; iter: 0; batch classifier loss: 0.367422; batch adversarial loss: 0.508635\n",
      "epoch 122; iter: 0; batch classifier loss: 0.356257; batch adversarial loss: 0.498294\n",
      "epoch 123; iter: 0; batch classifier loss: 0.387373; batch adversarial loss: 0.543895\n",
      "epoch 124; iter: 0; batch classifier loss: 0.370384; batch adversarial loss: 0.544022\n",
      "epoch 125; iter: 0; batch classifier loss: 0.413455; batch adversarial loss: 0.563099\n",
      "epoch 126; iter: 0; batch classifier loss: 0.434033; batch adversarial loss: 0.452628\n",
      "epoch 127; iter: 0; batch classifier loss: 0.404716; batch adversarial loss: 0.580642\n",
      "epoch 128; iter: 0; batch classifier loss: 0.313366; batch adversarial loss: 0.498624\n",
      "epoch 129; iter: 0; batch classifier loss: 0.377016; batch adversarial loss: 0.526277\n",
      "epoch 130; iter: 0; batch classifier loss: 0.294463; batch adversarial loss: 0.617215\n",
      "epoch 131; iter: 0; batch classifier loss: 0.313324; batch adversarial loss: 0.590048\n",
      "epoch 132; iter: 0; batch classifier loss: 0.275707; batch adversarial loss: 0.525934\n",
      "epoch 133; iter: 0; batch classifier loss: 0.378184; batch adversarial loss: 0.571450\n",
      "epoch 134; iter: 0; batch classifier loss: 0.396477; batch adversarial loss: 0.599519\n",
      "epoch 135; iter: 0; batch classifier loss: 0.375061; batch adversarial loss: 0.562907\n",
      "epoch 136; iter: 0; batch classifier loss: 0.403604; batch adversarial loss: 0.554282\n",
      "epoch 137; iter: 0; batch classifier loss: 0.391708; batch adversarial loss: 0.535665\n",
      "epoch 138; iter: 0; batch classifier loss: 0.393951; batch adversarial loss: 0.554087\n",
      "epoch 139; iter: 0; batch classifier loss: 0.431080; batch adversarial loss: 0.590001\n",
      "epoch 140; iter: 0; batch classifier loss: 0.377813; batch adversarial loss: 0.553853\n",
      "epoch 141; iter: 0; batch classifier loss: 0.349272; batch adversarial loss: 0.535743\n",
      "epoch 142; iter: 0; batch classifier loss: 0.408660; batch adversarial loss: 0.563397\n",
      "epoch 143; iter: 0; batch classifier loss: 0.406613; batch adversarial loss: 0.498171\n",
      "epoch 144; iter: 0; batch classifier loss: 0.354437; batch adversarial loss: 0.489792\n",
      "epoch 145; iter: 0; batch classifier loss: 0.348807; batch adversarial loss: 0.517108\n",
      "epoch 146; iter: 0; batch classifier loss: 0.384766; batch adversarial loss: 0.507060\n",
      "epoch 147; iter: 0; batch classifier loss: 0.424033; batch adversarial loss: 0.581385\n",
      "epoch 148; iter: 0; batch classifier loss: 0.368795; batch adversarial loss: 0.518124\n",
      "epoch 149; iter: 0; batch classifier loss: 0.399776; batch adversarial loss: 0.572021\n",
      "epoch 150; iter: 0; batch classifier loss: 0.446783; batch adversarial loss: 0.517820\n",
      "epoch 151; iter: 0; batch classifier loss: 0.300977; batch adversarial loss: 0.590485\n",
      "epoch 152; iter: 0; batch classifier loss: 0.275080; batch adversarial loss: 0.571969\n",
      "epoch 153; iter: 0; batch classifier loss: 0.469126; batch adversarial loss: 0.563476\n",
      "epoch 154; iter: 0; batch classifier loss: 0.363752; batch adversarial loss: 0.563546\n",
      "epoch 155; iter: 0; batch classifier loss: 0.367260; batch adversarial loss: 0.608488\n",
      "epoch 156; iter: 0; batch classifier loss: 0.385137; batch adversarial loss: 0.534456\n",
      "epoch 157; iter: 0; batch classifier loss: 0.297839; batch adversarial loss: 0.599086\n",
      "epoch 158; iter: 0; batch classifier loss: 0.339504; batch adversarial loss: 0.553406\n",
      "epoch 159; iter: 0; batch classifier loss: 0.327255; batch adversarial loss: 0.554638\n",
      "epoch 160; iter: 0; batch classifier loss: 0.441696; batch adversarial loss: 0.525940\n",
      "epoch 161; iter: 0; batch classifier loss: 0.414319; batch adversarial loss: 0.544450\n",
      "epoch 162; iter: 0; batch classifier loss: 0.374168; batch adversarial loss: 0.544496\n",
      "epoch 163; iter: 0; batch classifier loss: 0.379822; batch adversarial loss: 0.489396\n",
      "epoch 164; iter: 0; batch classifier loss: 0.372915; batch adversarial loss: 0.571969\n",
      "epoch 165; iter: 0; batch classifier loss: 0.362211; batch adversarial loss: 0.527118\n",
      "epoch 166; iter: 0; batch classifier loss: 0.299903; batch adversarial loss: 0.534560\n",
      "epoch 167; iter: 0; batch classifier loss: 0.304709; batch adversarial loss: 0.498055\n",
      "epoch 168; iter: 0; batch classifier loss: 0.404080; batch adversarial loss: 0.489075\n",
      "epoch 169; iter: 0; batch classifier loss: 0.349225; batch adversarial loss: 0.489790\n",
      "epoch 170; iter: 0; batch classifier loss: 0.369379; batch adversarial loss: 0.553867\n",
      "epoch 171; iter: 0; batch classifier loss: 0.358940; batch adversarial loss: 0.444897\n",
      "epoch 172; iter: 0; batch classifier loss: 0.351107; batch adversarial loss: 0.544883\n",
      "epoch 173; iter: 0; batch classifier loss: 0.392529; batch adversarial loss: 0.470779\n",
      "epoch 174; iter: 0; batch classifier loss: 0.476791; batch adversarial loss: 0.562081\n",
      "epoch 175; iter: 0; batch classifier loss: 0.392176; batch adversarial loss: 0.516846\n",
      "epoch 176; iter: 0; batch classifier loss: 0.369207; batch adversarial loss: 0.452299\n",
      "epoch 177; iter: 0; batch classifier loss: 0.393327; batch adversarial loss: 0.535440\n",
      "epoch 178; iter: 0; batch classifier loss: 0.370247; batch adversarial loss: 0.554954\n",
      "epoch 179; iter: 0; batch classifier loss: 0.318382; batch adversarial loss: 0.508182\n",
      "epoch 180; iter: 0; batch classifier loss: 0.380983; batch adversarial loss: 0.526162\n",
      "epoch 181; iter: 0; batch classifier loss: 0.363645; batch adversarial loss: 0.599414\n",
      "epoch 182; iter: 0; batch classifier loss: 0.385765; batch adversarial loss: 0.562699\n",
      "epoch 183; iter: 0; batch classifier loss: 0.321217; batch adversarial loss: 0.553451\n",
      "epoch 184; iter: 0; batch classifier loss: 0.374844; batch adversarial loss: 0.563514\n",
      "epoch 185; iter: 0; batch classifier loss: 0.331874; batch adversarial loss: 0.599959\n",
      "epoch 186; iter: 0; batch classifier loss: 0.452230; batch adversarial loss: 0.571677\n",
      "epoch 187; iter: 0; batch classifier loss: 0.466387; batch adversarial loss: 0.527068\n",
      "epoch 188; iter: 0; batch classifier loss: 0.301192; batch adversarial loss: 0.480381\n",
      "epoch 189; iter: 0; batch classifier loss: 0.294708; batch adversarial loss: 0.572036\n",
      "epoch 190; iter: 0; batch classifier loss: 0.336108; batch adversarial loss: 0.563040\n",
      "epoch 191; iter: 0; batch classifier loss: 0.431179; batch adversarial loss: 0.472337\n",
      "epoch 192; iter: 0; batch classifier loss: 0.286734; batch adversarial loss: 0.516938\n",
      "epoch 193; iter: 0; batch classifier loss: 0.303830; batch adversarial loss: 0.608110\n",
      "epoch 194; iter: 0; batch classifier loss: 0.356741; batch adversarial loss: 0.590040\n",
      "epoch 195; iter: 0; batch classifier loss: 0.290602; batch adversarial loss: 0.553107\n",
      "epoch 196; iter: 0; batch classifier loss: 0.342394; batch adversarial loss: 0.453081\n",
      "epoch 197; iter: 0; batch classifier loss: 0.270392; batch adversarial loss: 0.590510\n",
      "epoch 198; iter: 0; batch classifier loss: 0.289044; batch adversarial loss: 0.525456\n",
      "epoch 199; iter: 0; batch classifier loss: 0.345890; batch adversarial loss: 0.462376\n",
      "epoch 0; iter: 0; batch classifier loss: 0.666839; batch adversarial loss: 0.715850\n",
      "epoch 1; iter: 0; batch classifier loss: 0.606752; batch adversarial loss: 0.682936\n",
      "epoch 2; iter: 0; batch classifier loss: 0.603897; batch adversarial loss: 0.647727\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3; iter: 0; batch classifier loss: 0.547288; batch adversarial loss: 0.657682\n",
      "epoch 4; iter: 0; batch classifier loss: 0.525564; batch adversarial loss: 0.610982\n",
      "epoch 5; iter: 0; batch classifier loss: 0.578755; batch adversarial loss: 0.626453\n",
      "epoch 6; iter: 0; batch classifier loss: 0.582804; batch adversarial loss: 0.621181\n",
      "epoch 7; iter: 0; batch classifier loss: 0.587669; batch adversarial loss: 0.562392\n",
      "epoch 8; iter: 0; batch classifier loss: 0.533026; batch adversarial loss: 0.562747\n",
      "epoch 9; iter: 0; batch classifier loss: 0.504985; batch adversarial loss: 0.588814\n",
      "epoch 10; iter: 0; batch classifier loss: 0.462068; batch adversarial loss: 0.566724\n",
      "epoch 11; iter: 0; batch classifier loss: 0.501841; batch adversarial loss: 0.521704\n",
      "epoch 12; iter: 0; batch classifier loss: 0.544625; batch adversarial loss: 0.589839\n",
      "epoch 13; iter: 0; batch classifier loss: 0.574256; batch adversarial loss: 0.512304\n",
      "epoch 14; iter: 0; batch classifier loss: 0.525266; batch adversarial loss: 0.552967\n",
      "epoch 15; iter: 0; batch classifier loss: 0.519572; batch adversarial loss: 0.579910\n",
      "epoch 16; iter: 0; batch classifier loss: 0.492867; batch adversarial loss: 0.544784\n",
      "epoch 17; iter: 0; batch classifier loss: 0.491654; batch adversarial loss: 0.590955\n",
      "epoch 18; iter: 0; batch classifier loss: 0.515794; batch adversarial loss: 0.555236\n",
      "epoch 19; iter: 0; batch classifier loss: 0.523023; batch adversarial loss: 0.488213\n",
      "epoch 20; iter: 0; batch classifier loss: 0.482859; batch adversarial loss: 0.506374\n",
      "epoch 21; iter: 0; batch classifier loss: 0.489392; batch adversarial loss: 0.514286\n",
      "epoch 22; iter: 0; batch classifier loss: 0.419700; batch adversarial loss: 0.604046\n",
      "epoch 23; iter: 0; batch classifier loss: 0.457067; batch adversarial loss: 0.564775\n",
      "epoch 24; iter: 0; batch classifier loss: 0.550187; batch adversarial loss: 0.626542\n",
      "epoch 25; iter: 0; batch classifier loss: 0.540529; batch adversarial loss: 0.540628\n",
      "epoch 26; iter: 0; batch classifier loss: 0.455675; batch adversarial loss: 0.539925\n",
      "epoch 27; iter: 0; batch classifier loss: 0.528944; batch adversarial loss: 0.537021\n",
      "epoch 28; iter: 0; batch classifier loss: 0.435005; batch adversarial loss: 0.536443\n",
      "epoch 29; iter: 0; batch classifier loss: 0.448131; batch adversarial loss: 0.535938\n",
      "epoch 30; iter: 0; batch classifier loss: 0.499154; batch adversarial loss: 0.545152\n",
      "epoch 31; iter: 0; batch classifier loss: 0.474704; batch adversarial loss: 0.527389\n",
      "epoch 32; iter: 0; batch classifier loss: 0.479006; batch adversarial loss: 0.545294\n",
      "epoch 33; iter: 0; batch classifier loss: 0.457814; batch adversarial loss: 0.471912\n",
      "epoch 34; iter: 0; batch classifier loss: 0.523942; batch adversarial loss: 0.500060\n",
      "epoch 35; iter: 0; batch classifier loss: 0.462158; batch adversarial loss: 0.471965\n",
      "epoch 36; iter: 0; batch classifier loss: 0.512781; batch adversarial loss: 0.526328\n",
      "epoch 37; iter: 0; batch classifier loss: 0.485835; batch adversarial loss: 0.507800\n",
      "epoch 38; iter: 0; batch classifier loss: 0.386404; batch adversarial loss: 0.562897\n",
      "epoch 39; iter: 0; batch classifier loss: 0.414355; batch adversarial loss: 0.544548\n",
      "epoch 40; iter: 0; batch classifier loss: 0.453640; batch adversarial loss: 0.544754\n",
      "epoch 41; iter: 0; batch classifier loss: 0.501941; batch adversarial loss: 0.477964\n",
      "epoch 42; iter: 0; batch classifier loss: 0.383772; batch adversarial loss: 0.462621\n",
      "epoch 43; iter: 0; batch classifier loss: 0.491558; batch adversarial loss: 0.488335\n",
      "epoch 44; iter: 0; batch classifier loss: 0.368954; batch adversarial loss: 0.590055\n",
      "epoch 45; iter: 0; batch classifier loss: 0.494158; batch adversarial loss: 0.460110\n",
      "epoch 46; iter: 0; batch classifier loss: 0.413275; batch adversarial loss: 0.629562\n",
      "epoch 47; iter: 0; batch classifier loss: 0.444520; batch adversarial loss: 0.619868\n",
      "epoch 48; iter: 0; batch classifier loss: 0.464568; batch adversarial loss: 0.569510\n",
      "epoch 49; iter: 0; batch classifier loss: 0.411981; batch adversarial loss: 0.542249\n",
      "epoch 50; iter: 0; batch classifier loss: 0.399102; batch adversarial loss: 0.559138\n",
      "epoch 51; iter: 0; batch classifier loss: 0.484175; batch adversarial loss: 0.557037\n",
      "epoch 52; iter: 0; batch classifier loss: 0.362605; batch adversarial loss: 0.516330\n",
      "epoch 53; iter: 0; batch classifier loss: 0.397409; batch adversarial loss: 0.504243\n",
      "epoch 54; iter: 0; batch classifier loss: 0.436107; batch adversarial loss: 0.612239\n",
      "epoch 55; iter: 0; batch classifier loss: 0.324796; batch adversarial loss: 0.536419\n",
      "epoch 56; iter: 0; batch classifier loss: 0.492601; batch adversarial loss: 0.496392\n",
      "epoch 57; iter: 0; batch classifier loss: 0.426364; batch adversarial loss: 0.504652\n",
      "epoch 58; iter: 0; batch classifier loss: 0.444755; batch adversarial loss: 0.547804\n",
      "epoch 59; iter: 0; batch classifier loss: 0.480413; batch adversarial loss: 0.535116\n",
      "epoch 60; iter: 0; batch classifier loss: 0.393614; batch adversarial loss: 0.465063\n",
      "epoch 61; iter: 0; batch classifier loss: 0.421733; batch adversarial loss: 0.562163\n",
      "epoch 62; iter: 0; batch classifier loss: 0.354075; batch adversarial loss: 0.465243\n",
      "epoch 63; iter: 0; batch classifier loss: 0.414649; batch adversarial loss: 0.536294\n",
      "epoch 64; iter: 0; batch classifier loss: 0.449836; batch adversarial loss: 0.506891\n",
      "epoch 65; iter: 0; batch classifier loss: 0.403007; batch adversarial loss: 0.496025\n",
      "epoch 66; iter: 0; batch classifier loss: 0.392875; batch adversarial loss: 0.476961\n",
      "epoch 67; iter: 0; batch classifier loss: 0.447758; batch adversarial loss: 0.505405\n",
      "epoch 68; iter: 0; batch classifier loss: 0.366031; batch adversarial loss: 0.534148\n",
      "epoch 69; iter: 0; batch classifier loss: 0.457687; batch adversarial loss: 0.533017\n",
      "epoch 70; iter: 0; batch classifier loss: 0.408474; batch adversarial loss: 0.535366\n",
      "epoch 71; iter: 0; batch classifier loss: 0.449497; batch adversarial loss: 0.554466\n",
      "epoch 72; iter: 0; batch classifier loss: 0.370993; batch adversarial loss: 0.486409\n",
      "epoch 73; iter: 0; batch classifier loss: 0.409609; batch adversarial loss: 0.525222\n",
      "epoch 74; iter: 0; batch classifier loss: 0.359534; batch adversarial loss: 0.588767\n",
      "epoch 75; iter: 0; batch classifier loss: 0.429234; batch adversarial loss: 0.498110\n",
      "epoch 76; iter: 0; batch classifier loss: 0.330085; batch adversarial loss: 0.554368\n",
      "epoch 77; iter: 0; batch classifier loss: 0.443048; batch adversarial loss: 0.553989\n",
      "epoch 78; iter: 0; batch classifier loss: 0.362953; batch adversarial loss: 0.449951\n",
      "epoch 79; iter: 0; batch classifier loss: 0.417557; batch adversarial loss: 0.515873\n",
      "epoch 80; iter: 0; batch classifier loss: 0.394229; batch adversarial loss: 0.496908\n",
      "epoch 81; iter: 0; batch classifier loss: 0.399748; batch adversarial loss: 0.569508\n",
      "epoch 82; iter: 0; batch classifier loss: 0.423798; batch adversarial loss: 0.505348\n",
      "epoch 83; iter: 0; batch classifier loss: 0.363956; batch adversarial loss: 0.598331\n",
      "epoch 84; iter: 0; batch classifier loss: 0.378068; batch adversarial loss: 0.596229\n",
      "epoch 85; iter: 0; batch classifier loss: 0.383960; batch adversarial loss: 0.506825\n",
      "epoch 86; iter: 0; batch classifier loss: 0.352255; batch adversarial loss: 0.507468\n",
      "epoch 87; iter: 0; batch classifier loss: 0.433053; batch adversarial loss: 0.532676\n",
      "epoch 88; iter: 0; batch classifier loss: 0.358375; batch adversarial loss: 0.478205\n",
      "epoch 89; iter: 0; batch classifier loss: 0.351220; batch adversarial loss: 0.551568\n",
      "epoch 90; iter: 0; batch classifier loss: 0.364563; batch adversarial loss: 0.551911\n",
      "epoch 91; iter: 0; batch classifier loss: 0.301814; batch adversarial loss: 0.537699\n",
      "epoch 92; iter: 0; batch classifier loss: 0.372965; batch adversarial loss: 0.543288\n",
      "epoch 93; iter: 0; batch classifier loss: 0.536624; batch adversarial loss: 0.551751\n",
      "epoch 94; iter: 0; batch classifier loss: 0.360858; batch adversarial loss: 0.541614\n",
      "epoch 95; iter: 0; batch classifier loss: 0.416508; batch adversarial loss: 0.601991\n",
      "epoch 96; iter: 0; batch classifier loss: 0.385510; batch adversarial loss: 0.533913\n",
      "epoch 97; iter: 0; batch classifier loss: 0.346219; batch adversarial loss: 0.541764\n",
      "epoch 98; iter: 0; batch classifier loss: 0.399897; batch adversarial loss: 0.464782\n",
      "epoch 99; iter: 0; batch classifier loss: 0.428718; batch adversarial loss: 0.510504\n",
      "epoch 100; iter: 0; batch classifier loss: 0.379268; batch adversarial loss: 0.507530\n",
      "epoch 101; iter: 0; batch classifier loss: 0.315160; batch adversarial loss: 0.600598\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 102; iter: 0; batch classifier loss: 0.436910; batch adversarial loss: 0.487562\n",
      "epoch 103; iter: 0; batch classifier loss: 0.355685; batch adversarial loss: 0.540381\n",
      "epoch 104; iter: 0; batch classifier loss: 0.353005; batch adversarial loss: 0.492897\n",
      "epoch 105; iter: 0; batch classifier loss: 0.387338; batch adversarial loss: 0.594938\n",
      "epoch 106; iter: 0; batch classifier loss: 0.414332; batch adversarial loss: 0.572527\n",
      "epoch 107; iter: 0; batch classifier loss: 0.385035; batch adversarial loss: 0.505478\n",
      "epoch 108; iter: 0; batch classifier loss: 0.393027; batch adversarial loss: 0.545371\n",
      "epoch 109; iter: 0; batch classifier loss: 0.419917; batch adversarial loss: 0.479586\n",
      "epoch 110; iter: 0; batch classifier loss: 0.365091; batch adversarial loss: 0.575508\n",
      "epoch 111; iter: 0; batch classifier loss: 0.363546; batch adversarial loss: 0.549188\n",
      "epoch 112; iter: 0; batch classifier loss: 0.378489; batch adversarial loss: 0.465986\n",
      "epoch 113; iter: 0; batch classifier loss: 0.378294; batch adversarial loss: 0.502741\n",
      "epoch 114; iter: 0; batch classifier loss: 0.384135; batch adversarial loss: 0.555220\n",
      "epoch 115; iter: 0; batch classifier loss: 0.333264; batch adversarial loss: 0.536356\n",
      "epoch 116; iter: 0; batch classifier loss: 0.432826; batch adversarial loss: 0.530666\n",
      "epoch 117; iter: 0; batch classifier loss: 0.441724; batch adversarial loss: 0.534307\n",
      "epoch 118; iter: 0; batch classifier loss: 0.377389; batch adversarial loss: 0.471132\n",
      "epoch 119; iter: 0; batch classifier loss: 0.364676; batch adversarial loss: 0.588090\n",
      "epoch 120; iter: 0; batch classifier loss: 0.344550; batch adversarial loss: 0.522878\n",
      "epoch 121; iter: 0; batch classifier loss: 0.392069; batch adversarial loss: 0.545005\n",
      "epoch 122; iter: 0; batch classifier loss: 0.448545; batch adversarial loss: 0.556026\n",
      "epoch 123; iter: 0; batch classifier loss: 0.459427; batch adversarial loss: 0.505950\n",
      "epoch 124; iter: 0; batch classifier loss: 0.377572; batch adversarial loss: 0.556739\n",
      "epoch 125; iter: 0; batch classifier loss: 0.361819; batch adversarial loss: 0.456652\n",
      "epoch 126; iter: 0; batch classifier loss: 0.294926; batch adversarial loss: 0.541832\n",
      "epoch 127; iter: 0; batch classifier loss: 0.341682; batch adversarial loss: 0.554847\n",
      "epoch 128; iter: 0; batch classifier loss: 0.338960; batch adversarial loss: 0.574143\n",
      "epoch 129; iter: 0; batch classifier loss: 0.373385; batch adversarial loss: 0.449458\n",
      "epoch 130; iter: 0; batch classifier loss: 0.404384; batch adversarial loss: 0.505242\n",
      "epoch 131; iter: 0; batch classifier loss: 0.389259; batch adversarial loss: 0.518925\n",
      "epoch 132; iter: 0; batch classifier loss: 0.367323; batch adversarial loss: 0.522994\n",
      "epoch 133; iter: 0; batch classifier loss: 0.302210; batch adversarial loss: 0.598149\n",
      "epoch 134; iter: 0; batch classifier loss: 0.379605; batch adversarial loss: 0.571335\n",
      "epoch 135; iter: 0; batch classifier loss: 0.369320; batch adversarial loss: 0.623843\n",
      "epoch 136; iter: 0; batch classifier loss: 0.384205; batch adversarial loss: 0.524803\n",
      "epoch 137; iter: 0; batch classifier loss: 0.375766; batch adversarial loss: 0.585893\n",
      "epoch 138; iter: 0; batch classifier loss: 0.352883; batch adversarial loss: 0.568616\n",
      "epoch 139; iter: 0; batch classifier loss: 0.418239; batch adversarial loss: 0.573794\n",
      "epoch 140; iter: 0; batch classifier loss: 0.461199; batch adversarial loss: 0.582973\n",
      "epoch 141; iter: 0; batch classifier loss: 0.311423; batch adversarial loss: 0.519003\n",
      "epoch 142; iter: 0; batch classifier loss: 0.402189; batch adversarial loss: 0.505610\n",
      "epoch 143; iter: 0; batch classifier loss: 0.344476; batch adversarial loss: 0.565383\n",
      "epoch 144; iter: 0; batch classifier loss: 0.446882; batch adversarial loss: 0.477213\n",
      "epoch 145; iter: 0; batch classifier loss: 0.365806; batch adversarial loss: 0.571253\n",
      "epoch 146; iter: 0; batch classifier loss: 0.394314; batch adversarial loss: 0.468757\n",
      "epoch 147; iter: 0; batch classifier loss: 0.472102; batch adversarial loss: 0.544330\n",
      "epoch 148; iter: 0; batch classifier loss: 0.344442; batch adversarial loss: 0.580386\n",
      "epoch 149; iter: 0; batch classifier loss: 0.400740; batch adversarial loss: 0.546079\n",
      "epoch 150; iter: 0; batch classifier loss: 0.343713; batch adversarial loss: 0.496614\n",
      "epoch 151; iter: 0; batch classifier loss: 0.295061; batch adversarial loss: 0.468955\n",
      "epoch 152; iter: 0; batch classifier loss: 0.338128; batch adversarial loss: 0.578769\n",
      "epoch 153; iter: 0; batch classifier loss: 0.383385; batch adversarial loss: 0.592355\n",
      "epoch 154; iter: 0; batch classifier loss: 0.353385; batch adversarial loss: 0.486485\n",
      "epoch 155; iter: 0; batch classifier loss: 0.392887; batch adversarial loss: 0.584704\n",
      "epoch 156; iter: 0; batch classifier loss: 0.344321; batch adversarial loss: 0.471173\n",
      "epoch 157; iter: 0; batch classifier loss: 0.326106; batch adversarial loss: 0.505111\n",
      "epoch 158; iter: 0; batch classifier loss: 0.402133; batch adversarial loss: 0.475295\n",
      "epoch 159; iter: 0; batch classifier loss: 0.303556; batch adversarial loss: 0.503283\n",
      "epoch 160; iter: 0; batch classifier loss: 0.340259; batch adversarial loss: 0.474877\n",
      "epoch 161; iter: 0; batch classifier loss: 0.333432; batch adversarial loss: 0.538295\n",
      "epoch 162; iter: 0; batch classifier loss: 0.427043; batch adversarial loss: 0.573243\n",
      "epoch 163; iter: 0; batch classifier loss: 0.325966; batch adversarial loss: 0.491153\n",
      "epoch 164; iter: 0; batch classifier loss: 0.389281; batch adversarial loss: 0.504551\n",
      "epoch 165; iter: 0; batch classifier loss: 0.381928; batch adversarial loss: 0.524365\n",
      "epoch 166; iter: 0; batch classifier loss: 0.375260; batch adversarial loss: 0.523891\n",
      "epoch 167; iter: 0; batch classifier loss: 0.294459; batch adversarial loss: 0.514075\n",
      "epoch 168; iter: 0; batch classifier loss: 0.356714; batch adversarial loss: 0.457251\n",
      "epoch 169; iter: 0; batch classifier loss: 0.316910; batch adversarial loss: 0.545321\n",
      "epoch 170; iter: 0; batch classifier loss: 0.371757; batch adversarial loss: 0.516976\n",
      "epoch 171; iter: 0; batch classifier loss: 0.393569; batch adversarial loss: 0.580186\n",
      "epoch 172; iter: 0; batch classifier loss: 0.515373; batch adversarial loss: 0.550811\n",
      "epoch 173; iter: 0; batch classifier loss: 0.377694; batch adversarial loss: 0.543021\n",
      "epoch 174; iter: 0; batch classifier loss: 0.392962; batch adversarial loss: 0.584186\n",
      "epoch 175; iter: 0; batch classifier loss: 0.389385; batch adversarial loss: 0.515637\n",
      "epoch 176; iter: 0; batch classifier loss: 0.369308; batch adversarial loss: 0.611683\n",
      "epoch 177; iter: 0; batch classifier loss: 0.453347; batch adversarial loss: 0.556448\n",
      "epoch 178; iter: 0; batch classifier loss: 0.346717; batch adversarial loss: 0.562084\n",
      "epoch 179; iter: 0; batch classifier loss: 0.418120; batch adversarial loss: 0.480672\n",
      "epoch 180; iter: 0; batch classifier loss: 0.354635; batch adversarial loss: 0.545961\n",
      "epoch 181; iter: 0; batch classifier loss: 0.291622; batch adversarial loss: 0.542229\n",
      "epoch 182; iter: 0; batch classifier loss: 0.314629; batch adversarial loss: 0.539515\n",
      "epoch 183; iter: 0; batch classifier loss: 0.429307; batch adversarial loss: 0.545395\n",
      "epoch 184; iter: 0; batch classifier loss: 0.385666; batch adversarial loss: 0.544453\n",
      "epoch 185; iter: 0; batch classifier loss: 0.405367; batch adversarial loss: 0.513578\n",
      "epoch 186; iter: 0; batch classifier loss: 0.376545; batch adversarial loss: 0.565910\n",
      "epoch 187; iter: 0; batch classifier loss: 0.346877; batch adversarial loss: 0.486996\n",
      "epoch 188; iter: 0; batch classifier loss: 0.336628; batch adversarial loss: 0.547408\n",
      "epoch 189; iter: 0; batch classifier loss: 0.334326; batch adversarial loss: 0.485677\n",
      "epoch 190; iter: 0; batch classifier loss: 0.239065; batch adversarial loss: 0.485257\n",
      "epoch 191; iter: 0; batch classifier loss: 0.381926; batch adversarial loss: 0.535785\n",
      "epoch 192; iter: 0; batch classifier loss: 0.409383; batch adversarial loss: 0.602875\n",
      "epoch 193; iter: 0; batch classifier loss: 0.463246; batch adversarial loss: 0.588086\n",
      "epoch 194; iter: 0; batch classifier loss: 0.311187; batch adversarial loss: 0.537013\n",
      "epoch 195; iter: 0; batch classifier loss: 0.353372; batch adversarial loss: 0.554729\n",
      "epoch 196; iter: 0; batch classifier loss: 0.353008; batch adversarial loss: 0.530089\n",
      "epoch 197; iter: 0; batch classifier loss: 0.362520; batch adversarial loss: 0.508234\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 198; iter: 0; batch classifier loss: 0.352188; batch adversarial loss: 0.456683\n",
      "epoch 199; iter: 0; batch classifier loss: 0.301702; batch adversarial loss: 0.537054\n",
      "epoch 0; iter: 0; batch classifier loss: 0.663173; batch adversarial loss: 0.717446\n",
      "epoch 1; iter: 0; batch classifier loss: 0.629428; batch adversarial loss: 0.694252\n",
      "epoch 2; iter: 0; batch classifier loss: 0.585170; batch adversarial loss: 0.662585\n",
      "epoch 3; iter: 0; batch classifier loss: 0.591691; batch adversarial loss: 0.637524\n",
      "epoch 4; iter: 0; batch classifier loss: 0.596693; batch adversarial loss: 0.628150\n",
      "epoch 5; iter: 0; batch classifier loss: 0.557302; batch adversarial loss: 0.622152\n",
      "epoch 6; iter: 0; batch classifier loss: 0.561008; batch adversarial loss: 0.586203\n",
      "epoch 7; iter: 0; batch classifier loss: 0.569596; batch adversarial loss: 0.613238\n",
      "epoch 8; iter: 0; batch classifier loss: 0.592711; batch adversarial loss: 0.653164\n",
      "epoch 9; iter: 0; batch classifier loss: 0.531870; batch adversarial loss: 0.626305\n",
      "epoch 10; iter: 0; batch classifier loss: 0.553674; batch adversarial loss: 0.591598\n",
      "epoch 11; iter: 0; batch classifier loss: 0.557530; batch adversarial loss: 0.563687\n",
      "epoch 12; iter: 0; batch classifier loss: 0.565717; batch adversarial loss: 0.558651\n",
      "epoch 13; iter: 0; batch classifier loss: 0.509392; batch adversarial loss: 0.540362\n",
      "epoch 14; iter: 0; batch classifier loss: 0.534303; batch adversarial loss: 0.528715\n",
      "epoch 15; iter: 0; batch classifier loss: 0.536860; batch adversarial loss: 0.583996\n",
      "epoch 16; iter: 0; batch classifier loss: 0.536209; batch adversarial loss: 0.610101\n",
      "epoch 17; iter: 0; batch classifier loss: 0.495577; batch adversarial loss: 0.613515\n",
      "epoch 18; iter: 0; batch classifier loss: 0.527465; batch adversarial loss: 0.561642\n",
      "epoch 19; iter: 0; batch classifier loss: 0.480371; batch adversarial loss: 0.630339\n",
      "epoch 20; iter: 0; batch classifier loss: 0.466942; batch adversarial loss: 0.593145\n",
      "epoch 21; iter: 0; batch classifier loss: 0.471392; batch adversarial loss: 0.563608\n",
      "epoch 22; iter: 0; batch classifier loss: 0.452498; batch adversarial loss: 0.556187\n",
      "epoch 23; iter: 0; batch classifier loss: 0.484465; batch adversarial loss: 0.595700\n",
      "epoch 24; iter: 0; batch classifier loss: 0.467286; batch adversarial loss: 0.525110\n",
      "epoch 25; iter: 0; batch classifier loss: 0.456114; batch adversarial loss: 0.562055\n",
      "epoch 26; iter: 0; batch classifier loss: 0.470766; batch adversarial loss: 0.563117\n",
      "epoch 27; iter: 0; batch classifier loss: 0.472233; batch adversarial loss: 0.538362\n",
      "epoch 28; iter: 0; batch classifier loss: 0.492580; batch adversarial loss: 0.562977\n",
      "epoch 29; iter: 0; batch classifier loss: 0.517703; batch adversarial loss: 0.537481\n",
      "epoch 30; iter: 0; batch classifier loss: 0.488132; batch adversarial loss: 0.528989\n",
      "epoch 31; iter: 0; batch classifier loss: 0.447318; batch adversarial loss: 0.486198\n",
      "epoch 32; iter: 0; batch classifier loss: 0.444761; batch adversarial loss: 0.519987\n",
      "epoch 33; iter: 0; batch classifier loss: 0.485232; batch adversarial loss: 0.571266\n",
      "epoch 34; iter: 0; batch classifier loss: 0.481682; batch adversarial loss: 0.587172\n",
      "epoch 35; iter: 0; batch classifier loss: 0.420103; batch adversarial loss: 0.528255\n",
      "epoch 36; iter: 0; batch classifier loss: 0.570252; batch adversarial loss: 0.624003\n",
      "epoch 37; iter: 0; batch classifier loss: 0.428841; batch adversarial loss: 0.684523\n",
      "epoch 38; iter: 0; batch classifier loss: 0.490740; batch adversarial loss: 0.535879\n",
      "epoch 39; iter: 0; batch classifier loss: 0.465014; batch adversarial loss: 0.581929\n",
      "epoch 40; iter: 0; batch classifier loss: 0.429613; batch adversarial loss: 0.429843\n",
      "epoch 41; iter: 0; batch classifier loss: 0.436760; batch adversarial loss: 0.579873\n",
      "epoch 42; iter: 0; batch classifier loss: 0.424112; batch adversarial loss: 0.497228\n",
      "epoch 43; iter: 0; batch classifier loss: 0.443150; batch adversarial loss: 0.598869\n",
      "epoch 44; iter: 0; batch classifier loss: 0.423632; batch adversarial loss: 0.572806\n",
      "epoch 45; iter: 0; batch classifier loss: 0.457191; batch adversarial loss: 0.525352\n",
      "epoch 46; iter: 0; batch classifier loss: 0.423892; batch adversarial loss: 0.462553\n",
      "epoch 47; iter: 0; batch classifier loss: 0.464682; batch adversarial loss: 0.519735\n",
      "epoch 48; iter: 0; batch classifier loss: 0.446109; batch adversarial loss: 0.591294\n",
      "epoch 49; iter: 0; batch classifier loss: 0.426967; batch adversarial loss: 0.554561\n",
      "epoch 50; iter: 0; batch classifier loss: 0.421492; batch adversarial loss: 0.534062\n",
      "epoch 51; iter: 0; batch classifier loss: 0.449782; batch adversarial loss: 0.550870\n",
      "epoch 52; iter: 0; batch classifier loss: 0.407384; batch adversarial loss: 0.508267\n",
      "epoch 53; iter: 0; batch classifier loss: 0.383238; batch adversarial loss: 0.589353\n",
      "epoch 54; iter: 0; batch classifier loss: 0.460134; batch adversarial loss: 0.562228\n",
      "epoch 55; iter: 0; batch classifier loss: 0.411175; batch adversarial loss: 0.511991\n",
      "epoch 56; iter: 0; batch classifier loss: 0.499348; batch adversarial loss: 0.500974\n",
      "epoch 57; iter: 0; batch classifier loss: 0.522158; batch adversarial loss: 0.517923\n",
      "epoch 58; iter: 0; batch classifier loss: 0.443495; batch adversarial loss: 0.546281\n",
      "epoch 59; iter: 0; batch classifier loss: 0.364592; batch adversarial loss: 0.536743\n",
      "epoch 60; iter: 0; batch classifier loss: 0.308606; batch adversarial loss: 0.552817\n",
      "epoch 61; iter: 0; batch classifier loss: 0.492663; batch adversarial loss: 0.544248\n",
      "epoch 62; iter: 0; batch classifier loss: 0.416237; batch adversarial loss: 0.518552\n",
      "epoch 63; iter: 0; batch classifier loss: 0.362886; batch adversarial loss: 0.626405\n",
      "epoch 64; iter: 0; batch classifier loss: 0.395656; batch adversarial loss: 0.573559\n",
      "epoch 65; iter: 0; batch classifier loss: 0.405020; batch adversarial loss: 0.473191\n",
      "epoch 66; iter: 0; batch classifier loss: 0.364559; batch adversarial loss: 0.454880\n",
      "epoch 67; iter: 0; batch classifier loss: 0.355475; batch adversarial loss: 0.575088\n",
      "epoch 68; iter: 0; batch classifier loss: 0.437355; batch adversarial loss: 0.563146\n",
      "epoch 69; iter: 0; batch classifier loss: 0.458872; batch adversarial loss: 0.554927\n",
      "epoch 70; iter: 0; batch classifier loss: 0.380172; batch adversarial loss: 0.643026\n",
      "epoch 71; iter: 0; batch classifier loss: 0.332656; batch adversarial loss: 0.534901\n",
      "epoch 72; iter: 0; batch classifier loss: 0.398582; batch adversarial loss: 0.632377\n",
      "epoch 73; iter: 0; batch classifier loss: 0.389435; batch adversarial loss: 0.590624\n",
      "epoch 74; iter: 0; batch classifier loss: 0.517895; batch adversarial loss: 0.552134\n",
      "epoch 75; iter: 0; batch classifier loss: 0.385671; batch adversarial loss: 0.625374\n",
      "epoch 76; iter: 0; batch classifier loss: 0.329722; batch adversarial loss: 0.547218\n",
      "epoch 77; iter: 0; batch classifier loss: 0.393152; batch adversarial loss: 0.520737\n",
      "epoch 78; iter: 0; batch classifier loss: 0.341154; batch adversarial loss: 0.548676\n",
      "epoch 79; iter: 0; batch classifier loss: 0.426788; batch adversarial loss: 0.599313\n",
      "epoch 80; iter: 0; batch classifier loss: 0.447018; batch adversarial loss: 0.552938\n",
      "epoch 81; iter: 0; batch classifier loss: 0.408870; batch adversarial loss: 0.582375\n",
      "epoch 82; iter: 0; batch classifier loss: 0.407298; batch adversarial loss: 0.537198\n",
      "epoch 83; iter: 0; batch classifier loss: 0.393284; batch adversarial loss: 0.616439\n",
      "epoch 84; iter: 0; batch classifier loss: 0.406148; batch adversarial loss: 0.525549\n",
      "epoch 85; iter: 0; batch classifier loss: 0.454301; batch adversarial loss: 0.571522\n",
      "epoch 86; iter: 0; batch classifier loss: 0.395019; batch adversarial loss: 0.554536\n",
      "epoch 87; iter: 0; batch classifier loss: 0.486625; batch adversarial loss: 0.508423\n",
      "epoch 88; iter: 0; batch classifier loss: 0.392741; batch adversarial loss: 0.584984\n",
      "epoch 89; iter: 0; batch classifier loss: 0.365410; batch adversarial loss: 0.517793\n",
      "epoch 90; iter: 0; batch classifier loss: 0.475687; batch adversarial loss: 0.463300\n",
      "epoch 91; iter: 0; batch classifier loss: 0.361543; batch adversarial loss: 0.479136\n",
      "epoch 92; iter: 0; batch classifier loss: 0.322357; batch adversarial loss: 0.542325\n",
      "epoch 93; iter: 0; batch classifier loss: 0.436692; batch adversarial loss: 0.510263\n",
      "epoch 94; iter: 0; batch classifier loss: 0.416285; batch adversarial loss: 0.588692\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 95; iter: 0; batch classifier loss: 0.371166; batch adversarial loss: 0.562349\n",
      "epoch 96; iter: 0; batch classifier loss: 0.339943; batch adversarial loss: 0.501663\n",
      "epoch 97; iter: 0; batch classifier loss: 0.388770; batch adversarial loss: 0.593966\n",
      "epoch 98; iter: 0; batch classifier loss: 0.361677; batch adversarial loss: 0.554915\n",
      "epoch 99; iter: 0; batch classifier loss: 0.446969; batch adversarial loss: 0.514815\n",
      "epoch 100; iter: 0; batch classifier loss: 0.370753; batch adversarial loss: 0.551883\n",
      "epoch 101; iter: 0; batch classifier loss: 0.377626; batch adversarial loss: 0.588781\n",
      "epoch 102; iter: 0; batch classifier loss: 0.416638; batch adversarial loss: 0.670124\n",
      "epoch 103; iter: 0; batch classifier loss: 0.358012; batch adversarial loss: 0.526169\n",
      "epoch 104; iter: 0; batch classifier loss: 0.383390; batch adversarial loss: 0.497812\n",
      "epoch 105; iter: 0; batch classifier loss: 0.412488; batch adversarial loss: 0.572868\n",
      "epoch 106; iter: 0; batch classifier loss: 0.367864; batch adversarial loss: 0.461250\n",
      "epoch 107; iter: 0; batch classifier loss: 0.361349; batch adversarial loss: 0.577706\n",
      "epoch 108; iter: 0; batch classifier loss: 0.537437; batch adversarial loss: 0.525650\n",
      "epoch 109; iter: 0; batch classifier loss: 0.437117; batch adversarial loss: 0.533350\n",
      "epoch 110; iter: 0; batch classifier loss: 0.408350; batch adversarial loss: 0.588139\n",
      "epoch 111; iter: 0; batch classifier loss: 0.333051; batch adversarial loss: 0.562349\n",
      "epoch 112; iter: 0; batch classifier loss: 0.346582; batch adversarial loss: 0.589803\n",
      "epoch 113; iter: 0; batch classifier loss: 0.371689; batch adversarial loss: 0.586742\n",
      "epoch 114; iter: 0; batch classifier loss: 0.306581; batch adversarial loss: 0.518471\n",
      "epoch 115; iter: 0; batch classifier loss: 0.412047; batch adversarial loss: 0.560784\n",
      "epoch 116; iter: 0; batch classifier loss: 0.400985; batch adversarial loss: 0.649884\n",
      "epoch 117; iter: 0; batch classifier loss: 0.414028; batch adversarial loss: 0.594664\n",
      "epoch 118; iter: 0; batch classifier loss: 0.308243; batch adversarial loss: 0.535422\n",
      "epoch 119; iter: 0; batch classifier loss: 0.385114; batch adversarial loss: 0.561791\n",
      "epoch 120; iter: 0; batch classifier loss: 0.428184; batch adversarial loss: 0.615852\n",
      "epoch 121; iter: 0; batch classifier loss: 0.271477; batch adversarial loss: 0.645579\n",
      "epoch 122; iter: 0; batch classifier loss: 0.418923; batch adversarial loss: 0.542809\n",
      "epoch 123; iter: 0; batch classifier loss: 0.339857; batch adversarial loss: 0.563403\n",
      "epoch 124; iter: 0; batch classifier loss: 0.303747; batch adversarial loss: 0.523372\n",
      "epoch 125; iter: 0; batch classifier loss: 0.372733; batch adversarial loss: 0.544576\n",
      "epoch 126; iter: 0; batch classifier loss: 0.458992; batch adversarial loss: 0.602282\n",
      "epoch 127; iter: 0; batch classifier loss: 0.342917; batch adversarial loss: 0.568909\n",
      "epoch 128; iter: 0; batch classifier loss: 0.460962; batch adversarial loss: 0.564461\n",
      "epoch 129; iter: 0; batch classifier loss: 0.304471; batch adversarial loss: 0.610302\n",
      "epoch 130; iter: 0; batch classifier loss: 0.405312; batch adversarial loss: 0.557363\n",
      "epoch 131; iter: 0; batch classifier loss: 0.427530; batch adversarial loss: 0.535705\n",
      "epoch 132; iter: 0; batch classifier loss: 0.376402; batch adversarial loss: 0.553377\n",
      "epoch 133; iter: 0; batch classifier loss: 0.348292; batch adversarial loss: 0.544356\n",
      "epoch 134; iter: 0; batch classifier loss: 0.393903; batch adversarial loss: 0.563027\n",
      "epoch 135; iter: 0; batch classifier loss: 0.298899; batch adversarial loss: 0.607591\n",
      "epoch 136; iter: 0; batch classifier loss: 0.409099; batch adversarial loss: 0.506397\n",
      "epoch 137; iter: 0; batch classifier loss: 0.377019; batch adversarial loss: 0.496319\n",
      "epoch 138; iter: 0; batch classifier loss: 0.345560; batch adversarial loss: 0.486945\n",
      "epoch 139; iter: 0; batch classifier loss: 0.487767; batch adversarial loss: 0.559635\n",
      "epoch 140; iter: 0; batch classifier loss: 0.332629; batch adversarial loss: 0.505215\n",
      "epoch 141; iter: 0; batch classifier loss: 0.339235; batch adversarial loss: 0.559254\n",
      "epoch 142; iter: 0; batch classifier loss: 0.397885; batch adversarial loss: 0.558672\n",
      "epoch 143; iter: 0; batch classifier loss: 0.329479; batch adversarial loss: 0.487159\n",
      "epoch 144; iter: 0; batch classifier loss: 0.344474; batch adversarial loss: 0.555608\n",
      "epoch 145; iter: 0; batch classifier loss: 0.331069; batch adversarial loss: 0.546944\n",
      "epoch 146; iter: 0; batch classifier loss: 0.425807; batch adversarial loss: 0.551403\n",
      "epoch 147; iter: 0; batch classifier loss: 0.358455; batch adversarial loss: 0.527050\n",
      "epoch 148; iter: 0; batch classifier loss: 0.261804; batch adversarial loss: 0.665405\n",
      "epoch 149; iter: 0; batch classifier loss: 0.463510; batch adversarial loss: 0.523447\n",
      "epoch 150; iter: 0; batch classifier loss: 0.433023; batch adversarial loss: 0.545553\n",
      "epoch 151; iter: 0; batch classifier loss: 0.315012; batch adversarial loss: 0.481799\n",
      "epoch 152; iter: 0; batch classifier loss: 0.363181; batch adversarial loss: 0.532991\n",
      "epoch 153; iter: 0; batch classifier loss: 0.413573; batch adversarial loss: 0.516917\n",
      "epoch 154; iter: 0; batch classifier loss: 0.351166; batch adversarial loss: 0.518633\n",
      "epoch 155; iter: 0; batch classifier loss: 0.395493; batch adversarial loss: 0.581525\n",
      "epoch 156; iter: 0; batch classifier loss: 0.390377; batch adversarial loss: 0.453431\n",
      "epoch 157; iter: 0; batch classifier loss: 0.400849; batch adversarial loss: 0.618627\n",
      "epoch 158; iter: 0; batch classifier loss: 0.432296; batch adversarial loss: 0.632171\n",
      "epoch 159; iter: 0; batch classifier loss: 0.456560; batch adversarial loss: 0.644710\n",
      "epoch 160; iter: 0; batch classifier loss: 0.409956; batch adversarial loss: 0.526641\n",
      "epoch 161; iter: 0; batch classifier loss: 0.339735; batch adversarial loss: 0.590046\n",
      "epoch 162; iter: 0; batch classifier loss: 0.416448; batch adversarial loss: 0.530001\n",
      "epoch 163; iter: 0; batch classifier loss: 0.386676; batch adversarial loss: 0.527575\n",
      "epoch 164; iter: 0; batch classifier loss: 0.369498; batch adversarial loss: 0.481530\n",
      "epoch 165; iter: 0; batch classifier loss: 0.434913; batch adversarial loss: 0.652153\n",
      "epoch 166; iter: 0; batch classifier loss: 0.342630; batch adversarial loss: 0.537685\n",
      "epoch 167; iter: 0; batch classifier loss: 0.369821; batch adversarial loss: 0.530604\n",
      "epoch 168; iter: 0; batch classifier loss: 0.372827; batch adversarial loss: 0.544801\n",
      "epoch 169; iter: 0; batch classifier loss: 0.369090; batch adversarial loss: 0.527522\n",
      "epoch 170; iter: 0; batch classifier loss: 0.443477; batch adversarial loss: 0.487300\n",
      "epoch 171; iter: 0; batch classifier loss: 0.408080; batch adversarial loss: 0.525083\n",
      "epoch 172; iter: 0; batch classifier loss: 0.414648; batch adversarial loss: 0.635906\n",
      "epoch 173; iter: 0; batch classifier loss: 0.424738; batch adversarial loss: 0.501356\n",
      "epoch 174; iter: 0; batch classifier loss: 0.396591; batch adversarial loss: 0.560525\n",
      "epoch 175; iter: 0; batch classifier loss: 0.427795; batch adversarial loss: 0.473379\n",
      "epoch 176; iter: 0; batch classifier loss: 0.464101; batch adversarial loss: 0.508883\n",
      "epoch 177; iter: 0; batch classifier loss: 0.315185; batch adversarial loss: 0.600431\n",
      "epoch 178; iter: 0; batch classifier loss: 0.318407; batch adversarial loss: 0.473433\n",
      "epoch 179; iter: 0; batch classifier loss: 0.339200; batch adversarial loss: 0.595766\n",
      "epoch 180; iter: 0; batch classifier loss: 0.377881; batch adversarial loss: 0.632195\n",
      "epoch 181; iter: 0; batch classifier loss: 0.397731; batch adversarial loss: 0.593280\n",
      "epoch 182; iter: 0; batch classifier loss: 0.356030; batch adversarial loss: 0.523004\n",
      "epoch 183; iter: 0; batch classifier loss: 0.367225; batch adversarial loss: 0.498634\n",
      "epoch 184; iter: 0; batch classifier loss: 0.394482; batch adversarial loss: 0.560259\n",
      "epoch 185; iter: 0; batch classifier loss: 0.375593; batch adversarial loss: 0.482193\n",
      "epoch 186; iter: 0; batch classifier loss: 0.407063; batch adversarial loss: 0.469187\n",
      "epoch 187; iter: 0; batch classifier loss: 0.409868; batch adversarial loss: 0.553300\n",
      "epoch 188; iter: 0; batch classifier loss: 0.410305; batch adversarial loss: 0.556607\n",
      "epoch 189; iter: 0; batch classifier loss: 0.366815; batch adversarial loss: 0.511440\n",
      "epoch 190; iter: 0; batch classifier loss: 0.390476; batch adversarial loss: 0.562184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 191; iter: 0; batch classifier loss: 0.287073; batch adversarial loss: 0.511470\n",
      "epoch 192; iter: 0; batch classifier loss: 0.406785; batch adversarial loss: 0.480725\n",
      "epoch 193; iter: 0; batch classifier loss: 0.442240; batch adversarial loss: 0.581412\n",
      "epoch 194; iter: 0; batch classifier loss: 0.477106; batch adversarial loss: 0.551792\n",
      "epoch 195; iter: 0; batch classifier loss: 0.376784; batch adversarial loss: 0.499766\n",
      "epoch 196; iter: 0; batch classifier loss: 0.398664; batch adversarial loss: 0.555714\n",
      "epoch 197; iter: 0; batch classifier loss: 0.366215; batch adversarial loss: 0.554094\n",
      "epoch 198; iter: 0; batch classifier loss: 0.392655; batch adversarial loss: 0.570348\n",
      "epoch 199; iter: 0; batch classifier loss: 0.326788; batch adversarial loss: 0.609042\n",
      "epoch 0; iter: 0; batch classifier loss: 0.728271; batch adversarial loss: 0.752052\n",
      "epoch 1; iter: 0; batch classifier loss: 0.703436; batch adversarial loss: 0.726993\n",
      "epoch 2; iter: 0; batch classifier loss: 0.708489; batch adversarial loss: 0.686998\n",
      "epoch 3; iter: 0; batch classifier loss: 0.531476; batch adversarial loss: 0.646485\n",
      "epoch 4; iter: 0; batch classifier loss: 0.617932; batch adversarial loss: 0.634958\n",
      "epoch 5; iter: 0; batch classifier loss: 0.579667; batch adversarial loss: 0.635954\n",
      "epoch 6; iter: 0; batch classifier loss: 0.590903; batch adversarial loss: 0.621600\n",
      "epoch 7; iter: 0; batch classifier loss: 0.532435; batch adversarial loss: 0.617405\n",
      "epoch 8; iter: 0; batch classifier loss: 0.537103; batch adversarial loss: 0.619222\n",
      "epoch 9; iter: 0; batch classifier loss: 0.484018; batch adversarial loss: 0.605026\n",
      "epoch 10; iter: 0; batch classifier loss: 0.540579; batch adversarial loss: 0.607836\n",
      "epoch 11; iter: 0; batch classifier loss: 0.531866; batch adversarial loss: 0.558611\n",
      "epoch 12; iter: 0; batch classifier loss: 0.522517; batch adversarial loss: 0.599376\n",
      "epoch 13; iter: 0; batch classifier loss: 0.565359; batch adversarial loss: 0.561841\n",
      "epoch 14; iter: 0; batch classifier loss: 0.514694; batch adversarial loss: 0.614265\n",
      "epoch 15; iter: 0; batch classifier loss: 0.523991; batch adversarial loss: 0.507479\n",
      "epoch 16; iter: 0; batch classifier loss: 0.512517; batch adversarial loss: 0.565803\n",
      "epoch 17; iter: 0; batch classifier loss: 0.554168; batch adversarial loss: 0.524888\n",
      "epoch 18; iter: 0; batch classifier loss: 0.578533; batch adversarial loss: 0.546295\n",
      "epoch 19; iter: 0; batch classifier loss: 0.515122; batch adversarial loss: 0.556475\n",
      "epoch 20; iter: 0; batch classifier loss: 0.493773; batch adversarial loss: 0.569814\n",
      "epoch 21; iter: 0; batch classifier loss: 0.516332; batch adversarial loss: 0.560204\n",
      "epoch 22; iter: 0; batch classifier loss: 0.484182; batch adversarial loss: 0.605708\n",
      "epoch 23; iter: 0; batch classifier loss: 0.559580; batch adversarial loss: 0.508823\n",
      "epoch 24; iter: 0; batch classifier loss: 0.448502; batch adversarial loss: 0.520501\n",
      "epoch 25; iter: 0; batch classifier loss: 0.483585; batch adversarial loss: 0.565090\n",
      "epoch 26; iter: 0; batch classifier loss: 0.495658; batch adversarial loss: 0.521071\n",
      "epoch 27; iter: 0; batch classifier loss: 0.518821; batch adversarial loss: 0.529528\n",
      "epoch 28; iter: 0; batch classifier loss: 0.474403; batch adversarial loss: 0.517594\n",
      "epoch 29; iter: 0; batch classifier loss: 0.506715; batch adversarial loss: 0.551161\n",
      "epoch 30; iter: 0; batch classifier loss: 0.477857; batch adversarial loss: 0.522585\n",
      "epoch 31; iter: 0; batch classifier loss: 0.410434; batch adversarial loss: 0.664383\n",
      "epoch 32; iter: 0; batch classifier loss: 0.410352; batch adversarial loss: 0.625473\n",
      "epoch 33; iter: 0; batch classifier loss: 0.437980; batch adversarial loss: 0.492574\n",
      "epoch 34; iter: 0; batch classifier loss: 0.523977; batch adversarial loss: 0.562780\n",
      "epoch 35; iter: 0; batch classifier loss: 0.538595; batch adversarial loss: 0.502611\n",
      "epoch 36; iter: 0; batch classifier loss: 0.405316; batch adversarial loss: 0.520338\n",
      "epoch 37; iter: 0; batch classifier loss: 0.493785; batch adversarial loss: 0.580888\n",
      "epoch 38; iter: 0; batch classifier loss: 0.407015; batch adversarial loss: 0.562588\n",
      "epoch 39; iter: 0; batch classifier loss: 0.383459; batch adversarial loss: 0.536674\n",
      "epoch 40; iter: 0; batch classifier loss: 0.469888; batch adversarial loss: 0.562803\n",
      "epoch 41; iter: 0; batch classifier loss: 0.449993; batch adversarial loss: 0.536139\n",
      "epoch 42; iter: 0; batch classifier loss: 0.448437; batch adversarial loss: 0.535866\n",
      "epoch 43; iter: 0; batch classifier loss: 0.394035; batch adversarial loss: 0.517723\n",
      "epoch 44; iter: 0; batch classifier loss: 0.484567; batch adversarial loss: 0.463414\n",
      "epoch 45; iter: 0; batch classifier loss: 0.401632; batch adversarial loss: 0.607857\n",
      "epoch 46; iter: 0; batch classifier loss: 0.432103; batch adversarial loss: 0.580750\n",
      "epoch 47; iter: 0; batch classifier loss: 0.420591; batch adversarial loss: 0.516994\n",
      "epoch 48; iter: 0; batch classifier loss: 0.471822; batch adversarial loss: 0.691505\n",
      "epoch 49; iter: 0; batch classifier loss: 0.409133; batch adversarial loss: 0.462676\n",
      "epoch 50; iter: 0; batch classifier loss: 0.416926; batch adversarial loss: 0.599247\n",
      "epoch 51; iter: 0; batch classifier loss: 0.446856; batch adversarial loss: 0.535470\n",
      "epoch 52; iter: 0; batch classifier loss: 0.424604; batch adversarial loss: 0.553479\n",
      "epoch 53; iter: 0; batch classifier loss: 0.471548; batch adversarial loss: 0.534813\n",
      "epoch 54; iter: 0; batch classifier loss: 0.482705; batch adversarial loss: 0.609116\n",
      "epoch 55; iter: 0; batch classifier loss: 0.379447; batch adversarial loss: 0.582435\n",
      "epoch 56; iter: 0; batch classifier loss: 0.467532; batch adversarial loss: 0.553161\n",
      "epoch 57; iter: 0; batch classifier loss: 0.454579; batch adversarial loss: 0.544206\n",
      "epoch 58; iter: 0; batch classifier loss: 0.466549; batch adversarial loss: 0.544983\n",
      "epoch 59; iter: 0; batch classifier loss: 0.389351; batch adversarial loss: 0.461024\n",
      "epoch 60; iter: 0; batch classifier loss: 0.441601; batch adversarial loss: 0.572640\n",
      "epoch 61; iter: 0; batch classifier loss: 0.468803; batch adversarial loss: 0.517398\n",
      "epoch 62; iter: 0; batch classifier loss: 0.408131; batch adversarial loss: 0.527228\n",
      "epoch 63; iter: 0; batch classifier loss: 0.369560; batch adversarial loss: 0.489642\n",
      "epoch 64; iter: 0; batch classifier loss: 0.357996; batch adversarial loss: 0.655933\n",
      "epoch 65; iter: 0; batch classifier loss: 0.367122; batch adversarial loss: 0.526737\n",
      "epoch 66; iter: 0; batch classifier loss: 0.376677; batch adversarial loss: 0.626951\n",
      "epoch 67; iter: 0; batch classifier loss: 0.358706; batch adversarial loss: 0.489517\n",
      "epoch 68; iter: 0; batch classifier loss: 0.406537; batch adversarial loss: 0.545302\n",
      "epoch 69; iter: 0; batch classifier loss: 0.481684; batch adversarial loss: 0.505420\n",
      "epoch 70; iter: 0; batch classifier loss: 0.336382; batch adversarial loss: 0.515443\n",
      "epoch 71; iter: 0; batch classifier loss: 0.342909; batch adversarial loss: 0.645249\n",
      "epoch 72; iter: 0; batch classifier loss: 0.390147; batch adversarial loss: 0.489217\n",
      "epoch 73; iter: 0; batch classifier loss: 0.478738; batch adversarial loss: 0.534565\n",
      "epoch 74; iter: 0; batch classifier loss: 0.410829; batch adversarial loss: 0.508563\n",
      "epoch 75; iter: 0; batch classifier loss: 0.370295; batch adversarial loss: 0.546196\n",
      "epoch 76; iter: 0; batch classifier loss: 0.382836; batch adversarial loss: 0.600323\n",
      "epoch 77; iter: 0; batch classifier loss: 0.448404; batch adversarial loss: 0.536052\n",
      "epoch 78; iter: 0; batch classifier loss: 0.354509; batch adversarial loss: 0.563561\n",
      "epoch 79; iter: 0; batch classifier loss: 0.382931; batch adversarial loss: 0.580644\n",
      "epoch 80; iter: 0; batch classifier loss: 0.432846; batch adversarial loss: 0.543881\n",
      "epoch 81; iter: 0; batch classifier loss: 0.350270; batch adversarial loss: 0.480091\n",
      "epoch 82; iter: 0; batch classifier loss: 0.407218; batch adversarial loss: 0.572546\n",
      "epoch 83; iter: 0; batch classifier loss: 0.365743; batch adversarial loss: 0.527798\n",
      "epoch 84; iter: 0; batch classifier loss: 0.442493; batch adversarial loss: 0.426058\n",
      "epoch 85; iter: 0; batch classifier loss: 0.443484; batch adversarial loss: 0.544907\n",
      "epoch 86; iter: 0; batch classifier loss: 0.388953; batch adversarial loss: 0.553398\n",
      "epoch 87; iter: 0; batch classifier loss: 0.356076; batch adversarial loss: 0.571084\n",
      "epoch 88; iter: 0; batch classifier loss: 0.362583; batch adversarial loss: 0.478621\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 89; iter: 0; batch classifier loss: 0.344352; batch adversarial loss: 0.561695\n",
      "epoch 90; iter: 0; batch classifier loss: 0.355953; batch adversarial loss: 0.592403\n",
      "epoch 91; iter: 0; batch classifier loss: 0.395438; batch adversarial loss: 0.561635\n",
      "epoch 92; iter: 0; batch classifier loss: 0.326980; batch adversarial loss: 0.526070\n",
      "epoch 93; iter: 0; batch classifier loss: 0.436468; batch adversarial loss: 0.573399\n",
      "epoch 94; iter: 0; batch classifier loss: 0.497746; batch adversarial loss: 0.536229\n",
      "epoch 95; iter: 0; batch classifier loss: 0.415700; batch adversarial loss: 0.609299\n",
      "epoch 96; iter: 0; batch classifier loss: 0.332157; batch adversarial loss: 0.616838\n",
      "epoch 97; iter: 0; batch classifier loss: 0.354044; batch adversarial loss: 0.506172\n",
      "epoch 98; iter: 0; batch classifier loss: 0.428004; batch adversarial loss: 0.432458\n",
      "epoch 99; iter: 0; batch classifier loss: 0.368731; batch adversarial loss: 0.537040\n",
      "epoch 100; iter: 0; batch classifier loss: 0.339723; batch adversarial loss: 0.627724\n",
      "epoch 101; iter: 0; batch classifier loss: 0.413733; batch adversarial loss: 0.471934\n",
      "epoch 102; iter: 0; batch classifier loss: 0.415934; batch adversarial loss: 0.479800\n",
      "epoch 103; iter: 0; batch classifier loss: 0.400510; batch adversarial loss: 0.527187\n",
      "epoch 104; iter: 0; batch classifier loss: 0.436805; batch adversarial loss: 0.498569\n",
      "epoch 105; iter: 0; batch classifier loss: 0.371699; batch adversarial loss: 0.536107\n",
      "epoch 106; iter: 0; batch classifier loss: 0.379384; batch adversarial loss: 0.572707\n",
      "epoch 107; iter: 0; batch classifier loss: 0.396689; batch adversarial loss: 0.571493\n",
      "epoch 108; iter: 0; batch classifier loss: 0.381342; batch adversarial loss: 0.535929\n",
      "epoch 109; iter: 0; batch classifier loss: 0.420073; batch adversarial loss: 0.544536\n",
      "epoch 110; iter: 0; batch classifier loss: 0.379272; batch adversarial loss: 0.524367\n",
      "epoch 111; iter: 0; batch classifier loss: 0.380993; batch adversarial loss: 0.598864\n",
      "epoch 112; iter: 0; batch classifier loss: 0.366595; batch adversarial loss: 0.608720\n",
      "epoch 113; iter: 0; batch classifier loss: 0.326269; batch adversarial loss: 0.582214\n",
      "epoch 114; iter: 0; batch classifier loss: 0.346480; batch adversarial loss: 0.487816\n",
      "epoch 115; iter: 0; batch classifier loss: 0.419531; batch adversarial loss: 0.543599\n",
      "epoch 116; iter: 0; batch classifier loss: 0.418993; batch adversarial loss: 0.562248\n",
      "epoch 117; iter: 0; batch classifier loss: 0.349896; batch adversarial loss: 0.582201\n",
      "epoch 118; iter: 0; batch classifier loss: 0.457451; batch adversarial loss: 0.525388\n",
      "epoch 119; iter: 0; batch classifier loss: 0.396970; batch adversarial loss: 0.578926\n",
      "epoch 120; iter: 0; batch classifier loss: 0.429370; batch adversarial loss: 0.648348\n",
      "epoch 121; iter: 0; batch classifier loss: 0.311546; batch adversarial loss: 0.564413\n",
      "epoch 122; iter: 0; batch classifier loss: 0.376258; batch adversarial loss: 0.506953\n",
      "epoch 123; iter: 0; batch classifier loss: 0.359779; batch adversarial loss: 0.545630\n",
      "epoch 124; iter: 0; batch classifier loss: 0.432639; batch adversarial loss: 0.525414\n",
      "epoch 125; iter: 0; batch classifier loss: 0.371371; batch adversarial loss: 0.592273\n",
      "epoch 126; iter: 0; batch classifier loss: 0.374559; batch adversarial loss: 0.545514\n",
      "epoch 127; iter: 0; batch classifier loss: 0.331878; batch adversarial loss: 0.562450\n",
      "epoch 128; iter: 0; batch classifier loss: 0.334145; batch adversarial loss: 0.574504\n",
      "epoch 129; iter: 0; batch classifier loss: 0.385022; batch adversarial loss: 0.553136\n",
      "epoch 130; iter: 0; batch classifier loss: 0.398277; batch adversarial loss: 0.554309\n",
      "epoch 131; iter: 0; batch classifier loss: 0.406826; batch adversarial loss: 0.479724\n",
      "epoch 132; iter: 0; batch classifier loss: 0.385033; batch adversarial loss: 0.581272\n",
      "epoch 133; iter: 0; batch classifier loss: 0.312422; batch adversarial loss: 0.580196\n",
      "epoch 134; iter: 0; batch classifier loss: 0.426178; batch adversarial loss: 0.601447\n",
      "epoch 135; iter: 0; batch classifier loss: 0.389618; batch adversarial loss: 0.553684\n",
      "epoch 136; iter: 0; batch classifier loss: 0.429798; batch adversarial loss: 0.498916\n",
      "epoch 137; iter: 0; batch classifier loss: 0.396118; batch adversarial loss: 0.581568\n",
      "epoch 138; iter: 0; batch classifier loss: 0.385360; batch adversarial loss: 0.543021\n",
      "epoch 139; iter: 0; batch classifier loss: 0.334251; batch adversarial loss: 0.544465\n",
      "epoch 140; iter: 0; batch classifier loss: 0.315435; batch adversarial loss: 0.544444\n",
      "epoch 141; iter: 0; batch classifier loss: 0.399707; batch adversarial loss: 0.499121\n",
      "epoch 142; iter: 0; batch classifier loss: 0.445746; batch adversarial loss: 0.453350\n",
      "epoch 143; iter: 0; batch classifier loss: 0.359814; batch adversarial loss: 0.508109\n",
      "epoch 144; iter: 0; batch classifier loss: 0.346271; batch adversarial loss: 0.471274\n",
      "epoch 145; iter: 0; batch classifier loss: 0.343325; batch adversarial loss: 0.553127\n",
      "epoch 146; iter: 0; batch classifier loss: 0.307156; batch adversarial loss: 0.602456\n",
      "epoch 147; iter: 0; batch classifier loss: 0.328975; batch adversarial loss: 0.459255\n",
      "epoch 148; iter: 0; batch classifier loss: 0.318415; batch adversarial loss: 0.535022\n",
      "epoch 149; iter: 0; batch classifier loss: 0.325821; batch adversarial loss: 0.490471\n",
      "epoch 150; iter: 0; batch classifier loss: 0.444903; batch adversarial loss: 0.581877\n",
      "epoch 151; iter: 0; batch classifier loss: 0.300135; batch adversarial loss: 0.533575\n",
      "epoch 152; iter: 0; batch classifier loss: 0.361720; batch adversarial loss: 0.505922\n",
      "epoch 153; iter: 0; batch classifier loss: 0.355920; batch adversarial loss: 0.554107\n",
      "epoch 154; iter: 0; batch classifier loss: 0.331119; batch adversarial loss: 0.543672\n",
      "epoch 155; iter: 0; batch classifier loss: 0.471865; batch adversarial loss: 0.517641\n",
      "epoch 156; iter: 0; batch classifier loss: 0.355058; batch adversarial loss: 0.506374\n",
      "epoch 157; iter: 0; batch classifier loss: 0.313735; batch adversarial loss: 0.490165\n",
      "epoch 158; iter: 0; batch classifier loss: 0.397311; batch adversarial loss: 0.562273\n",
      "epoch 159; iter: 0; batch classifier loss: 0.400815; batch adversarial loss: 0.601835\n",
      "epoch 160; iter: 0; batch classifier loss: 0.339780; batch adversarial loss: 0.506789\n",
      "epoch 161; iter: 0; batch classifier loss: 0.432850; batch adversarial loss: 0.553554\n",
      "epoch 162; iter: 0; batch classifier loss: 0.385038; batch adversarial loss: 0.535845\n",
      "epoch 163; iter: 0; batch classifier loss: 0.263327; batch adversarial loss: 0.570288\n",
      "epoch 164; iter: 0; batch classifier loss: 0.422243; batch adversarial loss: 0.554396\n",
      "epoch 165; iter: 0; batch classifier loss: 0.376445; batch adversarial loss: 0.525349\n",
      "epoch 166; iter: 0; batch classifier loss: 0.371052; batch adversarial loss: 0.561697\n",
      "epoch 167; iter: 0; batch classifier loss: 0.387218; batch adversarial loss: 0.544774\n",
      "epoch 168; iter: 0; batch classifier loss: 0.340889; batch adversarial loss: 0.507925\n",
      "epoch 169; iter: 0; batch classifier loss: 0.357081; batch adversarial loss: 0.489267\n",
      "epoch 170; iter: 0; batch classifier loss: 0.354437; batch adversarial loss: 0.542198\n",
      "epoch 171; iter: 0; batch classifier loss: 0.345785; batch adversarial loss: 0.573749\n",
      "epoch 172; iter: 0; batch classifier loss: 0.363004; batch adversarial loss: 0.479894\n",
      "epoch 173; iter: 0; batch classifier loss: 0.348860; batch adversarial loss: 0.525575\n",
      "epoch 174; iter: 0; batch classifier loss: 0.355155; batch adversarial loss: 0.451276\n",
      "epoch 175; iter: 0; batch classifier loss: 0.343725; batch adversarial loss: 0.553302\n",
      "epoch 176; iter: 0; batch classifier loss: 0.319204; batch adversarial loss: 0.611185\n",
      "epoch 177; iter: 0; batch classifier loss: 0.383821; batch adversarial loss: 0.620174\n",
      "epoch 178; iter: 0; batch classifier loss: 0.330248; batch adversarial loss: 0.579725\n",
      "epoch 179; iter: 0; batch classifier loss: 0.363531; batch adversarial loss: 0.536054\n",
      "epoch 180; iter: 0; batch classifier loss: 0.324805; batch adversarial loss: 0.469205\n",
      "epoch 181; iter: 0; batch classifier loss: 0.367007; batch adversarial loss: 0.450653\n",
      "epoch 182; iter: 0; batch classifier loss: 0.318532; batch adversarial loss: 0.579695\n",
      "epoch 183; iter: 0; batch classifier loss: 0.328963; batch adversarial loss: 0.563511\n",
      "epoch 184; iter: 0; batch classifier loss: 0.312680; batch adversarial loss: 0.515440\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 185; iter: 0; batch classifier loss: 0.395645; batch adversarial loss: 0.572730\n",
      "epoch 186; iter: 0; batch classifier loss: 0.334893; batch adversarial loss: 0.618691\n",
      "epoch 187; iter: 0; batch classifier loss: 0.321464; batch adversarial loss: 0.546916\n",
      "epoch 188; iter: 0; batch classifier loss: 0.336331; batch adversarial loss: 0.526297\n",
      "epoch 189; iter: 0; batch classifier loss: 0.382733; batch adversarial loss: 0.469816\n",
      "epoch 190; iter: 0; batch classifier loss: 0.372072; batch adversarial loss: 0.569975\n",
      "epoch 191; iter: 0; batch classifier loss: 0.359223; batch adversarial loss: 0.451044\n",
      "epoch 192; iter: 0; batch classifier loss: 0.347803; batch adversarial loss: 0.543839\n",
      "epoch 193; iter: 0; batch classifier loss: 0.337591; batch adversarial loss: 0.553693\n",
      "epoch 194; iter: 0; batch classifier loss: 0.285684; batch adversarial loss: 0.553758\n",
      "epoch 195; iter: 0; batch classifier loss: 0.320141; batch adversarial loss: 0.572922\n",
      "epoch 196; iter: 0; batch classifier loss: 0.313037; batch adversarial loss: 0.524975\n",
      "epoch 197; iter: 0; batch classifier loss: 0.335386; batch adversarial loss: 0.602837\n",
      "epoch 198; iter: 0; batch classifier loss: 0.299551; batch adversarial loss: 0.589532\n",
      "epoch 199; iter: 0; batch classifier loss: 0.405129; batch adversarial loss: 0.496887\n",
      "epoch 0; iter: 0; batch classifier loss: 0.789909; batch adversarial loss: 0.727680\n",
      "epoch 1; iter: 0; batch classifier loss: 0.608729; batch adversarial loss: 0.707074\n",
      "epoch 2; iter: 0; batch classifier loss: 0.626174; batch adversarial loss: 0.670788\n",
      "epoch 3; iter: 0; batch classifier loss: 0.643641; batch adversarial loss: 0.709764\n",
      "epoch 4; iter: 0; batch classifier loss: 0.555854; batch adversarial loss: 0.643844\n",
      "epoch 5; iter: 0; batch classifier loss: 0.560460; batch adversarial loss: 0.632420\n",
      "epoch 6; iter: 0; batch classifier loss: 0.527058; batch adversarial loss: 0.594726\n",
      "epoch 7; iter: 0; batch classifier loss: 0.528669; batch adversarial loss: 0.586717\n",
      "epoch 8; iter: 0; batch classifier loss: 0.596907; batch adversarial loss: 0.601376\n",
      "epoch 9; iter: 0; batch classifier loss: 0.517032; batch adversarial loss: 0.569073\n",
      "epoch 10; iter: 0; batch classifier loss: 0.511904; batch adversarial loss: 0.583345\n",
      "epoch 11; iter: 0; batch classifier loss: 0.483460; batch adversarial loss: 0.580049\n",
      "epoch 12; iter: 0; batch classifier loss: 0.461170; batch adversarial loss: 0.555616\n",
      "epoch 13; iter: 0; batch classifier loss: 0.556321; batch adversarial loss: 0.572249\n",
      "epoch 14; iter: 0; batch classifier loss: 0.501495; batch adversarial loss: 0.570791\n",
      "epoch 15; iter: 0; batch classifier loss: 0.524426; batch adversarial loss: 0.582496\n",
      "epoch 16; iter: 0; batch classifier loss: 0.510758; batch adversarial loss: 0.570735\n",
      "epoch 17; iter: 0; batch classifier loss: 0.495062; batch adversarial loss: 0.683499\n",
      "epoch 18; iter: 0; batch classifier loss: 0.529025; batch adversarial loss: 0.615114\n",
      "epoch 19; iter: 0; batch classifier loss: 0.424181; batch adversarial loss: 0.585775\n",
      "epoch 20; iter: 0; batch classifier loss: 0.440072; batch adversarial loss: 0.559057\n",
      "epoch 21; iter: 0; batch classifier loss: 0.556902; batch adversarial loss: 0.626770\n",
      "epoch 22; iter: 0; batch classifier loss: 0.594328; batch adversarial loss: 0.573807\n",
      "epoch 23; iter: 0; batch classifier loss: 0.446909; batch adversarial loss: 0.593642\n",
      "epoch 24; iter: 0; batch classifier loss: 0.518870; batch adversarial loss: 0.594331\n",
      "epoch 25; iter: 0; batch classifier loss: 0.441128; batch adversarial loss: 0.603788\n",
      "epoch 26; iter: 0; batch classifier loss: 0.574871; batch adversarial loss: 0.635560\n",
      "epoch 27; iter: 0; batch classifier loss: 0.508681; batch adversarial loss: 0.522784\n",
      "epoch 28; iter: 0; batch classifier loss: 0.541055; batch adversarial loss: 0.592972\n",
      "epoch 29; iter: 0; batch classifier loss: 0.493601; batch adversarial loss: 0.541607\n",
      "epoch 30; iter: 0; batch classifier loss: 0.500569; batch adversarial loss: 0.509363\n",
      "epoch 31; iter: 0; batch classifier loss: 0.465279; batch adversarial loss: 0.556119\n",
      "epoch 32; iter: 0; batch classifier loss: 0.434425; batch adversarial loss: 0.490978\n",
      "epoch 33; iter: 0; batch classifier loss: 0.492569; batch adversarial loss: 0.628814\n",
      "epoch 34; iter: 0; batch classifier loss: 0.423945; batch adversarial loss: 0.535230\n",
      "epoch 35; iter: 0; batch classifier loss: 0.458981; batch adversarial loss: 0.544595\n",
      "epoch 36; iter: 0; batch classifier loss: 0.412040; batch adversarial loss: 0.539838\n",
      "epoch 37; iter: 0; batch classifier loss: 0.425719; batch adversarial loss: 0.621589\n",
      "epoch 38; iter: 0; batch classifier loss: 0.514691; batch adversarial loss: 0.572724\n",
      "epoch 39; iter: 0; batch classifier loss: 0.406680; batch adversarial loss: 0.545069\n",
      "epoch 40; iter: 0; batch classifier loss: 0.451945; batch adversarial loss: 0.555146\n",
      "epoch 41; iter: 0; batch classifier loss: 0.476974; batch adversarial loss: 0.493661\n",
      "epoch 42; iter: 0; batch classifier loss: 0.403418; batch adversarial loss: 0.638619\n",
      "epoch 43; iter: 0; batch classifier loss: 0.365790; batch adversarial loss: 0.518976\n",
      "epoch 44; iter: 0; batch classifier loss: 0.449978; batch adversarial loss: 0.605199\n",
      "epoch 45; iter: 0; batch classifier loss: 0.408587; batch adversarial loss: 0.556592\n",
      "epoch 46; iter: 0; batch classifier loss: 0.487151; batch adversarial loss: 0.536867\n",
      "epoch 47; iter: 0; batch classifier loss: 0.441843; batch adversarial loss: 0.595796\n",
      "epoch 48; iter: 0; batch classifier loss: 0.449586; batch adversarial loss: 0.534260\n",
      "epoch 49; iter: 0; batch classifier loss: 0.492750; batch adversarial loss: 0.589323\n",
      "epoch 50; iter: 0; batch classifier loss: 0.440323; batch adversarial loss: 0.552567\n",
      "epoch 51; iter: 0; batch classifier loss: 0.353935; batch adversarial loss: 0.519905\n",
      "epoch 52; iter: 0; batch classifier loss: 0.392641; batch adversarial loss: 0.597121\n",
      "epoch 53; iter: 0; batch classifier loss: 0.428500; batch adversarial loss: 0.537235\n",
      "epoch 54; iter: 0; batch classifier loss: 0.412789; batch adversarial loss: 0.544347\n",
      "epoch 55; iter: 0; batch classifier loss: 0.403891; batch adversarial loss: 0.570018\n",
      "epoch 56; iter: 0; batch classifier loss: 0.479667; batch adversarial loss: 0.563890\n",
      "epoch 57; iter: 0; batch classifier loss: 0.409089; batch adversarial loss: 0.579747\n",
      "epoch 58; iter: 0; batch classifier loss: 0.407570; batch adversarial loss: 0.587882\n",
      "epoch 59; iter: 0; batch classifier loss: 0.322406; batch adversarial loss: 0.658017\n",
      "epoch 60; iter: 0; batch classifier loss: 0.457102; batch adversarial loss: 0.474223\n",
      "epoch 61; iter: 0; batch classifier loss: 0.345901; batch adversarial loss: 0.607466\n",
      "epoch 62; iter: 0; batch classifier loss: 0.443713; batch adversarial loss: 0.579062\n",
      "epoch 63; iter: 0; batch classifier loss: 0.448419; batch adversarial loss: 0.568981\n",
      "epoch 64; iter: 0; batch classifier loss: 0.372586; batch adversarial loss: 0.587187\n",
      "epoch 65; iter: 0; batch classifier loss: 0.488078; batch adversarial loss: 0.587581\n",
      "epoch 66; iter: 0; batch classifier loss: 0.454908; batch adversarial loss: 0.544125\n",
      "epoch 67; iter: 0; batch classifier loss: 0.432913; batch adversarial loss: 0.563234\n",
      "epoch 68; iter: 0; batch classifier loss: 0.414140; batch adversarial loss: 0.589135\n",
      "epoch 69; iter: 0; batch classifier loss: 0.399513; batch adversarial loss: 0.624676\n",
      "epoch 70; iter: 0; batch classifier loss: 0.418611; batch adversarial loss: 0.501086\n",
      "epoch 71; iter: 0; batch classifier loss: 0.352728; batch adversarial loss: 0.500798\n",
      "epoch 72; iter: 0; batch classifier loss: 0.390260; batch adversarial loss: 0.589920\n",
      "epoch 73; iter: 0; batch classifier loss: 0.315062; batch adversarial loss: 0.527935\n",
      "epoch 74; iter: 0; batch classifier loss: 0.389634; batch adversarial loss: 0.545674\n",
      "epoch 75; iter: 0; batch classifier loss: 0.413301; batch adversarial loss: 0.492876\n",
      "epoch 76; iter: 0; batch classifier loss: 0.486186; batch adversarial loss: 0.580251\n",
      "epoch 77; iter: 0; batch classifier loss: 0.452399; batch adversarial loss: 0.598074\n",
      "epoch 78; iter: 0; batch classifier loss: 0.440493; batch adversarial loss: 0.544397\n",
      "epoch 79; iter: 0; batch classifier loss: 0.403516; batch adversarial loss: 0.569742\n",
      "epoch 80; iter: 0; batch classifier loss: 0.390767; batch adversarial loss: 0.526376\n",
      "epoch 81; iter: 0; batch classifier loss: 0.408388; batch adversarial loss: 0.581080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 82; iter: 0; batch classifier loss: 0.402362; batch adversarial loss: 0.509112\n",
      "epoch 83; iter: 0; batch classifier loss: 0.330318; batch adversarial loss: 0.570479\n",
      "epoch 84; iter: 0; batch classifier loss: 0.415482; batch adversarial loss: 0.518542\n",
      "epoch 85; iter: 0; batch classifier loss: 0.452904; batch adversarial loss: 0.501415\n",
      "epoch 86; iter: 0; batch classifier loss: 0.344093; batch adversarial loss: 0.571112\n",
      "epoch 87; iter: 0; batch classifier loss: 0.404719; batch adversarial loss: 0.658671\n",
      "epoch 88; iter: 0; batch classifier loss: 0.427780; batch adversarial loss: 0.562112\n",
      "epoch 89; iter: 0; batch classifier loss: 0.403163; batch adversarial loss: 0.492196\n",
      "epoch 90; iter: 0; batch classifier loss: 0.384139; batch adversarial loss: 0.528073\n",
      "epoch 91; iter: 0; batch classifier loss: 0.455014; batch adversarial loss: 0.572089\n",
      "epoch 92; iter: 0; batch classifier loss: 0.444027; batch adversarial loss: 0.508868\n",
      "epoch 93; iter: 0; batch classifier loss: 0.369438; batch adversarial loss: 0.615256\n",
      "epoch 94; iter: 0; batch classifier loss: 0.350556; batch adversarial loss: 0.517773\n",
      "epoch 95; iter: 0; batch classifier loss: 0.356313; batch adversarial loss: 0.518534\n",
      "epoch 96; iter: 0; batch classifier loss: 0.410749; batch adversarial loss: 0.483149\n",
      "epoch 97; iter: 0; batch classifier loss: 0.430618; batch adversarial loss: 0.562838\n",
      "epoch 98; iter: 0; batch classifier loss: 0.376443; batch adversarial loss: 0.544700\n",
      "epoch 99; iter: 0; batch classifier loss: 0.434879; batch adversarial loss: 0.466303\n",
      "epoch 100; iter: 0; batch classifier loss: 0.497066; batch adversarial loss: 0.553659\n",
      "epoch 101; iter: 0; batch classifier loss: 0.392210; batch adversarial loss: 0.624117\n",
      "epoch 102; iter: 0; batch classifier loss: 0.369129; batch adversarial loss: 0.561955\n",
      "epoch 103; iter: 0; batch classifier loss: 0.447118; batch adversarial loss: 0.561682\n",
      "epoch 104; iter: 0; batch classifier loss: 0.386206; batch adversarial loss: 0.439067\n",
      "epoch 105; iter: 0; batch classifier loss: 0.383652; batch adversarial loss: 0.492555\n",
      "epoch 106; iter: 0; batch classifier loss: 0.339809; batch adversarial loss: 0.622482\n",
      "epoch 107; iter: 0; batch classifier loss: 0.386080; batch adversarial loss: 0.616393\n",
      "epoch 108; iter: 0; batch classifier loss: 0.392342; batch adversarial loss: 0.535487\n",
      "epoch 109; iter: 0; batch classifier loss: 0.358934; batch adversarial loss: 0.562399\n",
      "epoch 110; iter: 0; batch classifier loss: 0.445730; batch adversarial loss: 0.491913\n",
      "epoch 111; iter: 0; batch classifier loss: 0.467926; batch adversarial loss: 0.633075\n",
      "epoch 112; iter: 0; batch classifier loss: 0.382169; batch adversarial loss: 0.526241\n",
      "epoch 113; iter: 0; batch classifier loss: 0.432538; batch adversarial loss: 0.500576\n",
      "epoch 114; iter: 0; batch classifier loss: 0.350964; batch adversarial loss: 0.669024\n",
      "epoch 115; iter: 0; batch classifier loss: 0.368977; batch adversarial loss: 0.589421\n",
      "epoch 116; iter: 0; batch classifier loss: 0.415358; batch adversarial loss: 0.598388\n",
      "epoch 117; iter: 0; batch classifier loss: 0.360276; batch adversarial loss: 0.641733\n",
      "epoch 118; iter: 0; batch classifier loss: 0.419594; batch adversarial loss: 0.562558\n",
      "epoch 119; iter: 0; batch classifier loss: 0.396104; batch adversarial loss: 0.545874\n",
      "epoch 120; iter: 0; batch classifier loss: 0.394301; batch adversarial loss: 0.562922\n",
      "epoch 121; iter: 0; batch classifier loss: 0.403972; batch adversarial loss: 0.597551\n",
      "epoch 122; iter: 0; batch classifier loss: 0.425226; batch adversarial loss: 0.516863\n",
      "epoch 123; iter: 0; batch classifier loss: 0.427520; batch adversarial loss: 0.578901\n",
      "epoch 124; iter: 0; batch classifier loss: 0.349581; batch adversarial loss: 0.642999\n",
      "epoch 125; iter: 0; batch classifier loss: 0.337893; batch adversarial loss: 0.562966\n",
      "epoch 126; iter: 0; batch classifier loss: 0.385364; batch adversarial loss: 0.544798\n",
      "epoch 127; iter: 0; batch classifier loss: 0.388097; batch adversarial loss: 0.543651\n",
      "epoch 128; iter: 0; batch classifier loss: 0.410929; batch adversarial loss: 0.553089\n",
      "epoch 129; iter: 0; batch classifier loss: 0.376636; batch adversarial loss: 0.589720\n",
      "epoch 130; iter: 0; batch classifier loss: 0.406006; batch adversarial loss: 0.588850\n",
      "epoch 131; iter: 0; batch classifier loss: 0.345582; batch adversarial loss: 0.563554\n",
      "epoch 132; iter: 0; batch classifier loss: 0.332591; batch adversarial loss: 0.492653\n",
      "epoch 133; iter: 0; batch classifier loss: 0.306214; batch adversarial loss: 0.641488\n",
      "epoch 134; iter: 0; batch classifier loss: 0.382922; batch adversarial loss: 0.545081\n",
      "epoch 135; iter: 0; batch classifier loss: 0.354841; batch adversarial loss: 0.563215\n",
      "epoch 136; iter: 0; batch classifier loss: 0.270346; batch adversarial loss: 0.578380\n",
      "epoch 137; iter: 0; batch classifier loss: 0.415199; batch adversarial loss: 0.518429\n",
      "epoch 138; iter: 0; batch classifier loss: 0.387943; batch adversarial loss: 0.553907\n",
      "epoch 139; iter: 0; batch classifier loss: 0.341311; batch adversarial loss: 0.615369\n",
      "epoch 140; iter: 0; batch classifier loss: 0.365203; batch adversarial loss: 0.605865\n",
      "epoch 141; iter: 0; batch classifier loss: 0.412304; batch adversarial loss: 0.579777\n",
      "epoch 142; iter: 0; batch classifier loss: 0.364468; batch adversarial loss: 0.649932\n",
      "epoch 143; iter: 0; batch classifier loss: 0.306926; batch adversarial loss: 0.570994\n",
      "epoch 144; iter: 0; batch classifier loss: 0.376037; batch adversarial loss: 0.508480\n",
      "epoch 145; iter: 0; batch classifier loss: 0.340126; batch adversarial loss: 0.607045\n",
      "epoch 146; iter: 0; batch classifier loss: 0.348914; batch adversarial loss: 0.615314\n",
      "epoch 147; iter: 0; batch classifier loss: 0.335146; batch adversarial loss: 0.596914\n",
      "epoch 148; iter: 0; batch classifier loss: 0.430227; batch adversarial loss: 0.570539\n",
      "epoch 149; iter: 0; batch classifier loss: 0.329368; batch adversarial loss: 0.562493\n",
      "epoch 150; iter: 0; batch classifier loss: 0.334747; batch adversarial loss: 0.545218\n",
      "epoch 151; iter: 0; batch classifier loss: 0.403243; batch adversarial loss: 0.526628\n",
      "epoch 152; iter: 0; batch classifier loss: 0.375929; batch adversarial loss: 0.553148\n",
      "epoch 153; iter: 0; batch classifier loss: 0.414810; batch adversarial loss: 0.508933\n",
      "epoch 154; iter: 0; batch classifier loss: 0.366649; batch adversarial loss: 0.588369\n",
      "epoch 155; iter: 0; batch classifier loss: 0.285114; batch adversarial loss: 0.527253\n",
      "epoch 156; iter: 0; batch classifier loss: 0.413533; batch adversarial loss: 0.474296\n",
      "epoch 157; iter: 0; batch classifier loss: 0.363842; batch adversarial loss: 0.658045\n",
      "epoch 158; iter: 0; batch classifier loss: 0.361497; batch adversarial loss: 0.641257\n",
      "epoch 159; iter: 0; batch classifier loss: 0.432754; batch adversarial loss: 0.535729\n",
      "epoch 160; iter: 0; batch classifier loss: 0.376777; batch adversarial loss: 0.588177\n",
      "epoch 161; iter: 0; batch classifier loss: 0.395579; batch adversarial loss: 0.546309\n",
      "epoch 162; iter: 0; batch classifier loss: 0.357697; batch adversarial loss: 0.615310\n",
      "epoch 163; iter: 0; batch classifier loss: 0.337646; batch adversarial loss: 0.517824\n",
      "epoch 164; iter: 0; batch classifier loss: 0.384078; batch adversarial loss: 0.500455\n",
      "epoch 165; iter: 0; batch classifier loss: 0.405649; batch adversarial loss: 0.536445\n",
      "epoch 166; iter: 0; batch classifier loss: 0.387240; batch adversarial loss: 0.589537\n",
      "epoch 167; iter: 0; batch classifier loss: 0.433339; batch adversarial loss: 0.544310\n",
      "epoch 168; iter: 0; batch classifier loss: 0.388619; batch adversarial loss: 0.659169\n",
      "epoch 169; iter: 0; batch classifier loss: 0.380267; batch adversarial loss: 0.537054\n",
      "epoch 170; iter: 0; batch classifier loss: 0.326180; batch adversarial loss: 0.517948\n",
      "epoch 171; iter: 0; batch classifier loss: 0.408911; batch adversarial loss: 0.658336\n",
      "epoch 172; iter: 0; batch classifier loss: 0.359226; batch adversarial loss: 0.526598\n",
      "epoch 173; iter: 0; batch classifier loss: 0.381607; batch adversarial loss: 0.535986\n",
      "epoch 174; iter: 0; batch classifier loss: 0.302488; batch adversarial loss: 0.545026\n",
      "epoch 175; iter: 0; batch classifier loss: 0.343450; batch adversarial loss: 0.562061\n",
      "epoch 176; iter: 0; batch classifier loss: 0.479756; batch adversarial loss: 0.570604\n",
      "epoch 177; iter: 0; batch classifier loss: 0.433073; batch adversarial loss: 0.465517\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 178; iter: 0; batch classifier loss: 0.348909; batch adversarial loss: 0.624990\n",
      "epoch 179; iter: 0; batch classifier loss: 0.303985; batch adversarial loss: 0.623332\n",
      "epoch 180; iter: 0; batch classifier loss: 0.326811; batch adversarial loss: 0.552873\n",
      "epoch 181; iter: 0; batch classifier loss: 0.399691; batch adversarial loss: 0.509561\n",
      "epoch 182; iter: 0; batch classifier loss: 0.389395; batch adversarial loss: 0.439361\n",
      "epoch 183; iter: 0; batch classifier loss: 0.308929; batch adversarial loss: 0.553683\n",
      "epoch 184; iter: 0; batch classifier loss: 0.277207; batch adversarial loss: 0.570931\n",
      "epoch 185; iter: 0; batch classifier loss: 0.384893; batch adversarial loss: 0.562480\n",
      "epoch 186; iter: 0; batch classifier loss: 0.284485; batch adversarial loss: 0.579651\n",
      "epoch 187; iter: 0; batch classifier loss: 0.385289; batch adversarial loss: 0.562722\n",
      "epoch 188; iter: 0; batch classifier loss: 0.333828; batch adversarial loss: 0.561963\n",
      "epoch 189; iter: 0; batch classifier loss: 0.330297; batch adversarial loss: 0.553127\n",
      "epoch 190; iter: 0; batch classifier loss: 0.304279; batch adversarial loss: 0.589332\n",
      "epoch 191; iter: 0; batch classifier loss: 0.385104; batch adversarial loss: 0.553895\n",
      "epoch 192; iter: 0; batch classifier loss: 0.371815; batch adversarial loss: 0.535832\n",
      "epoch 193; iter: 0; batch classifier loss: 0.311195; batch adversarial loss: 0.568960\n",
      "epoch 194; iter: 0; batch classifier loss: 0.420098; batch adversarial loss: 0.658462\n",
      "epoch 195; iter: 0; batch classifier loss: 0.361730; batch adversarial loss: 0.509771\n",
      "epoch 196; iter: 0; batch classifier loss: 0.385771; batch adversarial loss: 0.500246\n",
      "epoch 197; iter: 0; batch classifier loss: 0.333453; batch adversarial loss: 0.544820\n",
      "epoch 198; iter: 0; batch classifier loss: 0.361677; batch adversarial loss: 0.659076\n",
      "epoch 199; iter: 0; batch classifier loss: 0.349862; batch adversarial loss: 0.615213\n",
      "epoch 0; iter: 0; batch classifier loss: 0.672100; batch adversarial loss: 0.650749\n",
      "epoch 1; iter: 0; batch classifier loss: 0.575437; batch adversarial loss: 0.655538\n",
      "epoch 2; iter: 0; batch classifier loss: 0.586712; batch adversarial loss: 0.655103\n",
      "epoch 3; iter: 0; batch classifier loss: 0.619912; batch adversarial loss: 0.647084\n",
      "epoch 4; iter: 0; batch classifier loss: 0.624964; batch adversarial loss: 0.674709\n",
      "epoch 5; iter: 0; batch classifier loss: 0.616080; batch adversarial loss: 0.617394\n",
      "epoch 6; iter: 0; batch classifier loss: 0.477767; batch adversarial loss: 0.638200\n",
      "epoch 7; iter: 0; batch classifier loss: 0.596935; batch adversarial loss: 0.704310\n",
      "epoch 8; iter: 0; batch classifier loss: 0.537763; batch adversarial loss: 0.560323\n",
      "epoch 9; iter: 0; batch classifier loss: 0.596153; batch adversarial loss: 0.646140\n",
      "epoch 10; iter: 0; batch classifier loss: 0.550872; batch adversarial loss: 0.576012\n",
      "epoch 11; iter: 0; batch classifier loss: 0.466875; batch adversarial loss: 0.546379\n",
      "epoch 12; iter: 0; batch classifier loss: 0.605849; batch adversarial loss: 0.588889\n",
      "epoch 13; iter: 0; batch classifier loss: 0.566640; batch adversarial loss: 0.556491\n",
      "epoch 14; iter: 0; batch classifier loss: 0.563314; batch adversarial loss: 0.561495\n",
      "epoch 15; iter: 0; batch classifier loss: 0.570502; batch adversarial loss: 0.602510\n",
      "epoch 16; iter: 0; batch classifier loss: 0.594586; batch adversarial loss: 0.556078\n",
      "epoch 17; iter: 0; batch classifier loss: 0.511078; batch adversarial loss: 0.616960\n",
      "epoch 18; iter: 0; batch classifier loss: 0.445190; batch adversarial loss: 0.511621\n",
      "epoch 19; iter: 0; batch classifier loss: 0.549618; batch adversarial loss: 0.465971\n",
      "epoch 20; iter: 0; batch classifier loss: 0.456024; batch adversarial loss: 0.582999\n",
      "epoch 21; iter: 0; batch classifier loss: 0.496344; batch adversarial loss: 0.564930\n",
      "epoch 22; iter: 0; batch classifier loss: 0.502653; batch adversarial loss: 0.531213\n",
      "epoch 23; iter: 0; batch classifier loss: 0.457080; batch adversarial loss: 0.537627\n",
      "epoch 24; iter: 0; batch classifier loss: 0.467923; batch adversarial loss: 0.538295\n",
      "epoch 25; iter: 0; batch classifier loss: 0.497936; batch adversarial loss: 0.563961\n",
      "epoch 26; iter: 0; batch classifier loss: 0.419517; batch adversarial loss: 0.555540\n",
      "epoch 27; iter: 0; batch classifier loss: 0.526890; batch adversarial loss: 0.554874\n",
      "epoch 28; iter: 0; batch classifier loss: 0.476958; batch adversarial loss: 0.545447\n",
      "epoch 29; iter: 0; batch classifier loss: 0.422231; batch adversarial loss: 0.545224\n",
      "epoch 30; iter: 0; batch classifier loss: 0.369352; batch adversarial loss: 0.562353\n",
      "epoch 31; iter: 0; batch classifier loss: 0.425053; batch adversarial loss: 0.475367\n",
      "epoch 32; iter: 0; batch classifier loss: 0.433327; batch adversarial loss: 0.553667\n",
      "epoch 33; iter: 0; batch classifier loss: 0.403503; batch adversarial loss: 0.535703\n",
      "epoch 34; iter: 0; batch classifier loss: 0.456800; batch adversarial loss: 0.570391\n",
      "epoch 35; iter: 0; batch classifier loss: 0.371501; batch adversarial loss: 0.535537\n",
      "epoch 36; iter: 0; batch classifier loss: 0.435374; batch adversarial loss: 0.536644\n",
      "epoch 37; iter: 0; batch classifier loss: 0.411871; batch adversarial loss: 0.508556\n",
      "epoch 38; iter: 0; batch classifier loss: 0.425149; batch adversarial loss: 0.550966\n",
      "epoch 39; iter: 0; batch classifier loss: 0.388323; batch adversarial loss: 0.515992\n",
      "epoch 40; iter: 0; batch classifier loss: 0.447386; batch adversarial loss: 0.554651\n",
      "epoch 41; iter: 0; batch classifier loss: 0.460321; batch adversarial loss: 0.618598\n",
      "epoch 42; iter: 0; batch classifier loss: 0.462011; batch adversarial loss: 0.552149\n",
      "epoch 43; iter: 0; batch classifier loss: 0.384422; batch adversarial loss: 0.565235\n",
      "epoch 44; iter: 0; batch classifier loss: 0.406160; batch adversarial loss: 0.581834\n",
      "epoch 45; iter: 0; batch classifier loss: 0.430178; batch adversarial loss: 0.600460\n",
      "epoch 46; iter: 0; batch classifier loss: 0.414449; batch adversarial loss: 0.506699\n",
      "epoch 47; iter: 0; batch classifier loss: 0.435990; batch adversarial loss: 0.662230\n",
      "epoch 48; iter: 0; batch classifier loss: 0.464331; batch adversarial loss: 0.545839\n",
      "epoch 49; iter: 0; batch classifier loss: 0.457769; batch adversarial loss: 0.626068\n",
      "epoch 50; iter: 0; batch classifier loss: 0.356963; batch adversarial loss: 0.542649\n",
      "epoch 51; iter: 0; batch classifier loss: 0.464770; batch adversarial loss: 0.515662\n",
      "epoch 52; iter: 0; batch classifier loss: 0.476798; batch adversarial loss: 0.610214\n",
      "epoch 53; iter: 0; batch classifier loss: 0.374742; batch adversarial loss: 0.563571\n",
      "epoch 54; iter: 0; batch classifier loss: 0.399079; batch adversarial loss: 0.610425\n",
      "epoch 55; iter: 0; batch classifier loss: 0.539722; batch adversarial loss: 0.530751\n",
      "epoch 56; iter: 0; batch classifier loss: 0.329933; batch adversarial loss: 0.571936\n",
      "epoch 57; iter: 0; batch classifier loss: 0.436503; batch adversarial loss: 0.594753\n",
      "epoch 58; iter: 0; batch classifier loss: 0.425314; batch adversarial loss: 0.549905\n",
      "epoch 59; iter: 0; batch classifier loss: 0.400524; batch adversarial loss: 0.551399\n",
      "epoch 60; iter: 0; batch classifier loss: 0.428654; batch adversarial loss: 0.571338\n",
      "epoch 61; iter: 0; batch classifier loss: 0.382378; batch adversarial loss: 0.516979\n",
      "epoch 62; iter: 0; batch classifier loss: 0.378358; batch adversarial loss: 0.598066\n",
      "epoch 63; iter: 0; batch classifier loss: 0.373887; batch adversarial loss: 0.543783\n",
      "epoch 64; iter: 0; batch classifier loss: 0.484638; batch adversarial loss: 0.507100\n",
      "epoch 65; iter: 0; batch classifier loss: 0.376936; batch adversarial loss: 0.553479\n",
      "epoch 66; iter: 0; batch classifier loss: 0.345351; batch adversarial loss: 0.572835\n",
      "epoch 67; iter: 0; batch classifier loss: 0.386935; batch adversarial loss: 0.634413\n",
      "epoch 68; iter: 0; batch classifier loss: 0.362071; batch adversarial loss: 0.533905\n",
      "epoch 69; iter: 0; batch classifier loss: 0.393723; batch adversarial loss: 0.451944\n",
      "epoch 70; iter: 0; batch classifier loss: 0.367608; batch adversarial loss: 0.478561\n",
      "epoch 71; iter: 0; batch classifier loss: 0.341729; batch adversarial loss: 0.512741\n",
      "epoch 72; iter: 0; batch classifier loss: 0.417205; batch adversarial loss: 0.490068\n",
      "epoch 73; iter: 0; batch classifier loss: 0.392654; batch adversarial loss: 0.535934\n",
      "epoch 74; iter: 0; batch classifier loss: 0.427537; batch adversarial loss: 0.620358\n",
      "epoch 75; iter: 0; batch classifier loss: 0.339366; batch adversarial loss: 0.588477\n",
      "epoch 76; iter: 0; batch classifier loss: 0.341287; batch adversarial loss: 0.597260\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 77; iter: 0; batch classifier loss: 0.435336; batch adversarial loss: 0.519508\n",
      "epoch 78; iter: 0; batch classifier loss: 0.541603; batch adversarial loss: 0.615995\n",
      "epoch 79; iter: 0; batch classifier loss: 0.318689; batch adversarial loss: 0.531636\n",
      "epoch 80; iter: 0; batch classifier loss: 0.319920; batch adversarial loss: 0.463843\n",
      "epoch 81; iter: 0; batch classifier loss: 0.329710; batch adversarial loss: 0.517797\n",
      "epoch 82; iter: 0; batch classifier loss: 0.409357; batch adversarial loss: 0.531211\n",
      "epoch 83; iter: 0; batch classifier loss: 0.413036; batch adversarial loss: 0.480332\n",
      "epoch 84; iter: 0; batch classifier loss: 0.382465; batch adversarial loss: 0.545561\n",
      "epoch 85; iter: 0; batch classifier loss: 0.378760; batch adversarial loss: 0.490085\n",
      "epoch 86; iter: 0; batch classifier loss: 0.455617; batch adversarial loss: 0.556639\n",
      "epoch 87; iter: 0; batch classifier loss: 0.404947; batch adversarial loss: 0.523963\n",
      "epoch 88; iter: 0; batch classifier loss: 0.298734; batch adversarial loss: 0.599347\n",
      "epoch 89; iter: 0; batch classifier loss: 0.328528; batch adversarial loss: 0.546636\n",
      "epoch 90; iter: 0; batch classifier loss: 0.419700; batch adversarial loss: 0.505551\n",
      "epoch 91; iter: 0; batch classifier loss: 0.399172; batch adversarial loss: 0.516430\n",
      "epoch 92; iter: 0; batch classifier loss: 0.392172; batch adversarial loss: 0.516781\n",
      "epoch 93; iter: 0; batch classifier loss: 0.471697; batch adversarial loss: 0.516030\n",
      "epoch 94; iter: 0; batch classifier loss: 0.384300; batch adversarial loss: 0.596350\n",
      "epoch 95; iter: 0; batch classifier loss: 0.419789; batch adversarial loss: 0.498327\n",
      "epoch 96; iter: 0; batch classifier loss: 0.397592; batch adversarial loss: 0.591997\n",
      "epoch 97; iter: 0; batch classifier loss: 0.349142; batch adversarial loss: 0.424043\n",
      "epoch 98; iter: 0; batch classifier loss: 0.398980; batch adversarial loss: 0.563227\n",
      "epoch 99; iter: 0; batch classifier loss: 0.368556; batch adversarial loss: 0.478285\n",
      "epoch 100; iter: 0; batch classifier loss: 0.396218; batch adversarial loss: 0.598738\n",
      "epoch 101; iter: 0; batch classifier loss: 0.356390; batch adversarial loss: 0.542916\n",
      "epoch 102; iter: 0; batch classifier loss: 0.422692; batch adversarial loss: 0.572146\n",
      "epoch 103; iter: 0; batch classifier loss: 0.365997; batch adversarial loss: 0.571471\n",
      "epoch 104; iter: 0; batch classifier loss: 0.276039; batch adversarial loss: 0.635463\n",
      "epoch 105; iter: 0; batch classifier loss: 0.391405; batch adversarial loss: 0.563124\n",
      "epoch 106; iter: 0; batch classifier loss: 0.443556; batch adversarial loss: 0.508027\n",
      "epoch 107; iter: 0; batch classifier loss: 0.391278; batch adversarial loss: 0.543605\n",
      "epoch 108; iter: 0; batch classifier loss: 0.354200; batch adversarial loss: 0.571867\n",
      "epoch 109; iter: 0; batch classifier loss: 0.327171; batch adversarial loss: 0.504720\n",
      "epoch 110; iter: 0; batch classifier loss: 0.315554; batch adversarial loss: 0.536733\n",
      "epoch 111; iter: 0; batch classifier loss: 0.462350; batch adversarial loss: 0.554215\n",
      "epoch 112; iter: 0; batch classifier loss: 0.417717; batch adversarial loss: 0.577044\n",
      "epoch 113; iter: 0; batch classifier loss: 0.388091; batch adversarial loss: 0.515967\n",
      "epoch 114; iter: 0; batch classifier loss: 0.433813; batch adversarial loss: 0.581395\n",
      "epoch 115; iter: 0; batch classifier loss: 0.401134; batch adversarial loss: 0.606301\n",
      "epoch 116; iter: 0; batch classifier loss: 0.354605; batch adversarial loss: 0.533674\n",
      "epoch 117; iter: 0; batch classifier loss: 0.300216; batch adversarial loss: 0.609455\n",
      "epoch 118; iter: 0; batch classifier loss: 0.394834; batch adversarial loss: 0.544131\n",
      "epoch 119; iter: 0; batch classifier loss: 0.443163; batch adversarial loss: 0.595236\n",
      "epoch 120; iter: 0; batch classifier loss: 0.383178; batch adversarial loss: 0.518473\n",
      "epoch 121; iter: 0; batch classifier loss: 0.345482; batch adversarial loss: 0.595862\n",
      "epoch 122; iter: 0; batch classifier loss: 0.394885; batch adversarial loss: 0.525541\n",
      "epoch 123; iter: 0; batch classifier loss: 0.413132; batch adversarial loss: 0.480592\n",
      "epoch 124; iter: 0; batch classifier loss: 0.369859; batch adversarial loss: 0.517883\n",
      "epoch 125; iter: 0; batch classifier loss: 0.286738; batch adversarial loss: 0.555015\n",
      "epoch 126; iter: 0; batch classifier loss: 0.437464; batch adversarial loss: 0.571689\n",
      "epoch 127; iter: 0; batch classifier loss: 0.366884; batch adversarial loss: 0.570889\n",
      "epoch 128; iter: 0; batch classifier loss: 0.429558; batch adversarial loss: 0.496174\n",
      "epoch 129; iter: 0; batch classifier loss: 0.433765; batch adversarial loss: 0.482626\n",
      "epoch 130; iter: 0; batch classifier loss: 0.349829; batch adversarial loss: 0.549932\n",
      "epoch 131; iter: 0; batch classifier loss: 0.374812; batch adversarial loss: 0.487247\n",
      "epoch 132; iter: 0; batch classifier loss: 0.427098; batch adversarial loss: 0.505363\n",
      "epoch 133; iter: 0; batch classifier loss: 0.442650; batch adversarial loss: 0.551973\n",
      "epoch 134; iter: 0; batch classifier loss: 0.357005; batch adversarial loss: 0.518035\n",
      "epoch 135; iter: 0; batch classifier loss: 0.315958; batch adversarial loss: 0.583917\n",
      "epoch 136; iter: 0; batch classifier loss: 0.411045; batch adversarial loss: 0.510562\n",
      "epoch 137; iter: 0; batch classifier loss: 0.333783; batch adversarial loss: 0.496791\n",
      "epoch 138; iter: 0; batch classifier loss: 0.383206; batch adversarial loss: 0.492022\n",
      "epoch 139; iter: 0; batch classifier loss: 0.358486; batch adversarial loss: 0.534957\n",
      "epoch 140; iter: 0; batch classifier loss: 0.365602; batch adversarial loss: 0.536337\n",
      "epoch 141; iter: 0; batch classifier loss: 0.323002; batch adversarial loss: 0.503758\n",
      "epoch 142; iter: 0; batch classifier loss: 0.403956; batch adversarial loss: 0.497820\n",
      "epoch 143; iter: 0; batch classifier loss: 0.342764; batch adversarial loss: 0.564196\n",
      "epoch 144; iter: 0; batch classifier loss: 0.315475; batch adversarial loss: 0.568136\n",
      "epoch 145; iter: 0; batch classifier loss: 0.399059; batch adversarial loss: 0.553157\n",
      "epoch 146; iter: 0; batch classifier loss: 0.463792; batch adversarial loss: 0.452237\n",
      "epoch 147; iter: 0; batch classifier loss: 0.376791; batch adversarial loss: 0.531708\n",
      "epoch 148; iter: 0; batch classifier loss: 0.423512; batch adversarial loss: 0.560692\n",
      "epoch 149; iter: 0; batch classifier loss: 0.276487; batch adversarial loss: 0.518004\n",
      "epoch 150; iter: 0; batch classifier loss: 0.395714; batch adversarial loss: 0.618005\n",
      "epoch 151; iter: 0; batch classifier loss: 0.372971; batch adversarial loss: 0.528464\n",
      "epoch 152; iter: 0; batch classifier loss: 0.365574; batch adversarial loss: 0.527624\n",
      "epoch 153; iter: 0; batch classifier loss: 0.351417; batch adversarial loss: 0.471536\n",
      "epoch 154; iter: 0; batch classifier loss: 0.300257; batch adversarial loss: 0.515177\n",
      "epoch 155; iter: 0; batch classifier loss: 0.349781; batch adversarial loss: 0.561722\n",
      "epoch 156; iter: 0; batch classifier loss: 0.412297; batch adversarial loss: 0.539257\n",
      "epoch 157; iter: 0; batch classifier loss: 0.328866; batch adversarial loss: 0.607966\n",
      "epoch 158; iter: 0; batch classifier loss: 0.336062; batch adversarial loss: 0.542292\n",
      "epoch 159; iter: 0; batch classifier loss: 0.359730; batch adversarial loss: 0.525233\n",
      "epoch 160; iter: 0; batch classifier loss: 0.344241; batch adversarial loss: 0.524583\n",
      "epoch 161; iter: 0; batch classifier loss: 0.333726; batch adversarial loss: 0.491859\n",
      "epoch 162; iter: 0; batch classifier loss: 0.405093; batch adversarial loss: 0.638983\n",
      "epoch 163; iter: 0; batch classifier loss: 0.355647; batch adversarial loss: 0.583352\n",
      "epoch 164; iter: 0; batch classifier loss: 0.410485; batch adversarial loss: 0.545723\n",
      "epoch 165; iter: 0; batch classifier loss: 0.372330; batch adversarial loss: 0.533407\n",
      "epoch 166; iter: 0; batch classifier loss: 0.370177; batch adversarial loss: 0.517496\n",
      "epoch 167; iter: 0; batch classifier loss: 0.431258; batch adversarial loss: 0.517848\n",
      "epoch 168; iter: 0; batch classifier loss: 0.322765; batch adversarial loss: 0.580896\n",
      "epoch 169; iter: 0; batch classifier loss: 0.421063; batch adversarial loss: 0.544428\n",
      "epoch 170; iter: 0; batch classifier loss: 0.321265; batch adversarial loss: 0.553470\n",
      "epoch 171; iter: 0; batch classifier loss: 0.381358; batch adversarial loss: 0.562647\n",
      "epoch 172; iter: 0; batch classifier loss: 0.331874; batch adversarial loss: 0.528603\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 173; iter: 0; batch classifier loss: 0.383992; batch adversarial loss: 0.525921\n",
      "epoch 174; iter: 0; batch classifier loss: 0.378297; batch adversarial loss: 0.608250\n",
      "epoch 175; iter: 0; batch classifier loss: 0.312682; batch adversarial loss: 0.534699\n",
      "epoch 176; iter: 0; batch classifier loss: 0.297351; batch adversarial loss: 0.534832\n",
      "epoch 177; iter: 0; batch classifier loss: 0.352030; batch adversarial loss: 0.564617\n",
      "epoch 178; iter: 0; batch classifier loss: 0.487520; batch adversarial loss: 0.554336\n",
      "epoch 179; iter: 0; batch classifier loss: 0.325866; batch adversarial loss: 0.536531\n",
      "epoch 180; iter: 0; batch classifier loss: 0.379288; batch adversarial loss: 0.578746\n",
      "epoch 181; iter: 0; batch classifier loss: 0.307705; batch adversarial loss: 0.517541\n",
      "epoch 182; iter: 0; batch classifier loss: 0.368770; batch adversarial loss: 0.535451\n",
      "epoch 183; iter: 0; batch classifier loss: 0.395001; batch adversarial loss: 0.558256\n",
      "epoch 184; iter: 0; batch classifier loss: 0.323551; batch adversarial loss: 0.471786\n",
      "epoch 185; iter: 0; batch classifier loss: 0.382093; batch adversarial loss: 0.599025\n",
      "epoch 186; iter: 0; batch classifier loss: 0.366131; batch adversarial loss: 0.487079\n",
      "epoch 187; iter: 0; batch classifier loss: 0.351334; batch adversarial loss: 0.608945\n",
      "epoch 188; iter: 0; batch classifier loss: 0.309985; batch adversarial loss: 0.498670\n",
      "epoch 189; iter: 0; batch classifier loss: 0.305910; batch adversarial loss: 0.572328\n",
      "epoch 190; iter: 0; batch classifier loss: 0.277494; batch adversarial loss: 0.562974\n",
      "epoch 191; iter: 0; batch classifier loss: 0.352633; batch adversarial loss: 0.467338\n",
      "epoch 192; iter: 0; batch classifier loss: 0.387117; batch adversarial loss: 0.512487\n",
      "epoch 193; iter: 0; batch classifier loss: 0.316964; batch adversarial loss: 0.506726\n",
      "epoch 194; iter: 0; batch classifier loss: 0.355468; batch adversarial loss: 0.594857\n",
      "epoch 195; iter: 0; batch classifier loss: 0.294382; batch adversarial loss: 0.592889\n",
      "epoch 196; iter: 0; batch classifier loss: 0.328452; batch adversarial loss: 0.599377\n",
      "epoch 197; iter: 0; batch classifier loss: 0.373468; batch adversarial loss: 0.559986\n",
      "epoch 198; iter: 0; batch classifier loss: 0.403295; batch adversarial loss: 0.545263\n",
      "epoch 199; iter: 0; batch classifier loss: 0.423894; batch adversarial loss: 0.589944\n",
      "epoch 0; iter: 0; batch classifier loss: 0.803861; batch adversarial loss: 0.906866\n",
      "epoch 1; iter: 0; batch classifier loss: 0.771256; batch adversarial loss: 0.888689\n",
      "epoch 2; iter: 0; batch classifier loss: 0.989275; batch adversarial loss: 0.869736\n",
      "epoch 3; iter: 0; batch classifier loss: 0.960186; batch adversarial loss: 0.793756\n",
      "epoch 4; iter: 0; batch classifier loss: 0.921066; batch adversarial loss: 0.729220\n",
      "epoch 5; iter: 0; batch classifier loss: 0.884761; batch adversarial loss: 0.680513\n",
      "epoch 6; iter: 0; batch classifier loss: 0.668366; batch adversarial loss: 0.618809\n",
      "epoch 7; iter: 0; batch classifier loss: 0.652355; batch adversarial loss: 0.572434\n",
      "epoch 8; iter: 0; batch classifier loss: 0.513962; batch adversarial loss: 0.595240\n",
      "epoch 9; iter: 0; batch classifier loss: 0.646444; batch adversarial loss: 0.630111\n",
      "epoch 10; iter: 0; batch classifier loss: 0.552131; batch adversarial loss: 0.607416\n",
      "epoch 11; iter: 0; batch classifier loss: 0.562560; batch adversarial loss: 0.636210\n",
      "epoch 12; iter: 0; batch classifier loss: 0.492752; batch adversarial loss: 0.568428\n",
      "epoch 13; iter: 0; batch classifier loss: 0.583891; batch adversarial loss: 0.559338\n",
      "epoch 14; iter: 0; batch classifier loss: 0.567919; batch adversarial loss: 0.533871\n",
      "epoch 15; iter: 0; batch classifier loss: 0.503519; batch adversarial loss: 0.509695\n",
      "epoch 16; iter: 0; batch classifier loss: 0.493647; batch adversarial loss: 0.558290\n",
      "epoch 17; iter: 0; batch classifier loss: 0.474847; batch adversarial loss: 0.501325\n",
      "epoch 18; iter: 0; batch classifier loss: 0.522977; batch adversarial loss: 0.522949\n",
      "epoch 19; iter: 0; batch classifier loss: 0.483817; batch adversarial loss: 0.588768\n",
      "epoch 20; iter: 0; batch classifier loss: 0.493785; batch adversarial loss: 0.533325\n",
      "epoch 21; iter: 0; batch classifier loss: 0.550605; batch adversarial loss: 0.516050\n",
      "epoch 22; iter: 0; batch classifier loss: 0.452277; batch adversarial loss: 0.573017\n",
      "epoch 23; iter: 0; batch classifier loss: 0.430581; batch adversarial loss: 0.493859\n",
      "epoch 24; iter: 0; batch classifier loss: 0.472977; batch adversarial loss: 0.587971\n",
      "epoch 25; iter: 0; batch classifier loss: 0.462394; batch adversarial loss: 0.586233\n",
      "epoch 26; iter: 0; batch classifier loss: 0.521309; batch adversarial loss: 0.503632\n",
      "epoch 27; iter: 0; batch classifier loss: 0.443725; batch adversarial loss: 0.497408\n",
      "epoch 28; iter: 0; batch classifier loss: 0.441717; batch adversarial loss: 0.525418\n",
      "epoch 29; iter: 0; batch classifier loss: 0.515073; batch adversarial loss: 0.529056\n",
      "epoch 30; iter: 0; batch classifier loss: 0.462108; batch adversarial loss: 0.487843\n",
      "epoch 31; iter: 0; batch classifier loss: 0.538317; batch adversarial loss: 0.567644\n",
      "epoch 32; iter: 0; batch classifier loss: 0.447682; batch adversarial loss: 0.519563\n",
      "epoch 33; iter: 0; batch classifier loss: 0.456120; batch adversarial loss: 0.603941\n",
      "epoch 34; iter: 0; batch classifier loss: 0.438592; batch adversarial loss: 0.553236\n",
      "epoch 35; iter: 0; batch classifier loss: 0.501374; batch adversarial loss: 0.484976\n",
      "epoch 36; iter: 0; batch classifier loss: 0.461495; batch adversarial loss: 0.570075\n",
      "epoch 37; iter: 0; batch classifier loss: 0.490329; batch adversarial loss: 0.537406\n",
      "epoch 38; iter: 0; batch classifier loss: 0.444843; batch adversarial loss: 0.561887\n",
      "epoch 39; iter: 0; batch classifier loss: 0.479863; batch adversarial loss: 0.547337\n",
      "epoch 40; iter: 0; batch classifier loss: 0.446834; batch adversarial loss: 0.532026\n",
      "epoch 41; iter: 0; batch classifier loss: 0.452836; batch adversarial loss: 0.469445\n",
      "epoch 42; iter: 0; batch classifier loss: 0.474757; batch adversarial loss: 0.541603\n",
      "epoch 43; iter: 0; batch classifier loss: 0.404008; batch adversarial loss: 0.563257\n",
      "epoch 44; iter: 0; batch classifier loss: 0.434557; batch adversarial loss: 0.554804\n",
      "epoch 45; iter: 0; batch classifier loss: 0.425240; batch adversarial loss: 0.580885\n",
      "epoch 46; iter: 0; batch classifier loss: 0.517796; batch adversarial loss: 0.563493\n",
      "epoch 47; iter: 0; batch classifier loss: 0.437896; batch adversarial loss: 0.500862\n",
      "epoch 48; iter: 0; batch classifier loss: 0.459416; batch adversarial loss: 0.509942\n",
      "epoch 49; iter: 0; batch classifier loss: 0.444171; batch adversarial loss: 0.535902\n",
      "epoch 50; iter: 0; batch classifier loss: 0.399949; batch adversarial loss: 0.508990\n",
      "epoch 51; iter: 0; batch classifier loss: 0.443088; batch adversarial loss: 0.509027\n",
      "epoch 52; iter: 0; batch classifier loss: 0.389445; batch adversarial loss: 0.535228\n",
      "epoch 53; iter: 0; batch classifier loss: 0.381925; batch adversarial loss: 0.544711\n",
      "epoch 54; iter: 0; batch classifier loss: 0.462164; batch adversarial loss: 0.554211\n",
      "epoch 55; iter: 0; batch classifier loss: 0.389989; batch adversarial loss: 0.572118\n",
      "epoch 56; iter: 0; batch classifier loss: 0.449412; batch adversarial loss: 0.507999\n",
      "epoch 57; iter: 0; batch classifier loss: 0.473079; batch adversarial loss: 0.581081\n",
      "epoch 58; iter: 0; batch classifier loss: 0.360579; batch adversarial loss: 0.544589\n",
      "epoch 59; iter: 0; batch classifier loss: 0.435495; batch adversarial loss: 0.571792\n",
      "epoch 60; iter: 0; batch classifier loss: 0.402770; batch adversarial loss: 0.571772\n",
      "epoch 61; iter: 0; batch classifier loss: 0.379160; batch adversarial loss: 0.535459\n",
      "epoch 62; iter: 0; batch classifier loss: 0.350389; batch adversarial loss: 0.553825\n",
      "epoch 63; iter: 0; batch classifier loss: 0.424339; batch adversarial loss: 0.553418\n",
      "epoch 64; iter: 0; batch classifier loss: 0.295132; batch adversarial loss: 0.581029\n",
      "epoch 65; iter: 0; batch classifier loss: 0.412111; batch adversarial loss: 0.526053\n",
      "epoch 66; iter: 0; batch classifier loss: 0.395492; batch adversarial loss: 0.581396\n",
      "epoch 67; iter: 0; batch classifier loss: 0.399119; batch adversarial loss: 0.544665\n",
      "epoch 68; iter: 0; batch classifier loss: 0.430903; batch adversarial loss: 0.572692\n",
      "epoch 69; iter: 0; batch classifier loss: 0.405675; batch adversarial loss: 0.673334\n",
      "epoch 70; iter: 0; batch classifier loss: 0.364553; batch adversarial loss: 0.516998\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 71; iter: 0; batch classifier loss: 0.426951; batch adversarial loss: 0.508164\n",
      "epoch 72; iter: 0; batch classifier loss: 0.306925; batch adversarial loss: 0.571843\n",
      "epoch 73; iter: 0; batch classifier loss: 0.491673; batch adversarial loss: 0.581129\n",
      "epoch 74; iter: 0; batch classifier loss: 0.424017; batch adversarial loss: 0.489808\n",
      "epoch 75; iter: 0; batch classifier loss: 0.362971; batch adversarial loss: 0.507703\n",
      "epoch 76; iter: 0; batch classifier loss: 0.441980; batch adversarial loss: 0.553396\n",
      "epoch 77; iter: 0; batch classifier loss: 0.423069; batch adversarial loss: 0.507407\n",
      "epoch 78; iter: 0; batch classifier loss: 0.291993; batch adversarial loss: 0.499189\n",
      "epoch 79; iter: 0; batch classifier loss: 0.400060; batch adversarial loss: 0.543414\n",
      "epoch 80; iter: 0; batch classifier loss: 0.351812; batch adversarial loss: 0.517613\n",
      "epoch 81; iter: 0; batch classifier loss: 0.500368; batch adversarial loss: 0.562532\n",
      "epoch 82; iter: 0; batch classifier loss: 0.387733; batch adversarial loss: 0.554481\n",
      "epoch 83; iter: 0; batch classifier loss: 0.343113; batch adversarial loss: 0.489902\n",
      "epoch 84; iter: 0; batch classifier loss: 0.385886; batch adversarial loss: 0.544859\n",
      "epoch 85; iter: 0; batch classifier loss: 0.471384; batch adversarial loss: 0.553601\n",
      "epoch 86; iter: 0; batch classifier loss: 0.471131; batch adversarial loss: 0.498870\n",
      "epoch 87; iter: 0; batch classifier loss: 0.341657; batch adversarial loss: 0.581228\n",
      "epoch 88; iter: 0; batch classifier loss: 0.468379; batch adversarial loss: 0.590041\n",
      "epoch 89; iter: 0; batch classifier loss: 0.353745; batch adversarial loss: 0.526545\n",
      "epoch 90; iter: 0; batch classifier loss: 0.386138; batch adversarial loss: 0.589636\n",
      "epoch 91; iter: 0; batch classifier loss: 0.443740; batch adversarial loss: 0.607702\n",
      "epoch 92; iter: 0; batch classifier loss: 0.365406; batch adversarial loss: 0.581869\n",
      "epoch 93; iter: 0; batch classifier loss: 0.421884; batch adversarial loss: 0.525593\n",
      "epoch 94; iter: 0; batch classifier loss: 0.361404; batch adversarial loss: 0.590180\n",
      "epoch 95; iter: 0; batch classifier loss: 0.395990; batch adversarial loss: 0.545199\n",
      "epoch 96; iter: 0; batch classifier loss: 0.413853; batch adversarial loss: 0.571786\n",
      "epoch 97; iter: 0; batch classifier loss: 0.369901; batch adversarial loss: 0.545036\n",
      "epoch 98; iter: 0; batch classifier loss: 0.386297; batch adversarial loss: 0.544796\n",
      "epoch 99; iter: 0; batch classifier loss: 0.360533; batch adversarial loss: 0.552738\n",
      "epoch 100; iter: 0; batch classifier loss: 0.376024; batch adversarial loss: 0.562801\n",
      "epoch 101; iter: 0; batch classifier loss: 0.433918; batch adversarial loss: 0.517902\n",
      "epoch 102; iter: 0; batch classifier loss: 0.340606; batch adversarial loss: 0.663711\n",
      "epoch 103; iter: 0; batch classifier loss: 0.415624; batch adversarial loss: 0.617026\n",
      "epoch 104; iter: 0; batch classifier loss: 0.257274; batch adversarial loss: 0.580844\n",
      "epoch 105; iter: 0; batch classifier loss: 0.414742; batch adversarial loss: 0.590904\n",
      "epoch 106; iter: 0; batch classifier loss: 0.330430; batch adversarial loss: 0.481279\n",
      "epoch 107; iter: 0; batch classifier loss: 0.358335; batch adversarial loss: 0.471005\n",
      "epoch 108; iter: 0; batch classifier loss: 0.317517; batch adversarial loss: 0.570923\n",
      "epoch 109; iter: 0; batch classifier loss: 0.323256; batch adversarial loss: 0.562673\n",
      "epoch 110; iter: 0; batch classifier loss: 0.351985; batch adversarial loss: 0.617526\n",
      "epoch 111; iter: 0; batch classifier loss: 0.351435; batch adversarial loss: 0.579969\n",
      "epoch 112; iter: 0; batch classifier loss: 0.326234; batch adversarial loss: 0.627659\n",
      "epoch 113; iter: 0; batch classifier loss: 0.386320; batch adversarial loss: 0.572214\n",
      "epoch 114; iter: 0; batch classifier loss: 0.328043; batch adversarial loss: 0.480608\n",
      "epoch 115; iter: 0; batch classifier loss: 0.333608; batch adversarial loss: 0.499040\n",
      "epoch 116; iter: 0; batch classifier loss: 0.340878; batch adversarial loss: 0.526820\n",
      "epoch 117; iter: 0; batch classifier loss: 0.383834; batch adversarial loss: 0.581994\n",
      "epoch 118; iter: 0; batch classifier loss: 0.327848; batch adversarial loss: 0.590187\n",
      "epoch 119; iter: 0; batch classifier loss: 0.337732; batch adversarial loss: 0.462401\n",
      "epoch 120; iter: 0; batch classifier loss: 0.386305; batch adversarial loss: 0.497944\n",
      "epoch 121; iter: 0; batch classifier loss: 0.384988; batch adversarial loss: 0.498785\n",
      "epoch 122; iter: 0; batch classifier loss: 0.353231; batch adversarial loss: 0.516549\n",
      "epoch 123; iter: 0; batch classifier loss: 0.365640; batch adversarial loss: 0.534504\n",
      "epoch 124; iter: 0; batch classifier loss: 0.403765; batch adversarial loss: 0.489694\n",
      "epoch 125; iter: 0; batch classifier loss: 0.379729; batch adversarial loss: 0.562760\n",
      "epoch 126; iter: 0; batch classifier loss: 0.363251; batch adversarial loss: 0.582309\n",
      "epoch 127; iter: 0; batch classifier loss: 0.403521; batch adversarial loss: 0.571939\n",
      "epoch 128; iter: 0; batch classifier loss: 0.362349; batch adversarial loss: 0.535465\n",
      "epoch 129; iter: 0; batch classifier loss: 0.338738; batch adversarial loss: 0.562881\n",
      "epoch 130; iter: 0; batch classifier loss: 0.326642; batch adversarial loss: 0.535643\n",
      "epoch 131; iter: 0; batch classifier loss: 0.292157; batch adversarial loss: 0.571781\n",
      "epoch 132; iter: 0; batch classifier loss: 0.400996; batch adversarial loss: 0.599162\n",
      "epoch 133; iter: 0; batch classifier loss: 0.418855; batch adversarial loss: 0.599578\n",
      "epoch 134; iter: 0; batch classifier loss: 0.421681; batch adversarial loss: 0.534727\n",
      "epoch 135; iter: 0; batch classifier loss: 0.364271; batch adversarial loss: 0.644925\n",
      "epoch 136; iter: 0; batch classifier loss: 0.452840; batch adversarial loss: 0.627091\n",
      "epoch 137; iter: 0; batch classifier loss: 0.322741; batch adversarial loss: 0.461911\n",
      "epoch 138; iter: 0; batch classifier loss: 0.268128; batch adversarial loss: 0.534695\n",
      "epoch 139; iter: 0; batch classifier loss: 0.335789; batch adversarial loss: 0.562431\n",
      "epoch 140; iter: 0; batch classifier loss: 0.354943; batch adversarial loss: 0.527936\n",
      "epoch 141; iter: 0; batch classifier loss: 0.360542; batch adversarial loss: 0.562363\n",
      "epoch 142; iter: 0; batch classifier loss: 0.381069; batch adversarial loss: 0.470078\n",
      "epoch 143; iter: 0; batch classifier loss: 0.377659; batch adversarial loss: 0.488126\n",
      "epoch 144; iter: 0; batch classifier loss: 0.368160; batch adversarial loss: 0.580695\n",
      "epoch 145; iter: 0; batch classifier loss: 0.352636; batch adversarial loss: 0.590902\n",
      "epoch 146; iter: 0; batch classifier loss: 0.317114; batch adversarial loss: 0.489353\n",
      "epoch 147; iter: 0; batch classifier loss: 0.305626; batch adversarial loss: 0.517479\n",
      "epoch 148; iter: 0; batch classifier loss: 0.354996; batch adversarial loss: 0.581374\n",
      "epoch 149; iter: 0; batch classifier loss: 0.263279; batch adversarial loss: 0.498137\n",
      "epoch 150; iter: 0; batch classifier loss: 0.362904; batch adversarial loss: 0.489219\n",
      "epoch 151; iter: 0; batch classifier loss: 0.270264; batch adversarial loss: 0.560980\n",
      "epoch 152; iter: 0; batch classifier loss: 0.360948; batch adversarial loss: 0.497424\n",
      "epoch 153; iter: 0; batch classifier loss: 0.270650; batch adversarial loss: 0.525637\n",
      "epoch 154; iter: 0; batch classifier loss: 0.332356; batch adversarial loss: 0.535458\n",
      "epoch 155; iter: 0; batch classifier loss: 0.344961; batch adversarial loss: 0.507445\n",
      "epoch 156; iter: 0; batch classifier loss: 0.325476; batch adversarial loss: 0.497901\n",
      "epoch 157; iter: 0; batch classifier loss: 0.393251; batch adversarial loss: 0.544428\n",
      "epoch 158; iter: 0; batch classifier loss: 0.314876; batch adversarial loss: 0.536189\n",
      "epoch 159; iter: 0; batch classifier loss: 0.300776; batch adversarial loss: 0.590204\n",
      "epoch 160; iter: 0; batch classifier loss: 0.360739; batch adversarial loss: 0.545445\n",
      "epoch 161; iter: 0; batch classifier loss: 0.253176; batch adversarial loss: 0.600008\n",
      "epoch 162; iter: 0; batch classifier loss: 0.350733; batch adversarial loss: 0.580995\n",
      "epoch 163; iter: 0; batch classifier loss: 0.341562; batch adversarial loss: 0.589850\n",
      "epoch 164; iter: 0; batch classifier loss: 0.293814; batch adversarial loss: 0.579934\n",
      "epoch 165; iter: 0; batch classifier loss: 0.355344; batch adversarial loss: 0.545130\n",
      "epoch 166; iter: 0; batch classifier loss: 0.326292; batch adversarial loss: 0.536362\n",
      "epoch 167; iter: 0; batch classifier loss: 0.384529; batch adversarial loss: 0.535480\n",
      "epoch 168; iter: 0; batch classifier loss: 0.358134; batch adversarial loss: 0.618833\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 169; iter: 0; batch classifier loss: 0.325613; batch adversarial loss: 0.553491\n",
      "epoch 170; iter: 0; batch classifier loss: 0.363655; batch adversarial loss: 0.553413\n",
      "epoch 171; iter: 0; batch classifier loss: 0.358153; batch adversarial loss: 0.479491\n",
      "epoch 172; iter: 0; batch classifier loss: 0.308773; batch adversarial loss: 0.525455\n",
      "epoch 173; iter: 0; batch classifier loss: 0.278859; batch adversarial loss: 0.533448\n",
      "epoch 174; iter: 0; batch classifier loss: 0.375655; batch adversarial loss: 0.507735\n",
      "epoch 175; iter: 0; batch classifier loss: 0.300756; batch adversarial loss: 0.508109\n",
      "epoch 176; iter: 0; batch classifier loss: 0.370884; batch adversarial loss: 0.508575\n",
      "epoch 177; iter: 0; batch classifier loss: 0.298206; batch adversarial loss: 0.563320\n",
      "epoch 178; iter: 0; batch classifier loss: 0.295308; batch adversarial loss: 0.451559\n",
      "epoch 179; iter: 0; batch classifier loss: 0.310609; batch adversarial loss: 0.508603\n",
      "epoch 180; iter: 0; batch classifier loss: 0.374882; batch adversarial loss: 0.516890\n",
      "epoch 181; iter: 0; batch classifier loss: 0.371167; batch adversarial loss: 0.572081\n",
      "epoch 182; iter: 0; batch classifier loss: 0.322777; batch adversarial loss: 0.498293\n",
      "epoch 183; iter: 0; batch classifier loss: 0.321896; batch adversarial loss: 0.553729\n",
      "epoch 184; iter: 0; batch classifier loss: 0.413561; batch adversarial loss: 0.525759\n",
      "epoch 185; iter: 0; batch classifier loss: 0.355790; batch adversarial loss: 0.507193\n",
      "epoch 186; iter: 0; batch classifier loss: 0.328429; batch adversarial loss: 0.516556\n",
      "epoch 187; iter: 0; batch classifier loss: 0.382434; batch adversarial loss: 0.580326\n",
      "epoch 188; iter: 0; batch classifier loss: 0.400680; batch adversarial loss: 0.545592\n",
      "epoch 189; iter: 0; batch classifier loss: 0.296897; batch adversarial loss: 0.535327\n",
      "epoch 190; iter: 0; batch classifier loss: 0.418213; batch adversarial loss: 0.535369\n",
      "epoch 191; iter: 0; batch classifier loss: 0.349168; batch adversarial loss: 0.600102\n",
      "epoch 192; iter: 0; batch classifier loss: 0.309276; batch adversarial loss: 0.554286\n",
      "epoch 193; iter: 0; batch classifier loss: 0.327342; batch adversarial loss: 0.588591\n",
      "epoch 194; iter: 0; batch classifier loss: 0.344112; batch adversarial loss: 0.572346\n",
      "epoch 195; iter: 0; batch classifier loss: 0.316821; batch adversarial loss: 0.500451\n",
      "epoch 196; iter: 0; batch classifier loss: 0.297941; batch adversarial loss: 0.626788\n",
      "epoch 197; iter: 0; batch classifier loss: 0.398232; batch adversarial loss: 0.544087\n",
      "epoch 198; iter: 0; batch classifier loss: 0.350359; batch adversarial loss: 0.470986\n",
      "epoch 199; iter: 0; batch classifier loss: 0.382458; batch adversarial loss: 0.526521\n",
      "epoch 0; iter: 0; batch classifier loss: 0.760736; batch adversarial loss: 0.828206\n",
      "epoch 1; iter: 0; batch classifier loss: 0.784415; batch adversarial loss: 0.831555\n",
      "epoch 2; iter: 0; batch classifier loss: 0.790660; batch adversarial loss: 0.773459\n",
      "epoch 3; iter: 0; batch classifier loss: 0.644014; batch adversarial loss: 0.702872\n",
      "epoch 4; iter: 0; batch classifier loss: 0.549285; batch adversarial loss: 0.697555\n",
      "epoch 5; iter: 0; batch classifier loss: 0.554660; batch adversarial loss: 0.624822\n",
      "epoch 6; iter: 0; batch classifier loss: 0.540605; batch adversarial loss: 0.645395\n",
      "epoch 7; iter: 0; batch classifier loss: 0.533727; batch adversarial loss: 0.634343\n",
      "epoch 8; iter: 0; batch classifier loss: 0.580861; batch adversarial loss: 0.643048\n",
      "epoch 9; iter: 0; batch classifier loss: 0.574807; batch adversarial loss: 0.584012\n",
      "epoch 10; iter: 0; batch classifier loss: 0.573242; batch adversarial loss: 0.620334\n",
      "epoch 11; iter: 0; batch classifier loss: 0.611453; batch adversarial loss: 0.579991\n",
      "epoch 12; iter: 0; batch classifier loss: 0.557528; batch adversarial loss: 0.592642\n",
      "epoch 13; iter: 0; batch classifier loss: 0.540741; batch adversarial loss: 0.585565\n",
      "epoch 14; iter: 0; batch classifier loss: 0.527302; batch adversarial loss: 0.587070\n",
      "epoch 15; iter: 0; batch classifier loss: 0.518423; batch adversarial loss: 0.583700\n",
      "epoch 16; iter: 0; batch classifier loss: 0.565955; batch adversarial loss: 0.506522\n",
      "epoch 17; iter: 0; batch classifier loss: 0.543812; batch adversarial loss: 0.610150\n",
      "epoch 18; iter: 0; batch classifier loss: 0.556946; batch adversarial loss: 0.505952\n",
      "epoch 19; iter: 0; batch classifier loss: 0.498250; batch adversarial loss: 0.634998\n",
      "epoch 20; iter: 0; batch classifier loss: 0.529255; batch adversarial loss: 0.586146\n",
      "epoch 21; iter: 0; batch classifier loss: 0.481069; batch adversarial loss: 0.599090\n",
      "epoch 22; iter: 0; batch classifier loss: 0.419127; batch adversarial loss: 0.562623\n",
      "epoch 23; iter: 0; batch classifier loss: 0.462967; batch adversarial loss: 0.568794\n",
      "epoch 24; iter: 0; batch classifier loss: 0.490279; batch adversarial loss: 0.637893\n",
      "epoch 25; iter: 0; batch classifier loss: 0.503020; batch adversarial loss: 0.590394\n",
      "epoch 26; iter: 0; batch classifier loss: 0.468275; batch adversarial loss: 0.503776\n",
      "epoch 27; iter: 0; batch classifier loss: 0.539910; batch adversarial loss: 0.483810\n",
      "epoch 28; iter: 0; batch classifier loss: 0.450945; batch adversarial loss: 0.524931\n",
      "epoch 29; iter: 0; batch classifier loss: 0.453756; batch adversarial loss: 0.495559\n",
      "epoch 30; iter: 0; batch classifier loss: 0.499756; batch adversarial loss: 0.587372\n",
      "epoch 31; iter: 0; batch classifier loss: 0.455677; batch adversarial loss: 0.525224\n",
      "epoch 32; iter: 0; batch classifier loss: 0.511816; batch adversarial loss: 0.605837\n",
      "epoch 33; iter: 0; batch classifier loss: 0.429312; batch adversarial loss: 0.537909\n",
      "epoch 34; iter: 0; batch classifier loss: 0.506967; batch adversarial loss: 0.584135\n",
      "epoch 35; iter: 0; batch classifier loss: 0.455390; batch adversarial loss: 0.593247\n",
      "epoch 36; iter: 0; batch classifier loss: 0.437944; batch adversarial loss: 0.532182\n",
      "epoch 37; iter: 0; batch classifier loss: 0.445953; batch adversarial loss: 0.553219\n",
      "epoch 38; iter: 0; batch classifier loss: 0.532867; batch adversarial loss: 0.602853\n",
      "epoch 39; iter: 0; batch classifier loss: 0.414074; batch adversarial loss: 0.541867\n",
      "epoch 40; iter: 0; batch classifier loss: 0.487612; batch adversarial loss: 0.603426\n",
      "epoch 41; iter: 0; batch classifier loss: 0.468031; batch adversarial loss: 0.544914\n",
      "epoch 42; iter: 0; batch classifier loss: 0.477939; batch adversarial loss: 0.590385\n",
      "epoch 43; iter: 0; batch classifier loss: 0.440680; batch adversarial loss: 0.598543\n",
      "epoch 44; iter: 0; batch classifier loss: 0.435223; batch adversarial loss: 0.580778\n",
      "epoch 45; iter: 0; batch classifier loss: 0.456520; batch adversarial loss: 0.538063\n",
      "epoch 46; iter: 0; batch classifier loss: 0.448613; batch adversarial loss: 0.587908\n",
      "epoch 47; iter: 0; batch classifier loss: 0.487057; batch adversarial loss: 0.588789\n",
      "epoch 48; iter: 0; batch classifier loss: 0.489373; batch adversarial loss: 0.571267\n",
      "epoch 49; iter: 0; batch classifier loss: 0.420975; batch adversarial loss: 0.544718\n",
      "epoch 50; iter: 0; batch classifier loss: 0.474405; batch adversarial loss: 0.527177\n",
      "epoch 51; iter: 0; batch classifier loss: 0.486918; batch adversarial loss: 0.536067\n",
      "epoch 52; iter: 0; batch classifier loss: 0.510353; batch adversarial loss: 0.639781\n",
      "epoch 53; iter: 0; batch classifier loss: 0.390675; batch adversarial loss: 0.623572\n",
      "epoch 54; iter: 0; batch classifier loss: 0.383590; batch adversarial loss: 0.509519\n",
      "epoch 55; iter: 0; batch classifier loss: 0.429327; batch adversarial loss: 0.607661\n",
      "epoch 56; iter: 0; batch classifier loss: 0.473855; batch adversarial loss: 0.509497\n",
      "epoch 57; iter: 0; batch classifier loss: 0.453902; batch adversarial loss: 0.580263\n",
      "epoch 58; iter: 0; batch classifier loss: 0.404715; batch adversarial loss: 0.588053\n",
      "epoch 59; iter: 0; batch classifier loss: 0.380906; batch adversarial loss: 0.554927\n",
      "epoch 60; iter: 0; batch classifier loss: 0.403469; batch adversarial loss: 0.534445\n",
      "epoch 61; iter: 0; batch classifier loss: 0.452984; batch adversarial loss: 0.573961\n",
      "epoch 62; iter: 0; batch classifier loss: 0.524005; batch adversarial loss: 0.536475\n",
      "epoch 63; iter: 0; batch classifier loss: 0.439660; batch adversarial loss: 0.568253\n",
      "epoch 64; iter: 0; batch classifier loss: 0.454551; batch adversarial loss: 0.526448\n",
      "epoch 65; iter: 0; batch classifier loss: 0.430847; batch adversarial loss: 0.503626\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 66; iter: 0; batch classifier loss: 0.386372; batch adversarial loss: 0.557463\n",
      "epoch 67; iter: 0; batch classifier loss: 0.423696; batch adversarial loss: 0.590382\n",
      "epoch 68; iter: 0; batch classifier loss: 0.369318; batch adversarial loss: 0.550219\n",
      "epoch 69; iter: 0; batch classifier loss: 0.403114; batch adversarial loss: 0.531218\n",
      "epoch 70; iter: 0; batch classifier loss: 0.490551; batch adversarial loss: 0.522957\n",
      "epoch 71; iter: 0; batch classifier loss: 0.490466; batch adversarial loss: 0.539054\n",
      "epoch 72; iter: 0; batch classifier loss: 0.392177; batch adversarial loss: 0.524450\n",
      "epoch 73; iter: 0; batch classifier loss: 0.387775; batch adversarial loss: 0.622877\n",
      "epoch 74; iter: 0; batch classifier loss: 0.415725; batch adversarial loss: 0.516737\n",
      "epoch 75; iter: 0; batch classifier loss: 0.440767; batch adversarial loss: 0.499304\n",
      "epoch 76; iter: 0; batch classifier loss: 0.418075; batch adversarial loss: 0.504374\n",
      "epoch 77; iter: 0; batch classifier loss: 0.362678; batch adversarial loss: 0.538214\n",
      "epoch 78; iter: 0; batch classifier loss: 0.456451; batch adversarial loss: 0.624931\n",
      "epoch 79; iter: 0; batch classifier loss: 0.308454; batch adversarial loss: 0.552659\n",
      "epoch 80; iter: 0; batch classifier loss: 0.477081; batch adversarial loss: 0.525146\n",
      "epoch 81; iter: 0; batch classifier loss: 0.433528; batch adversarial loss: 0.608138\n",
      "epoch 82; iter: 0; batch classifier loss: 0.443825; batch adversarial loss: 0.508420\n",
      "epoch 83; iter: 0; batch classifier loss: 0.445082; batch adversarial loss: 0.584368\n",
      "epoch 84; iter: 0; batch classifier loss: 0.433745; batch adversarial loss: 0.627085\n",
      "epoch 85; iter: 0; batch classifier loss: 0.419095; batch adversarial loss: 0.564646\n",
      "epoch 86; iter: 0; batch classifier loss: 0.407670; batch adversarial loss: 0.521482\n",
      "epoch 87; iter: 0; batch classifier loss: 0.412961; batch adversarial loss: 0.554141\n",
      "epoch 88; iter: 0; batch classifier loss: 0.340501; batch adversarial loss: 0.512337\n",
      "epoch 89; iter: 0; batch classifier loss: 0.390718; batch adversarial loss: 0.507334\n",
      "epoch 90; iter: 0; batch classifier loss: 0.316005; batch adversarial loss: 0.535561\n",
      "epoch 91; iter: 0; batch classifier loss: 0.394754; batch adversarial loss: 0.614646\n",
      "epoch 92; iter: 0; batch classifier loss: 0.367322; batch adversarial loss: 0.570195\n",
      "epoch 93; iter: 0; batch classifier loss: 0.375525; batch adversarial loss: 0.575294\n",
      "epoch 94; iter: 0; batch classifier loss: 0.365417; batch adversarial loss: 0.479694\n",
      "epoch 95; iter: 0; batch classifier loss: 0.381209; batch adversarial loss: 0.555563\n",
      "epoch 96; iter: 0; batch classifier loss: 0.410819; batch adversarial loss: 0.562859\n",
      "epoch 97; iter: 0; batch classifier loss: 0.446717; batch adversarial loss: 0.585227\n",
      "epoch 98; iter: 0; batch classifier loss: 0.489486; batch adversarial loss: 0.630974\n",
      "epoch 99; iter: 0; batch classifier loss: 0.331056; batch adversarial loss: 0.592676\n",
      "epoch 100; iter: 0; batch classifier loss: 0.349340; batch adversarial loss: 0.558848\n",
      "epoch 101; iter: 0; batch classifier loss: 0.484315; batch adversarial loss: 0.598039\n",
      "epoch 102; iter: 0; batch classifier loss: 0.376174; batch adversarial loss: 0.521986\n",
      "epoch 103; iter: 0; batch classifier loss: 0.365674; batch adversarial loss: 0.462983\n",
      "epoch 104; iter: 0; batch classifier loss: 0.431283; batch adversarial loss: 0.493141\n",
      "epoch 105; iter: 0; batch classifier loss: 0.435708; batch adversarial loss: 0.632229\n",
      "epoch 106; iter: 0; batch classifier loss: 0.397104; batch adversarial loss: 0.537578\n",
      "epoch 107; iter: 0; batch classifier loss: 0.380550; batch adversarial loss: 0.596862\n",
      "epoch 108; iter: 0; batch classifier loss: 0.441353; batch adversarial loss: 0.534772\n",
      "epoch 109; iter: 0; batch classifier loss: 0.373394; batch adversarial loss: 0.519747\n",
      "epoch 110; iter: 0; batch classifier loss: 0.390185; batch adversarial loss: 0.570250\n",
      "epoch 111; iter: 0; batch classifier loss: 0.366389; batch adversarial loss: 0.559454\n",
      "epoch 112; iter: 0; batch classifier loss: 0.370146; batch adversarial loss: 0.578043\n",
      "epoch 113; iter: 0; batch classifier loss: 0.371656; batch adversarial loss: 0.597956\n",
      "epoch 114; iter: 0; batch classifier loss: 0.448538; batch adversarial loss: 0.595353\n",
      "epoch 115; iter: 0; batch classifier loss: 0.339681; batch adversarial loss: 0.534167\n",
      "epoch 116; iter: 0; batch classifier loss: 0.406671; batch adversarial loss: 0.601194\n",
      "epoch 117; iter: 0; batch classifier loss: 0.380281; batch adversarial loss: 0.513631\n",
      "epoch 118; iter: 0; batch classifier loss: 0.339332; batch adversarial loss: 0.580180\n",
      "epoch 119; iter: 0; batch classifier loss: 0.364695; batch adversarial loss: 0.532666\n",
      "epoch 120; iter: 0; batch classifier loss: 0.412268; batch adversarial loss: 0.536565\n",
      "epoch 121; iter: 0; batch classifier loss: 0.455239; batch adversarial loss: 0.626414\n",
      "epoch 122; iter: 0; batch classifier loss: 0.395929; batch adversarial loss: 0.436054\n",
      "epoch 123; iter: 0; batch classifier loss: 0.366230; batch adversarial loss: 0.555804\n",
      "epoch 124; iter: 0; batch classifier loss: 0.371995; batch adversarial loss: 0.518222\n",
      "epoch 125; iter: 0; batch classifier loss: 0.438746; batch adversarial loss: 0.479678\n",
      "epoch 126; iter: 0; batch classifier loss: 0.329594; batch adversarial loss: 0.584662\n",
      "epoch 127; iter: 0; batch classifier loss: 0.387449; batch adversarial loss: 0.470748\n",
      "epoch 128; iter: 0; batch classifier loss: 0.358746; batch adversarial loss: 0.578470\n",
      "epoch 129; iter: 0; batch classifier loss: 0.379534; batch adversarial loss: 0.458078\n",
      "epoch 130; iter: 0; batch classifier loss: 0.428028; batch adversarial loss: 0.525106\n",
      "epoch 131; iter: 0; batch classifier loss: 0.392822; batch adversarial loss: 0.463502\n",
      "epoch 132; iter: 0; batch classifier loss: 0.352551; batch adversarial loss: 0.507297\n",
      "epoch 133; iter: 0; batch classifier loss: 0.425458; batch adversarial loss: 0.496525\n",
      "epoch 134; iter: 0; batch classifier loss: 0.456410; batch adversarial loss: 0.556836\n",
      "epoch 135; iter: 0; batch classifier loss: 0.377121; batch adversarial loss: 0.539248\n",
      "epoch 136; iter: 0; batch classifier loss: 0.392837; batch adversarial loss: 0.525984\n",
      "epoch 137; iter: 0; batch classifier loss: 0.404194; batch adversarial loss: 0.562439\n",
      "epoch 138; iter: 0; batch classifier loss: 0.317384; batch adversarial loss: 0.540137\n",
      "epoch 139; iter: 0; batch classifier loss: 0.327272; batch adversarial loss: 0.516623\n",
      "epoch 140; iter: 0; batch classifier loss: 0.353015; batch adversarial loss: 0.545854\n",
      "epoch 141; iter: 0; batch classifier loss: 0.372835; batch adversarial loss: 0.536380\n",
      "epoch 142; iter: 0; batch classifier loss: 0.352967; batch adversarial loss: 0.581362\n",
      "epoch 143; iter: 0; batch classifier loss: 0.433396; batch adversarial loss: 0.578033\n",
      "epoch 144; iter: 0; batch classifier loss: 0.384761; batch adversarial loss: 0.598820\n",
      "epoch 145; iter: 0; batch classifier loss: 0.452660; batch adversarial loss: 0.567435\n",
      "epoch 146; iter: 0; batch classifier loss: 0.484153; batch adversarial loss: 0.607254\n",
      "epoch 147; iter: 0; batch classifier loss: 0.318590; batch adversarial loss: 0.558719\n",
      "epoch 148; iter: 0; batch classifier loss: 0.397506; batch adversarial loss: 0.541526\n",
      "epoch 149; iter: 0; batch classifier loss: 0.368239; batch adversarial loss: 0.515357\n",
      "epoch 150; iter: 0; batch classifier loss: 0.433032; batch adversarial loss: 0.602066\n",
      "epoch 151; iter: 0; batch classifier loss: 0.409437; batch adversarial loss: 0.579575\n",
      "epoch 152; iter: 0; batch classifier loss: 0.304992; batch adversarial loss: 0.500790\n",
      "epoch 153; iter: 0; batch classifier loss: 0.370105; batch adversarial loss: 0.529119\n",
      "epoch 154; iter: 0; batch classifier loss: 0.374149; batch adversarial loss: 0.551497\n",
      "epoch 155; iter: 0; batch classifier loss: 0.402382; batch adversarial loss: 0.611501\n",
      "epoch 156; iter: 0; batch classifier loss: 0.331216; batch adversarial loss: 0.547864\n",
      "epoch 157; iter: 0; batch classifier loss: 0.417317; batch adversarial loss: 0.640734\n",
      "epoch 158; iter: 0; batch classifier loss: 0.438589; batch adversarial loss: 0.497953\n",
      "epoch 159; iter: 0; batch classifier loss: 0.458900; batch adversarial loss: 0.579733\n",
      "epoch 160; iter: 0; batch classifier loss: 0.354981; batch adversarial loss: 0.530103\n",
      "epoch 161; iter: 0; batch classifier loss: 0.367023; batch adversarial loss: 0.528917\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 162; iter: 0; batch classifier loss: 0.348884; batch adversarial loss: 0.470924\n",
      "epoch 163; iter: 0; batch classifier loss: 0.403352; batch adversarial loss: 0.576485\n",
      "epoch 164; iter: 0; batch classifier loss: 0.445902; batch adversarial loss: 0.600354\n",
      "epoch 165; iter: 0; batch classifier loss: 0.430446; batch adversarial loss: 0.582927\n",
      "epoch 166; iter: 0; batch classifier loss: 0.449896; batch adversarial loss: 0.550816\n",
      "epoch 167; iter: 0; batch classifier loss: 0.291122; batch adversarial loss: 0.579212\n",
      "epoch 168; iter: 0; batch classifier loss: 0.378107; batch adversarial loss: 0.561891\n",
      "epoch 169; iter: 0; batch classifier loss: 0.476062; batch adversarial loss: 0.632844\n",
      "epoch 170; iter: 0; batch classifier loss: 0.362554; batch adversarial loss: 0.574677\n",
      "epoch 171; iter: 0; batch classifier loss: 0.456457; batch adversarial loss: 0.559921\n",
      "epoch 172; iter: 0; batch classifier loss: 0.410401; batch adversarial loss: 0.558491\n",
      "epoch 173; iter: 0; batch classifier loss: 0.335918; batch adversarial loss: 0.556322\n",
      "epoch 174; iter: 0; batch classifier loss: 0.293340; batch adversarial loss: 0.638814\n",
      "epoch 175; iter: 0; batch classifier loss: 0.376680; batch adversarial loss: 0.468924\n",
      "epoch 176; iter: 0; batch classifier loss: 0.410382; batch adversarial loss: 0.573427\n",
      "epoch 177; iter: 0; batch classifier loss: 0.392993; batch adversarial loss: 0.631677\n",
      "epoch 178; iter: 0; batch classifier loss: 0.364203; batch adversarial loss: 0.589312\n",
      "epoch 179; iter: 0; batch classifier loss: 0.411545; batch adversarial loss: 0.573992\n",
      "epoch 180; iter: 0; batch classifier loss: 0.458263; batch adversarial loss: 0.550966\n",
      "epoch 181; iter: 0; batch classifier loss: 0.412463; batch adversarial loss: 0.530566\n",
      "epoch 182; iter: 0; batch classifier loss: 0.385086; batch adversarial loss: 0.536300\n",
      "epoch 183; iter: 0; batch classifier loss: 0.282329; batch adversarial loss: 0.559501\n",
      "epoch 184; iter: 0; batch classifier loss: 0.390829; batch adversarial loss: 0.563939\n",
      "epoch 185; iter: 0; batch classifier loss: 0.380828; batch adversarial loss: 0.530717\n",
      "epoch 186; iter: 0; batch classifier loss: 0.333374; batch adversarial loss: 0.617887\n",
      "epoch 187; iter: 0; batch classifier loss: 0.307372; batch adversarial loss: 0.455475\n",
      "epoch 188; iter: 0; batch classifier loss: 0.335981; batch adversarial loss: 0.453175\n",
      "epoch 189; iter: 0; batch classifier loss: 0.365001; batch adversarial loss: 0.528287\n",
      "epoch 190; iter: 0; batch classifier loss: 0.367600; batch adversarial loss: 0.536262\n",
      "epoch 191; iter: 0; batch classifier loss: 0.377352; batch adversarial loss: 0.568442\n",
      "epoch 192; iter: 0; batch classifier loss: 0.400750; batch adversarial loss: 0.572423\n",
      "epoch 193; iter: 0; batch classifier loss: 0.330851; batch adversarial loss: 0.496074\n",
      "epoch 194; iter: 0; batch classifier loss: 0.366815; batch adversarial loss: 0.537629\n",
      "epoch 195; iter: 0; batch classifier loss: 0.358587; batch adversarial loss: 0.505145\n",
      "epoch 196; iter: 0; batch classifier loss: 0.379923; batch adversarial loss: 0.560846\n",
      "epoch 197; iter: 0; batch classifier loss: 0.369436; batch adversarial loss: 0.601052\n",
      "epoch 198; iter: 0; batch classifier loss: 0.397568; batch adversarial loss: 0.616731\n",
      "epoch 199; iter: 0; batch classifier loss: 0.340164; batch adversarial loss: 0.602724\n",
      "epoch 0; iter: 0; batch classifier loss: 0.681754; batch adversarial loss: 0.711043\n",
      "epoch 1; iter: 0; batch classifier loss: 0.618915; batch adversarial loss: 0.694484\n",
      "epoch 2; iter: 0; batch classifier loss: 0.573178; batch adversarial loss: 0.655370\n",
      "epoch 3; iter: 0; batch classifier loss: 0.631801; batch adversarial loss: 0.641315\n",
      "epoch 4; iter: 0; batch classifier loss: 0.619213; batch adversarial loss: 0.636309\n",
      "epoch 5; iter: 0; batch classifier loss: 0.517419; batch adversarial loss: 0.621768\n",
      "epoch 6; iter: 0; batch classifier loss: 0.494785; batch adversarial loss: 0.599681\n",
      "epoch 7; iter: 0; batch classifier loss: 0.550742; batch adversarial loss: 0.604853\n",
      "epoch 8; iter: 0; batch classifier loss: 0.498160; batch adversarial loss: 0.594628\n",
      "epoch 9; iter: 0; batch classifier loss: 0.481965; batch adversarial loss: 0.612315\n",
      "epoch 10; iter: 0; batch classifier loss: 0.601457; batch adversarial loss: 0.536272\n",
      "epoch 11; iter: 0; batch classifier loss: 0.511994; batch adversarial loss: 0.554405\n",
      "epoch 12; iter: 0; batch classifier loss: 0.557729; batch adversarial loss: 0.571432\n",
      "epoch 13; iter: 0; batch classifier loss: 0.516072; batch adversarial loss: 0.566271\n",
      "epoch 14; iter: 0; batch classifier loss: 0.541354; batch adversarial loss: 0.514989\n",
      "epoch 15; iter: 0; batch classifier loss: 0.549709; batch adversarial loss: 0.488472\n",
      "epoch 16; iter: 0; batch classifier loss: 0.612271; batch adversarial loss: 0.603410\n",
      "epoch 17; iter: 0; batch classifier loss: 0.501889; batch adversarial loss: 0.544425\n",
      "epoch 18; iter: 0; batch classifier loss: 0.561011; batch adversarial loss: 0.561401\n",
      "epoch 19; iter: 0; batch classifier loss: 0.531781; batch adversarial loss: 0.596983\n",
      "epoch 20; iter: 0; batch classifier loss: 0.543598; batch adversarial loss: 0.522329\n",
      "epoch 21; iter: 0; batch classifier loss: 0.456255; batch adversarial loss: 0.545048\n",
      "epoch 22; iter: 0; batch classifier loss: 0.450729; batch adversarial loss: 0.500755\n",
      "epoch 23; iter: 0; batch classifier loss: 0.512831; batch adversarial loss: 0.488302\n",
      "epoch 24; iter: 0; batch classifier loss: 0.457780; batch adversarial loss: 0.582877\n",
      "epoch 25; iter: 0; batch classifier loss: 0.510053; batch adversarial loss: 0.472693\n",
      "epoch 26; iter: 0; batch classifier loss: 0.458840; batch adversarial loss: 0.638498\n",
      "epoch 27; iter: 0; batch classifier loss: 0.476352; batch adversarial loss: 0.491494\n",
      "epoch 28; iter: 0; batch classifier loss: 0.463338; batch adversarial loss: 0.534341\n",
      "epoch 29; iter: 0; batch classifier loss: 0.451339; batch adversarial loss: 0.525577\n",
      "epoch 30; iter: 0; batch classifier loss: 0.448961; batch adversarial loss: 0.486579\n",
      "epoch 31; iter: 0; batch classifier loss: 0.453383; batch adversarial loss: 0.526016\n",
      "epoch 32; iter: 0; batch classifier loss: 0.488152; batch adversarial loss: 0.574889\n",
      "epoch 33; iter: 0; batch classifier loss: 0.420955; batch adversarial loss: 0.555219\n",
      "epoch 34; iter: 0; batch classifier loss: 0.514226; batch adversarial loss: 0.482459\n",
      "epoch 35; iter: 0; batch classifier loss: 0.410887; batch adversarial loss: 0.524884\n",
      "epoch 36; iter: 0; batch classifier loss: 0.427081; batch adversarial loss: 0.609593\n",
      "epoch 37; iter: 0; batch classifier loss: 0.462914; batch adversarial loss: 0.516754\n",
      "epoch 38; iter: 0; batch classifier loss: 0.464150; batch adversarial loss: 0.478760\n",
      "epoch 39; iter: 0; batch classifier loss: 0.439287; batch adversarial loss: 0.545914\n",
      "epoch 40; iter: 0; batch classifier loss: 0.492325; batch adversarial loss: 0.517174\n",
      "epoch 41; iter: 0; batch classifier loss: 0.411331; batch adversarial loss: 0.507465\n",
      "epoch 42; iter: 0; batch classifier loss: 0.352909; batch adversarial loss: 0.525334\n",
      "epoch 43; iter: 0; batch classifier loss: 0.481232; batch adversarial loss: 0.515926\n",
      "epoch 44; iter: 0; batch classifier loss: 0.469903; batch adversarial loss: 0.545175\n",
      "epoch 45; iter: 0; batch classifier loss: 0.417502; batch adversarial loss: 0.554279\n",
      "epoch 46; iter: 0; batch classifier loss: 0.380953; batch adversarial loss: 0.486898\n",
      "epoch 47; iter: 0; batch classifier loss: 0.407022; batch adversarial loss: 0.574249\n",
      "epoch 48; iter: 0; batch classifier loss: 0.410567; batch adversarial loss: 0.544745\n",
      "epoch 49; iter: 0; batch classifier loss: 0.353744; batch adversarial loss: 0.592874\n",
      "epoch 50; iter: 0; batch classifier loss: 0.418511; batch adversarial loss: 0.563812\n",
      "epoch 51; iter: 0; batch classifier loss: 0.379599; batch adversarial loss: 0.544785\n",
      "epoch 52; iter: 0; batch classifier loss: 0.353827; batch adversarial loss: 0.475399\n",
      "epoch 53; iter: 0; batch classifier loss: 0.413497; batch adversarial loss: 0.505778\n",
      "epoch 54; iter: 0; batch classifier loss: 0.420467; batch adversarial loss: 0.534379\n",
      "epoch 55; iter: 0; batch classifier loss: 0.433072; batch adversarial loss: 0.506437\n",
      "epoch 56; iter: 0; batch classifier loss: 0.377437; batch adversarial loss: 0.486742\n",
      "epoch 57; iter: 0; batch classifier loss: 0.397330; batch adversarial loss: 0.563943\n",
      "epoch 58; iter: 0; batch classifier loss: 0.392673; batch adversarial loss: 0.564639\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 59; iter: 0; batch classifier loss: 0.468636; batch adversarial loss: 0.632570\n",
      "epoch 60; iter: 0; batch classifier loss: 0.437480; batch adversarial loss: 0.486052\n",
      "epoch 61; iter: 0; batch classifier loss: 0.417526; batch adversarial loss: 0.525331\n",
      "epoch 62; iter: 0; batch classifier loss: 0.364291; batch adversarial loss: 0.593013\n",
      "epoch 63; iter: 0; batch classifier loss: 0.381158; batch adversarial loss: 0.544195\n",
      "epoch 64; iter: 0; batch classifier loss: 0.409039; batch adversarial loss: 0.477641\n",
      "epoch 65; iter: 0; batch classifier loss: 0.393826; batch adversarial loss: 0.662382\n",
      "epoch 66; iter: 0; batch classifier loss: 0.409241; batch adversarial loss: 0.517014\n",
      "epoch 67; iter: 0; batch classifier loss: 0.392655; batch adversarial loss: 0.553205\n",
      "epoch 68; iter: 0; batch classifier loss: 0.418665; batch adversarial loss: 0.486625\n",
      "epoch 69; iter: 0; batch classifier loss: 0.440897; batch adversarial loss: 0.593688\n",
      "epoch 70; iter: 0; batch classifier loss: 0.396398; batch adversarial loss: 0.515854\n",
      "epoch 71; iter: 0; batch classifier loss: 0.389887; batch adversarial loss: 0.505378\n",
      "epoch 72; iter: 0; batch classifier loss: 0.349987; batch adversarial loss: 0.525300\n",
      "epoch 73; iter: 0; batch classifier loss: 0.422925; batch adversarial loss: 0.555246\n",
      "epoch 74; iter: 0; batch classifier loss: 0.412592; batch adversarial loss: 0.563659\n",
      "epoch 75; iter: 0; batch classifier loss: 0.353392; batch adversarial loss: 0.525878\n",
      "epoch 76; iter: 0; batch classifier loss: 0.404988; batch adversarial loss: 0.533358\n",
      "epoch 77; iter: 0; batch classifier loss: 0.400564; batch adversarial loss: 0.486370\n",
      "epoch 78; iter: 0; batch classifier loss: 0.337355; batch adversarial loss: 0.602994\n",
      "epoch 79; iter: 0; batch classifier loss: 0.427302; batch adversarial loss: 0.505689\n",
      "epoch 80; iter: 0; batch classifier loss: 0.399596; batch adversarial loss: 0.545218\n",
      "epoch 81; iter: 0; batch classifier loss: 0.450310; batch adversarial loss: 0.525563\n",
      "epoch 82; iter: 0; batch classifier loss: 0.488303; batch adversarial loss: 0.535275\n",
      "epoch 83; iter: 0; batch classifier loss: 0.437738; batch adversarial loss: 0.504586\n",
      "epoch 84; iter: 0; batch classifier loss: 0.431648; batch adversarial loss: 0.466969\n",
      "epoch 85; iter: 0; batch classifier loss: 0.418751; batch adversarial loss: 0.446883\n",
      "epoch 86; iter: 0; batch classifier loss: 0.404882; batch adversarial loss: 0.497414\n",
      "epoch 87; iter: 0; batch classifier loss: 0.447176; batch adversarial loss: 0.516406\n",
      "epoch 88; iter: 0; batch classifier loss: 0.478012; batch adversarial loss: 0.593264\n",
      "epoch 89; iter: 0; batch classifier loss: 0.385514; batch adversarial loss: 0.592628\n",
      "epoch 90; iter: 0; batch classifier loss: 0.412078; batch adversarial loss: 0.534979\n",
      "epoch 91; iter: 0; batch classifier loss: 0.409041; batch adversarial loss: 0.622255\n",
      "epoch 92; iter: 0; batch classifier loss: 0.358433; batch adversarial loss: 0.702021\n",
      "epoch 93; iter: 0; batch classifier loss: 0.393216; batch adversarial loss: 0.514004\n",
      "epoch 94; iter: 0; batch classifier loss: 0.349890; batch adversarial loss: 0.544366\n",
      "epoch 95; iter: 0; batch classifier loss: 0.396459; batch adversarial loss: 0.554611\n",
      "epoch 96; iter: 0; batch classifier loss: 0.326390; batch adversarial loss: 0.552196\n",
      "epoch 97; iter: 0; batch classifier loss: 0.388351; batch adversarial loss: 0.594100\n",
      "epoch 98; iter: 0; batch classifier loss: 0.360507; batch adversarial loss: 0.445598\n",
      "epoch 99; iter: 0; batch classifier loss: 0.422432; batch adversarial loss: 0.544757\n",
      "epoch 100; iter: 0; batch classifier loss: 0.372349; batch adversarial loss: 0.497032\n",
      "epoch 101; iter: 0; batch classifier loss: 0.437090; batch adversarial loss: 0.497223\n",
      "epoch 102; iter: 0; batch classifier loss: 0.410294; batch adversarial loss: 0.563199\n",
      "epoch 103; iter: 0; batch classifier loss: 0.362567; batch adversarial loss: 0.535241\n",
      "epoch 104; iter: 0; batch classifier loss: 0.364761; batch adversarial loss: 0.604412\n",
      "epoch 105; iter: 0; batch classifier loss: 0.360346; batch adversarial loss: 0.584469\n",
      "epoch 106; iter: 0; batch classifier loss: 0.333479; batch adversarial loss: 0.494359\n",
      "epoch 107; iter: 0; batch classifier loss: 0.418980; batch adversarial loss: 0.515116\n",
      "epoch 108; iter: 0; batch classifier loss: 0.348988; batch adversarial loss: 0.575673\n",
      "epoch 109; iter: 0; batch classifier loss: 0.376494; batch adversarial loss: 0.544687\n",
      "epoch 110; iter: 0; batch classifier loss: 0.408983; batch adversarial loss: 0.555190\n",
      "epoch 111; iter: 0; batch classifier loss: 0.394140; batch adversarial loss: 0.505260\n",
      "epoch 112; iter: 0; batch classifier loss: 0.355634; batch adversarial loss: 0.496981\n",
      "epoch 113; iter: 0; batch classifier loss: 0.358263; batch adversarial loss: 0.523067\n",
      "epoch 114; iter: 0; batch classifier loss: 0.338231; batch adversarial loss: 0.485951\n",
      "epoch 115; iter: 0; batch classifier loss: 0.303440; batch adversarial loss: 0.495846\n",
      "epoch 116; iter: 0; batch classifier loss: 0.447668; batch adversarial loss: 0.476086\n",
      "epoch 117; iter: 0; batch classifier loss: 0.332554; batch adversarial loss: 0.496745\n",
      "epoch 118; iter: 0; batch classifier loss: 0.340306; batch adversarial loss: 0.515660\n",
      "epoch 119; iter: 0; batch classifier loss: 0.300399; batch adversarial loss: 0.464753\n",
      "epoch 120; iter: 0; batch classifier loss: 0.450903; batch adversarial loss: 0.524220\n",
      "epoch 121; iter: 0; batch classifier loss: 0.353098; batch adversarial loss: 0.543591\n",
      "epoch 122; iter: 0; batch classifier loss: 0.330105; batch adversarial loss: 0.524234\n",
      "epoch 123; iter: 0; batch classifier loss: 0.337026; batch adversarial loss: 0.612722\n",
      "epoch 124; iter: 0; batch classifier loss: 0.379737; batch adversarial loss: 0.571774\n",
      "epoch 125; iter: 0; batch classifier loss: 0.380418; batch adversarial loss: 0.613095\n",
      "epoch 126; iter: 0; batch classifier loss: 0.417953; batch adversarial loss: 0.641057\n",
      "epoch 127; iter: 0; batch classifier loss: 0.364454; batch adversarial loss: 0.544433\n",
      "epoch 128; iter: 0; batch classifier loss: 0.359620; batch adversarial loss: 0.594380\n",
      "epoch 129; iter: 0; batch classifier loss: 0.364236; batch adversarial loss: 0.485964\n",
      "epoch 130; iter: 0; batch classifier loss: 0.371969; batch adversarial loss: 0.538272\n",
      "epoch 131; iter: 0; batch classifier loss: 0.348628; batch adversarial loss: 0.555381\n",
      "epoch 132; iter: 0; batch classifier loss: 0.365736; batch adversarial loss: 0.534899\n",
      "epoch 133; iter: 0; batch classifier loss: 0.352274; batch adversarial loss: 0.511985\n",
      "epoch 134; iter: 0; batch classifier loss: 0.411447; batch adversarial loss: 0.506355\n",
      "epoch 135; iter: 0; batch classifier loss: 0.361062; batch adversarial loss: 0.564234\n",
      "epoch 136; iter: 0; batch classifier loss: 0.369118; batch adversarial loss: 0.515428\n",
      "epoch 137; iter: 0; batch classifier loss: 0.354357; batch adversarial loss: 0.427573\n",
      "epoch 138; iter: 0; batch classifier loss: 0.333461; batch adversarial loss: 0.534408\n",
      "epoch 139; iter: 0; batch classifier loss: 0.395567; batch adversarial loss: 0.415897\n",
      "epoch 140; iter: 0; batch classifier loss: 0.375386; batch adversarial loss: 0.495000\n",
      "epoch 141; iter: 0; batch classifier loss: 0.391443; batch adversarial loss: 0.477133\n",
      "epoch 142; iter: 0; batch classifier loss: 0.419049; batch adversarial loss: 0.633970\n",
      "epoch 143; iter: 0; batch classifier loss: 0.398612; batch adversarial loss: 0.554334\n",
      "epoch 144; iter: 0; batch classifier loss: 0.324093; batch adversarial loss: 0.515848\n",
      "epoch 145; iter: 0; batch classifier loss: 0.380801; batch adversarial loss: 0.494221\n",
      "epoch 146; iter: 0; batch classifier loss: 0.345282; batch adversarial loss: 0.552460\n",
      "epoch 147; iter: 0; batch classifier loss: 0.362997; batch adversarial loss: 0.475608\n",
      "epoch 148; iter: 0; batch classifier loss: 0.345619; batch adversarial loss: 0.477244\n",
      "epoch 149; iter: 0; batch classifier loss: 0.384065; batch adversarial loss: 0.536708\n",
      "epoch 150; iter: 0; batch classifier loss: 0.334019; batch adversarial loss: 0.497869\n",
      "epoch 151; iter: 0; batch classifier loss: 0.490033; batch adversarial loss: 0.536583\n",
      "epoch 152; iter: 0; batch classifier loss: 0.397825; batch adversarial loss: 0.525450\n",
      "epoch 153; iter: 0; batch classifier loss: 0.388914; batch adversarial loss: 0.649891\n",
      "epoch 154; iter: 0; batch classifier loss: 0.363357; batch adversarial loss: 0.567883\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 155; iter: 0; batch classifier loss: 0.402217; batch adversarial loss: 0.466426\n",
      "epoch 156; iter: 0; batch classifier loss: 0.372216; batch adversarial loss: 0.496723\n",
      "epoch 157; iter: 0; batch classifier loss: 0.365531; batch adversarial loss: 0.485807\n",
      "epoch 158; iter: 0; batch classifier loss: 0.475249; batch adversarial loss: 0.485765\n",
      "epoch 159; iter: 0; batch classifier loss: 0.348460; batch adversarial loss: 0.553799\n",
      "epoch 160; iter: 0; batch classifier loss: 0.385889; batch adversarial loss: 0.563761\n",
      "epoch 161; iter: 0; batch classifier loss: 0.363449; batch adversarial loss: 0.573436\n",
      "epoch 162; iter: 0; batch classifier loss: 0.472168; batch adversarial loss: 0.495575\n",
      "epoch 163; iter: 0; batch classifier loss: 0.391477; batch adversarial loss: 0.555531\n",
      "epoch 164; iter: 0; batch classifier loss: 0.380722; batch adversarial loss: 0.600193\n",
      "epoch 165; iter: 0; batch classifier loss: 0.351109; batch adversarial loss: 0.515973\n",
      "epoch 166; iter: 0; batch classifier loss: 0.310268; batch adversarial loss: 0.556144\n",
      "epoch 167; iter: 0; batch classifier loss: 0.368164; batch adversarial loss: 0.553447\n",
      "epoch 168; iter: 0; batch classifier loss: 0.320295; batch adversarial loss: 0.513695\n",
      "epoch 169; iter: 0; batch classifier loss: 0.289883; batch adversarial loss: 0.464166\n",
      "epoch 170; iter: 0; batch classifier loss: 0.354354; batch adversarial loss: 0.565525\n",
      "epoch 171; iter: 0; batch classifier loss: 0.356147; batch adversarial loss: 0.536428\n",
      "epoch 172; iter: 0; batch classifier loss: 0.355499; batch adversarial loss: 0.486536\n",
      "epoch 173; iter: 0; batch classifier loss: 0.312308; batch adversarial loss: 0.478232\n",
      "epoch 174; iter: 0; batch classifier loss: 0.368594; batch adversarial loss: 0.475156\n",
      "epoch 175; iter: 0; batch classifier loss: 0.381033; batch adversarial loss: 0.584959\n",
      "epoch 176; iter: 0; batch classifier loss: 0.272955; batch adversarial loss: 0.477437\n",
      "epoch 177; iter: 0; batch classifier loss: 0.300607; batch adversarial loss: 0.506085\n",
      "epoch 178; iter: 0; batch classifier loss: 0.415628; batch adversarial loss: 0.574602\n",
      "epoch 179; iter: 0; batch classifier loss: 0.364423; batch adversarial loss: 0.545551\n",
      "epoch 180; iter: 0; batch classifier loss: 0.324420; batch adversarial loss: 0.526170\n",
      "epoch 181; iter: 0; batch classifier loss: 0.371497; batch adversarial loss: 0.593217\n",
      "epoch 182; iter: 0; batch classifier loss: 0.279177; batch adversarial loss: 0.526748\n",
      "epoch 183; iter: 0; batch classifier loss: 0.385574; batch adversarial loss: 0.605074\n",
      "epoch 184; iter: 0; batch classifier loss: 0.317349; batch adversarial loss: 0.516452\n",
      "epoch 185; iter: 0; batch classifier loss: 0.330081; batch adversarial loss: 0.517301\n",
      "epoch 186; iter: 0; batch classifier loss: 0.371122; batch adversarial loss: 0.469120\n",
      "epoch 187; iter: 0; batch classifier loss: 0.344521; batch adversarial loss: 0.554744\n",
      "epoch 188; iter: 0; batch classifier loss: 0.334644; batch adversarial loss: 0.584687\n",
      "epoch 189; iter: 0; batch classifier loss: 0.336047; batch adversarial loss: 0.594649\n",
      "epoch 190; iter: 0; batch classifier loss: 0.376590; batch adversarial loss: 0.593701\n",
      "epoch 191; iter: 0; batch classifier loss: 0.351777; batch adversarial loss: 0.566665\n",
      "epoch 192; iter: 0; batch classifier loss: 0.372779; batch adversarial loss: 0.583724\n",
      "epoch 193; iter: 0; batch classifier loss: 0.289147; batch adversarial loss: 0.546547\n",
      "epoch 194; iter: 0; batch classifier loss: 0.411669; batch adversarial loss: 0.455282\n",
      "epoch 195; iter: 0; batch classifier loss: 0.346842; batch adversarial loss: 0.487680\n",
      "epoch 196; iter: 0; batch classifier loss: 0.328390; batch adversarial loss: 0.571383\n",
      "epoch 197; iter: 0; batch classifier loss: 0.358490; batch adversarial loss: 0.556001\n",
      "epoch 198; iter: 0; batch classifier loss: 0.331962; batch adversarial loss: 0.605345\n",
      "epoch 199; iter: 0; batch classifier loss: 0.286343; batch adversarial loss: 0.456168\n",
      "epoch 0; iter: 0; batch classifier loss: 0.684273; batch adversarial loss: 0.559110\n",
      "epoch 1; iter: 0; batch classifier loss: 0.603528; batch adversarial loss: 0.663622\n",
      "epoch 2; iter: 0; batch classifier loss: 0.629226; batch adversarial loss: 0.676622\n",
      "epoch 3; iter: 0; batch classifier loss: 0.604775; batch adversarial loss: 0.686236\n",
      "epoch 4; iter: 0; batch classifier loss: 0.576351; batch adversarial loss: 0.616916\n",
      "epoch 5; iter: 0; batch classifier loss: 0.582190; batch adversarial loss: 0.654270\n",
      "epoch 6; iter: 0; batch classifier loss: 0.575627; batch adversarial loss: 0.679715\n",
      "epoch 7; iter: 0; batch classifier loss: 0.546406; batch adversarial loss: 0.564907\n",
      "epoch 8; iter: 0; batch classifier loss: 0.597619; batch adversarial loss: 0.594142\n",
      "epoch 9; iter: 0; batch classifier loss: 0.505663; batch adversarial loss: 0.613733\n",
      "epoch 10; iter: 0; batch classifier loss: 0.610997; batch adversarial loss: 0.595894\n",
      "epoch 11; iter: 0; batch classifier loss: 0.564286; batch adversarial loss: 0.599711\n",
      "epoch 12; iter: 0; batch classifier loss: 0.553758; batch adversarial loss: 0.540354\n",
      "epoch 13; iter: 0; batch classifier loss: 0.533981; batch adversarial loss: 0.577508\n",
      "epoch 14; iter: 0; batch classifier loss: 0.489487; batch adversarial loss: 0.551878\n",
      "epoch 15; iter: 0; batch classifier loss: 0.579750; batch adversarial loss: 0.543563\n",
      "epoch 16; iter: 0; batch classifier loss: 0.491406; batch adversarial loss: 0.580776\n",
      "epoch 17; iter: 0; batch classifier loss: 0.509523; batch adversarial loss: 0.539562\n",
      "epoch 18; iter: 0; batch classifier loss: 0.496645; batch adversarial loss: 0.512735\n",
      "epoch 19; iter: 0; batch classifier loss: 0.510866; batch adversarial loss: 0.598071\n",
      "epoch 20; iter: 0; batch classifier loss: 0.543456; batch adversarial loss: 0.590666\n",
      "epoch 21; iter: 0; batch classifier loss: 0.414489; batch adversarial loss: 0.538600\n",
      "epoch 22; iter: 0; batch classifier loss: 0.462960; batch adversarial loss: 0.567159\n",
      "epoch 23; iter: 0; batch classifier loss: 0.400672; batch adversarial loss: 0.571687\n",
      "epoch 24; iter: 0; batch classifier loss: 0.473190; batch adversarial loss: 0.541753\n",
      "epoch 25; iter: 0; batch classifier loss: 0.476820; batch adversarial loss: 0.588529\n",
      "epoch 26; iter: 0; batch classifier loss: 0.443360; batch adversarial loss: 0.557395\n",
      "epoch 27; iter: 0; batch classifier loss: 0.468505; batch adversarial loss: 0.555632\n",
      "epoch 28; iter: 0; batch classifier loss: 0.461898; batch adversarial loss: 0.587109\n",
      "epoch 29; iter: 0; batch classifier loss: 0.489169; batch adversarial loss: 0.545545\n",
      "epoch 30; iter: 0; batch classifier loss: 0.442248; batch adversarial loss: 0.528257\n",
      "epoch 31; iter: 0; batch classifier loss: 0.461624; batch adversarial loss: 0.561670\n",
      "epoch 32; iter: 0; batch classifier loss: 0.407137; batch adversarial loss: 0.586334\n",
      "epoch 33; iter: 0; batch classifier loss: 0.432658; batch adversarial loss: 0.517493\n",
      "epoch 34; iter: 0; batch classifier loss: 0.492096; batch adversarial loss: 0.577436\n",
      "epoch 35; iter: 0; batch classifier loss: 0.382386; batch adversarial loss: 0.553520\n",
      "epoch 36; iter: 0; batch classifier loss: 0.540375; batch adversarial loss: 0.540195\n",
      "epoch 37; iter: 0; batch classifier loss: 0.416933; batch adversarial loss: 0.482830\n",
      "epoch 38; iter: 0; batch classifier loss: 0.450097; batch adversarial loss: 0.562975\n",
      "epoch 39; iter: 0; batch classifier loss: 0.404671; batch adversarial loss: 0.490749\n",
      "epoch 40; iter: 0; batch classifier loss: 0.423135; batch adversarial loss: 0.545907\n",
      "epoch 41; iter: 0; batch classifier loss: 0.483344; batch adversarial loss: 0.571501\n",
      "epoch 42; iter: 0; batch classifier loss: 0.433475; batch adversarial loss: 0.589886\n",
      "epoch 43; iter: 0; batch classifier loss: 0.455330; batch adversarial loss: 0.518228\n",
      "epoch 44; iter: 0; batch classifier loss: 0.392235; batch adversarial loss: 0.571739\n",
      "epoch 45; iter: 0; batch classifier loss: 0.459065; batch adversarial loss: 0.536179\n",
      "epoch 46; iter: 0; batch classifier loss: 0.374738; batch adversarial loss: 0.526529\n",
      "epoch 47; iter: 0; batch classifier loss: 0.447400; batch adversarial loss: 0.517770\n",
      "epoch 48; iter: 0; batch classifier loss: 0.409020; batch adversarial loss: 0.571924\n",
      "epoch 49; iter: 0; batch classifier loss: 0.450053; batch adversarial loss: 0.481569\n",
      "epoch 50; iter: 0; batch classifier loss: 0.489903; batch adversarial loss: 0.499943\n",
      "epoch 51; iter: 0; batch classifier loss: 0.396330; batch adversarial loss: 0.607382\n",
      "epoch 52; iter: 0; batch classifier loss: 0.504369; batch adversarial loss: 0.491054\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 53; iter: 0; batch classifier loss: 0.385134; batch adversarial loss: 0.544395\n",
      "epoch 54; iter: 0; batch classifier loss: 0.400803; batch adversarial loss: 0.554749\n",
      "epoch 55; iter: 0; batch classifier loss: 0.459800; batch adversarial loss: 0.560987\n",
      "epoch 56; iter: 0; batch classifier loss: 0.508428; batch adversarial loss: 0.595418\n",
      "epoch 57; iter: 0; batch classifier loss: 0.439192; batch adversarial loss: 0.608925\n",
      "epoch 58; iter: 0; batch classifier loss: 0.434192; batch adversarial loss: 0.568939\n",
      "epoch 59; iter: 0; batch classifier loss: 0.437714; batch adversarial loss: 0.572271\n",
      "epoch 60; iter: 0; batch classifier loss: 0.441045; batch adversarial loss: 0.466449\n",
      "epoch 61; iter: 0; batch classifier loss: 0.379695; batch adversarial loss: 0.666383\n",
      "epoch 62; iter: 0; batch classifier loss: 0.506277; batch adversarial loss: 0.559095\n",
      "epoch 63; iter: 0; batch classifier loss: 0.462638; batch adversarial loss: 0.490700\n",
      "epoch 64; iter: 0; batch classifier loss: 0.351341; batch adversarial loss: 0.601662\n",
      "epoch 65; iter: 0; batch classifier loss: 0.397700; batch adversarial loss: 0.546491\n",
      "epoch 66; iter: 0; batch classifier loss: 0.389263; batch adversarial loss: 0.502291\n",
      "epoch 67; iter: 0; batch classifier loss: 0.381814; batch adversarial loss: 0.528581\n",
      "epoch 68; iter: 0; batch classifier loss: 0.370820; batch adversarial loss: 0.536380\n",
      "epoch 69; iter: 0; batch classifier loss: 0.435604; batch adversarial loss: 0.500867\n",
      "epoch 70; iter: 0; batch classifier loss: 0.366434; batch adversarial loss: 0.474256\n",
      "epoch 71; iter: 0; batch classifier loss: 0.393266; batch adversarial loss: 0.579747\n",
      "epoch 72; iter: 0; batch classifier loss: 0.402640; batch adversarial loss: 0.587833\n",
      "epoch 73; iter: 0; batch classifier loss: 0.364258; batch adversarial loss: 0.509374\n",
      "epoch 74; iter: 0; batch classifier loss: 0.361556; batch adversarial loss: 0.580121\n",
      "epoch 75; iter: 0; batch classifier loss: 0.374634; batch adversarial loss: 0.571770\n",
      "epoch 76; iter: 0; batch classifier loss: 0.369578; batch adversarial loss: 0.473311\n",
      "epoch 77; iter: 0; batch classifier loss: 0.422378; batch adversarial loss: 0.625003\n",
      "epoch 78; iter: 0; batch classifier loss: 0.347605; batch adversarial loss: 0.535094\n",
      "epoch 79; iter: 0; batch classifier loss: 0.388238; batch adversarial loss: 0.509622\n",
      "epoch 80; iter: 0; batch classifier loss: 0.415350; batch adversarial loss: 0.589694\n",
      "epoch 81; iter: 0; batch classifier loss: 0.439736; batch adversarial loss: 0.544322\n",
      "epoch 82; iter: 0; batch classifier loss: 0.373828; batch adversarial loss: 0.598036\n",
      "epoch 83; iter: 0; batch classifier loss: 0.435400; batch adversarial loss: 0.562007\n",
      "epoch 84; iter: 0; batch classifier loss: 0.433653; batch adversarial loss: 0.542621\n",
      "epoch 85; iter: 0; batch classifier loss: 0.386499; batch adversarial loss: 0.651597\n",
      "epoch 86; iter: 0; batch classifier loss: 0.456120; batch adversarial loss: 0.517920\n",
      "epoch 87; iter: 0; batch classifier loss: 0.359695; batch adversarial loss: 0.527284\n",
      "epoch 88; iter: 0; batch classifier loss: 0.412769; batch adversarial loss: 0.580074\n",
      "epoch 89; iter: 0; batch classifier loss: 0.390972; batch adversarial loss: 0.590241\n",
      "epoch 90; iter: 0; batch classifier loss: 0.321772; batch adversarial loss: 0.560006\n",
      "epoch 91; iter: 0; batch classifier loss: 0.446452; batch adversarial loss: 0.480937\n",
      "epoch 92; iter: 0; batch classifier loss: 0.387488; batch adversarial loss: 0.641888\n",
      "epoch 93; iter: 0; batch classifier loss: 0.340318; batch adversarial loss: 0.580238\n",
      "epoch 94; iter: 0; batch classifier loss: 0.390375; batch adversarial loss: 0.535316\n",
      "epoch 95; iter: 0; batch classifier loss: 0.357160; batch adversarial loss: 0.527019\n",
      "epoch 96; iter: 0; batch classifier loss: 0.425860; batch adversarial loss: 0.554114\n",
      "epoch 97; iter: 0; batch classifier loss: 0.408239; batch adversarial loss: 0.500687\n",
      "epoch 98; iter: 0; batch classifier loss: 0.345989; batch adversarial loss: 0.535458\n",
      "epoch 99; iter: 0; batch classifier loss: 0.334556; batch adversarial loss: 0.614283\n",
      "epoch 100; iter: 0; batch classifier loss: 0.347193; batch adversarial loss: 0.519076\n",
      "epoch 101; iter: 0; batch classifier loss: 0.397662; batch adversarial loss: 0.553461\n",
      "epoch 102; iter: 0; batch classifier loss: 0.377084; batch adversarial loss: 0.661692\n",
      "epoch 103; iter: 0; batch classifier loss: 0.361204; batch adversarial loss: 0.571629\n",
      "epoch 104; iter: 0; batch classifier loss: 0.435354; batch adversarial loss: 0.560875\n",
      "epoch 105; iter: 0; batch classifier loss: 0.357226; batch adversarial loss: 0.484190\n",
      "epoch 106; iter: 0; batch classifier loss: 0.373241; batch adversarial loss: 0.490324\n",
      "epoch 107; iter: 0; batch classifier loss: 0.407564; batch adversarial loss: 0.572667\n",
      "epoch 108; iter: 0; batch classifier loss: 0.482721; batch adversarial loss: 0.581503\n",
      "epoch 109; iter: 0; batch classifier loss: 0.432847; batch adversarial loss: 0.572107\n",
      "epoch 110; iter: 0; batch classifier loss: 0.396305; batch adversarial loss: 0.570836\n",
      "epoch 111; iter: 0; batch classifier loss: 0.362664; batch adversarial loss: 0.482472\n",
      "epoch 112; iter: 0; batch classifier loss: 0.388542; batch adversarial loss: 0.560668\n",
      "epoch 113; iter: 0; batch classifier loss: 0.429348; batch adversarial loss: 0.606773\n",
      "epoch 114; iter: 0; batch classifier loss: 0.360599; batch adversarial loss: 0.529950\n",
      "epoch 115; iter: 0; batch classifier loss: 0.387206; batch adversarial loss: 0.587332\n",
      "epoch 116; iter: 0; batch classifier loss: 0.290233; batch adversarial loss: 0.529906\n",
      "epoch 117; iter: 0; batch classifier loss: 0.474853; batch adversarial loss: 0.553396\n",
      "epoch 118; iter: 0; batch classifier loss: 0.388293; batch adversarial loss: 0.482164\n",
      "epoch 119; iter: 0; batch classifier loss: 0.421948; batch adversarial loss: 0.544803\n",
      "epoch 120; iter: 0; batch classifier loss: 0.453113; batch adversarial loss: 0.570949\n",
      "epoch 121; iter: 0; batch classifier loss: 0.333438; batch adversarial loss: 0.552939\n",
      "epoch 122; iter: 0; batch classifier loss: 0.364171; batch adversarial loss: 0.481743\n",
      "epoch 123; iter: 0; batch classifier loss: 0.328816; batch adversarial loss: 0.606524\n",
      "epoch 124; iter: 0; batch classifier loss: 0.410406; batch adversarial loss: 0.520142\n",
      "epoch 125; iter: 0; batch classifier loss: 0.353613; batch adversarial loss: 0.552466\n",
      "epoch 126; iter: 0; batch classifier loss: 0.347638; batch adversarial loss: 0.482996\n",
      "epoch 127; iter: 0; batch classifier loss: 0.444788; batch adversarial loss: 0.588887\n",
      "epoch 128; iter: 0; batch classifier loss: 0.350768; batch adversarial loss: 0.500416\n",
      "epoch 129; iter: 0; batch classifier loss: 0.446125; batch adversarial loss: 0.572468\n",
      "epoch 130; iter: 0; batch classifier loss: 0.355179; batch adversarial loss: 0.631069\n",
      "epoch 131; iter: 0; batch classifier loss: 0.396266; batch adversarial loss: 0.511405\n",
      "epoch 132; iter: 0; batch classifier loss: 0.451244; batch adversarial loss: 0.566665\n",
      "epoch 133; iter: 0; batch classifier loss: 0.300948; batch adversarial loss: 0.565592\n",
      "epoch 134; iter: 0; batch classifier loss: 0.356334; batch adversarial loss: 0.634093\n",
      "epoch 135; iter: 0; batch classifier loss: 0.420572; batch adversarial loss: 0.600856\n",
      "epoch 136; iter: 0; batch classifier loss: 0.404400; batch adversarial loss: 0.599007\n",
      "epoch 137; iter: 0; batch classifier loss: 0.323365; batch adversarial loss: 0.471210\n",
      "epoch 138; iter: 0; batch classifier loss: 0.373656; batch adversarial loss: 0.553622\n",
      "epoch 139; iter: 0; batch classifier loss: 0.436300; batch adversarial loss: 0.544636\n",
      "epoch 140; iter: 0; batch classifier loss: 0.384130; batch adversarial loss: 0.598736\n",
      "epoch 141; iter: 0; batch classifier loss: 0.311853; batch adversarial loss: 0.608338\n",
      "epoch 142; iter: 0; batch classifier loss: 0.408449; batch adversarial loss: 0.535090\n",
      "epoch 143; iter: 0; batch classifier loss: 0.334465; batch adversarial loss: 0.500469\n",
      "epoch 144; iter: 0; batch classifier loss: 0.393773; batch adversarial loss: 0.517280\n",
      "epoch 145; iter: 0; batch classifier loss: 0.384083; batch adversarial loss: 0.462946\n",
      "epoch 146; iter: 0; batch classifier loss: 0.451717; batch adversarial loss: 0.481841\n",
      "epoch 147; iter: 0; batch classifier loss: 0.414840; batch adversarial loss: 0.651535\n",
      "epoch 148; iter: 0; batch classifier loss: 0.321856; batch adversarial loss: 0.652408\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 149; iter: 0; batch classifier loss: 0.355595; batch adversarial loss: 0.553328\n",
      "epoch 150; iter: 0; batch classifier loss: 0.314854; batch adversarial loss: 0.552300\n",
      "epoch 151; iter: 0; batch classifier loss: 0.374686; batch adversarial loss: 0.600207\n",
      "epoch 152; iter: 0; batch classifier loss: 0.363823; batch adversarial loss: 0.528382\n",
      "epoch 153; iter: 0; batch classifier loss: 0.324906; batch adversarial loss: 0.588012\n",
      "epoch 154; iter: 0; batch classifier loss: 0.323292; batch adversarial loss: 0.536360\n",
      "epoch 155; iter: 0; batch classifier loss: 0.377151; batch adversarial loss: 0.580936\n",
      "epoch 156; iter: 0; batch classifier loss: 0.368843; batch adversarial loss: 0.606915\n",
      "epoch 157; iter: 0; batch classifier loss: 0.315009; batch adversarial loss: 0.536376\n",
      "epoch 158; iter: 0; batch classifier loss: 0.374625; batch adversarial loss: 0.608149\n",
      "epoch 159; iter: 0; batch classifier loss: 0.455505; batch adversarial loss: 0.544833\n",
      "epoch 160; iter: 0; batch classifier loss: 0.347699; batch adversarial loss: 0.561883\n",
      "epoch 161; iter: 0; batch classifier loss: 0.258563; batch adversarial loss: 0.491928\n",
      "epoch 162; iter: 0; batch classifier loss: 0.347989; batch adversarial loss: 0.507227\n",
      "epoch 163; iter: 0; batch classifier loss: 0.385927; batch adversarial loss: 0.510101\n",
      "epoch 164; iter: 0; batch classifier loss: 0.389165; batch adversarial loss: 0.562931\n",
      "epoch 165; iter: 0; batch classifier loss: 0.393519; batch adversarial loss: 0.490059\n",
      "epoch 166; iter: 0; batch classifier loss: 0.377305; batch adversarial loss: 0.552950\n",
      "epoch 167; iter: 0; batch classifier loss: 0.333774; batch adversarial loss: 0.545141\n",
      "epoch 168; iter: 0; batch classifier loss: 0.358281; batch adversarial loss: 0.501257\n",
      "epoch 169; iter: 0; batch classifier loss: 0.430497; batch adversarial loss: 0.500246\n",
      "epoch 170; iter: 0; batch classifier loss: 0.329535; batch adversarial loss: 0.642878\n",
      "epoch 171; iter: 0; batch classifier loss: 0.354336; batch adversarial loss: 0.518733\n",
      "epoch 172; iter: 0; batch classifier loss: 0.318624; batch adversarial loss: 0.634331\n",
      "epoch 173; iter: 0; batch classifier loss: 0.325496; batch adversarial loss: 0.598661\n",
      "epoch 174; iter: 0; batch classifier loss: 0.310243; batch adversarial loss: 0.607907\n",
      "epoch 175; iter: 0; batch classifier loss: 0.395976; batch adversarial loss: 0.561564\n",
      "epoch 176; iter: 0; batch classifier loss: 0.368502; batch adversarial loss: 0.500508\n",
      "epoch 177; iter: 0; batch classifier loss: 0.342234; batch adversarial loss: 0.607533\n",
      "epoch 178; iter: 0; batch classifier loss: 0.329432; batch adversarial loss: 0.564069\n",
      "epoch 179; iter: 0; batch classifier loss: 0.338915; batch adversarial loss: 0.599604\n",
      "epoch 180; iter: 0; batch classifier loss: 0.432129; batch adversarial loss: 0.599265\n",
      "epoch 181; iter: 0; batch classifier loss: 0.413191; batch adversarial loss: 0.536287\n",
      "epoch 182; iter: 0; batch classifier loss: 0.359769; batch adversarial loss: 0.544711\n",
      "epoch 183; iter: 0; batch classifier loss: 0.369151; batch adversarial loss: 0.535014\n",
      "epoch 184; iter: 0; batch classifier loss: 0.465675; batch adversarial loss: 0.490813\n",
      "epoch 185; iter: 0; batch classifier loss: 0.249977; batch adversarial loss: 0.446323\n",
      "epoch 186; iter: 0; batch classifier loss: 0.374694; batch adversarial loss: 0.533855\n",
      "epoch 187; iter: 0; batch classifier loss: 0.425271; batch adversarial loss: 0.544197\n",
      "epoch 188; iter: 0; batch classifier loss: 0.402921; batch adversarial loss: 0.509046\n",
      "epoch 189; iter: 0; batch classifier loss: 0.352299; batch adversarial loss: 0.491619\n",
      "epoch 190; iter: 0; batch classifier loss: 0.311328; batch adversarial loss: 0.589954\n",
      "epoch 191; iter: 0; batch classifier loss: 0.347413; batch adversarial loss: 0.462742\n",
      "epoch 192; iter: 0; batch classifier loss: 0.395518; batch adversarial loss: 0.554122\n",
      "epoch 193; iter: 0; batch classifier loss: 0.317294; batch adversarial loss: 0.536084\n",
      "epoch 194; iter: 0; batch classifier loss: 0.359147; batch adversarial loss: 0.500078\n",
      "epoch 195; iter: 0; batch classifier loss: 0.393273; batch adversarial loss: 0.500797\n",
      "epoch 196; iter: 0; batch classifier loss: 0.372161; batch adversarial loss: 0.606804\n",
      "epoch 197; iter: 0; batch classifier loss: 0.375485; batch adversarial loss: 0.553761\n",
      "epoch 198; iter: 0; batch classifier loss: 0.337633; batch adversarial loss: 0.472944\n",
      "epoch 199; iter: 0; batch classifier loss: 0.315843; batch adversarial loss: 0.570944\n",
      "epoch 0; iter: 0; batch classifier loss: 0.732502; batch adversarial loss: 1.057501\n",
      "epoch 1; iter: 0; batch classifier loss: 0.872190; batch adversarial loss: 1.316145\n",
      "epoch 2; iter: 0; batch classifier loss: 1.100603; batch adversarial loss: 1.347951\n",
      "epoch 3; iter: 0; batch classifier loss: 1.137150; batch adversarial loss: 1.248042\n",
      "epoch 4; iter: 0; batch classifier loss: 1.289756; batch adversarial loss: 1.157529\n",
      "epoch 5; iter: 0; batch classifier loss: 1.199615; batch adversarial loss: 1.046911\n",
      "epoch 6; iter: 0; batch classifier loss: 1.325825; batch adversarial loss: 0.983365\n",
      "epoch 7; iter: 0; batch classifier loss: 1.143781; batch adversarial loss: 0.899368\n",
      "epoch 8; iter: 0; batch classifier loss: 1.050856; batch adversarial loss: 0.832068\n",
      "epoch 9; iter: 0; batch classifier loss: 1.028385; batch adversarial loss: 0.779065\n",
      "epoch 10; iter: 0; batch classifier loss: 0.866255; batch adversarial loss: 0.683962\n",
      "epoch 11; iter: 0; batch classifier loss: 0.719282; batch adversarial loss: 0.641629\n",
      "epoch 12; iter: 0; batch classifier loss: 0.673300; batch adversarial loss: 0.625879\n",
      "epoch 13; iter: 0; batch classifier loss: 0.568591; batch adversarial loss: 0.587094\n",
      "epoch 14; iter: 0; batch classifier loss: 0.553242; batch adversarial loss: 0.575863\n",
      "epoch 15; iter: 0; batch classifier loss: 0.604130; batch adversarial loss: 0.566167\n",
      "epoch 16; iter: 0; batch classifier loss: 0.544959; batch adversarial loss: 0.585623\n",
      "epoch 17; iter: 0; batch classifier loss: 0.531580; batch adversarial loss: 0.572815\n",
      "epoch 18; iter: 0; batch classifier loss: 0.512417; batch adversarial loss: 0.555020\n",
      "epoch 19; iter: 0; batch classifier loss: 0.579064; batch adversarial loss: 0.547812\n",
      "epoch 20; iter: 0; batch classifier loss: 0.540220; batch adversarial loss: 0.573190\n",
      "epoch 21; iter: 0; batch classifier loss: 0.513669; batch adversarial loss: 0.609676\n",
      "epoch 22; iter: 0; batch classifier loss: 0.485827; batch adversarial loss: 0.522215\n",
      "epoch 23; iter: 0; batch classifier loss: 0.518611; batch adversarial loss: 0.635054\n",
      "epoch 24; iter: 0; batch classifier loss: 0.423646; batch adversarial loss: 0.577745\n",
      "epoch 25; iter: 0; batch classifier loss: 0.524495; batch adversarial loss: 0.561060\n",
      "epoch 26; iter: 0; batch classifier loss: 0.499599; batch adversarial loss: 0.563390\n",
      "epoch 27; iter: 0; batch classifier loss: 0.486786; batch adversarial loss: 0.541978\n",
      "epoch 28; iter: 0; batch classifier loss: 0.469186; batch adversarial loss: 0.549616\n",
      "epoch 29; iter: 0; batch classifier loss: 0.508500; batch adversarial loss: 0.516208\n",
      "epoch 30; iter: 0; batch classifier loss: 0.491321; batch adversarial loss: 0.531281\n",
      "epoch 31; iter: 0; batch classifier loss: 0.485637; batch adversarial loss: 0.537732\n",
      "epoch 32; iter: 0; batch classifier loss: 0.530219; batch adversarial loss: 0.522053\n",
      "epoch 33; iter: 0; batch classifier loss: 0.450051; batch adversarial loss: 0.595977\n",
      "epoch 34; iter: 0; batch classifier loss: 0.450289; batch adversarial loss: 0.508015\n",
      "epoch 35; iter: 0; batch classifier loss: 0.512838; batch adversarial loss: 0.511982\n",
      "epoch 36; iter: 0; batch classifier loss: 0.450351; batch adversarial loss: 0.463729\n",
      "epoch 37; iter: 0; batch classifier loss: 0.459645; batch adversarial loss: 0.471547\n",
      "epoch 38; iter: 0; batch classifier loss: 0.498548; batch adversarial loss: 0.566519\n",
      "epoch 39; iter: 0; batch classifier loss: 0.414867; batch adversarial loss: 0.545476\n",
      "epoch 40; iter: 0; batch classifier loss: 0.503639; batch adversarial loss: 0.533610\n",
      "epoch 41; iter: 0; batch classifier loss: 0.460351; batch adversarial loss: 0.572943\n",
      "epoch 42; iter: 0; batch classifier loss: 0.458230; batch adversarial loss: 0.475797\n",
      "epoch 43; iter: 0; batch classifier loss: 0.458328; batch adversarial loss: 0.477070\n",
      "epoch 44; iter: 0; batch classifier loss: 0.459602; batch adversarial loss: 0.580820\n",
      "epoch 45; iter: 0; batch classifier loss: 0.481427; batch adversarial loss: 0.607183\n",
      "epoch 46; iter: 0; batch classifier loss: 0.447285; batch adversarial loss: 0.573243\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 47; iter: 0; batch classifier loss: 0.415960; batch adversarial loss: 0.593133\n",
      "epoch 48; iter: 0; batch classifier loss: 0.397464; batch adversarial loss: 0.533728\n",
      "epoch 49; iter: 0; batch classifier loss: 0.446555; batch adversarial loss: 0.530819\n",
      "epoch 50; iter: 0; batch classifier loss: 0.477049; batch adversarial loss: 0.530249\n",
      "epoch 51; iter: 0; batch classifier loss: 0.407364; batch adversarial loss: 0.515817\n",
      "epoch 52; iter: 0; batch classifier loss: 0.522949; batch adversarial loss: 0.543925\n",
      "epoch 53; iter: 0; batch classifier loss: 0.399316; batch adversarial loss: 0.455452\n",
      "epoch 54; iter: 0; batch classifier loss: 0.461675; batch adversarial loss: 0.498111\n",
      "epoch 55; iter: 0; batch classifier loss: 0.356446; batch adversarial loss: 0.552307\n",
      "epoch 56; iter: 0; batch classifier loss: 0.429874; batch adversarial loss: 0.610723\n",
      "epoch 57; iter: 0; batch classifier loss: 0.336192; batch adversarial loss: 0.546298\n",
      "epoch 58; iter: 0; batch classifier loss: 0.397676; batch adversarial loss: 0.487532\n",
      "epoch 59; iter: 0; batch classifier loss: 0.364782; batch adversarial loss: 0.529137\n",
      "epoch 60; iter: 0; batch classifier loss: 0.427596; batch adversarial loss: 0.620509\n",
      "epoch 61; iter: 0; batch classifier loss: 0.439273; batch adversarial loss: 0.428316\n",
      "epoch 62; iter: 0; batch classifier loss: 0.454348; batch adversarial loss: 0.676806\n",
      "epoch 63; iter: 0; batch classifier loss: 0.423112; batch adversarial loss: 0.574498\n",
      "epoch 64; iter: 0; batch classifier loss: 0.432295; batch adversarial loss: 0.495707\n",
      "epoch 65; iter: 0; batch classifier loss: 0.400340; batch adversarial loss: 0.581100\n",
      "epoch 66; iter: 0; batch classifier loss: 0.404455; batch adversarial loss: 0.558138\n",
      "epoch 67; iter: 0; batch classifier loss: 0.447644; batch adversarial loss: 0.479335\n",
      "epoch 68; iter: 0; batch classifier loss: 0.404474; batch adversarial loss: 0.545694\n",
      "epoch 69; iter: 0; batch classifier loss: 0.444686; batch adversarial loss: 0.517280\n",
      "epoch 70; iter: 0; batch classifier loss: 0.371265; batch adversarial loss: 0.521486\n",
      "epoch 71; iter: 0; batch classifier loss: 0.388625; batch adversarial loss: 0.545178\n",
      "epoch 72; iter: 0; batch classifier loss: 0.365168; batch adversarial loss: 0.543368\n",
      "epoch 73; iter: 0; batch classifier loss: 0.387075; batch adversarial loss: 0.543737\n",
      "epoch 74; iter: 0; batch classifier loss: 0.453051; batch adversarial loss: 0.553086\n",
      "epoch 75; iter: 0; batch classifier loss: 0.409461; batch adversarial loss: 0.536196\n",
      "epoch 76; iter: 0; batch classifier loss: 0.375857; batch adversarial loss: 0.507466\n",
      "epoch 77; iter: 0; batch classifier loss: 0.468517; batch adversarial loss: 0.553704\n",
      "epoch 78; iter: 0; batch classifier loss: 0.339991; batch adversarial loss: 0.562137\n",
      "epoch 79; iter: 0; batch classifier loss: 0.445608; batch adversarial loss: 0.516503\n",
      "epoch 80; iter: 0; batch classifier loss: 0.458823; batch adversarial loss: 0.566565\n",
      "epoch 81; iter: 0; batch classifier loss: 0.393432; batch adversarial loss: 0.464076\n",
      "epoch 82; iter: 0; batch classifier loss: 0.438579; batch adversarial loss: 0.559130\n",
      "epoch 83; iter: 0; batch classifier loss: 0.441212; batch adversarial loss: 0.504536\n",
      "epoch 84; iter: 0; batch classifier loss: 0.379753; batch adversarial loss: 0.484239\n",
      "epoch 85; iter: 0; batch classifier loss: 0.330590; batch adversarial loss: 0.506523\n",
      "epoch 86; iter: 0; batch classifier loss: 0.347606; batch adversarial loss: 0.586425\n",
      "epoch 87; iter: 0; batch classifier loss: 0.419819; batch adversarial loss: 0.546479\n",
      "epoch 88; iter: 0; batch classifier loss: 0.368954; batch adversarial loss: 0.436787\n",
      "epoch 89; iter: 0; batch classifier loss: 0.315627; batch adversarial loss: 0.545684\n",
      "epoch 90; iter: 0; batch classifier loss: 0.480451; batch adversarial loss: 0.535812\n",
      "epoch 91; iter: 0; batch classifier loss: 0.408658; batch adversarial loss: 0.564577\n",
      "epoch 92; iter: 0; batch classifier loss: 0.406071; batch adversarial loss: 0.638357\n",
      "epoch 93; iter: 0; batch classifier loss: 0.383604; batch adversarial loss: 0.574339\n",
      "epoch 94; iter: 0; batch classifier loss: 0.431535; batch adversarial loss: 0.447980\n",
      "epoch 95; iter: 0; batch classifier loss: 0.337156; batch adversarial loss: 0.541560\n",
      "epoch 96; iter: 0; batch classifier loss: 0.425789; batch adversarial loss: 0.595732\n",
      "epoch 97; iter: 0; batch classifier loss: 0.427664; batch adversarial loss: 0.489762\n",
      "epoch 98; iter: 0; batch classifier loss: 0.412686; batch adversarial loss: 0.575300\n",
      "epoch 99; iter: 0; batch classifier loss: 0.379458; batch adversarial loss: 0.592728\n",
      "epoch 100; iter: 0; batch classifier loss: 0.328814; batch adversarial loss: 0.524848\n",
      "epoch 101; iter: 0; batch classifier loss: 0.402212; batch adversarial loss: 0.572878\n",
      "epoch 102; iter: 0; batch classifier loss: 0.339892; batch adversarial loss: 0.543333\n",
      "epoch 103; iter: 0; batch classifier loss: 0.283858; batch adversarial loss: 0.561841\n",
      "epoch 104; iter: 0; batch classifier loss: 0.349715; batch adversarial loss: 0.537849\n",
      "epoch 105; iter: 0; batch classifier loss: 0.351635; batch adversarial loss: 0.496707\n",
      "epoch 106; iter: 0; batch classifier loss: 0.326475; batch adversarial loss: 0.523575\n",
      "epoch 107; iter: 0; batch classifier loss: 0.324598; batch adversarial loss: 0.517092\n",
      "epoch 108; iter: 0; batch classifier loss: 0.447785; batch adversarial loss: 0.542314\n",
      "epoch 109; iter: 0; batch classifier loss: 0.342954; batch adversarial loss: 0.573116\n",
      "epoch 110; iter: 0; batch classifier loss: 0.354270; batch adversarial loss: 0.506966\n",
      "epoch 111; iter: 0; batch classifier loss: 0.367988; batch adversarial loss: 0.534120\n",
      "epoch 112; iter: 0; batch classifier loss: 0.365418; batch adversarial loss: 0.537128\n",
      "epoch 113; iter: 0; batch classifier loss: 0.312114; batch adversarial loss: 0.525314\n",
      "epoch 114; iter: 0; batch classifier loss: 0.309743; batch adversarial loss: 0.554826\n",
      "epoch 115; iter: 0; batch classifier loss: 0.363241; batch adversarial loss: 0.535266\n",
      "epoch 116; iter: 0; batch classifier loss: 0.376704; batch adversarial loss: 0.563421\n",
      "epoch 117; iter: 0; batch classifier loss: 0.385006; batch adversarial loss: 0.583502\n",
      "epoch 118; iter: 0; batch classifier loss: 0.333119; batch adversarial loss: 0.534518\n",
      "epoch 119; iter: 0; batch classifier loss: 0.338076; batch adversarial loss: 0.508324\n",
      "epoch 120; iter: 0; batch classifier loss: 0.315538; batch adversarial loss: 0.469375\n",
      "epoch 121; iter: 0; batch classifier loss: 0.334832; batch adversarial loss: 0.592288\n",
      "epoch 122; iter: 0; batch classifier loss: 0.382209; batch adversarial loss: 0.487011\n",
      "epoch 123; iter: 0; batch classifier loss: 0.371788; batch adversarial loss: 0.476210\n",
      "epoch 124; iter: 0; batch classifier loss: 0.331821; batch adversarial loss: 0.534688\n",
      "epoch 125; iter: 0; batch classifier loss: 0.335331; batch adversarial loss: 0.603700\n",
      "epoch 126; iter: 0; batch classifier loss: 0.404826; batch adversarial loss: 0.534908\n",
      "epoch 127; iter: 0; batch classifier loss: 0.355778; batch adversarial loss: 0.515809\n",
      "epoch 128; iter: 0; batch classifier loss: 0.270179; batch adversarial loss: 0.478381\n",
      "epoch 129; iter: 0; batch classifier loss: 0.291928; batch adversarial loss: 0.554601\n",
      "epoch 130; iter: 0; batch classifier loss: 0.311406; batch adversarial loss: 0.525502\n",
      "epoch 131; iter: 0; batch classifier loss: 0.340328; batch adversarial loss: 0.524131\n",
      "epoch 132; iter: 0; batch classifier loss: 0.318503; batch adversarial loss: 0.487254\n",
      "epoch 133; iter: 0; batch classifier loss: 0.377907; batch adversarial loss: 0.545669\n",
      "epoch 134; iter: 0; batch classifier loss: 0.436006; batch adversarial loss: 0.525683\n",
      "epoch 135; iter: 0; batch classifier loss: 0.353810; batch adversarial loss: 0.563931\n",
      "epoch 136; iter: 0; batch classifier loss: 0.341408; batch adversarial loss: 0.496965\n",
      "epoch 137; iter: 0; batch classifier loss: 0.300603; batch adversarial loss: 0.572420\n",
      "epoch 138; iter: 0; batch classifier loss: 0.356209; batch adversarial loss: 0.535337\n",
      "epoch 139; iter: 0; batch classifier loss: 0.379511; batch adversarial loss: 0.583887\n",
      "epoch 140; iter: 0; batch classifier loss: 0.338164; batch adversarial loss: 0.515709\n",
      "epoch 141; iter: 0; batch classifier loss: 0.353748; batch adversarial loss: 0.602868\n",
      "epoch 142; iter: 0; batch classifier loss: 0.334329; batch adversarial loss: 0.602100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 143; iter: 0; batch classifier loss: 0.293905; batch adversarial loss: 0.660808\n",
      "epoch 144; iter: 0; batch classifier loss: 0.323399; batch adversarial loss: 0.467695\n",
      "epoch 145; iter: 0; batch classifier loss: 0.412950; batch adversarial loss: 0.552888\n",
      "epoch 146; iter: 0; batch classifier loss: 0.341439; batch adversarial loss: 0.533787\n",
      "epoch 147; iter: 0; batch classifier loss: 0.369962; batch adversarial loss: 0.514115\n",
      "epoch 148; iter: 0; batch classifier loss: 0.375135; batch adversarial loss: 0.505705\n",
      "epoch 149; iter: 0; batch classifier loss: 0.343585; batch adversarial loss: 0.552664\n",
      "epoch 150; iter: 0; batch classifier loss: 0.356564; batch adversarial loss: 0.582702\n",
      "epoch 151; iter: 0; batch classifier loss: 0.396567; batch adversarial loss: 0.495217\n",
      "epoch 152; iter: 0; batch classifier loss: 0.332708; batch adversarial loss: 0.449035\n",
      "epoch 153; iter: 0; batch classifier loss: 0.321314; batch adversarial loss: 0.534550\n",
      "epoch 154; iter: 0; batch classifier loss: 0.335931; batch adversarial loss: 0.642110\n",
      "epoch 155; iter: 0; batch classifier loss: 0.344379; batch adversarial loss: 0.554543\n",
      "epoch 156; iter: 0; batch classifier loss: 0.320083; batch adversarial loss: 0.698599\n",
      "epoch 157; iter: 0; batch classifier loss: 0.309660; batch adversarial loss: 0.506331\n",
      "epoch 158; iter: 0; batch classifier loss: 0.294890; batch adversarial loss: 0.535931\n",
      "epoch 159; iter: 0; batch classifier loss: 0.382831; batch adversarial loss: 0.466943\n",
      "epoch 160; iter: 0; batch classifier loss: 0.321537; batch adversarial loss: 0.459713\n",
      "epoch 161; iter: 0; batch classifier loss: 0.378163; batch adversarial loss: 0.534643\n",
      "epoch 162; iter: 0; batch classifier loss: 0.346696; batch adversarial loss: 0.554801\n",
      "epoch 163; iter: 0; batch classifier loss: 0.321497; batch adversarial loss: 0.555374\n",
      "epoch 164; iter: 0; batch classifier loss: 0.385718; batch adversarial loss: 0.505844\n",
      "epoch 165; iter: 0; batch classifier loss: 0.316048; batch adversarial loss: 0.553873\n",
      "epoch 166; iter: 0; batch classifier loss: 0.351014; batch adversarial loss: 0.659332\n",
      "epoch 167; iter: 0; batch classifier loss: 0.359690; batch adversarial loss: 0.611966\n",
      "epoch 168; iter: 0; batch classifier loss: 0.276764; batch adversarial loss: 0.533402\n",
      "epoch 169; iter: 0; batch classifier loss: 0.350472; batch adversarial loss: 0.555606\n",
      "epoch 170; iter: 0; batch classifier loss: 0.338414; batch adversarial loss: 0.639542\n",
      "epoch 171; iter: 0; batch classifier loss: 0.336363; batch adversarial loss: 0.535922\n",
      "epoch 172; iter: 0; batch classifier loss: 0.394515; batch adversarial loss: 0.439947\n",
      "epoch 173; iter: 0; batch classifier loss: 0.394472; batch adversarial loss: 0.545007\n",
      "epoch 174; iter: 0; batch classifier loss: 0.273727; batch adversarial loss: 0.590903\n",
      "epoch 175; iter: 0; batch classifier loss: 0.340221; batch adversarial loss: 0.535407\n",
      "epoch 176; iter: 0; batch classifier loss: 0.313110; batch adversarial loss: 0.534109\n",
      "epoch 177; iter: 0; batch classifier loss: 0.280478; batch adversarial loss: 0.487505\n",
      "epoch 178; iter: 0; batch classifier loss: 0.355716; batch adversarial loss: 0.553060\n",
      "epoch 179; iter: 0; batch classifier loss: 0.289884; batch adversarial loss: 0.517844\n",
      "epoch 180; iter: 0; batch classifier loss: 0.326850; batch adversarial loss: 0.438032\n",
      "epoch 181; iter: 0; batch classifier loss: 0.282200; batch adversarial loss: 0.496532\n",
      "epoch 182; iter: 0; batch classifier loss: 0.376888; batch adversarial loss: 0.534456\n",
      "epoch 183; iter: 0; batch classifier loss: 0.350825; batch adversarial loss: 0.476749\n",
      "epoch 184; iter: 0; batch classifier loss: 0.308764; batch adversarial loss: 0.543334\n",
      "epoch 185; iter: 0; batch classifier loss: 0.307278; batch adversarial loss: 0.591059\n",
      "epoch 186; iter: 0; batch classifier loss: 0.266743; batch adversarial loss: 0.524065\n",
      "epoch 187; iter: 0; batch classifier loss: 0.402750; batch adversarial loss: 0.498749\n",
      "epoch 188; iter: 0; batch classifier loss: 0.357852; batch adversarial loss: 0.563518\n",
      "epoch 189; iter: 0; batch classifier loss: 0.367238; batch adversarial loss: 0.429501\n",
      "epoch 190; iter: 0; batch classifier loss: 0.283375; batch adversarial loss: 0.478129\n",
      "epoch 191; iter: 0; batch classifier loss: 0.365445; batch adversarial loss: 0.631602\n",
      "epoch 192; iter: 0; batch classifier loss: 0.273565; batch adversarial loss: 0.554206\n",
      "epoch 193; iter: 0; batch classifier loss: 0.329885; batch adversarial loss: 0.525316\n",
      "epoch 194; iter: 0; batch classifier loss: 0.293166; batch adversarial loss: 0.515513\n",
      "epoch 195; iter: 0; batch classifier loss: 0.312050; batch adversarial loss: 0.592124\n",
      "epoch 196; iter: 0; batch classifier loss: 0.311686; batch adversarial loss: 0.594171\n",
      "epoch 197; iter: 0; batch classifier loss: 0.283564; batch adversarial loss: 0.583887\n",
      "epoch 198; iter: 0; batch classifier loss: 0.279042; batch adversarial loss: 0.506335\n",
      "epoch 199; iter: 0; batch classifier loss: 0.328676; batch adversarial loss: 0.590749\n",
      "epoch 0; iter: 0; batch classifier loss: 0.679761; batch adversarial loss: 0.693771\n",
      "epoch 1; iter: 0; batch classifier loss: 0.622423; batch adversarial loss: 0.672163\n",
      "epoch 2; iter: 0; batch classifier loss: 0.643159; batch adversarial loss: 0.652502\n",
      "epoch 3; iter: 0; batch classifier loss: 0.614817; batch adversarial loss: 0.611210\n",
      "epoch 4; iter: 0; batch classifier loss: 0.560107; batch adversarial loss: 0.621102\n",
      "epoch 5; iter: 0; batch classifier loss: 0.576562; batch adversarial loss: 0.578040\n",
      "epoch 6; iter: 0; batch classifier loss: 0.491231; batch adversarial loss: 0.584047\n",
      "epoch 7; iter: 0; batch classifier loss: 0.496782; batch adversarial loss: 0.618321\n",
      "epoch 8; iter: 0; batch classifier loss: 0.549752; batch adversarial loss: 0.566739\n",
      "epoch 9; iter: 0; batch classifier loss: 0.549328; batch adversarial loss: 0.582070\n",
      "epoch 10; iter: 0; batch classifier loss: 0.514098; batch adversarial loss: 0.594761\n",
      "epoch 11; iter: 0; batch classifier loss: 0.598673; batch adversarial loss: 0.614745\n",
      "epoch 12; iter: 0; batch classifier loss: 0.491928; batch adversarial loss: 0.576229\n",
      "epoch 13; iter: 0; batch classifier loss: 0.557972; batch adversarial loss: 0.582214\n",
      "epoch 14; iter: 0; batch classifier loss: 0.453849; batch adversarial loss: 0.591882\n",
      "epoch 15; iter: 0; batch classifier loss: 0.557292; batch adversarial loss: 0.590907\n",
      "epoch 16; iter: 0; batch classifier loss: 0.547938; batch adversarial loss: 0.529116\n",
      "epoch 17; iter: 0; batch classifier loss: 0.535857; batch adversarial loss: 0.475048\n",
      "epoch 18; iter: 0; batch classifier loss: 0.548714; batch adversarial loss: 0.565004\n",
      "epoch 19; iter: 0; batch classifier loss: 0.504568; batch adversarial loss: 0.645252\n",
      "epoch 20; iter: 0; batch classifier loss: 0.480854; batch adversarial loss: 0.502020\n",
      "epoch 21; iter: 0; batch classifier loss: 0.470138; batch adversarial loss: 0.672683\n",
      "epoch 22; iter: 0; batch classifier loss: 0.516010; batch adversarial loss: 0.548994\n",
      "epoch 23; iter: 0; batch classifier loss: 0.432687; batch adversarial loss: 0.601135\n",
      "epoch 24; iter: 0; batch classifier loss: 0.419980; batch adversarial loss: 0.521464\n",
      "epoch 25; iter: 0; batch classifier loss: 0.540089; batch adversarial loss: 0.549614\n",
      "epoch 26; iter: 0; batch classifier loss: 0.497059; batch adversarial loss: 0.595212\n",
      "epoch 27; iter: 0; batch classifier loss: 0.452863; batch adversarial loss: 0.612812\n",
      "epoch 28; iter: 0; batch classifier loss: 0.460961; batch adversarial loss: 0.455148\n",
      "epoch 29; iter: 0; batch classifier loss: 0.523320; batch adversarial loss: 0.563535\n",
      "epoch 30; iter: 0; batch classifier loss: 0.458036; batch adversarial loss: 0.571391\n",
      "epoch 31; iter: 0; batch classifier loss: 0.474444; batch adversarial loss: 0.554083\n",
      "epoch 32; iter: 0; batch classifier loss: 0.499254; batch adversarial loss: 0.553785\n",
      "epoch 33; iter: 0; batch classifier loss: 0.502628; batch adversarial loss: 0.544798\n",
      "epoch 34; iter: 0; batch classifier loss: 0.486946; batch adversarial loss: 0.536245\n",
      "epoch 35; iter: 0; batch classifier loss: 0.468477; batch adversarial loss: 0.554379\n",
      "epoch 36; iter: 0; batch classifier loss: 0.439616; batch adversarial loss: 0.580943\n",
      "epoch 37; iter: 0; batch classifier loss: 0.499394; batch adversarial loss: 0.527030\n",
      "epoch 38; iter: 0; batch classifier loss: 0.528432; batch adversarial loss: 0.517638\n",
      "epoch 39; iter: 0; batch classifier loss: 0.466492; batch adversarial loss: 0.552921\n",
      "epoch 40; iter: 0; batch classifier loss: 0.479926; batch adversarial loss: 0.534864\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 41; iter: 0; batch classifier loss: 0.451806; batch adversarial loss: 0.554052\n",
      "epoch 42; iter: 0; batch classifier loss: 0.406639; batch adversarial loss: 0.544715\n",
      "epoch 43; iter: 0; batch classifier loss: 0.463948; batch adversarial loss: 0.580729\n",
      "epoch 44; iter: 0; batch classifier loss: 0.481193; batch adversarial loss: 0.526980\n",
      "epoch 45; iter: 0; batch classifier loss: 0.394970; batch adversarial loss: 0.490071\n",
      "epoch 46; iter: 0; batch classifier loss: 0.540976; batch adversarial loss: 0.608457\n",
      "epoch 47; iter: 0; batch classifier loss: 0.445375; batch adversarial loss: 0.526536\n",
      "epoch 48; iter: 0; batch classifier loss: 0.483208; batch adversarial loss: 0.480668\n",
      "epoch 49; iter: 0; batch classifier loss: 0.460904; batch adversarial loss: 0.517064\n",
      "epoch 50; iter: 0; batch classifier loss: 0.456320; batch adversarial loss: 0.480450\n",
      "epoch 51; iter: 0; batch classifier loss: 0.482691; batch adversarial loss: 0.562111\n",
      "epoch 52; iter: 0; batch classifier loss: 0.420835; batch adversarial loss: 0.534414\n",
      "epoch 53; iter: 0; batch classifier loss: 0.436870; batch adversarial loss: 0.591768\n",
      "epoch 54; iter: 0; batch classifier loss: 0.460066; batch adversarial loss: 0.432692\n",
      "epoch 55; iter: 0; batch classifier loss: 0.555774; batch adversarial loss: 0.498941\n",
      "epoch 56; iter: 0; batch classifier loss: 0.415606; batch adversarial loss: 0.553025\n",
      "epoch 57; iter: 0; batch classifier loss: 0.479109; batch adversarial loss: 0.618750\n",
      "epoch 58; iter: 0; batch classifier loss: 0.415315; batch adversarial loss: 0.492895\n",
      "epoch 59; iter: 0; batch classifier loss: 0.456514; batch adversarial loss: 0.600081\n",
      "epoch 60; iter: 0; batch classifier loss: 0.521668; batch adversarial loss: 0.553185\n",
      "epoch 61; iter: 0; batch classifier loss: 0.429769; batch adversarial loss: 0.561160\n",
      "epoch 62; iter: 0; batch classifier loss: 0.437928; batch adversarial loss: 0.508175\n",
      "epoch 63; iter: 0; batch classifier loss: 0.419795; batch adversarial loss: 0.575125\n",
      "epoch 64; iter: 0; batch classifier loss: 0.475577; batch adversarial loss: 0.569062\n",
      "epoch 65; iter: 0; batch classifier loss: 0.390285; batch adversarial loss: 0.522976\n",
      "epoch 66; iter: 0; batch classifier loss: 0.478419; batch adversarial loss: 0.545676\n",
      "epoch 67; iter: 0; batch classifier loss: 0.406947; batch adversarial loss: 0.491281\n",
      "epoch 68; iter: 0; batch classifier loss: 0.370632; batch adversarial loss: 0.518069\n",
      "epoch 69; iter: 0; batch classifier loss: 0.393052; batch adversarial loss: 0.558118\n",
      "epoch 70; iter: 0; batch classifier loss: 0.397060; batch adversarial loss: 0.562595\n",
      "epoch 71; iter: 0; batch classifier loss: 0.415923; batch adversarial loss: 0.528061\n",
      "epoch 72; iter: 0; batch classifier loss: 0.448202; batch adversarial loss: 0.525675\n",
      "epoch 73; iter: 0; batch classifier loss: 0.456150; batch adversarial loss: 0.544609\n",
      "epoch 74; iter: 0; batch classifier loss: 0.436682; batch adversarial loss: 0.552962\n",
      "epoch 75; iter: 0; batch classifier loss: 0.450837; batch adversarial loss: 0.554469\n",
      "epoch 76; iter: 0; batch classifier loss: 0.368747; batch adversarial loss: 0.507951\n",
      "epoch 77; iter: 0; batch classifier loss: 0.493991; batch adversarial loss: 0.526855\n",
      "epoch 78; iter: 0; batch classifier loss: 0.427448; batch adversarial loss: 0.508664\n",
      "epoch 79; iter: 0; batch classifier loss: 0.387400; batch adversarial loss: 0.471799\n",
      "epoch 80; iter: 0; batch classifier loss: 0.381538; batch adversarial loss: 0.498318\n",
      "epoch 81; iter: 0; batch classifier loss: 0.383007; batch adversarial loss: 0.535343\n",
      "epoch 82; iter: 0; batch classifier loss: 0.418180; batch adversarial loss: 0.517549\n",
      "epoch 83; iter: 0; batch classifier loss: 0.386940; batch adversarial loss: 0.525732\n",
      "epoch 84; iter: 0; batch classifier loss: 0.369000; batch adversarial loss: 0.581100\n",
      "epoch 85; iter: 0; batch classifier loss: 0.409251; batch adversarial loss: 0.545742\n",
      "epoch 86; iter: 0; batch classifier loss: 0.379154; batch adversarial loss: 0.645725\n",
      "epoch 87; iter: 0; batch classifier loss: 0.387929; batch adversarial loss: 0.525311\n",
      "epoch 88; iter: 0; batch classifier loss: 0.371301; batch adversarial loss: 0.582052\n",
      "epoch 89; iter: 0; batch classifier loss: 0.446331; batch adversarial loss: 0.534922\n",
      "epoch 90; iter: 0; batch classifier loss: 0.415353; batch adversarial loss: 0.499573\n",
      "epoch 91; iter: 0; batch classifier loss: 0.378221; batch adversarial loss: 0.470956\n",
      "epoch 92; iter: 0; batch classifier loss: 0.369189; batch adversarial loss: 0.562282\n",
      "epoch 93; iter: 0; batch classifier loss: 0.345263; batch adversarial loss: 0.626082\n",
      "epoch 94; iter: 0; batch classifier loss: 0.380290; batch adversarial loss: 0.525752\n",
      "epoch 95; iter: 0; batch classifier loss: 0.335290; batch adversarial loss: 0.471463\n",
      "epoch 96; iter: 0; batch classifier loss: 0.400273; batch adversarial loss: 0.572845\n",
      "epoch 97; iter: 0; batch classifier loss: 0.426948; batch adversarial loss: 0.599434\n",
      "epoch 98; iter: 0; batch classifier loss: 0.378521; batch adversarial loss: 0.544764\n",
      "epoch 99; iter: 0; batch classifier loss: 0.419628; batch adversarial loss: 0.673247\n",
      "epoch 100; iter: 0; batch classifier loss: 0.446657; batch adversarial loss: 0.526170\n",
      "epoch 101; iter: 0; batch classifier loss: 0.486602; batch adversarial loss: 0.589689\n",
      "epoch 102; iter: 0; batch classifier loss: 0.351943; batch adversarial loss: 0.590635\n",
      "epoch 103; iter: 0; batch classifier loss: 0.345145; batch adversarial loss: 0.499330\n",
      "epoch 104; iter: 0; batch classifier loss: 0.441918; batch adversarial loss: 0.580952\n",
      "epoch 105; iter: 0; batch classifier loss: 0.373268; batch adversarial loss: 0.518270\n",
      "epoch 106; iter: 0; batch classifier loss: 0.406527; batch adversarial loss: 0.581322\n",
      "epoch 107; iter: 0; batch classifier loss: 0.428792; batch adversarial loss: 0.588653\n",
      "epoch 108; iter: 0; batch classifier loss: 0.351452; batch adversarial loss: 0.562468\n",
      "epoch 109; iter: 0; batch classifier loss: 0.452979; batch adversarial loss: 0.580297\n",
      "epoch 110; iter: 0; batch classifier loss: 0.426513; batch adversarial loss: 0.534033\n",
      "epoch 111; iter: 0; batch classifier loss: 0.431471; batch adversarial loss: 0.480719\n",
      "epoch 112; iter: 0; batch classifier loss: 0.332714; batch adversarial loss: 0.570604\n",
      "epoch 113; iter: 0; batch classifier loss: 0.350476; batch adversarial loss: 0.618384\n",
      "epoch 114; iter: 0; batch classifier loss: 0.439724; batch adversarial loss: 0.525043\n",
      "epoch 115; iter: 0; batch classifier loss: 0.391770; batch adversarial loss: 0.598082\n",
      "epoch 116; iter: 0; batch classifier loss: 0.376963; batch adversarial loss: 0.508541\n",
      "epoch 117; iter: 0; batch classifier loss: 0.368779; batch adversarial loss: 0.479957\n",
      "epoch 118; iter: 0; batch classifier loss: 0.397126; batch adversarial loss: 0.498815\n",
      "epoch 119; iter: 0; batch classifier loss: 0.490080; batch adversarial loss: 0.553734\n",
      "epoch 120; iter: 0; batch classifier loss: 0.457584; batch adversarial loss: 0.600701\n",
      "epoch 121; iter: 0; batch classifier loss: 0.366853; batch adversarial loss: 0.563795\n",
      "epoch 122; iter: 0; batch classifier loss: 0.456379; batch adversarial loss: 0.553339\n",
      "epoch 123; iter: 0; batch classifier loss: 0.343519; batch adversarial loss: 0.598433\n",
      "epoch 124; iter: 0; batch classifier loss: 0.458444; batch adversarial loss: 0.480762\n",
      "epoch 125; iter: 0; batch classifier loss: 0.415377; batch adversarial loss: 0.562292\n",
      "epoch 126; iter: 0; batch classifier loss: 0.322860; batch adversarial loss: 0.508239\n",
      "epoch 127; iter: 0; batch classifier loss: 0.418907; batch adversarial loss: 0.580199\n",
      "epoch 128; iter: 0; batch classifier loss: 0.396865; batch adversarial loss: 0.527128\n",
      "epoch 129; iter: 0; batch classifier loss: 0.309045; batch adversarial loss: 0.534806\n",
      "epoch 130; iter: 0; batch classifier loss: 0.425330; batch adversarial loss: 0.516436\n",
      "epoch 131; iter: 0; batch classifier loss: 0.389870; batch adversarial loss: 0.573184\n",
      "epoch 132; iter: 0; batch classifier loss: 0.400507; batch adversarial loss: 0.516594\n",
      "epoch 133; iter: 0; batch classifier loss: 0.410228; batch adversarial loss: 0.461298\n",
      "epoch 134; iter: 0; batch classifier loss: 0.400086; batch adversarial loss: 0.452104\n",
      "epoch 135; iter: 0; batch classifier loss: 0.377178; batch adversarial loss: 0.570448\n",
      "epoch 136; iter: 0; batch classifier loss: 0.407799; batch adversarial loss: 0.526036\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 137; iter: 0; batch classifier loss: 0.418106; batch adversarial loss: 0.581176\n",
      "epoch 138; iter: 0; batch classifier loss: 0.360927; batch adversarial loss: 0.488170\n",
      "epoch 139; iter: 0; batch classifier loss: 0.449203; batch adversarial loss: 0.524659\n",
      "epoch 140; iter: 0; batch classifier loss: 0.381374; batch adversarial loss: 0.490515\n",
      "epoch 141; iter: 0; batch classifier loss: 0.408231; batch adversarial loss: 0.551470\n",
      "epoch 142; iter: 0; batch classifier loss: 0.331358; batch adversarial loss: 0.562995\n",
      "epoch 143; iter: 0; batch classifier loss: 0.413453; batch adversarial loss: 0.507960\n",
      "epoch 144; iter: 0; batch classifier loss: 0.337966; batch adversarial loss: 0.543593\n",
      "epoch 145; iter: 0; batch classifier loss: 0.299444; batch adversarial loss: 0.545005\n",
      "epoch 146; iter: 0; batch classifier loss: 0.437042; batch adversarial loss: 0.591131\n",
      "epoch 147; iter: 0; batch classifier loss: 0.354019; batch adversarial loss: 0.480390\n",
      "epoch 148; iter: 0; batch classifier loss: 0.349238; batch adversarial loss: 0.496345\n",
      "epoch 149; iter: 0; batch classifier loss: 0.389876; batch adversarial loss: 0.580988\n",
      "epoch 150; iter: 0; batch classifier loss: 0.341303; batch adversarial loss: 0.653392\n",
      "epoch 151; iter: 0; batch classifier loss: 0.369714; batch adversarial loss: 0.507815\n",
      "epoch 152; iter: 0; batch classifier loss: 0.349724; batch adversarial loss: 0.498070\n",
      "epoch 153; iter: 0; batch classifier loss: 0.325533; batch adversarial loss: 0.489719\n",
      "epoch 154; iter: 0; batch classifier loss: 0.354099; batch adversarial loss: 0.610627\n",
      "epoch 155; iter: 0; batch classifier loss: 0.343875; batch adversarial loss: 0.518120\n",
      "epoch 156; iter: 0; batch classifier loss: 0.362310; batch adversarial loss: 0.525220\n",
      "epoch 157; iter: 0; batch classifier loss: 0.336009; batch adversarial loss: 0.581948\n",
      "epoch 158; iter: 0; batch classifier loss: 0.390827; batch adversarial loss: 0.544964\n",
      "epoch 159; iter: 0; batch classifier loss: 0.401693; batch adversarial loss: 0.551112\n",
      "epoch 160; iter: 0; batch classifier loss: 0.361616; batch adversarial loss: 0.526979\n",
      "epoch 161; iter: 0; batch classifier loss: 0.327653; batch adversarial loss: 0.515191\n",
      "epoch 162; iter: 0; batch classifier loss: 0.397143; batch adversarial loss: 0.562508\n",
      "epoch 163; iter: 0; batch classifier loss: 0.288003; batch adversarial loss: 0.663016\n",
      "epoch 164; iter: 0; batch classifier loss: 0.369184; batch adversarial loss: 0.497809\n",
      "epoch 165; iter: 0; batch classifier loss: 0.402836; batch adversarial loss: 0.508264\n",
      "epoch 166; iter: 0; batch classifier loss: 0.359885; batch adversarial loss: 0.563530\n",
      "epoch 167; iter: 0; batch classifier loss: 0.306562; batch adversarial loss: 0.642955\n",
      "epoch 168; iter: 0; batch classifier loss: 0.336383; batch adversarial loss: 0.560305\n",
      "epoch 169; iter: 0; batch classifier loss: 0.360258; batch adversarial loss: 0.588505\n",
      "epoch 170; iter: 0; batch classifier loss: 0.353973; batch adversarial loss: 0.563972\n",
      "epoch 171; iter: 0; batch classifier loss: 0.283736; batch adversarial loss: 0.552196\n",
      "epoch 172; iter: 0; batch classifier loss: 0.311023; batch adversarial loss: 0.489393\n",
      "epoch 173; iter: 0; batch classifier loss: 0.407215; batch adversarial loss: 0.499033\n",
      "epoch 174; iter: 0; batch classifier loss: 0.324817; batch adversarial loss: 0.499474\n",
      "epoch 175; iter: 0; batch classifier loss: 0.334330; batch adversarial loss: 0.519567\n",
      "epoch 176; iter: 0; batch classifier loss: 0.355580; batch adversarial loss: 0.544424\n",
      "epoch 177; iter: 0; batch classifier loss: 0.375644; batch adversarial loss: 0.623801\n",
      "epoch 178; iter: 0; batch classifier loss: 0.269671; batch adversarial loss: 0.589704\n",
      "epoch 179; iter: 0; batch classifier loss: 0.365609; batch adversarial loss: 0.535335\n",
      "epoch 180; iter: 0; batch classifier loss: 0.420270; batch adversarial loss: 0.581781\n",
      "epoch 181; iter: 0; batch classifier loss: 0.435176; batch adversarial loss: 0.591853\n",
      "epoch 182; iter: 0; batch classifier loss: 0.332517; batch adversarial loss: 0.627178\n",
      "epoch 183; iter: 0; batch classifier loss: 0.339049; batch adversarial loss: 0.488863\n",
      "epoch 184; iter: 0; batch classifier loss: 0.352933; batch adversarial loss: 0.498614\n",
      "epoch 185; iter: 0; batch classifier loss: 0.463497; batch adversarial loss: 0.534354\n",
      "epoch 186; iter: 0; batch classifier loss: 0.403492; batch adversarial loss: 0.573748\n",
      "epoch 187; iter: 0; batch classifier loss: 0.391105; batch adversarial loss: 0.527188\n",
      "epoch 188; iter: 0; batch classifier loss: 0.383142; batch adversarial loss: 0.573336\n",
      "epoch 189; iter: 0; batch classifier loss: 0.446548; batch adversarial loss: 0.517065\n",
      "epoch 190; iter: 0; batch classifier loss: 0.392396; batch adversarial loss: 0.562935\n",
      "epoch 191; iter: 0; batch classifier loss: 0.456374; batch adversarial loss: 0.462646\n",
      "epoch 192; iter: 0; batch classifier loss: 0.364799; batch adversarial loss: 0.497997\n",
      "epoch 193; iter: 0; batch classifier loss: 0.296475; batch adversarial loss: 0.561887\n",
      "epoch 194; iter: 0; batch classifier loss: 0.439305; batch adversarial loss: 0.508292\n",
      "epoch 195; iter: 0; batch classifier loss: 0.417701; batch adversarial loss: 0.546510\n",
      "epoch 196; iter: 0; batch classifier loss: 0.375415; batch adversarial loss: 0.590305\n",
      "epoch 197; iter: 0; batch classifier loss: 0.387073; batch adversarial loss: 0.534286\n",
      "epoch 198; iter: 0; batch classifier loss: 0.349977; batch adversarial loss: 0.536436\n",
      "epoch 199; iter: 0; batch classifier loss: 0.335961; batch adversarial loss: 0.518207\n",
      "epoch 0; iter: 0; batch classifier loss: 0.758120; batch adversarial loss: 0.894727\n",
      "epoch 1; iter: 0; batch classifier loss: 0.755824; batch adversarial loss: 0.946689\n",
      "epoch 2; iter: 0; batch classifier loss: 0.844976; batch adversarial loss: 0.904939\n",
      "epoch 3; iter: 0; batch classifier loss: 0.945959; batch adversarial loss: 0.833441\n",
      "epoch 4; iter: 0; batch classifier loss: 0.949393; batch adversarial loss: 0.768210\n",
      "epoch 5; iter: 0; batch classifier loss: 1.139012; batch adversarial loss: 0.717995\n",
      "epoch 6; iter: 0; batch classifier loss: 1.103693; batch adversarial loss: 0.665680\n",
      "epoch 7; iter: 0; batch classifier loss: 0.834347; batch adversarial loss: 0.616455\n",
      "epoch 8; iter: 0; batch classifier loss: 0.551748; batch adversarial loss: 0.591675\n",
      "epoch 9; iter: 0; batch classifier loss: 0.546429; batch adversarial loss: 0.592785\n",
      "epoch 10; iter: 0; batch classifier loss: 0.526303; batch adversarial loss: 0.570895\n",
      "epoch 11; iter: 0; batch classifier loss: 0.488162; batch adversarial loss: 0.600171\n",
      "epoch 12; iter: 0; batch classifier loss: 0.538718; batch adversarial loss: 0.618146\n",
      "epoch 13; iter: 0; batch classifier loss: 0.451269; batch adversarial loss: 0.595267\n",
      "epoch 14; iter: 0; batch classifier loss: 0.526559; batch adversarial loss: 0.548778\n",
      "epoch 15; iter: 0; batch classifier loss: 0.493126; batch adversarial loss: 0.587748\n",
      "epoch 16; iter: 0; batch classifier loss: 0.522105; batch adversarial loss: 0.547061\n",
      "epoch 17; iter: 0; batch classifier loss: 0.491648; batch adversarial loss: 0.560623\n",
      "epoch 18; iter: 0; batch classifier loss: 0.427427; batch adversarial loss: 0.597138\n",
      "epoch 19; iter: 0; batch classifier loss: 0.561841; batch adversarial loss: 0.576134\n",
      "epoch 20; iter: 0; batch classifier loss: 0.490399; batch adversarial loss: 0.556934\n",
      "epoch 21; iter: 0; batch classifier loss: 0.495702; batch adversarial loss: 0.656785\n",
      "epoch 22; iter: 0; batch classifier loss: 0.457952; batch adversarial loss: 0.578408\n",
      "epoch 23; iter: 0; batch classifier loss: 0.549742; batch adversarial loss: 0.520875\n",
      "epoch 24; iter: 0; batch classifier loss: 0.484421; batch adversarial loss: 0.559447\n",
      "epoch 25; iter: 0; batch classifier loss: 0.482907; batch adversarial loss: 0.522664\n",
      "epoch 26; iter: 0; batch classifier loss: 0.459981; batch adversarial loss: 0.544978\n",
      "epoch 27; iter: 0; batch classifier loss: 0.457758; batch adversarial loss: 0.561127\n",
      "epoch 28; iter: 0; batch classifier loss: 0.475418; batch adversarial loss: 0.597525\n",
      "epoch 29; iter: 0; batch classifier loss: 0.411807; batch adversarial loss: 0.543768\n",
      "epoch 30; iter: 0; batch classifier loss: 0.468885; batch adversarial loss: 0.556870\n",
      "epoch 31; iter: 0; batch classifier loss: 0.426504; batch adversarial loss: 0.534998\n",
      "epoch 32; iter: 0; batch classifier loss: 0.442232; batch adversarial loss: 0.558517\n",
      "epoch 33; iter: 0; batch classifier loss: 0.448247; batch adversarial loss: 0.549167\n",
      "epoch 34; iter: 0; batch classifier loss: 0.470150; batch adversarial loss: 0.586372\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 35; iter: 0; batch classifier loss: 0.428042; batch adversarial loss: 0.486398\n",
      "epoch 36; iter: 0; batch classifier loss: 0.406643; batch adversarial loss: 0.552107\n",
      "epoch 37; iter: 0; batch classifier loss: 0.438136; batch adversarial loss: 0.532441\n",
      "epoch 38; iter: 0; batch classifier loss: 0.496131; batch adversarial loss: 0.555611\n",
      "epoch 39; iter: 0; batch classifier loss: 0.438911; batch adversarial loss: 0.536853\n",
      "epoch 40; iter: 0; batch classifier loss: 0.412303; batch adversarial loss: 0.581741\n",
      "epoch 41; iter: 0; batch classifier loss: 0.511712; batch adversarial loss: 0.512478\n",
      "epoch 42; iter: 0; batch classifier loss: 0.468183; batch adversarial loss: 0.521780\n",
      "epoch 43; iter: 0; batch classifier loss: 0.408441; batch adversarial loss: 0.517167\n",
      "epoch 44; iter: 0; batch classifier loss: 0.402232; batch adversarial loss: 0.537735\n",
      "epoch 45; iter: 0; batch classifier loss: 0.383868; batch adversarial loss: 0.563277\n",
      "epoch 46; iter: 0; batch classifier loss: 0.484462; batch adversarial loss: 0.607285\n",
      "epoch 47; iter: 0; batch classifier loss: 0.304961; batch adversarial loss: 0.520090\n",
      "epoch 48; iter: 0; batch classifier loss: 0.368116; batch adversarial loss: 0.480585\n",
      "epoch 49; iter: 0; batch classifier loss: 0.400047; batch adversarial loss: 0.554225\n",
      "epoch 50; iter: 0; batch classifier loss: 0.393901; batch adversarial loss: 0.579240\n",
      "epoch 51; iter: 0; batch classifier loss: 0.397250; batch adversarial loss: 0.497177\n",
      "epoch 52; iter: 0; batch classifier loss: 0.460265; batch adversarial loss: 0.519575\n",
      "epoch 53; iter: 0; batch classifier loss: 0.392546; batch adversarial loss: 0.471843\n",
      "epoch 54; iter: 0; batch classifier loss: 0.421138; batch adversarial loss: 0.513706\n",
      "epoch 55; iter: 0; batch classifier loss: 0.446661; batch adversarial loss: 0.540091\n",
      "epoch 56; iter: 0; batch classifier loss: 0.500976; batch adversarial loss: 0.519235\n",
      "epoch 57; iter: 0; batch classifier loss: 0.413403; batch adversarial loss: 0.528777\n",
      "epoch 58; iter: 0; batch classifier loss: 0.414909; batch adversarial loss: 0.490447\n",
      "epoch 59; iter: 0; batch classifier loss: 0.388710; batch adversarial loss: 0.470400\n",
      "epoch 60; iter: 0; batch classifier loss: 0.372448; batch adversarial loss: 0.540815\n",
      "epoch 61; iter: 0; batch classifier loss: 0.366104; batch adversarial loss: 0.583846\n",
      "epoch 62; iter: 0; batch classifier loss: 0.393274; batch adversarial loss: 0.571434\n",
      "epoch 63; iter: 0; batch classifier loss: 0.425586; batch adversarial loss: 0.519568\n",
      "epoch 64; iter: 0; batch classifier loss: 0.363842; batch adversarial loss: 0.569875\n",
      "epoch 65; iter: 0; batch classifier loss: 0.294897; batch adversarial loss: 0.523268\n",
      "epoch 66; iter: 0; batch classifier loss: 0.415152; batch adversarial loss: 0.552208\n",
      "epoch 67; iter: 0; batch classifier loss: 0.407995; batch adversarial loss: 0.584224\n",
      "epoch 68; iter: 0; batch classifier loss: 0.424091; batch adversarial loss: 0.543034\n",
      "epoch 69; iter: 0; batch classifier loss: 0.373089; batch adversarial loss: 0.490496\n",
      "epoch 70; iter: 0; batch classifier loss: 0.359828; batch adversarial loss: 0.589317\n",
      "epoch 71; iter: 0; batch classifier loss: 0.317291; batch adversarial loss: 0.506509\n",
      "epoch 72; iter: 0; batch classifier loss: 0.353789; batch adversarial loss: 0.577514\n",
      "epoch 73; iter: 0; batch classifier loss: 0.423750; batch adversarial loss: 0.570688\n",
      "epoch 74; iter: 0; batch classifier loss: 0.347989; batch adversarial loss: 0.617915\n",
      "epoch 75; iter: 0; batch classifier loss: 0.424474; batch adversarial loss: 0.487323\n",
      "epoch 76; iter: 0; batch classifier loss: 0.457948; batch adversarial loss: 0.526773\n",
      "epoch 77; iter: 0; batch classifier loss: 0.387707; batch adversarial loss: 0.533037\n",
      "epoch 78; iter: 0; batch classifier loss: 0.456022; batch adversarial loss: 0.572578\n",
      "epoch 79; iter: 0; batch classifier loss: 0.389940; batch adversarial loss: 0.579640\n",
      "epoch 80; iter: 0; batch classifier loss: 0.299656; batch adversarial loss: 0.550617\n",
      "epoch 81; iter: 0; batch classifier loss: 0.346667; batch adversarial loss: 0.569502\n",
      "epoch 82; iter: 0; batch classifier loss: 0.373465; batch adversarial loss: 0.562643\n",
      "epoch 83; iter: 0; batch classifier loss: 0.397883; batch adversarial loss: 0.533780\n",
      "epoch 84; iter: 0; batch classifier loss: 0.308279; batch adversarial loss: 0.501671\n",
      "epoch 85; iter: 0; batch classifier loss: 0.299027; batch adversarial loss: 0.532121\n",
      "epoch 86; iter: 0; batch classifier loss: 0.401798; batch adversarial loss: 0.592545\n",
      "epoch 87; iter: 0; batch classifier loss: 0.382552; batch adversarial loss: 0.542981\n",
      "epoch 88; iter: 0; batch classifier loss: 0.435270; batch adversarial loss: 0.555681\n",
      "epoch 89; iter: 0; batch classifier loss: 0.370934; batch adversarial loss: 0.510318\n",
      "epoch 90; iter: 0; batch classifier loss: 0.342533; batch adversarial loss: 0.549926\n",
      "epoch 91; iter: 0; batch classifier loss: 0.404642; batch adversarial loss: 0.592616\n",
      "epoch 92; iter: 0; batch classifier loss: 0.390019; batch adversarial loss: 0.547094\n",
      "epoch 93; iter: 0; batch classifier loss: 0.325992; batch adversarial loss: 0.517138\n",
      "epoch 94; iter: 0; batch classifier loss: 0.345564; batch adversarial loss: 0.504430\n",
      "epoch 95; iter: 0; batch classifier loss: 0.359098; batch adversarial loss: 0.567467\n",
      "epoch 96; iter: 0; batch classifier loss: 0.409703; batch adversarial loss: 0.587988\n",
      "epoch 97; iter: 0; batch classifier loss: 0.317608; batch adversarial loss: 0.621497\n",
      "epoch 98; iter: 0; batch classifier loss: 0.332504; batch adversarial loss: 0.525195\n",
      "epoch 99; iter: 0; batch classifier loss: 0.332880; batch adversarial loss: 0.633893\n",
      "epoch 100; iter: 0; batch classifier loss: 0.325560; batch adversarial loss: 0.616554\n",
      "epoch 101; iter: 0; batch classifier loss: 0.330690; batch adversarial loss: 0.526333\n",
      "epoch 102; iter: 0; batch classifier loss: 0.350041; batch adversarial loss: 0.557577\n",
      "epoch 103; iter: 0; batch classifier loss: 0.365218; batch adversarial loss: 0.592176\n",
      "epoch 104; iter: 0; batch classifier loss: 0.358976; batch adversarial loss: 0.554754\n",
      "epoch 105; iter: 0; batch classifier loss: 0.325139; batch adversarial loss: 0.501970\n",
      "epoch 106; iter: 0; batch classifier loss: 0.284535; batch adversarial loss: 0.587132\n",
      "epoch 107; iter: 0; batch classifier loss: 0.433153; batch adversarial loss: 0.580097\n",
      "epoch 108; iter: 0; batch classifier loss: 0.363892; batch adversarial loss: 0.588772\n",
      "epoch 109; iter: 0; batch classifier loss: 0.337292; batch adversarial loss: 0.561705\n",
      "epoch 110; iter: 0; batch classifier loss: 0.349382; batch adversarial loss: 0.544460\n",
      "epoch 111; iter: 0; batch classifier loss: 0.398184; batch adversarial loss: 0.570254\n",
      "epoch 112; iter: 0; batch classifier loss: 0.371492; batch adversarial loss: 0.657740\n",
      "epoch 113; iter: 0; batch classifier loss: 0.315058; batch adversarial loss: 0.571190\n",
      "epoch 114; iter: 0; batch classifier loss: 0.333939; batch adversarial loss: 0.581956\n",
      "epoch 115; iter: 0; batch classifier loss: 0.246523; batch adversarial loss: 0.626701\n",
      "epoch 116; iter: 0; batch classifier loss: 0.353981; batch adversarial loss: 0.525539\n",
      "epoch 117; iter: 0; batch classifier loss: 0.443046; batch adversarial loss: 0.532737\n",
      "epoch 118; iter: 0; batch classifier loss: 0.358705; batch adversarial loss: 0.453225\n",
      "epoch 119; iter: 0; batch classifier loss: 0.383295; batch adversarial loss: 0.652972\n",
      "epoch 120; iter: 0; batch classifier loss: 0.417483; batch adversarial loss: 0.653324\n",
      "epoch 121; iter: 0; batch classifier loss: 0.298883; batch adversarial loss: 0.645635\n",
      "epoch 122; iter: 0; batch classifier loss: 0.411807; batch adversarial loss: 0.573205\n",
      "epoch 123; iter: 0; batch classifier loss: 0.326614; batch adversarial loss: 0.606912\n",
      "epoch 124; iter: 0; batch classifier loss: 0.348185; batch adversarial loss: 0.581967\n",
      "epoch 125; iter: 0; batch classifier loss: 0.310180; batch adversarial loss: 0.625028\n",
      "epoch 126; iter: 0; batch classifier loss: 0.408347; batch adversarial loss: 0.467483\n",
      "epoch 127; iter: 0; batch classifier loss: 0.339800; batch adversarial loss: 0.540442\n",
      "epoch 128; iter: 0; batch classifier loss: 0.352369; batch adversarial loss: 0.555633\n",
      "epoch 129; iter: 0; batch classifier loss: 0.297632; batch adversarial loss: 0.570975\n",
      "epoch 130; iter: 0; batch classifier loss: 0.386079; batch adversarial loss: 0.459955\n",
      "epoch 131; iter: 0; batch classifier loss: 0.359314; batch adversarial loss: 0.469613\n",
      "epoch 132; iter: 0; batch classifier loss: 0.359547; batch adversarial loss: 0.597269\n",
      "epoch 133; iter: 0; batch classifier loss: 0.336588; batch adversarial loss: 0.553887\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 134; iter: 0; batch classifier loss: 0.361305; batch adversarial loss: 0.588641\n",
      "epoch 135; iter: 0; batch classifier loss: 0.323031; batch adversarial loss: 0.582875\n",
      "epoch 136; iter: 0; batch classifier loss: 0.357962; batch adversarial loss: 0.542659\n",
      "epoch 137; iter: 0; batch classifier loss: 0.329918; batch adversarial loss: 0.500657\n",
      "epoch 138; iter: 0; batch classifier loss: 0.335084; batch adversarial loss: 0.562955\n",
      "epoch 139; iter: 0; batch classifier loss: 0.333447; batch adversarial loss: 0.595463\n",
      "epoch 140; iter: 0; batch classifier loss: 0.365893; batch adversarial loss: 0.552091\n",
      "epoch 141; iter: 0; batch classifier loss: 0.419244; batch adversarial loss: 0.560488\n",
      "epoch 142; iter: 0; batch classifier loss: 0.283149; batch adversarial loss: 0.570951\n",
      "epoch 143; iter: 0; batch classifier loss: 0.321960; batch adversarial loss: 0.456036\n",
      "epoch 144; iter: 0; batch classifier loss: 0.380838; batch adversarial loss: 0.534850\n",
      "epoch 145; iter: 0; batch classifier loss: 0.319147; batch adversarial loss: 0.576259\n",
      "epoch 146; iter: 0; batch classifier loss: 0.417613; batch adversarial loss: 0.536155\n",
      "epoch 147; iter: 0; batch classifier loss: 0.325144; batch adversarial loss: 0.613693\n",
      "epoch 148; iter: 0; batch classifier loss: 0.307316; batch adversarial loss: 0.552769\n",
      "epoch 149; iter: 0; batch classifier loss: 0.349724; batch adversarial loss: 0.606480\n",
      "epoch 150; iter: 0; batch classifier loss: 0.348931; batch adversarial loss: 0.572385\n",
      "epoch 151; iter: 0; batch classifier loss: 0.320041; batch adversarial loss: 0.588441\n",
      "epoch 152; iter: 0; batch classifier loss: 0.316660; batch adversarial loss: 0.569810\n",
      "epoch 153; iter: 0; batch classifier loss: 0.354522; batch adversarial loss: 0.491858\n",
      "epoch 154; iter: 0; batch classifier loss: 0.346603; batch adversarial loss: 0.579846\n",
      "epoch 155; iter: 0; batch classifier loss: 0.331072; batch adversarial loss: 0.621932\n",
      "epoch 156; iter: 0; batch classifier loss: 0.308454; batch adversarial loss: 0.538116\n",
      "epoch 157; iter: 0; batch classifier loss: 0.324787; batch adversarial loss: 0.623422\n",
      "epoch 158; iter: 0; batch classifier loss: 0.336352; batch adversarial loss: 0.588719\n",
      "epoch 159; iter: 0; batch classifier loss: 0.286316; batch adversarial loss: 0.534478\n",
      "epoch 160; iter: 0; batch classifier loss: 0.357379; batch adversarial loss: 0.545460\n",
      "epoch 161; iter: 0; batch classifier loss: 0.306087; batch adversarial loss: 0.562184\n",
      "epoch 162; iter: 0; batch classifier loss: 0.358623; batch adversarial loss: 0.517488\n",
      "epoch 163; iter: 0; batch classifier loss: 0.350346; batch adversarial loss: 0.525703\n",
      "epoch 164; iter: 0; batch classifier loss: 0.289773; batch adversarial loss: 0.545050\n",
      "epoch 165; iter: 0; batch classifier loss: 0.342830; batch adversarial loss: 0.520040\n",
      "epoch 166; iter: 0; batch classifier loss: 0.307189; batch adversarial loss: 0.536728\n",
      "epoch 167; iter: 0; batch classifier loss: 0.378671; batch adversarial loss: 0.546497\n",
      "epoch 168; iter: 0; batch classifier loss: 0.358930; batch adversarial loss: 0.535656\n",
      "epoch 169; iter: 0; batch classifier loss: 0.355323; batch adversarial loss: 0.560942\n",
      "epoch 170; iter: 0; batch classifier loss: 0.366450; batch adversarial loss: 0.586036\n",
      "epoch 171; iter: 0; batch classifier loss: 0.336099; batch adversarial loss: 0.580933\n",
      "epoch 172; iter: 0; batch classifier loss: 0.378941; batch adversarial loss: 0.508638\n",
      "epoch 173; iter: 0; batch classifier loss: 0.347260; batch adversarial loss: 0.555160\n",
      "epoch 174; iter: 0; batch classifier loss: 0.303949; batch adversarial loss: 0.552222\n",
      "epoch 175; iter: 0; batch classifier loss: 0.283097; batch adversarial loss: 0.554796\n",
      "epoch 176; iter: 0; batch classifier loss: 0.243570; batch adversarial loss: 0.614480\n",
      "epoch 177; iter: 0; batch classifier loss: 0.338845; batch adversarial loss: 0.509070\n",
      "epoch 178; iter: 0; batch classifier loss: 0.274494; batch adversarial loss: 0.625468\n",
      "epoch 179; iter: 0; batch classifier loss: 0.365277; batch adversarial loss: 0.577872\n",
      "epoch 180; iter: 0; batch classifier loss: 0.316169; batch adversarial loss: 0.570924\n",
      "epoch 181; iter: 0; batch classifier loss: 0.321772; batch adversarial loss: 0.502328\n",
      "epoch 182; iter: 0; batch classifier loss: 0.266267; batch adversarial loss: 0.536586\n",
      "epoch 183; iter: 0; batch classifier loss: 0.352293; batch adversarial loss: 0.605567\n",
      "epoch 184; iter: 0; batch classifier loss: 0.310134; batch adversarial loss: 0.517810\n",
      "epoch 185; iter: 0; batch classifier loss: 0.331109; batch adversarial loss: 0.589608\n",
      "epoch 186; iter: 0; batch classifier loss: 0.307068; batch adversarial loss: 0.578767\n",
      "epoch 187; iter: 0; batch classifier loss: 0.295443; batch adversarial loss: 0.591720\n",
      "epoch 188; iter: 0; batch classifier loss: 0.273567; batch adversarial loss: 0.614686\n",
      "epoch 189; iter: 0; batch classifier loss: 0.263619; batch adversarial loss: 0.642594\n",
      "epoch 190; iter: 0; batch classifier loss: 0.282140; batch adversarial loss: 0.526722\n",
      "epoch 191; iter: 0; batch classifier loss: 0.271737; batch adversarial loss: 0.535717\n",
      "epoch 192; iter: 0; batch classifier loss: 0.354449; batch adversarial loss: 0.537104\n",
      "epoch 193; iter: 0; batch classifier loss: 0.331034; batch adversarial loss: 0.546408\n",
      "epoch 194; iter: 0; batch classifier loss: 0.279702; batch adversarial loss: 0.534264\n",
      "epoch 195; iter: 0; batch classifier loss: 0.315984; batch adversarial loss: 0.597430\n",
      "epoch 196; iter: 0; batch classifier loss: 0.220631; batch adversarial loss: 0.571996\n",
      "epoch 197; iter: 0; batch classifier loss: 0.318183; batch adversarial loss: 0.604188\n",
      "epoch 198; iter: 0; batch classifier loss: 0.261436; batch adversarial loss: 0.483386\n",
      "epoch 199; iter: 0; batch classifier loss: 0.324367; batch adversarial loss: 0.595927\n",
      "epoch 0; iter: 0; batch classifier loss: 0.728057; batch adversarial loss: 0.576352\n",
      "epoch 1; iter: 0; batch classifier loss: 0.541132; batch adversarial loss: 0.659337\n",
      "epoch 2; iter: 0; batch classifier loss: 0.630478; batch adversarial loss: 0.613335\n",
      "epoch 3; iter: 0; batch classifier loss: 0.602394; batch adversarial loss: 0.617951\n",
      "epoch 4; iter: 0; batch classifier loss: 0.505289; batch adversarial loss: 0.586695\n",
      "epoch 5; iter: 0; batch classifier loss: 0.546279; batch adversarial loss: 0.652139\n",
      "epoch 6; iter: 0; batch classifier loss: 0.550917; batch adversarial loss: 0.602812\n",
      "epoch 7; iter: 0; batch classifier loss: 0.584676; batch adversarial loss: 0.632664\n",
      "epoch 8; iter: 0; batch classifier loss: 0.530245; batch adversarial loss: 0.600637\n",
      "epoch 9; iter: 0; batch classifier loss: 0.560731; batch adversarial loss: 0.580009\n",
      "epoch 10; iter: 0; batch classifier loss: 0.529853; batch adversarial loss: 0.595751\n",
      "epoch 11; iter: 0; batch classifier loss: 0.502740; batch adversarial loss: 0.636674\n",
      "epoch 12; iter: 0; batch classifier loss: 0.481261; batch adversarial loss: 0.562542\n",
      "epoch 13; iter: 0; batch classifier loss: 0.485941; batch adversarial loss: 0.566320\n",
      "epoch 14; iter: 0; batch classifier loss: 0.496322; batch adversarial loss: 0.549015\n",
      "epoch 15; iter: 0; batch classifier loss: 0.535507; batch adversarial loss: 0.585087\n",
      "epoch 16; iter: 0; batch classifier loss: 0.505371; batch adversarial loss: 0.553182\n",
      "epoch 17; iter: 0; batch classifier loss: 0.507634; batch adversarial loss: 0.562356\n",
      "epoch 18; iter: 0; batch classifier loss: 0.440564; batch adversarial loss: 0.566869\n",
      "epoch 19; iter: 0; batch classifier loss: 0.505702; batch adversarial loss: 0.642038\n",
      "epoch 20; iter: 0; batch classifier loss: 0.525176; batch adversarial loss: 0.581277\n",
      "epoch 21; iter: 0; batch classifier loss: 0.432665; batch adversarial loss: 0.508816\n",
      "epoch 22; iter: 0; batch classifier loss: 0.492981; batch adversarial loss: 0.522156\n",
      "epoch 23; iter: 0; batch classifier loss: 0.450064; batch adversarial loss: 0.561014\n",
      "epoch 24; iter: 0; batch classifier loss: 0.442298; batch adversarial loss: 0.545755\n",
      "epoch 25; iter: 0; batch classifier loss: 0.479959; batch adversarial loss: 0.543710\n",
      "epoch 26; iter: 0; batch classifier loss: 0.451443; batch adversarial loss: 0.598492\n",
      "epoch 27; iter: 0; batch classifier loss: 0.430261; batch adversarial loss: 0.556634\n",
      "epoch 28; iter: 0; batch classifier loss: 0.474309; batch adversarial loss: 0.641217\n",
      "epoch 29; iter: 0; batch classifier loss: 0.402733; batch adversarial loss: 0.528274\n",
      "epoch 30; iter: 0; batch classifier loss: 0.413718; batch adversarial loss: 0.528771\n",
      "epoch 31; iter: 0; batch classifier loss: 0.462092; batch adversarial loss: 0.493368\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 32; iter: 0; batch classifier loss: 0.390481; batch adversarial loss: 0.501203\n",
      "epoch 33; iter: 0; batch classifier loss: 0.386758; batch adversarial loss: 0.493745\n",
      "epoch 34; iter: 0; batch classifier loss: 0.425069; batch adversarial loss: 0.510637\n",
      "epoch 35; iter: 0; batch classifier loss: 0.499652; batch adversarial loss: 0.431956\n",
      "epoch 36; iter: 0; batch classifier loss: 0.465841; batch adversarial loss: 0.579652\n",
      "epoch 37; iter: 0; batch classifier loss: 0.416227; batch adversarial loss: 0.597548\n",
      "epoch 38; iter: 0; batch classifier loss: 0.449497; batch adversarial loss: 0.500351\n",
      "epoch 39; iter: 0; batch classifier loss: 0.437165; batch adversarial loss: 0.482838\n",
      "epoch 40; iter: 0; batch classifier loss: 0.534334; batch adversarial loss: 0.518304\n",
      "epoch 41; iter: 0; batch classifier loss: 0.428205; batch adversarial loss: 0.507495\n",
      "epoch 42; iter: 0; batch classifier loss: 0.417806; batch adversarial loss: 0.647371\n",
      "epoch 43; iter: 0; batch classifier loss: 0.400085; batch adversarial loss: 0.516712\n",
      "epoch 44; iter: 0; batch classifier loss: 0.500505; batch adversarial loss: 0.531561\n",
      "epoch 45; iter: 0; batch classifier loss: 0.329971; batch adversarial loss: 0.568404\n",
      "epoch 46; iter: 0; batch classifier loss: 0.410140; batch adversarial loss: 0.598569\n",
      "epoch 47; iter: 0; batch classifier loss: 0.362636; batch adversarial loss: 0.669354\n",
      "epoch 48; iter: 0; batch classifier loss: 0.454592; batch adversarial loss: 0.573893\n",
      "epoch 49; iter: 0; batch classifier loss: 0.475902; batch adversarial loss: 0.605137\n",
      "epoch 50; iter: 0; batch classifier loss: 0.441271; batch adversarial loss: 0.443289\n",
      "epoch 51; iter: 0; batch classifier loss: 0.426750; batch adversarial loss: 0.590458\n",
      "epoch 52; iter: 0; batch classifier loss: 0.452597; batch adversarial loss: 0.563493\n",
      "epoch 53; iter: 0; batch classifier loss: 0.390787; batch adversarial loss: 0.544679\n",
      "epoch 54; iter: 0; batch classifier loss: 0.426572; batch adversarial loss: 0.544634\n",
      "epoch 55; iter: 0; batch classifier loss: 0.387050; batch adversarial loss: 0.544503\n",
      "epoch 56; iter: 0; batch classifier loss: 0.466647; batch adversarial loss: 0.571988\n",
      "epoch 57; iter: 0; batch classifier loss: 0.339911; batch adversarial loss: 0.535754\n",
      "epoch 58; iter: 0; batch classifier loss: 0.453986; batch adversarial loss: 0.490303\n",
      "epoch 59; iter: 0; batch classifier loss: 0.444027; batch adversarial loss: 0.571074\n",
      "epoch 60; iter: 0; batch classifier loss: 0.362169; batch adversarial loss: 0.527911\n",
      "epoch 61; iter: 0; batch classifier loss: 0.369121; batch adversarial loss: 0.553792\n",
      "epoch 62; iter: 0; batch classifier loss: 0.408195; batch adversarial loss: 0.582331\n",
      "epoch 63; iter: 0; batch classifier loss: 0.350851; batch adversarial loss: 0.526458\n",
      "epoch 64; iter: 0; batch classifier loss: 0.363082; batch adversarial loss: 0.554584\n",
      "epoch 65; iter: 0; batch classifier loss: 0.411248; batch adversarial loss: 0.671836\n",
      "epoch 66; iter: 0; batch classifier loss: 0.384016; batch adversarial loss: 0.544707\n",
      "epoch 67; iter: 0; batch classifier loss: 0.483021; batch adversarial loss: 0.499916\n",
      "epoch 68; iter: 0; batch classifier loss: 0.381463; batch adversarial loss: 0.643429\n",
      "epoch 69; iter: 0; batch classifier loss: 0.431611; batch adversarial loss: 0.491178\n",
      "epoch 70; iter: 0; batch classifier loss: 0.454470; batch adversarial loss: 0.518080\n",
      "epoch 71; iter: 0; batch classifier loss: 0.462703; batch adversarial loss: 0.509726\n",
      "epoch 72; iter: 0; batch classifier loss: 0.439515; batch adversarial loss: 0.481051\n",
      "epoch 73; iter: 0; batch classifier loss: 0.445369; batch adversarial loss: 0.617739\n",
      "epoch 74; iter: 0; batch classifier loss: 0.364901; batch adversarial loss: 0.516401\n",
      "epoch 75; iter: 0; batch classifier loss: 0.436087; batch adversarial loss: 0.571334\n",
      "epoch 76; iter: 0; batch classifier loss: 0.387656; batch adversarial loss: 0.535248\n",
      "epoch 77; iter: 0; batch classifier loss: 0.358178; batch adversarial loss: 0.570240\n",
      "epoch 78; iter: 0; batch classifier loss: 0.366295; batch adversarial loss: 0.652215\n",
      "epoch 79; iter: 0; batch classifier loss: 0.279929; batch adversarial loss: 0.544439\n",
      "epoch 80; iter: 0; batch classifier loss: 0.347802; batch adversarial loss: 0.571170\n",
      "epoch 81; iter: 0; batch classifier loss: 0.322352; batch adversarial loss: 0.525910\n",
      "epoch 82; iter: 0; batch classifier loss: 0.488916; batch adversarial loss: 0.533735\n",
      "epoch 83; iter: 0; batch classifier loss: 0.409857; batch adversarial loss: 0.605577\n",
      "epoch 84; iter: 0; batch classifier loss: 0.443000; batch adversarial loss: 0.561450\n",
      "epoch 85; iter: 0; batch classifier loss: 0.361427; batch adversarial loss: 0.571058\n",
      "epoch 86; iter: 0; batch classifier loss: 0.415193; batch adversarial loss: 0.616631\n",
      "epoch 87; iter: 0; batch classifier loss: 0.351312; batch adversarial loss: 0.536465\n",
      "epoch 88; iter: 0; batch classifier loss: 0.401292; batch adversarial loss: 0.606273\n",
      "epoch 89; iter: 0; batch classifier loss: 0.334047; batch adversarial loss: 0.652966\n",
      "epoch 90; iter: 0; batch classifier loss: 0.428993; batch adversarial loss: 0.516911\n",
      "epoch 91; iter: 0; batch classifier loss: 0.493196; batch adversarial loss: 0.497976\n",
      "epoch 92; iter: 0; batch classifier loss: 0.340952; batch adversarial loss: 0.597817\n",
      "epoch 93; iter: 0; batch classifier loss: 0.366407; batch adversarial loss: 0.491604\n",
      "epoch 94; iter: 0; batch classifier loss: 0.411095; batch adversarial loss: 0.635022\n",
      "epoch 95; iter: 0; batch classifier loss: 0.410661; batch adversarial loss: 0.560645\n",
      "epoch 96; iter: 0; batch classifier loss: 0.306991; batch adversarial loss: 0.543933\n",
      "epoch 97; iter: 0; batch classifier loss: 0.455707; batch adversarial loss: 0.545993\n",
      "epoch 98; iter: 0; batch classifier loss: 0.315073; batch adversarial loss: 0.536370\n",
      "epoch 99; iter: 0; batch classifier loss: 0.395278; batch adversarial loss: 0.535234\n",
      "epoch 100; iter: 0; batch classifier loss: 0.391100; batch adversarial loss: 0.509311\n",
      "epoch 101; iter: 0; batch classifier loss: 0.347545; batch adversarial loss: 0.536451\n",
      "epoch 102; iter: 0; batch classifier loss: 0.407514; batch adversarial loss: 0.563544\n",
      "epoch 103; iter: 0; batch classifier loss: 0.337061; batch adversarial loss: 0.498658\n",
      "epoch 104; iter: 0; batch classifier loss: 0.362032; batch adversarial loss: 0.580162\n",
      "epoch 105; iter: 0; batch classifier loss: 0.370084; batch adversarial loss: 0.527586\n",
      "epoch 106; iter: 0; batch classifier loss: 0.391597; batch adversarial loss: 0.553155\n",
      "epoch 107; iter: 0; batch classifier loss: 0.319538; batch adversarial loss: 0.544560\n",
      "epoch 108; iter: 0; batch classifier loss: 0.289280; batch adversarial loss: 0.588929\n",
      "epoch 109; iter: 0; batch classifier loss: 0.306739; batch adversarial loss: 0.607053\n",
      "epoch 110; iter: 0; batch classifier loss: 0.374018; batch adversarial loss: 0.546150\n",
      "epoch 111; iter: 0; batch classifier loss: 0.340792; batch adversarial loss: 0.555278\n",
      "epoch 112; iter: 0; batch classifier loss: 0.419078; batch adversarial loss: 0.482233\n",
      "epoch 113; iter: 0; batch classifier loss: 0.387577; batch adversarial loss: 0.525592\n",
      "epoch 114; iter: 0; batch classifier loss: 0.317545; batch adversarial loss: 0.536185\n",
      "epoch 115; iter: 0; batch classifier loss: 0.425450; batch adversarial loss: 0.546450\n",
      "epoch 116; iter: 0; batch classifier loss: 0.321517; batch adversarial loss: 0.627087\n",
      "epoch 117; iter: 0; batch classifier loss: 0.322624; batch adversarial loss: 0.563585\n",
      "epoch 118; iter: 0; batch classifier loss: 0.428736; batch adversarial loss: 0.578324\n",
      "epoch 119; iter: 0; batch classifier loss: 0.348935; batch adversarial loss: 0.581274\n",
      "epoch 120; iter: 0; batch classifier loss: 0.465304; batch adversarial loss: 0.608116\n",
      "epoch 121; iter: 0; batch classifier loss: 0.341121; batch adversarial loss: 0.491213\n",
      "epoch 122; iter: 0; batch classifier loss: 0.418839; batch adversarial loss: 0.579913\n",
      "epoch 123; iter: 0; batch classifier loss: 0.339915; batch adversarial loss: 0.491346\n",
      "epoch 124; iter: 0; batch classifier loss: 0.318237; batch adversarial loss: 0.608254\n",
      "epoch 125; iter: 0; batch classifier loss: 0.334377; batch adversarial loss: 0.579926\n",
      "epoch 126; iter: 0; batch classifier loss: 0.343002; batch adversarial loss: 0.562052\n",
      "epoch 127; iter: 0; batch classifier loss: 0.399646; batch adversarial loss: 0.562394\n",
      "epoch 128; iter: 0; batch classifier loss: 0.286182; batch adversarial loss: 0.590462\n",
      "epoch 129; iter: 0; batch classifier loss: 0.315630; batch adversarial loss: 0.588231\n",
      "epoch 130; iter: 0; batch classifier loss: 0.375093; batch adversarial loss: 0.537303\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 131; iter: 0; batch classifier loss: 0.304139; batch adversarial loss: 0.588428\n",
      "epoch 132; iter: 0; batch classifier loss: 0.419473; batch adversarial loss: 0.499540\n",
      "epoch 133; iter: 0; batch classifier loss: 0.372148; batch adversarial loss: 0.508020\n",
      "epoch 134; iter: 0; batch classifier loss: 0.333852; batch adversarial loss: 0.596990\n",
      "epoch 135; iter: 0; batch classifier loss: 0.364592; batch adversarial loss: 0.509985\n",
      "epoch 136; iter: 0; batch classifier loss: 0.366658; batch adversarial loss: 0.562502\n",
      "epoch 137; iter: 0; batch classifier loss: 0.474902; batch adversarial loss: 0.608820\n",
      "epoch 138; iter: 0; batch classifier loss: 0.373006; batch adversarial loss: 0.554409\n",
      "epoch 139; iter: 0; batch classifier loss: 0.356105; batch adversarial loss: 0.534333\n",
      "epoch 140; iter: 0; batch classifier loss: 0.379371; batch adversarial loss: 0.526585\n",
      "epoch 141; iter: 0; batch classifier loss: 0.399123; batch adversarial loss: 0.598283\n",
      "epoch 142; iter: 0; batch classifier loss: 0.346983; batch adversarial loss: 0.545927\n",
      "epoch 143; iter: 0; batch classifier loss: 0.323059; batch adversarial loss: 0.536188\n",
      "epoch 144; iter: 0; batch classifier loss: 0.439150; batch adversarial loss: 0.501302\n",
      "epoch 145; iter: 0; batch classifier loss: 0.406397; batch adversarial loss: 0.515121\n",
      "epoch 146; iter: 0; batch classifier loss: 0.358617; batch adversarial loss: 0.561380\n",
      "epoch 147; iter: 0; batch classifier loss: 0.413584; batch adversarial loss: 0.516766\n",
      "epoch 148; iter: 0; batch classifier loss: 0.318859; batch adversarial loss: 0.661384\n",
      "epoch 149; iter: 0; batch classifier loss: 0.302380; batch adversarial loss: 0.555845\n",
      "epoch 150; iter: 0; batch classifier loss: 0.377772; batch adversarial loss: 0.633505\n",
      "epoch 151; iter: 0; batch classifier loss: 0.347826; batch adversarial loss: 0.527230\n",
      "epoch 152; iter: 0; batch classifier loss: 0.344073; batch adversarial loss: 0.553717\n",
      "epoch 153; iter: 0; batch classifier loss: 0.405882; batch adversarial loss: 0.518408\n",
      "epoch 154; iter: 0; batch classifier loss: 0.422892; batch adversarial loss: 0.542895\n",
      "epoch 155; iter: 0; batch classifier loss: 0.370320; batch adversarial loss: 0.545535\n",
      "epoch 156; iter: 0; batch classifier loss: 0.348677; batch adversarial loss: 0.507496\n",
      "epoch 157; iter: 0; batch classifier loss: 0.300607; batch adversarial loss: 0.535390\n",
      "epoch 158; iter: 0; batch classifier loss: 0.326910; batch adversarial loss: 0.500949\n",
      "epoch 159; iter: 0; batch classifier loss: 0.425915; batch adversarial loss: 0.533933\n",
      "epoch 160; iter: 0; batch classifier loss: 0.422114; batch adversarial loss: 0.634994\n",
      "epoch 161; iter: 0; batch classifier loss: 0.480848; batch adversarial loss: 0.581532\n",
      "epoch 162; iter: 0; batch classifier loss: 0.312286; batch adversarial loss: 0.525495\n",
      "epoch 163; iter: 0; batch classifier loss: 0.259974; batch adversarial loss: 0.588504\n",
      "epoch 164; iter: 0; batch classifier loss: 0.402566; batch adversarial loss: 0.554105\n",
      "epoch 165; iter: 0; batch classifier loss: 0.399621; batch adversarial loss: 0.491511\n",
      "epoch 166; iter: 0; batch classifier loss: 0.341441; batch adversarial loss: 0.598196\n",
      "epoch 167; iter: 0; batch classifier loss: 0.318883; batch adversarial loss: 0.508457\n",
      "epoch 168; iter: 0; batch classifier loss: 0.426946; batch adversarial loss: 0.509544\n",
      "epoch 169; iter: 0; batch classifier loss: 0.364885; batch adversarial loss: 0.490828\n",
      "epoch 170; iter: 0; batch classifier loss: 0.320193; batch adversarial loss: 0.571585\n",
      "epoch 171; iter: 0; batch classifier loss: 0.364534; batch adversarial loss: 0.515539\n",
      "epoch 172; iter: 0; batch classifier loss: 0.376876; batch adversarial loss: 0.617755\n",
      "epoch 173; iter: 0; batch classifier loss: 0.493063; batch adversarial loss: 0.626891\n",
      "epoch 174; iter: 0; batch classifier loss: 0.391586; batch adversarial loss: 0.606198\n",
      "epoch 175; iter: 0; batch classifier loss: 0.285495; batch adversarial loss: 0.654100\n",
      "epoch 176; iter: 0; batch classifier loss: 0.336346; batch adversarial loss: 0.591902\n",
      "epoch 177; iter: 0; batch classifier loss: 0.389097; batch adversarial loss: 0.545805\n",
      "epoch 178; iter: 0; batch classifier loss: 0.354092; batch adversarial loss: 0.482575\n",
      "epoch 179; iter: 0; batch classifier loss: 0.344608; batch adversarial loss: 0.570349\n",
      "epoch 180; iter: 0; batch classifier loss: 0.371824; batch adversarial loss: 0.556672\n",
      "epoch 181; iter: 0; batch classifier loss: 0.360357; batch adversarial loss: 0.570775\n",
      "epoch 182; iter: 0; batch classifier loss: 0.324410; batch adversarial loss: 0.526451\n",
      "epoch 183; iter: 0; batch classifier loss: 0.387100; batch adversarial loss: 0.641754\n",
      "epoch 184; iter: 0; batch classifier loss: 0.438634; batch adversarial loss: 0.482450\n",
      "epoch 185; iter: 0; batch classifier loss: 0.325818; batch adversarial loss: 0.554368\n",
      "epoch 186; iter: 0; batch classifier loss: 0.356349; batch adversarial loss: 0.493806\n",
      "epoch 187; iter: 0; batch classifier loss: 0.324187; batch adversarial loss: 0.563401\n",
      "epoch 188; iter: 0; batch classifier loss: 0.365794; batch adversarial loss: 0.480505\n",
      "epoch 189; iter: 0; batch classifier loss: 0.357638; batch adversarial loss: 0.498987\n",
      "epoch 190; iter: 0; batch classifier loss: 0.352646; batch adversarial loss: 0.526929\n",
      "epoch 191; iter: 0; batch classifier loss: 0.338110; batch adversarial loss: 0.580167\n",
      "epoch 192; iter: 0; batch classifier loss: 0.317914; batch adversarial loss: 0.655470\n",
      "epoch 193; iter: 0; batch classifier loss: 0.419254; batch adversarial loss: 0.569867\n",
      "epoch 194; iter: 0; batch classifier loss: 0.385450; batch adversarial loss: 0.525394\n",
      "epoch 195; iter: 0; batch classifier loss: 0.338915; batch adversarial loss: 0.537542\n",
      "epoch 196; iter: 0; batch classifier loss: 0.347934; batch adversarial loss: 0.543883\n",
      "epoch 197; iter: 0; batch classifier loss: 0.357688; batch adversarial loss: 0.499021\n",
      "epoch 198; iter: 0; batch classifier loss: 0.366602; batch adversarial loss: 0.545792\n",
      "epoch 199; iter: 0; batch classifier loss: 0.388319; batch adversarial loss: 0.570451\n",
      "epoch 0; iter: 0; batch classifier loss: 0.725188; batch adversarial loss: 0.868365\n",
      "epoch 1; iter: 0; batch classifier loss: 0.864669; batch adversarial loss: 1.018321\n",
      "epoch 2; iter: 0; batch classifier loss: 1.003322; batch adversarial loss: 0.992029\n",
      "epoch 3; iter: 0; batch classifier loss: 1.001987; batch adversarial loss: 0.918432\n",
      "epoch 4; iter: 0; batch classifier loss: 0.842786; batch adversarial loss: 0.794695\n",
      "epoch 5; iter: 0; batch classifier loss: 0.750922; batch adversarial loss: 0.740191\n",
      "epoch 6; iter: 0; batch classifier loss: 0.712519; batch adversarial loss: 0.700452\n",
      "epoch 7; iter: 0; batch classifier loss: 0.591195; batch adversarial loss: 0.631575\n",
      "epoch 8; iter: 0; batch classifier loss: 0.527707; batch adversarial loss: 0.659033\n",
      "epoch 9; iter: 0; batch classifier loss: 0.549637; batch adversarial loss: 0.567461\n",
      "epoch 10; iter: 0; batch classifier loss: 0.549566; batch adversarial loss: 0.612096\n",
      "epoch 11; iter: 0; batch classifier loss: 0.542782; batch adversarial loss: 0.622383\n",
      "epoch 12; iter: 0; batch classifier loss: 0.531790; batch adversarial loss: 0.548590\n",
      "epoch 13; iter: 0; batch classifier loss: 0.533175; batch adversarial loss: 0.559411\n",
      "epoch 14; iter: 0; batch classifier loss: 0.541282; batch adversarial loss: 0.637215\n",
      "epoch 15; iter: 0; batch classifier loss: 0.566083; batch adversarial loss: 0.594201\n",
      "epoch 16; iter: 0; batch classifier loss: 0.515146; batch adversarial loss: 0.623252\n",
      "epoch 17; iter: 0; batch classifier loss: 0.476137; batch adversarial loss: 0.595287\n",
      "epoch 18; iter: 0; batch classifier loss: 0.523398; batch adversarial loss: 0.544470\n",
      "epoch 19; iter: 0; batch classifier loss: 0.521260; batch adversarial loss: 0.518513\n",
      "epoch 20; iter: 0; batch classifier loss: 0.516537; batch adversarial loss: 0.509229\n",
      "epoch 21; iter: 0; batch classifier loss: 0.473656; batch adversarial loss: 0.559779\n",
      "epoch 22; iter: 0; batch classifier loss: 0.525437; batch adversarial loss: 0.544912\n",
      "epoch 23; iter: 0; batch classifier loss: 0.547387; batch adversarial loss: 0.559034\n",
      "epoch 24; iter: 0; batch classifier loss: 0.491165; batch adversarial loss: 0.567958\n",
      "epoch 25; iter: 0; batch classifier loss: 0.466502; batch adversarial loss: 0.531217\n",
      "epoch 26; iter: 0; batch classifier loss: 0.534237; batch adversarial loss: 0.553194\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 27; iter: 0; batch classifier loss: 0.492037; batch adversarial loss: 0.572948\n",
      "epoch 28; iter: 0; batch classifier loss: 0.542000; batch adversarial loss: 0.552598\n",
      "epoch 29; iter: 0; batch classifier loss: 0.361006; batch adversarial loss: 0.504585\n",
      "epoch 30; iter: 0; batch classifier loss: 0.468627; batch adversarial loss: 0.473301\n",
      "epoch 31; iter: 0; batch classifier loss: 0.521476; batch adversarial loss: 0.581966\n",
      "epoch 32; iter: 0; batch classifier loss: 0.500744; batch adversarial loss: 0.547290\n",
      "epoch 33; iter: 0; batch classifier loss: 0.487214; batch adversarial loss: 0.481868\n",
      "epoch 34; iter: 0; batch classifier loss: 0.424726; batch adversarial loss: 0.611167\n",
      "epoch 35; iter: 0; batch classifier loss: 0.419362; batch adversarial loss: 0.558062\n",
      "epoch 36; iter: 0; batch classifier loss: 0.470851; batch adversarial loss: 0.644919\n",
      "epoch 37; iter: 0; batch classifier loss: 0.471889; batch adversarial loss: 0.529966\n",
      "epoch 38; iter: 0; batch classifier loss: 0.459719; batch adversarial loss: 0.538367\n",
      "epoch 39; iter: 0; batch classifier loss: 0.460282; batch adversarial loss: 0.604128\n",
      "epoch 40; iter: 0; batch classifier loss: 0.446148; batch adversarial loss: 0.543925\n",
      "epoch 41; iter: 0; batch classifier loss: 0.464524; batch adversarial loss: 0.596128\n",
      "epoch 42; iter: 0; batch classifier loss: 0.450741; batch adversarial loss: 0.561844\n",
      "epoch 43; iter: 0; batch classifier loss: 0.449502; batch adversarial loss: 0.472706\n",
      "epoch 44; iter: 0; batch classifier loss: 0.424761; batch adversarial loss: 0.585979\n",
      "epoch 45; iter: 0; batch classifier loss: 0.531621; batch adversarial loss: 0.543982\n",
      "epoch 46; iter: 0; batch classifier loss: 0.511126; batch adversarial loss: 0.510708\n",
      "epoch 47; iter: 0; batch classifier loss: 0.442269; batch adversarial loss: 0.536205\n",
      "epoch 48; iter: 0; batch classifier loss: 0.444949; batch adversarial loss: 0.556545\n",
      "epoch 49; iter: 0; batch classifier loss: 0.450206; batch adversarial loss: 0.511317\n",
      "epoch 50; iter: 0; batch classifier loss: 0.412194; batch adversarial loss: 0.575030\n",
      "epoch 51; iter: 0; batch classifier loss: 0.420436; batch adversarial loss: 0.528973\n",
      "epoch 52; iter: 0; batch classifier loss: 0.377147; batch adversarial loss: 0.507804\n",
      "epoch 53; iter: 0; batch classifier loss: 0.430592; batch adversarial loss: 0.499041\n",
      "epoch 54; iter: 0; batch classifier loss: 0.465053; batch adversarial loss: 0.483382\n",
      "epoch 55; iter: 0; batch classifier loss: 0.412597; batch adversarial loss: 0.499391\n",
      "epoch 56; iter: 0; batch classifier loss: 0.459449; batch adversarial loss: 0.480873\n",
      "epoch 57; iter: 0; batch classifier loss: 0.440618; batch adversarial loss: 0.545011\n",
      "epoch 58; iter: 0; batch classifier loss: 0.422791; batch adversarial loss: 0.499176\n",
      "epoch 59; iter: 0; batch classifier loss: 0.402482; batch adversarial loss: 0.535696\n",
      "epoch 60; iter: 0; batch classifier loss: 0.425868; batch adversarial loss: 0.571824\n",
      "epoch 61; iter: 0; batch classifier loss: 0.387987; batch adversarial loss: 0.498295\n",
      "epoch 62; iter: 0; batch classifier loss: 0.388107; batch adversarial loss: 0.535252\n",
      "epoch 63; iter: 0; batch classifier loss: 0.410963; batch adversarial loss: 0.489840\n",
      "epoch 64; iter: 0; batch classifier loss: 0.363803; batch adversarial loss: 0.481861\n",
      "epoch 65; iter: 0; batch classifier loss: 0.423911; batch adversarial loss: 0.518985\n",
      "epoch 66; iter: 0; batch classifier loss: 0.378803; batch adversarial loss: 0.590537\n",
      "epoch 67; iter: 0; batch classifier loss: 0.434818; batch adversarial loss: 0.489392\n",
      "epoch 68; iter: 0; batch classifier loss: 0.451269; batch adversarial loss: 0.589987\n",
      "epoch 69; iter: 0; batch classifier loss: 0.432822; batch adversarial loss: 0.516413\n",
      "epoch 70; iter: 0; batch classifier loss: 0.405871; batch adversarial loss: 0.599739\n",
      "epoch 71; iter: 0; batch classifier loss: 0.381902; batch adversarial loss: 0.605563\n",
      "epoch 72; iter: 0; batch classifier loss: 0.408629; batch adversarial loss: 0.543594\n",
      "epoch 73; iter: 0; batch classifier loss: 0.372883; batch adversarial loss: 0.507485\n",
      "epoch 74; iter: 0; batch classifier loss: 0.385201; batch adversarial loss: 0.578103\n",
      "epoch 75; iter: 0; batch classifier loss: 0.391750; batch adversarial loss: 0.620736\n",
      "epoch 76; iter: 0; batch classifier loss: 0.457247; batch adversarial loss: 0.636235\n",
      "epoch 77; iter: 0; batch classifier loss: 0.424539; batch adversarial loss: 0.573082\n",
      "epoch 78; iter: 0; batch classifier loss: 0.354037; batch adversarial loss: 0.543743\n",
      "epoch 79; iter: 0; batch classifier loss: 0.381517; batch adversarial loss: 0.581597\n",
      "epoch 80; iter: 0; batch classifier loss: 0.433351; batch adversarial loss: 0.523375\n",
      "epoch 81; iter: 0; batch classifier loss: 0.371499; batch adversarial loss: 0.496816\n",
      "epoch 82; iter: 0; batch classifier loss: 0.410377; batch adversarial loss: 0.524496\n",
      "epoch 83; iter: 0; batch classifier loss: 0.390507; batch adversarial loss: 0.599142\n",
      "epoch 84; iter: 0; batch classifier loss: 0.376996; batch adversarial loss: 0.545886\n",
      "epoch 85; iter: 0; batch classifier loss: 0.355712; batch adversarial loss: 0.541653\n",
      "epoch 86; iter: 0; batch classifier loss: 0.334224; batch adversarial loss: 0.598090\n",
      "epoch 87; iter: 0; batch classifier loss: 0.415774; batch adversarial loss: 0.547645\n",
      "epoch 88; iter: 0; batch classifier loss: 0.400178; batch adversarial loss: 0.470861\n",
      "epoch 89; iter: 0; batch classifier loss: 0.406917; batch adversarial loss: 0.490867\n",
      "epoch 90; iter: 0; batch classifier loss: 0.350732; batch adversarial loss: 0.526141\n",
      "epoch 91; iter: 0; batch classifier loss: 0.403407; batch adversarial loss: 0.519367\n",
      "epoch 92; iter: 0; batch classifier loss: 0.377163; batch adversarial loss: 0.561555\n",
      "epoch 93; iter: 0; batch classifier loss: 0.415347; batch adversarial loss: 0.490811\n",
      "epoch 94; iter: 0; batch classifier loss: 0.403480; batch adversarial loss: 0.506296\n",
      "epoch 95; iter: 0; batch classifier loss: 0.444668; batch adversarial loss: 0.564385\n",
      "epoch 96; iter: 0; batch classifier loss: 0.366887; batch adversarial loss: 0.528598\n",
      "epoch 97; iter: 0; batch classifier loss: 0.373420; batch adversarial loss: 0.543867\n",
      "epoch 98; iter: 0; batch classifier loss: 0.365180; batch adversarial loss: 0.561189\n",
      "epoch 99; iter: 0; batch classifier loss: 0.412294; batch adversarial loss: 0.498019\n",
      "epoch 100; iter: 0; batch classifier loss: 0.385718; batch adversarial loss: 0.533851\n",
      "epoch 101; iter: 0; batch classifier loss: 0.367486; batch adversarial loss: 0.552161\n",
      "epoch 102; iter: 0; batch classifier loss: 0.442546; batch adversarial loss: 0.497052\n",
      "epoch 103; iter: 0; batch classifier loss: 0.302841; batch adversarial loss: 0.551699\n",
      "epoch 104; iter: 0; batch classifier loss: 0.463386; batch adversarial loss: 0.465499\n",
      "epoch 105; iter: 0; batch classifier loss: 0.406652; batch adversarial loss: 0.536164\n",
      "epoch 106; iter: 0; batch classifier loss: 0.332715; batch adversarial loss: 0.545862\n",
      "epoch 107; iter: 0; batch classifier loss: 0.365338; batch adversarial loss: 0.549520\n",
      "epoch 108; iter: 0; batch classifier loss: 0.397585; batch adversarial loss: 0.451527\n",
      "epoch 109; iter: 0; batch classifier loss: 0.407404; batch adversarial loss: 0.573890\n",
      "epoch 110; iter: 0; batch classifier loss: 0.447999; batch adversarial loss: 0.536817\n",
      "epoch 111; iter: 0; batch classifier loss: 0.368092; batch adversarial loss: 0.479663\n",
      "epoch 112; iter: 0; batch classifier loss: 0.326286; batch adversarial loss: 0.542330\n",
      "epoch 113; iter: 0; batch classifier loss: 0.399197; batch adversarial loss: 0.536503\n",
      "epoch 114; iter: 0; batch classifier loss: 0.378513; batch adversarial loss: 0.570086\n",
      "epoch 115; iter: 0; batch classifier loss: 0.382549; batch adversarial loss: 0.598568\n",
      "epoch 116; iter: 0; batch classifier loss: 0.358782; batch adversarial loss: 0.545955\n",
      "epoch 117; iter: 0; batch classifier loss: 0.407839; batch adversarial loss: 0.601216\n",
      "epoch 118; iter: 0; batch classifier loss: 0.350965; batch adversarial loss: 0.583165\n",
      "epoch 119; iter: 0; batch classifier loss: 0.343613; batch adversarial loss: 0.543234\n",
      "epoch 120; iter: 0; batch classifier loss: 0.381581; batch adversarial loss: 0.512835\n",
      "epoch 121; iter: 0; batch classifier loss: 0.398050; batch adversarial loss: 0.573405\n",
      "epoch 122; iter: 0; batch classifier loss: 0.420851; batch adversarial loss: 0.554816\n",
      "epoch 123; iter: 0; batch classifier loss: 0.381311; batch adversarial loss: 0.509544\n",
      "epoch 124; iter: 0; batch classifier loss: 0.353372; batch adversarial loss: 0.579924\n",
      "epoch 125; iter: 0; batch classifier loss: 0.372196; batch adversarial loss: 0.499640\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 126; iter: 0; batch classifier loss: 0.363940; batch adversarial loss: 0.527450\n",
      "epoch 127; iter: 0; batch classifier loss: 0.380411; batch adversarial loss: 0.510447\n",
      "epoch 128; iter: 0; batch classifier loss: 0.363336; batch adversarial loss: 0.509078\n",
      "epoch 129; iter: 0; batch classifier loss: 0.370893; batch adversarial loss: 0.535371\n",
      "epoch 130; iter: 0; batch classifier loss: 0.304576; batch adversarial loss: 0.521543\n",
      "epoch 131; iter: 0; batch classifier loss: 0.350550; batch adversarial loss: 0.591591\n",
      "epoch 132; iter: 0; batch classifier loss: 0.408658; batch adversarial loss: 0.542889\n",
      "epoch 133; iter: 0; batch classifier loss: 0.405297; batch adversarial loss: 0.543189\n",
      "epoch 134; iter: 0; batch classifier loss: 0.370808; batch adversarial loss: 0.559153\n",
      "epoch 135; iter: 0; batch classifier loss: 0.361200; batch adversarial loss: 0.591025\n",
      "epoch 136; iter: 0; batch classifier loss: 0.402087; batch adversarial loss: 0.486894\n",
      "epoch 137; iter: 0; batch classifier loss: 0.318908; batch adversarial loss: 0.488691\n",
      "epoch 138; iter: 0; batch classifier loss: 0.318204; batch adversarial loss: 0.579450\n",
      "epoch 139; iter: 0; batch classifier loss: 0.338072; batch adversarial loss: 0.552781\n",
      "epoch 140; iter: 0; batch classifier loss: 0.349835; batch adversarial loss: 0.609430\n",
      "epoch 141; iter: 0; batch classifier loss: 0.427134; batch adversarial loss: 0.523852\n",
      "epoch 142; iter: 0; batch classifier loss: 0.429324; batch adversarial loss: 0.509390\n",
      "epoch 143; iter: 0; batch classifier loss: 0.360470; batch adversarial loss: 0.561487\n",
      "epoch 144; iter: 0; batch classifier loss: 0.359543; batch adversarial loss: 0.484519\n",
      "epoch 145; iter: 0; batch classifier loss: 0.347585; batch adversarial loss: 0.497241\n",
      "epoch 146; iter: 0; batch classifier loss: 0.419453; batch adversarial loss: 0.569513\n",
      "epoch 147; iter: 0; batch classifier loss: 0.453743; batch adversarial loss: 0.513840\n",
      "epoch 148; iter: 0; batch classifier loss: 0.364213; batch adversarial loss: 0.637295\n",
      "epoch 149; iter: 0; batch classifier loss: 0.355897; batch adversarial loss: 0.554705\n",
      "epoch 150; iter: 0; batch classifier loss: 0.316725; batch adversarial loss: 0.544932\n",
      "epoch 151; iter: 0; batch classifier loss: 0.447654; batch adversarial loss: 0.493081\n",
      "epoch 152; iter: 0; batch classifier loss: 0.363398; batch adversarial loss: 0.515958\n",
      "epoch 153; iter: 0; batch classifier loss: 0.368975; batch adversarial loss: 0.509170\n",
      "epoch 154; iter: 0; batch classifier loss: 0.424798; batch adversarial loss: 0.474699\n",
      "epoch 155; iter: 0; batch classifier loss: 0.346149; batch adversarial loss: 0.560840\n",
      "epoch 156; iter: 0; batch classifier loss: 0.380782; batch adversarial loss: 0.554763\n",
      "epoch 157; iter: 0; batch classifier loss: 0.361665; batch adversarial loss: 0.624784\n",
      "epoch 158; iter: 0; batch classifier loss: 0.392806; batch adversarial loss: 0.612848\n",
      "epoch 159; iter: 0; batch classifier loss: 0.360131; batch adversarial loss: 0.504392\n",
      "epoch 160; iter: 0; batch classifier loss: 0.414763; batch adversarial loss: 0.621714\n",
      "epoch 161; iter: 0; batch classifier loss: 0.330215; batch adversarial loss: 0.479644\n",
      "epoch 162; iter: 0; batch classifier loss: 0.325798; batch adversarial loss: 0.630744\n",
      "epoch 163; iter: 0; batch classifier loss: 0.401125; batch adversarial loss: 0.571025\n",
      "epoch 164; iter: 0; batch classifier loss: 0.351273; batch adversarial loss: 0.507381\n",
      "epoch 165; iter: 0; batch classifier loss: 0.294780; batch adversarial loss: 0.578565\n",
      "epoch 166; iter: 0; batch classifier loss: 0.428283; batch adversarial loss: 0.524630\n",
      "epoch 167; iter: 0; batch classifier loss: 0.399509; batch adversarial loss: 0.562183\n",
      "epoch 168; iter: 0; batch classifier loss: 0.340617; batch adversarial loss: 0.608135\n",
      "epoch 169; iter: 0; batch classifier loss: 0.378933; batch adversarial loss: 0.552338\n",
      "epoch 170; iter: 0; batch classifier loss: 0.360515; batch adversarial loss: 0.661295\n",
      "epoch 171; iter: 0; batch classifier loss: 0.333202; batch adversarial loss: 0.535666\n",
      "epoch 172; iter: 0; batch classifier loss: 0.362866; batch adversarial loss: 0.501622\n",
      "epoch 173; iter: 0; batch classifier loss: 0.252360; batch adversarial loss: 0.543325\n",
      "epoch 174; iter: 0; batch classifier loss: 0.340847; batch adversarial loss: 0.581502\n",
      "epoch 175; iter: 0; batch classifier loss: 0.379087; batch adversarial loss: 0.507717\n",
      "epoch 176; iter: 0; batch classifier loss: 0.382422; batch adversarial loss: 0.542648\n",
      "epoch 177; iter: 0; batch classifier loss: 0.423994; batch adversarial loss: 0.499259\n",
      "epoch 178; iter: 0; batch classifier loss: 0.271866; batch adversarial loss: 0.479659\n",
      "epoch 179; iter: 0; batch classifier loss: 0.392987; batch adversarial loss: 0.569894\n",
      "epoch 180; iter: 0; batch classifier loss: 0.301963; batch adversarial loss: 0.562760\n",
      "epoch 181; iter: 0; batch classifier loss: 0.397541; batch adversarial loss: 0.518610\n",
      "epoch 182; iter: 0; batch classifier loss: 0.402470; batch adversarial loss: 0.544775\n",
      "epoch 183; iter: 0; batch classifier loss: 0.310681; batch adversarial loss: 0.591882\n",
      "epoch 184; iter: 0; batch classifier loss: 0.352010; batch adversarial loss: 0.537147\n",
      "epoch 185; iter: 0; batch classifier loss: 0.308406; batch adversarial loss: 0.525200\n",
      "epoch 186; iter: 0; batch classifier loss: 0.355781; batch adversarial loss: 0.563825\n",
      "epoch 187; iter: 0; batch classifier loss: 0.291435; batch adversarial loss: 0.516114\n",
      "epoch 188; iter: 0; batch classifier loss: 0.318738; batch adversarial loss: 0.553367\n",
      "epoch 189; iter: 0; batch classifier loss: 0.340193; batch adversarial loss: 0.581071\n",
      "epoch 190; iter: 0; batch classifier loss: 0.398363; batch adversarial loss: 0.609618\n",
      "epoch 191; iter: 0; batch classifier loss: 0.397772; batch adversarial loss: 0.605733\n",
      "epoch 192; iter: 0; batch classifier loss: 0.242475; batch adversarial loss: 0.562884\n",
      "epoch 193; iter: 0; batch classifier loss: 0.332403; batch adversarial loss: 0.607390\n",
      "epoch 194; iter: 0; batch classifier loss: 0.290321; batch adversarial loss: 0.567906\n",
      "epoch 195; iter: 0; batch classifier loss: 0.357554; batch adversarial loss: 0.572369\n",
      "epoch 196; iter: 0; batch classifier loss: 0.313971; batch adversarial loss: 0.590500\n",
      "epoch 197; iter: 0; batch classifier loss: 0.340897; batch adversarial loss: 0.563762\n",
      "epoch 198; iter: 0; batch classifier loss: 0.323395; batch adversarial loss: 0.530411\n",
      "epoch 199; iter: 0; batch classifier loss: 0.482842; batch adversarial loss: 0.541179\n",
      "epoch 0; iter: 0; batch classifier loss: 0.728618; batch adversarial loss: 0.778523\n",
      "epoch 1; iter: 0; batch classifier loss: 0.720467; batch adversarial loss: 0.743072\n",
      "epoch 2; iter: 0; batch classifier loss: 0.716795; batch adversarial loss: 0.697041\n",
      "epoch 3; iter: 0; batch classifier loss: 0.583378; batch adversarial loss: 0.636036\n",
      "epoch 4; iter: 0; batch classifier loss: 0.550954; batch adversarial loss: 0.621800\n",
      "epoch 5; iter: 0; batch classifier loss: 0.605323; batch adversarial loss: 0.618855\n",
      "epoch 6; iter: 0; batch classifier loss: 0.555166; batch adversarial loss: 0.594669\n",
      "epoch 7; iter: 0; batch classifier loss: 0.530181; batch adversarial loss: 0.597264\n",
      "epoch 8; iter: 0; batch classifier loss: 0.521403; batch adversarial loss: 0.599545\n",
      "epoch 9; iter: 0; batch classifier loss: 0.546048; batch adversarial loss: 0.583557\n",
      "epoch 10; iter: 0; batch classifier loss: 0.524511; batch adversarial loss: 0.599143\n",
      "epoch 11; iter: 0; batch classifier loss: 0.514648; batch adversarial loss: 0.579905\n",
      "epoch 12; iter: 0; batch classifier loss: 0.510426; batch adversarial loss: 0.623885\n",
      "epoch 13; iter: 0; batch classifier loss: 0.522309; batch adversarial loss: 0.600391\n",
      "epoch 14; iter: 0; batch classifier loss: 0.542854; batch adversarial loss: 0.519259\n",
      "epoch 15; iter: 0; batch classifier loss: 0.513822; batch adversarial loss: 0.618602\n",
      "epoch 16; iter: 0; batch classifier loss: 0.505296; batch adversarial loss: 0.557567\n",
      "epoch 17; iter: 0; batch classifier loss: 0.496041; batch adversarial loss: 0.538391\n",
      "epoch 18; iter: 0; batch classifier loss: 0.520793; batch adversarial loss: 0.566633\n",
      "epoch 19; iter: 0; batch classifier loss: 0.498324; batch adversarial loss: 0.527957\n",
      "epoch 20; iter: 0; batch classifier loss: 0.515825; batch adversarial loss: 0.558908\n",
      "epoch 21; iter: 0; batch classifier loss: 0.537474; batch adversarial loss: 0.554957\n",
      "epoch 22; iter: 0; batch classifier loss: 0.471829; batch adversarial loss: 0.508484\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 23; iter: 0; batch classifier loss: 0.495107; batch adversarial loss: 0.507859\n",
      "epoch 24; iter: 0; batch classifier loss: 0.494542; batch adversarial loss: 0.492678\n",
      "epoch 25; iter: 0; batch classifier loss: 0.473601; batch adversarial loss: 0.562949\n",
      "epoch 26; iter: 0; batch classifier loss: 0.445489; batch adversarial loss: 0.580673\n",
      "epoch 27; iter: 0; batch classifier loss: 0.553153; batch adversarial loss: 0.513155\n",
      "epoch 28; iter: 0; batch classifier loss: 0.475461; batch adversarial loss: 0.582869\n",
      "epoch 29; iter: 0; batch classifier loss: 0.477008; batch adversarial loss: 0.513821\n",
      "epoch 30; iter: 0; batch classifier loss: 0.432651; batch adversarial loss: 0.601940\n",
      "epoch 31; iter: 0; batch classifier loss: 0.515834; batch adversarial loss: 0.494518\n",
      "epoch 32; iter: 0; batch classifier loss: 0.409606; batch adversarial loss: 0.629240\n",
      "epoch 33; iter: 0; batch classifier loss: 0.397447; batch adversarial loss: 0.589377\n",
      "epoch 34; iter: 0; batch classifier loss: 0.482570; batch adversarial loss: 0.596763\n",
      "epoch 35; iter: 0; batch classifier loss: 0.424466; batch adversarial loss: 0.579572\n",
      "epoch 36; iter: 0; batch classifier loss: 0.447571; batch adversarial loss: 0.581445\n",
      "epoch 37; iter: 0; batch classifier loss: 0.455862; batch adversarial loss: 0.566514\n",
      "epoch 38; iter: 0; batch classifier loss: 0.464352; batch adversarial loss: 0.580548\n",
      "epoch 39; iter: 0; batch classifier loss: 0.431515; batch adversarial loss: 0.569903\n",
      "epoch 40; iter: 0; batch classifier loss: 0.439055; batch adversarial loss: 0.597816\n",
      "epoch 41; iter: 0; batch classifier loss: 0.483216; batch adversarial loss: 0.524552\n",
      "epoch 42; iter: 0; batch classifier loss: 0.438580; batch adversarial loss: 0.553940\n",
      "epoch 43; iter: 0; batch classifier loss: 0.495568; batch adversarial loss: 0.462551\n",
      "epoch 44; iter: 0; batch classifier loss: 0.412341; batch adversarial loss: 0.522673\n",
      "epoch 45; iter: 0; batch classifier loss: 0.399407; batch adversarial loss: 0.517529\n",
      "epoch 46; iter: 0; batch classifier loss: 0.450721; batch adversarial loss: 0.540731\n",
      "epoch 47; iter: 0; batch classifier loss: 0.393931; batch adversarial loss: 0.546862\n",
      "epoch 48; iter: 0; batch classifier loss: 0.430984; batch adversarial loss: 0.562230\n",
      "epoch 49; iter: 0; batch classifier loss: 0.388911; batch adversarial loss: 0.624064\n",
      "epoch 50; iter: 0; batch classifier loss: 0.429397; batch adversarial loss: 0.501756\n",
      "epoch 51; iter: 0; batch classifier loss: 0.562198; batch adversarial loss: 0.483610\n",
      "epoch 52; iter: 0; batch classifier loss: 0.425037; batch adversarial loss: 0.571323\n",
      "epoch 53; iter: 0; batch classifier loss: 0.474943; batch adversarial loss: 0.579972\n",
      "epoch 54; iter: 0; batch classifier loss: 0.364757; batch adversarial loss: 0.580505\n",
      "epoch 55; iter: 0; batch classifier loss: 0.426005; batch adversarial loss: 0.526842\n",
      "epoch 56; iter: 0; batch classifier loss: 0.439798; batch adversarial loss: 0.634431\n",
      "epoch 57; iter: 0; batch classifier loss: 0.344677; batch adversarial loss: 0.517224\n",
      "epoch 58; iter: 0; batch classifier loss: 0.445964; batch adversarial loss: 0.553844\n",
      "epoch 59; iter: 0; batch classifier loss: 0.354325; batch adversarial loss: 0.526877\n",
      "epoch 60; iter: 0; batch classifier loss: 0.458761; batch adversarial loss: 0.471674\n",
      "epoch 61; iter: 0; batch classifier loss: 0.337650; batch adversarial loss: 0.581185\n",
      "epoch 62; iter: 0; batch classifier loss: 0.424244; batch adversarial loss: 0.544477\n",
      "epoch 63; iter: 0; batch classifier loss: 0.437526; batch adversarial loss: 0.544124\n",
      "epoch 64; iter: 0; batch classifier loss: 0.357860; batch adversarial loss: 0.599228\n",
      "epoch 65; iter: 0; batch classifier loss: 0.418043; batch adversarial loss: 0.535497\n",
      "epoch 66; iter: 0; batch classifier loss: 0.360924; batch adversarial loss: 0.535716\n",
      "epoch 67; iter: 0; batch classifier loss: 0.458993; batch adversarial loss: 0.553696\n",
      "epoch 68; iter: 0; batch classifier loss: 0.337889; batch adversarial loss: 0.617745\n",
      "epoch 69; iter: 0; batch classifier loss: 0.382598; batch adversarial loss: 0.571759\n",
      "epoch 70; iter: 0; batch classifier loss: 0.323229; batch adversarial loss: 0.581277\n",
      "epoch 71; iter: 0; batch classifier loss: 0.357044; batch adversarial loss: 0.663483\n",
      "epoch 72; iter: 0; batch classifier loss: 0.374465; batch adversarial loss: 0.499513\n",
      "epoch 73; iter: 0; batch classifier loss: 0.439784; batch adversarial loss: 0.544077\n",
      "epoch 74; iter: 0; batch classifier loss: 0.367462; batch adversarial loss: 0.470280\n",
      "epoch 75; iter: 0; batch classifier loss: 0.405784; batch adversarial loss: 0.525934\n",
      "epoch 76; iter: 0; batch classifier loss: 0.396151; batch adversarial loss: 0.544713\n",
      "epoch 77; iter: 0; batch classifier loss: 0.370925; batch adversarial loss: 0.553670\n",
      "epoch 78; iter: 0; batch classifier loss: 0.370329; batch adversarial loss: 0.616690\n",
      "epoch 79; iter: 0; batch classifier loss: 0.514768; batch adversarial loss: 0.526292\n",
      "epoch 80; iter: 0; batch classifier loss: 0.362295; batch adversarial loss: 0.590292\n",
      "epoch 81; iter: 0; batch classifier loss: 0.416032; batch adversarial loss: 0.563094\n",
      "epoch 82; iter: 0; batch classifier loss: 0.345735; batch adversarial loss: 0.534603\n",
      "epoch 83; iter: 0; batch classifier loss: 0.417178; batch adversarial loss: 0.597755\n",
      "epoch 84; iter: 0; batch classifier loss: 0.472183; batch adversarial loss: 0.598891\n",
      "epoch 85; iter: 0; batch classifier loss: 0.449474; batch adversarial loss: 0.570863\n",
      "epoch 86; iter: 0; batch classifier loss: 0.365104; batch adversarial loss: 0.525860\n",
      "epoch 87; iter: 0; batch classifier loss: 0.440923; batch adversarial loss: 0.570889\n",
      "epoch 88; iter: 0; batch classifier loss: 0.400043; batch adversarial loss: 0.480314\n",
      "epoch 89; iter: 0; batch classifier loss: 0.327046; batch adversarial loss: 0.617333\n",
      "epoch 90; iter: 0; batch classifier loss: 0.363496; batch adversarial loss: 0.562773\n",
      "epoch 91; iter: 0; batch classifier loss: 0.402227; batch adversarial loss: 0.507002\n",
      "epoch 92; iter: 0; batch classifier loss: 0.352772; batch adversarial loss: 0.526205\n",
      "epoch 93; iter: 0; batch classifier loss: 0.359041; batch adversarial loss: 0.571818\n",
      "epoch 94; iter: 0; batch classifier loss: 0.402081; batch adversarial loss: 0.535713\n",
      "epoch 95; iter: 0; batch classifier loss: 0.433347; batch adversarial loss: 0.571550\n",
      "epoch 96; iter: 0; batch classifier loss: 0.396831; batch adversarial loss: 0.553286\n",
      "epoch 97; iter: 0; batch classifier loss: 0.363496; batch adversarial loss: 0.599204\n",
      "epoch 98; iter: 0; batch classifier loss: 0.436121; batch adversarial loss: 0.526520\n",
      "epoch 99; iter: 0; batch classifier loss: 0.403619; batch adversarial loss: 0.544132\n",
      "epoch 100; iter: 0; batch classifier loss: 0.367043; batch adversarial loss: 0.508579\n",
      "epoch 101; iter: 0; batch classifier loss: 0.391234; batch adversarial loss: 0.554142\n",
      "epoch 102; iter: 0; batch classifier loss: 0.394439; batch adversarial loss: 0.525811\n",
      "epoch 103; iter: 0; batch classifier loss: 0.320572; batch adversarial loss: 0.500415\n",
      "epoch 104; iter: 0; batch classifier loss: 0.374256; batch adversarial loss: 0.607038\n",
      "epoch 105; iter: 0; batch classifier loss: 0.365043; batch adversarial loss: 0.590580\n",
      "epoch 106; iter: 0; batch classifier loss: 0.451379; batch adversarial loss: 0.561502\n",
      "epoch 107; iter: 0; batch classifier loss: 0.345212; batch adversarial loss: 0.544406\n",
      "epoch 108; iter: 0; batch classifier loss: 0.410426; batch adversarial loss: 0.481180\n",
      "epoch 109; iter: 0; batch classifier loss: 0.413384; batch adversarial loss: 0.525584\n",
      "epoch 110; iter: 0; batch classifier loss: 0.392975; batch adversarial loss: 0.554002\n",
      "epoch 111; iter: 0; batch classifier loss: 0.336749; batch adversarial loss: 0.526031\n",
      "epoch 112; iter: 0; batch classifier loss: 0.379546; batch adversarial loss: 0.580879\n",
      "epoch 113; iter: 0; batch classifier loss: 0.298790; batch adversarial loss: 0.554685\n",
      "epoch 114; iter: 0; batch classifier loss: 0.428774; batch adversarial loss: 0.617351\n",
      "epoch 115; iter: 0; batch classifier loss: 0.312492; batch adversarial loss: 0.517764\n",
      "epoch 116; iter: 0; batch classifier loss: 0.404413; batch adversarial loss: 0.571711\n",
      "epoch 117; iter: 0; batch classifier loss: 0.415730; batch adversarial loss: 0.590292\n",
      "epoch 118; iter: 0; batch classifier loss: 0.326262; batch adversarial loss: 0.571557\n",
      "epoch 119; iter: 0; batch classifier loss: 0.422215; batch adversarial loss: 0.562001\n",
      "epoch 120; iter: 0; batch classifier loss: 0.373830; batch adversarial loss: 0.563136\n",
      "epoch 121; iter: 0; batch classifier loss: 0.371962; batch adversarial loss: 0.544691\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 122; iter: 0; batch classifier loss: 0.322388; batch adversarial loss: 0.498841\n",
      "epoch 123; iter: 0; batch classifier loss: 0.343454; batch adversarial loss: 0.489920\n",
      "epoch 124; iter: 0; batch classifier loss: 0.395188; batch adversarial loss: 0.516528\n",
      "epoch 125; iter: 0; batch classifier loss: 0.346200; batch adversarial loss: 0.543634\n",
      "epoch 126; iter: 0; batch classifier loss: 0.424731; batch adversarial loss: 0.580032\n",
      "epoch 127; iter: 0; batch classifier loss: 0.381925; batch adversarial loss: 0.535097\n",
      "epoch 128; iter: 0; batch classifier loss: 0.426911; batch adversarial loss: 0.526180\n",
      "epoch 129; iter: 0; batch classifier loss: 0.431558; batch adversarial loss: 0.534846\n",
      "epoch 130; iter: 0; batch classifier loss: 0.322898; batch adversarial loss: 0.589710\n",
      "epoch 131; iter: 0; batch classifier loss: 0.394040; batch adversarial loss: 0.490387\n",
      "epoch 132; iter: 0; batch classifier loss: 0.401593; batch adversarial loss: 0.616275\n",
      "epoch 133; iter: 0; batch classifier loss: 0.373885; batch adversarial loss: 0.544133\n",
      "epoch 134; iter: 0; batch classifier loss: 0.366229; batch adversarial loss: 0.563116\n",
      "epoch 135; iter: 0; batch classifier loss: 0.368224; batch adversarial loss: 0.535798\n",
      "epoch 136; iter: 0; batch classifier loss: 0.352362; batch adversarial loss: 0.534593\n",
      "epoch 137; iter: 0; batch classifier loss: 0.369736; batch adversarial loss: 0.599275\n",
      "epoch 138; iter: 0; batch classifier loss: 0.343044; batch adversarial loss: 0.618415\n",
      "epoch 139; iter: 0; batch classifier loss: 0.424153; batch adversarial loss: 0.525168\n",
      "epoch 140; iter: 0; batch classifier loss: 0.324029; batch adversarial loss: 0.507318\n",
      "epoch 141; iter: 0; batch classifier loss: 0.345965; batch adversarial loss: 0.644306\n",
      "epoch 142; iter: 0; batch classifier loss: 0.308088; batch adversarial loss: 0.445088\n",
      "epoch 143; iter: 0; batch classifier loss: 0.500485; batch adversarial loss: 0.582051\n",
      "epoch 144; iter: 0; batch classifier loss: 0.396149; batch adversarial loss: 0.525881\n",
      "epoch 145; iter: 0; batch classifier loss: 0.326421; batch adversarial loss: 0.516827\n",
      "epoch 146; iter: 0; batch classifier loss: 0.309834; batch adversarial loss: 0.462662\n",
      "epoch 147; iter: 0; batch classifier loss: 0.337154; batch adversarial loss: 0.563041\n",
      "epoch 148; iter: 0; batch classifier loss: 0.357403; batch adversarial loss: 0.553416\n",
      "epoch 149; iter: 0; batch classifier loss: 0.330002; batch adversarial loss: 0.470639\n",
      "epoch 150; iter: 0; batch classifier loss: 0.400453; batch adversarial loss: 0.554003\n",
      "epoch 151; iter: 0; batch classifier loss: 0.366291; batch adversarial loss: 0.489279\n",
      "epoch 152; iter: 0; batch classifier loss: 0.365983; batch adversarial loss: 0.525552\n",
      "epoch 153; iter: 0; batch classifier loss: 0.236017; batch adversarial loss: 0.553805\n",
      "epoch 154; iter: 0; batch classifier loss: 0.372000; batch adversarial loss: 0.572301\n",
      "epoch 155; iter: 0; batch classifier loss: 0.334951; batch adversarial loss: 0.517332\n",
      "epoch 156; iter: 0; batch classifier loss: 0.333831; batch adversarial loss: 0.552557\n",
      "epoch 157; iter: 0; batch classifier loss: 0.362815; batch adversarial loss: 0.599480\n",
      "epoch 158; iter: 0; batch classifier loss: 0.373975; batch adversarial loss: 0.553513\n",
      "epoch 159; iter: 0; batch classifier loss: 0.375597; batch adversarial loss: 0.517322\n",
      "epoch 160; iter: 0; batch classifier loss: 0.401814; batch adversarial loss: 0.571281\n",
      "epoch 161; iter: 0; batch classifier loss: 0.298114; batch adversarial loss: 0.543384\n",
      "epoch 162; iter: 0; batch classifier loss: 0.421789; batch adversarial loss: 0.608326\n",
      "epoch 163; iter: 0; batch classifier loss: 0.340682; batch adversarial loss: 0.570217\n",
      "epoch 164; iter: 0; batch classifier loss: 0.387185; batch adversarial loss: 0.563427\n",
      "epoch 165; iter: 0; batch classifier loss: 0.300212; batch adversarial loss: 0.544510\n",
      "epoch 166; iter: 0; batch classifier loss: 0.294147; batch adversarial loss: 0.407504\n",
      "epoch 167; iter: 0; batch classifier loss: 0.292291; batch adversarial loss: 0.626165\n",
      "epoch 168; iter: 0; batch classifier loss: 0.314914; batch adversarial loss: 0.563573\n",
      "epoch 169; iter: 0; batch classifier loss: 0.407859; batch adversarial loss: 0.554439\n",
      "epoch 170; iter: 0; batch classifier loss: 0.368607; batch adversarial loss: 0.573039\n",
      "epoch 171; iter: 0; batch classifier loss: 0.349486; batch adversarial loss: 0.636584\n",
      "epoch 172; iter: 0; batch classifier loss: 0.289536; batch adversarial loss: 0.544133\n",
      "epoch 173; iter: 0; batch classifier loss: 0.327008; batch adversarial loss: 0.561933\n",
      "epoch 174; iter: 0; batch classifier loss: 0.346915; batch adversarial loss: 0.544128\n",
      "epoch 175; iter: 0; batch classifier loss: 0.350930; batch adversarial loss: 0.590369\n",
      "epoch 176; iter: 0; batch classifier loss: 0.377275; batch adversarial loss: 0.535915\n",
      "epoch 177; iter: 0; batch classifier loss: 0.378141; batch adversarial loss: 0.598191\n",
      "epoch 178; iter: 0; batch classifier loss: 0.328992; batch adversarial loss: 0.526044\n",
      "epoch 179; iter: 0; batch classifier loss: 0.388244; batch adversarial loss: 0.571212\n",
      "epoch 180; iter: 0; batch classifier loss: 0.469824; batch adversarial loss: 0.571843\n",
      "epoch 181; iter: 0; batch classifier loss: 0.401925; batch adversarial loss: 0.471526\n",
      "epoch 182; iter: 0; batch classifier loss: 0.339563; batch adversarial loss: 0.507931\n",
      "epoch 183; iter: 0; batch classifier loss: 0.408955; batch adversarial loss: 0.563968\n",
      "epoch 184; iter: 0; batch classifier loss: 0.393035; batch adversarial loss: 0.562245\n",
      "epoch 185; iter: 0; batch classifier loss: 0.368472; batch adversarial loss: 0.554215\n",
      "epoch 186; iter: 0; batch classifier loss: 0.266949; batch adversarial loss: 0.571525\n",
      "epoch 187; iter: 0; batch classifier loss: 0.383540; batch adversarial loss: 0.580750\n",
      "epoch 188; iter: 0; batch classifier loss: 0.357957; batch adversarial loss: 0.554415\n",
      "epoch 189; iter: 0; batch classifier loss: 0.414539; batch adversarial loss: 0.498908\n",
      "epoch 190; iter: 0; batch classifier loss: 0.345084; batch adversarial loss: 0.589916\n",
      "epoch 191; iter: 0; batch classifier loss: 0.288734; batch adversarial loss: 0.534871\n",
      "epoch 192; iter: 0; batch classifier loss: 0.374107; batch adversarial loss: 0.607792\n",
      "epoch 193; iter: 0; batch classifier loss: 0.360650; batch adversarial loss: 0.534840\n",
      "epoch 194; iter: 0; batch classifier loss: 0.363334; batch adversarial loss: 0.581461\n",
      "epoch 195; iter: 0; batch classifier loss: 0.316681; batch adversarial loss: 0.571405\n",
      "epoch 196; iter: 0; batch classifier loss: 0.334546; batch adversarial loss: 0.526952\n",
      "epoch 197; iter: 0; batch classifier loss: 0.390439; batch adversarial loss: 0.517951\n",
      "epoch 198; iter: 0; batch classifier loss: 0.391654; batch adversarial loss: 0.589893\n",
      "epoch 199; iter: 0; batch classifier loss: 0.330646; batch adversarial loss: 0.517479\n",
      "epoch 0; iter: 0; batch classifier loss: 0.637075; batch adversarial loss: 0.574347\n",
      "epoch 1; iter: 0; batch classifier loss: 0.595885; batch adversarial loss: 0.612967\n",
      "epoch 2; iter: 0; batch classifier loss: 0.621568; batch adversarial loss: 0.635254\n",
      "epoch 3; iter: 0; batch classifier loss: 0.514820; batch adversarial loss: 0.660388\n",
      "epoch 4; iter: 0; batch classifier loss: 0.585362; batch adversarial loss: 0.663572\n",
      "epoch 5; iter: 0; batch classifier loss: 0.511980; batch adversarial loss: 0.590171\n",
      "epoch 6; iter: 0; batch classifier loss: 0.575394; batch adversarial loss: 0.675271\n",
      "epoch 7; iter: 0; batch classifier loss: 0.608566; batch adversarial loss: 0.599864\n",
      "epoch 8; iter: 0; batch classifier loss: 0.499704; batch adversarial loss: 0.645817\n",
      "epoch 9; iter: 0; batch classifier loss: 0.536773; batch adversarial loss: 0.556963\n",
      "epoch 10; iter: 0; batch classifier loss: 0.634986; batch adversarial loss: 0.610773\n",
      "epoch 11; iter: 0; batch classifier loss: 0.640736; batch adversarial loss: 0.615477\n",
      "epoch 12; iter: 0; batch classifier loss: 0.504156; batch adversarial loss: 0.587517\n",
      "epoch 13; iter: 0; batch classifier loss: 0.538842; batch adversarial loss: 0.596676\n",
      "epoch 14; iter: 0; batch classifier loss: 0.606326; batch adversarial loss: 0.537427\n",
      "epoch 15; iter: 0; batch classifier loss: 0.533046; batch adversarial loss: 0.578328\n",
      "epoch 16; iter: 0; batch classifier loss: 0.560189; batch adversarial loss: 0.584955\n",
      "epoch 17; iter: 0; batch classifier loss: 0.500900; batch adversarial loss: 0.549793\n",
      "epoch 18; iter: 0; batch classifier loss: 0.488976; batch adversarial loss: 0.587470\n",
      "epoch 19; iter: 0; batch classifier loss: 0.487932; batch adversarial loss: 0.586939\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20; iter: 0; batch classifier loss: 0.548676; batch adversarial loss: 0.659302\n",
      "epoch 21; iter: 0; batch classifier loss: 0.485987; batch adversarial loss: 0.467770\n",
      "epoch 22; iter: 0; batch classifier loss: 0.480225; batch adversarial loss: 0.563384\n",
      "epoch 23; iter: 0; batch classifier loss: 0.547764; batch adversarial loss: 0.514988\n",
      "epoch 24; iter: 0; batch classifier loss: 0.401840; batch adversarial loss: 0.591254\n",
      "epoch 25; iter: 0; batch classifier loss: 0.504118; batch adversarial loss: 0.550036\n",
      "epoch 26; iter: 0; batch classifier loss: 0.485356; batch adversarial loss: 0.515646\n",
      "epoch 27; iter: 0; batch classifier loss: 0.466447; batch adversarial loss: 0.572669\n",
      "epoch 28; iter: 0; batch classifier loss: 0.468025; batch adversarial loss: 0.569252\n",
      "epoch 29; iter: 0; batch classifier loss: 0.363013; batch adversarial loss: 0.537278\n",
      "epoch 30; iter: 0; batch classifier loss: 0.482567; batch adversarial loss: 0.597571\n",
      "epoch 31; iter: 0; batch classifier loss: 0.495118; batch adversarial loss: 0.477295\n",
      "epoch 32; iter: 0; batch classifier loss: 0.488038; batch adversarial loss: 0.521354\n",
      "epoch 33; iter: 0; batch classifier loss: 0.423070; batch adversarial loss: 0.585166\n",
      "epoch 34; iter: 0; batch classifier loss: 0.506043; batch adversarial loss: 0.517578\n",
      "epoch 35; iter: 0; batch classifier loss: 0.431018; batch adversarial loss: 0.529529\n",
      "epoch 36; iter: 0; batch classifier loss: 0.502377; batch adversarial loss: 0.550382\n",
      "epoch 37; iter: 0; batch classifier loss: 0.481317; batch adversarial loss: 0.617236\n",
      "epoch 38; iter: 0; batch classifier loss: 0.390173; batch adversarial loss: 0.498814\n",
      "epoch 39; iter: 0; batch classifier loss: 0.432367; batch adversarial loss: 0.544846\n",
      "epoch 40; iter: 0; batch classifier loss: 0.457822; batch adversarial loss: 0.534724\n",
      "epoch 41; iter: 0; batch classifier loss: 0.467457; batch adversarial loss: 0.581186\n",
      "epoch 42; iter: 0; batch classifier loss: 0.427223; batch adversarial loss: 0.580367\n",
      "epoch 43; iter: 0; batch classifier loss: 0.456446; batch adversarial loss: 0.526819\n",
      "epoch 44; iter: 0; batch classifier loss: 0.470763; batch adversarial loss: 0.553171\n",
      "epoch 45; iter: 0; batch classifier loss: 0.413146; batch adversarial loss: 0.562464\n",
      "epoch 46; iter: 0; batch classifier loss: 0.501712; batch adversarial loss: 0.507712\n",
      "epoch 47; iter: 0; batch classifier loss: 0.371207; batch adversarial loss: 0.525501\n",
      "epoch 48; iter: 0; batch classifier loss: 0.418355; batch adversarial loss: 0.562182\n",
      "epoch 49; iter: 0; batch classifier loss: 0.583900; batch adversarial loss: 0.545500\n",
      "epoch 50; iter: 0; batch classifier loss: 0.375642; batch adversarial loss: 0.526469\n",
      "epoch 51; iter: 0; batch classifier loss: 0.468079; batch adversarial loss: 0.563730\n",
      "epoch 52; iter: 0; batch classifier loss: 0.466500; batch adversarial loss: 0.536178\n",
      "epoch 53; iter: 0; batch classifier loss: 0.427198; batch adversarial loss: 0.536071\n",
      "epoch 54; iter: 0; batch classifier loss: 0.435380; batch adversarial loss: 0.535401\n",
      "epoch 55; iter: 0; batch classifier loss: 0.434103; batch adversarial loss: 0.572196\n",
      "epoch 56; iter: 0; batch classifier loss: 0.454779; batch adversarial loss: 0.498029\n",
      "epoch 57; iter: 0; batch classifier loss: 0.484023; batch adversarial loss: 0.544990\n",
      "epoch 58; iter: 0; batch classifier loss: 0.360908; batch adversarial loss: 0.544704\n",
      "epoch 59; iter: 0; batch classifier loss: 0.459943; batch adversarial loss: 0.525714\n",
      "epoch 60; iter: 0; batch classifier loss: 0.340917; batch adversarial loss: 0.554076\n",
      "epoch 61; iter: 0; batch classifier loss: 0.433006; batch adversarial loss: 0.488076\n",
      "epoch 62; iter: 0; batch classifier loss: 0.421153; batch adversarial loss: 0.487196\n",
      "epoch 63; iter: 0; batch classifier loss: 0.409483; batch adversarial loss: 0.572188\n",
      "epoch 64; iter: 0; batch classifier loss: 0.419127; batch adversarial loss: 0.516247\n",
      "epoch 65; iter: 0; batch classifier loss: 0.467186; batch adversarial loss: 0.507082\n",
      "epoch 66; iter: 0; batch classifier loss: 0.409149; batch adversarial loss: 0.470641\n",
      "epoch 67; iter: 0; batch classifier loss: 0.517290; batch adversarial loss: 0.544604\n",
      "epoch 68; iter: 0; batch classifier loss: 0.421475; batch adversarial loss: 0.609646\n",
      "epoch 69; iter: 0; batch classifier loss: 0.384494; batch adversarial loss: 0.488119\n",
      "epoch 70; iter: 0; batch classifier loss: 0.446454; batch adversarial loss: 0.496701\n",
      "epoch 71; iter: 0; batch classifier loss: 0.357781; batch adversarial loss: 0.507743\n",
      "epoch 72; iter: 0; batch classifier loss: 0.502543; batch adversarial loss: 0.554680\n",
      "epoch 73; iter: 0; batch classifier loss: 0.412027; batch adversarial loss: 0.646499\n",
      "epoch 74; iter: 0; batch classifier loss: 0.432549; batch adversarial loss: 0.527113\n",
      "epoch 75; iter: 0; batch classifier loss: 0.431280; batch adversarial loss: 0.554442\n",
      "epoch 76; iter: 0; batch classifier loss: 0.422419; batch adversarial loss: 0.459962\n",
      "epoch 77; iter: 0; batch classifier loss: 0.407329; batch adversarial loss: 0.572276\n",
      "epoch 78; iter: 0; batch classifier loss: 0.427406; batch adversarial loss: 0.507008\n",
      "epoch 79; iter: 0; batch classifier loss: 0.382774; batch adversarial loss: 0.572354\n",
      "epoch 80; iter: 0; batch classifier loss: 0.345539; batch adversarial loss: 0.525410\n",
      "epoch 81; iter: 0; batch classifier loss: 0.418600; batch adversarial loss: 0.534433\n",
      "epoch 82; iter: 0; batch classifier loss: 0.430278; batch adversarial loss: 0.479705\n",
      "epoch 83; iter: 0; batch classifier loss: 0.424437; batch adversarial loss: 0.636617\n",
      "epoch 84; iter: 0; batch classifier loss: 0.366669; batch adversarial loss: 0.552299\n",
      "epoch 85; iter: 0; batch classifier loss: 0.452519; batch adversarial loss: 0.469507\n",
      "epoch 86; iter: 0; batch classifier loss: 0.332781; batch adversarial loss: 0.544552\n",
      "epoch 87; iter: 0; batch classifier loss: 0.326130; batch adversarial loss: 0.591535\n",
      "epoch 88; iter: 0; batch classifier loss: 0.345041; batch adversarial loss: 0.552780\n",
      "epoch 89; iter: 0; batch classifier loss: 0.406853; batch adversarial loss: 0.478623\n",
      "epoch 90; iter: 0; batch classifier loss: 0.427271; batch adversarial loss: 0.497710\n",
      "epoch 91; iter: 0; batch classifier loss: 0.450117; batch adversarial loss: 0.592725\n",
      "epoch 92; iter: 0; batch classifier loss: 0.351190; batch adversarial loss: 0.618265\n",
      "epoch 93; iter: 0; batch classifier loss: 0.366047; batch adversarial loss: 0.562967\n",
      "epoch 94; iter: 0; batch classifier loss: 0.347740; batch adversarial loss: 0.553492\n",
      "epoch 95; iter: 0; batch classifier loss: 0.441521; batch adversarial loss: 0.516089\n",
      "epoch 96; iter: 0; batch classifier loss: 0.382494; batch adversarial loss: 0.600786\n",
      "epoch 97; iter: 0; batch classifier loss: 0.399038; batch adversarial loss: 0.526408\n",
      "epoch 98; iter: 0; batch classifier loss: 0.397450; batch adversarial loss: 0.506937\n",
      "epoch 99; iter: 0; batch classifier loss: 0.361805; batch adversarial loss: 0.450373\n",
      "epoch 100; iter: 0; batch classifier loss: 0.316306; batch adversarial loss: 0.581373\n",
      "epoch 101; iter: 0; batch classifier loss: 0.417324; batch adversarial loss: 0.525474\n",
      "epoch 102; iter: 0; batch classifier loss: 0.320207; batch adversarial loss: 0.545497\n",
      "epoch 103; iter: 0; batch classifier loss: 0.447595; batch adversarial loss: 0.592408\n",
      "epoch 104; iter: 0; batch classifier loss: 0.344257; batch adversarial loss: 0.480072\n",
      "epoch 105; iter: 0; batch classifier loss: 0.407775; batch adversarial loss: 0.524559\n",
      "epoch 106; iter: 0; batch classifier loss: 0.359670; batch adversarial loss: 0.506319\n",
      "epoch 107; iter: 0; batch classifier loss: 0.453703; batch adversarial loss: 0.636982\n",
      "epoch 108; iter: 0; batch classifier loss: 0.433456; batch adversarial loss: 0.552364\n",
      "epoch 109; iter: 0; batch classifier loss: 0.409355; batch adversarial loss: 0.526329\n",
      "epoch 110; iter: 0; batch classifier loss: 0.371783; batch adversarial loss: 0.507448\n",
      "epoch 111; iter: 0; batch classifier loss: 0.399807; batch adversarial loss: 0.573719\n",
      "epoch 112; iter: 0; batch classifier loss: 0.434633; batch adversarial loss: 0.536215\n",
      "epoch 113; iter: 0; batch classifier loss: 0.374874; batch adversarial loss: 0.554016\n",
      "epoch 114; iter: 0; batch classifier loss: 0.426439; batch adversarial loss: 0.581849\n",
      "epoch 115; iter: 0; batch classifier loss: 0.331382; batch adversarial loss: 0.543974\n",
      "epoch 116; iter: 0; batch classifier loss: 0.462970; batch adversarial loss: 0.534314\n",
      "epoch 117; iter: 0; batch classifier loss: 0.383607; batch adversarial loss: 0.490247\n",
      "epoch 118; iter: 0; batch classifier loss: 0.328046; batch adversarial loss: 0.508481\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 119; iter: 0; batch classifier loss: 0.359434; batch adversarial loss: 0.561197\n",
      "epoch 120; iter: 0; batch classifier loss: 0.420409; batch adversarial loss: 0.560986\n",
      "epoch 121; iter: 0; batch classifier loss: 0.423279; batch adversarial loss: 0.489336\n",
      "epoch 122; iter: 0; batch classifier loss: 0.433219; batch adversarial loss: 0.506120\n",
      "epoch 123; iter: 0; batch classifier loss: 0.421512; batch adversarial loss: 0.545658\n",
      "epoch 124; iter: 0; batch classifier loss: 0.442675; batch adversarial loss: 0.572494\n",
      "epoch 125; iter: 0; batch classifier loss: 0.321973; batch adversarial loss: 0.487304\n",
      "epoch 126; iter: 0; batch classifier loss: 0.422629; batch adversarial loss: 0.573211\n",
      "epoch 127; iter: 0; batch classifier loss: 0.269919; batch adversarial loss: 0.592560\n",
      "epoch 128; iter: 0; batch classifier loss: 0.387574; batch adversarial loss: 0.532866\n",
      "epoch 129; iter: 0; batch classifier loss: 0.340713; batch adversarial loss: 0.609499\n",
      "epoch 130; iter: 0; batch classifier loss: 0.455923; batch adversarial loss: 0.536557\n",
      "epoch 131; iter: 0; batch classifier loss: 0.319779; batch adversarial loss: 0.572309\n",
      "epoch 132; iter: 0; batch classifier loss: 0.459116; batch adversarial loss: 0.592099\n",
      "epoch 133; iter: 0; batch classifier loss: 0.351725; batch adversarial loss: 0.506865\n",
      "epoch 134; iter: 0; batch classifier loss: 0.349592; batch adversarial loss: 0.488119\n",
      "epoch 135; iter: 0; batch classifier loss: 0.386997; batch adversarial loss: 0.590798\n",
      "epoch 136; iter: 0; batch classifier loss: 0.379462; batch adversarial loss: 0.543828\n",
      "epoch 137; iter: 0; batch classifier loss: 0.334075; batch adversarial loss: 0.599347\n",
      "epoch 138; iter: 0; batch classifier loss: 0.341541; batch adversarial loss: 0.526568\n",
      "epoch 139; iter: 0; batch classifier loss: 0.367379; batch adversarial loss: 0.527097\n",
      "epoch 140; iter: 0; batch classifier loss: 0.434108; batch adversarial loss: 0.562164\n",
      "epoch 141; iter: 0; batch classifier loss: 0.452855; batch adversarial loss: 0.516696\n",
      "epoch 142; iter: 0; batch classifier loss: 0.359316; batch adversarial loss: 0.554246\n",
      "epoch 143; iter: 0; batch classifier loss: 0.367851; batch adversarial loss: 0.572010\n",
      "epoch 144; iter: 0; batch classifier loss: 0.458743; batch adversarial loss: 0.581424\n",
      "epoch 145; iter: 0; batch classifier loss: 0.393737; batch adversarial loss: 0.563300\n",
      "epoch 146; iter: 0; batch classifier loss: 0.371347; batch adversarial loss: 0.533261\n",
      "epoch 147; iter: 0; batch classifier loss: 0.376495; batch adversarial loss: 0.554758\n",
      "epoch 148; iter: 0; batch classifier loss: 0.412462; batch adversarial loss: 0.628623\n",
      "epoch 149; iter: 0; batch classifier loss: 0.351299; batch adversarial loss: 0.525605\n",
      "epoch 150; iter: 0; batch classifier loss: 0.376189; batch adversarial loss: 0.524942\n",
      "epoch 151; iter: 0; batch classifier loss: 0.354074; batch adversarial loss: 0.525847\n",
      "epoch 152; iter: 0; batch classifier loss: 0.416304; batch adversarial loss: 0.524951\n",
      "epoch 153; iter: 0; batch classifier loss: 0.357627; batch adversarial loss: 0.534751\n",
      "epoch 154; iter: 0; batch classifier loss: 0.338855; batch adversarial loss: 0.628513\n",
      "epoch 155; iter: 0; batch classifier loss: 0.343002; batch adversarial loss: 0.498087\n",
      "epoch 156; iter: 0; batch classifier loss: 0.371923; batch adversarial loss: 0.515058\n",
      "epoch 157; iter: 0; batch classifier loss: 0.285019; batch adversarial loss: 0.599451\n",
      "epoch 158; iter: 0; batch classifier loss: 0.292065; batch adversarial loss: 0.534162\n",
      "epoch 159; iter: 0; batch classifier loss: 0.342005; batch adversarial loss: 0.534351\n",
      "epoch 160; iter: 0; batch classifier loss: 0.319144; batch adversarial loss: 0.600424\n",
      "epoch 161; iter: 0; batch classifier loss: 0.337283; batch adversarial loss: 0.525773\n",
      "epoch 162; iter: 0; batch classifier loss: 0.316077; batch adversarial loss: 0.564594\n",
      "epoch 163; iter: 0; batch classifier loss: 0.404258; batch adversarial loss: 0.506096\n",
      "epoch 164; iter: 0; batch classifier loss: 0.400180; batch adversarial loss: 0.553033\n",
      "epoch 165; iter: 0; batch classifier loss: 0.362086; batch adversarial loss: 0.572506\n",
      "epoch 166; iter: 0; batch classifier loss: 0.339608; batch adversarial loss: 0.525585\n",
      "epoch 167; iter: 0; batch classifier loss: 0.291312; batch adversarial loss: 0.573819\n",
      "epoch 168; iter: 0; batch classifier loss: 0.451222; batch adversarial loss: 0.619424\n",
      "epoch 169; iter: 0; batch classifier loss: 0.378488; batch adversarial loss: 0.507637\n",
      "epoch 170; iter: 0; batch classifier loss: 0.352695; batch adversarial loss: 0.468515\n",
      "epoch 171; iter: 0; batch classifier loss: 0.342138; batch adversarial loss: 0.581427\n",
      "epoch 172; iter: 0; batch classifier loss: 0.409267; batch adversarial loss: 0.497076\n",
      "epoch 173; iter: 0; batch classifier loss: 0.425365; batch adversarial loss: 0.572787\n",
      "epoch 174; iter: 0; batch classifier loss: 0.364954; batch adversarial loss: 0.498000\n",
      "epoch 175; iter: 0; batch classifier loss: 0.357000; batch adversarial loss: 0.620218\n",
      "epoch 176; iter: 0; batch classifier loss: 0.344419; batch adversarial loss: 0.562324\n",
      "epoch 177; iter: 0; batch classifier loss: 0.340350; batch adversarial loss: 0.609197\n",
      "epoch 178; iter: 0; batch classifier loss: 0.356959; batch adversarial loss: 0.508715\n",
      "epoch 179; iter: 0; batch classifier loss: 0.429172; batch adversarial loss: 0.598778\n",
      "epoch 180; iter: 0; batch classifier loss: 0.297138; batch adversarial loss: 0.534397\n",
      "epoch 181; iter: 0; batch classifier loss: 0.376209; batch adversarial loss: 0.599808\n",
      "epoch 182; iter: 0; batch classifier loss: 0.360414; batch adversarial loss: 0.487615\n",
      "epoch 183; iter: 0; batch classifier loss: 0.387446; batch adversarial loss: 0.526281\n",
      "epoch 184; iter: 0; batch classifier loss: 0.377400; batch adversarial loss: 0.535512\n",
      "epoch 185; iter: 0; batch classifier loss: 0.369166; batch adversarial loss: 0.675839\n",
      "epoch 186; iter: 0; batch classifier loss: 0.389553; batch adversarial loss: 0.572430\n",
      "epoch 187; iter: 0; batch classifier loss: 0.244403; batch adversarial loss: 0.628770\n",
      "epoch 188; iter: 0; batch classifier loss: 0.347883; batch adversarial loss: 0.676022\n",
      "epoch 189; iter: 0; batch classifier loss: 0.345102; batch adversarial loss: 0.600737\n",
      "epoch 190; iter: 0; batch classifier loss: 0.425532; batch adversarial loss: 0.566054\n",
      "epoch 191; iter: 0; batch classifier loss: 0.281870; batch adversarial loss: 0.499875\n",
      "epoch 192; iter: 0; batch classifier loss: 0.353550; batch adversarial loss: 0.555167\n",
      "epoch 193; iter: 0; batch classifier loss: 0.325014; batch adversarial loss: 0.581851\n",
      "epoch 194; iter: 0; batch classifier loss: 0.306472; batch adversarial loss: 0.507124\n",
      "epoch 195; iter: 0; batch classifier loss: 0.438966; batch adversarial loss: 0.497873\n",
      "epoch 196; iter: 0; batch classifier loss: 0.326531; batch adversarial loss: 0.554284\n",
      "epoch 197; iter: 0; batch classifier loss: 0.317334; batch adversarial loss: 0.553825\n",
      "epoch 198; iter: 0; batch classifier loss: 0.372263; batch adversarial loss: 0.535347\n",
      "epoch 199; iter: 0; batch classifier loss: 0.362306; batch adversarial loss: 0.590653\n",
      "epoch 0; iter: 0; batch classifier loss: 0.699300; batch adversarial loss: 0.558195\n",
      "epoch 1; iter: 0; batch classifier loss: 0.575847; batch adversarial loss: 0.623391\n",
      "epoch 2; iter: 0; batch classifier loss: 0.595531; batch adversarial loss: 0.650845\n",
      "epoch 3; iter: 0; batch classifier loss: 0.548593; batch adversarial loss: 0.638556\n",
      "epoch 4; iter: 0; batch classifier loss: 0.544828; batch adversarial loss: 0.605038\n",
      "epoch 5; iter: 0; batch classifier loss: 0.564592; batch adversarial loss: 0.649499\n",
      "epoch 6; iter: 0; batch classifier loss: 0.578140; batch adversarial loss: 0.580976\n",
      "epoch 7; iter: 0; batch classifier loss: 0.542584; batch adversarial loss: 0.689433\n",
      "epoch 8; iter: 0; batch classifier loss: 0.516188; batch adversarial loss: 0.605504\n",
      "epoch 9; iter: 0; batch classifier loss: 0.517225; batch adversarial loss: 0.578472\n",
      "epoch 10; iter: 0; batch classifier loss: 0.581054; batch adversarial loss: 0.639035\n",
      "epoch 11; iter: 0; batch classifier loss: 0.556499; batch adversarial loss: 0.569772\n",
      "epoch 12; iter: 0; batch classifier loss: 0.488366; batch adversarial loss: 0.587374\n",
      "epoch 13; iter: 0; batch classifier loss: 0.455294; batch adversarial loss: 0.591650\n",
      "epoch 14; iter: 0; batch classifier loss: 0.515361; batch adversarial loss: 0.534448\n",
      "epoch 15; iter: 0; batch classifier loss: 0.497620; batch adversarial loss: 0.545087\n",
      "epoch 16; iter: 0; batch classifier loss: 0.531753; batch adversarial loss: 0.559877\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 17; iter: 0; batch classifier loss: 0.527523; batch adversarial loss: 0.592812\n",
      "epoch 18; iter: 0; batch classifier loss: 0.559326; batch adversarial loss: 0.554185\n",
      "epoch 19; iter: 0; batch classifier loss: 0.406397; batch adversarial loss: 0.497772\n",
      "epoch 20; iter: 0; batch classifier loss: 0.516785; batch adversarial loss: 0.513985\n",
      "epoch 21; iter: 0; batch classifier loss: 0.499092; batch adversarial loss: 0.553365\n",
      "epoch 22; iter: 0; batch classifier loss: 0.470138; batch adversarial loss: 0.513190\n",
      "epoch 23; iter: 0; batch classifier loss: 0.553280; batch adversarial loss: 0.580272\n",
      "epoch 24; iter: 0; batch classifier loss: 0.474692; batch adversarial loss: 0.544696\n",
      "epoch 25; iter: 0; batch classifier loss: 0.440117; batch adversarial loss: 0.559970\n",
      "epoch 26; iter: 0; batch classifier loss: 0.460546; batch adversarial loss: 0.518415\n",
      "epoch 27; iter: 0; batch classifier loss: 0.463166; batch adversarial loss: 0.566110\n",
      "epoch 28; iter: 0; batch classifier loss: 0.394835; batch adversarial loss: 0.530491\n",
      "epoch 29; iter: 0; batch classifier loss: 0.520994; batch adversarial loss: 0.555908\n",
      "epoch 30; iter: 0; batch classifier loss: 0.491478; batch adversarial loss: 0.557502\n",
      "epoch 31; iter: 0; batch classifier loss: 0.489819; batch adversarial loss: 0.571509\n",
      "epoch 32; iter: 0; batch classifier loss: 0.438313; batch adversarial loss: 0.579408\n",
      "epoch 33; iter: 0; batch classifier loss: 0.482998; batch adversarial loss: 0.537361\n",
      "epoch 34; iter: 0; batch classifier loss: 0.490080; batch adversarial loss: 0.527520\n",
      "epoch 35; iter: 0; batch classifier loss: 0.478704; batch adversarial loss: 0.544920\n",
      "epoch 36; iter: 0; batch classifier loss: 0.481846; batch adversarial loss: 0.499922\n",
      "epoch 37; iter: 0; batch classifier loss: 0.456998; batch adversarial loss: 0.535614\n",
      "epoch 38; iter: 0; batch classifier loss: 0.449512; batch adversarial loss: 0.572038\n",
      "epoch 39; iter: 0; batch classifier loss: 0.463751; batch adversarial loss: 0.498814\n",
      "epoch 40; iter: 0; batch classifier loss: 0.530505; batch adversarial loss: 0.525926\n",
      "epoch 41; iter: 0; batch classifier loss: 0.500367; batch adversarial loss: 0.507576\n",
      "epoch 42; iter: 0; batch classifier loss: 0.518930; batch adversarial loss: 0.516468\n",
      "epoch 43; iter: 0; batch classifier loss: 0.482434; batch adversarial loss: 0.534089\n",
      "epoch 44; iter: 0; batch classifier loss: 0.414712; batch adversarial loss: 0.516776\n",
      "epoch 45; iter: 0; batch classifier loss: 0.418692; batch adversarial loss: 0.512551\n",
      "epoch 46; iter: 0; batch classifier loss: 0.502590; batch adversarial loss: 0.571060\n",
      "epoch 47; iter: 0; batch classifier loss: 0.465629; batch adversarial loss: 0.590458\n",
      "epoch 48; iter: 0; batch classifier loss: 0.387372; batch adversarial loss: 0.510144\n",
      "epoch 49; iter: 0; batch classifier loss: 0.394018; batch adversarial loss: 0.519045\n",
      "epoch 50; iter: 0; batch classifier loss: 0.494564; batch adversarial loss: 0.535244\n",
      "epoch 51; iter: 0; batch classifier loss: 0.416266; batch adversarial loss: 0.477035\n",
      "epoch 52; iter: 0; batch classifier loss: 0.509525; batch adversarial loss: 0.457654\n",
      "epoch 53; iter: 0; batch classifier loss: 0.493681; batch adversarial loss: 0.510103\n",
      "epoch 54; iter: 0; batch classifier loss: 0.431514; batch adversarial loss: 0.585362\n",
      "epoch 55; iter: 0; batch classifier loss: 0.511683; batch adversarial loss: 0.546059\n",
      "epoch 56; iter: 0; batch classifier loss: 0.451194; batch adversarial loss: 0.527152\n",
      "epoch 57; iter: 0; batch classifier loss: 0.461619; batch adversarial loss: 0.516281\n",
      "epoch 58; iter: 0; batch classifier loss: 0.412688; batch adversarial loss: 0.574404\n",
      "epoch 59; iter: 0; batch classifier loss: 0.398282; batch adversarial loss: 0.527655\n",
      "epoch 60; iter: 0; batch classifier loss: 0.513872; batch adversarial loss: 0.546259\n",
      "epoch 61; iter: 0; batch classifier loss: 0.366043; batch adversarial loss: 0.448940\n",
      "epoch 62; iter: 0; batch classifier loss: 0.451379; batch adversarial loss: 0.572258\n",
      "epoch 63; iter: 0; batch classifier loss: 0.392564; batch adversarial loss: 0.581075\n",
      "epoch 64; iter: 0; batch classifier loss: 0.436849; batch adversarial loss: 0.606850\n",
      "epoch 65; iter: 0; batch classifier loss: 0.393807; batch adversarial loss: 0.607761\n",
      "epoch 66; iter: 0; batch classifier loss: 0.396307; batch adversarial loss: 0.535514\n",
      "epoch 67; iter: 0; batch classifier loss: 0.410902; batch adversarial loss: 0.645149\n",
      "epoch 68; iter: 0; batch classifier loss: 0.428949; batch adversarial loss: 0.562909\n",
      "epoch 69; iter: 0; batch classifier loss: 0.414153; batch adversarial loss: 0.479995\n",
      "epoch 70; iter: 0; batch classifier loss: 0.383425; batch adversarial loss: 0.544449\n",
      "epoch 71; iter: 0; batch classifier loss: 0.390467; batch adversarial loss: 0.516740\n",
      "epoch 72; iter: 0; batch classifier loss: 0.416620; batch adversarial loss: 0.507731\n",
      "epoch 73; iter: 0; batch classifier loss: 0.438527; batch adversarial loss: 0.572406\n",
      "epoch 74; iter: 0; batch classifier loss: 0.331518; batch adversarial loss: 0.562717\n",
      "epoch 75; iter: 0; batch classifier loss: 0.380584; batch adversarial loss: 0.553903\n",
      "epoch 76; iter: 0; batch classifier loss: 0.354799; batch adversarial loss: 0.619172\n",
      "epoch 77; iter: 0; batch classifier loss: 0.408333; batch adversarial loss: 0.535791\n",
      "epoch 78; iter: 0; batch classifier loss: 0.457962; batch adversarial loss: 0.516214\n",
      "epoch 79; iter: 0; batch classifier loss: 0.586544; batch adversarial loss: 0.516835\n",
      "epoch 80; iter: 0; batch classifier loss: 0.422158; batch adversarial loss: 0.515810\n",
      "epoch 81; iter: 0; batch classifier loss: 0.356228; batch adversarial loss: 0.562900\n",
      "epoch 82; iter: 0; batch classifier loss: 0.367821; batch adversarial loss: 0.535311\n",
      "epoch 83; iter: 0; batch classifier loss: 0.402362; batch adversarial loss: 0.460418\n",
      "epoch 84; iter: 0; batch classifier loss: 0.471833; batch adversarial loss: 0.630760\n",
      "epoch 85; iter: 0; batch classifier loss: 0.472349; batch adversarial loss: 0.554603\n",
      "epoch 86; iter: 0; batch classifier loss: 0.324340; batch adversarial loss: 0.499838\n",
      "epoch 87; iter: 0; batch classifier loss: 0.404826; batch adversarial loss: 0.544545\n",
      "epoch 88; iter: 0; batch classifier loss: 0.397973; batch adversarial loss: 0.499221\n",
      "epoch 89; iter: 0; batch classifier loss: 0.436100; batch adversarial loss: 0.572126\n",
      "epoch 90; iter: 0; batch classifier loss: 0.443786; batch adversarial loss: 0.663666\n",
      "epoch 91; iter: 0; batch classifier loss: 0.447461; batch adversarial loss: 0.581044\n",
      "epoch 92; iter: 0; batch classifier loss: 0.356810; batch adversarial loss: 0.553901\n",
      "epoch 93; iter: 0; batch classifier loss: 0.441396; batch adversarial loss: 0.517569\n",
      "epoch 94; iter: 0; batch classifier loss: 0.421223; batch adversarial loss: 0.508534\n",
      "epoch 95; iter: 0; batch classifier loss: 0.317705; batch adversarial loss: 0.516990\n",
      "epoch 96; iter: 0; batch classifier loss: 0.380667; batch adversarial loss: 0.553935\n",
      "epoch 97; iter: 0; batch classifier loss: 0.438724; batch adversarial loss: 0.516910\n",
      "epoch 98; iter: 0; batch classifier loss: 0.394704; batch adversarial loss: 0.498024\n",
      "epoch 99; iter: 0; batch classifier loss: 0.377582; batch adversarial loss: 0.590183\n",
      "epoch 100; iter: 0; batch classifier loss: 0.402188; batch adversarial loss: 0.507530\n",
      "epoch 101; iter: 0; batch classifier loss: 0.416713; batch adversarial loss: 0.609020\n",
      "epoch 102; iter: 0; batch classifier loss: 0.403923; batch adversarial loss: 0.581223\n",
      "epoch 103; iter: 0; batch classifier loss: 0.411767; batch adversarial loss: 0.590784\n",
      "epoch 104; iter: 0; batch classifier loss: 0.445326; batch adversarial loss: 0.590340\n",
      "epoch 105; iter: 0; batch classifier loss: 0.423369; batch adversarial loss: 0.553644\n",
      "epoch 106; iter: 0; batch classifier loss: 0.408919; batch adversarial loss: 0.507490\n",
      "epoch 107; iter: 0; batch classifier loss: 0.352750; batch adversarial loss: 0.535322\n",
      "epoch 108; iter: 0; batch classifier loss: 0.343657; batch adversarial loss: 0.507082\n",
      "epoch 109; iter: 0; batch classifier loss: 0.407061; batch adversarial loss: 0.525315\n",
      "epoch 110; iter: 0; batch classifier loss: 0.422964; batch adversarial loss: 0.507864\n",
      "epoch 111; iter: 0; batch classifier loss: 0.418224; batch adversarial loss: 0.553820\n",
      "epoch 112; iter: 0; batch classifier loss: 0.507192; batch adversarial loss: 0.591171\n",
      "epoch 113; iter: 0; batch classifier loss: 0.316795; batch adversarial loss: 0.507854\n",
      "epoch 114; iter: 0; batch classifier loss: 0.426720; batch adversarial loss: 0.637500\n",
      "epoch 115; iter: 0; batch classifier loss: 0.473803; batch adversarial loss: 0.497673\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 116; iter: 0; batch classifier loss: 0.413657; batch adversarial loss: 0.544457\n",
      "epoch 117; iter: 0; batch classifier loss: 0.358066; batch adversarial loss: 0.489124\n",
      "epoch 118; iter: 0; batch classifier loss: 0.398049; batch adversarial loss: 0.525797\n",
      "epoch 119; iter: 0; batch classifier loss: 0.431655; batch adversarial loss: 0.526343\n",
      "epoch 120; iter: 0; batch classifier loss: 0.476857; batch adversarial loss: 0.544713\n",
      "epoch 121; iter: 0; batch classifier loss: 0.360948; batch adversarial loss: 0.535238\n",
      "epoch 122; iter: 0; batch classifier loss: 0.442629; batch adversarial loss: 0.572608\n",
      "epoch 123; iter: 0; batch classifier loss: 0.455594; batch adversarial loss: 0.590614\n",
      "epoch 124; iter: 0; batch classifier loss: 0.399853; batch adversarial loss: 0.553857\n",
      "epoch 125; iter: 0; batch classifier loss: 0.291508; batch adversarial loss: 0.544916\n",
      "epoch 126; iter: 0; batch classifier loss: 0.403372; batch adversarial loss: 0.535282\n",
      "epoch 127; iter: 0; batch classifier loss: 0.348546; batch adversarial loss: 0.507391\n",
      "epoch 128; iter: 0; batch classifier loss: 0.432114; batch adversarial loss: 0.516778\n",
      "epoch 129; iter: 0; batch classifier loss: 0.450487; batch adversarial loss: 0.507518\n",
      "epoch 130; iter: 0; batch classifier loss: 0.322039; batch adversarial loss: 0.516283\n",
      "epoch 131; iter: 0; batch classifier loss: 0.414738; batch adversarial loss: 0.627907\n",
      "epoch 132; iter: 0; batch classifier loss: 0.372365; batch adversarial loss: 0.534849\n",
      "epoch 133; iter: 0; batch classifier loss: 0.435380; batch adversarial loss: 0.517200\n",
      "epoch 134; iter: 0; batch classifier loss: 0.318796; batch adversarial loss: 0.535403\n",
      "epoch 135; iter: 0; batch classifier loss: 0.376362; batch adversarial loss: 0.627342\n",
      "epoch 136; iter: 0; batch classifier loss: 0.425826; batch adversarial loss: 0.553511\n",
      "epoch 137; iter: 0; batch classifier loss: 0.394970; batch adversarial loss: 0.489273\n",
      "epoch 138; iter: 0; batch classifier loss: 0.426593; batch adversarial loss: 0.608295\n",
      "epoch 139; iter: 0; batch classifier loss: 0.357949; batch adversarial loss: 0.534433\n",
      "epoch 140; iter: 0; batch classifier loss: 0.386620; batch adversarial loss: 0.563528\n",
      "epoch 141; iter: 0; batch classifier loss: 0.369226; batch adversarial loss: 0.607970\n",
      "epoch 142; iter: 0; batch classifier loss: 0.395505; batch adversarial loss: 0.508268\n",
      "epoch 143; iter: 0; batch classifier loss: 0.442765; batch adversarial loss: 0.544337\n",
      "epoch 144; iter: 0; batch classifier loss: 0.365145; batch adversarial loss: 0.554088\n",
      "epoch 145; iter: 0; batch classifier loss: 0.362485; batch adversarial loss: 0.471838\n",
      "epoch 146; iter: 0; batch classifier loss: 0.361977; batch adversarial loss: 0.515432\n",
      "epoch 147; iter: 0; batch classifier loss: 0.353275; batch adversarial loss: 0.608788\n",
      "epoch 148; iter: 0; batch classifier loss: 0.401099; batch adversarial loss: 0.589406\n",
      "epoch 149; iter: 0; batch classifier loss: 0.303958; batch adversarial loss: 0.509129\n",
      "epoch 150; iter: 0; batch classifier loss: 0.315733; batch adversarial loss: 0.533802\n",
      "epoch 151; iter: 0; batch classifier loss: 0.409042; batch adversarial loss: 0.545403\n",
      "epoch 152; iter: 0; batch classifier loss: 0.324193; batch adversarial loss: 0.516141\n",
      "epoch 153; iter: 0; batch classifier loss: 0.365386; batch adversarial loss: 0.516357\n",
      "epoch 154; iter: 0; batch classifier loss: 0.456600; batch adversarial loss: 0.471877\n",
      "epoch 155; iter: 0; batch classifier loss: 0.345720; batch adversarial loss: 0.497733\n",
      "epoch 156; iter: 0; batch classifier loss: 0.356522; batch adversarial loss: 0.582304\n",
      "epoch 157; iter: 0; batch classifier loss: 0.362509; batch adversarial loss: 0.525802\n",
      "epoch 158; iter: 0; batch classifier loss: 0.437404; batch adversarial loss: 0.572482\n",
      "epoch 159; iter: 0; batch classifier loss: 0.405664; batch adversarial loss: 0.619460\n",
      "epoch 160; iter: 0; batch classifier loss: 0.417485; batch adversarial loss: 0.544684\n",
      "epoch 161; iter: 0; batch classifier loss: 0.313761; batch adversarial loss: 0.600357\n",
      "epoch 162; iter: 0; batch classifier loss: 0.479158; batch adversarial loss: 0.535134\n",
      "epoch 163; iter: 0; batch classifier loss: 0.326813; batch adversarial loss: 0.479785\n",
      "epoch 164; iter: 0; batch classifier loss: 0.310309; batch adversarial loss: 0.516781\n",
      "epoch 165; iter: 0; batch classifier loss: 0.364874; batch adversarial loss: 0.479923\n",
      "epoch 166; iter: 0; batch classifier loss: 0.396971; batch adversarial loss: 0.544716\n",
      "epoch 167; iter: 0; batch classifier loss: 0.340868; batch adversarial loss: 0.516754\n",
      "epoch 168; iter: 0; batch classifier loss: 0.347156; batch adversarial loss: 0.572636\n",
      "epoch 169; iter: 0; batch classifier loss: 0.405139; batch adversarial loss: 0.590577\n",
      "epoch 170; iter: 0; batch classifier loss: 0.363874; batch adversarial loss: 0.553131\n",
      "epoch 171; iter: 0; batch classifier loss: 0.372392; batch adversarial loss: 0.535424\n",
      "epoch 172; iter: 0; batch classifier loss: 0.367651; batch adversarial loss: 0.516698\n",
      "epoch 173; iter: 0; batch classifier loss: 0.392109; batch adversarial loss: 0.517252\n",
      "epoch 174; iter: 0; batch classifier loss: 0.370884; batch adversarial loss: 0.507193\n",
      "epoch 175; iter: 0; batch classifier loss: 0.468506; batch adversarial loss: 0.489005\n",
      "epoch 176; iter: 0; batch classifier loss: 0.338890; batch adversarial loss: 0.562979\n",
      "epoch 177; iter: 0; batch classifier loss: 0.327645; batch adversarial loss: 0.479091\n",
      "epoch 178; iter: 0; batch classifier loss: 0.335454; batch adversarial loss: 0.573096\n",
      "epoch 179; iter: 0; batch classifier loss: 0.446253; batch adversarial loss: 0.571835\n",
      "epoch 180; iter: 0; batch classifier loss: 0.317971; batch adversarial loss: 0.535053\n",
      "epoch 181; iter: 0; batch classifier loss: 0.363100; batch adversarial loss: 0.562855\n",
      "epoch 182; iter: 0; batch classifier loss: 0.366800; batch adversarial loss: 0.544891\n",
      "epoch 183; iter: 0; batch classifier loss: 0.324407; batch adversarial loss: 0.609695\n",
      "epoch 184; iter: 0; batch classifier loss: 0.363524; batch adversarial loss: 0.609336\n",
      "epoch 185; iter: 0; batch classifier loss: 0.288408; batch adversarial loss: 0.601060\n",
      "epoch 186; iter: 0; batch classifier loss: 0.348830; batch adversarial loss: 0.534908\n",
      "epoch 187; iter: 0; batch classifier loss: 0.364896; batch adversarial loss: 0.480478\n",
      "epoch 188; iter: 0; batch classifier loss: 0.347227; batch adversarial loss: 0.507699\n",
      "epoch 189; iter: 0; batch classifier loss: 0.317522; batch adversarial loss: 0.507150\n",
      "epoch 190; iter: 0; batch classifier loss: 0.437194; batch adversarial loss: 0.683408\n",
      "epoch 191; iter: 0; batch classifier loss: 0.390682; batch adversarial loss: 0.655935\n",
      "epoch 192; iter: 0; batch classifier loss: 0.328748; batch adversarial loss: 0.581947\n",
      "epoch 193; iter: 0; batch classifier loss: 0.396192; batch adversarial loss: 0.591478\n",
      "epoch 194; iter: 0; batch classifier loss: 0.446409; batch adversarial loss: 0.488525\n",
      "epoch 195; iter: 0; batch classifier loss: 0.369772; batch adversarial loss: 0.572006\n",
      "epoch 196; iter: 0; batch classifier loss: 0.373802; batch adversarial loss: 0.609273\n",
      "epoch 197; iter: 0; batch classifier loss: 0.320100; batch adversarial loss: 0.526090\n",
      "epoch 198; iter: 0; batch classifier loss: 0.304851; batch adversarial loss: 0.526608\n",
      "epoch 199; iter: 0; batch classifier loss: 0.350598; batch adversarial loss: 0.525863\n",
      "epoch 0; iter: 0; batch classifier loss: 0.721824; batch adversarial loss: 0.704501\n",
      "epoch 1; iter: 0; batch classifier loss: 0.632593; batch adversarial loss: 0.665701\n",
      "epoch 2; iter: 0; batch classifier loss: 0.607161; batch adversarial loss: 0.636282\n",
      "epoch 3; iter: 0; batch classifier loss: 0.575471; batch adversarial loss: 0.625770\n",
      "epoch 4; iter: 0; batch classifier loss: 0.607675; batch adversarial loss: 0.598951\n",
      "epoch 5; iter: 0; batch classifier loss: 0.550733; batch adversarial loss: 0.597782\n",
      "epoch 6; iter: 0; batch classifier loss: 0.542354; batch adversarial loss: 0.644175\n",
      "epoch 7; iter: 0; batch classifier loss: 0.462486; batch adversarial loss: 0.562310\n",
      "epoch 8; iter: 0; batch classifier loss: 0.576112; batch adversarial loss: 0.567679\n",
      "epoch 9; iter: 0; batch classifier loss: 0.534690; batch adversarial loss: 0.582832\n",
      "epoch 10; iter: 0; batch classifier loss: 0.501685; batch adversarial loss: 0.530396\n",
      "epoch 11; iter: 0; batch classifier loss: 0.519153; batch adversarial loss: 0.603808\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12; iter: 0; batch classifier loss: 0.545152; batch adversarial loss: 0.574290\n",
      "epoch 13; iter: 0; batch classifier loss: 0.539542; batch adversarial loss: 0.612776\n",
      "epoch 14; iter: 0; batch classifier loss: 0.480759; batch adversarial loss: 0.609840\n",
      "epoch 15; iter: 0; batch classifier loss: 0.538355; batch adversarial loss: 0.634211\n",
      "epoch 16; iter: 0; batch classifier loss: 0.558035; batch adversarial loss: 0.512207\n",
      "epoch 17; iter: 0; batch classifier loss: 0.522470; batch adversarial loss: 0.582939\n",
      "epoch 18; iter: 0; batch classifier loss: 0.454141; batch adversarial loss: 0.619304\n",
      "epoch 19; iter: 0; batch classifier loss: 0.530580; batch adversarial loss: 0.585892\n",
      "epoch 20; iter: 0; batch classifier loss: 0.562342; batch adversarial loss: 0.629765\n",
      "epoch 21; iter: 0; batch classifier loss: 0.521039; batch adversarial loss: 0.580909\n",
      "epoch 22; iter: 0; batch classifier loss: 0.572897; batch adversarial loss: 0.599162\n",
      "epoch 23; iter: 0; batch classifier loss: 0.481569; batch adversarial loss: 0.573792\n",
      "epoch 24; iter: 0; batch classifier loss: 0.476797; batch adversarial loss: 0.538203\n",
      "epoch 25; iter: 0; batch classifier loss: 0.538026; batch adversarial loss: 0.604783\n",
      "epoch 26; iter: 0; batch classifier loss: 0.473844; batch adversarial loss: 0.570004\n",
      "epoch 27; iter: 0; batch classifier loss: 0.450569; batch adversarial loss: 0.577628\n",
      "epoch 28; iter: 0; batch classifier loss: 0.455886; batch adversarial loss: 0.575884\n",
      "epoch 29; iter: 0; batch classifier loss: 0.494032; batch adversarial loss: 0.557243\n",
      "epoch 30; iter: 0; batch classifier loss: 0.419973; batch adversarial loss: 0.555898\n",
      "epoch 31; iter: 0; batch classifier loss: 0.472808; batch adversarial loss: 0.584273\n",
      "epoch 32; iter: 0; batch classifier loss: 0.455381; batch adversarial loss: 0.535799\n",
      "epoch 33; iter: 0; batch classifier loss: 0.425268; batch adversarial loss: 0.548208\n",
      "epoch 34; iter: 0; batch classifier loss: 0.451709; batch adversarial loss: 0.562141\n",
      "epoch 35; iter: 0; batch classifier loss: 0.371987; batch adversarial loss: 0.571035\n",
      "epoch 36; iter: 0; batch classifier loss: 0.442961; batch adversarial loss: 0.538379\n",
      "epoch 37; iter: 0; batch classifier loss: 0.432148; batch adversarial loss: 0.589012\n",
      "epoch 38; iter: 0; batch classifier loss: 0.423921; batch adversarial loss: 0.528436\n",
      "epoch 39; iter: 0; batch classifier loss: 0.445347; batch adversarial loss: 0.561722\n",
      "epoch 40; iter: 0; batch classifier loss: 0.442378; batch adversarial loss: 0.545792\n",
      "epoch 41; iter: 0; batch classifier loss: 0.379026; batch adversarial loss: 0.618080\n",
      "epoch 42; iter: 0; batch classifier loss: 0.483232; batch adversarial loss: 0.526844\n",
      "epoch 43; iter: 0; batch classifier loss: 0.415588; batch adversarial loss: 0.553185\n",
      "epoch 44; iter: 0; batch classifier loss: 0.434918; batch adversarial loss: 0.555929\n",
      "epoch 45; iter: 0; batch classifier loss: 0.516005; batch adversarial loss: 0.559661\n",
      "epoch 46; iter: 0; batch classifier loss: 0.493980; batch adversarial loss: 0.569705\n",
      "epoch 47; iter: 0; batch classifier loss: 0.445241; batch adversarial loss: 0.604120\n",
      "epoch 48; iter: 0; batch classifier loss: 0.399265; batch adversarial loss: 0.554749\n",
      "epoch 49; iter: 0; batch classifier loss: 0.445477; batch adversarial loss: 0.471351\n",
      "epoch 50; iter: 0; batch classifier loss: 0.364752; batch adversarial loss: 0.481011\n",
      "epoch 51; iter: 0; batch classifier loss: 0.379307; batch adversarial loss: 0.545152\n",
      "epoch 52; iter: 0; batch classifier loss: 0.465034; batch adversarial loss: 0.600015\n",
      "epoch 53; iter: 0; batch classifier loss: 0.502809; batch adversarial loss: 0.592265\n",
      "epoch 54; iter: 0; batch classifier loss: 0.433223; batch adversarial loss: 0.542373\n",
      "epoch 55; iter: 0; batch classifier loss: 0.390561; batch adversarial loss: 0.481006\n",
      "epoch 56; iter: 0; batch classifier loss: 0.428780; batch adversarial loss: 0.553890\n",
      "epoch 57; iter: 0; batch classifier loss: 0.398707; batch adversarial loss: 0.660129\n",
      "epoch 58; iter: 0; batch classifier loss: 0.426336; batch adversarial loss: 0.597346\n",
      "epoch 59; iter: 0; batch classifier loss: 0.369411; batch adversarial loss: 0.490524\n",
      "epoch 60; iter: 0; batch classifier loss: 0.440187; batch adversarial loss: 0.491081\n",
      "epoch 61; iter: 0; batch classifier loss: 0.362699; batch adversarial loss: 0.496957\n",
      "epoch 62; iter: 0; batch classifier loss: 0.479564; batch adversarial loss: 0.634399\n",
      "epoch 63; iter: 0; batch classifier loss: 0.381398; batch adversarial loss: 0.468585\n",
      "epoch 64; iter: 0; batch classifier loss: 0.425267; batch adversarial loss: 0.469640\n",
      "epoch 65; iter: 0; batch classifier loss: 0.414336; batch adversarial loss: 0.496879\n",
      "epoch 66; iter: 0; batch classifier loss: 0.443360; batch adversarial loss: 0.533094\n",
      "epoch 67; iter: 0; batch classifier loss: 0.375747; batch adversarial loss: 0.580124\n",
      "epoch 68; iter: 0; batch classifier loss: 0.436250; batch adversarial loss: 0.560373\n",
      "epoch 69; iter: 0; batch classifier loss: 0.377716; batch adversarial loss: 0.527716\n",
      "epoch 70; iter: 0; batch classifier loss: 0.439734; batch adversarial loss: 0.518018\n",
      "epoch 71; iter: 0; batch classifier loss: 0.396540; batch adversarial loss: 0.526411\n",
      "epoch 72; iter: 0; batch classifier loss: 0.411656; batch adversarial loss: 0.524598\n",
      "epoch 73; iter: 0; batch classifier loss: 0.419268; batch adversarial loss: 0.597623\n",
      "epoch 74; iter: 0; batch classifier loss: 0.385432; batch adversarial loss: 0.497116\n",
      "epoch 75; iter: 0; batch classifier loss: 0.397709; batch adversarial loss: 0.504562\n",
      "epoch 76; iter: 0; batch classifier loss: 0.365416; batch adversarial loss: 0.555091\n",
      "epoch 77; iter: 0; batch classifier loss: 0.433758; batch adversarial loss: 0.419038\n",
      "epoch 78; iter: 0; batch classifier loss: 0.392130; batch adversarial loss: 0.496375\n",
      "epoch 79; iter: 0; batch classifier loss: 0.460487; batch adversarial loss: 0.688592\n",
      "epoch 80; iter: 0; batch classifier loss: 0.351596; batch adversarial loss: 0.579342\n",
      "epoch 81; iter: 0; batch classifier loss: 0.365776; batch adversarial loss: 0.519686\n",
      "epoch 82; iter: 0; batch classifier loss: 0.330603; batch adversarial loss: 0.504440\n",
      "epoch 83; iter: 0; batch classifier loss: 0.344552; batch adversarial loss: 0.523374\n",
      "epoch 84; iter: 0; batch classifier loss: 0.386727; batch adversarial loss: 0.498304\n",
      "epoch 85; iter: 0; batch classifier loss: 0.379779; batch adversarial loss: 0.515238\n",
      "epoch 86; iter: 0; batch classifier loss: 0.387925; batch adversarial loss: 0.590492\n",
      "epoch 87; iter: 0; batch classifier loss: 0.360285; batch adversarial loss: 0.488578\n",
      "epoch 88; iter: 0; batch classifier loss: 0.354240; batch adversarial loss: 0.498892\n",
      "epoch 89; iter: 0; batch classifier loss: 0.407524; batch adversarial loss: 0.554546\n",
      "epoch 90; iter: 0; batch classifier loss: 0.331907; batch adversarial loss: 0.570263\n",
      "epoch 91; iter: 0; batch classifier loss: 0.356426; batch adversarial loss: 0.431993\n",
      "epoch 92; iter: 0; batch classifier loss: 0.393693; batch adversarial loss: 0.580604\n",
      "epoch 93; iter: 0; batch classifier loss: 0.451858; batch adversarial loss: 0.552451\n",
      "epoch 94; iter: 0; batch classifier loss: 0.439952; batch adversarial loss: 0.490958\n",
      "epoch 95; iter: 0; batch classifier loss: 0.359786; batch adversarial loss: 0.536056\n",
      "epoch 96; iter: 0; batch classifier loss: 0.404628; batch adversarial loss: 0.534818\n",
      "epoch 97; iter: 0; batch classifier loss: 0.343798; batch adversarial loss: 0.553801\n",
      "epoch 98; iter: 0; batch classifier loss: 0.388391; batch adversarial loss: 0.531649\n",
      "epoch 99; iter: 0; batch classifier loss: 0.348717; batch adversarial loss: 0.537828\n",
      "epoch 100; iter: 0; batch classifier loss: 0.416366; batch adversarial loss: 0.516409\n",
      "epoch 101; iter: 0; batch classifier loss: 0.415743; batch adversarial loss: 0.589149\n",
      "epoch 102; iter: 0; batch classifier loss: 0.429026; batch adversarial loss: 0.509657\n",
      "epoch 103; iter: 0; batch classifier loss: 0.472121; batch adversarial loss: 0.581576\n",
      "epoch 104; iter: 0; batch classifier loss: 0.340651; batch adversarial loss: 0.543324\n",
      "epoch 105; iter: 0; batch classifier loss: 0.385573; batch adversarial loss: 0.590865\n",
      "epoch 106; iter: 0; batch classifier loss: 0.257757; batch adversarial loss: 0.491278\n",
      "epoch 107; iter: 0; batch classifier loss: 0.354264; batch adversarial loss: 0.553916\n",
      "epoch 108; iter: 0; batch classifier loss: 0.377851; batch adversarial loss: 0.598372\n",
      "epoch 109; iter: 0; batch classifier loss: 0.502075; batch adversarial loss: 0.589927\n",
      "epoch 110; iter: 0; batch classifier loss: 0.381799; batch adversarial loss: 0.514532\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 111; iter: 0; batch classifier loss: 0.367704; batch adversarial loss: 0.565964\n",
      "epoch 112; iter: 0; batch classifier loss: 0.382588; batch adversarial loss: 0.581951\n",
      "epoch 113; iter: 0; batch classifier loss: 0.413771; batch adversarial loss: 0.509534\n",
      "epoch 114; iter: 0; batch classifier loss: 0.385298; batch adversarial loss: 0.588270\n",
      "epoch 115; iter: 0; batch classifier loss: 0.380592; batch adversarial loss: 0.554987\n",
      "epoch 116; iter: 0; batch classifier loss: 0.355532; batch adversarial loss: 0.477205\n",
      "epoch 117; iter: 0; batch classifier loss: 0.453407; batch adversarial loss: 0.583919\n",
      "epoch 118; iter: 0; batch classifier loss: 0.372818; batch adversarial loss: 0.647224\n",
      "epoch 119; iter: 0; batch classifier loss: 0.428413; batch adversarial loss: 0.517684\n",
      "epoch 120; iter: 0; batch classifier loss: 0.356970; batch adversarial loss: 0.486554\n",
      "epoch 121; iter: 0; batch classifier loss: 0.348279; batch adversarial loss: 0.481120\n",
      "epoch 122; iter: 0; batch classifier loss: 0.404622; batch adversarial loss: 0.551705\n",
      "epoch 123; iter: 0; batch classifier loss: 0.404554; batch adversarial loss: 0.601064\n",
      "epoch 124; iter: 0; batch classifier loss: 0.377641; batch adversarial loss: 0.598263\n",
      "epoch 125; iter: 0; batch classifier loss: 0.407337; batch adversarial loss: 0.450758\n",
      "epoch 126; iter: 0; batch classifier loss: 0.338250; batch adversarial loss: 0.522446\n",
      "epoch 127; iter: 0; batch classifier loss: 0.359157; batch adversarial loss: 0.526228\n",
      "epoch 128; iter: 0; batch classifier loss: 0.326297; batch adversarial loss: 0.534587\n",
      "epoch 129; iter: 0; batch classifier loss: 0.336704; batch adversarial loss: 0.562184\n",
      "epoch 130; iter: 0; batch classifier loss: 0.336997; batch adversarial loss: 0.520876\n",
      "epoch 131; iter: 0; batch classifier loss: 0.359528; batch adversarial loss: 0.589612\n",
      "epoch 132; iter: 0; batch classifier loss: 0.441519; batch adversarial loss: 0.561861\n",
      "epoch 133; iter: 0; batch classifier loss: 0.331038; batch adversarial loss: 0.452632\n",
      "epoch 134; iter: 0; batch classifier loss: 0.420880; batch adversarial loss: 0.526423\n",
      "epoch 135; iter: 0; batch classifier loss: 0.354581; batch adversarial loss: 0.591726\n",
      "epoch 136; iter: 0; batch classifier loss: 0.364315; batch adversarial loss: 0.544747\n",
      "epoch 137; iter: 0; batch classifier loss: 0.343594; batch adversarial loss: 0.593548\n",
      "epoch 138; iter: 0; batch classifier loss: 0.377786; batch adversarial loss: 0.532866\n",
      "epoch 139; iter: 0; batch classifier loss: 0.333391; batch adversarial loss: 0.571002\n",
      "epoch 140; iter: 0; batch classifier loss: 0.372269; batch adversarial loss: 0.652844\n",
      "epoch 141; iter: 0; batch classifier loss: 0.303243; batch adversarial loss: 0.524289\n",
      "epoch 142; iter: 0; batch classifier loss: 0.362887; batch adversarial loss: 0.508433\n",
      "epoch 143; iter: 0; batch classifier loss: 0.383078; batch adversarial loss: 0.638524\n",
      "epoch 144; iter: 0; batch classifier loss: 0.350070; batch adversarial loss: 0.525595\n",
      "epoch 145; iter: 0; batch classifier loss: 0.416978; batch adversarial loss: 0.592605\n",
      "epoch 146; iter: 0; batch classifier loss: 0.324823; batch adversarial loss: 0.559407\n",
      "epoch 147; iter: 0; batch classifier loss: 0.458471; batch adversarial loss: 0.517492\n",
      "epoch 148; iter: 0; batch classifier loss: 0.420438; batch adversarial loss: 0.562293\n",
      "epoch 149; iter: 0; batch classifier loss: 0.279213; batch adversarial loss: 0.631410\n",
      "epoch 150; iter: 0; batch classifier loss: 0.365654; batch adversarial loss: 0.630616\n",
      "epoch 151; iter: 0; batch classifier loss: 0.357548; batch adversarial loss: 0.553584\n",
      "epoch 152; iter: 0; batch classifier loss: 0.340226; batch adversarial loss: 0.484212\n",
      "epoch 153; iter: 0; batch classifier loss: 0.387663; batch adversarial loss: 0.622849\n",
      "epoch 154; iter: 0; batch classifier loss: 0.305036; batch adversarial loss: 0.508821\n",
      "epoch 155; iter: 0; batch classifier loss: 0.452375; batch adversarial loss: 0.572579\n",
      "epoch 156; iter: 0; batch classifier loss: 0.380756; batch adversarial loss: 0.597664\n",
      "epoch 157; iter: 0; batch classifier loss: 0.350319; batch adversarial loss: 0.547912\n",
      "epoch 158; iter: 0; batch classifier loss: 0.346322; batch adversarial loss: 0.489119\n",
      "epoch 159; iter: 0; batch classifier loss: 0.355922; batch adversarial loss: 0.515441\n",
      "epoch 160; iter: 0; batch classifier loss: 0.402267; batch adversarial loss: 0.510681\n",
      "epoch 161; iter: 0; batch classifier loss: 0.413357; batch adversarial loss: 0.481139\n",
      "epoch 162; iter: 0; batch classifier loss: 0.461444; batch adversarial loss: 0.552874\n",
      "epoch 163; iter: 0; batch classifier loss: 0.367896; batch adversarial loss: 0.471434\n",
      "epoch 164; iter: 0; batch classifier loss: 0.313355; batch adversarial loss: 0.478918\n",
      "epoch 165; iter: 0; batch classifier loss: 0.371735; batch adversarial loss: 0.589100\n",
      "epoch 166; iter: 0; batch classifier loss: 0.332156; batch adversarial loss: 0.612598\n",
      "epoch 167; iter: 0; batch classifier loss: 0.399010; batch adversarial loss: 0.655623\n",
      "epoch 168; iter: 0; batch classifier loss: 0.295642; batch adversarial loss: 0.509086\n",
      "epoch 169; iter: 0; batch classifier loss: 0.422450; batch adversarial loss: 0.504001\n",
      "epoch 170; iter: 0; batch classifier loss: 0.322372; batch adversarial loss: 0.551477\n",
      "epoch 171; iter: 0; batch classifier loss: 0.364979; batch adversarial loss: 0.574864\n",
      "epoch 172; iter: 0; batch classifier loss: 0.391482; batch adversarial loss: 0.616126\n",
      "epoch 173; iter: 0; batch classifier loss: 0.301542; batch adversarial loss: 0.534845\n",
      "epoch 174; iter: 0; batch classifier loss: 0.402200; batch adversarial loss: 0.499597\n",
      "epoch 175; iter: 0; batch classifier loss: 0.376914; batch adversarial loss: 0.572034\n",
      "epoch 176; iter: 0; batch classifier loss: 0.290389; batch adversarial loss: 0.541951\n",
      "epoch 177; iter: 0; batch classifier loss: 0.340205; batch adversarial loss: 0.535312\n",
      "epoch 178; iter: 0; batch classifier loss: 0.355999; batch adversarial loss: 0.615265\n",
      "epoch 179; iter: 0; batch classifier loss: 0.347075; batch adversarial loss: 0.537541\n",
      "epoch 180; iter: 0; batch classifier loss: 0.352054; batch adversarial loss: 0.506969\n",
      "epoch 181; iter: 0; batch classifier loss: 0.342281; batch adversarial loss: 0.534496\n",
      "epoch 182; iter: 0; batch classifier loss: 0.346374; batch adversarial loss: 0.517190\n",
      "epoch 183; iter: 0; batch classifier loss: 0.295433; batch adversarial loss: 0.600180\n",
      "epoch 184; iter: 0; batch classifier loss: 0.412944; batch adversarial loss: 0.600084\n",
      "epoch 185; iter: 0; batch classifier loss: 0.361725; batch adversarial loss: 0.562873\n",
      "epoch 186; iter: 0; batch classifier loss: 0.372439; batch adversarial loss: 0.545692\n",
      "epoch 187; iter: 0; batch classifier loss: 0.387947; batch adversarial loss: 0.627401\n",
      "epoch 188; iter: 0; batch classifier loss: 0.376188; batch adversarial loss: 0.586226\n",
      "epoch 189; iter: 0; batch classifier loss: 0.397942; batch adversarial loss: 0.526783\n",
      "epoch 190; iter: 0; batch classifier loss: 0.375537; batch adversarial loss: 0.551585\n",
      "epoch 191; iter: 0; batch classifier loss: 0.382047; batch adversarial loss: 0.452620\n",
      "epoch 192; iter: 0; batch classifier loss: 0.357275; batch adversarial loss: 0.636617\n",
      "epoch 193; iter: 0; batch classifier loss: 0.372442; batch adversarial loss: 0.500491\n",
      "epoch 194; iter: 0; batch classifier loss: 0.322639; batch adversarial loss: 0.562760\n",
      "epoch 195; iter: 0; batch classifier loss: 0.286052; batch adversarial loss: 0.531042\n",
      "epoch 196; iter: 0; batch classifier loss: 0.385141; batch adversarial loss: 0.478275\n",
      "epoch 197; iter: 0; batch classifier loss: 0.344026; batch adversarial loss: 0.525637\n",
      "epoch 198; iter: 0; batch classifier loss: 0.334112; batch adversarial loss: 0.591210\n",
      "epoch 199; iter: 0; batch classifier loss: 0.364421; batch adversarial loss: 0.424486\n",
      "epoch 0; iter: 0; batch classifier loss: 0.703806; batch adversarial loss: 0.721662\n",
      "epoch 1; iter: 0; batch classifier loss: 0.710485; batch adversarial loss: 0.740703\n",
      "epoch 2; iter: 0; batch classifier loss: 0.728680; batch adversarial loss: 0.705096\n",
      "epoch 3; iter: 0; batch classifier loss: 0.599823; batch adversarial loss: 0.648317\n",
      "epoch 4; iter: 0; batch classifier loss: 0.603280; batch adversarial loss: 0.633817\n",
      "epoch 5; iter: 0; batch classifier loss: 0.529072; batch adversarial loss: 0.619997\n",
      "epoch 6; iter: 0; batch classifier loss: 0.544048; batch adversarial loss: 0.629289\n",
      "epoch 7; iter: 0; batch classifier loss: 0.549063; batch adversarial loss: 0.606464\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8; iter: 0; batch classifier loss: 0.533523; batch adversarial loss: 0.578835\n",
      "epoch 9; iter: 0; batch classifier loss: 0.509727; batch adversarial loss: 0.550611\n",
      "epoch 10; iter: 0; batch classifier loss: 0.569678; batch adversarial loss: 0.605395\n",
      "epoch 11; iter: 0; batch classifier loss: 0.473261; batch adversarial loss: 0.587988\n",
      "epoch 12; iter: 0; batch classifier loss: 0.536025; batch adversarial loss: 0.547134\n",
      "epoch 13; iter: 0; batch classifier loss: 0.471082; batch adversarial loss: 0.553323\n",
      "epoch 14; iter: 0; batch classifier loss: 0.531009; batch adversarial loss: 0.514987\n",
      "epoch 15; iter: 0; batch classifier loss: 0.501556; batch adversarial loss: 0.533793\n",
      "epoch 16; iter: 0; batch classifier loss: 0.522130; batch adversarial loss: 0.561982\n",
      "epoch 17; iter: 0; batch classifier loss: 0.470806; batch adversarial loss: 0.512529\n",
      "epoch 18; iter: 0; batch classifier loss: 0.529616; batch adversarial loss: 0.565576\n",
      "epoch 19; iter: 0; batch classifier loss: 0.515273; batch adversarial loss: 0.588543\n",
      "epoch 20; iter: 0; batch classifier loss: 0.404554; batch adversarial loss: 0.576220\n",
      "epoch 21; iter: 0; batch classifier loss: 0.533956; batch adversarial loss: 0.619109\n",
      "epoch 22; iter: 0; batch classifier loss: 0.455625; batch adversarial loss: 0.568980\n",
      "epoch 23; iter: 0; batch classifier loss: 0.451677; batch adversarial loss: 0.541657\n",
      "epoch 24; iter: 0; batch classifier loss: 0.487814; batch adversarial loss: 0.506198\n",
      "epoch 25; iter: 0; batch classifier loss: 0.523546; batch adversarial loss: 0.554745\n",
      "epoch 26; iter: 0; batch classifier loss: 0.458107; batch adversarial loss: 0.535399\n",
      "epoch 27; iter: 0; batch classifier loss: 0.469004; batch adversarial loss: 0.515602\n",
      "epoch 28; iter: 0; batch classifier loss: 0.477316; batch adversarial loss: 0.532996\n",
      "epoch 29; iter: 0; batch classifier loss: 0.432074; batch adversarial loss: 0.536744\n",
      "epoch 30; iter: 0; batch classifier loss: 0.497025; batch adversarial loss: 0.567748\n",
      "epoch 31; iter: 0; batch classifier loss: 0.459986; batch adversarial loss: 0.541206\n",
      "epoch 32; iter: 0; batch classifier loss: 0.440496; batch adversarial loss: 0.603477\n",
      "epoch 33; iter: 0; batch classifier loss: 0.429394; batch adversarial loss: 0.535421\n",
      "epoch 34; iter: 0; batch classifier loss: 0.413556; batch adversarial loss: 0.539013\n",
      "epoch 35; iter: 0; batch classifier loss: 0.451574; batch adversarial loss: 0.618308\n",
      "epoch 36; iter: 0; batch classifier loss: 0.513010; batch adversarial loss: 0.550428\n",
      "epoch 37; iter: 0; batch classifier loss: 0.471580; batch adversarial loss: 0.553242\n",
      "epoch 38; iter: 0; batch classifier loss: 0.437506; batch adversarial loss: 0.529907\n",
      "epoch 39; iter: 0; batch classifier loss: 0.418495; batch adversarial loss: 0.516396\n",
      "epoch 40; iter: 0; batch classifier loss: 0.431632; batch adversarial loss: 0.656664\n",
      "epoch 41; iter: 0; batch classifier loss: 0.411669; batch adversarial loss: 0.565855\n",
      "epoch 42; iter: 0; batch classifier loss: 0.425311; batch adversarial loss: 0.612087\n",
      "epoch 43; iter: 0; batch classifier loss: 0.489550; batch adversarial loss: 0.542876\n",
      "epoch 44; iter: 0; batch classifier loss: 0.428258; batch adversarial loss: 0.562899\n",
      "epoch 45; iter: 0; batch classifier loss: 0.418987; batch adversarial loss: 0.566052\n",
      "epoch 46; iter: 0; batch classifier loss: 0.377968; batch adversarial loss: 0.545377\n",
      "epoch 47; iter: 0; batch classifier loss: 0.395960; batch adversarial loss: 0.579268\n",
      "epoch 48; iter: 0; batch classifier loss: 0.378890; batch adversarial loss: 0.571339\n",
      "epoch 49; iter: 0; batch classifier loss: 0.411324; batch adversarial loss: 0.450376\n",
      "epoch 50; iter: 0; batch classifier loss: 0.428254; batch adversarial loss: 0.545252\n",
      "epoch 51; iter: 0; batch classifier loss: 0.456500; batch adversarial loss: 0.527250\n",
      "epoch 52; iter: 0; batch classifier loss: 0.373895; batch adversarial loss: 0.536602\n",
      "epoch 53; iter: 0; batch classifier loss: 0.436981; batch adversarial loss: 0.483268\n",
      "epoch 54; iter: 0; batch classifier loss: 0.479307; batch adversarial loss: 0.545574\n",
      "epoch 55; iter: 0; batch classifier loss: 0.397135; batch adversarial loss: 0.527639\n",
      "epoch 56; iter: 0; batch classifier loss: 0.427767; batch adversarial loss: 0.510119\n",
      "epoch 57; iter: 0; batch classifier loss: 0.489743; batch adversarial loss: 0.544681\n",
      "epoch 58; iter: 0; batch classifier loss: 0.467441; batch adversarial loss: 0.553506\n",
      "epoch 59; iter: 0; batch classifier loss: 0.442998; batch adversarial loss: 0.545060\n",
      "epoch 60; iter: 0; batch classifier loss: 0.429299; batch adversarial loss: 0.509489\n",
      "epoch 61; iter: 0; batch classifier loss: 0.413884; batch adversarial loss: 0.544764\n",
      "epoch 62; iter: 0; batch classifier loss: 0.403806; batch adversarial loss: 0.517846\n",
      "epoch 63; iter: 0; batch classifier loss: 0.448514; batch adversarial loss: 0.517887\n",
      "epoch 64; iter: 0; batch classifier loss: 0.337255; batch adversarial loss: 0.509005\n",
      "epoch 65; iter: 0; batch classifier loss: 0.437212; batch adversarial loss: 0.535721\n",
      "epoch 66; iter: 0; batch classifier loss: 0.482285; batch adversarial loss: 0.642523\n",
      "epoch 67; iter: 0; batch classifier loss: 0.363315; batch adversarial loss: 0.508631\n",
      "epoch 68; iter: 0; batch classifier loss: 0.391906; batch adversarial loss: 0.464122\n",
      "epoch 69; iter: 0; batch classifier loss: 0.424944; batch adversarial loss: 0.517985\n",
      "epoch 70; iter: 0; batch classifier loss: 0.429338; batch adversarial loss: 0.491482\n",
      "epoch 71; iter: 0; batch classifier loss: 0.409291; batch adversarial loss: 0.553725\n",
      "epoch 72; iter: 0; batch classifier loss: 0.409293; batch adversarial loss: 0.607271\n",
      "epoch 73; iter: 0; batch classifier loss: 0.426119; batch adversarial loss: 0.580534\n",
      "epoch 74; iter: 0; batch classifier loss: 0.387458; batch adversarial loss: 0.571564\n",
      "epoch 75; iter: 0; batch classifier loss: 0.420704; batch adversarial loss: 0.607427\n",
      "epoch 76; iter: 0; batch classifier loss: 0.387318; batch adversarial loss: 0.526391\n",
      "epoch 77; iter: 0; batch classifier loss: 0.367002; batch adversarial loss: 0.598598\n",
      "epoch 78; iter: 0; batch classifier loss: 0.444303; batch adversarial loss: 0.526590\n",
      "epoch 79; iter: 0; batch classifier loss: 0.432495; batch adversarial loss: 0.535886\n",
      "epoch 80; iter: 0; batch classifier loss: 0.408541; batch adversarial loss: 0.562608\n",
      "epoch 81; iter: 0; batch classifier loss: 0.352845; batch adversarial loss: 0.553770\n",
      "epoch 82; iter: 0; batch classifier loss: 0.364420; batch adversarial loss: 0.499930\n",
      "epoch 83; iter: 0; batch classifier loss: 0.409652; batch adversarial loss: 0.553391\n",
      "epoch 84; iter: 0; batch classifier loss: 0.447042; batch adversarial loss: 0.580821\n",
      "epoch 85; iter: 0; batch classifier loss: 0.411332; batch adversarial loss: 0.526622\n",
      "epoch 86; iter: 0; batch classifier loss: 0.451074; batch adversarial loss: 0.526690\n",
      "epoch 87; iter: 0; batch classifier loss: 0.412345; batch adversarial loss: 0.509136\n",
      "epoch 88; iter: 0; batch classifier loss: 0.450282; batch adversarial loss: 0.499781\n",
      "epoch 89; iter: 0; batch classifier loss: 0.427134; batch adversarial loss: 0.500169\n",
      "epoch 90; iter: 0; batch classifier loss: 0.332716; batch adversarial loss: 0.552768\n",
      "epoch 91; iter: 0; batch classifier loss: 0.313126; batch adversarial loss: 0.613466\n",
      "epoch 92; iter: 0; batch classifier loss: 0.399397; batch adversarial loss: 0.518150\n",
      "epoch 93; iter: 0; batch classifier loss: 0.396807; batch adversarial loss: 0.561476\n",
      "epoch 94; iter: 0; batch classifier loss: 0.380712; batch adversarial loss: 0.545124\n",
      "epoch 95; iter: 0; batch classifier loss: 0.392104; batch adversarial loss: 0.580926\n",
      "epoch 96; iter: 0; batch classifier loss: 0.365098; batch adversarial loss: 0.543189\n",
      "epoch 97; iter: 0; batch classifier loss: 0.401322; batch adversarial loss: 0.609279\n",
      "epoch 98; iter: 0; batch classifier loss: 0.371808; batch adversarial loss: 0.581065\n",
      "epoch 99; iter: 0; batch classifier loss: 0.348958; batch adversarial loss: 0.543093\n",
      "epoch 100; iter: 0; batch classifier loss: 0.444869; batch adversarial loss: 0.617879\n",
      "epoch 101; iter: 0; batch classifier loss: 0.414928; batch adversarial loss: 0.555248\n",
      "epoch 102; iter: 0; batch classifier loss: 0.380680; batch adversarial loss: 0.532793\n",
      "epoch 103; iter: 0; batch classifier loss: 0.365162; batch adversarial loss: 0.560848\n",
      "epoch 104; iter: 0; batch classifier loss: 0.425736; batch adversarial loss: 0.629728\n",
      "epoch 105; iter: 0; batch classifier loss: 0.380727; batch adversarial loss: 0.523998\n",
      "epoch 106; iter: 0; batch classifier loss: 0.428440; batch adversarial loss: 0.562055\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 107; iter: 0; batch classifier loss: 0.399854; batch adversarial loss: 0.614722\n",
      "epoch 108; iter: 0; batch classifier loss: 0.398638; batch adversarial loss: 0.571495\n",
      "epoch 109; iter: 0; batch classifier loss: 0.291357; batch adversarial loss: 0.600659\n",
      "epoch 110; iter: 0; batch classifier loss: 0.397404; batch adversarial loss: 0.591618\n",
      "epoch 111; iter: 0; batch classifier loss: 0.368066; batch adversarial loss: 0.527806\n",
      "epoch 112; iter: 0; batch classifier loss: 0.405981; batch adversarial loss: 0.635545\n",
      "epoch 113; iter: 0; batch classifier loss: 0.434561; batch adversarial loss: 0.543722\n",
      "epoch 114; iter: 0; batch classifier loss: 0.378941; batch adversarial loss: 0.526568\n",
      "epoch 115; iter: 0; batch classifier loss: 0.345104; batch adversarial loss: 0.507649\n",
      "epoch 116; iter: 0; batch classifier loss: 0.381951; batch adversarial loss: 0.545197\n",
      "epoch 117; iter: 0; batch classifier loss: 0.400679; batch adversarial loss: 0.644712\n",
      "epoch 118; iter: 0; batch classifier loss: 0.432541; batch adversarial loss: 0.527618\n",
      "epoch 119; iter: 0; batch classifier loss: 0.317874; batch adversarial loss: 0.571660\n",
      "epoch 120; iter: 0; batch classifier loss: 0.406829; batch adversarial loss: 0.537363\n",
      "epoch 121; iter: 0; batch classifier loss: 0.334871; batch adversarial loss: 0.580631\n",
      "epoch 122; iter: 0; batch classifier loss: 0.441840; batch adversarial loss: 0.533454\n",
      "epoch 123; iter: 0; batch classifier loss: 0.291162; batch adversarial loss: 0.599030\n",
      "epoch 124; iter: 0; batch classifier loss: 0.349936; batch adversarial loss: 0.504300\n",
      "epoch 125; iter: 0; batch classifier loss: 0.369010; batch adversarial loss: 0.575571\n",
      "epoch 126; iter: 0; batch classifier loss: 0.382658; batch adversarial loss: 0.568699\n",
      "epoch 127; iter: 0; batch classifier loss: 0.368412; batch adversarial loss: 0.602365\n",
      "epoch 128; iter: 0; batch classifier loss: 0.349495; batch adversarial loss: 0.565712\n",
      "epoch 129; iter: 0; batch classifier loss: 0.278757; batch adversarial loss: 0.566638\n",
      "epoch 130; iter: 0; batch classifier loss: 0.376617; batch adversarial loss: 0.476927\n",
      "epoch 131; iter: 0; batch classifier loss: 0.406009; batch adversarial loss: 0.544993\n",
      "epoch 132; iter: 0; batch classifier loss: 0.313135; batch adversarial loss: 0.581040\n",
      "epoch 133; iter: 0; batch classifier loss: 0.362025; batch adversarial loss: 0.491580\n",
      "epoch 134; iter: 0; batch classifier loss: 0.327193; batch adversarial loss: 0.542266\n",
      "epoch 135; iter: 0; batch classifier loss: 0.377718; batch adversarial loss: 0.509252\n",
      "epoch 136; iter: 0; batch classifier loss: 0.436788; batch adversarial loss: 0.481355\n",
      "epoch 137; iter: 0; batch classifier loss: 0.346903; batch adversarial loss: 0.515624\n",
      "epoch 138; iter: 0; batch classifier loss: 0.346261; batch adversarial loss: 0.537875\n",
      "epoch 139; iter: 0; batch classifier loss: 0.372646; batch adversarial loss: 0.507204\n",
      "epoch 140; iter: 0; batch classifier loss: 0.388442; batch adversarial loss: 0.569256\n",
      "epoch 141; iter: 0; batch classifier loss: 0.447367; batch adversarial loss: 0.455933\n",
      "epoch 142; iter: 0; batch classifier loss: 0.350733; batch adversarial loss: 0.589818\n",
      "epoch 143; iter: 0; batch classifier loss: 0.345658; batch adversarial loss: 0.536591\n",
      "epoch 144; iter: 0; batch classifier loss: 0.468295; batch adversarial loss: 0.536727\n",
      "epoch 145; iter: 0; batch classifier loss: 0.356804; batch adversarial loss: 0.580250\n",
      "epoch 146; iter: 0; batch classifier loss: 0.317402; batch adversarial loss: 0.529711\n",
      "epoch 147; iter: 0; batch classifier loss: 0.391444; batch adversarial loss: 0.687392\n",
      "epoch 148; iter: 0; batch classifier loss: 0.251170; batch adversarial loss: 0.534337\n",
      "epoch 149; iter: 0; batch classifier loss: 0.369129; batch adversarial loss: 0.615801\n",
      "epoch 150; iter: 0; batch classifier loss: 0.480487; batch adversarial loss: 0.526097\n",
      "epoch 151; iter: 0; batch classifier loss: 0.337473; batch adversarial loss: 0.500275\n",
      "epoch 152; iter: 0; batch classifier loss: 0.359508; batch adversarial loss: 0.537135\n",
      "epoch 153; iter: 0; batch classifier loss: 0.344545; batch adversarial loss: 0.516598\n",
      "epoch 154; iter: 0; batch classifier loss: 0.378887; batch adversarial loss: 0.544652\n",
      "epoch 155; iter: 0; batch classifier loss: 0.333045; batch adversarial loss: 0.480194\n",
      "epoch 156; iter: 0; batch classifier loss: 0.342122; batch adversarial loss: 0.480714\n",
      "epoch 157; iter: 0; batch classifier loss: 0.323039; batch adversarial loss: 0.571591\n",
      "epoch 158; iter: 0; batch classifier loss: 0.391102; batch adversarial loss: 0.517643\n",
      "epoch 159; iter: 0; batch classifier loss: 0.442858; batch adversarial loss: 0.640178\n",
      "epoch 160; iter: 0; batch classifier loss: 0.354032; batch adversarial loss: 0.596132\n",
      "epoch 161; iter: 0; batch classifier loss: 0.406811; batch adversarial loss: 0.600809\n",
      "epoch 162; iter: 0; batch classifier loss: 0.358824; batch adversarial loss: 0.507821\n",
      "epoch 163; iter: 0; batch classifier loss: 0.356709; batch adversarial loss: 0.562771\n",
      "epoch 164; iter: 0; batch classifier loss: 0.344265; batch adversarial loss: 0.580466\n",
      "epoch 165; iter: 0; batch classifier loss: 0.331661; batch adversarial loss: 0.515595\n",
      "epoch 166; iter: 0; batch classifier loss: 0.392672; batch adversarial loss: 0.517457\n",
      "epoch 167; iter: 0; batch classifier loss: 0.380706; batch adversarial loss: 0.481341\n",
      "epoch 168; iter: 0; batch classifier loss: 0.299523; batch adversarial loss: 0.506447\n",
      "epoch 169; iter: 0; batch classifier loss: 0.320321; batch adversarial loss: 0.490793\n",
      "epoch 170; iter: 0; batch classifier loss: 0.390890; batch adversarial loss: 0.517188\n",
      "epoch 171; iter: 0; batch classifier loss: 0.421586; batch adversarial loss: 0.501254\n",
      "epoch 172; iter: 0; batch classifier loss: 0.270401; batch adversarial loss: 0.551307\n",
      "epoch 173; iter: 0; batch classifier loss: 0.385822; batch adversarial loss: 0.553745\n",
      "epoch 174; iter: 0; batch classifier loss: 0.322859; batch adversarial loss: 0.492735\n",
      "epoch 175; iter: 0; batch classifier loss: 0.508566; batch adversarial loss: 0.524366\n",
      "epoch 176; iter: 0; batch classifier loss: 0.324203; batch adversarial loss: 0.517479\n",
      "epoch 177; iter: 0; batch classifier loss: 0.316152; batch adversarial loss: 0.536927\n",
      "epoch 178; iter: 0; batch classifier loss: 0.348538; batch adversarial loss: 0.515858\n",
      "epoch 179; iter: 0; batch classifier loss: 0.294189; batch adversarial loss: 0.563780\n",
      "epoch 180; iter: 0; batch classifier loss: 0.284234; batch adversarial loss: 0.552229\n",
      "epoch 181; iter: 0; batch classifier loss: 0.358517; batch adversarial loss: 0.563314\n",
      "epoch 182; iter: 0; batch classifier loss: 0.415441; batch adversarial loss: 0.580559\n",
      "epoch 183; iter: 0; batch classifier loss: 0.390204; batch adversarial loss: 0.464301\n",
      "epoch 184; iter: 0; batch classifier loss: 0.418795; batch adversarial loss: 0.597138\n",
      "epoch 185; iter: 0; batch classifier loss: 0.293825; batch adversarial loss: 0.499571\n",
      "epoch 186; iter: 0; batch classifier loss: 0.331072; batch adversarial loss: 0.590533\n",
      "epoch 187; iter: 0; batch classifier loss: 0.361878; batch adversarial loss: 0.635456\n",
      "epoch 188; iter: 0; batch classifier loss: 0.351444; batch adversarial loss: 0.562714\n",
      "epoch 189; iter: 0; batch classifier loss: 0.409004; batch adversarial loss: 0.599790\n",
      "epoch 190; iter: 0; batch classifier loss: 0.426263; batch adversarial loss: 0.607491\n",
      "epoch 191; iter: 0; batch classifier loss: 0.313055; batch adversarial loss: 0.509225\n",
      "epoch 192; iter: 0; batch classifier loss: 0.317722; batch adversarial loss: 0.596243\n",
      "epoch 193; iter: 0; batch classifier loss: 0.417906; batch adversarial loss: 0.525109\n",
      "epoch 194; iter: 0; batch classifier loss: 0.315712; batch adversarial loss: 0.490775\n",
      "epoch 195; iter: 0; batch classifier loss: 0.387781; batch adversarial loss: 0.508922\n",
      "epoch 196; iter: 0; batch classifier loss: 0.323366; batch adversarial loss: 0.624371\n",
      "epoch 197; iter: 0; batch classifier loss: 0.318601; batch adversarial loss: 0.562948\n",
      "epoch 198; iter: 0; batch classifier loss: 0.418330; batch adversarial loss: 0.454451\n",
      "epoch 199; iter: 0; batch classifier loss: 0.281797; batch adversarial loss: 0.472504\n",
      "epoch 0; iter: 0; batch classifier loss: 0.705775; batch adversarial loss: 0.623721\n",
      "epoch 1; iter: 0; batch classifier loss: 0.661811; batch adversarial loss: 0.658891\n",
      "epoch 2; iter: 0; batch classifier loss: 0.666500; batch adversarial loss: 0.665183\n",
      "epoch 3; iter: 0; batch classifier loss: 0.597492; batch adversarial loss: 0.689102\n",
      "epoch 4; iter: 0; batch classifier loss: 0.537116; batch adversarial loss: 0.619536\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5; iter: 0; batch classifier loss: 0.590221; batch adversarial loss: 0.689361\n",
      "epoch 6; iter: 0; batch classifier loss: 0.660274; batch adversarial loss: 0.672491\n",
      "epoch 7; iter: 0; batch classifier loss: 0.568768; batch adversarial loss: 0.618405\n",
      "epoch 8; iter: 0; batch classifier loss: 0.552951; batch adversarial loss: 0.641377\n",
      "epoch 9; iter: 0; batch classifier loss: 0.612729; batch adversarial loss: 0.588789\n",
      "epoch 10; iter: 0; batch classifier loss: 0.651489; batch adversarial loss: 0.583706\n",
      "epoch 11; iter: 0; batch classifier loss: 0.503388; batch adversarial loss: 0.606233\n",
      "epoch 12; iter: 0; batch classifier loss: 0.564754; batch adversarial loss: 0.578489\n",
      "epoch 13; iter: 0; batch classifier loss: 0.504487; batch adversarial loss: 0.567703\n",
      "epoch 14; iter: 0; batch classifier loss: 0.526826; batch adversarial loss: 0.565867\n",
      "epoch 15; iter: 0; batch classifier loss: 0.475898; batch adversarial loss: 0.568026\n",
      "epoch 16; iter: 0; batch classifier loss: 0.521103; batch adversarial loss: 0.578208\n",
      "epoch 17; iter: 0; batch classifier loss: 0.472981; batch adversarial loss: 0.540344\n",
      "epoch 18; iter: 0; batch classifier loss: 0.543229; batch adversarial loss: 0.541165\n",
      "epoch 19; iter: 0; batch classifier loss: 0.528002; batch adversarial loss: 0.521188\n",
      "epoch 20; iter: 0; batch classifier loss: 0.448846; batch adversarial loss: 0.535380\n",
      "epoch 21; iter: 0; batch classifier loss: 0.472398; batch adversarial loss: 0.517535\n",
      "epoch 22; iter: 0; batch classifier loss: 0.457608; batch adversarial loss: 0.581865\n",
      "epoch 23; iter: 0; batch classifier loss: 0.503611; batch adversarial loss: 0.564101\n",
      "epoch 24; iter: 0; batch classifier loss: 0.444902; batch adversarial loss: 0.539291\n",
      "epoch 25; iter: 0; batch classifier loss: 0.476859; batch adversarial loss: 0.563693\n",
      "epoch 26; iter: 0; batch classifier loss: 0.470936; batch adversarial loss: 0.505570\n",
      "epoch 27; iter: 0; batch classifier loss: 0.538574; batch adversarial loss: 0.553781\n",
      "epoch 28; iter: 0; batch classifier loss: 0.461456; batch adversarial loss: 0.570540\n",
      "epoch 29; iter: 0; batch classifier loss: 0.457370; batch adversarial loss: 0.579915\n",
      "epoch 30; iter: 0; batch classifier loss: 0.441083; batch adversarial loss: 0.545193\n",
      "epoch 31; iter: 0; batch classifier loss: 0.355372; batch adversarial loss: 0.570886\n",
      "epoch 32; iter: 0; batch classifier loss: 0.454894; batch adversarial loss: 0.518024\n",
      "epoch 33; iter: 0; batch classifier loss: 0.472359; batch adversarial loss: 0.482343\n",
      "epoch 34; iter: 0; batch classifier loss: 0.439634; batch adversarial loss: 0.544843\n",
      "epoch 35; iter: 0; batch classifier loss: 0.423316; batch adversarial loss: 0.535222\n",
      "epoch 36; iter: 0; batch classifier loss: 0.495537; batch adversarial loss: 0.498643\n",
      "epoch 37; iter: 0; batch classifier loss: 0.523275; batch adversarial loss: 0.526629\n",
      "epoch 38; iter: 0; batch classifier loss: 0.487151; batch adversarial loss: 0.581669\n",
      "epoch 39; iter: 0; batch classifier loss: 0.500830; batch adversarial loss: 0.508955\n",
      "epoch 40; iter: 0; batch classifier loss: 0.473747; batch adversarial loss: 0.590105\n",
      "epoch 41; iter: 0; batch classifier loss: 0.470688; batch adversarial loss: 0.461836\n",
      "epoch 42; iter: 0; batch classifier loss: 0.456443; batch adversarial loss: 0.599713\n",
      "epoch 43; iter: 0; batch classifier loss: 0.394454; batch adversarial loss: 0.526592\n",
      "epoch 44; iter: 0; batch classifier loss: 0.397703; batch adversarial loss: 0.526102\n",
      "epoch 45; iter: 0; batch classifier loss: 0.408946; batch adversarial loss: 0.553795\n",
      "epoch 46; iter: 0; batch classifier loss: 0.439198; batch adversarial loss: 0.536884\n",
      "epoch 47; iter: 0; batch classifier loss: 0.438179; batch adversarial loss: 0.571479\n",
      "epoch 48; iter: 0; batch classifier loss: 0.461951; batch adversarial loss: 0.489849\n",
      "epoch 49; iter: 0; batch classifier loss: 0.403417; batch adversarial loss: 0.600131\n",
      "epoch 50; iter: 0; batch classifier loss: 0.452560; batch adversarial loss: 0.478023\n",
      "epoch 51; iter: 0; batch classifier loss: 0.467170; batch adversarial loss: 0.544929\n",
      "epoch 52; iter: 0; batch classifier loss: 0.427806; batch adversarial loss: 0.452648\n",
      "epoch 53; iter: 0; batch classifier loss: 0.353973; batch adversarial loss: 0.563947\n",
      "epoch 54; iter: 0; batch classifier loss: 0.410152; batch adversarial loss: 0.573309\n",
      "epoch 55; iter: 0; batch classifier loss: 0.395472; batch adversarial loss: 0.507869\n",
      "epoch 56; iter: 0; batch classifier loss: 0.418182; batch adversarial loss: 0.587588\n",
      "epoch 57; iter: 0; batch classifier loss: 0.431290; batch adversarial loss: 0.462473\n",
      "epoch 58; iter: 0; batch classifier loss: 0.431937; batch adversarial loss: 0.545872\n",
      "epoch 59; iter: 0; batch classifier loss: 0.402600; batch adversarial loss: 0.500184\n",
      "epoch 60; iter: 0; batch classifier loss: 0.373260; batch adversarial loss: 0.564051\n",
      "epoch 61; iter: 0; batch classifier loss: 0.427694; batch adversarial loss: 0.572867\n",
      "epoch 62; iter: 0; batch classifier loss: 0.377894; batch adversarial loss: 0.563180\n",
      "epoch 63; iter: 0; batch classifier loss: 0.394356; batch adversarial loss: 0.571418\n",
      "epoch 64; iter: 0; batch classifier loss: 0.330108; batch adversarial loss: 0.526544\n",
      "epoch 65; iter: 0; batch classifier loss: 0.435870; batch adversarial loss: 0.496990\n",
      "epoch 66; iter: 0; batch classifier loss: 0.395613; batch adversarial loss: 0.551685\n",
      "epoch 67; iter: 0; batch classifier loss: 0.476549; batch adversarial loss: 0.537972\n",
      "epoch 68; iter: 0; batch classifier loss: 0.427533; batch adversarial loss: 0.543554\n",
      "epoch 69; iter: 0; batch classifier loss: 0.426279; batch adversarial loss: 0.613406\n",
      "epoch 70; iter: 0; batch classifier loss: 0.473226; batch adversarial loss: 0.533143\n",
      "epoch 71; iter: 0; batch classifier loss: 0.461181; batch adversarial loss: 0.504526\n",
      "epoch 72; iter: 0; batch classifier loss: 0.425504; batch adversarial loss: 0.512965\n",
      "epoch 73; iter: 0; batch classifier loss: 0.374311; batch adversarial loss: 0.548675\n",
      "epoch 74; iter: 0; batch classifier loss: 0.310241; batch adversarial loss: 0.567231\n",
      "epoch 75; iter: 0; batch classifier loss: 0.461954; batch adversarial loss: 0.629658\n",
      "epoch 76; iter: 0; batch classifier loss: 0.391707; batch adversarial loss: 0.556451\n",
      "epoch 77; iter: 0; batch classifier loss: 0.449948; batch adversarial loss: 0.566033\n",
      "epoch 78; iter: 0; batch classifier loss: 0.448370; batch adversarial loss: 0.478850\n",
      "epoch 79; iter: 0; batch classifier loss: 0.405709; batch adversarial loss: 0.572778\n",
      "epoch 80; iter: 0; batch classifier loss: 0.373175; batch adversarial loss: 0.563275\n",
      "epoch 81; iter: 0; batch classifier loss: 0.394634; batch adversarial loss: 0.553413\n",
      "epoch 82; iter: 0; batch classifier loss: 0.371601; batch adversarial loss: 0.515778\n",
      "epoch 83; iter: 0; batch classifier loss: 0.391340; batch adversarial loss: 0.572254\n",
      "epoch 84; iter: 0; batch classifier loss: 0.462471; batch adversarial loss: 0.507116\n",
      "epoch 85; iter: 0; batch classifier loss: 0.416293; batch adversarial loss: 0.525048\n",
      "epoch 86; iter: 0; batch classifier loss: 0.356238; batch adversarial loss: 0.579476\n",
      "epoch 87; iter: 0; batch classifier loss: 0.390293; batch adversarial loss: 0.480625\n",
      "epoch 88; iter: 0; batch classifier loss: 0.416214; batch adversarial loss: 0.553652\n",
      "epoch 89; iter: 0; batch classifier loss: 0.465344; batch adversarial loss: 0.518007\n",
      "epoch 90; iter: 0; batch classifier loss: 0.413357; batch adversarial loss: 0.570313\n",
      "epoch 91; iter: 0; batch classifier loss: 0.404826; batch adversarial loss: 0.527812\n",
      "epoch 92; iter: 0; batch classifier loss: 0.345277; batch adversarial loss: 0.536811\n",
      "epoch 93; iter: 0; batch classifier loss: 0.443760; batch adversarial loss: 0.589419\n",
      "epoch 94; iter: 0; batch classifier loss: 0.426439; batch adversarial loss: 0.525873\n",
      "epoch 95; iter: 0; batch classifier loss: 0.473904; batch adversarial loss: 0.563848\n",
      "epoch 96; iter: 0; batch classifier loss: 0.311231; batch adversarial loss: 0.442193\n",
      "epoch 97; iter: 0; batch classifier loss: 0.388351; batch adversarial loss: 0.534568\n",
      "epoch 98; iter: 0; batch classifier loss: 0.362254; batch adversarial loss: 0.580401\n",
      "epoch 99; iter: 0; batch classifier loss: 0.341671; batch adversarial loss: 0.525564\n",
      "epoch 100; iter: 0; batch classifier loss: 0.335763; batch adversarial loss: 0.459893\n",
      "epoch 101; iter: 0; batch classifier loss: 0.340873; batch adversarial loss: 0.536169\n",
      "epoch 102; iter: 0; batch classifier loss: 0.405043; batch adversarial loss: 0.499513\n",
      "epoch 103; iter: 0; batch classifier loss: 0.408270; batch adversarial loss: 0.571968\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 104; iter: 0; batch classifier loss: 0.383670; batch adversarial loss: 0.591565\n",
      "epoch 105; iter: 0; batch classifier loss: 0.340376; batch adversarial loss: 0.516850\n",
      "epoch 106; iter: 0; batch classifier loss: 0.343729; batch adversarial loss: 0.509657\n",
      "epoch 107; iter: 0; batch classifier loss: 0.433414; batch adversarial loss: 0.580239\n",
      "epoch 108; iter: 0; batch classifier loss: 0.287678; batch adversarial loss: 0.524897\n",
      "epoch 109; iter: 0; batch classifier loss: 0.407096; batch adversarial loss: 0.487693\n",
      "epoch 110; iter: 0; batch classifier loss: 0.347515; batch adversarial loss: 0.563740\n",
      "epoch 111; iter: 0; batch classifier loss: 0.354925; batch adversarial loss: 0.536273\n",
      "epoch 112; iter: 0; batch classifier loss: 0.359828; batch adversarial loss: 0.535320\n",
      "epoch 113; iter: 0; batch classifier loss: 0.418813; batch adversarial loss: 0.572371\n",
      "epoch 114; iter: 0; batch classifier loss: 0.330735; batch adversarial loss: 0.614416\n",
      "epoch 115; iter: 0; batch classifier loss: 0.371706; batch adversarial loss: 0.507368\n",
      "epoch 116; iter: 0; batch classifier loss: 0.423606; batch adversarial loss: 0.500461\n",
      "epoch 117; iter: 0; batch classifier loss: 0.436075; batch adversarial loss: 0.628036\n",
      "epoch 118; iter: 0; batch classifier loss: 0.346967; batch adversarial loss: 0.565989\n",
      "epoch 119; iter: 0; batch classifier loss: 0.371259; batch adversarial loss: 0.534437\n",
      "epoch 120; iter: 0; batch classifier loss: 0.320667; batch adversarial loss: 0.514960\n",
      "epoch 121; iter: 0; batch classifier loss: 0.446211; batch adversarial loss: 0.450766\n",
      "epoch 122; iter: 0; batch classifier loss: 0.350632; batch adversarial loss: 0.571694\n",
      "epoch 123; iter: 0; batch classifier loss: 0.363181; batch adversarial loss: 0.451002\n",
      "epoch 124; iter: 0; batch classifier loss: 0.395956; batch adversarial loss: 0.571746\n",
      "epoch 125; iter: 0; batch classifier loss: 0.389458; batch adversarial loss: 0.562260\n",
      "epoch 126; iter: 0; batch classifier loss: 0.334572; batch adversarial loss: 0.523984\n",
      "epoch 127; iter: 0; batch classifier loss: 0.330537; batch adversarial loss: 0.588586\n",
      "epoch 128; iter: 0; batch classifier loss: 0.328904; batch adversarial loss: 0.638015\n",
      "epoch 129; iter: 0; batch classifier loss: 0.379654; batch adversarial loss: 0.580858\n",
      "epoch 130; iter: 0; batch classifier loss: 0.449734; batch adversarial loss: 0.517191\n",
      "epoch 131; iter: 0; batch classifier loss: 0.369885; batch adversarial loss: 0.534157\n",
      "epoch 132; iter: 0; batch classifier loss: 0.274016; batch adversarial loss: 0.565300\n",
      "epoch 133; iter: 0; batch classifier loss: 0.339383; batch adversarial loss: 0.564640\n",
      "epoch 134; iter: 0; batch classifier loss: 0.399852; batch adversarial loss: 0.553269\n",
      "epoch 135; iter: 0; batch classifier loss: 0.339838; batch adversarial loss: 0.554463\n",
      "epoch 136; iter: 0; batch classifier loss: 0.370262; batch adversarial loss: 0.598228\n",
      "epoch 137; iter: 0; batch classifier loss: 0.393121; batch adversarial loss: 0.518114\n",
      "epoch 138; iter: 0; batch classifier loss: 0.313443; batch adversarial loss: 0.534895\n",
      "epoch 139; iter: 0; batch classifier loss: 0.381975; batch adversarial loss: 0.527633\n",
      "epoch 140; iter: 0; batch classifier loss: 0.363949; batch adversarial loss: 0.570987\n",
      "epoch 141; iter: 0; batch classifier loss: 0.379234; batch adversarial loss: 0.519973\n",
      "epoch 142; iter: 0; batch classifier loss: 0.411957; batch adversarial loss: 0.513044\n",
      "epoch 143; iter: 0; batch classifier loss: 0.376314; batch adversarial loss: 0.529630\n",
      "epoch 144; iter: 0; batch classifier loss: 0.333484; batch adversarial loss: 0.584941\n",
      "epoch 145; iter: 0; batch classifier loss: 0.301292; batch adversarial loss: 0.543944\n",
      "epoch 146; iter: 0; batch classifier loss: 0.310628; batch adversarial loss: 0.500229\n",
      "epoch 147; iter: 0; batch classifier loss: 0.304397; batch adversarial loss: 0.534134\n",
      "epoch 148; iter: 0; batch classifier loss: 0.317054; batch adversarial loss: 0.573393\n",
      "epoch 149; iter: 0; batch classifier loss: 0.383193; batch adversarial loss: 0.491407\n",
      "epoch 150; iter: 0; batch classifier loss: 0.344685; batch adversarial loss: 0.560034\n",
      "epoch 151; iter: 0; batch classifier loss: 0.372053; batch adversarial loss: 0.470065\n",
      "epoch 152; iter: 0; batch classifier loss: 0.422240; batch adversarial loss: 0.460043\n",
      "epoch 153; iter: 0; batch classifier loss: 0.317204; batch adversarial loss: 0.564320\n",
      "epoch 154; iter: 0; batch classifier loss: 0.282741; batch adversarial loss: 0.589531\n",
      "epoch 155; iter: 0; batch classifier loss: 0.334350; batch adversarial loss: 0.487668\n",
      "epoch 156; iter: 0; batch classifier loss: 0.295442; batch adversarial loss: 0.479977\n",
      "epoch 157; iter: 0; batch classifier loss: 0.364882; batch adversarial loss: 0.505818\n",
      "epoch 158; iter: 0; batch classifier loss: 0.352582; batch adversarial loss: 0.555690\n",
      "epoch 159; iter: 0; batch classifier loss: 0.385740; batch adversarial loss: 0.486353\n",
      "epoch 160; iter: 0; batch classifier loss: 0.374274; batch adversarial loss: 0.519019\n",
      "epoch 161; iter: 0; batch classifier loss: 0.409650; batch adversarial loss: 0.488920\n",
      "epoch 162; iter: 0; batch classifier loss: 0.447337; batch adversarial loss: 0.545380\n",
      "epoch 163; iter: 0; batch classifier loss: 0.426190; batch adversarial loss: 0.536748\n",
      "epoch 164; iter: 0; batch classifier loss: 0.387134; batch adversarial loss: 0.521788\n",
      "epoch 165; iter: 0; batch classifier loss: 0.340396; batch adversarial loss: 0.609349\n",
      "epoch 166; iter: 0; batch classifier loss: 0.394846; batch adversarial loss: 0.569167\n",
      "epoch 167; iter: 0; batch classifier loss: 0.320328; batch adversarial loss: 0.498037\n",
      "epoch 168; iter: 0; batch classifier loss: 0.408183; batch adversarial loss: 0.572087\n",
      "epoch 169; iter: 0; batch classifier loss: 0.432185; batch adversarial loss: 0.590995\n",
      "epoch 170; iter: 0; batch classifier loss: 0.302006; batch adversarial loss: 0.496995\n",
      "epoch 171; iter: 0; batch classifier loss: 0.366269; batch adversarial loss: 0.545258\n",
      "epoch 172; iter: 0; batch classifier loss: 0.349470; batch adversarial loss: 0.587043\n",
      "epoch 173; iter: 0; batch classifier loss: 0.367053; batch adversarial loss: 0.459858\n",
      "epoch 174; iter: 0; batch classifier loss: 0.394663; batch adversarial loss: 0.560383\n",
      "epoch 175; iter: 0; batch classifier loss: 0.390950; batch adversarial loss: 0.543401\n",
      "epoch 176; iter: 0; batch classifier loss: 0.351061; batch adversarial loss: 0.517067\n",
      "epoch 177; iter: 0; batch classifier loss: 0.356190; batch adversarial loss: 0.605447\n",
      "epoch 178; iter: 0; batch classifier loss: 0.316949; batch adversarial loss: 0.538363\n",
      "epoch 179; iter: 0; batch classifier loss: 0.450757; batch adversarial loss: 0.569864\n",
      "epoch 180; iter: 0; batch classifier loss: 0.354887; batch adversarial loss: 0.487971\n",
      "epoch 181; iter: 0; batch classifier loss: 0.349512; batch adversarial loss: 0.459396\n",
      "epoch 182; iter: 0; batch classifier loss: 0.402685; batch adversarial loss: 0.536679\n",
      "epoch 183; iter: 0; batch classifier loss: 0.396129; batch adversarial loss: 0.523275\n",
      "epoch 184; iter: 0; batch classifier loss: 0.399340; batch adversarial loss: 0.643882\n",
      "epoch 185; iter: 0; batch classifier loss: 0.333242; batch adversarial loss: 0.598609\n",
      "epoch 186; iter: 0; batch classifier loss: 0.340354; batch adversarial loss: 0.538496\n",
      "epoch 187; iter: 0; batch classifier loss: 0.392993; batch adversarial loss: 0.653126\n",
      "epoch 188; iter: 0; batch classifier loss: 0.332857; batch adversarial loss: 0.547727\n",
      "epoch 189; iter: 0; batch classifier loss: 0.398470; batch adversarial loss: 0.500711\n",
      "epoch 190; iter: 0; batch classifier loss: 0.428320; batch adversarial loss: 0.526016\n",
      "epoch 191; iter: 0; batch classifier loss: 0.352773; batch adversarial loss: 0.589079\n",
      "epoch 192; iter: 0; batch classifier loss: 0.316425; batch adversarial loss: 0.545900\n",
      "epoch 193; iter: 0; batch classifier loss: 0.370277; batch adversarial loss: 0.545451\n",
      "epoch 194; iter: 0; batch classifier loss: 0.325563; batch adversarial loss: 0.564134\n",
      "epoch 195; iter: 0; batch classifier loss: 0.384238; batch adversarial loss: 0.532120\n",
      "epoch 196; iter: 0; batch classifier loss: 0.373297; batch adversarial loss: 0.506352\n",
      "epoch 197; iter: 0; batch classifier loss: 0.406161; batch adversarial loss: 0.452422\n",
      "epoch 198; iter: 0; batch classifier loss: 0.261314; batch adversarial loss: 0.619169\n",
      "epoch 199; iter: 0; batch classifier loss: 0.391756; batch adversarial loss: 0.535308\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.721656; batch adversarial loss: 0.641391\n",
      "epoch 1; iter: 0; batch classifier loss: 0.558139; batch adversarial loss: 0.647963\n",
      "epoch 2; iter: 0; batch classifier loss: 0.634275; batch adversarial loss: 0.619412\n",
      "epoch 3; iter: 0; batch classifier loss: 0.574751; batch adversarial loss: 0.635133\n",
      "epoch 4; iter: 0; batch classifier loss: 0.587649; batch adversarial loss: 0.684388\n",
      "epoch 5; iter: 0; batch classifier loss: 0.595597; batch adversarial loss: 0.611550\n",
      "epoch 6; iter: 0; batch classifier loss: 0.625959; batch adversarial loss: 0.601265\n",
      "epoch 7; iter: 0; batch classifier loss: 0.583033; batch adversarial loss: 0.612918\n",
      "epoch 8; iter: 0; batch classifier loss: 0.552600; batch adversarial loss: 0.569285\n",
      "epoch 9; iter: 0; batch classifier loss: 0.526023; batch adversarial loss: 0.595834\n",
      "epoch 10; iter: 0; batch classifier loss: 0.552696; batch adversarial loss: 0.605080\n",
      "epoch 11; iter: 0; batch classifier loss: 0.557096; batch adversarial loss: 0.545848\n",
      "epoch 12; iter: 0; batch classifier loss: 0.557863; batch adversarial loss: 0.565145\n",
      "epoch 13; iter: 0; batch classifier loss: 0.488456; batch adversarial loss: 0.556037\n",
      "epoch 14; iter: 0; batch classifier loss: 0.527474; batch adversarial loss: 0.578372\n",
      "epoch 15; iter: 0; batch classifier loss: 0.521450; batch adversarial loss: 0.591144\n",
      "epoch 16; iter: 0; batch classifier loss: 0.457544; batch adversarial loss: 0.597235\n",
      "epoch 17; iter: 0; batch classifier loss: 0.560448; batch adversarial loss: 0.559195\n",
      "epoch 18; iter: 0; batch classifier loss: 0.528025; batch adversarial loss: 0.582705\n",
      "epoch 19; iter: 0; batch classifier loss: 0.504613; batch adversarial loss: 0.567083\n",
      "epoch 20; iter: 0; batch classifier loss: 0.534129; batch adversarial loss: 0.539942\n",
      "epoch 21; iter: 0; batch classifier loss: 0.506661; batch adversarial loss: 0.593828\n",
      "epoch 22; iter: 0; batch classifier loss: 0.516559; batch adversarial loss: 0.494253\n",
      "epoch 23; iter: 0; batch classifier loss: 0.465109; batch adversarial loss: 0.507988\n",
      "epoch 24; iter: 0; batch classifier loss: 0.484533; batch adversarial loss: 0.587343\n",
      "epoch 25; iter: 0; batch classifier loss: 0.501104; batch adversarial loss: 0.519302\n",
      "epoch 26; iter: 0; batch classifier loss: 0.461844; batch adversarial loss: 0.524747\n",
      "epoch 27; iter: 0; batch classifier loss: 0.505784; batch adversarial loss: 0.532263\n",
      "epoch 28; iter: 0; batch classifier loss: 0.439018; batch adversarial loss: 0.494210\n",
      "epoch 29; iter: 0; batch classifier loss: 0.495641; batch adversarial loss: 0.563627\n",
      "epoch 30; iter: 0; batch classifier loss: 0.444562; batch adversarial loss: 0.588496\n",
      "epoch 31; iter: 0; batch classifier loss: 0.444239; batch adversarial loss: 0.569101\n",
      "epoch 32; iter: 0; batch classifier loss: 0.422623; batch adversarial loss: 0.528898\n",
      "epoch 33; iter: 0; batch classifier loss: 0.481072; batch adversarial loss: 0.528579\n",
      "epoch 34; iter: 0; batch classifier loss: 0.393684; batch adversarial loss: 0.553380\n",
      "epoch 35; iter: 0; batch classifier loss: 0.403608; batch adversarial loss: 0.516359\n",
      "epoch 36; iter: 0; batch classifier loss: 0.444365; batch adversarial loss: 0.524546\n",
      "epoch 37; iter: 0; batch classifier loss: 0.494692; batch adversarial loss: 0.619702\n",
      "epoch 38; iter: 0; batch classifier loss: 0.436687; batch adversarial loss: 0.642031\n",
      "epoch 39; iter: 0; batch classifier loss: 0.403289; batch adversarial loss: 0.590992\n",
      "epoch 40; iter: 0; batch classifier loss: 0.417282; batch adversarial loss: 0.587048\n",
      "epoch 41; iter: 0; batch classifier loss: 0.418362; batch adversarial loss: 0.579204\n",
      "epoch 42; iter: 0; batch classifier loss: 0.459227; batch adversarial loss: 0.619945\n",
      "epoch 43; iter: 0; batch classifier loss: 0.442307; batch adversarial loss: 0.570101\n",
      "epoch 44; iter: 0; batch classifier loss: 0.423634; batch adversarial loss: 0.597101\n",
      "epoch 45; iter: 0; batch classifier loss: 0.527036; batch adversarial loss: 0.563053\n",
      "epoch 46; iter: 0; batch classifier loss: 0.437556; batch adversarial loss: 0.546857\n",
      "epoch 47; iter: 0; batch classifier loss: 0.460614; batch adversarial loss: 0.614832\n",
      "epoch 48; iter: 0; batch classifier loss: 0.443393; batch adversarial loss: 0.641535\n",
      "epoch 49; iter: 0; batch classifier loss: 0.350364; batch adversarial loss: 0.571556\n",
      "epoch 50; iter: 0; batch classifier loss: 0.407477; batch adversarial loss: 0.545480\n",
      "epoch 51; iter: 0; batch classifier loss: 0.333559; batch adversarial loss: 0.597847\n",
      "epoch 52; iter: 0; batch classifier loss: 0.479684; batch adversarial loss: 0.552106\n",
      "epoch 53; iter: 0; batch classifier loss: 0.405536; batch adversarial loss: 0.545949\n",
      "epoch 54; iter: 0; batch classifier loss: 0.356595; batch adversarial loss: 0.534423\n",
      "epoch 55; iter: 0; batch classifier loss: 0.434579; batch adversarial loss: 0.508749\n",
      "epoch 56; iter: 0; batch classifier loss: 0.398416; batch adversarial loss: 0.598264\n",
      "epoch 57; iter: 0; batch classifier loss: 0.439522; batch adversarial loss: 0.499878\n",
      "epoch 58; iter: 0; batch classifier loss: 0.371562; batch adversarial loss: 0.587066\n",
      "epoch 59; iter: 0; batch classifier loss: 0.370389; batch adversarial loss: 0.514600\n",
      "epoch 60; iter: 0; batch classifier loss: 0.417028; batch adversarial loss: 0.481122\n",
      "epoch 61; iter: 0; batch classifier loss: 0.398314; batch adversarial loss: 0.580120\n",
      "epoch 62; iter: 0; batch classifier loss: 0.422303; batch adversarial loss: 0.492358\n",
      "epoch 63; iter: 0; batch classifier loss: 0.381222; batch adversarial loss: 0.460064\n",
      "epoch 64; iter: 0; batch classifier loss: 0.397514; batch adversarial loss: 0.545038\n",
      "epoch 65; iter: 0; batch classifier loss: 0.377380; batch adversarial loss: 0.527056\n",
      "epoch 66; iter: 0; batch classifier loss: 0.407788; batch adversarial loss: 0.481487\n",
      "epoch 67; iter: 0; batch classifier loss: 0.401376; batch adversarial loss: 0.522334\n",
      "epoch 68; iter: 0; batch classifier loss: 0.421747; batch adversarial loss: 0.539034\n",
      "epoch 69; iter: 0; batch classifier loss: 0.473239; batch adversarial loss: 0.510393\n",
      "epoch 70; iter: 0; batch classifier loss: 0.414246; batch adversarial loss: 0.571995\n",
      "epoch 71; iter: 0; batch classifier loss: 0.413504; batch adversarial loss: 0.589059\n",
      "epoch 72; iter: 0; batch classifier loss: 0.431991; batch adversarial loss: 0.475915\n",
      "epoch 73; iter: 0; batch classifier loss: 0.419817; batch adversarial loss: 0.667221\n",
      "epoch 74; iter: 0; batch classifier loss: 0.382894; batch adversarial loss: 0.501463\n",
      "epoch 75; iter: 0; batch classifier loss: 0.395345; batch adversarial loss: 0.605679\n",
      "epoch 76; iter: 0; batch classifier loss: 0.355395; batch adversarial loss: 0.579860\n",
      "epoch 77; iter: 0; batch classifier loss: 0.342982; batch adversarial loss: 0.579982\n",
      "epoch 78; iter: 0; batch classifier loss: 0.406832; batch adversarial loss: 0.544820\n",
      "epoch 79; iter: 0; batch classifier loss: 0.402402; batch adversarial loss: 0.544661\n",
      "epoch 80; iter: 0; batch classifier loss: 0.383473; batch adversarial loss: 0.455892\n",
      "epoch 81; iter: 0; batch classifier loss: 0.396499; batch adversarial loss: 0.625257\n",
      "epoch 82; iter: 0; batch classifier loss: 0.422753; batch adversarial loss: 0.544083\n",
      "epoch 83; iter: 0; batch classifier loss: 0.380657; batch adversarial loss: 0.569711\n",
      "epoch 84; iter: 0; batch classifier loss: 0.375331; batch adversarial loss: 0.509451\n",
      "epoch 85; iter: 0; batch classifier loss: 0.395434; batch adversarial loss: 0.600176\n",
      "epoch 86; iter: 0; batch classifier loss: 0.418761; batch adversarial loss: 0.496245\n",
      "epoch 87; iter: 0; batch classifier loss: 0.455266; batch adversarial loss: 0.561492\n",
      "epoch 88; iter: 0; batch classifier loss: 0.448471; batch adversarial loss: 0.526045\n",
      "epoch 89; iter: 0; batch classifier loss: 0.470275; batch adversarial loss: 0.581786\n",
      "epoch 90; iter: 0; batch classifier loss: 0.361203; batch adversarial loss: 0.526939\n",
      "epoch 91; iter: 0; batch classifier loss: 0.394548; batch adversarial loss: 0.473774\n",
      "epoch 92; iter: 0; batch classifier loss: 0.332109; batch adversarial loss: 0.562732\n",
      "epoch 93; iter: 0; batch classifier loss: 0.394433; batch adversarial loss: 0.518994\n",
      "epoch 94; iter: 0; batch classifier loss: 0.381568; batch adversarial loss: 0.606371\n",
      "epoch 95; iter: 0; batch classifier loss: 0.399440; batch adversarial loss: 0.570148\n",
      "epoch 96; iter: 0; batch classifier loss: 0.426131; batch adversarial loss: 0.535823\n",
      "epoch 97; iter: 0; batch classifier loss: 0.370140; batch adversarial loss: 0.634161\n",
      "epoch 98; iter: 0; batch classifier loss: 0.356934; batch adversarial loss: 0.519072\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 99; iter: 0; batch classifier loss: 0.382518; batch adversarial loss: 0.580028\n",
      "epoch 100; iter: 0; batch classifier loss: 0.314344; batch adversarial loss: 0.527468\n",
      "epoch 101; iter: 0; batch classifier loss: 0.371058; batch adversarial loss: 0.553688\n",
      "epoch 102; iter: 0; batch classifier loss: 0.347683; batch adversarial loss: 0.536122\n",
      "epoch 103; iter: 0; batch classifier loss: 0.295984; batch adversarial loss: 0.597339\n",
      "epoch 104; iter: 0; batch classifier loss: 0.454270; batch adversarial loss: 0.527194\n",
      "epoch 105; iter: 0; batch classifier loss: 0.459494; batch adversarial loss: 0.580201\n",
      "epoch 106; iter: 0; batch classifier loss: 0.371308; batch adversarial loss: 0.518075\n",
      "epoch 107; iter: 0; batch classifier loss: 0.350526; batch adversarial loss: 0.535688\n",
      "epoch 108; iter: 0; batch classifier loss: 0.415232; batch adversarial loss: 0.517430\n",
      "epoch 109; iter: 0; batch classifier loss: 0.424175; batch adversarial loss: 0.562449\n",
      "epoch 110; iter: 0; batch classifier loss: 0.304843; batch adversarial loss: 0.536363\n",
      "epoch 111; iter: 0; batch classifier loss: 0.372952; batch adversarial loss: 0.607905\n",
      "epoch 112; iter: 0; batch classifier loss: 0.386822; batch adversarial loss: 0.525230\n",
      "epoch 113; iter: 0; batch classifier loss: 0.380061; batch adversarial loss: 0.579312\n",
      "epoch 114; iter: 0; batch classifier loss: 0.334299; batch adversarial loss: 0.519219\n",
      "epoch 115; iter: 0; batch classifier loss: 0.343107; batch adversarial loss: 0.589347\n",
      "epoch 116; iter: 0; batch classifier loss: 0.355119; batch adversarial loss: 0.581632\n",
      "epoch 117; iter: 0; batch classifier loss: 0.377415; batch adversarial loss: 0.535202\n",
      "epoch 118; iter: 0; batch classifier loss: 0.381801; batch adversarial loss: 0.591550\n",
      "epoch 119; iter: 0; batch classifier loss: 0.420318; batch adversarial loss: 0.490307\n",
      "epoch 120; iter: 0; batch classifier loss: 0.433298; batch adversarial loss: 0.527107\n",
      "epoch 121; iter: 0; batch classifier loss: 0.350101; batch adversarial loss: 0.525553\n",
      "epoch 122; iter: 0; batch classifier loss: 0.386840; batch adversarial loss: 0.525713\n",
      "epoch 123; iter: 0; batch classifier loss: 0.415366; batch adversarial loss: 0.535810\n",
      "epoch 124; iter: 0; batch classifier loss: 0.347543; batch adversarial loss: 0.545785\n",
      "epoch 125; iter: 0; batch classifier loss: 0.338083; batch adversarial loss: 0.529387\n",
      "epoch 126; iter: 0; batch classifier loss: 0.419484; batch adversarial loss: 0.578121\n",
      "epoch 127; iter: 0; batch classifier loss: 0.394283; batch adversarial loss: 0.527108\n",
      "epoch 128; iter: 0; batch classifier loss: 0.410991; batch adversarial loss: 0.461293\n",
      "epoch 129; iter: 0; batch classifier loss: 0.335318; batch adversarial loss: 0.531846\n",
      "epoch 130; iter: 0; batch classifier loss: 0.342064; batch adversarial loss: 0.580148\n",
      "epoch 131; iter: 0; batch classifier loss: 0.426386; batch adversarial loss: 0.556586\n",
      "epoch 132; iter: 0; batch classifier loss: 0.388034; batch adversarial loss: 0.570563\n",
      "epoch 133; iter: 0; batch classifier loss: 0.374798; batch adversarial loss: 0.552313\n",
      "epoch 134; iter: 0; batch classifier loss: 0.421205; batch adversarial loss: 0.580884\n",
      "epoch 135; iter: 0; batch classifier loss: 0.372716; batch adversarial loss: 0.498699\n",
      "epoch 136; iter: 0; batch classifier loss: 0.414827; batch adversarial loss: 0.612638\n",
      "epoch 137; iter: 0; batch classifier loss: 0.353827; batch adversarial loss: 0.553878\n",
      "epoch 138; iter: 0; batch classifier loss: 0.379898; batch adversarial loss: 0.558693\n",
      "epoch 139; iter: 0; batch classifier loss: 0.449333; batch adversarial loss: 0.516552\n",
      "epoch 140; iter: 0; batch classifier loss: 0.355086; batch adversarial loss: 0.544600\n",
      "epoch 141; iter: 0; batch classifier loss: 0.353764; batch adversarial loss: 0.528197\n",
      "epoch 142; iter: 0; batch classifier loss: 0.399486; batch adversarial loss: 0.538307\n",
      "epoch 143; iter: 0; batch classifier loss: 0.390093; batch adversarial loss: 0.552523\n",
      "epoch 144; iter: 0; batch classifier loss: 0.379659; batch adversarial loss: 0.551785\n",
      "epoch 145; iter: 0; batch classifier loss: 0.333338; batch adversarial loss: 0.563206\n",
      "epoch 146; iter: 0; batch classifier loss: 0.326771; batch adversarial loss: 0.554438\n",
      "epoch 147; iter: 0; batch classifier loss: 0.394224; batch adversarial loss: 0.546411\n",
      "epoch 148; iter: 0; batch classifier loss: 0.346700; batch adversarial loss: 0.578603\n",
      "epoch 149; iter: 0; batch classifier loss: 0.395292; batch adversarial loss: 0.597782\n",
      "epoch 150; iter: 0; batch classifier loss: 0.321243; batch adversarial loss: 0.526907\n",
      "epoch 151; iter: 0; batch classifier loss: 0.484615; batch adversarial loss: 0.491080\n",
      "epoch 152; iter: 0; batch classifier loss: 0.328535; batch adversarial loss: 0.615085\n",
      "epoch 153; iter: 0; batch classifier loss: 0.349364; batch adversarial loss: 0.560555\n",
      "epoch 154; iter: 0; batch classifier loss: 0.345503; batch adversarial loss: 0.528036\n",
      "epoch 155; iter: 0; batch classifier loss: 0.361344; batch adversarial loss: 0.518485\n",
      "epoch 156; iter: 0; batch classifier loss: 0.380826; batch adversarial loss: 0.589392\n",
      "epoch 157; iter: 0; batch classifier loss: 0.328020; batch adversarial loss: 0.562423\n",
      "epoch 158; iter: 0; batch classifier loss: 0.329310; batch adversarial loss: 0.501411\n",
      "epoch 159; iter: 0; batch classifier loss: 0.473615; batch adversarial loss: 0.606537\n",
      "epoch 160; iter: 0; batch classifier loss: 0.401522; batch adversarial loss: 0.588234\n",
      "epoch 161; iter: 0; batch classifier loss: 0.414075; batch adversarial loss: 0.535226\n",
      "epoch 162; iter: 0; batch classifier loss: 0.358959; batch adversarial loss: 0.527344\n",
      "epoch 163; iter: 0; batch classifier loss: 0.317892; batch adversarial loss: 0.598575\n",
      "epoch 164; iter: 0; batch classifier loss: 0.480966; batch adversarial loss: 0.581671\n",
      "epoch 165; iter: 0; batch classifier loss: 0.392164; batch adversarial loss: 0.499442\n",
      "epoch 166; iter: 0; batch classifier loss: 0.312489; batch adversarial loss: 0.553678\n",
      "epoch 167; iter: 0; batch classifier loss: 0.355816; batch adversarial loss: 0.598798\n",
      "epoch 168; iter: 0; batch classifier loss: 0.342866; batch adversarial loss: 0.447683\n",
      "epoch 169; iter: 0; batch classifier loss: 0.458181; batch adversarial loss: 0.571156\n",
      "epoch 170; iter: 0; batch classifier loss: 0.362904; batch adversarial loss: 0.563159\n",
      "epoch 171; iter: 0; batch classifier loss: 0.409464; batch adversarial loss: 0.500823\n",
      "epoch 172; iter: 0; batch classifier loss: 0.329609; batch adversarial loss: 0.597959\n",
      "epoch 173; iter: 0; batch classifier loss: 0.412378; batch adversarial loss: 0.509314\n",
      "epoch 174; iter: 0; batch classifier loss: 0.321329; batch adversarial loss: 0.562266\n",
      "epoch 175; iter: 0; batch classifier loss: 0.488578; batch adversarial loss: 0.500713\n",
      "epoch 176; iter: 0; batch classifier loss: 0.374046; batch adversarial loss: 0.544800\n",
      "epoch 177; iter: 0; batch classifier loss: 0.377468; batch adversarial loss: 0.588982\n",
      "epoch 178; iter: 0; batch classifier loss: 0.350526; batch adversarial loss: 0.526833\n",
      "epoch 179; iter: 0; batch classifier loss: 0.446718; batch adversarial loss: 0.562178\n",
      "epoch 180; iter: 0; batch classifier loss: 0.286119; batch adversarial loss: 0.535852\n",
      "epoch 181; iter: 0; batch classifier loss: 0.324157; batch adversarial loss: 0.526214\n",
      "epoch 182; iter: 0; batch classifier loss: 0.346568; batch adversarial loss: 0.506936\n",
      "epoch 183; iter: 0; batch classifier loss: 0.394706; batch adversarial loss: 0.561784\n",
      "epoch 184; iter: 0; batch classifier loss: 0.380222; batch adversarial loss: 0.542795\n",
      "epoch 185; iter: 0; batch classifier loss: 0.364371; batch adversarial loss: 0.602145\n",
      "epoch 186; iter: 0; batch classifier loss: 0.382272; batch adversarial loss: 0.588604\n",
      "epoch 187; iter: 0; batch classifier loss: 0.417415; batch adversarial loss: 0.538030\n",
      "epoch 188; iter: 0; batch classifier loss: 0.374828; batch adversarial loss: 0.571520\n",
      "epoch 189; iter: 0; batch classifier loss: 0.404963; batch adversarial loss: 0.536778\n",
      "epoch 190; iter: 0; batch classifier loss: 0.344185; batch adversarial loss: 0.564475\n",
      "epoch 191; iter: 0; batch classifier loss: 0.333305; batch adversarial loss: 0.668551\n",
      "epoch 192; iter: 0; batch classifier loss: 0.387124; batch adversarial loss: 0.552624\n",
      "epoch 193; iter: 0; batch classifier loss: 0.313263; batch adversarial loss: 0.534850\n",
      "epoch 194; iter: 0; batch classifier loss: 0.422396; batch adversarial loss: 0.554465\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 195; iter: 0; batch classifier loss: 0.252220; batch adversarial loss: 0.481866\n",
      "epoch 196; iter: 0; batch classifier loss: 0.387649; batch adversarial loss: 0.525480\n",
      "epoch 197; iter: 0; batch classifier loss: 0.374662; batch adversarial loss: 0.588574\n",
      "epoch 198; iter: 0; batch classifier loss: 0.312601; batch adversarial loss: 0.546038\n",
      "epoch 199; iter: 0; batch classifier loss: 0.351575; batch adversarial loss: 0.553437\n",
      "epoch 0; iter: 0; batch classifier loss: 0.852364; batch adversarial loss: 0.819892\n",
      "epoch 1; iter: 0; batch classifier loss: 0.671689; batch adversarial loss: 0.716106\n",
      "epoch 2; iter: 0; batch classifier loss: 0.647834; batch adversarial loss: 0.691985\n",
      "epoch 3; iter: 0; batch classifier loss: 0.583043; batch adversarial loss: 0.646322\n",
      "epoch 4; iter: 0; batch classifier loss: 0.568039; batch adversarial loss: 0.655150\n",
      "epoch 5; iter: 0; batch classifier loss: 0.592853; batch adversarial loss: 0.633204\n",
      "epoch 6; iter: 0; batch classifier loss: 0.585673; batch adversarial loss: 0.653355\n",
      "epoch 7; iter: 0; batch classifier loss: 0.482183; batch adversarial loss: 0.588934\n",
      "epoch 8; iter: 0; batch classifier loss: 0.557385; batch adversarial loss: 0.623430\n",
      "epoch 9; iter: 0; batch classifier loss: 0.548648; batch adversarial loss: 0.591552\n",
      "epoch 10; iter: 0; batch classifier loss: 0.484873; batch adversarial loss: 0.580686\n",
      "epoch 11; iter: 0; batch classifier loss: 0.482459; batch adversarial loss: 0.595702\n",
      "epoch 12; iter: 0; batch classifier loss: 0.472333; batch adversarial loss: 0.575822\n",
      "epoch 13; iter: 0; batch classifier loss: 0.519817; batch adversarial loss: 0.579853\n",
      "epoch 14; iter: 0; batch classifier loss: 0.520779; batch adversarial loss: 0.573543\n",
      "epoch 15; iter: 0; batch classifier loss: 0.496322; batch adversarial loss: 0.567659\n",
      "epoch 16; iter: 0; batch classifier loss: 0.464944; batch adversarial loss: 0.561409\n",
      "epoch 17; iter: 0; batch classifier loss: 0.474030; batch adversarial loss: 0.642969\n",
      "epoch 18; iter: 0; batch classifier loss: 0.486809; batch adversarial loss: 0.586397\n",
      "epoch 19; iter: 0; batch classifier loss: 0.491858; batch adversarial loss: 0.521436\n",
      "epoch 20; iter: 0; batch classifier loss: 0.525979; batch adversarial loss: 0.499977\n",
      "epoch 21; iter: 0; batch classifier loss: 0.522766; batch adversarial loss: 0.540945\n",
      "epoch 22; iter: 0; batch classifier loss: 0.431116; batch adversarial loss: 0.583917\n",
      "epoch 23; iter: 0; batch classifier loss: 0.492200; batch adversarial loss: 0.555971\n",
      "epoch 24; iter: 0; batch classifier loss: 0.460163; batch adversarial loss: 0.567467\n",
      "epoch 25; iter: 0; batch classifier loss: 0.530465; batch adversarial loss: 0.563143\n",
      "epoch 26; iter: 0; batch classifier loss: 0.449209; batch adversarial loss: 0.542817\n",
      "epoch 27; iter: 0; batch classifier loss: 0.435704; batch adversarial loss: 0.571503\n",
      "epoch 28; iter: 0; batch classifier loss: 0.445507; batch adversarial loss: 0.570258\n",
      "epoch 29; iter: 0; batch classifier loss: 0.424001; batch adversarial loss: 0.613144\n",
      "epoch 30; iter: 0; batch classifier loss: 0.541262; batch adversarial loss: 0.533580\n",
      "epoch 31; iter: 0; batch classifier loss: 0.492289; batch adversarial loss: 0.594624\n",
      "epoch 32; iter: 0; batch classifier loss: 0.516042; batch adversarial loss: 0.547056\n",
      "epoch 33; iter: 0; batch classifier loss: 0.510498; batch adversarial loss: 0.537839\n",
      "epoch 34; iter: 0; batch classifier loss: 0.472135; batch adversarial loss: 0.474785\n",
      "epoch 35; iter: 0; batch classifier loss: 0.485071; batch adversarial loss: 0.578912\n",
      "epoch 36; iter: 0; batch classifier loss: 0.492121; batch adversarial loss: 0.638688\n",
      "epoch 37; iter: 0; batch classifier loss: 0.474261; batch adversarial loss: 0.530669\n",
      "epoch 38; iter: 0; batch classifier loss: 0.368206; batch adversarial loss: 0.503928\n",
      "epoch 39; iter: 0; batch classifier loss: 0.420441; batch adversarial loss: 0.494728\n",
      "epoch 40; iter: 0; batch classifier loss: 0.445128; batch adversarial loss: 0.623368\n",
      "epoch 41; iter: 0; batch classifier loss: 0.454411; batch adversarial loss: 0.587423\n",
      "epoch 42; iter: 0; batch classifier loss: 0.449685; batch adversarial loss: 0.553131\n",
      "epoch 43; iter: 0; batch classifier loss: 0.381697; batch adversarial loss: 0.580815\n",
      "epoch 44; iter: 0; batch classifier loss: 0.415235; batch adversarial loss: 0.529258\n",
      "epoch 45; iter: 0; batch classifier loss: 0.473096; batch adversarial loss: 0.554122\n",
      "epoch 46; iter: 0; batch classifier loss: 0.441004; batch adversarial loss: 0.624719\n",
      "epoch 47; iter: 0; batch classifier loss: 0.410960; batch adversarial loss: 0.569146\n",
      "epoch 48; iter: 0; batch classifier loss: 0.444066; batch adversarial loss: 0.580367\n",
      "epoch 49; iter: 0; batch classifier loss: 0.377307; batch adversarial loss: 0.570794\n",
      "epoch 50; iter: 0; batch classifier loss: 0.384093; batch adversarial loss: 0.650522\n",
      "epoch 51; iter: 0; batch classifier loss: 0.434509; batch adversarial loss: 0.554065\n",
      "epoch 52; iter: 0; batch classifier loss: 0.392607; batch adversarial loss: 0.535380\n",
      "epoch 53; iter: 0; batch classifier loss: 0.486935; batch adversarial loss: 0.518130\n",
      "epoch 54; iter: 0; batch classifier loss: 0.414462; batch adversarial loss: 0.597398\n",
      "epoch 55; iter: 0; batch classifier loss: 0.390652; batch adversarial loss: 0.571140\n",
      "epoch 56; iter: 0; batch classifier loss: 0.439656; batch adversarial loss: 0.552978\n",
      "epoch 57; iter: 0; batch classifier loss: 0.415787; batch adversarial loss: 0.553877\n",
      "epoch 58; iter: 0; batch classifier loss: 0.393985; batch adversarial loss: 0.606468\n",
      "epoch 59; iter: 0; batch classifier loss: 0.352651; batch adversarial loss: 0.518272\n",
      "epoch 60; iter: 0; batch classifier loss: 0.372428; batch adversarial loss: 0.554988\n",
      "epoch 61; iter: 0; batch classifier loss: 0.301074; batch adversarial loss: 0.598741\n",
      "epoch 62; iter: 0; batch classifier loss: 0.457979; batch adversarial loss: 0.616162\n",
      "epoch 63; iter: 0; batch classifier loss: 0.459019; batch adversarial loss: 0.509270\n",
      "epoch 64; iter: 0; batch classifier loss: 0.463963; batch adversarial loss: 0.588668\n",
      "epoch 65; iter: 0; batch classifier loss: 0.376208; batch adversarial loss: 0.491820\n",
      "epoch 66; iter: 0; batch classifier loss: 0.445617; batch adversarial loss: 0.553548\n",
      "epoch 67; iter: 0; batch classifier loss: 0.370369; batch adversarial loss: 0.562249\n",
      "epoch 68; iter: 0; batch classifier loss: 0.389839; batch adversarial loss: 0.562218\n",
      "epoch 69; iter: 0; batch classifier loss: 0.365481; batch adversarial loss: 0.473896\n",
      "epoch 70; iter: 0; batch classifier loss: 0.413742; batch adversarial loss: 0.598180\n",
      "epoch 71; iter: 0; batch classifier loss: 0.453788; batch adversarial loss: 0.536613\n",
      "epoch 72; iter: 0; batch classifier loss: 0.340714; batch adversarial loss: 0.589972\n",
      "epoch 73; iter: 0; batch classifier loss: 0.375160; batch adversarial loss: 0.554425\n",
      "epoch 74; iter: 0; batch classifier loss: 0.392953; batch adversarial loss: 0.535028\n",
      "epoch 75; iter: 0; batch classifier loss: 0.395522; batch adversarial loss: 0.659322\n",
      "epoch 76; iter: 0; batch classifier loss: 0.420659; batch adversarial loss: 0.545521\n",
      "epoch 77; iter: 0; batch classifier loss: 0.426666; batch adversarial loss: 0.590001\n",
      "epoch 78; iter: 0; batch classifier loss: 0.391057; batch adversarial loss: 0.517236\n",
      "epoch 79; iter: 0; batch classifier loss: 0.450539; batch adversarial loss: 0.580400\n",
      "epoch 80; iter: 0; batch classifier loss: 0.366293; batch adversarial loss: 0.499630\n",
      "epoch 81; iter: 0; batch classifier loss: 0.433825; batch adversarial loss: 0.481952\n",
      "epoch 82; iter: 0; batch classifier loss: 0.417972; batch adversarial loss: 0.607418\n",
      "epoch 83; iter: 0; batch classifier loss: 0.382080; batch adversarial loss: 0.571870\n",
      "epoch 84; iter: 0; batch classifier loss: 0.377550; batch adversarial loss: 0.661182\n",
      "epoch 85; iter: 0; batch classifier loss: 0.421601; batch adversarial loss: 0.535877\n",
      "epoch 86; iter: 0; batch classifier loss: 0.402450; batch adversarial loss: 0.588934\n",
      "epoch 87; iter: 0; batch classifier loss: 0.390187; batch adversarial loss: 0.571860\n",
      "epoch 88; iter: 0; batch classifier loss: 0.363371; batch adversarial loss: 0.535244\n",
      "epoch 89; iter: 0; batch classifier loss: 0.405985; batch adversarial loss: 0.517220\n",
      "epoch 90; iter: 0; batch classifier loss: 0.348166; batch adversarial loss: 0.571288\n",
      "epoch 91; iter: 0; batch classifier loss: 0.351274; batch adversarial loss: 0.580830\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 92; iter: 0; batch classifier loss: 0.309670; batch adversarial loss: 0.445885\n",
      "epoch 93; iter: 0; batch classifier loss: 0.495286; batch adversarial loss: 0.608494\n",
      "epoch 94; iter: 0; batch classifier loss: 0.396569; batch adversarial loss: 0.527836\n",
      "epoch 95; iter: 0; batch classifier loss: 0.329872; batch adversarial loss: 0.517533\n",
      "epoch 96; iter: 0; batch classifier loss: 0.310106; batch adversarial loss: 0.642495\n",
      "epoch 97; iter: 0; batch classifier loss: 0.425225; batch adversarial loss: 0.580945\n",
      "epoch 98; iter: 0; batch classifier loss: 0.317737; batch adversarial loss: 0.625647\n",
      "epoch 99; iter: 0; batch classifier loss: 0.404910; batch adversarial loss: 0.509638\n",
      "epoch 100; iter: 0; batch classifier loss: 0.421220; batch adversarial loss: 0.499965\n",
      "epoch 101; iter: 0; batch classifier loss: 0.355553; batch adversarial loss: 0.589293\n",
      "epoch 102; iter: 0; batch classifier loss: 0.422742; batch adversarial loss: 0.509260\n",
      "epoch 103; iter: 0; batch classifier loss: 0.374258; batch adversarial loss: 0.508889\n",
      "epoch 104; iter: 0; batch classifier loss: 0.387300; batch adversarial loss: 0.580523\n",
      "epoch 105; iter: 0; batch classifier loss: 0.456926; batch adversarial loss: 0.534901\n",
      "epoch 106; iter: 0; batch classifier loss: 0.357529; batch adversarial loss: 0.536366\n",
      "epoch 107; iter: 0; batch classifier loss: 0.317714; batch adversarial loss: 0.482123\n",
      "epoch 108; iter: 0; batch classifier loss: 0.382675; batch adversarial loss: 0.598662\n",
      "epoch 109; iter: 0; batch classifier loss: 0.346982; batch adversarial loss: 0.499404\n",
      "epoch 110; iter: 0; batch classifier loss: 0.316178; batch adversarial loss: 0.518083\n",
      "epoch 111; iter: 0; batch classifier loss: 0.393299; batch adversarial loss: 0.561877\n",
      "epoch 112; iter: 0; batch classifier loss: 0.364400; batch adversarial loss: 0.552851\n",
      "epoch 113; iter: 0; batch classifier loss: 0.406126; batch adversarial loss: 0.553783\n",
      "epoch 114; iter: 0; batch classifier loss: 0.318652; batch adversarial loss: 0.544561\n",
      "epoch 115; iter: 0; batch classifier loss: 0.301145; batch adversarial loss: 0.535881\n",
      "epoch 116; iter: 0; batch classifier loss: 0.334141; batch adversarial loss: 0.553481\n",
      "epoch 117; iter: 0; batch classifier loss: 0.326968; batch adversarial loss: 0.571294\n",
      "epoch 118; iter: 0; batch classifier loss: 0.334001; batch adversarial loss: 0.571870\n",
      "epoch 119; iter: 0; batch classifier loss: 0.380888; batch adversarial loss: 0.571207\n",
      "epoch 120; iter: 0; batch classifier loss: 0.369420; batch adversarial loss: 0.562534\n",
      "epoch 121; iter: 0; batch classifier loss: 0.301116; batch adversarial loss: 0.561579\n",
      "epoch 122; iter: 0; batch classifier loss: 0.316673; batch adversarial loss: 0.580312\n",
      "epoch 123; iter: 0; batch classifier loss: 0.385290; batch adversarial loss: 0.484024\n",
      "epoch 124; iter: 0; batch classifier loss: 0.353876; batch adversarial loss: 0.481130\n",
      "epoch 125; iter: 0; batch classifier loss: 0.316489; batch adversarial loss: 0.571589\n",
      "epoch 126; iter: 0; batch classifier loss: 0.369428; batch adversarial loss: 0.588078\n",
      "epoch 127; iter: 0; batch classifier loss: 0.474902; batch adversarial loss: 0.543859\n",
      "epoch 128; iter: 0; batch classifier loss: 0.359731; batch adversarial loss: 0.473404\n",
      "epoch 129; iter: 0; batch classifier loss: 0.386926; batch adversarial loss: 0.607942\n",
      "epoch 130; iter: 0; batch classifier loss: 0.481854; batch adversarial loss: 0.553262\n",
      "epoch 131; iter: 0; batch classifier loss: 0.347570; batch adversarial loss: 0.571262\n",
      "epoch 132; iter: 0; batch classifier loss: 0.381834; batch adversarial loss: 0.536295\n",
      "epoch 133; iter: 0; batch classifier loss: 0.314239; batch adversarial loss: 0.507590\n",
      "epoch 134; iter: 0; batch classifier loss: 0.324719; batch adversarial loss: 0.573358\n",
      "epoch 135; iter: 0; batch classifier loss: 0.334117; batch adversarial loss: 0.571478\n",
      "epoch 136; iter: 0; batch classifier loss: 0.435039; batch adversarial loss: 0.554649\n",
      "epoch 137; iter: 0; batch classifier loss: 0.348164; batch adversarial loss: 0.501022\n",
      "epoch 138; iter: 0; batch classifier loss: 0.423943; batch adversarial loss: 0.562184\n",
      "epoch 139; iter: 0; batch classifier loss: 0.335551; batch adversarial loss: 0.473523\n",
      "epoch 140; iter: 0; batch classifier loss: 0.368329; batch adversarial loss: 0.607148\n",
      "epoch 141; iter: 0; batch classifier loss: 0.405368; batch adversarial loss: 0.508302\n",
      "epoch 142; iter: 0; batch classifier loss: 0.458522; batch adversarial loss: 0.543867\n",
      "epoch 143; iter: 0; batch classifier loss: 0.335134; batch adversarial loss: 0.632978\n",
      "epoch 144; iter: 0; batch classifier loss: 0.309303; batch adversarial loss: 0.580826\n",
      "epoch 145; iter: 0; batch classifier loss: 0.283433; batch adversarial loss: 0.599500\n",
      "epoch 146; iter: 0; batch classifier loss: 0.366097; batch adversarial loss: 0.554304\n",
      "epoch 147; iter: 0; batch classifier loss: 0.336501; batch adversarial loss: 0.552437\n",
      "epoch 148; iter: 0; batch classifier loss: 0.338453; batch adversarial loss: 0.518376\n",
      "epoch 149; iter: 0; batch classifier loss: 0.360412; batch adversarial loss: 0.616406\n",
      "epoch 150; iter: 0; batch classifier loss: 0.478696; batch adversarial loss: 0.581185\n",
      "epoch 151; iter: 0; batch classifier loss: 0.405938; batch adversarial loss: 0.535454\n",
      "epoch 152; iter: 0; batch classifier loss: 0.330435; batch adversarial loss: 0.598730\n",
      "epoch 153; iter: 0; batch classifier loss: 0.318594; batch adversarial loss: 0.588063\n",
      "epoch 154; iter: 0; batch classifier loss: 0.336790; batch adversarial loss: 0.542932\n",
      "epoch 155; iter: 0; batch classifier loss: 0.389839; batch adversarial loss: 0.508303\n",
      "epoch 156; iter: 0; batch classifier loss: 0.315206; batch adversarial loss: 0.545395\n",
      "epoch 157; iter: 0; batch classifier loss: 0.281590; batch adversarial loss: 0.634586\n",
      "epoch 158; iter: 0; batch classifier loss: 0.295217; batch adversarial loss: 0.588593\n",
      "epoch 159; iter: 0; batch classifier loss: 0.327066; batch adversarial loss: 0.562918\n",
      "epoch 160; iter: 0; batch classifier loss: 0.349348; batch adversarial loss: 0.623955\n",
      "epoch 161; iter: 0; batch classifier loss: 0.290476; batch adversarial loss: 0.571894\n",
      "epoch 162; iter: 0; batch classifier loss: 0.366646; batch adversarial loss: 0.607174\n",
      "epoch 163; iter: 0; batch classifier loss: 0.274775; batch adversarial loss: 0.543561\n",
      "epoch 164; iter: 0; batch classifier loss: 0.373073; batch adversarial loss: 0.509387\n",
      "epoch 165; iter: 0; batch classifier loss: 0.261484; batch adversarial loss: 0.634106\n",
      "epoch 166; iter: 0; batch classifier loss: 0.395252; batch adversarial loss: 0.535265\n",
      "epoch 167; iter: 0; batch classifier loss: 0.418826; batch adversarial loss: 0.590392\n",
      "epoch 168; iter: 0; batch classifier loss: 0.354510; batch adversarial loss: 0.561624\n",
      "epoch 169; iter: 0; batch classifier loss: 0.299481; batch adversarial loss: 0.518579\n",
      "epoch 170; iter: 0; batch classifier loss: 0.375690; batch adversarial loss: 0.555376\n",
      "epoch 171; iter: 0; batch classifier loss: 0.359366; batch adversarial loss: 0.526335\n",
      "epoch 172; iter: 0; batch classifier loss: 0.417634; batch adversarial loss: 0.518426\n",
      "epoch 173; iter: 0; batch classifier loss: 0.386692; batch adversarial loss: 0.561982\n",
      "epoch 174; iter: 0; batch classifier loss: 0.388309; batch adversarial loss: 0.508917\n",
      "epoch 175; iter: 0; batch classifier loss: 0.433563; batch adversarial loss: 0.517239\n",
      "epoch 176; iter: 0; batch classifier loss: 0.264040; batch adversarial loss: 0.534671\n",
      "epoch 177; iter: 0; batch classifier loss: 0.255716; batch adversarial loss: 0.527678\n",
      "epoch 178; iter: 0; batch classifier loss: 0.362180; batch adversarial loss: 0.561804\n",
      "epoch 179; iter: 0; batch classifier loss: 0.470967; batch adversarial loss: 0.535550\n",
      "epoch 180; iter: 0; batch classifier loss: 0.335696; batch adversarial loss: 0.580138\n",
      "epoch 181; iter: 0; batch classifier loss: 0.311415; batch adversarial loss: 0.536644\n",
      "epoch 182; iter: 0; batch classifier loss: 0.262931; batch adversarial loss: 0.545745\n",
      "epoch 183; iter: 0; batch classifier loss: 0.334732; batch adversarial loss: 0.508850\n",
      "epoch 184; iter: 0; batch classifier loss: 0.339235; batch adversarial loss: 0.518366\n",
      "epoch 185; iter: 0; batch classifier loss: 0.366084; batch adversarial loss: 0.579348\n",
      "epoch 186; iter: 0; batch classifier loss: 0.403026; batch adversarial loss: 0.473042\n",
      "epoch 187; iter: 0; batch classifier loss: 0.395361; batch adversarial loss: 0.491466\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 188; iter: 0; batch classifier loss: 0.305808; batch adversarial loss: 0.534727\n",
      "epoch 189; iter: 0; batch classifier loss: 0.404989; batch adversarial loss: 0.536052\n",
      "epoch 190; iter: 0; batch classifier loss: 0.404814; batch adversarial loss: 0.499966\n",
      "epoch 191; iter: 0; batch classifier loss: 0.379611; batch adversarial loss: 0.545272\n",
      "epoch 192; iter: 0; batch classifier loss: 0.414396; batch adversarial loss: 0.509097\n",
      "epoch 193; iter: 0; batch classifier loss: 0.303847; batch adversarial loss: 0.570716\n",
      "epoch 194; iter: 0; batch classifier loss: 0.319478; batch adversarial loss: 0.482587\n",
      "epoch 195; iter: 0; batch classifier loss: 0.357629; batch adversarial loss: 0.571313\n",
      "epoch 196; iter: 0; batch classifier loss: 0.367458; batch adversarial loss: 0.571419\n",
      "epoch 197; iter: 0; batch classifier loss: 0.297403; batch adversarial loss: 0.517367\n",
      "epoch 198; iter: 0; batch classifier loss: 0.370276; batch adversarial loss: 0.553949\n",
      "epoch 199; iter: 0; batch classifier loss: 0.364275; batch adversarial loss: 0.591730\n",
      "epoch 0; iter: 0; batch classifier loss: 0.672364; batch adversarial loss: 0.815711\n",
      "epoch 1; iter: 0; batch classifier loss: 0.703789; batch adversarial loss: 0.804069\n",
      "epoch 2; iter: 0; batch classifier loss: 0.844434; batch adversarial loss: 0.764237\n",
      "epoch 3; iter: 0; batch classifier loss: 0.903414; batch adversarial loss: 0.698269\n",
      "epoch 4; iter: 0; batch classifier loss: 0.744549; batch adversarial loss: 0.649445\n",
      "epoch 5; iter: 0; batch classifier loss: 0.576715; batch adversarial loss: 0.625512\n",
      "epoch 6; iter: 0; batch classifier loss: 0.515713; batch adversarial loss: 0.617882\n",
      "epoch 7; iter: 0; batch classifier loss: 0.515646; batch adversarial loss: 0.601308\n",
      "epoch 8; iter: 0; batch classifier loss: 0.587157; batch adversarial loss: 0.601660\n",
      "epoch 9; iter: 0; batch classifier loss: 0.559302; batch adversarial loss: 0.594033\n",
      "epoch 10; iter: 0; batch classifier loss: 0.537917; batch adversarial loss: 0.619518\n",
      "epoch 11; iter: 0; batch classifier loss: 0.476109; batch adversarial loss: 0.588742\n",
      "epoch 12; iter: 0; batch classifier loss: 0.609425; batch adversarial loss: 0.639402\n",
      "epoch 13; iter: 0; batch classifier loss: 0.540319; batch adversarial loss: 0.552932\n",
      "epoch 14; iter: 0; batch classifier loss: 0.507691; batch adversarial loss: 0.621384\n",
      "epoch 15; iter: 0; batch classifier loss: 0.520222; batch adversarial loss: 0.591221\n",
      "epoch 16; iter: 0; batch classifier loss: 0.464951; batch adversarial loss: 0.607916\n",
      "epoch 17; iter: 0; batch classifier loss: 0.515756; batch adversarial loss: 0.557530\n",
      "epoch 18; iter: 0; batch classifier loss: 0.430391; batch adversarial loss: 0.561342\n",
      "epoch 19; iter: 0; batch classifier loss: 0.462917; batch adversarial loss: 0.503558\n",
      "epoch 20; iter: 0; batch classifier loss: 0.509687; batch adversarial loss: 0.521424\n",
      "epoch 21; iter: 0; batch classifier loss: 0.534449; batch adversarial loss: 0.526710\n",
      "epoch 22; iter: 0; batch classifier loss: 0.457331; batch adversarial loss: 0.488249\n",
      "epoch 23; iter: 0; batch classifier loss: 0.487607; batch adversarial loss: 0.594505\n",
      "epoch 24; iter: 0; batch classifier loss: 0.466254; batch adversarial loss: 0.542194\n",
      "epoch 25; iter: 0; batch classifier loss: 0.484492; batch adversarial loss: 0.601375\n",
      "epoch 26; iter: 0; batch classifier loss: 0.418965; batch adversarial loss: 0.635931\n",
      "epoch 27; iter: 0; batch classifier loss: 0.596902; batch adversarial loss: 0.593611\n",
      "epoch 28; iter: 0; batch classifier loss: 0.558875; batch adversarial loss: 0.571625\n",
      "epoch 29; iter: 0; batch classifier loss: 0.468121; batch adversarial loss: 0.615546\n",
      "epoch 30; iter: 0; batch classifier loss: 0.437735; batch adversarial loss: 0.547623\n",
      "epoch 31; iter: 0; batch classifier loss: 0.439522; batch adversarial loss: 0.551868\n",
      "epoch 32; iter: 0; batch classifier loss: 0.524807; batch adversarial loss: 0.564853\n",
      "epoch 33; iter: 0; batch classifier loss: 0.478937; batch adversarial loss: 0.591910\n",
      "epoch 34; iter: 0; batch classifier loss: 0.387239; batch adversarial loss: 0.550618\n",
      "epoch 35; iter: 0; batch classifier loss: 0.470970; batch adversarial loss: 0.532056\n",
      "epoch 36; iter: 0; batch classifier loss: 0.435782; batch adversarial loss: 0.567066\n",
      "epoch 37; iter: 0; batch classifier loss: 0.471387; batch adversarial loss: 0.459181\n",
      "epoch 38; iter: 0; batch classifier loss: 0.431887; batch adversarial loss: 0.532584\n",
      "epoch 39; iter: 0; batch classifier loss: 0.483260; batch adversarial loss: 0.587586\n",
      "epoch 40; iter: 0; batch classifier loss: 0.427370; batch adversarial loss: 0.493739\n",
      "epoch 41; iter: 0; batch classifier loss: 0.468172; batch adversarial loss: 0.479644\n",
      "epoch 42; iter: 0; batch classifier loss: 0.444897; batch adversarial loss: 0.614235\n",
      "epoch 43; iter: 0; batch classifier loss: 0.403236; batch adversarial loss: 0.492964\n",
      "epoch 44; iter: 0; batch classifier loss: 0.389540; batch adversarial loss: 0.628643\n",
      "epoch 45; iter: 0; batch classifier loss: 0.480777; batch adversarial loss: 0.591871\n",
      "epoch 46; iter: 0; batch classifier loss: 0.467903; batch adversarial loss: 0.667050\n",
      "epoch 47; iter: 0; batch classifier loss: 0.487676; batch adversarial loss: 0.599314\n",
      "epoch 48; iter: 0; batch classifier loss: 0.357945; batch adversarial loss: 0.536410\n",
      "epoch 49; iter: 0; batch classifier loss: 0.447933; batch adversarial loss: 0.580865\n",
      "epoch 50; iter: 0; batch classifier loss: 0.411331; batch adversarial loss: 0.557993\n",
      "epoch 51; iter: 0; batch classifier loss: 0.373983; batch adversarial loss: 0.579942\n",
      "epoch 52; iter: 0; batch classifier loss: 0.448485; batch adversarial loss: 0.634773\n",
      "epoch 53; iter: 0; batch classifier loss: 0.525303; batch adversarial loss: 0.553385\n",
      "epoch 54; iter: 0; batch classifier loss: 0.494394; batch adversarial loss: 0.614817\n",
      "epoch 55; iter: 0; batch classifier loss: 0.336702; batch adversarial loss: 0.545776\n",
      "epoch 56; iter: 0; batch classifier loss: 0.337896; batch adversarial loss: 0.571022\n",
      "epoch 57; iter: 0; batch classifier loss: 0.404887; batch adversarial loss: 0.511083\n",
      "epoch 58; iter: 0; batch classifier loss: 0.393874; batch adversarial loss: 0.493427\n",
      "epoch 59; iter: 0; batch classifier loss: 0.363616; batch adversarial loss: 0.579665\n",
      "epoch 60; iter: 0; batch classifier loss: 0.380263; batch adversarial loss: 0.484807\n",
      "epoch 61; iter: 0; batch classifier loss: 0.390001; batch adversarial loss: 0.509873\n",
      "epoch 62; iter: 0; batch classifier loss: 0.313697; batch adversarial loss: 0.527497\n",
      "epoch 63; iter: 0; batch classifier loss: 0.444026; batch adversarial loss: 0.597636\n",
      "epoch 64; iter: 0; batch classifier loss: 0.369360; batch adversarial loss: 0.535028\n",
      "epoch 65; iter: 0; batch classifier loss: 0.414374; batch adversarial loss: 0.606184\n",
      "epoch 66; iter: 0; batch classifier loss: 0.441360; batch adversarial loss: 0.588791\n",
      "epoch 67; iter: 0; batch classifier loss: 0.426211; batch adversarial loss: 0.623906\n",
      "epoch 68; iter: 0; batch classifier loss: 0.487089; batch adversarial loss: 0.568794\n",
      "epoch 69; iter: 0; batch classifier loss: 0.300386; batch adversarial loss: 0.637866\n",
      "epoch 70; iter: 0; batch classifier loss: 0.358692; batch adversarial loss: 0.575055\n",
      "epoch 71; iter: 0; batch classifier loss: 0.404072; batch adversarial loss: 0.591634\n",
      "epoch 72; iter: 0; batch classifier loss: 0.356449; batch adversarial loss: 0.670116\n",
      "epoch 73; iter: 0; batch classifier loss: 0.401961; batch adversarial loss: 0.604503\n",
      "epoch 74; iter: 0; batch classifier loss: 0.328960; batch adversarial loss: 0.527692\n",
      "epoch 75; iter: 0; batch classifier loss: 0.439545; batch adversarial loss: 0.675767\n",
      "epoch 76; iter: 0; batch classifier loss: 0.347683; batch adversarial loss: 0.510100\n",
      "epoch 77; iter: 0; batch classifier loss: 0.441803; batch adversarial loss: 0.527593\n",
      "epoch 78; iter: 0; batch classifier loss: 0.425711; batch adversarial loss: 0.510557\n",
      "epoch 79; iter: 0; batch classifier loss: 0.428890; batch adversarial loss: 0.502510\n",
      "epoch 80; iter: 0; batch classifier loss: 0.416736; batch adversarial loss: 0.596746\n",
      "epoch 81; iter: 0; batch classifier loss: 0.397199; batch adversarial loss: 0.510465\n",
      "epoch 82; iter: 0; batch classifier loss: 0.360819; batch adversarial loss: 0.553410\n",
      "epoch 83; iter: 0; batch classifier loss: 0.421297; batch adversarial loss: 0.509369\n",
      "epoch 84; iter: 0; batch classifier loss: 0.320351; batch adversarial loss: 0.518560\n",
      "epoch 85; iter: 0; batch classifier loss: 0.428757; batch adversarial loss: 0.510194\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 86; iter: 0; batch classifier loss: 0.437871; batch adversarial loss: 0.570468\n",
      "epoch 87; iter: 0; batch classifier loss: 0.367389; batch adversarial loss: 0.535618\n",
      "epoch 88; iter: 0; batch classifier loss: 0.363601; batch adversarial loss: 0.651932\n",
      "epoch 89; iter: 0; batch classifier loss: 0.393974; batch adversarial loss: 0.510777\n",
      "epoch 90; iter: 0; batch classifier loss: 0.286995; batch adversarial loss: 0.510848\n",
      "epoch 91; iter: 0; batch classifier loss: 0.336804; batch adversarial loss: 0.553702\n",
      "epoch 92; iter: 0; batch classifier loss: 0.353171; batch adversarial loss: 0.587797\n",
      "epoch 93; iter: 0; batch classifier loss: 0.357744; batch adversarial loss: 0.500788\n",
      "epoch 94; iter: 0; batch classifier loss: 0.414840; batch adversarial loss: 0.580872\n",
      "epoch 95; iter: 0; batch classifier loss: 0.398651; batch adversarial loss: 0.526516\n",
      "epoch 96; iter: 0; batch classifier loss: 0.293369; batch adversarial loss: 0.545337\n",
      "epoch 97; iter: 0; batch classifier loss: 0.357961; batch adversarial loss: 0.605646\n",
      "epoch 98; iter: 0; batch classifier loss: 0.421692; batch adversarial loss: 0.484582\n",
      "epoch 99; iter: 0; batch classifier loss: 0.283012; batch adversarial loss: 0.588531\n",
      "epoch 100; iter: 0; batch classifier loss: 0.327594; batch adversarial loss: 0.544857\n",
      "epoch 101; iter: 0; batch classifier loss: 0.384868; batch adversarial loss: 0.562220\n",
      "epoch 102; iter: 0; batch classifier loss: 0.415549; batch adversarial loss: 0.518545\n",
      "epoch 103; iter: 0; batch classifier loss: 0.361456; batch adversarial loss: 0.562477\n",
      "epoch 104; iter: 0; batch classifier loss: 0.396991; batch adversarial loss: 0.579734\n",
      "epoch 105; iter: 0; batch classifier loss: 0.442069; batch adversarial loss: 0.518573\n",
      "epoch 106; iter: 0; batch classifier loss: 0.329838; batch adversarial loss: 0.632954\n",
      "epoch 107; iter: 0; batch classifier loss: 0.268326; batch adversarial loss: 0.553815\n",
      "epoch 108; iter: 0; batch classifier loss: 0.390904; batch adversarial loss: 0.535719\n",
      "epoch 109; iter: 0; batch classifier loss: 0.291066; batch adversarial loss: 0.580808\n",
      "epoch 110; iter: 0; batch classifier loss: 0.366625; batch adversarial loss: 0.570801\n",
      "epoch 111; iter: 0; batch classifier loss: 0.357228; batch adversarial loss: 0.554518\n",
      "epoch 112; iter: 0; batch classifier loss: 0.310454; batch adversarial loss: 0.501533\n",
      "epoch 113; iter: 0; batch classifier loss: 0.277681; batch adversarial loss: 0.588315\n",
      "epoch 114; iter: 0; batch classifier loss: 0.369912; batch adversarial loss: 0.510010\n",
      "epoch 115; iter: 0; batch classifier loss: 0.399489; batch adversarial loss: 0.589677\n",
      "epoch 116; iter: 0; batch classifier loss: 0.349919; batch adversarial loss: 0.517874\n",
      "epoch 117; iter: 0; batch classifier loss: 0.369041; batch adversarial loss: 0.570803\n",
      "epoch 118; iter: 0; batch classifier loss: 0.435411; batch adversarial loss: 0.571641\n",
      "epoch 119; iter: 0; batch classifier loss: 0.349069; batch adversarial loss: 0.535747\n",
      "epoch 120; iter: 0; batch classifier loss: 0.338136; batch adversarial loss: 0.537332\n",
      "epoch 121; iter: 0; batch classifier loss: 0.296787; batch adversarial loss: 0.473083\n",
      "epoch 122; iter: 0; batch classifier loss: 0.390203; batch adversarial loss: 0.526563\n",
      "epoch 123; iter: 0; batch classifier loss: 0.359507; batch adversarial loss: 0.562068\n",
      "epoch 124; iter: 0; batch classifier loss: 0.397378; batch adversarial loss: 0.545510\n",
      "epoch 125; iter: 0; batch classifier loss: 0.401411; batch adversarial loss: 0.545125\n",
      "epoch 126; iter: 0; batch classifier loss: 0.413196; batch adversarial loss: 0.586525\n",
      "epoch 127; iter: 0; batch classifier loss: 0.392820; batch adversarial loss: 0.402799\n",
      "epoch 128; iter: 0; batch classifier loss: 0.378186; batch adversarial loss: 0.554386\n",
      "epoch 129; iter: 0; batch classifier loss: 0.432279; batch adversarial loss: 0.589252\n",
      "epoch 130; iter: 0; batch classifier loss: 0.326397; batch adversarial loss: 0.485365\n",
      "epoch 131; iter: 0; batch classifier loss: 0.330822; batch adversarial loss: 0.533992\n",
      "epoch 132; iter: 0; batch classifier loss: 0.366450; batch adversarial loss: 0.571173\n",
      "epoch 133; iter: 0; batch classifier loss: 0.408088; batch adversarial loss: 0.551954\n",
      "epoch 134; iter: 0; batch classifier loss: 0.295954; batch adversarial loss: 0.596521\n",
      "epoch 135; iter: 0; batch classifier loss: 0.352700; batch adversarial loss: 0.581115\n",
      "epoch 136; iter: 0; batch classifier loss: 0.407260; batch adversarial loss: 0.466387\n",
      "epoch 137; iter: 0; batch classifier loss: 0.340953; batch adversarial loss: 0.605744\n",
      "epoch 138; iter: 0; batch classifier loss: 0.363097; batch adversarial loss: 0.562300\n",
      "epoch 139; iter: 0; batch classifier loss: 0.310591; batch adversarial loss: 0.570883\n",
      "epoch 140; iter: 0; batch classifier loss: 0.383416; batch adversarial loss: 0.657960\n",
      "epoch 141; iter: 0; batch classifier loss: 0.292496; batch adversarial loss: 0.562889\n",
      "epoch 142; iter: 0; batch classifier loss: 0.369853; batch adversarial loss: 0.642142\n",
      "epoch 143; iter: 0; batch classifier loss: 0.346650; batch adversarial loss: 0.518008\n",
      "epoch 144; iter: 0; batch classifier loss: 0.318934; batch adversarial loss: 0.527064\n",
      "epoch 145; iter: 0; batch classifier loss: 0.428927; batch adversarial loss: 0.561458\n",
      "epoch 146; iter: 0; batch classifier loss: 0.382101; batch adversarial loss: 0.536516\n",
      "epoch 147; iter: 0; batch classifier loss: 0.362117; batch adversarial loss: 0.596843\n",
      "epoch 148; iter: 0; batch classifier loss: 0.318734; batch adversarial loss: 0.588887\n",
      "epoch 149; iter: 0; batch classifier loss: 0.271896; batch adversarial loss: 0.597902\n",
      "epoch 150; iter: 0; batch classifier loss: 0.395707; batch adversarial loss: 0.545020\n",
      "epoch 151; iter: 0; batch classifier loss: 0.416808; batch adversarial loss: 0.492401\n",
      "epoch 152; iter: 0; batch classifier loss: 0.316978; batch adversarial loss: 0.570624\n",
      "epoch 153; iter: 0; batch classifier loss: 0.353441; batch adversarial loss: 0.536378\n",
      "epoch 154; iter: 0; batch classifier loss: 0.376470; batch adversarial loss: 0.571290\n",
      "epoch 155; iter: 0; batch classifier loss: 0.356775; batch adversarial loss: 0.553567\n",
      "epoch 156; iter: 0; batch classifier loss: 0.310027; batch adversarial loss: 0.631411\n",
      "epoch 157; iter: 0; batch classifier loss: 0.350397; batch adversarial loss: 0.570639\n",
      "epoch 158; iter: 0; batch classifier loss: 0.380552; batch adversarial loss: 0.527403\n",
      "epoch 159; iter: 0; batch classifier loss: 0.333111; batch adversarial loss: 0.562450\n",
      "epoch 160; iter: 0; batch classifier loss: 0.332120; batch adversarial loss: 0.544525\n",
      "epoch 161; iter: 0; batch classifier loss: 0.360009; batch adversarial loss: 0.614708\n",
      "epoch 162; iter: 0; batch classifier loss: 0.336751; batch adversarial loss: 0.615131\n",
      "epoch 163; iter: 0; batch classifier loss: 0.285743; batch adversarial loss: 0.562045\n",
      "epoch 164; iter: 0; batch classifier loss: 0.361421; batch adversarial loss: 0.482919\n",
      "epoch 165; iter: 0; batch classifier loss: 0.366354; batch adversarial loss: 0.482321\n",
      "epoch 166; iter: 0; batch classifier loss: 0.324891; batch adversarial loss: 0.578954\n",
      "epoch 167; iter: 0; batch classifier loss: 0.375280; batch adversarial loss: 0.542667\n",
      "epoch 168; iter: 0; batch classifier loss: 0.345700; batch adversarial loss: 0.590392\n",
      "epoch 169; iter: 0; batch classifier loss: 0.389894; batch adversarial loss: 0.553698\n",
      "epoch 170; iter: 0; batch classifier loss: 0.280856; batch adversarial loss: 0.544155\n",
      "epoch 171; iter: 0; batch classifier loss: 0.343277; batch adversarial loss: 0.572317\n",
      "epoch 172; iter: 0; batch classifier loss: 0.332645; batch adversarial loss: 0.528518\n",
      "epoch 173; iter: 0; batch classifier loss: 0.316585; batch adversarial loss: 0.509889\n",
      "epoch 174; iter: 0; batch classifier loss: 0.298658; batch adversarial loss: 0.555028\n",
      "epoch 175; iter: 0; batch classifier loss: 0.359980; batch adversarial loss: 0.563312\n",
      "epoch 176; iter: 0; batch classifier loss: 0.291660; batch adversarial loss: 0.596288\n",
      "epoch 177; iter: 0; batch classifier loss: 0.411292; batch adversarial loss: 0.596108\n",
      "epoch 178; iter: 0; batch classifier loss: 0.307643; batch adversarial loss: 0.509622\n",
      "epoch 179; iter: 0; batch classifier loss: 0.304377; batch adversarial loss: 0.545028\n",
      "epoch 180; iter: 0; batch classifier loss: 0.371422; batch adversarial loss: 0.527948\n",
      "epoch 181; iter: 0; batch classifier loss: 0.279702; batch adversarial loss: 0.606619\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 182; iter: 0; batch classifier loss: 0.292593; batch adversarial loss: 0.527519\n",
      "epoch 183; iter: 0; batch classifier loss: 0.321028; batch adversarial loss: 0.587744\n",
      "epoch 184; iter: 0; batch classifier loss: 0.294915; batch adversarial loss: 0.535535\n",
      "epoch 185; iter: 0; batch classifier loss: 0.285657; batch adversarial loss: 0.527299\n",
      "epoch 186; iter: 0; batch classifier loss: 0.327898; batch adversarial loss: 0.483860\n",
      "epoch 187; iter: 0; batch classifier loss: 0.329569; batch adversarial loss: 0.562432\n",
      "epoch 188; iter: 0; batch classifier loss: 0.347744; batch adversarial loss: 0.493634\n",
      "epoch 189; iter: 0; batch classifier loss: 0.371793; batch adversarial loss: 0.526808\n",
      "epoch 190; iter: 0; batch classifier loss: 0.297153; batch adversarial loss: 0.579985\n",
      "epoch 191; iter: 0; batch classifier loss: 0.341345; batch adversarial loss: 0.553470\n",
      "epoch 192; iter: 0; batch classifier loss: 0.298974; batch adversarial loss: 0.607155\n",
      "epoch 193; iter: 0; batch classifier loss: 0.304021; batch adversarial loss: 0.552589\n",
      "epoch 194; iter: 0; batch classifier loss: 0.359077; batch adversarial loss: 0.526519\n",
      "epoch 195; iter: 0; batch classifier loss: 0.308069; batch adversarial loss: 0.579892\n",
      "epoch 196; iter: 0; batch classifier loss: 0.270314; batch adversarial loss: 0.510215\n",
      "epoch 197; iter: 0; batch classifier loss: 0.315130; batch adversarial loss: 0.562229\n",
      "epoch 198; iter: 0; batch classifier loss: 0.378881; batch adversarial loss: 0.571749\n",
      "epoch 199; iter: 0; batch classifier loss: 0.326541; batch adversarial loss: 0.536680\n",
      "epoch 0; iter: 0; batch classifier loss: 0.702509; batch adversarial loss: 0.695692\n",
      "epoch 1; iter: 0; batch classifier loss: 0.608530; batch adversarial loss: 0.673659\n",
      "epoch 2; iter: 0; batch classifier loss: 0.523312; batch adversarial loss: 0.650348\n",
      "epoch 3; iter: 0; batch classifier loss: 0.551374; batch adversarial loss: 0.623023\n",
      "epoch 4; iter: 0; batch classifier loss: 0.605114; batch adversarial loss: 0.611024\n",
      "epoch 5; iter: 0; batch classifier loss: 0.581597; batch adversarial loss: 0.608386\n",
      "epoch 6; iter: 0; batch classifier loss: 0.577115; batch adversarial loss: 0.592688\n",
      "epoch 7; iter: 0; batch classifier loss: 0.545269; batch adversarial loss: 0.615732\n",
      "epoch 8; iter: 0; batch classifier loss: 0.553885; batch adversarial loss: 0.551181\n",
      "epoch 9; iter: 0; batch classifier loss: 0.521009; batch adversarial loss: 0.604195\n",
      "epoch 10; iter: 0; batch classifier loss: 0.514859; batch adversarial loss: 0.578083\n",
      "epoch 11; iter: 0; batch classifier loss: 0.503015; batch adversarial loss: 0.548236\n",
      "epoch 12; iter: 0; batch classifier loss: 0.574566; batch adversarial loss: 0.547959\n",
      "epoch 13; iter: 0; batch classifier loss: 0.509943; batch adversarial loss: 0.612723\n",
      "epoch 14; iter: 0; batch classifier loss: 0.565805; batch adversarial loss: 0.566199\n",
      "epoch 15; iter: 0; batch classifier loss: 0.526687; batch adversarial loss: 0.592237\n",
      "epoch 16; iter: 0; batch classifier loss: 0.664685; batch adversarial loss: 0.524600\n",
      "epoch 17; iter: 0; batch classifier loss: 0.494764; batch adversarial loss: 0.573556\n",
      "epoch 18; iter: 0; batch classifier loss: 0.537974; batch adversarial loss: 0.563533\n",
      "epoch 19; iter: 0; batch classifier loss: 0.576165; batch adversarial loss: 0.610036\n",
      "epoch 20; iter: 0; batch classifier loss: 0.480635; batch adversarial loss: 0.545822\n",
      "epoch 21; iter: 0; batch classifier loss: 0.477544; batch adversarial loss: 0.482726\n",
      "epoch 22; iter: 0; batch classifier loss: 0.469469; batch adversarial loss: 0.488865\n",
      "epoch 23; iter: 0; batch classifier loss: 0.443324; batch adversarial loss: 0.554981\n",
      "epoch 24; iter: 0; batch classifier loss: 0.445693; batch adversarial loss: 0.507207\n",
      "epoch 25; iter: 0; batch classifier loss: 0.528008; batch adversarial loss: 0.493842\n",
      "epoch 26; iter: 0; batch classifier loss: 0.494535; batch adversarial loss: 0.553185\n",
      "epoch 27; iter: 0; batch classifier loss: 0.458932; batch adversarial loss: 0.596974\n",
      "epoch 28; iter: 0; batch classifier loss: 0.447880; batch adversarial loss: 0.509947\n",
      "epoch 29; iter: 0; batch classifier loss: 0.440709; batch adversarial loss: 0.634935\n",
      "epoch 30; iter: 0; batch classifier loss: 0.439997; batch adversarial loss: 0.587701\n",
      "epoch 31; iter: 0; batch classifier loss: 0.453231; batch adversarial loss: 0.526376\n",
      "epoch 32; iter: 0; batch classifier loss: 0.463081; batch adversarial loss: 0.517673\n",
      "epoch 33; iter: 0; batch classifier loss: 0.491053; batch adversarial loss: 0.546074\n",
      "epoch 34; iter: 0; batch classifier loss: 0.436474; batch adversarial loss: 0.536032\n",
      "epoch 35; iter: 0; batch classifier loss: 0.470044; batch adversarial loss: 0.563387\n",
      "epoch 36; iter: 0; batch classifier loss: 0.479282; batch adversarial loss: 0.506322\n",
      "epoch 37; iter: 0; batch classifier loss: 0.469562; batch adversarial loss: 0.545449\n",
      "epoch 38; iter: 0; batch classifier loss: 0.422484; batch adversarial loss: 0.562329\n",
      "epoch 39; iter: 0; batch classifier loss: 0.405307; batch adversarial loss: 0.525871\n",
      "epoch 40; iter: 0; batch classifier loss: 0.468085; batch adversarial loss: 0.515174\n",
      "epoch 41; iter: 0; batch classifier loss: 0.482477; batch adversarial loss: 0.506134\n",
      "epoch 42; iter: 0; batch classifier loss: 0.387035; batch adversarial loss: 0.495396\n",
      "epoch 43; iter: 0; batch classifier loss: 0.491799; batch adversarial loss: 0.542589\n",
      "epoch 44; iter: 0; batch classifier loss: 0.430178; batch adversarial loss: 0.536602\n",
      "epoch 45; iter: 0; batch classifier loss: 0.517348; batch adversarial loss: 0.582580\n",
      "epoch 46; iter: 0; batch classifier loss: 0.486390; batch adversarial loss: 0.544556\n",
      "epoch 47; iter: 0; batch classifier loss: 0.504941; batch adversarial loss: 0.536132\n",
      "epoch 48; iter: 0; batch classifier loss: 0.484893; batch adversarial loss: 0.553789\n",
      "epoch 49; iter: 0; batch classifier loss: 0.452321; batch adversarial loss: 0.535141\n",
      "epoch 50; iter: 0; batch classifier loss: 0.462407; batch adversarial loss: 0.600260\n",
      "epoch 51; iter: 0; batch classifier loss: 0.448083; batch adversarial loss: 0.525513\n",
      "epoch 52; iter: 0; batch classifier loss: 0.432626; batch adversarial loss: 0.525281\n",
      "epoch 53; iter: 0; batch classifier loss: 0.472739; batch adversarial loss: 0.535300\n",
      "epoch 54; iter: 0; batch classifier loss: 0.458092; batch adversarial loss: 0.554057\n",
      "epoch 55; iter: 0; batch classifier loss: 0.434564; batch adversarial loss: 0.487561\n",
      "epoch 56; iter: 0; batch classifier loss: 0.362338; batch adversarial loss: 0.506108\n",
      "epoch 57; iter: 0; batch classifier loss: 0.411739; batch adversarial loss: 0.488211\n",
      "epoch 58; iter: 0; batch classifier loss: 0.395033; batch adversarial loss: 0.553006\n",
      "epoch 59; iter: 0; batch classifier loss: 0.446741; batch adversarial loss: 0.516264\n",
      "epoch 60; iter: 0; batch classifier loss: 0.464637; batch adversarial loss: 0.497990\n",
      "epoch 61; iter: 0; batch classifier loss: 0.317881; batch adversarial loss: 0.543707\n",
      "epoch 62; iter: 0; batch classifier loss: 0.391934; batch adversarial loss: 0.525757\n",
      "epoch 63; iter: 0; batch classifier loss: 0.411118; batch adversarial loss: 0.525435\n",
      "epoch 64; iter: 0; batch classifier loss: 0.318831; batch adversarial loss: 0.553756\n",
      "epoch 65; iter: 0; batch classifier loss: 0.410818; batch adversarial loss: 0.507030\n",
      "epoch 66; iter: 0; batch classifier loss: 0.374033; batch adversarial loss: 0.583113\n",
      "epoch 67; iter: 0; batch classifier loss: 0.436653; batch adversarial loss: 0.601740\n",
      "epoch 68; iter: 0; batch classifier loss: 0.378807; batch adversarial loss: 0.525692\n",
      "epoch 69; iter: 0; batch classifier loss: 0.461678; batch adversarial loss: 0.610967\n",
      "epoch 70; iter: 0; batch classifier loss: 0.340453; batch adversarial loss: 0.535029\n",
      "epoch 71; iter: 0; batch classifier loss: 0.369526; batch adversarial loss: 0.544384\n",
      "epoch 72; iter: 0; batch classifier loss: 0.383747; batch adversarial loss: 0.525902\n",
      "epoch 73; iter: 0; batch classifier loss: 0.382507; batch adversarial loss: 0.508185\n",
      "epoch 74; iter: 0; batch classifier loss: 0.407860; batch adversarial loss: 0.638188\n",
      "epoch 75; iter: 0; batch classifier loss: 0.366844; batch adversarial loss: 0.459181\n",
      "epoch 76; iter: 0; batch classifier loss: 0.375630; batch adversarial loss: 0.525637\n",
      "epoch 77; iter: 0; batch classifier loss: 0.452616; batch adversarial loss: 0.524424\n",
      "epoch 78; iter: 0; batch classifier loss: 0.439076; batch adversarial loss: 0.544376\n",
      "epoch 79; iter: 0; batch classifier loss: 0.421919; batch adversarial loss: 0.620950\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 80; iter: 0; batch classifier loss: 0.364719; batch adversarial loss: 0.546124\n",
      "epoch 81; iter: 0; batch classifier loss: 0.434069; batch adversarial loss: 0.440219\n",
      "epoch 82; iter: 0; batch classifier loss: 0.382554; batch adversarial loss: 0.516152\n",
      "epoch 83; iter: 0; batch classifier loss: 0.425513; batch adversarial loss: 0.488242\n",
      "epoch 84; iter: 0; batch classifier loss: 0.500372; batch adversarial loss: 0.516524\n",
      "epoch 85; iter: 0; batch classifier loss: 0.460441; batch adversarial loss: 0.563321\n",
      "epoch 86; iter: 0; batch classifier loss: 0.348933; batch adversarial loss: 0.545351\n",
      "epoch 87; iter: 0; batch classifier loss: 0.396355; batch adversarial loss: 0.487851\n",
      "epoch 88; iter: 0; batch classifier loss: 0.405423; batch adversarial loss: 0.612324\n",
      "epoch 89; iter: 0; batch classifier loss: 0.416996; batch adversarial loss: 0.535169\n",
      "epoch 90; iter: 0; batch classifier loss: 0.351608; batch adversarial loss: 0.515815\n",
      "epoch 91; iter: 0; batch classifier loss: 0.431511; batch adversarial loss: 0.524985\n",
      "epoch 92; iter: 0; batch classifier loss: 0.379092; batch adversarial loss: 0.459617\n",
      "epoch 93; iter: 0; batch classifier loss: 0.432799; batch adversarial loss: 0.505226\n",
      "epoch 94; iter: 0; batch classifier loss: 0.372425; batch adversarial loss: 0.554387\n",
      "epoch 95; iter: 0; batch classifier loss: 0.387464; batch adversarial loss: 0.583523\n",
      "epoch 96; iter: 0; batch classifier loss: 0.388664; batch adversarial loss: 0.469396\n",
      "epoch 97; iter: 0; batch classifier loss: 0.368715; batch adversarial loss: 0.459289\n",
      "epoch 98; iter: 0; batch classifier loss: 0.531951; batch adversarial loss: 0.487560\n",
      "epoch 99; iter: 0; batch classifier loss: 0.483042; batch adversarial loss: 0.612273\n",
      "epoch 100; iter: 0; batch classifier loss: 0.331821; batch adversarial loss: 0.526300\n",
      "epoch 101; iter: 0; batch classifier loss: 0.387941; batch adversarial loss: 0.515563\n",
      "epoch 102; iter: 0; batch classifier loss: 0.333684; batch adversarial loss: 0.516327\n",
      "epoch 103; iter: 0; batch classifier loss: 0.429373; batch adversarial loss: 0.516428\n",
      "epoch 104; iter: 0; batch classifier loss: 0.376351; batch adversarial loss: 0.553356\n",
      "epoch 105; iter: 0; batch classifier loss: 0.425445; batch adversarial loss: 0.533580\n",
      "epoch 106; iter: 0; batch classifier loss: 0.435923; batch adversarial loss: 0.517776\n",
      "epoch 107; iter: 0; batch classifier loss: 0.328167; batch adversarial loss: 0.534785\n",
      "epoch 108; iter: 0; batch classifier loss: 0.474102; batch adversarial loss: 0.591434\n",
      "epoch 109; iter: 0; batch classifier loss: 0.402147; batch adversarial loss: 0.554541\n",
      "epoch 110; iter: 0; batch classifier loss: 0.364568; batch adversarial loss: 0.487577\n",
      "epoch 111; iter: 0; batch classifier loss: 0.381936; batch adversarial loss: 0.573830\n",
      "epoch 112; iter: 0; batch classifier loss: 0.432735; batch adversarial loss: 0.581310\n",
      "epoch 113; iter: 0; batch classifier loss: 0.440685; batch adversarial loss: 0.505237\n",
      "epoch 114; iter: 0; batch classifier loss: 0.369384; batch adversarial loss: 0.516012\n",
      "epoch 115; iter: 0; batch classifier loss: 0.429592; batch adversarial loss: 0.543814\n",
      "epoch 116; iter: 0; batch classifier loss: 0.369097; batch adversarial loss: 0.420966\n",
      "epoch 117; iter: 0; batch classifier loss: 0.474154; batch adversarial loss: 0.553836\n",
      "epoch 118; iter: 0; batch classifier loss: 0.407832; batch adversarial loss: 0.554473\n",
      "epoch 119; iter: 0; batch classifier loss: 0.407197; batch adversarial loss: 0.573354\n",
      "epoch 120; iter: 0; batch classifier loss: 0.439071; batch adversarial loss: 0.507397\n",
      "epoch 121; iter: 0; batch classifier loss: 0.300692; batch adversarial loss: 0.526042\n",
      "epoch 122; iter: 0; batch classifier loss: 0.429889; batch adversarial loss: 0.573226\n",
      "epoch 123; iter: 0; batch classifier loss: 0.454497; batch adversarial loss: 0.516895\n",
      "epoch 124; iter: 0; batch classifier loss: 0.363296; batch adversarial loss: 0.572172\n",
      "epoch 125; iter: 0; batch classifier loss: 0.469480; batch adversarial loss: 0.582172\n",
      "epoch 126; iter: 0; batch classifier loss: 0.494149; batch adversarial loss: 0.554199\n",
      "epoch 127; iter: 0; batch classifier loss: 0.382302; batch adversarial loss: 0.564854\n",
      "epoch 128; iter: 0; batch classifier loss: 0.441467; batch adversarial loss: 0.600127\n",
      "epoch 129; iter: 0; batch classifier loss: 0.324540; batch adversarial loss: 0.487748\n",
      "epoch 130; iter: 0; batch classifier loss: 0.524822; batch adversarial loss: 0.516608\n",
      "epoch 131; iter: 0; batch classifier loss: 0.368317; batch adversarial loss: 0.506106\n",
      "epoch 132; iter: 0; batch classifier loss: 0.366854; batch adversarial loss: 0.556394\n",
      "epoch 133; iter: 0; batch classifier loss: 0.370985; batch adversarial loss: 0.554403\n",
      "epoch 134; iter: 0; batch classifier loss: 0.390171; batch adversarial loss: 0.582762\n",
      "epoch 135; iter: 0; batch classifier loss: 0.308800; batch adversarial loss: 0.592480\n",
      "epoch 136; iter: 0; batch classifier loss: 0.354020; batch adversarial loss: 0.515594\n",
      "epoch 137; iter: 0; batch classifier loss: 0.385451; batch adversarial loss: 0.517325\n",
      "epoch 138; iter: 0; batch classifier loss: 0.297473; batch adversarial loss: 0.543846\n",
      "epoch 139; iter: 0; batch classifier loss: 0.383267; batch adversarial loss: 0.525595\n",
      "epoch 140; iter: 0; batch classifier loss: 0.391396; batch adversarial loss: 0.505763\n",
      "epoch 141; iter: 0; batch classifier loss: 0.332035; batch adversarial loss: 0.496855\n",
      "epoch 142; iter: 0; batch classifier loss: 0.388866; batch adversarial loss: 0.477975\n",
      "epoch 143; iter: 0; batch classifier loss: 0.329053; batch adversarial loss: 0.563496\n",
      "epoch 144; iter: 0; batch classifier loss: 0.345624; batch adversarial loss: 0.517074\n",
      "epoch 145; iter: 0; batch classifier loss: 0.380999; batch adversarial loss: 0.603333\n",
      "epoch 146; iter: 0; batch classifier loss: 0.400685; batch adversarial loss: 0.505993\n",
      "epoch 147; iter: 0; batch classifier loss: 0.409513; batch adversarial loss: 0.629567\n",
      "epoch 148; iter: 0; batch classifier loss: 0.316213; batch adversarial loss: 0.582502\n",
      "epoch 149; iter: 0; batch classifier loss: 0.335565; batch adversarial loss: 0.621937\n",
      "epoch 150; iter: 0; batch classifier loss: 0.370070; batch adversarial loss: 0.459727\n",
      "epoch 151; iter: 0; batch classifier loss: 0.363977; batch adversarial loss: 0.572240\n",
      "epoch 152; iter: 0; batch classifier loss: 0.342781; batch adversarial loss: 0.506365\n",
      "epoch 153; iter: 0; batch classifier loss: 0.376486; batch adversarial loss: 0.554345\n",
      "epoch 154; iter: 0; batch classifier loss: 0.312910; batch adversarial loss: 0.505464\n",
      "epoch 155; iter: 0; batch classifier loss: 0.415609; batch adversarial loss: 0.562839\n",
      "epoch 156; iter: 0; batch classifier loss: 0.405660; batch adversarial loss: 0.554176\n",
      "epoch 157; iter: 0; batch classifier loss: 0.371987; batch adversarial loss: 0.591881\n",
      "epoch 158; iter: 0; batch classifier loss: 0.413816; batch adversarial loss: 0.650790\n",
      "epoch 159; iter: 0; batch classifier loss: 0.435592; batch adversarial loss: 0.495737\n",
      "epoch 160; iter: 0; batch classifier loss: 0.481755; batch adversarial loss: 0.555257\n",
      "epoch 161; iter: 0; batch classifier loss: 0.414200; batch adversarial loss: 0.488129\n",
      "epoch 162; iter: 0; batch classifier loss: 0.394333; batch adversarial loss: 0.534357\n",
      "epoch 163; iter: 0; batch classifier loss: 0.353688; batch adversarial loss: 0.526496\n",
      "epoch 164; iter: 0; batch classifier loss: 0.487228; batch adversarial loss: 0.571916\n",
      "epoch 165; iter: 0; batch classifier loss: 0.418763; batch adversarial loss: 0.506486\n",
      "epoch 166; iter: 0; batch classifier loss: 0.304726; batch adversarial loss: 0.487659\n",
      "epoch 167; iter: 0; batch classifier loss: 0.370165; batch adversarial loss: 0.506098\n",
      "epoch 168; iter: 0; batch classifier loss: 0.389816; batch adversarial loss: 0.497175\n",
      "epoch 169; iter: 0; batch classifier loss: 0.353670; batch adversarial loss: 0.601361\n",
      "epoch 170; iter: 0; batch classifier loss: 0.390408; batch adversarial loss: 0.544902\n",
      "epoch 171; iter: 0; batch classifier loss: 0.366302; batch adversarial loss: 0.563394\n",
      "epoch 172; iter: 0; batch classifier loss: 0.402883; batch adversarial loss: 0.620891\n",
      "epoch 173; iter: 0; batch classifier loss: 0.325358; batch adversarial loss: 0.495828\n",
      "epoch 174; iter: 0; batch classifier loss: 0.374900; batch adversarial loss: 0.591416\n",
      "epoch 175; iter: 0; batch classifier loss: 0.392958; batch adversarial loss: 0.563265\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 176; iter: 0; batch classifier loss: 0.383311; batch adversarial loss: 0.583052\n",
      "epoch 177; iter: 0; batch classifier loss: 0.337789; batch adversarial loss: 0.554342\n",
      "epoch 178; iter: 0; batch classifier loss: 0.287175; batch adversarial loss: 0.535857\n",
      "epoch 179; iter: 0; batch classifier loss: 0.405735; batch adversarial loss: 0.477510\n",
      "epoch 180; iter: 0; batch classifier loss: 0.340676; batch adversarial loss: 0.506693\n",
      "epoch 181; iter: 0; batch classifier loss: 0.364534; batch adversarial loss: 0.517289\n",
      "epoch 182; iter: 0; batch classifier loss: 0.405133; batch adversarial loss: 0.572758\n",
      "epoch 183; iter: 0; batch classifier loss: 0.337683; batch adversarial loss: 0.572549\n",
      "epoch 184; iter: 0; batch classifier loss: 0.331766; batch adversarial loss: 0.554707\n",
      "epoch 185; iter: 0; batch classifier loss: 0.400170; batch adversarial loss: 0.630081\n",
      "epoch 186; iter: 0; batch classifier loss: 0.430467; batch adversarial loss: 0.523926\n",
      "epoch 187; iter: 0; batch classifier loss: 0.296962; batch adversarial loss: 0.610988\n",
      "epoch 188; iter: 0; batch classifier loss: 0.423199; batch adversarial loss: 0.469159\n",
      "epoch 189; iter: 0; batch classifier loss: 0.370186; batch adversarial loss: 0.610830\n",
      "epoch 190; iter: 0; batch classifier loss: 0.431781; batch adversarial loss: 0.553709\n",
      "epoch 191; iter: 0; batch classifier loss: 0.372203; batch adversarial loss: 0.573101\n",
      "epoch 192; iter: 0; batch classifier loss: 0.449841; batch adversarial loss: 0.478290\n",
      "epoch 193; iter: 0; batch classifier loss: 0.356865; batch adversarial loss: 0.524999\n",
      "epoch 194; iter: 0; batch classifier loss: 0.357052; batch adversarial loss: 0.620832\n",
      "epoch 195; iter: 0; batch classifier loss: 0.301808; batch adversarial loss: 0.496860\n",
      "epoch 196; iter: 0; batch classifier loss: 0.376925; batch adversarial loss: 0.468157\n",
      "epoch 197; iter: 0; batch classifier loss: 0.361699; batch adversarial loss: 0.505138\n",
      "epoch 198; iter: 0; batch classifier loss: 0.365782; batch adversarial loss: 0.468074\n",
      "epoch 199; iter: 0; batch classifier loss: 0.352734; batch adversarial loss: 0.535760\n",
      "epoch 0; iter: 0; batch classifier loss: 0.701118; batch adversarial loss: 0.666317\n",
      "epoch 1; iter: 0; batch classifier loss: 0.572051; batch adversarial loss: 0.648199\n",
      "epoch 2; iter: 0; batch classifier loss: 0.597799; batch adversarial loss: 0.660406\n",
      "epoch 3; iter: 0; batch classifier loss: 0.578281; batch adversarial loss: 0.638054\n",
      "epoch 4; iter: 0; batch classifier loss: 0.610216; batch adversarial loss: 0.616058\n",
      "epoch 5; iter: 0; batch classifier loss: 0.575173; batch adversarial loss: 0.613552\n",
      "epoch 6; iter: 0; batch classifier loss: 0.534873; batch adversarial loss: 0.655196\n",
      "epoch 7; iter: 0; batch classifier loss: 0.522214; batch adversarial loss: 0.607124\n",
      "epoch 8; iter: 0; batch classifier loss: 0.578259; batch adversarial loss: 0.598287\n",
      "epoch 9; iter: 0; batch classifier loss: 0.601828; batch adversarial loss: 0.580570\n",
      "epoch 10; iter: 0; batch classifier loss: 0.549347; batch adversarial loss: 0.557622\n",
      "epoch 11; iter: 0; batch classifier loss: 0.555033; batch adversarial loss: 0.585660\n",
      "epoch 12; iter: 0; batch classifier loss: 0.493461; batch adversarial loss: 0.588495\n",
      "epoch 13; iter: 0; batch classifier loss: 0.494735; batch adversarial loss: 0.573400\n",
      "epoch 14; iter: 0; batch classifier loss: 0.529008; batch adversarial loss: 0.570418\n",
      "epoch 15; iter: 0; batch classifier loss: 0.505576; batch adversarial loss: 0.567546\n",
      "epoch 16; iter: 0; batch classifier loss: 0.498390; batch adversarial loss: 0.524863\n",
      "epoch 17; iter: 0; batch classifier loss: 0.513052; batch adversarial loss: 0.559968\n",
      "epoch 18; iter: 0; batch classifier loss: 0.547282; batch adversarial loss: 0.600611\n",
      "epoch 19; iter: 0; batch classifier loss: 0.445572; batch adversarial loss: 0.559725\n",
      "epoch 20; iter: 0; batch classifier loss: 0.492658; batch adversarial loss: 0.543491\n",
      "epoch 21; iter: 0; batch classifier loss: 0.521931; batch adversarial loss: 0.556911\n",
      "epoch 22; iter: 0; batch classifier loss: 0.479887; batch adversarial loss: 0.603106\n",
      "epoch 23; iter: 0; batch classifier loss: 0.418794; batch adversarial loss: 0.531968\n",
      "epoch 24; iter: 0; batch classifier loss: 0.505679; batch adversarial loss: 0.489286\n",
      "epoch 25; iter: 0; batch classifier loss: 0.513013; batch adversarial loss: 0.579294\n",
      "epoch 26; iter: 0; batch classifier loss: 0.433955; batch adversarial loss: 0.569916\n",
      "epoch 27; iter: 0; batch classifier loss: 0.439587; batch adversarial loss: 0.605456\n",
      "epoch 28; iter: 0; batch classifier loss: 0.500232; batch adversarial loss: 0.501425\n",
      "epoch 29; iter: 0; batch classifier loss: 0.506270; batch adversarial loss: 0.562745\n",
      "epoch 30; iter: 0; batch classifier loss: 0.439366; batch adversarial loss: 0.491884\n",
      "epoch 31; iter: 0; batch classifier loss: 0.456325; batch adversarial loss: 0.456138\n",
      "epoch 32; iter: 0; batch classifier loss: 0.488853; batch adversarial loss: 0.482935\n",
      "epoch 33; iter: 0; batch classifier loss: 0.454458; batch adversarial loss: 0.545154\n",
      "epoch 34; iter: 0; batch classifier loss: 0.431328; batch adversarial loss: 0.598020\n",
      "epoch 35; iter: 0; batch classifier loss: 0.436191; batch adversarial loss: 0.588839\n",
      "epoch 36; iter: 0; batch classifier loss: 0.450894; batch adversarial loss: 0.489775\n",
      "epoch 37; iter: 0; batch classifier loss: 0.455734; batch adversarial loss: 0.517407\n",
      "epoch 38; iter: 0; batch classifier loss: 0.478888; batch adversarial loss: 0.625718\n",
      "epoch 39; iter: 0; batch classifier loss: 0.523767; batch adversarial loss: 0.600221\n",
      "epoch 40; iter: 0; batch classifier loss: 0.389036; batch adversarial loss: 0.498267\n",
      "epoch 41; iter: 0; batch classifier loss: 0.375525; batch adversarial loss: 0.508077\n",
      "epoch 42; iter: 0; batch classifier loss: 0.415756; batch adversarial loss: 0.525758\n",
      "epoch 43; iter: 0; batch classifier loss: 0.524191; batch adversarial loss: 0.526378\n",
      "epoch 44; iter: 0; batch classifier loss: 0.493400; batch adversarial loss: 0.562886\n",
      "epoch 45; iter: 0; batch classifier loss: 0.507562; batch adversarial loss: 0.590423\n",
      "epoch 46; iter: 0; batch classifier loss: 0.343265; batch adversarial loss: 0.490218\n",
      "epoch 47; iter: 0; batch classifier loss: 0.421418; batch adversarial loss: 0.517131\n",
      "epoch 48; iter: 0; batch classifier loss: 0.388755; batch adversarial loss: 0.589985\n",
      "epoch 49; iter: 0; batch classifier loss: 0.437728; batch adversarial loss: 0.508469\n",
      "epoch 50; iter: 0; batch classifier loss: 0.454216; batch adversarial loss: 0.596838\n",
      "epoch 51; iter: 0; batch classifier loss: 0.433436; batch adversarial loss: 0.561926\n",
      "epoch 52; iter: 0; batch classifier loss: 0.378753; batch adversarial loss: 0.627230\n",
      "epoch 53; iter: 0; batch classifier loss: 0.449602; batch adversarial loss: 0.599498\n",
      "epoch 54; iter: 0; batch classifier loss: 0.487989; batch adversarial loss: 0.523562\n",
      "epoch 55; iter: 0; batch classifier loss: 0.400006; batch adversarial loss: 0.554630\n",
      "epoch 56; iter: 0; batch classifier loss: 0.434222; batch adversarial loss: 0.516337\n",
      "epoch 57; iter: 0; batch classifier loss: 0.407936; batch adversarial loss: 0.516194\n",
      "epoch 58; iter: 0; batch classifier loss: 0.387136; batch adversarial loss: 0.592734\n",
      "epoch 59; iter: 0; batch classifier loss: 0.436863; batch adversarial loss: 0.570840\n",
      "epoch 60; iter: 0; batch classifier loss: 0.396966; batch adversarial loss: 0.552461\n",
      "epoch 61; iter: 0; batch classifier loss: 0.407165; batch adversarial loss: 0.563079\n",
      "epoch 62; iter: 0; batch classifier loss: 0.465946; batch adversarial loss: 0.534374\n",
      "epoch 63; iter: 0; batch classifier loss: 0.398340; batch adversarial loss: 0.608290\n",
      "epoch 64; iter: 0; batch classifier loss: 0.359319; batch adversarial loss: 0.523666\n",
      "epoch 65; iter: 0; batch classifier loss: 0.420609; batch adversarial loss: 0.540870\n",
      "epoch 66; iter: 0; batch classifier loss: 0.347885; batch adversarial loss: 0.516589\n",
      "epoch 67; iter: 0; batch classifier loss: 0.426998; batch adversarial loss: 0.487453\n",
      "epoch 68; iter: 0; batch classifier loss: 0.406591; batch adversarial loss: 0.558977\n",
      "epoch 69; iter: 0; batch classifier loss: 0.384270; batch adversarial loss: 0.545228\n",
      "epoch 70; iter: 0; batch classifier loss: 0.408378; batch adversarial loss: 0.479152\n",
      "epoch 71; iter: 0; batch classifier loss: 0.291104; batch adversarial loss: 0.494631\n",
      "epoch 72; iter: 0; batch classifier loss: 0.382549; batch adversarial loss: 0.496939\n",
      "epoch 73; iter: 0; batch classifier loss: 0.422026; batch adversarial loss: 0.528826\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 74; iter: 0; batch classifier loss: 0.402793; batch adversarial loss: 0.560214\n",
      "epoch 75; iter: 0; batch classifier loss: 0.372492; batch adversarial loss: 0.489244\n",
      "epoch 76; iter: 0; batch classifier loss: 0.390682; batch adversarial loss: 0.506265\n",
      "epoch 77; iter: 0; batch classifier loss: 0.405706; batch adversarial loss: 0.535669\n",
      "epoch 78; iter: 0; batch classifier loss: 0.341311; batch adversarial loss: 0.467411\n",
      "epoch 79; iter: 0; batch classifier loss: 0.418343; batch adversarial loss: 0.574823\n",
      "epoch 80; iter: 0; batch classifier loss: 0.342814; batch adversarial loss: 0.563982\n",
      "epoch 81; iter: 0; batch classifier loss: 0.423839; batch adversarial loss: 0.487847\n",
      "epoch 82; iter: 0; batch classifier loss: 0.403993; batch adversarial loss: 0.554483\n",
      "epoch 83; iter: 0; batch classifier loss: 0.359240; batch adversarial loss: 0.572449\n",
      "epoch 84; iter: 0; batch classifier loss: 0.374047; batch adversarial loss: 0.553930\n",
      "epoch 85; iter: 0; batch classifier loss: 0.393855; batch adversarial loss: 0.507452\n",
      "epoch 86; iter: 0; batch classifier loss: 0.358200; batch adversarial loss: 0.589832\n",
      "epoch 87; iter: 0; batch classifier loss: 0.369326; batch adversarial loss: 0.588876\n",
      "epoch 88; iter: 0; batch classifier loss: 0.345320; batch adversarial loss: 0.535130\n",
      "epoch 89; iter: 0; batch classifier loss: 0.339365; batch adversarial loss: 0.553902\n",
      "epoch 90; iter: 0; batch classifier loss: 0.378976; batch adversarial loss: 0.553896\n",
      "epoch 91; iter: 0; batch classifier loss: 0.326937; batch adversarial loss: 0.592276\n",
      "epoch 92; iter: 0; batch classifier loss: 0.455669; batch adversarial loss: 0.504282\n",
      "epoch 93; iter: 0; batch classifier loss: 0.454902; batch adversarial loss: 0.564360\n",
      "epoch 94; iter: 0; batch classifier loss: 0.450264; batch adversarial loss: 0.536665\n",
      "epoch 95; iter: 0; batch classifier loss: 0.422705; batch adversarial loss: 0.513569\n",
      "epoch 96; iter: 0; batch classifier loss: 0.330771; batch adversarial loss: 0.551379\n",
      "epoch 97; iter: 0; batch classifier loss: 0.381837; batch adversarial loss: 0.533758\n",
      "epoch 98; iter: 0; batch classifier loss: 0.446911; batch adversarial loss: 0.525229\n",
      "epoch 99; iter: 0; batch classifier loss: 0.370845; batch adversarial loss: 0.462075\n",
      "epoch 100; iter: 0; batch classifier loss: 0.411886; batch adversarial loss: 0.581421\n",
      "epoch 101; iter: 0; batch classifier loss: 0.397288; batch adversarial loss: 0.516662\n",
      "epoch 102; iter: 0; batch classifier loss: 0.436943; batch adversarial loss: 0.535272\n",
      "epoch 103; iter: 0; batch classifier loss: 0.277340; batch adversarial loss: 0.565123\n",
      "epoch 104; iter: 0; batch classifier loss: 0.377036; batch adversarial loss: 0.534550\n",
      "epoch 105; iter: 0; batch classifier loss: 0.454759; batch adversarial loss: 0.534680\n",
      "epoch 106; iter: 0; batch classifier loss: 0.399649; batch adversarial loss: 0.517908\n",
      "epoch 107; iter: 0; batch classifier loss: 0.397758; batch adversarial loss: 0.545299\n",
      "epoch 108; iter: 0; batch classifier loss: 0.366453; batch adversarial loss: 0.498289\n",
      "epoch 109; iter: 0; batch classifier loss: 0.357869; batch adversarial loss: 0.536597\n",
      "epoch 110; iter: 0; batch classifier loss: 0.423739; batch adversarial loss: 0.555832\n",
      "epoch 111; iter: 0; batch classifier loss: 0.419781; batch adversarial loss: 0.534217\n",
      "epoch 112; iter: 0; batch classifier loss: 0.365915; batch adversarial loss: 0.573490\n",
      "epoch 113; iter: 0; batch classifier loss: 0.461644; batch adversarial loss: 0.534557\n",
      "epoch 114; iter: 0; batch classifier loss: 0.347056; batch adversarial loss: 0.509575\n",
      "epoch 115; iter: 0; batch classifier loss: 0.430816; batch adversarial loss: 0.542736\n",
      "epoch 116; iter: 0; batch classifier loss: 0.335892; batch adversarial loss: 0.524336\n",
      "epoch 117; iter: 0; batch classifier loss: 0.461170; batch adversarial loss: 0.600679\n",
      "epoch 118; iter: 0; batch classifier loss: 0.345816; batch adversarial loss: 0.608832\n",
      "epoch 119; iter: 0; batch classifier loss: 0.302281; batch adversarial loss: 0.514794\n",
      "epoch 120; iter: 0; batch classifier loss: 0.354000; batch adversarial loss: 0.570042\n",
      "epoch 121; iter: 0; batch classifier loss: 0.270983; batch adversarial loss: 0.619147\n",
      "epoch 122; iter: 0; batch classifier loss: 0.327035; batch adversarial loss: 0.543415\n",
      "epoch 123; iter: 0; batch classifier loss: 0.267741; batch adversarial loss: 0.482086\n",
      "epoch 124; iter: 0; batch classifier loss: 0.402198; batch adversarial loss: 0.404321\n",
      "epoch 125; iter: 0; batch classifier loss: 0.351244; batch adversarial loss: 0.467125\n",
      "epoch 126; iter: 0; batch classifier loss: 0.306639; batch adversarial loss: 0.516973\n",
      "epoch 127; iter: 0; batch classifier loss: 0.415859; batch adversarial loss: 0.534023\n",
      "epoch 128; iter: 0; batch classifier loss: 0.395339; batch adversarial loss: 0.601882\n",
      "epoch 129; iter: 0; batch classifier loss: 0.348707; batch adversarial loss: 0.481219\n",
      "epoch 130; iter: 0; batch classifier loss: 0.318599; batch adversarial loss: 0.524453\n",
      "epoch 131; iter: 0; batch classifier loss: 0.425025; batch adversarial loss: 0.537712\n",
      "epoch 132; iter: 0; batch classifier loss: 0.363842; batch adversarial loss: 0.572612\n",
      "epoch 133; iter: 0; batch classifier loss: 0.387953; batch adversarial loss: 0.551784\n",
      "epoch 134; iter: 0; batch classifier loss: 0.372970; batch adversarial loss: 0.555977\n",
      "epoch 135; iter: 0; batch classifier loss: 0.362648; batch adversarial loss: 0.502728\n",
      "epoch 136; iter: 0; batch classifier loss: 0.408147; batch adversarial loss: 0.536208\n",
      "epoch 137; iter: 0; batch classifier loss: 0.291375; batch adversarial loss: 0.543955\n",
      "epoch 138; iter: 0; batch classifier loss: 0.346970; batch adversarial loss: 0.551838\n",
      "epoch 139; iter: 0; batch classifier loss: 0.256766; batch adversarial loss: 0.637925\n",
      "epoch 140; iter: 0; batch classifier loss: 0.356027; batch adversarial loss: 0.542429\n",
      "epoch 141; iter: 0; batch classifier loss: 0.351841; batch adversarial loss: 0.561423\n",
      "epoch 142; iter: 0; batch classifier loss: 0.328969; batch adversarial loss: 0.526464\n",
      "epoch 143; iter: 0; batch classifier loss: 0.357268; batch adversarial loss: 0.439991\n",
      "epoch 144; iter: 0; batch classifier loss: 0.399319; batch adversarial loss: 0.529020\n",
      "epoch 145; iter: 0; batch classifier loss: 0.339505; batch adversarial loss: 0.598480\n",
      "epoch 146; iter: 0; batch classifier loss: 0.422444; batch adversarial loss: 0.545357\n",
      "epoch 147; iter: 0; batch classifier loss: 0.339018; batch adversarial loss: 0.477476\n",
      "epoch 148; iter: 0; batch classifier loss: 0.466154; batch adversarial loss: 0.628305\n",
      "epoch 149; iter: 0; batch classifier loss: 0.334324; batch adversarial loss: 0.571729\n",
      "epoch 150; iter: 0; batch classifier loss: 0.307479; batch adversarial loss: 0.506857\n",
      "epoch 151; iter: 0; batch classifier loss: 0.421276; batch adversarial loss: 0.545327\n",
      "epoch 152; iter: 0; batch classifier loss: 0.410392; batch adversarial loss: 0.556095\n",
      "epoch 153; iter: 0; batch classifier loss: 0.300205; batch adversarial loss: 0.506719\n",
      "epoch 154; iter: 0; batch classifier loss: 0.350174; batch adversarial loss: 0.555671\n",
      "epoch 155; iter: 0; batch classifier loss: 0.304413; batch adversarial loss: 0.527405\n",
      "epoch 156; iter: 0; batch classifier loss: 0.437686; batch adversarial loss: 0.533486\n",
      "epoch 157; iter: 0; batch classifier loss: 0.356464; batch adversarial loss: 0.517406\n",
      "epoch 158; iter: 0; batch classifier loss: 0.404905; batch adversarial loss: 0.479666\n",
      "epoch 159; iter: 0; batch classifier loss: 0.347744; batch adversarial loss: 0.467506\n",
      "epoch 160; iter: 0; batch classifier loss: 0.453448; batch adversarial loss: 0.552911\n",
      "epoch 161; iter: 0; batch classifier loss: 0.339059; batch adversarial loss: 0.487705\n",
      "epoch 162; iter: 0; batch classifier loss: 0.301153; batch adversarial loss: 0.543316\n",
      "epoch 163; iter: 0; batch classifier loss: 0.400804; batch adversarial loss: 0.589769\n",
      "epoch 164; iter: 0; batch classifier loss: 0.312305; batch adversarial loss: 0.553654\n",
      "epoch 165; iter: 0; batch classifier loss: 0.330593; batch adversarial loss: 0.513753\n",
      "epoch 166; iter: 0; batch classifier loss: 0.325465; batch adversarial loss: 0.507132\n",
      "epoch 167; iter: 0; batch classifier loss: 0.342880; batch adversarial loss: 0.504622\n",
      "epoch 168; iter: 0; batch classifier loss: 0.320819; batch adversarial loss: 0.566249\n",
      "epoch 169; iter: 0; batch classifier loss: 0.388375; batch adversarial loss: 0.535611\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 170; iter: 0; batch classifier loss: 0.238889; batch adversarial loss: 0.552550\n",
      "epoch 171; iter: 0; batch classifier loss: 0.437453; batch adversarial loss: 0.552341\n",
      "epoch 172; iter: 0; batch classifier loss: 0.395453; batch adversarial loss: 0.604334\n",
      "epoch 173; iter: 0; batch classifier loss: 0.334713; batch adversarial loss: 0.606390\n",
      "epoch 174; iter: 0; batch classifier loss: 0.388166; batch adversarial loss: 0.497242\n",
      "epoch 175; iter: 0; batch classifier loss: 0.360438; batch adversarial loss: 0.486360\n",
      "epoch 176; iter: 0; batch classifier loss: 0.362295; batch adversarial loss: 0.498441\n",
      "epoch 177; iter: 0; batch classifier loss: 0.347615; batch adversarial loss: 0.613249\n",
      "epoch 178; iter: 0; batch classifier loss: 0.350380; batch adversarial loss: 0.534244\n",
      "epoch 179; iter: 0; batch classifier loss: 0.416373; batch adversarial loss: 0.571584\n",
      "epoch 180; iter: 0; batch classifier loss: 0.382762; batch adversarial loss: 0.542377\n",
      "epoch 181; iter: 0; batch classifier loss: 0.296945; batch adversarial loss: 0.550273\n",
      "epoch 182; iter: 0; batch classifier loss: 0.296602; batch adversarial loss: 0.518699\n",
      "epoch 183; iter: 0; batch classifier loss: 0.408701; batch adversarial loss: 0.570364\n",
      "epoch 184; iter: 0; batch classifier loss: 0.362591; batch adversarial loss: 0.633746\n",
      "epoch 185; iter: 0; batch classifier loss: 0.359856; batch adversarial loss: 0.517022\n",
      "epoch 186; iter: 0; batch classifier loss: 0.353532; batch adversarial loss: 0.569631\n",
      "epoch 187; iter: 0; batch classifier loss: 0.287954; batch adversarial loss: 0.451775\n",
      "epoch 188; iter: 0; batch classifier loss: 0.453866; batch adversarial loss: 0.535244\n",
      "epoch 189; iter: 0; batch classifier loss: 0.342754; batch adversarial loss: 0.530455\n",
      "epoch 190; iter: 0; batch classifier loss: 0.306719; batch adversarial loss: 0.488542\n",
      "epoch 191; iter: 0; batch classifier loss: 0.323133; batch adversarial loss: 0.509447\n",
      "epoch 192; iter: 0; batch classifier loss: 0.361310; batch adversarial loss: 0.584278\n",
      "epoch 193; iter: 0; batch classifier loss: 0.300565; batch adversarial loss: 0.508236\n",
      "epoch 194; iter: 0; batch classifier loss: 0.396381; batch adversarial loss: 0.589456\n",
      "epoch 195; iter: 0; batch classifier loss: 0.365242; batch adversarial loss: 0.514211\n",
      "epoch 196; iter: 0; batch classifier loss: 0.396480; batch adversarial loss: 0.510671\n",
      "epoch 197; iter: 0; batch classifier loss: 0.356447; batch adversarial loss: 0.584147\n",
      "epoch 198; iter: 0; batch classifier loss: 0.404403; batch adversarial loss: 0.665914\n",
      "epoch 199; iter: 0; batch classifier loss: 0.315547; batch adversarial loss: 0.563966\n",
      "epoch 0; iter: 0; batch classifier loss: 0.755361; batch adversarial loss: 0.596732\n",
      "epoch 1; iter: 0; batch classifier loss: 0.588058; batch adversarial loss: 0.657727\n",
      "epoch 2; iter: 0; batch classifier loss: 0.694281; batch adversarial loss: 0.649349\n",
      "epoch 3; iter: 0; batch classifier loss: 0.550632; batch adversarial loss: 0.623169\n",
      "epoch 4; iter: 0; batch classifier loss: 0.548437; batch adversarial loss: 0.653998\n",
      "epoch 5; iter: 0; batch classifier loss: 0.558515; batch adversarial loss: 0.618852\n",
      "epoch 6; iter: 0; batch classifier loss: 0.487416; batch adversarial loss: 0.598666\n",
      "epoch 7; iter: 0; batch classifier loss: 0.575083; batch adversarial loss: 0.586725\n",
      "epoch 8; iter: 0; batch classifier loss: 0.551843; batch adversarial loss: 0.638675\n",
      "epoch 9; iter: 0; batch classifier loss: 0.598433; batch adversarial loss: 0.607685\n",
      "epoch 10; iter: 0; batch classifier loss: 0.559708; batch adversarial loss: 0.555942\n",
      "epoch 11; iter: 0; batch classifier loss: 0.450720; batch adversarial loss: 0.565215\n",
      "epoch 12; iter: 0; batch classifier loss: 0.525317; batch adversarial loss: 0.534123\n",
      "epoch 13; iter: 0; batch classifier loss: 0.529394; batch adversarial loss: 0.545963\n",
      "epoch 14; iter: 0; batch classifier loss: 0.542104; batch adversarial loss: 0.566147\n",
      "epoch 15; iter: 0; batch classifier loss: 0.499307; batch adversarial loss: 0.622640\n",
      "epoch 16; iter: 0; batch classifier loss: 0.483290; batch adversarial loss: 0.560071\n",
      "epoch 17; iter: 0; batch classifier loss: 0.547474; batch adversarial loss: 0.565112\n",
      "epoch 18; iter: 0; batch classifier loss: 0.535231; batch adversarial loss: 0.500759\n",
      "epoch 19; iter: 0; batch classifier loss: 0.507041; batch adversarial loss: 0.585357\n",
      "epoch 20; iter: 0; batch classifier loss: 0.578383; batch adversarial loss: 0.527012\n",
      "epoch 21; iter: 0; batch classifier loss: 0.514119; batch adversarial loss: 0.505745\n",
      "epoch 22; iter: 0; batch classifier loss: 0.458942; batch adversarial loss: 0.568676\n",
      "epoch 23; iter: 0; batch classifier loss: 0.422824; batch adversarial loss: 0.562691\n",
      "epoch 24; iter: 0; batch classifier loss: 0.493740; batch adversarial loss: 0.524367\n",
      "epoch 25; iter: 0; batch classifier loss: 0.507427; batch adversarial loss: 0.581015\n",
      "epoch 26; iter: 0; batch classifier loss: 0.480125; batch adversarial loss: 0.513900\n",
      "epoch 27; iter: 0; batch classifier loss: 0.494893; batch adversarial loss: 0.557260\n",
      "epoch 28; iter: 0; batch classifier loss: 0.409310; batch adversarial loss: 0.571805\n",
      "epoch 29; iter: 0; batch classifier loss: 0.447174; batch adversarial loss: 0.531802\n",
      "epoch 30; iter: 0; batch classifier loss: 0.410332; batch adversarial loss: 0.583658\n",
      "epoch 31; iter: 0; batch classifier loss: 0.460363; batch adversarial loss: 0.569811\n",
      "epoch 32; iter: 0; batch classifier loss: 0.450852; batch adversarial loss: 0.553661\n",
      "epoch 33; iter: 0; batch classifier loss: 0.461781; batch adversarial loss: 0.509414\n",
      "epoch 34; iter: 0; batch classifier loss: 0.488184; batch adversarial loss: 0.519007\n",
      "epoch 35; iter: 0; batch classifier loss: 0.452323; batch adversarial loss: 0.587170\n",
      "epoch 36; iter: 0; batch classifier loss: 0.433416; batch adversarial loss: 0.543941\n",
      "epoch 37; iter: 0; batch classifier loss: 0.446792; batch adversarial loss: 0.584301\n",
      "epoch 38; iter: 0; batch classifier loss: 0.506130; batch adversarial loss: 0.487680\n",
      "epoch 39; iter: 0; batch classifier loss: 0.431731; batch adversarial loss: 0.584990\n",
      "epoch 40; iter: 0; batch classifier loss: 0.390791; batch adversarial loss: 0.482036\n",
      "epoch 41; iter: 0; batch classifier loss: 0.397798; batch adversarial loss: 0.563086\n",
      "epoch 42; iter: 0; batch classifier loss: 0.415483; batch adversarial loss: 0.538464\n",
      "epoch 43; iter: 0; batch classifier loss: 0.487698; batch adversarial loss: 0.580197\n",
      "epoch 44; iter: 0; batch classifier loss: 0.396638; batch adversarial loss: 0.551477\n",
      "epoch 45; iter: 0; batch classifier loss: 0.485446; batch adversarial loss: 0.574046\n",
      "epoch 46; iter: 0; batch classifier loss: 0.445471; batch adversarial loss: 0.573923\n",
      "epoch 47; iter: 0; batch classifier loss: 0.474365; batch adversarial loss: 0.554471\n",
      "epoch 48; iter: 0; batch classifier loss: 0.385486; batch adversarial loss: 0.465670\n",
      "epoch 49; iter: 0; batch classifier loss: 0.433060; batch adversarial loss: 0.615718\n",
      "epoch 50; iter: 0; batch classifier loss: 0.412619; batch adversarial loss: 0.582117\n",
      "epoch 51; iter: 0; batch classifier loss: 0.485802; batch adversarial loss: 0.523560\n",
      "epoch 52; iter: 0; batch classifier loss: 0.401960; batch adversarial loss: 0.506194\n",
      "epoch 53; iter: 0; batch classifier loss: 0.422486; batch adversarial loss: 0.567469\n",
      "epoch 54; iter: 0; batch classifier loss: 0.465840; batch adversarial loss: 0.507579\n",
      "epoch 55; iter: 0; batch classifier loss: 0.455633; batch adversarial loss: 0.582353\n",
      "epoch 56; iter: 0; batch classifier loss: 0.365000; batch adversarial loss: 0.563707\n",
      "epoch 57; iter: 0; batch classifier loss: 0.386976; batch adversarial loss: 0.600132\n",
      "epoch 58; iter: 0; batch classifier loss: 0.428313; batch adversarial loss: 0.516141\n",
      "epoch 59; iter: 0; batch classifier loss: 0.476910; batch adversarial loss: 0.561332\n",
      "epoch 60; iter: 0; batch classifier loss: 0.433269; batch adversarial loss: 0.582152\n",
      "epoch 61; iter: 0; batch classifier loss: 0.406352; batch adversarial loss: 0.543455\n",
      "epoch 62; iter: 0; batch classifier loss: 0.363308; batch adversarial loss: 0.527495\n",
      "epoch 63; iter: 0; batch classifier loss: 0.366186; batch adversarial loss: 0.572711\n",
      "epoch 64; iter: 0; batch classifier loss: 0.502483; batch adversarial loss: 0.562635\n",
      "epoch 65; iter: 0; batch classifier loss: 0.350695; batch adversarial loss: 0.584146\n",
      "epoch 66; iter: 0; batch classifier loss: 0.385610; batch adversarial loss: 0.598628\n",
      "epoch 67; iter: 0; batch classifier loss: 0.385058; batch adversarial loss: 0.600736\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 68; iter: 0; batch classifier loss: 0.454889; batch adversarial loss: 0.561465\n",
      "epoch 69; iter: 0; batch classifier loss: 0.455326; batch adversarial loss: 0.534299\n",
      "epoch 70; iter: 0; batch classifier loss: 0.401896; batch adversarial loss: 0.553122\n",
      "epoch 71; iter: 0; batch classifier loss: 0.502722; batch adversarial loss: 0.533113\n",
      "epoch 72; iter: 0; batch classifier loss: 0.367317; batch adversarial loss: 0.506389\n",
      "epoch 73; iter: 0; batch classifier loss: 0.357623; batch adversarial loss: 0.528383\n",
      "epoch 74; iter: 0; batch classifier loss: 0.349896; batch adversarial loss: 0.507222\n",
      "epoch 75; iter: 0; batch classifier loss: 0.346988; batch adversarial loss: 0.571924\n",
      "epoch 76; iter: 0; batch classifier loss: 0.430064; batch adversarial loss: 0.584760\n",
      "epoch 77; iter: 0; batch classifier loss: 0.438382; batch adversarial loss: 0.574235\n",
      "epoch 78; iter: 0; batch classifier loss: 0.381500; batch adversarial loss: 0.517763\n",
      "epoch 79; iter: 0; batch classifier loss: 0.344290; batch adversarial loss: 0.567936\n",
      "epoch 80; iter: 0; batch classifier loss: 0.430941; batch adversarial loss: 0.525466\n",
      "epoch 81; iter: 0; batch classifier loss: 0.445279; batch adversarial loss: 0.536007\n",
      "epoch 82; iter: 0; batch classifier loss: 0.407041; batch adversarial loss: 0.563826\n",
      "epoch 83; iter: 0; batch classifier loss: 0.440610; batch adversarial loss: 0.506742\n",
      "epoch 84; iter: 0; batch classifier loss: 0.388862; batch adversarial loss: 0.480222\n",
      "epoch 85; iter: 0; batch classifier loss: 0.373118; batch adversarial loss: 0.515154\n",
      "epoch 86; iter: 0; batch classifier loss: 0.391125; batch adversarial loss: 0.509118\n",
      "epoch 87; iter: 0; batch classifier loss: 0.335184; batch adversarial loss: 0.590086\n",
      "epoch 88; iter: 0; batch classifier loss: 0.371762; batch adversarial loss: 0.453047\n",
      "epoch 89; iter: 0; batch classifier loss: 0.431479; batch adversarial loss: 0.580492\n",
      "epoch 90; iter: 0; batch classifier loss: 0.421960; batch adversarial loss: 0.515784\n",
      "epoch 91; iter: 0; batch classifier loss: 0.352530; batch adversarial loss: 0.470586\n",
      "epoch 92; iter: 0; batch classifier loss: 0.390509; batch adversarial loss: 0.544658\n",
      "epoch 93; iter: 0; batch classifier loss: 0.328705; batch adversarial loss: 0.640925\n",
      "epoch 94; iter: 0; batch classifier loss: 0.401081; batch adversarial loss: 0.578667\n",
      "epoch 95; iter: 0; batch classifier loss: 0.378067; batch adversarial loss: 0.545189\n",
      "epoch 96; iter: 0; batch classifier loss: 0.355399; batch adversarial loss: 0.515941\n",
      "epoch 97; iter: 0; batch classifier loss: 0.369363; batch adversarial loss: 0.455056\n",
      "epoch 98; iter: 0; batch classifier loss: 0.304523; batch adversarial loss: 0.552409\n",
      "epoch 99; iter: 0; batch classifier loss: 0.476351; batch adversarial loss: 0.568166\n",
      "epoch 100; iter: 0; batch classifier loss: 0.433081; batch adversarial loss: 0.462397\n",
      "epoch 101; iter: 0; batch classifier loss: 0.354713; batch adversarial loss: 0.582722\n",
      "epoch 102; iter: 0; batch classifier loss: 0.326534; batch adversarial loss: 0.552237\n",
      "epoch 103; iter: 0; batch classifier loss: 0.417340; batch adversarial loss: 0.506756\n",
      "epoch 104; iter: 0; batch classifier loss: 0.468191; batch adversarial loss: 0.585872\n",
      "epoch 105; iter: 0; batch classifier loss: 0.286906; batch adversarial loss: 0.517430\n",
      "epoch 106; iter: 0; batch classifier loss: 0.382293; batch adversarial loss: 0.608425\n",
      "epoch 107; iter: 0; batch classifier loss: 0.374140; batch adversarial loss: 0.522765\n",
      "epoch 108; iter: 0; batch classifier loss: 0.338332; batch adversarial loss: 0.589856\n",
      "epoch 109; iter: 0; batch classifier loss: 0.348758; batch adversarial loss: 0.572435\n",
      "epoch 110; iter: 0; batch classifier loss: 0.410198; batch adversarial loss: 0.524631\n",
      "epoch 111; iter: 0; batch classifier loss: 0.422361; batch adversarial loss: 0.580382\n",
      "epoch 112; iter: 0; batch classifier loss: 0.292933; batch adversarial loss: 0.516212\n",
      "epoch 113; iter: 0; batch classifier loss: 0.481044; batch adversarial loss: 0.550806\n",
      "epoch 114; iter: 0; batch classifier loss: 0.452762; batch adversarial loss: 0.554306\n",
      "epoch 115; iter: 0; batch classifier loss: 0.371938; batch adversarial loss: 0.648998\n",
      "epoch 116; iter: 0; batch classifier loss: 0.356462; batch adversarial loss: 0.581765\n",
      "epoch 117; iter: 0; batch classifier loss: 0.357940; batch adversarial loss: 0.616037\n",
      "epoch 118; iter: 0; batch classifier loss: 0.387720; batch adversarial loss: 0.655348\n",
      "epoch 119; iter: 0; batch classifier loss: 0.310537; batch adversarial loss: 0.577421\n",
      "epoch 120; iter: 0; batch classifier loss: 0.343748; batch adversarial loss: 0.501370\n",
      "epoch 121; iter: 0; batch classifier loss: 0.411560; batch adversarial loss: 0.565104\n",
      "epoch 122; iter: 0; batch classifier loss: 0.363020; batch adversarial loss: 0.564012\n",
      "epoch 123; iter: 0; batch classifier loss: 0.329047; batch adversarial loss: 0.582737\n",
      "epoch 124; iter: 0; batch classifier loss: 0.382939; batch adversarial loss: 0.633340\n",
      "epoch 125; iter: 0; batch classifier loss: 0.348092; batch adversarial loss: 0.598828\n",
      "epoch 126; iter: 0; batch classifier loss: 0.370498; batch adversarial loss: 0.553941\n",
      "epoch 127; iter: 0; batch classifier loss: 0.401729; batch adversarial loss: 0.635043\n",
      "epoch 128; iter: 0; batch classifier loss: 0.458758; batch adversarial loss: 0.525985\n",
      "epoch 129; iter: 0; batch classifier loss: 0.450090; batch adversarial loss: 0.524336\n",
      "epoch 130; iter: 0; batch classifier loss: 0.321308; batch adversarial loss: 0.591125\n",
      "epoch 131; iter: 0; batch classifier loss: 0.406812; batch adversarial loss: 0.572143\n",
      "epoch 132; iter: 0; batch classifier loss: 0.347441; batch adversarial loss: 0.524290\n",
      "epoch 133; iter: 0; batch classifier loss: 0.312755; batch adversarial loss: 0.518581\n",
      "epoch 134; iter: 0; batch classifier loss: 0.346040; batch adversarial loss: 0.478212\n",
      "epoch 135; iter: 0; batch classifier loss: 0.429465; batch adversarial loss: 0.559091\n",
      "epoch 136; iter: 0; batch classifier loss: 0.300626; batch adversarial loss: 0.491003\n",
      "epoch 137; iter: 0; batch classifier loss: 0.370893; batch adversarial loss: 0.609986\n",
      "epoch 138; iter: 0; batch classifier loss: 0.324716; batch adversarial loss: 0.551520\n",
      "epoch 139; iter: 0; batch classifier loss: 0.285485; batch adversarial loss: 0.533021\n",
      "epoch 140; iter: 0; batch classifier loss: 0.387871; batch adversarial loss: 0.535450\n",
      "epoch 141; iter: 0; batch classifier loss: 0.358994; batch adversarial loss: 0.488904\n",
      "epoch 142; iter: 0; batch classifier loss: 0.393351; batch adversarial loss: 0.557634\n",
      "epoch 143; iter: 0; batch classifier loss: 0.374404; batch adversarial loss: 0.563147\n",
      "epoch 144; iter: 0; batch classifier loss: 0.355379; batch adversarial loss: 0.633641\n",
      "epoch 145; iter: 0; batch classifier loss: 0.335329; batch adversarial loss: 0.544146\n",
      "epoch 146; iter: 0; batch classifier loss: 0.358808; batch adversarial loss: 0.536307\n",
      "epoch 147; iter: 0; batch classifier loss: 0.383297; batch adversarial loss: 0.717661\n",
      "epoch 148; iter: 0; batch classifier loss: 0.360897; batch adversarial loss: 0.587404\n",
      "epoch 149; iter: 0; batch classifier loss: 0.432514; batch adversarial loss: 0.535419\n",
      "epoch 150; iter: 0; batch classifier loss: 0.378085; batch adversarial loss: 0.506837\n",
      "epoch 151; iter: 0; batch classifier loss: 0.359824; batch adversarial loss: 0.571961\n",
      "epoch 152; iter: 0; batch classifier loss: 0.331649; batch adversarial loss: 0.574214\n",
      "epoch 153; iter: 0; batch classifier loss: 0.416767; batch adversarial loss: 0.517519\n",
      "epoch 154; iter: 0; batch classifier loss: 0.362003; batch adversarial loss: 0.479405\n",
      "epoch 155; iter: 0; batch classifier loss: 0.423320; batch adversarial loss: 0.655131\n",
      "epoch 156; iter: 0; batch classifier loss: 0.458124; batch adversarial loss: 0.533528\n",
      "epoch 157; iter: 0; batch classifier loss: 0.350010; batch adversarial loss: 0.596756\n",
      "epoch 158; iter: 0; batch classifier loss: 0.334627; batch adversarial loss: 0.584291\n",
      "epoch 159; iter: 0; batch classifier loss: 0.284434; batch adversarial loss: 0.491227\n",
      "epoch 160; iter: 0; batch classifier loss: 0.339226; batch adversarial loss: 0.535379\n",
      "epoch 161; iter: 0; batch classifier loss: 0.398158; batch adversarial loss: 0.492359\n",
      "epoch 162; iter: 0; batch classifier loss: 0.357673; batch adversarial loss: 0.516023\n",
      "epoch 163; iter: 0; batch classifier loss: 0.373942; batch adversarial loss: 0.590679\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 164; iter: 0; batch classifier loss: 0.322043; batch adversarial loss: 0.550140\n",
      "epoch 165; iter: 0; batch classifier loss: 0.373600; batch adversarial loss: 0.653050\n",
      "epoch 166; iter: 0; batch classifier loss: 0.301775; batch adversarial loss: 0.544385\n",
      "epoch 167; iter: 0; batch classifier loss: 0.319123; batch adversarial loss: 0.491074\n",
      "epoch 168; iter: 0; batch classifier loss: 0.313239; batch adversarial loss: 0.473244\n",
      "epoch 169; iter: 0; batch classifier loss: 0.346301; batch adversarial loss: 0.532939\n",
      "epoch 170; iter: 0; batch classifier loss: 0.360074; batch adversarial loss: 0.603105\n",
      "epoch 171; iter: 0; batch classifier loss: 0.396707; batch adversarial loss: 0.590155\n",
      "epoch 172; iter: 0; batch classifier loss: 0.321987; batch adversarial loss: 0.663817\n",
      "epoch 173; iter: 0; batch classifier loss: 0.436765; batch adversarial loss: 0.646273\n",
      "epoch 174; iter: 0; batch classifier loss: 0.416345; batch adversarial loss: 0.586983\n",
      "epoch 175; iter: 0; batch classifier loss: 0.349942; batch adversarial loss: 0.562745\n",
      "epoch 176; iter: 0; batch classifier loss: 0.360427; batch adversarial loss: 0.598763\n",
      "epoch 177; iter: 0; batch classifier loss: 0.251483; batch adversarial loss: 0.527499\n",
      "epoch 178; iter: 0; batch classifier loss: 0.387427; batch adversarial loss: 0.518279\n",
      "epoch 179; iter: 0; batch classifier loss: 0.370639; batch adversarial loss: 0.617788\n",
      "epoch 180; iter: 0; batch classifier loss: 0.341072; batch adversarial loss: 0.551515\n",
      "epoch 181; iter: 0; batch classifier loss: 0.375980; batch adversarial loss: 0.555333\n",
      "epoch 182; iter: 0; batch classifier loss: 0.327926; batch adversarial loss: 0.560979\n",
      "epoch 183; iter: 0; batch classifier loss: 0.338599; batch adversarial loss: 0.499507\n",
      "epoch 184; iter: 0; batch classifier loss: 0.320026; batch adversarial loss: 0.590317\n",
      "epoch 185; iter: 0; batch classifier loss: 0.401764; batch adversarial loss: 0.520009\n",
      "epoch 186; iter: 0; batch classifier loss: 0.400276; batch adversarial loss: 0.525651\n",
      "epoch 187; iter: 0; batch classifier loss: 0.373085; batch adversarial loss: 0.560656\n",
      "epoch 188; iter: 0; batch classifier loss: 0.365999; batch adversarial loss: 0.479581\n",
      "epoch 189; iter: 0; batch classifier loss: 0.295040; batch adversarial loss: 0.571363\n",
      "epoch 190; iter: 0; batch classifier loss: 0.375614; batch adversarial loss: 0.564549\n",
      "epoch 191; iter: 0; batch classifier loss: 0.410564; batch adversarial loss: 0.518887\n",
      "epoch 192; iter: 0; batch classifier loss: 0.311253; batch adversarial loss: 0.501710\n",
      "epoch 193; iter: 0; batch classifier loss: 0.395862; batch adversarial loss: 0.490904\n",
      "epoch 194; iter: 0; batch classifier loss: 0.330611; batch adversarial loss: 0.562292\n",
      "epoch 195; iter: 0; batch classifier loss: 0.360072; batch adversarial loss: 0.641690\n",
      "epoch 196; iter: 0; batch classifier loss: 0.390533; batch adversarial loss: 0.535397\n",
      "epoch 197; iter: 0; batch classifier loss: 0.375541; batch adversarial loss: 0.517826\n",
      "epoch 198; iter: 0; batch classifier loss: 0.309459; batch adversarial loss: 0.590455\n",
      "epoch 199; iter: 0; batch classifier loss: 0.377521; batch adversarial loss: 0.451976\n",
      "epoch 0; iter: 0; batch classifier loss: 0.728716; batch adversarial loss: 0.951497\n",
      "epoch 1; iter: 0; batch classifier loss: 0.759777; batch adversarial loss: 1.060714\n",
      "epoch 2; iter: 0; batch classifier loss: 0.858484; batch adversarial loss: 0.978760\n",
      "epoch 3; iter: 0; batch classifier loss: 0.812453; batch adversarial loss: 0.900808\n",
      "epoch 4; iter: 0; batch classifier loss: 0.734121; batch adversarial loss: 0.798931\n",
      "epoch 5; iter: 0; batch classifier loss: 0.593265; batch adversarial loss: 0.744099\n",
      "epoch 6; iter: 0; batch classifier loss: 0.565454; batch adversarial loss: 0.689444\n",
      "epoch 7; iter: 0; batch classifier loss: 0.595240; batch adversarial loss: 0.659125\n",
      "epoch 8; iter: 0; batch classifier loss: 0.574986; batch adversarial loss: 0.624757\n",
      "epoch 9; iter: 0; batch classifier loss: 0.518828; batch adversarial loss: 0.585666\n",
      "epoch 10; iter: 0; batch classifier loss: 0.560503; batch adversarial loss: 0.611010\n",
      "epoch 11; iter: 0; batch classifier loss: 0.542357; batch adversarial loss: 0.578500\n",
      "epoch 12; iter: 0; batch classifier loss: 0.508090; batch adversarial loss: 0.572967\n",
      "epoch 13; iter: 0; batch classifier loss: 0.408534; batch adversarial loss: 0.638138\n",
      "epoch 14; iter: 0; batch classifier loss: 0.554769; batch adversarial loss: 0.558172\n",
      "epoch 15; iter: 0; batch classifier loss: 0.575620; batch adversarial loss: 0.580663\n",
      "epoch 16; iter: 0; batch classifier loss: 0.482695; batch adversarial loss: 0.566260\n",
      "epoch 17; iter: 0; batch classifier loss: 0.513197; batch adversarial loss: 0.534435\n",
      "epoch 18; iter: 0; batch classifier loss: 0.464255; batch adversarial loss: 0.574887\n",
      "epoch 19; iter: 0; batch classifier loss: 0.522419; batch adversarial loss: 0.531011\n",
      "epoch 20; iter: 0; batch classifier loss: 0.530184; batch adversarial loss: 0.539156\n",
      "epoch 21; iter: 0; batch classifier loss: 0.582457; batch adversarial loss: 0.610232\n",
      "epoch 22; iter: 0; batch classifier loss: 0.450128; batch adversarial loss: 0.631620\n",
      "epoch 23; iter: 0; batch classifier loss: 0.501906; batch adversarial loss: 0.567796\n",
      "epoch 24; iter: 0; batch classifier loss: 0.459743; batch adversarial loss: 0.527575\n",
      "epoch 25; iter: 0; batch classifier loss: 0.484577; batch adversarial loss: 0.626733\n",
      "epoch 26; iter: 0; batch classifier loss: 0.459492; batch adversarial loss: 0.574052\n",
      "epoch 27; iter: 0; batch classifier loss: 0.402759; batch adversarial loss: 0.547312\n",
      "epoch 28; iter: 0; batch classifier loss: 0.453079; batch adversarial loss: 0.569995\n",
      "epoch 29; iter: 0; batch classifier loss: 0.462588; batch adversarial loss: 0.484457\n",
      "epoch 30; iter: 0; batch classifier loss: 0.453147; batch adversarial loss: 0.596473\n",
      "epoch 31; iter: 0; batch classifier loss: 0.532827; batch adversarial loss: 0.467810\n",
      "epoch 32; iter: 0; batch classifier loss: 0.506762; batch adversarial loss: 0.613339\n",
      "epoch 33; iter: 0; batch classifier loss: 0.495419; batch adversarial loss: 0.569869\n",
      "epoch 34; iter: 0; batch classifier loss: 0.491035; batch adversarial loss: 0.542218\n",
      "epoch 35; iter: 0; batch classifier loss: 0.454073; batch adversarial loss: 0.470361\n",
      "epoch 36; iter: 0; batch classifier loss: 0.433170; batch adversarial loss: 0.583073\n",
      "epoch 37; iter: 0; batch classifier loss: 0.534979; batch adversarial loss: 0.533595\n",
      "epoch 38; iter: 0; batch classifier loss: 0.461363; batch adversarial loss: 0.527419\n",
      "epoch 39; iter: 0; batch classifier loss: 0.434067; batch adversarial loss: 0.502215\n",
      "epoch 40; iter: 0; batch classifier loss: 0.490110; batch adversarial loss: 0.567336\n",
      "epoch 41; iter: 0; batch classifier loss: 0.469740; batch adversarial loss: 0.478393\n",
      "epoch 42; iter: 0; batch classifier loss: 0.417380; batch adversarial loss: 0.508935\n",
      "epoch 43; iter: 0; batch classifier loss: 0.462050; batch adversarial loss: 0.492465\n",
      "epoch 44; iter: 0; batch classifier loss: 0.393944; batch adversarial loss: 0.487119\n",
      "epoch 45; iter: 0; batch classifier loss: 0.435158; batch adversarial loss: 0.510647\n",
      "epoch 46; iter: 0; batch classifier loss: 0.412838; batch adversarial loss: 0.551854\n",
      "epoch 47; iter: 0; batch classifier loss: 0.437122; batch adversarial loss: 0.564697\n",
      "epoch 48; iter: 0; batch classifier loss: 0.487253; batch adversarial loss: 0.507400\n",
      "epoch 49; iter: 0; batch classifier loss: 0.446078; batch adversarial loss: 0.563938\n",
      "epoch 50; iter: 0; batch classifier loss: 0.402970; batch adversarial loss: 0.550980\n",
      "epoch 51; iter: 0; batch classifier loss: 0.498288; batch adversarial loss: 0.581283\n",
      "epoch 52; iter: 0; batch classifier loss: 0.458153; batch adversarial loss: 0.525205\n",
      "epoch 53; iter: 0; batch classifier loss: 0.397909; batch adversarial loss: 0.545126\n",
      "epoch 54; iter: 0; batch classifier loss: 0.434649; batch adversarial loss: 0.577552\n",
      "epoch 55; iter: 0; batch classifier loss: 0.454191; batch adversarial loss: 0.447898\n",
      "epoch 56; iter: 0; batch classifier loss: 0.443294; batch adversarial loss: 0.641945\n",
      "epoch 57; iter: 0; batch classifier loss: 0.417840; batch adversarial loss: 0.608725\n",
      "epoch 58; iter: 0; batch classifier loss: 0.428205; batch adversarial loss: 0.496284\n",
      "epoch 59; iter: 0; batch classifier loss: 0.407317; batch adversarial loss: 0.535040\n",
      "epoch 60; iter: 0; batch classifier loss: 0.397534; batch adversarial loss: 0.582160\n",
      "epoch 61; iter: 0; batch classifier loss: 0.459654; batch adversarial loss: 0.551586\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 62; iter: 0; batch classifier loss: 0.397717; batch adversarial loss: 0.554384\n",
      "epoch 63; iter: 0; batch classifier loss: 0.405003; batch adversarial loss: 0.545491\n",
      "epoch 64; iter: 0; batch classifier loss: 0.359878; batch adversarial loss: 0.553777\n",
      "epoch 65; iter: 0; batch classifier loss: 0.447692; batch adversarial loss: 0.543887\n",
      "epoch 66; iter: 0; batch classifier loss: 0.387004; batch adversarial loss: 0.531731\n",
      "epoch 67; iter: 0; batch classifier loss: 0.439684; batch adversarial loss: 0.540444\n",
      "epoch 68; iter: 0; batch classifier loss: 0.393674; batch adversarial loss: 0.546853\n",
      "epoch 69; iter: 0; batch classifier loss: 0.349859; batch adversarial loss: 0.483747\n",
      "epoch 70; iter: 0; batch classifier loss: 0.369553; batch adversarial loss: 0.624950\n",
      "epoch 71; iter: 0; batch classifier loss: 0.462694; batch adversarial loss: 0.452021\n",
      "epoch 72; iter: 0; batch classifier loss: 0.409596; batch adversarial loss: 0.627456\n",
      "epoch 73; iter: 0; batch classifier loss: 0.390038; batch adversarial loss: 0.588455\n",
      "epoch 74; iter: 0; batch classifier loss: 0.405478; batch adversarial loss: 0.554042\n",
      "epoch 75; iter: 0; batch classifier loss: 0.429297; batch adversarial loss: 0.537843\n",
      "epoch 76; iter: 0; batch classifier loss: 0.429214; batch adversarial loss: 0.555598\n",
      "epoch 77; iter: 0; batch classifier loss: 0.334867; batch adversarial loss: 0.619143\n",
      "epoch 78; iter: 0; batch classifier loss: 0.483591; batch adversarial loss: 0.619620\n",
      "epoch 79; iter: 0; batch classifier loss: 0.393593; batch adversarial loss: 0.520925\n",
      "epoch 80; iter: 0; batch classifier loss: 0.421020; batch adversarial loss: 0.502711\n",
      "epoch 81; iter: 0; batch classifier loss: 0.391312; batch adversarial loss: 0.543504\n",
      "epoch 82; iter: 0; batch classifier loss: 0.358554; batch adversarial loss: 0.502281\n",
      "epoch 83; iter: 0; batch classifier loss: 0.459196; batch adversarial loss: 0.525079\n",
      "epoch 84; iter: 0; batch classifier loss: 0.369704; batch adversarial loss: 0.578891\n",
      "epoch 85; iter: 0; batch classifier loss: 0.385196; batch adversarial loss: 0.534640\n",
      "epoch 86; iter: 0; batch classifier loss: 0.362959; batch adversarial loss: 0.565028\n",
      "epoch 87; iter: 0; batch classifier loss: 0.450608; batch adversarial loss: 0.460657\n",
      "epoch 88; iter: 0; batch classifier loss: 0.396585; batch adversarial loss: 0.593297\n",
      "epoch 89; iter: 0; batch classifier loss: 0.438490; batch adversarial loss: 0.412070\n",
      "epoch 90; iter: 0; batch classifier loss: 0.317758; batch adversarial loss: 0.528997\n",
      "epoch 91; iter: 0; batch classifier loss: 0.449235; batch adversarial loss: 0.590758\n",
      "epoch 92; iter: 0; batch classifier loss: 0.442729; batch adversarial loss: 0.486724\n",
      "epoch 93; iter: 0; batch classifier loss: 0.441305; batch adversarial loss: 0.560627\n",
      "epoch 94; iter: 0; batch classifier loss: 0.394985; batch adversarial loss: 0.507842\n",
      "epoch 95; iter: 0; batch classifier loss: 0.387964; batch adversarial loss: 0.574296\n",
      "epoch 96; iter: 0; batch classifier loss: 0.400408; batch adversarial loss: 0.521641\n",
      "epoch 97; iter: 0; batch classifier loss: 0.369196; batch adversarial loss: 0.596749\n",
      "epoch 98; iter: 0; batch classifier loss: 0.452205; batch adversarial loss: 0.517438\n",
      "epoch 99; iter: 0; batch classifier loss: 0.406187; batch adversarial loss: 0.624926\n",
      "epoch 100; iter: 0; batch classifier loss: 0.367583; batch adversarial loss: 0.586197\n",
      "epoch 101; iter: 0; batch classifier loss: 0.325151; batch adversarial loss: 0.473437\n",
      "epoch 102; iter: 0; batch classifier loss: 0.395872; batch adversarial loss: 0.580076\n",
      "epoch 103; iter: 0; batch classifier loss: 0.398071; batch adversarial loss: 0.527087\n",
      "epoch 104; iter: 0; batch classifier loss: 0.378343; batch adversarial loss: 0.546699\n",
      "epoch 105; iter: 0; batch classifier loss: 0.324410; batch adversarial loss: 0.565734\n",
      "epoch 106; iter: 0; batch classifier loss: 0.408785; batch adversarial loss: 0.466765\n",
      "epoch 107; iter: 0; batch classifier loss: 0.364782; batch adversarial loss: 0.531252\n",
      "epoch 108; iter: 0; batch classifier loss: 0.370862; batch adversarial loss: 0.571333\n",
      "epoch 109; iter: 0; batch classifier loss: 0.317554; batch adversarial loss: 0.521174\n",
      "epoch 110; iter: 0; batch classifier loss: 0.492519; batch adversarial loss: 0.536743\n",
      "epoch 111; iter: 0; batch classifier loss: 0.364286; batch adversarial loss: 0.576786\n",
      "epoch 112; iter: 0; batch classifier loss: 0.376457; batch adversarial loss: 0.513490\n",
      "epoch 113; iter: 0; batch classifier loss: 0.443117; batch adversarial loss: 0.586112\n",
      "epoch 114; iter: 0; batch classifier loss: 0.419929; batch adversarial loss: 0.577075\n",
      "epoch 115; iter: 0; batch classifier loss: 0.347979; batch adversarial loss: 0.556845\n",
      "epoch 116; iter: 0; batch classifier loss: 0.361778; batch adversarial loss: 0.534574\n",
      "epoch 117; iter: 0; batch classifier loss: 0.351916; batch adversarial loss: 0.537614\n",
      "epoch 118; iter: 0; batch classifier loss: 0.414020; batch adversarial loss: 0.460994\n",
      "epoch 119; iter: 0; batch classifier loss: 0.487340; batch adversarial loss: 0.629149\n",
      "epoch 120; iter: 0; batch classifier loss: 0.460464; batch adversarial loss: 0.526660\n",
      "epoch 121; iter: 0; batch classifier loss: 0.373995; batch adversarial loss: 0.555985\n",
      "epoch 122; iter: 0; batch classifier loss: 0.298847; batch adversarial loss: 0.509451\n",
      "epoch 123; iter: 0; batch classifier loss: 0.317982; batch adversarial loss: 0.486399\n",
      "epoch 124; iter: 0; batch classifier loss: 0.451895; batch adversarial loss: 0.516434\n",
      "epoch 125; iter: 0; batch classifier loss: 0.336813; batch adversarial loss: 0.612765\n",
      "epoch 126; iter: 0; batch classifier loss: 0.363461; batch adversarial loss: 0.549299\n",
      "epoch 127; iter: 0; batch classifier loss: 0.416796; batch adversarial loss: 0.470657\n",
      "epoch 128; iter: 0; batch classifier loss: 0.425944; batch adversarial loss: 0.593011\n",
      "epoch 129; iter: 0; batch classifier loss: 0.334670; batch adversarial loss: 0.609343\n",
      "epoch 130; iter: 0; batch classifier loss: 0.371315; batch adversarial loss: 0.544345\n",
      "epoch 131; iter: 0; batch classifier loss: 0.281362; batch adversarial loss: 0.615727\n",
      "epoch 132; iter: 0; batch classifier loss: 0.426772; batch adversarial loss: 0.529958\n",
      "epoch 133; iter: 0; batch classifier loss: 0.394117; batch adversarial loss: 0.613104\n",
      "epoch 134; iter: 0; batch classifier loss: 0.338907; batch adversarial loss: 0.507289\n",
      "epoch 135; iter: 0; batch classifier loss: 0.335412; batch adversarial loss: 0.592201\n",
      "epoch 136; iter: 0; batch classifier loss: 0.389234; batch adversarial loss: 0.602221\n",
      "epoch 137; iter: 0; batch classifier loss: 0.350467; batch adversarial loss: 0.580541\n",
      "epoch 138; iter: 0; batch classifier loss: 0.348456; batch adversarial loss: 0.499797\n",
      "epoch 139; iter: 0; batch classifier loss: 0.383610; batch adversarial loss: 0.526943\n",
      "epoch 140; iter: 0; batch classifier loss: 0.406561; batch adversarial loss: 0.546423\n",
      "epoch 141; iter: 0; batch classifier loss: 0.318105; batch adversarial loss: 0.610880\n",
      "epoch 142; iter: 0; batch classifier loss: 0.326868; batch adversarial loss: 0.579319\n",
      "epoch 143; iter: 0; batch classifier loss: 0.466201; batch adversarial loss: 0.592455\n",
      "epoch 144; iter: 0; batch classifier loss: 0.308136; batch adversarial loss: 0.511788\n",
      "epoch 145; iter: 0; batch classifier loss: 0.416640; batch adversarial loss: 0.579876\n",
      "epoch 146; iter: 0; batch classifier loss: 0.326363; batch adversarial loss: 0.653281\n",
      "epoch 147; iter: 0; batch classifier loss: 0.374929; batch adversarial loss: 0.631543\n",
      "epoch 148; iter: 0; batch classifier loss: 0.362447; batch adversarial loss: 0.568918\n",
      "epoch 149; iter: 0; batch classifier loss: 0.447775; batch adversarial loss: 0.600372\n",
      "epoch 150; iter: 0; batch classifier loss: 0.448845; batch adversarial loss: 0.564522\n",
      "epoch 151; iter: 0; batch classifier loss: 0.367586; batch adversarial loss: 0.573296\n",
      "epoch 152; iter: 0; batch classifier loss: 0.421827; batch adversarial loss: 0.522294\n",
      "epoch 153; iter: 0; batch classifier loss: 0.343704; batch adversarial loss: 0.554774\n",
      "epoch 154; iter: 0; batch classifier loss: 0.438066; batch adversarial loss: 0.586658\n",
      "epoch 155; iter: 0; batch classifier loss: 0.330657; batch adversarial loss: 0.512736\n",
      "epoch 156; iter: 0; batch classifier loss: 0.363735; batch adversarial loss: 0.547866\n",
      "epoch 157; iter: 0; batch classifier loss: 0.327622; batch adversarial loss: 0.510319\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 158; iter: 0; batch classifier loss: 0.352615; batch adversarial loss: 0.582213\n",
      "epoch 159; iter: 0; batch classifier loss: 0.347447; batch adversarial loss: 0.545200\n",
      "epoch 160; iter: 0; batch classifier loss: 0.410025; batch adversarial loss: 0.500111\n",
      "epoch 161; iter: 0; batch classifier loss: 0.402093; batch adversarial loss: 0.633824\n",
      "epoch 162; iter: 0; batch classifier loss: 0.331554; batch adversarial loss: 0.528201\n",
      "epoch 163; iter: 0; batch classifier loss: 0.410231; batch adversarial loss: 0.448148\n",
      "epoch 164; iter: 0; batch classifier loss: 0.395708; batch adversarial loss: 0.510125\n",
      "epoch 165; iter: 0; batch classifier loss: 0.339952; batch adversarial loss: 0.629027\n",
      "epoch 166; iter: 0; batch classifier loss: 0.416767; batch adversarial loss: 0.613335\n",
      "epoch 167; iter: 0; batch classifier loss: 0.335488; batch adversarial loss: 0.553589\n",
      "epoch 168; iter: 0; batch classifier loss: 0.365537; batch adversarial loss: 0.529956\n",
      "epoch 169; iter: 0; batch classifier loss: 0.348050; batch adversarial loss: 0.612159\n",
      "epoch 170; iter: 0; batch classifier loss: 0.380717; batch adversarial loss: 0.498054\n",
      "epoch 171; iter: 0; batch classifier loss: 0.354358; batch adversarial loss: 0.495400\n",
      "epoch 172; iter: 0; batch classifier loss: 0.363237; batch adversarial loss: 0.553755\n",
      "epoch 173; iter: 0; batch classifier loss: 0.388423; batch adversarial loss: 0.490192\n",
      "epoch 174; iter: 0; batch classifier loss: 0.336092; batch adversarial loss: 0.427407\n",
      "epoch 175; iter: 0; batch classifier loss: 0.357658; batch adversarial loss: 0.492970\n",
      "epoch 176; iter: 0; batch classifier loss: 0.354240; batch adversarial loss: 0.610353\n",
      "epoch 177; iter: 0; batch classifier loss: 0.388810; batch adversarial loss: 0.601207\n",
      "epoch 178; iter: 0; batch classifier loss: 0.348550; batch adversarial loss: 0.558766\n",
      "epoch 179; iter: 0; batch classifier loss: 0.331935; batch adversarial loss: 0.577544\n",
      "epoch 180; iter: 0; batch classifier loss: 0.359777; batch adversarial loss: 0.515707\n",
      "epoch 181; iter: 0; batch classifier loss: 0.371493; batch adversarial loss: 0.507416\n",
      "epoch 182; iter: 0; batch classifier loss: 0.365806; batch adversarial loss: 0.580887\n",
      "epoch 183; iter: 0; batch classifier loss: 0.354406; batch adversarial loss: 0.505041\n",
      "epoch 184; iter: 0; batch classifier loss: 0.366994; batch adversarial loss: 0.568137\n",
      "epoch 185; iter: 0; batch classifier loss: 0.352687; batch adversarial loss: 0.571254\n",
      "epoch 186; iter: 0; batch classifier loss: 0.390349; batch adversarial loss: 0.570811\n",
      "epoch 187; iter: 0; batch classifier loss: 0.352556; batch adversarial loss: 0.516500\n",
      "epoch 188; iter: 0; batch classifier loss: 0.300554; batch adversarial loss: 0.677686\n",
      "epoch 189; iter: 0; batch classifier loss: 0.383123; batch adversarial loss: 0.579780\n",
      "epoch 190; iter: 0; batch classifier loss: 0.344301; batch adversarial loss: 0.537936\n",
      "epoch 191; iter: 0; batch classifier loss: 0.365339; batch adversarial loss: 0.558097\n",
      "epoch 192; iter: 0; batch classifier loss: 0.391572; batch adversarial loss: 0.515316\n",
      "epoch 193; iter: 0; batch classifier loss: 0.428867; batch adversarial loss: 0.532278\n",
      "epoch 194; iter: 0; batch classifier loss: 0.293160; batch adversarial loss: 0.541167\n",
      "epoch 195; iter: 0; batch classifier loss: 0.331580; batch adversarial loss: 0.598982\n",
      "epoch 196; iter: 0; batch classifier loss: 0.415069; batch adversarial loss: 0.561292\n",
      "epoch 197; iter: 0; batch classifier loss: 0.286097; batch adversarial loss: 0.506289\n",
      "epoch 198; iter: 0; batch classifier loss: 0.422098; batch adversarial loss: 0.546261\n",
      "epoch 199; iter: 0; batch classifier loss: 0.330532; batch adversarial loss: 0.552561\n",
      "epoch 0; iter: 0; batch classifier loss: 0.712746; batch adversarial loss: 0.689582\n",
      "epoch 1; iter: 0; batch classifier loss: 0.577509; batch adversarial loss: 0.662985\n",
      "epoch 2; iter: 0; batch classifier loss: 0.551405; batch adversarial loss: 0.638641\n",
      "epoch 3; iter: 0; batch classifier loss: 0.566684; batch adversarial loss: 0.628760\n",
      "epoch 4; iter: 0; batch classifier loss: 0.502926; batch adversarial loss: 0.621945\n",
      "epoch 5; iter: 0; batch classifier loss: 0.549485; batch adversarial loss: 0.645953\n",
      "epoch 6; iter: 0; batch classifier loss: 0.496031; batch adversarial loss: 0.612901\n",
      "epoch 7; iter: 0; batch classifier loss: 0.591993; batch adversarial loss: 0.559665\n",
      "epoch 8; iter: 0; batch classifier loss: 0.588425; batch adversarial loss: 0.523332\n",
      "epoch 9; iter: 0; batch classifier loss: 0.523644; batch adversarial loss: 0.594410\n",
      "epoch 10; iter: 0; batch classifier loss: 0.515920; batch adversarial loss: 0.584102\n",
      "epoch 11; iter: 0; batch classifier loss: 0.589346; batch adversarial loss: 0.521502\n",
      "epoch 12; iter: 0; batch classifier loss: 0.520290; batch adversarial loss: 0.613255\n",
      "epoch 13; iter: 0; batch classifier loss: 0.455069; batch adversarial loss: 0.601620\n",
      "epoch 14; iter: 0; batch classifier loss: 0.534144; batch adversarial loss: 0.549762\n",
      "epoch 15; iter: 0; batch classifier loss: 0.526113; batch adversarial loss: 0.548836\n",
      "epoch 16; iter: 0; batch classifier loss: 0.543704; batch adversarial loss: 0.565581\n",
      "epoch 17; iter: 0; batch classifier loss: 0.512206; batch adversarial loss: 0.517007\n",
      "epoch 18; iter: 0; batch classifier loss: 0.466856; batch adversarial loss: 0.597645\n",
      "epoch 19; iter: 0; batch classifier loss: 0.522882; batch adversarial loss: 0.592633\n",
      "epoch 20; iter: 0; batch classifier loss: 0.519344; batch adversarial loss: 0.527586\n",
      "epoch 21; iter: 0; batch classifier loss: 0.480405; batch adversarial loss: 0.502830\n",
      "epoch 22; iter: 0; batch classifier loss: 0.460509; batch adversarial loss: 0.500355\n",
      "epoch 23; iter: 0; batch classifier loss: 0.485916; batch adversarial loss: 0.571972\n",
      "epoch 24; iter: 0; batch classifier loss: 0.491815; batch adversarial loss: 0.563092\n",
      "epoch 25; iter: 0; batch classifier loss: 0.494899; batch adversarial loss: 0.563442\n",
      "epoch 26; iter: 0; batch classifier loss: 0.530896; batch adversarial loss: 0.546697\n",
      "epoch 27; iter: 0; batch classifier loss: 0.467434; batch adversarial loss: 0.555190\n",
      "epoch 28; iter: 0; batch classifier loss: 0.473431; batch adversarial loss: 0.487746\n",
      "epoch 29; iter: 0; batch classifier loss: 0.530042; batch adversarial loss: 0.511810\n",
      "epoch 30; iter: 0; batch classifier loss: 0.468644; batch adversarial loss: 0.503254\n",
      "epoch 31; iter: 0; batch classifier loss: 0.515058; batch adversarial loss: 0.492652\n",
      "epoch 32; iter: 0; batch classifier loss: 0.439331; batch adversarial loss: 0.605815\n",
      "epoch 33; iter: 0; batch classifier loss: 0.464581; batch adversarial loss: 0.518566\n",
      "epoch 34; iter: 0; batch classifier loss: 0.536420; batch adversarial loss: 0.589062\n",
      "epoch 35; iter: 0; batch classifier loss: 0.419725; batch adversarial loss: 0.580352\n",
      "epoch 36; iter: 0; batch classifier loss: 0.450159; batch adversarial loss: 0.606755\n",
      "epoch 37; iter: 0; batch classifier loss: 0.513130; batch adversarial loss: 0.474167\n",
      "epoch 38; iter: 0; batch classifier loss: 0.488104; batch adversarial loss: 0.518015\n",
      "epoch 39; iter: 0; batch classifier loss: 0.434934; batch adversarial loss: 0.588978\n",
      "epoch 40; iter: 0; batch classifier loss: 0.460559; batch adversarial loss: 0.491129\n",
      "epoch 41; iter: 0; batch classifier loss: 0.443302; batch adversarial loss: 0.526617\n",
      "epoch 42; iter: 0; batch classifier loss: 0.424661; batch adversarial loss: 0.625019\n",
      "epoch 43; iter: 0; batch classifier loss: 0.438591; batch adversarial loss: 0.553147\n",
      "epoch 44; iter: 0; batch classifier loss: 0.400327; batch adversarial loss: 0.562506\n",
      "epoch 45; iter: 0; batch classifier loss: 0.367001; batch adversarial loss: 0.563754\n",
      "epoch 46; iter: 0; batch classifier loss: 0.407329; batch adversarial loss: 0.516439\n",
      "epoch 47; iter: 0; batch classifier loss: 0.490479; batch adversarial loss: 0.580495\n",
      "epoch 48; iter: 0; batch classifier loss: 0.465915; batch adversarial loss: 0.560594\n",
      "epoch 49; iter: 0; batch classifier loss: 0.405974; batch adversarial loss: 0.519152\n",
      "epoch 50; iter: 0; batch classifier loss: 0.381304; batch adversarial loss: 0.598322\n",
      "epoch 51; iter: 0; batch classifier loss: 0.380544; batch adversarial loss: 0.507281\n",
      "epoch 52; iter: 0; batch classifier loss: 0.355494; batch adversarial loss: 0.537512\n",
      "epoch 53; iter: 0; batch classifier loss: 0.367163; batch adversarial loss: 0.587362\n",
      "epoch 54; iter: 0; batch classifier loss: 0.432848; batch adversarial loss: 0.472636\n",
      "epoch 55; iter: 0; batch classifier loss: 0.422490; batch adversarial loss: 0.554178\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 56; iter: 0; batch classifier loss: 0.412916; batch adversarial loss: 0.619158\n",
      "epoch 57; iter: 0; batch classifier loss: 0.423393; batch adversarial loss: 0.655637\n",
      "epoch 58; iter: 0; batch classifier loss: 0.405694; batch adversarial loss: 0.542713\n",
      "epoch 59; iter: 0; batch classifier loss: 0.381312; batch adversarial loss: 0.562360\n",
      "epoch 60; iter: 0; batch classifier loss: 0.423600; batch adversarial loss: 0.481408\n",
      "epoch 61; iter: 0; batch classifier loss: 0.407564; batch adversarial loss: 0.608755\n",
      "epoch 62; iter: 0; batch classifier loss: 0.438106; batch adversarial loss: 0.561169\n",
      "epoch 63; iter: 0; batch classifier loss: 0.394880; batch adversarial loss: 0.543481\n",
      "epoch 64; iter: 0; batch classifier loss: 0.440674; batch adversarial loss: 0.571761\n",
      "epoch 65; iter: 0; batch classifier loss: 0.417252; batch adversarial loss: 0.541940\n",
      "epoch 66; iter: 0; batch classifier loss: 0.409759; batch adversarial loss: 0.527298\n",
      "epoch 67; iter: 0; batch classifier loss: 0.418689; batch adversarial loss: 0.516620\n",
      "epoch 68; iter: 0; batch classifier loss: 0.403274; batch adversarial loss: 0.543522\n",
      "epoch 69; iter: 0; batch classifier loss: 0.392746; batch adversarial loss: 0.545450\n",
      "epoch 70; iter: 0; batch classifier loss: 0.418705; batch adversarial loss: 0.710116\n",
      "epoch 71; iter: 0; batch classifier loss: 0.350532; batch adversarial loss: 0.499658\n",
      "epoch 72; iter: 0; batch classifier loss: 0.428760; batch adversarial loss: 0.587922\n",
      "epoch 73; iter: 0; batch classifier loss: 0.445328; batch adversarial loss: 0.555412\n",
      "epoch 74; iter: 0; batch classifier loss: 0.430874; batch adversarial loss: 0.582770\n",
      "epoch 75; iter: 0; batch classifier loss: 0.448513; batch adversarial loss: 0.592316\n",
      "epoch 76; iter: 0; batch classifier loss: 0.454792; batch adversarial loss: 0.544496\n",
      "epoch 77; iter: 0; batch classifier loss: 0.464729; batch adversarial loss: 0.517315\n",
      "epoch 78; iter: 0; batch classifier loss: 0.373899; batch adversarial loss: 0.544418\n",
      "epoch 79; iter: 0; batch classifier loss: 0.420100; batch adversarial loss: 0.536573\n",
      "epoch 80; iter: 0; batch classifier loss: 0.422534; batch adversarial loss: 0.480882\n",
      "epoch 81; iter: 0; batch classifier loss: 0.385039; batch adversarial loss: 0.561395\n",
      "epoch 82; iter: 0; batch classifier loss: 0.392143; batch adversarial loss: 0.581262\n",
      "epoch 83; iter: 0; batch classifier loss: 0.402772; batch adversarial loss: 0.508066\n",
      "epoch 84; iter: 0; batch classifier loss: 0.419192; batch adversarial loss: 0.535344\n",
      "epoch 85; iter: 0; batch classifier loss: 0.440568; batch adversarial loss: 0.427391\n",
      "epoch 86; iter: 0; batch classifier loss: 0.350078; batch adversarial loss: 0.606801\n",
      "epoch 87; iter: 0; batch classifier loss: 0.397965; batch adversarial loss: 0.506922\n",
      "epoch 88; iter: 0; batch classifier loss: 0.388645; batch adversarial loss: 0.472181\n",
      "epoch 89; iter: 0; batch classifier loss: 0.371523; batch adversarial loss: 0.552299\n",
      "epoch 90; iter: 0; batch classifier loss: 0.388035; batch adversarial loss: 0.581723\n",
      "epoch 91; iter: 0; batch classifier loss: 0.474364; batch adversarial loss: 0.555033\n",
      "epoch 92; iter: 0; batch classifier loss: 0.410221; batch adversarial loss: 0.589547\n",
      "epoch 93; iter: 0; batch classifier loss: 0.385332; batch adversarial loss: 0.579970\n",
      "epoch 94; iter: 0; batch classifier loss: 0.485137; batch adversarial loss: 0.545336\n",
      "epoch 95; iter: 0; batch classifier loss: 0.416731; batch adversarial loss: 0.535323\n",
      "epoch 96; iter: 0; batch classifier loss: 0.345391; batch adversarial loss: 0.626267\n",
      "epoch 97; iter: 0; batch classifier loss: 0.428330; batch adversarial loss: 0.552400\n",
      "epoch 98; iter: 0; batch classifier loss: 0.454853; batch adversarial loss: 0.527148\n",
      "epoch 99; iter: 0; batch classifier loss: 0.436889; batch adversarial loss: 0.597981\n",
      "epoch 100; iter: 0; batch classifier loss: 0.355848; batch adversarial loss: 0.563517\n",
      "epoch 101; iter: 0; batch classifier loss: 0.491087; batch adversarial loss: 0.562104\n",
      "epoch 102; iter: 0; batch classifier loss: 0.358789; batch adversarial loss: 0.572244\n",
      "epoch 103; iter: 0; batch classifier loss: 0.420841; batch adversarial loss: 0.552761\n",
      "epoch 104; iter: 0; batch classifier loss: 0.416682; batch adversarial loss: 0.551396\n",
      "epoch 105; iter: 0; batch classifier loss: 0.376208; batch adversarial loss: 0.507050\n",
      "epoch 106; iter: 0; batch classifier loss: 0.506436; batch adversarial loss: 0.607447\n",
      "epoch 107; iter: 0; batch classifier loss: 0.355212; batch adversarial loss: 0.453121\n",
      "epoch 108; iter: 0; batch classifier loss: 0.411018; batch adversarial loss: 0.498728\n",
      "epoch 109; iter: 0; batch classifier loss: 0.443230; batch adversarial loss: 0.561795\n",
      "epoch 110; iter: 0; batch classifier loss: 0.343671; batch adversarial loss: 0.606393\n",
      "epoch 111; iter: 0; batch classifier loss: 0.410569; batch adversarial loss: 0.516544\n",
      "epoch 112; iter: 0; batch classifier loss: 0.405006; batch adversarial loss: 0.573257\n",
      "epoch 113; iter: 0; batch classifier loss: 0.450648; batch adversarial loss: 0.580645\n",
      "epoch 114; iter: 0; batch classifier loss: 0.381866; batch adversarial loss: 0.544741\n",
      "epoch 115; iter: 0; batch classifier loss: 0.306552; batch adversarial loss: 0.573274\n",
      "epoch 116; iter: 0; batch classifier loss: 0.324373; batch adversarial loss: 0.516027\n",
      "epoch 117; iter: 0; batch classifier loss: 0.398175; batch adversarial loss: 0.590816\n",
      "epoch 118; iter: 0; batch classifier loss: 0.464022; batch adversarial loss: 0.462717\n",
      "epoch 119; iter: 0; batch classifier loss: 0.365825; batch adversarial loss: 0.510587\n",
      "epoch 120; iter: 0; batch classifier loss: 0.329439; batch adversarial loss: 0.570812\n",
      "epoch 121; iter: 0; batch classifier loss: 0.338265; batch adversarial loss: 0.553240\n",
      "epoch 122; iter: 0; batch classifier loss: 0.348670; batch adversarial loss: 0.581351\n",
      "epoch 123; iter: 0; batch classifier loss: 0.429231; batch adversarial loss: 0.579605\n",
      "epoch 124; iter: 0; batch classifier loss: 0.389244; batch adversarial loss: 0.580781\n",
      "epoch 125; iter: 0; batch classifier loss: 0.437381; batch adversarial loss: 0.590162\n",
      "epoch 126; iter: 0; batch classifier loss: 0.368511; batch adversarial loss: 0.517857\n",
      "epoch 127; iter: 0; batch classifier loss: 0.484331; batch adversarial loss: 0.472327\n",
      "epoch 128; iter: 0; batch classifier loss: 0.377665; batch adversarial loss: 0.635917\n",
      "epoch 129; iter: 0; batch classifier loss: 0.327648; batch adversarial loss: 0.507889\n",
      "epoch 130; iter: 0; batch classifier loss: 0.359309; batch adversarial loss: 0.615182\n",
      "epoch 131; iter: 0; batch classifier loss: 0.355726; batch adversarial loss: 0.553166\n",
      "epoch 132; iter: 0; batch classifier loss: 0.348529; batch adversarial loss: 0.646237\n",
      "epoch 133; iter: 0; batch classifier loss: 0.384809; batch adversarial loss: 0.500028\n",
      "epoch 134; iter: 0; batch classifier loss: 0.352210; batch adversarial loss: 0.517363\n",
      "epoch 135; iter: 0; batch classifier loss: 0.334798; batch adversarial loss: 0.572215\n",
      "epoch 136; iter: 0; batch classifier loss: 0.381376; batch adversarial loss: 0.508536\n",
      "epoch 137; iter: 0; batch classifier loss: 0.423514; batch adversarial loss: 0.554455\n",
      "epoch 138; iter: 0; batch classifier loss: 0.438950; batch adversarial loss: 0.517094\n",
      "epoch 139; iter: 0; batch classifier loss: 0.376815; batch adversarial loss: 0.507721\n",
      "epoch 140; iter: 0; batch classifier loss: 0.309712; batch adversarial loss: 0.552701\n",
      "epoch 141; iter: 0; batch classifier loss: 0.411678; batch adversarial loss: 0.616915\n",
      "epoch 142; iter: 0; batch classifier loss: 0.322677; batch adversarial loss: 0.536796\n",
      "epoch 143; iter: 0; batch classifier loss: 0.433693; batch adversarial loss: 0.481240\n",
      "epoch 144; iter: 0; batch classifier loss: 0.439802; batch adversarial loss: 0.508325\n",
      "epoch 145; iter: 0; batch classifier loss: 0.431996; batch adversarial loss: 0.553298\n",
      "epoch 146; iter: 0; batch classifier loss: 0.307914; batch adversarial loss: 0.544845\n",
      "epoch 147; iter: 0; batch classifier loss: 0.361226; batch adversarial loss: 0.544358\n",
      "epoch 148; iter: 0; batch classifier loss: 0.392646; batch adversarial loss: 0.543533\n",
      "epoch 149; iter: 0; batch classifier loss: 0.315312; batch adversarial loss: 0.590560\n",
      "epoch 150; iter: 0; batch classifier loss: 0.365028; batch adversarial loss: 0.561350\n",
      "epoch 151; iter: 0; batch classifier loss: 0.337633; batch adversarial loss: 0.555023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 152; iter: 0; batch classifier loss: 0.335394; batch adversarial loss: 0.473037\n",
      "epoch 153; iter: 0; batch classifier loss: 0.383003; batch adversarial loss: 0.644160\n",
      "epoch 154; iter: 0; batch classifier loss: 0.356844; batch adversarial loss: 0.499948\n",
      "epoch 155; iter: 0; batch classifier loss: 0.341445; batch adversarial loss: 0.534620\n",
      "epoch 156; iter: 0; batch classifier loss: 0.413416; batch adversarial loss: 0.461607\n",
      "epoch 157; iter: 0; batch classifier loss: 0.353457; batch adversarial loss: 0.501689\n",
      "epoch 158; iter: 0; batch classifier loss: 0.327758; batch adversarial loss: 0.572192\n",
      "epoch 159; iter: 0; batch classifier loss: 0.383129; batch adversarial loss: 0.534046\n",
      "epoch 160; iter: 0; batch classifier loss: 0.356435; batch adversarial loss: 0.553482\n",
      "epoch 161; iter: 0; batch classifier loss: 0.400025; batch adversarial loss: 0.490848\n",
      "epoch 162; iter: 0; batch classifier loss: 0.347982; batch adversarial loss: 0.516709\n",
      "epoch 163; iter: 0; batch classifier loss: 0.289876; batch adversarial loss: 0.571252\n",
      "epoch 164; iter: 0; batch classifier loss: 0.361202; batch adversarial loss: 0.555365\n",
      "epoch 165; iter: 0; batch classifier loss: 0.397232; batch adversarial loss: 0.570822\n",
      "epoch 166; iter: 0; batch classifier loss: 0.409271; batch adversarial loss: 0.545196\n",
      "epoch 167; iter: 0; batch classifier loss: 0.369742; batch adversarial loss: 0.600872\n",
      "epoch 168; iter: 0; batch classifier loss: 0.329835; batch adversarial loss: 0.589753\n",
      "epoch 169; iter: 0; batch classifier loss: 0.371863; batch adversarial loss: 0.534992\n",
      "epoch 170; iter: 0; batch classifier loss: 0.410011; batch adversarial loss: 0.572425\n",
      "epoch 171; iter: 0; batch classifier loss: 0.417049; batch adversarial loss: 0.488723\n",
      "epoch 172; iter: 0; batch classifier loss: 0.530977; batch adversarial loss: 0.516623\n",
      "epoch 173; iter: 0; batch classifier loss: 0.369408; batch adversarial loss: 0.537419\n",
      "epoch 174; iter: 0; batch classifier loss: 0.404289; batch adversarial loss: 0.580993\n",
      "epoch 175; iter: 0; batch classifier loss: 0.363233; batch adversarial loss: 0.498926\n",
      "epoch 176; iter: 0; batch classifier loss: 0.399827; batch adversarial loss: 0.562125\n",
      "epoch 177; iter: 0; batch classifier loss: 0.284795; batch adversarial loss: 0.563350\n",
      "epoch 178; iter: 0; batch classifier loss: 0.334931; batch adversarial loss: 0.615349\n",
      "epoch 179; iter: 0; batch classifier loss: 0.362017; batch adversarial loss: 0.545488\n",
      "epoch 180; iter: 0; batch classifier loss: 0.350351; batch adversarial loss: 0.490081\n",
      "epoch 181; iter: 0; batch classifier loss: 0.365766; batch adversarial loss: 0.617429\n",
      "epoch 182; iter: 0; batch classifier loss: 0.390018; batch adversarial loss: 0.561283\n",
      "epoch 183; iter: 0; batch classifier loss: 0.347410; batch adversarial loss: 0.634877\n",
      "epoch 184; iter: 0; batch classifier loss: 0.385724; batch adversarial loss: 0.607800\n",
      "epoch 185; iter: 0; batch classifier loss: 0.337093; batch adversarial loss: 0.507977\n",
      "epoch 186; iter: 0; batch classifier loss: 0.313320; batch adversarial loss: 0.490785\n",
      "epoch 187; iter: 0; batch classifier loss: 0.316399; batch adversarial loss: 0.508639\n",
      "epoch 188; iter: 0; batch classifier loss: 0.385415; batch adversarial loss: 0.518085\n",
      "epoch 189; iter: 0; batch classifier loss: 0.417788; batch adversarial loss: 0.471139\n",
      "epoch 190; iter: 0; batch classifier loss: 0.289431; batch adversarial loss: 0.544352\n",
      "epoch 191; iter: 0; batch classifier loss: 0.357089; batch adversarial loss: 0.507095\n",
      "epoch 192; iter: 0; batch classifier loss: 0.305444; batch adversarial loss: 0.546058\n",
      "epoch 193; iter: 0; batch classifier loss: 0.373797; batch adversarial loss: 0.518662\n",
      "epoch 194; iter: 0; batch classifier loss: 0.335458; batch adversarial loss: 0.518209\n",
      "epoch 195; iter: 0; batch classifier loss: 0.376212; batch adversarial loss: 0.535167\n",
      "epoch 196; iter: 0; batch classifier loss: 0.456069; batch adversarial loss: 0.589996\n",
      "epoch 197; iter: 0; batch classifier loss: 0.309606; batch adversarial loss: 0.479302\n",
      "epoch 198; iter: 0; batch classifier loss: 0.432040; batch adversarial loss: 0.444992\n",
      "epoch 199; iter: 0; batch classifier loss: 0.385311; batch adversarial loss: 0.608821\n",
      "epoch 0; iter: 0; batch classifier loss: 0.668241; batch adversarial loss: 0.615931\n",
      "epoch 1; iter: 0; batch classifier loss: 0.573125; batch adversarial loss: 0.692828\n",
      "epoch 2; iter: 0; batch classifier loss: 0.581217; batch adversarial loss: 0.637174\n",
      "epoch 3; iter: 0; batch classifier loss: 0.589191; batch adversarial loss: 0.699061\n",
      "epoch 4; iter: 0; batch classifier loss: 0.510542; batch adversarial loss: 0.629437\n",
      "epoch 5; iter: 0; batch classifier loss: 0.559364; batch adversarial loss: 0.628941\n",
      "epoch 6; iter: 0; batch classifier loss: 0.608792; batch adversarial loss: 0.635223\n",
      "epoch 7; iter: 0; batch classifier loss: 0.617019; batch adversarial loss: 0.593259\n",
      "epoch 8; iter: 0; batch classifier loss: 0.644237; batch adversarial loss: 0.600122\n",
      "epoch 9; iter: 0; batch classifier loss: 0.535558; batch adversarial loss: 0.585200\n",
      "epoch 10; iter: 0; batch classifier loss: 0.529869; batch adversarial loss: 0.611228\n",
      "epoch 11; iter: 0; batch classifier loss: 0.475945; batch adversarial loss: 0.587121\n",
      "epoch 12; iter: 0; batch classifier loss: 0.537011; batch adversarial loss: 0.535051\n",
      "epoch 13; iter: 0; batch classifier loss: 0.550277; batch adversarial loss: 0.634899\n",
      "epoch 14; iter: 0; batch classifier loss: 0.541924; batch adversarial loss: 0.562776\n",
      "epoch 15; iter: 0; batch classifier loss: 0.492074; batch adversarial loss: 0.565417\n",
      "epoch 16; iter: 0; batch classifier loss: 0.571882; batch adversarial loss: 0.577409\n",
      "epoch 17; iter: 0; batch classifier loss: 0.455846; batch adversarial loss: 0.525939\n",
      "epoch 18; iter: 0; batch classifier loss: 0.429251; batch adversarial loss: 0.536414\n",
      "epoch 19; iter: 0; batch classifier loss: 0.526468; batch adversarial loss: 0.561117\n",
      "epoch 20; iter: 0; batch classifier loss: 0.490465; batch adversarial loss: 0.572772\n",
      "epoch 21; iter: 0; batch classifier loss: 0.461860; batch adversarial loss: 0.598973\n",
      "epoch 22; iter: 0; batch classifier loss: 0.482335; batch adversarial loss: 0.516676\n",
      "epoch 23; iter: 0; batch classifier loss: 0.470653; batch adversarial loss: 0.588665\n",
      "epoch 24; iter: 0; batch classifier loss: 0.528585; batch adversarial loss: 0.536055\n",
      "epoch 25; iter: 0; batch classifier loss: 0.465919; batch adversarial loss: 0.522955\n",
      "epoch 26; iter: 0; batch classifier loss: 0.479550; batch adversarial loss: 0.500647\n",
      "epoch 27; iter: 0; batch classifier loss: 0.474193; batch adversarial loss: 0.543961\n",
      "epoch 28; iter: 0; batch classifier loss: 0.523704; batch adversarial loss: 0.530645\n",
      "epoch 29; iter: 0; batch classifier loss: 0.426446; batch adversarial loss: 0.572546\n",
      "epoch 30; iter: 0; batch classifier loss: 0.457635; batch adversarial loss: 0.497818\n",
      "epoch 31; iter: 0; batch classifier loss: 0.471699; batch adversarial loss: 0.490131\n",
      "epoch 32; iter: 0; batch classifier loss: 0.507882; batch adversarial loss: 0.575139\n",
      "epoch 33; iter: 0; batch classifier loss: 0.611171; batch adversarial loss: 0.614177\n",
      "epoch 34; iter: 0; batch classifier loss: 0.485139; batch adversarial loss: 0.544312\n",
      "epoch 35; iter: 0; batch classifier loss: 0.399445; batch adversarial loss: 0.486829\n",
      "epoch 36; iter: 0; batch classifier loss: 0.457904; batch adversarial loss: 0.598023\n",
      "epoch 37; iter: 0; batch classifier loss: 0.427959; batch adversarial loss: 0.620006\n",
      "epoch 38; iter: 0; batch classifier loss: 0.600691; batch adversarial loss: 0.480172\n",
      "epoch 39; iter: 0; batch classifier loss: 0.460188; batch adversarial loss: 0.565144\n",
      "epoch 40; iter: 0; batch classifier loss: 0.440680; batch adversarial loss: 0.599162\n",
      "epoch 41; iter: 0; batch classifier loss: 0.422027; batch adversarial loss: 0.490195\n",
      "epoch 42; iter: 0; batch classifier loss: 0.432178; batch adversarial loss: 0.580764\n",
      "epoch 43; iter: 0; batch classifier loss: 0.476983; batch adversarial loss: 0.526358\n",
      "epoch 44; iter: 0; batch classifier loss: 0.413716; batch adversarial loss: 0.590375\n",
      "epoch 45; iter: 0; batch classifier loss: 0.428873; batch adversarial loss: 0.498916\n",
      "epoch 46; iter: 0; batch classifier loss: 0.454600; batch adversarial loss: 0.553357\n",
      "epoch 47; iter: 0; batch classifier loss: 0.488994; batch adversarial loss: 0.553368\n",
      "epoch 48; iter: 0; batch classifier loss: 0.539529; batch adversarial loss: 0.552377\n",
      "epoch 49; iter: 0; batch classifier loss: 0.407770; batch adversarial loss: 0.618171\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 50; iter: 0; batch classifier loss: 0.461883; batch adversarial loss: 0.597607\n",
      "epoch 51; iter: 0; batch classifier loss: 0.422435; batch adversarial loss: 0.544017\n",
      "epoch 52; iter: 0; batch classifier loss: 0.421886; batch adversarial loss: 0.488612\n",
      "epoch 53; iter: 0; batch classifier loss: 0.406225; batch adversarial loss: 0.535782\n",
      "epoch 54; iter: 0; batch classifier loss: 0.417935; batch adversarial loss: 0.545606\n",
      "epoch 55; iter: 0; batch classifier loss: 0.413472; batch adversarial loss: 0.471485\n",
      "epoch 56; iter: 0; batch classifier loss: 0.466148; batch adversarial loss: 0.470445\n",
      "epoch 57; iter: 0; batch classifier loss: 0.353766; batch adversarial loss: 0.487839\n",
      "epoch 58; iter: 0; batch classifier loss: 0.471476; batch adversarial loss: 0.563627\n",
      "epoch 59; iter: 0; batch classifier loss: 0.366921; batch adversarial loss: 0.554581\n",
      "epoch 60; iter: 0; batch classifier loss: 0.396631; batch adversarial loss: 0.525527\n",
      "epoch 61; iter: 0; batch classifier loss: 0.409890; batch adversarial loss: 0.516607\n",
      "epoch 62; iter: 0; batch classifier loss: 0.423042; batch adversarial loss: 0.535230\n",
      "epoch 63; iter: 0; batch classifier loss: 0.348567; batch adversarial loss: 0.656663\n",
      "epoch 64; iter: 0; batch classifier loss: 0.483216; batch adversarial loss: 0.544836\n",
      "epoch 65; iter: 0; batch classifier loss: 0.353403; batch adversarial loss: 0.515485\n",
      "epoch 66; iter: 0; batch classifier loss: 0.465487; batch adversarial loss: 0.517006\n",
      "epoch 67; iter: 0; batch classifier loss: 0.430653; batch adversarial loss: 0.610484\n",
      "epoch 68; iter: 0; batch classifier loss: 0.404668; batch adversarial loss: 0.478482\n",
      "epoch 69; iter: 0; batch classifier loss: 0.287870; batch adversarial loss: 0.478551\n",
      "epoch 70; iter: 0; batch classifier loss: 0.475733; batch adversarial loss: 0.553411\n",
      "epoch 71; iter: 0; batch classifier loss: 0.498276; batch adversarial loss: 0.618456\n",
      "epoch 72; iter: 0; batch classifier loss: 0.359618; batch adversarial loss: 0.507084\n",
      "epoch 73; iter: 0; batch classifier loss: 0.384350; batch adversarial loss: 0.607981\n",
      "epoch 74; iter: 0; batch classifier loss: 0.446854; batch adversarial loss: 0.564367\n",
      "epoch 75; iter: 0; batch classifier loss: 0.422248; batch adversarial loss: 0.497295\n",
      "epoch 76; iter: 0; batch classifier loss: 0.388885; batch adversarial loss: 0.648992\n",
      "epoch 77; iter: 0; batch classifier loss: 0.333365; batch adversarial loss: 0.563624\n",
      "epoch 78; iter: 0; batch classifier loss: 0.386629; batch adversarial loss: 0.563419\n",
      "epoch 79; iter: 0; batch classifier loss: 0.402322; batch adversarial loss: 0.525577\n",
      "epoch 80; iter: 0; batch classifier loss: 0.314920; batch adversarial loss: 0.544238\n",
      "epoch 81; iter: 0; batch classifier loss: 0.336450; batch adversarial loss: 0.599841\n",
      "epoch 82; iter: 0; batch classifier loss: 0.381916; batch adversarial loss: 0.543397\n",
      "epoch 83; iter: 0; batch classifier loss: 0.362169; batch adversarial loss: 0.591140\n",
      "epoch 84; iter: 0; batch classifier loss: 0.396511; batch adversarial loss: 0.480191\n",
      "epoch 85; iter: 0; batch classifier loss: 0.414835; batch adversarial loss: 0.526757\n",
      "epoch 86; iter: 0; batch classifier loss: 0.386366; batch adversarial loss: 0.451737\n",
      "epoch 87; iter: 0; batch classifier loss: 0.415849; batch adversarial loss: 0.621614\n",
      "epoch 88; iter: 0; batch classifier loss: 0.309403; batch adversarial loss: 0.540908\n",
      "epoch 89; iter: 0; batch classifier loss: 0.300674; batch adversarial loss: 0.558428\n",
      "epoch 90; iter: 0; batch classifier loss: 0.384718; batch adversarial loss: 0.592077\n",
      "epoch 91; iter: 0; batch classifier loss: 0.443977; batch adversarial loss: 0.490070\n",
      "epoch 92; iter: 0; batch classifier loss: 0.421741; batch adversarial loss: 0.564515\n",
      "epoch 93; iter: 0; batch classifier loss: 0.421880; batch adversarial loss: 0.583008\n",
      "epoch 94; iter: 0; batch classifier loss: 0.407826; batch adversarial loss: 0.542073\n",
      "epoch 95; iter: 0; batch classifier loss: 0.467330; batch adversarial loss: 0.469728\n",
      "epoch 96; iter: 0; batch classifier loss: 0.361421; batch adversarial loss: 0.497953\n",
      "epoch 97; iter: 0; batch classifier loss: 0.383349; batch adversarial loss: 0.619198\n",
      "epoch 98; iter: 0; batch classifier loss: 0.448808; batch adversarial loss: 0.582529\n",
      "epoch 99; iter: 0; batch classifier loss: 0.415545; batch adversarial loss: 0.525299\n",
      "epoch 100; iter: 0; batch classifier loss: 0.484972; batch adversarial loss: 0.459917\n",
      "epoch 101; iter: 0; batch classifier loss: 0.353410; batch adversarial loss: 0.525618\n",
      "epoch 102; iter: 0; batch classifier loss: 0.488693; batch adversarial loss: 0.535712\n",
      "epoch 103; iter: 0; batch classifier loss: 0.419723; batch adversarial loss: 0.506837\n",
      "epoch 104; iter: 0; batch classifier loss: 0.383017; batch adversarial loss: 0.545207\n",
      "epoch 105; iter: 0; batch classifier loss: 0.331857; batch adversarial loss: 0.526024\n",
      "epoch 106; iter: 0; batch classifier loss: 0.353984; batch adversarial loss: 0.636472\n",
      "epoch 107; iter: 0; batch classifier loss: 0.442650; batch adversarial loss: 0.516798\n",
      "epoch 108; iter: 0; batch classifier loss: 0.493127; batch adversarial loss: 0.498008\n",
      "epoch 109; iter: 0; batch classifier loss: 0.322103; batch adversarial loss: 0.531528\n",
      "epoch 110; iter: 0; batch classifier loss: 0.367242; batch adversarial loss: 0.534687\n",
      "epoch 111; iter: 0; batch classifier loss: 0.361825; batch adversarial loss: 0.515996\n",
      "epoch 112; iter: 0; batch classifier loss: 0.419797; batch adversarial loss: 0.469439\n",
      "epoch 113; iter: 0; batch classifier loss: 0.349719; batch adversarial loss: 0.544812\n",
      "epoch 114; iter: 0; batch classifier loss: 0.382254; batch adversarial loss: 0.590419\n",
      "epoch 115; iter: 0; batch classifier loss: 0.393208; batch adversarial loss: 0.543583\n",
      "epoch 116; iter: 0; batch classifier loss: 0.361260; batch adversarial loss: 0.506920\n",
      "epoch 117; iter: 0; batch classifier loss: 0.357368; batch adversarial loss: 0.497443\n",
      "epoch 118; iter: 0; batch classifier loss: 0.308031; batch adversarial loss: 0.601325\n",
      "epoch 119; iter: 0; batch classifier loss: 0.375743; batch adversarial loss: 0.544909\n",
      "epoch 120; iter: 0; batch classifier loss: 0.363059; batch adversarial loss: 0.525034\n",
      "epoch 121; iter: 0; batch classifier loss: 0.429034; batch adversarial loss: 0.619345\n",
      "epoch 122; iter: 0; batch classifier loss: 0.412628; batch adversarial loss: 0.534722\n",
      "epoch 123; iter: 0; batch classifier loss: 0.363201; batch adversarial loss: 0.468259\n",
      "epoch 124; iter: 0; batch classifier loss: 0.435510; batch adversarial loss: 0.532688\n",
      "epoch 125; iter: 0; batch classifier loss: 0.399834; batch adversarial loss: 0.571175\n",
      "epoch 126; iter: 0; batch classifier loss: 0.372375; batch adversarial loss: 0.528301\n",
      "epoch 127; iter: 0; batch classifier loss: 0.332646; batch adversarial loss: 0.562510\n",
      "epoch 128; iter: 0; batch classifier loss: 0.427011; batch adversarial loss: 0.546422\n",
      "epoch 129; iter: 0; batch classifier loss: 0.338620; batch adversarial loss: 0.590749\n",
      "epoch 130; iter: 0; batch classifier loss: 0.419869; batch adversarial loss: 0.552994\n",
      "epoch 131; iter: 0; batch classifier loss: 0.322840; batch adversarial loss: 0.526295\n",
      "epoch 132; iter: 0; batch classifier loss: 0.342887; batch adversarial loss: 0.553302\n",
      "epoch 133; iter: 0; batch classifier loss: 0.367232; batch adversarial loss: 0.497378\n",
      "epoch 134; iter: 0; batch classifier loss: 0.332012; batch adversarial loss: 0.534551\n",
      "epoch 135; iter: 0; batch classifier loss: 0.348968; batch adversarial loss: 0.451211\n",
      "epoch 136; iter: 0; batch classifier loss: 0.440228; batch adversarial loss: 0.486485\n",
      "epoch 137; iter: 0; batch classifier loss: 0.318992; batch adversarial loss: 0.573771\n",
      "epoch 138; iter: 0; batch classifier loss: 0.375209; batch adversarial loss: 0.532248\n",
      "epoch 139; iter: 0; batch classifier loss: 0.345176; batch adversarial loss: 0.550934\n",
      "epoch 140; iter: 0; batch classifier loss: 0.390204; batch adversarial loss: 0.543070\n",
      "epoch 141; iter: 0; batch classifier loss: 0.391874; batch adversarial loss: 0.598740\n",
      "epoch 142; iter: 0; batch classifier loss: 0.397108; batch adversarial loss: 0.543863\n",
      "epoch 143; iter: 0; batch classifier loss: 0.287939; batch adversarial loss: 0.574254\n",
      "epoch 144; iter: 0; batch classifier loss: 0.339742; batch adversarial loss: 0.537174\n",
      "epoch 145; iter: 0; batch classifier loss: 0.298889; batch adversarial loss: 0.638880\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 146; iter: 0; batch classifier loss: 0.413688; batch adversarial loss: 0.497120\n",
      "epoch 147; iter: 0; batch classifier loss: 0.345420; batch adversarial loss: 0.563783\n",
      "epoch 148; iter: 0; batch classifier loss: 0.392790; batch adversarial loss: 0.544091\n",
      "epoch 149; iter: 0; batch classifier loss: 0.354159; batch adversarial loss: 0.534472\n",
      "epoch 150; iter: 0; batch classifier loss: 0.450244; batch adversarial loss: 0.561929\n",
      "epoch 151; iter: 0; batch classifier loss: 0.424217; batch adversarial loss: 0.553988\n",
      "epoch 152; iter: 0; batch classifier loss: 0.350153; batch adversarial loss: 0.545474\n",
      "epoch 153; iter: 0; batch classifier loss: 0.397057; batch adversarial loss: 0.515665\n",
      "epoch 154; iter: 0; batch classifier loss: 0.323010; batch adversarial loss: 0.593078\n",
      "epoch 155; iter: 0; batch classifier loss: 0.338700; batch adversarial loss: 0.498554\n",
      "epoch 156; iter: 0; batch classifier loss: 0.405251; batch adversarial loss: 0.524432\n",
      "epoch 157; iter: 0; batch classifier loss: 0.408995; batch adversarial loss: 0.572326\n",
      "epoch 158; iter: 0; batch classifier loss: 0.318197; batch adversarial loss: 0.507184\n",
      "epoch 159; iter: 0; batch classifier loss: 0.345776; batch adversarial loss: 0.544690\n",
      "epoch 160; iter: 0; batch classifier loss: 0.363766; batch adversarial loss: 0.554975\n",
      "epoch 161; iter: 0; batch classifier loss: 0.376467; batch adversarial loss: 0.525874\n",
      "epoch 162; iter: 0; batch classifier loss: 0.398203; batch adversarial loss: 0.544562\n",
      "epoch 163; iter: 0; batch classifier loss: 0.407201; batch adversarial loss: 0.498165\n",
      "epoch 164; iter: 0; batch classifier loss: 0.301526; batch adversarial loss: 0.599515\n",
      "epoch 165; iter: 0; batch classifier loss: 0.342141; batch adversarial loss: 0.451276\n",
      "epoch 166; iter: 0; batch classifier loss: 0.301888; batch adversarial loss: 0.506238\n",
      "epoch 167; iter: 0; batch classifier loss: 0.347377; batch adversarial loss: 0.479550\n",
      "epoch 168; iter: 0; batch classifier loss: 0.348426; batch adversarial loss: 0.469158\n",
      "epoch 169; iter: 0; batch classifier loss: 0.353471; batch adversarial loss: 0.497856\n",
      "epoch 170; iter: 0; batch classifier loss: 0.268939; batch adversarial loss: 0.497676\n",
      "epoch 171; iter: 0; batch classifier loss: 0.327184; batch adversarial loss: 0.562987\n",
      "epoch 172; iter: 0; batch classifier loss: 0.386261; batch adversarial loss: 0.516704\n",
      "epoch 173; iter: 0; batch classifier loss: 0.339917; batch adversarial loss: 0.618930\n",
      "epoch 174; iter: 0; batch classifier loss: 0.413997; batch adversarial loss: 0.545195\n",
      "epoch 175; iter: 0; batch classifier loss: 0.309273; batch adversarial loss: 0.553986\n",
      "epoch 176; iter: 0; batch classifier loss: 0.299935; batch adversarial loss: 0.460693\n",
      "epoch 177; iter: 0; batch classifier loss: 0.368395; batch adversarial loss: 0.506885\n",
      "epoch 178; iter: 0; batch classifier loss: 0.417479; batch adversarial loss: 0.600025\n",
      "epoch 179; iter: 0; batch classifier loss: 0.347547; batch adversarial loss: 0.571576\n",
      "epoch 180; iter: 0; batch classifier loss: 0.417755; batch adversarial loss: 0.573276\n",
      "epoch 181; iter: 0; batch classifier loss: 0.438418; batch adversarial loss: 0.497533\n",
      "epoch 182; iter: 0; batch classifier loss: 0.320364; batch adversarial loss: 0.480069\n",
      "epoch 183; iter: 0; batch classifier loss: 0.416473; batch adversarial loss: 0.516939\n",
      "epoch 184; iter: 0; batch classifier loss: 0.370098; batch adversarial loss: 0.534840\n",
      "epoch 185; iter: 0; batch classifier loss: 0.333648; batch adversarial loss: 0.553522\n",
      "epoch 186; iter: 0; batch classifier loss: 0.340019; batch adversarial loss: 0.516058\n",
      "epoch 187; iter: 0; batch classifier loss: 0.391488; batch adversarial loss: 0.609490\n",
      "epoch 188; iter: 0; batch classifier loss: 0.315823; batch adversarial loss: 0.562787\n",
      "epoch 189; iter: 0; batch classifier loss: 0.341370; batch adversarial loss: 0.525681\n",
      "epoch 190; iter: 0; batch classifier loss: 0.349291; batch adversarial loss: 0.590347\n",
      "epoch 191; iter: 0; batch classifier loss: 0.324315; batch adversarial loss: 0.497580\n",
      "epoch 192; iter: 0; batch classifier loss: 0.300675; batch adversarial loss: 0.507487\n",
      "epoch 193; iter: 0; batch classifier loss: 0.308883; batch adversarial loss: 0.572520\n",
      "epoch 194; iter: 0; batch classifier loss: 0.386466; batch adversarial loss: 0.555164\n",
      "epoch 195; iter: 0; batch classifier loss: 0.384653; batch adversarial loss: 0.470003\n",
      "epoch 196; iter: 0; batch classifier loss: 0.419070; batch adversarial loss: 0.571525\n",
      "epoch 197; iter: 0; batch classifier loss: 0.326283; batch adversarial loss: 0.563118\n",
      "epoch 198; iter: 0; batch classifier loss: 0.331626; batch adversarial loss: 0.544206\n",
      "epoch 199; iter: 0; batch classifier loss: 0.384054; batch adversarial loss: 0.534842\n",
      "epoch 0; iter: 0; batch classifier loss: 0.689513; batch adversarial loss: 0.644478\n",
      "epoch 1; iter: 0; batch classifier loss: 0.606711; batch adversarial loss: 0.649181\n",
      "epoch 2; iter: 0; batch classifier loss: 0.579689; batch adversarial loss: 0.633209\n",
      "epoch 3; iter: 0; batch classifier loss: 0.591119; batch adversarial loss: 0.655650\n",
      "epoch 4; iter: 0; batch classifier loss: 0.543493; batch adversarial loss: 0.639444\n",
      "epoch 5; iter: 0; batch classifier loss: 0.555675; batch adversarial loss: 0.632938\n",
      "epoch 6; iter: 0; batch classifier loss: 0.550043; batch adversarial loss: 0.637984\n",
      "epoch 7; iter: 0; batch classifier loss: 0.558358; batch adversarial loss: 0.633253\n",
      "epoch 8; iter: 0; batch classifier loss: 0.525351; batch adversarial loss: 0.596752\n",
      "epoch 9; iter: 0; batch classifier loss: 0.534169; batch adversarial loss: 0.534529\n",
      "epoch 10; iter: 0; batch classifier loss: 0.490296; batch adversarial loss: 0.569602\n",
      "epoch 11; iter: 0; batch classifier loss: 0.514093; batch adversarial loss: 0.562736\n",
      "epoch 12; iter: 0; batch classifier loss: 0.503822; batch adversarial loss: 0.560892\n",
      "epoch 13; iter: 0; batch classifier loss: 0.462573; batch adversarial loss: 0.569176\n",
      "epoch 14; iter: 0; batch classifier loss: 0.453113; batch adversarial loss: 0.542564\n",
      "epoch 15; iter: 0; batch classifier loss: 0.444004; batch adversarial loss: 0.582265\n",
      "epoch 16; iter: 0; batch classifier loss: 0.493751; batch adversarial loss: 0.516642\n",
      "epoch 17; iter: 0; batch classifier loss: 0.484069; batch adversarial loss: 0.526977\n",
      "epoch 18; iter: 0; batch classifier loss: 0.533793; batch adversarial loss: 0.540310\n",
      "epoch 19; iter: 0; batch classifier loss: 0.542584; batch adversarial loss: 0.546670\n",
      "epoch 20; iter: 0; batch classifier loss: 0.447007; batch adversarial loss: 0.537583\n",
      "epoch 21; iter: 0; batch classifier loss: 0.468880; batch adversarial loss: 0.587168\n",
      "epoch 22; iter: 0; batch classifier loss: 0.477633; batch adversarial loss: 0.516658\n",
      "epoch 23; iter: 0; batch classifier loss: 0.494224; batch adversarial loss: 0.519295\n",
      "epoch 24; iter: 0; batch classifier loss: 0.437036; batch adversarial loss: 0.583123\n",
      "epoch 25; iter: 0; batch classifier loss: 0.484568; batch adversarial loss: 0.596112\n",
      "epoch 26; iter: 0; batch classifier loss: 0.454634; batch adversarial loss: 0.509188\n",
      "epoch 27; iter: 0; batch classifier loss: 0.428530; batch adversarial loss: 0.576162\n",
      "epoch 28; iter: 0; batch classifier loss: 0.474268; batch adversarial loss: 0.616326\n",
      "epoch 29; iter: 0; batch classifier loss: 0.425788; batch adversarial loss: 0.506987\n",
      "epoch 30; iter: 0; batch classifier loss: 0.459728; batch adversarial loss: 0.556679\n",
      "epoch 31; iter: 0; batch classifier loss: 0.396088; batch adversarial loss: 0.540695\n",
      "epoch 32; iter: 0; batch classifier loss: 0.412866; batch adversarial loss: 0.545473\n",
      "epoch 33; iter: 0; batch classifier loss: 0.392316; batch adversarial loss: 0.502185\n",
      "epoch 34; iter: 0; batch classifier loss: 0.425536; batch adversarial loss: 0.562167\n",
      "epoch 35; iter: 0; batch classifier loss: 0.511320; batch adversarial loss: 0.550552\n",
      "epoch 36; iter: 0; batch classifier loss: 0.407895; batch adversarial loss: 0.614787\n",
      "epoch 37; iter: 0; batch classifier loss: 0.472119; batch adversarial loss: 0.616225\n",
      "epoch 38; iter: 0; batch classifier loss: 0.441707; batch adversarial loss: 0.542226\n",
      "epoch 39; iter: 0; batch classifier loss: 0.450066; batch adversarial loss: 0.600916\n",
      "epoch 40; iter: 0; batch classifier loss: 0.403739; batch adversarial loss: 0.621811\n",
      "epoch 41; iter: 0; batch classifier loss: 0.445075; batch adversarial loss: 0.580333\n",
      "epoch 42; iter: 0; batch classifier loss: 0.411789; batch adversarial loss: 0.572246\n",
      "epoch 43; iter: 0; batch classifier loss: 0.378434; batch adversarial loss: 0.509553\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 44; iter: 0; batch classifier loss: 0.412920; batch adversarial loss: 0.499344\n",
      "epoch 45; iter: 0; batch classifier loss: 0.588796; batch adversarial loss: 0.570264\n",
      "epoch 46; iter: 0; batch classifier loss: 0.450527; batch adversarial loss: 0.562870\n",
      "epoch 47; iter: 0; batch classifier loss: 0.468566; batch adversarial loss: 0.564936\n",
      "epoch 48; iter: 0; batch classifier loss: 0.426991; batch adversarial loss: 0.534543\n",
      "epoch 49; iter: 0; batch classifier loss: 0.432550; batch adversarial loss: 0.506766\n",
      "epoch 50; iter: 0; batch classifier loss: 0.327351; batch adversarial loss: 0.536056\n",
      "epoch 51; iter: 0; batch classifier loss: 0.497943; batch adversarial loss: 0.571433\n",
      "epoch 52; iter: 0; batch classifier loss: 0.404911; batch adversarial loss: 0.580996\n",
      "epoch 53; iter: 0; batch classifier loss: 0.373720; batch adversarial loss: 0.556331\n",
      "epoch 54; iter: 0; batch classifier loss: 0.446583; batch adversarial loss: 0.592071\n",
      "epoch 55; iter: 0; batch classifier loss: 0.368643; batch adversarial loss: 0.580022\n",
      "epoch 56; iter: 0; batch classifier loss: 0.321241; batch adversarial loss: 0.658073\n",
      "epoch 57; iter: 0; batch classifier loss: 0.444846; batch adversarial loss: 0.545526\n",
      "epoch 58; iter: 0; batch classifier loss: 0.412752; batch adversarial loss: 0.579003\n",
      "epoch 59; iter: 0; batch classifier loss: 0.423156; batch adversarial loss: 0.605590\n",
      "epoch 60; iter: 0; batch classifier loss: 0.366333; batch adversarial loss: 0.518519\n",
      "epoch 61; iter: 0; batch classifier loss: 0.401389; batch adversarial loss: 0.501308\n",
      "epoch 62; iter: 0; batch classifier loss: 0.442172; batch adversarial loss: 0.579327\n",
      "epoch 63; iter: 0; batch classifier loss: 0.392884; batch adversarial loss: 0.463076\n",
      "epoch 64; iter: 0; batch classifier loss: 0.422619; batch adversarial loss: 0.552701\n",
      "epoch 65; iter: 0; batch classifier loss: 0.385077; batch adversarial loss: 0.588670\n",
      "epoch 66; iter: 0; batch classifier loss: 0.395430; batch adversarial loss: 0.616808\n",
      "epoch 67; iter: 0; batch classifier loss: 0.428398; batch adversarial loss: 0.553998\n",
      "epoch 68; iter: 0; batch classifier loss: 0.458693; batch adversarial loss: 0.529985\n",
      "epoch 69; iter: 0; batch classifier loss: 0.422925; batch adversarial loss: 0.508577\n",
      "epoch 70; iter: 0; batch classifier loss: 0.428745; batch adversarial loss: 0.535415\n",
      "epoch 71; iter: 0; batch classifier loss: 0.486758; batch adversarial loss: 0.510820\n",
      "epoch 72; iter: 0; batch classifier loss: 0.480638; batch adversarial loss: 0.527485\n",
      "epoch 73; iter: 0; batch classifier loss: 0.413105; batch adversarial loss: 0.475580\n",
      "epoch 74; iter: 0; batch classifier loss: 0.393119; batch adversarial loss: 0.649530\n",
      "epoch 75; iter: 0; batch classifier loss: 0.390515; batch adversarial loss: 0.650454\n",
      "epoch 76; iter: 0; batch classifier loss: 0.310212; batch adversarial loss: 0.554470\n",
      "epoch 77; iter: 0; batch classifier loss: 0.470062; batch adversarial loss: 0.518426\n",
      "epoch 78; iter: 0; batch classifier loss: 0.472153; batch adversarial loss: 0.553817\n",
      "epoch 79; iter: 0; batch classifier loss: 0.421647; batch adversarial loss: 0.607772\n",
      "epoch 80; iter: 0; batch classifier loss: 0.358436; batch adversarial loss: 0.499025\n",
      "epoch 81; iter: 0; batch classifier loss: 0.374931; batch adversarial loss: 0.526445\n",
      "epoch 82; iter: 0; batch classifier loss: 0.362830; batch adversarial loss: 0.580870\n",
      "epoch 83; iter: 0; batch classifier loss: 0.444460; batch adversarial loss: 0.553016\n",
      "epoch 84; iter: 0; batch classifier loss: 0.467494; batch adversarial loss: 0.562532\n",
      "epoch 85; iter: 0; batch classifier loss: 0.477371; batch adversarial loss: 0.482301\n",
      "epoch 86; iter: 0; batch classifier loss: 0.413152; batch adversarial loss: 0.482855\n",
      "epoch 87; iter: 0; batch classifier loss: 0.326776; batch adversarial loss: 0.491680\n",
      "epoch 88; iter: 0; batch classifier loss: 0.354785; batch adversarial loss: 0.519283\n",
      "epoch 89; iter: 0; batch classifier loss: 0.382901; batch adversarial loss: 0.544662\n",
      "epoch 90; iter: 0; batch classifier loss: 0.345748; batch adversarial loss: 0.561502\n",
      "epoch 91; iter: 0; batch classifier loss: 0.376294; batch adversarial loss: 0.597693\n",
      "epoch 92; iter: 0; batch classifier loss: 0.401489; batch adversarial loss: 0.572211\n",
      "epoch 93; iter: 0; batch classifier loss: 0.395097; batch adversarial loss: 0.580627\n",
      "epoch 94; iter: 0; batch classifier loss: 0.371890; batch adversarial loss: 0.516171\n",
      "epoch 95; iter: 0; batch classifier loss: 0.302685; batch adversarial loss: 0.580985\n",
      "epoch 96; iter: 0; batch classifier loss: 0.396486; batch adversarial loss: 0.526571\n",
      "epoch 97; iter: 0; batch classifier loss: 0.452002; batch adversarial loss: 0.581113\n",
      "epoch 98; iter: 0; batch classifier loss: 0.432765; batch adversarial loss: 0.553665\n",
      "epoch 99; iter: 0; batch classifier loss: 0.428879; batch adversarial loss: 0.570228\n",
      "epoch 100; iter: 0; batch classifier loss: 0.340376; batch adversarial loss: 0.587350\n",
      "epoch 101; iter: 0; batch classifier loss: 0.334909; batch adversarial loss: 0.589216\n",
      "epoch 102; iter: 0; batch classifier loss: 0.337118; batch adversarial loss: 0.572960\n",
      "epoch 103; iter: 0; batch classifier loss: 0.367730; batch adversarial loss: 0.588650\n",
      "epoch 104; iter: 0; batch classifier loss: 0.302934; batch adversarial loss: 0.534866\n",
      "epoch 105; iter: 0; batch classifier loss: 0.388754; batch adversarial loss: 0.536183\n",
      "epoch 106; iter: 0; batch classifier loss: 0.375211; batch adversarial loss: 0.571074\n",
      "epoch 107; iter: 0; batch classifier loss: 0.381160; batch adversarial loss: 0.554067\n",
      "epoch 108; iter: 0; batch classifier loss: 0.404502; batch adversarial loss: 0.606921\n",
      "epoch 109; iter: 0; batch classifier loss: 0.433231; batch adversarial loss: 0.589463\n",
      "epoch 110; iter: 0; batch classifier loss: 0.378381; batch adversarial loss: 0.519167\n",
      "epoch 111; iter: 0; batch classifier loss: 0.340549; batch adversarial loss: 0.643578\n",
      "epoch 112; iter: 0; batch classifier loss: 0.357255; batch adversarial loss: 0.553681\n",
      "epoch 113; iter: 0; batch classifier loss: 0.329797; batch adversarial loss: 0.654411\n",
      "epoch 114; iter: 0; batch classifier loss: 0.394313; batch adversarial loss: 0.535576\n",
      "epoch 115; iter: 0; batch classifier loss: 0.404530; batch adversarial loss: 0.589646\n",
      "epoch 116; iter: 0; batch classifier loss: 0.328850; batch adversarial loss: 0.474190\n",
      "epoch 117; iter: 0; batch classifier loss: 0.396760; batch adversarial loss: 0.535898\n",
      "epoch 118; iter: 0; batch classifier loss: 0.315913; batch adversarial loss: 0.500147\n",
      "epoch 119; iter: 0; batch classifier loss: 0.373461; batch adversarial loss: 0.544819\n",
      "epoch 120; iter: 0; batch classifier loss: 0.337081; batch adversarial loss: 0.633888\n",
      "epoch 121; iter: 0; batch classifier loss: 0.307902; batch adversarial loss: 0.544411\n",
      "epoch 122; iter: 0; batch classifier loss: 0.296116; batch adversarial loss: 0.642575\n",
      "epoch 123; iter: 0; batch classifier loss: 0.388353; batch adversarial loss: 0.597707\n",
      "epoch 124; iter: 0; batch classifier loss: 0.399774; batch adversarial loss: 0.615551\n",
      "epoch 125; iter: 0; batch classifier loss: 0.409014; batch adversarial loss: 0.598034\n",
      "epoch 126; iter: 0; batch classifier loss: 0.382141; batch adversarial loss: 0.570990\n",
      "epoch 127; iter: 0; batch classifier loss: 0.332394; batch adversarial loss: 0.508456\n",
      "epoch 128; iter: 0; batch classifier loss: 0.325977; batch adversarial loss: 0.527662\n",
      "epoch 129; iter: 0; batch classifier loss: 0.340417; batch adversarial loss: 0.589053\n",
      "epoch 130; iter: 0; batch classifier loss: 0.313543; batch adversarial loss: 0.517741\n",
      "epoch 131; iter: 0; batch classifier loss: 0.366421; batch adversarial loss: 0.526840\n",
      "epoch 132; iter: 0; batch classifier loss: 0.388780; batch adversarial loss: 0.561930\n",
      "epoch 133; iter: 0; batch classifier loss: 0.311603; batch adversarial loss: 0.653293\n",
      "epoch 134; iter: 0; batch classifier loss: 0.402280; batch adversarial loss: 0.490369\n",
      "epoch 135; iter: 0; batch classifier loss: 0.369021; batch adversarial loss: 0.508516\n",
      "epoch 136; iter: 0; batch classifier loss: 0.323212; batch adversarial loss: 0.534191\n",
      "epoch 137; iter: 0; batch classifier loss: 0.316393; batch adversarial loss: 0.598036\n",
      "epoch 138; iter: 0; batch classifier loss: 0.346307; batch adversarial loss: 0.590572\n",
      "epoch 139; iter: 0; batch classifier loss: 0.298865; batch adversarial loss: 0.543700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 140; iter: 0; batch classifier loss: 0.316788; batch adversarial loss: 0.535613\n",
      "epoch 141; iter: 0; batch classifier loss: 0.403837; batch adversarial loss: 0.553433\n",
      "epoch 142; iter: 0; batch classifier loss: 0.312640; batch adversarial loss: 0.500215\n",
      "epoch 143; iter: 0; batch classifier loss: 0.353802; batch adversarial loss: 0.473111\n",
      "epoch 144; iter: 0; batch classifier loss: 0.349143; batch adversarial loss: 0.579976\n",
      "epoch 145; iter: 0; batch classifier loss: 0.402124; batch adversarial loss: 0.624615\n",
      "epoch 146; iter: 0; batch classifier loss: 0.337443; batch adversarial loss: 0.572118\n",
      "epoch 147; iter: 0; batch classifier loss: 0.348776; batch adversarial loss: 0.562476\n",
      "epoch 148; iter: 0; batch classifier loss: 0.335862; batch adversarial loss: 0.563479\n",
      "epoch 149; iter: 0; batch classifier loss: 0.382621; batch adversarial loss: 0.526328\n",
      "epoch 150; iter: 0; batch classifier loss: 0.290929; batch adversarial loss: 0.508512\n",
      "epoch 151; iter: 0; batch classifier loss: 0.392287; batch adversarial loss: 0.473685\n",
      "epoch 152; iter: 0; batch classifier loss: 0.354548; batch adversarial loss: 0.588592\n",
      "epoch 153; iter: 0; batch classifier loss: 0.333996; batch adversarial loss: 0.552720\n",
      "epoch 154; iter: 0; batch classifier loss: 0.320248; batch adversarial loss: 0.607290\n",
      "epoch 155; iter: 0; batch classifier loss: 0.360740; batch adversarial loss: 0.553932\n",
      "epoch 156; iter: 0; batch classifier loss: 0.395277; batch adversarial loss: 0.605809\n",
      "epoch 157; iter: 0; batch classifier loss: 0.338991; batch adversarial loss: 0.500828\n",
      "epoch 158; iter: 0; batch classifier loss: 0.352283; batch adversarial loss: 0.588586\n",
      "epoch 159; iter: 0; batch classifier loss: 0.434034; batch adversarial loss: 0.544724\n",
      "epoch 160; iter: 0; batch classifier loss: 0.471295; batch adversarial loss: 0.499216\n",
      "epoch 161; iter: 0; batch classifier loss: 0.357187; batch adversarial loss: 0.517726\n",
      "epoch 162; iter: 0; batch classifier loss: 0.331456; batch adversarial loss: 0.571168\n",
      "epoch 163; iter: 0; batch classifier loss: 0.325134; batch adversarial loss: 0.590593\n",
      "epoch 164; iter: 0; batch classifier loss: 0.337138; batch adversarial loss: 0.599535\n",
      "epoch 165; iter: 0; batch classifier loss: 0.313845; batch adversarial loss: 0.527258\n",
      "epoch 166; iter: 0; batch classifier loss: 0.383282; batch adversarial loss: 0.563243\n",
      "epoch 167; iter: 0; batch classifier loss: 0.348559; batch adversarial loss: 0.553450\n",
      "epoch 168; iter: 0; batch classifier loss: 0.326727; batch adversarial loss: 0.519115\n",
      "epoch 169; iter: 0; batch classifier loss: 0.285482; batch adversarial loss: 0.518497\n",
      "epoch 170; iter: 0; batch classifier loss: 0.306351; batch adversarial loss: 0.580151\n",
      "epoch 171; iter: 0; batch classifier loss: 0.382371; batch adversarial loss: 0.518292\n",
      "epoch 172; iter: 0; batch classifier loss: 0.351929; batch adversarial loss: 0.516831\n",
      "epoch 173; iter: 0; batch classifier loss: 0.428450; batch adversarial loss: 0.552341\n",
      "epoch 174; iter: 0; batch classifier loss: 0.362049; batch adversarial loss: 0.579343\n",
      "epoch 175; iter: 0; batch classifier loss: 0.391755; batch adversarial loss: 0.464206\n",
      "epoch 176; iter: 0; batch classifier loss: 0.330308; batch adversarial loss: 0.590164\n",
      "epoch 177; iter: 0; batch classifier loss: 0.443411; batch adversarial loss: 0.562279\n",
      "epoch 178; iter: 0; batch classifier loss: 0.400626; batch adversarial loss: 0.546182\n",
      "epoch 179; iter: 0; batch classifier loss: 0.289959; batch adversarial loss: 0.526875\n",
      "epoch 180; iter: 0; batch classifier loss: 0.436431; batch adversarial loss: 0.518106\n",
      "epoch 181; iter: 0; batch classifier loss: 0.303598; batch adversarial loss: 0.534471\n",
      "epoch 182; iter: 0; batch classifier loss: 0.389997; batch adversarial loss: 0.509066\n",
      "epoch 183; iter: 0; batch classifier loss: 0.384505; batch adversarial loss: 0.598471\n",
      "epoch 184; iter: 0; batch classifier loss: 0.378329; batch adversarial loss: 0.517439\n",
      "epoch 185; iter: 0; batch classifier loss: 0.326348; batch adversarial loss: 0.586736\n",
      "epoch 186; iter: 0; batch classifier loss: 0.349763; batch adversarial loss: 0.571795\n",
      "epoch 187; iter: 0; batch classifier loss: 0.273032; batch adversarial loss: 0.617759\n",
      "epoch 188; iter: 0; batch classifier loss: 0.386781; batch adversarial loss: 0.598058\n",
      "epoch 189; iter: 0; batch classifier loss: 0.359002; batch adversarial loss: 0.535625\n",
      "epoch 190; iter: 0; batch classifier loss: 0.411073; batch adversarial loss: 0.588615\n",
      "epoch 191; iter: 0; batch classifier loss: 0.323379; batch adversarial loss: 0.589844\n",
      "epoch 192; iter: 0; batch classifier loss: 0.366344; batch adversarial loss: 0.580070\n",
      "epoch 193; iter: 0; batch classifier loss: 0.309695; batch adversarial loss: 0.536164\n",
      "epoch 194; iter: 0; batch classifier loss: 0.321769; batch adversarial loss: 0.526520\n",
      "epoch 195; iter: 0; batch classifier loss: 0.356771; batch adversarial loss: 0.491264\n",
      "epoch 196; iter: 0; batch classifier loss: 0.345898; batch adversarial loss: 0.590415\n",
      "epoch 197; iter: 0; batch classifier loss: 0.338019; batch adversarial loss: 0.571659\n",
      "epoch 198; iter: 0; batch classifier loss: 0.363728; batch adversarial loss: 0.589423\n",
      "epoch 199; iter: 0; batch classifier loss: 0.345975; batch adversarial loss: 0.590291\n",
      "epoch 0; iter: 0; batch classifier loss: 0.700209; batch adversarial loss: 0.826117\n",
      "epoch 1; iter: 0; batch classifier loss: 0.741035; batch adversarial loss: 0.924361\n",
      "epoch 2; iter: 0; batch classifier loss: 0.884962; batch adversarial loss: 0.885649\n",
      "epoch 3; iter: 0; batch classifier loss: 0.956601; batch adversarial loss: 0.813765\n",
      "epoch 4; iter: 0; batch classifier loss: 0.914641; batch adversarial loss: 0.743722\n",
      "epoch 5; iter: 0; batch classifier loss: 1.076659; batch adversarial loss: 0.681887\n",
      "epoch 6; iter: 0; batch classifier loss: 0.926516; batch adversarial loss: 0.630605\n",
      "epoch 7; iter: 0; batch classifier loss: 0.642678; batch adversarial loss: 0.617671\n",
      "epoch 8; iter: 0; batch classifier loss: 0.536367; batch adversarial loss: 0.589429\n",
      "epoch 9; iter: 0; batch classifier loss: 0.557878; batch adversarial loss: 0.587732\n",
      "epoch 10; iter: 0; batch classifier loss: 0.560011; batch adversarial loss: 0.622283\n",
      "epoch 11; iter: 0; batch classifier loss: 0.544968; batch adversarial loss: 0.628289\n",
      "epoch 12; iter: 0; batch classifier loss: 0.569425; batch adversarial loss: 0.564551\n",
      "epoch 13; iter: 0; batch classifier loss: 0.501053; batch adversarial loss: 0.538653\n",
      "epoch 14; iter: 0; batch classifier loss: 0.567085; batch adversarial loss: 0.552812\n",
      "epoch 15; iter: 0; batch classifier loss: 0.560233; batch adversarial loss: 0.575675\n",
      "epoch 16; iter: 0; batch classifier loss: 0.513560; batch adversarial loss: 0.549967\n",
      "epoch 17; iter: 0; batch classifier loss: 0.509279; batch adversarial loss: 0.586871\n",
      "epoch 18; iter: 0; batch classifier loss: 0.574700; batch adversarial loss: 0.591747\n",
      "epoch 19; iter: 0; batch classifier loss: 0.490518; batch adversarial loss: 0.576421\n",
      "epoch 20; iter: 0; batch classifier loss: 0.509878; batch adversarial loss: 0.553881\n",
      "epoch 21; iter: 0; batch classifier loss: 0.517244; batch adversarial loss: 0.506502\n",
      "epoch 22; iter: 0; batch classifier loss: 0.485419; batch adversarial loss: 0.630717\n",
      "epoch 23; iter: 0; batch classifier loss: 0.510501; batch adversarial loss: 0.538234\n",
      "epoch 24; iter: 0; batch classifier loss: 0.577177; batch adversarial loss: 0.587725\n",
      "epoch 25; iter: 0; batch classifier loss: 0.512857; batch adversarial loss: 0.543633\n",
      "epoch 26; iter: 0; batch classifier loss: 0.471801; batch adversarial loss: 0.539283\n",
      "epoch 27; iter: 0; batch classifier loss: 0.460613; batch adversarial loss: 0.488382\n",
      "epoch 28; iter: 0; batch classifier loss: 0.447873; batch adversarial loss: 0.574081\n",
      "epoch 29; iter: 0; batch classifier loss: 0.402866; batch adversarial loss: 0.543915\n",
      "epoch 30; iter: 0; batch classifier loss: 0.502324; batch adversarial loss: 0.570012\n",
      "epoch 31; iter: 0; batch classifier loss: 0.433867; batch adversarial loss: 0.504666\n",
      "epoch 32; iter: 0; batch classifier loss: 0.494865; batch adversarial loss: 0.551080\n",
      "epoch 33; iter: 0; batch classifier loss: 0.439133; batch adversarial loss: 0.453564\n",
      "epoch 34; iter: 0; batch classifier loss: 0.469643; batch adversarial loss: 0.521543\n",
      "epoch 35; iter: 0; batch classifier loss: 0.451159; batch adversarial loss: 0.519234\n",
      "epoch 36; iter: 0; batch classifier loss: 0.465613; batch adversarial loss: 0.554073\n",
      "epoch 37; iter: 0; batch classifier loss: 0.516508; batch adversarial loss: 0.561799\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 38; iter: 0; batch classifier loss: 0.456703; batch adversarial loss: 0.580344\n",
      "epoch 39; iter: 0; batch classifier loss: 0.531229; batch adversarial loss: 0.520098\n",
      "epoch 40; iter: 0; batch classifier loss: 0.461969; batch adversarial loss: 0.493560\n",
      "epoch 41; iter: 0; batch classifier loss: 0.432764; batch adversarial loss: 0.526397\n",
      "epoch 42; iter: 0; batch classifier loss: 0.470116; batch adversarial loss: 0.650001\n",
      "epoch 43; iter: 0; batch classifier loss: 0.374553; batch adversarial loss: 0.526415\n",
      "epoch 44; iter: 0; batch classifier loss: 0.387747; batch adversarial loss: 0.581073\n",
      "epoch 45; iter: 0; batch classifier loss: 0.478574; batch adversarial loss: 0.499791\n",
      "epoch 46; iter: 0; batch classifier loss: 0.501287; batch adversarial loss: 0.562298\n",
      "epoch 47; iter: 0; batch classifier loss: 0.400567; batch adversarial loss: 0.518294\n",
      "epoch 48; iter: 0; batch classifier loss: 0.465291; batch adversarial loss: 0.599084\n",
      "epoch 49; iter: 0; batch classifier loss: 0.411518; batch adversarial loss: 0.473654\n",
      "epoch 50; iter: 0; batch classifier loss: 0.384267; batch adversarial loss: 0.508872\n",
      "epoch 51; iter: 0; batch classifier loss: 0.375187; batch adversarial loss: 0.571676\n",
      "epoch 52; iter: 0; batch classifier loss: 0.505204; batch adversarial loss: 0.589388\n",
      "epoch 53; iter: 0; batch classifier loss: 0.461047; batch adversarial loss: 0.562510\n",
      "epoch 54; iter: 0; batch classifier loss: 0.442184; batch adversarial loss: 0.517772\n",
      "epoch 55; iter: 0; batch classifier loss: 0.398033; batch adversarial loss: 0.472947\n",
      "epoch 56; iter: 0; batch classifier loss: 0.452911; batch adversarial loss: 0.580520\n",
      "epoch 57; iter: 0; batch classifier loss: 0.331530; batch adversarial loss: 0.589584\n",
      "epoch 58; iter: 0; batch classifier loss: 0.505259; batch adversarial loss: 0.571289\n",
      "epoch 59; iter: 0; batch classifier loss: 0.410903; batch adversarial loss: 0.571616\n",
      "epoch 60; iter: 0; batch classifier loss: 0.401241; batch adversarial loss: 0.580832\n",
      "epoch 61; iter: 0; batch classifier loss: 0.380566; batch adversarial loss: 0.562741\n",
      "epoch 62; iter: 0; batch classifier loss: 0.416188; batch adversarial loss: 0.545076\n",
      "epoch 63; iter: 0; batch classifier loss: 0.366235; batch adversarial loss: 0.608506\n",
      "epoch 64; iter: 0; batch classifier loss: 0.334203; batch adversarial loss: 0.562258\n",
      "epoch 65; iter: 0; batch classifier loss: 0.424280; batch adversarial loss: 0.535094\n",
      "epoch 66; iter: 0; batch classifier loss: 0.454806; batch adversarial loss: 0.571522\n",
      "epoch 67; iter: 0; batch classifier loss: 0.360291; batch adversarial loss: 0.607817\n",
      "epoch 68; iter: 0; batch classifier loss: 0.402308; batch adversarial loss: 0.580188\n",
      "epoch 69; iter: 0; batch classifier loss: 0.346150; batch adversarial loss: 0.499540\n",
      "epoch 70; iter: 0; batch classifier loss: 0.349442; batch adversarial loss: 0.553291\n",
      "epoch 71; iter: 0; batch classifier loss: 0.311073; batch adversarial loss: 0.579831\n",
      "epoch 72; iter: 0; batch classifier loss: 0.367988; batch adversarial loss: 0.535561\n",
      "epoch 73; iter: 0; batch classifier loss: 0.319883; batch adversarial loss: 0.571690\n",
      "epoch 74; iter: 0; batch classifier loss: 0.356087; batch adversarial loss: 0.544269\n",
      "epoch 75; iter: 0; batch classifier loss: 0.380921; batch adversarial loss: 0.561817\n",
      "epoch 76; iter: 0; batch classifier loss: 0.393082; batch adversarial loss: 0.579693\n",
      "epoch 77; iter: 0; batch classifier loss: 0.405859; batch adversarial loss: 0.554193\n",
      "epoch 78; iter: 0; batch classifier loss: 0.405364; batch adversarial loss: 0.581279\n",
      "epoch 79; iter: 0; batch classifier loss: 0.347022; batch adversarial loss: 0.580410\n",
      "epoch 80; iter: 0; batch classifier loss: 0.409598; batch adversarial loss: 0.498673\n",
      "epoch 81; iter: 0; batch classifier loss: 0.358368; batch adversarial loss: 0.500003\n",
      "epoch 82; iter: 0; batch classifier loss: 0.384092; batch adversarial loss: 0.588699\n",
      "epoch 83; iter: 0; batch classifier loss: 0.420984; batch adversarial loss: 0.562357\n",
      "epoch 84; iter: 0; batch classifier loss: 0.388909; batch adversarial loss: 0.600461\n",
      "epoch 85; iter: 0; batch classifier loss: 0.372821; batch adversarial loss: 0.570610\n",
      "epoch 86; iter: 0; batch classifier loss: 0.346606; batch adversarial loss: 0.535901\n",
      "epoch 87; iter: 0; batch classifier loss: 0.385289; batch adversarial loss: 0.571692\n",
      "epoch 88; iter: 0; batch classifier loss: 0.376238; batch adversarial loss: 0.499534\n",
      "epoch 89; iter: 0; batch classifier loss: 0.319848; batch adversarial loss: 0.563269\n",
      "epoch 90; iter: 0; batch classifier loss: 0.431305; batch adversarial loss: 0.607555\n",
      "epoch 91; iter: 0; batch classifier loss: 0.310151; batch adversarial loss: 0.542907\n",
      "epoch 92; iter: 0; batch classifier loss: 0.404626; batch adversarial loss: 0.542797\n",
      "epoch 93; iter: 0; batch classifier loss: 0.358088; batch adversarial loss: 0.618560\n",
      "epoch 94; iter: 0; batch classifier loss: 0.372616; batch adversarial loss: 0.553653\n",
      "epoch 95; iter: 0; batch classifier loss: 0.310523; batch adversarial loss: 0.606745\n",
      "epoch 96; iter: 0; batch classifier loss: 0.320958; batch adversarial loss: 0.490931\n",
      "epoch 97; iter: 0; batch classifier loss: 0.385411; batch adversarial loss: 0.499274\n",
      "epoch 98; iter: 0; batch classifier loss: 0.351902; batch adversarial loss: 0.535478\n",
      "epoch 99; iter: 0; batch classifier loss: 0.378317; batch adversarial loss: 0.499515\n",
      "epoch 100; iter: 0; batch classifier loss: 0.423693; batch adversarial loss: 0.561998\n",
      "epoch 101; iter: 0; batch classifier loss: 0.399032; batch adversarial loss: 0.561524\n",
      "epoch 102; iter: 0; batch classifier loss: 0.312742; batch adversarial loss: 0.571067\n",
      "epoch 103; iter: 0; batch classifier loss: 0.428092; batch adversarial loss: 0.554110\n",
      "epoch 104; iter: 0; batch classifier loss: 0.375767; batch adversarial loss: 0.579301\n",
      "epoch 105; iter: 0; batch classifier loss: 0.309229; batch adversarial loss: 0.527175\n",
      "epoch 106; iter: 0; batch classifier loss: 0.324942; batch adversarial loss: 0.553629\n",
      "epoch 107; iter: 0; batch classifier loss: 0.341986; batch adversarial loss: 0.570714\n",
      "epoch 108; iter: 0; batch classifier loss: 0.327246; batch adversarial loss: 0.598019\n",
      "epoch 109; iter: 0; batch classifier loss: 0.310966; batch adversarial loss: 0.599710\n",
      "epoch 110; iter: 0; batch classifier loss: 0.332758; batch adversarial loss: 0.472392\n",
      "epoch 111; iter: 0; batch classifier loss: 0.312929; batch adversarial loss: 0.453286\n",
      "epoch 112; iter: 0; batch classifier loss: 0.355685; batch adversarial loss: 0.500878\n",
      "epoch 113; iter: 0; batch classifier loss: 0.332220; batch adversarial loss: 0.607678\n",
      "epoch 114; iter: 0; batch classifier loss: 0.390934; batch adversarial loss: 0.482142\n",
      "epoch 115; iter: 0; batch classifier loss: 0.399427; batch adversarial loss: 0.508419\n",
      "epoch 116; iter: 0; batch classifier loss: 0.229930; batch adversarial loss: 0.617320\n",
      "epoch 117; iter: 0; batch classifier loss: 0.334485; batch adversarial loss: 0.472716\n",
      "epoch 118; iter: 0; batch classifier loss: 0.335203; batch adversarial loss: 0.525755\n",
      "epoch 119; iter: 0; batch classifier loss: 0.325755; batch adversarial loss: 0.491468\n",
      "epoch 120; iter: 0; batch classifier loss: 0.307922; batch adversarial loss: 0.515298\n",
      "epoch 121; iter: 0; batch classifier loss: 0.428071; batch adversarial loss: 0.570750\n",
      "epoch 122; iter: 0; batch classifier loss: 0.280902; batch adversarial loss: 0.617148\n",
      "epoch 123; iter: 0; batch classifier loss: 0.336891; batch adversarial loss: 0.517528\n",
      "epoch 124; iter: 0; batch classifier loss: 0.290100; batch adversarial loss: 0.491071\n",
      "epoch 125; iter: 0; batch classifier loss: 0.343069; batch adversarial loss: 0.579761\n",
      "epoch 126; iter: 0; batch classifier loss: 0.375125; batch adversarial loss: 0.553798\n",
      "epoch 127; iter: 0; batch classifier loss: 0.321152; batch adversarial loss: 0.637248\n",
      "epoch 128; iter: 0; batch classifier loss: 0.322465; batch adversarial loss: 0.535399\n",
      "epoch 129; iter: 0; batch classifier loss: 0.367138; batch adversarial loss: 0.599202\n",
      "epoch 130; iter: 0; batch classifier loss: 0.273454; batch adversarial loss: 0.553780\n",
      "epoch 131; iter: 0; batch classifier loss: 0.315501; batch adversarial loss: 0.580647\n",
      "epoch 132; iter: 0; batch classifier loss: 0.409435; batch adversarial loss: 0.506331\n",
      "epoch 133; iter: 0; batch classifier loss: 0.324517; batch adversarial loss: 0.607060\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 134; iter: 0; batch classifier loss: 0.316193; batch adversarial loss: 0.525794\n",
      "epoch 135; iter: 0; batch classifier loss: 0.442561; batch adversarial loss: 0.525778\n",
      "epoch 136; iter: 0; batch classifier loss: 0.385043; batch adversarial loss: 0.562921\n",
      "epoch 137; iter: 0; batch classifier loss: 0.307361; batch adversarial loss: 0.527010\n",
      "epoch 138; iter: 0; batch classifier loss: 0.354126; batch adversarial loss: 0.554168\n",
      "epoch 139; iter: 0; batch classifier loss: 0.288704; batch adversarial loss: 0.553595\n",
      "epoch 140; iter: 0; batch classifier loss: 0.318198; batch adversarial loss: 0.526283\n",
      "epoch 141; iter: 0; batch classifier loss: 0.307714; batch adversarial loss: 0.534261\n",
      "epoch 142; iter: 0; batch classifier loss: 0.294354; batch adversarial loss: 0.590716\n",
      "epoch 143; iter: 0; batch classifier loss: 0.289569; batch adversarial loss: 0.571572\n",
      "epoch 144; iter: 0; batch classifier loss: 0.345859; batch adversarial loss: 0.588804\n",
      "epoch 145; iter: 0; batch classifier loss: 0.367017; batch adversarial loss: 0.526489\n",
      "epoch 146; iter: 0; batch classifier loss: 0.288372; batch adversarial loss: 0.471555\n",
      "epoch 147; iter: 0; batch classifier loss: 0.278374; batch adversarial loss: 0.552780\n",
      "epoch 148; iter: 0; batch classifier loss: 0.374968; batch adversarial loss: 0.517572\n",
      "epoch 149; iter: 0; batch classifier loss: 0.372276; batch adversarial loss: 0.562784\n",
      "epoch 150; iter: 0; batch classifier loss: 0.268519; batch adversarial loss: 0.552765\n",
      "epoch 151; iter: 0; batch classifier loss: 0.240018; batch adversarial loss: 0.506091\n",
      "epoch 152; iter: 0; batch classifier loss: 0.413162; batch adversarial loss: 0.664318\n",
      "epoch 153; iter: 0; batch classifier loss: 0.334693; batch adversarial loss: 0.500846\n",
      "epoch 154; iter: 0; batch classifier loss: 0.277232; batch adversarial loss: 0.507344\n",
      "epoch 155; iter: 0; batch classifier loss: 0.297799; batch adversarial loss: 0.554215\n",
      "epoch 156; iter: 0; batch classifier loss: 0.381334; batch adversarial loss: 0.570853\n",
      "epoch 157; iter: 0; batch classifier loss: 0.281912; batch adversarial loss: 0.533773\n",
      "epoch 158; iter: 0; batch classifier loss: 0.320185; batch adversarial loss: 0.527453\n",
      "epoch 159; iter: 0; batch classifier loss: 0.312965; batch adversarial loss: 0.526342\n",
      "epoch 160; iter: 0; batch classifier loss: 0.364176; batch adversarial loss: 0.535522\n",
      "epoch 161; iter: 0; batch classifier loss: 0.367849; batch adversarial loss: 0.563045\n",
      "epoch 162; iter: 0; batch classifier loss: 0.335900; batch adversarial loss: 0.553409\n",
      "epoch 163; iter: 0; batch classifier loss: 0.393648; batch adversarial loss: 0.543442\n",
      "epoch 164; iter: 0; batch classifier loss: 0.339976; batch adversarial loss: 0.527550\n",
      "epoch 165; iter: 0; batch classifier loss: 0.365070; batch adversarial loss: 0.524988\n",
      "epoch 166; iter: 0; batch classifier loss: 0.381872; batch adversarial loss: 0.543278\n",
      "epoch 167; iter: 0; batch classifier loss: 0.316774; batch adversarial loss: 0.517025\n",
      "epoch 168; iter: 0; batch classifier loss: 0.275086; batch adversarial loss: 0.536083\n",
      "epoch 169; iter: 0; batch classifier loss: 0.397674; batch adversarial loss: 0.553816\n",
      "epoch 170; iter: 0; batch classifier loss: 0.283398; batch adversarial loss: 0.552091\n",
      "epoch 171; iter: 0; batch classifier loss: 0.375938; batch adversarial loss: 0.533217\n",
      "epoch 172; iter: 0; batch classifier loss: 0.331103; batch adversarial loss: 0.517093\n",
      "epoch 173; iter: 0; batch classifier loss: 0.359136; batch adversarial loss: 0.507370\n",
      "epoch 174; iter: 0; batch classifier loss: 0.374447; batch adversarial loss: 0.571974\n",
      "epoch 175; iter: 0; batch classifier loss: 0.267035; batch adversarial loss: 0.488092\n",
      "epoch 176; iter: 0; batch classifier loss: 0.316274; batch adversarial loss: 0.544899\n",
      "epoch 177; iter: 0; batch classifier loss: 0.411014; batch adversarial loss: 0.616557\n",
      "epoch 178; iter: 0; batch classifier loss: 0.295641; batch adversarial loss: 0.528081\n",
      "epoch 179; iter: 0; batch classifier loss: 0.352617; batch adversarial loss: 0.561900\n",
      "epoch 180; iter: 0; batch classifier loss: 0.307421; batch adversarial loss: 0.499693\n",
      "epoch 181; iter: 0; batch classifier loss: 0.350598; batch adversarial loss: 0.599677\n",
      "epoch 182; iter: 0; batch classifier loss: 0.317436; batch adversarial loss: 0.482150\n",
      "epoch 183; iter: 0; batch classifier loss: 0.343973; batch adversarial loss: 0.527132\n",
      "epoch 184; iter: 0; batch classifier loss: 0.302392; batch adversarial loss: 0.553835\n",
      "epoch 185; iter: 0; batch classifier loss: 0.398804; batch adversarial loss: 0.574679\n",
      "epoch 186; iter: 0; batch classifier loss: 0.313912; batch adversarial loss: 0.554430\n",
      "epoch 187; iter: 0; batch classifier loss: 0.276231; batch adversarial loss: 0.508804\n",
      "epoch 188; iter: 0; batch classifier loss: 0.300940; batch adversarial loss: 0.542834\n",
      "epoch 189; iter: 0; batch classifier loss: 0.352178; batch adversarial loss: 0.542956\n",
      "epoch 190; iter: 0; batch classifier loss: 0.384753; batch adversarial loss: 0.580666\n",
      "epoch 191; iter: 0; batch classifier loss: 0.296253; batch adversarial loss: 0.528420\n",
      "epoch 192; iter: 0; batch classifier loss: 0.262369; batch adversarial loss: 0.525210\n",
      "epoch 193; iter: 0; batch classifier loss: 0.292987; batch adversarial loss: 0.626495\n",
      "epoch 194; iter: 0; batch classifier loss: 0.371877; batch adversarial loss: 0.570997\n",
      "epoch 195; iter: 0; batch classifier loss: 0.274257; batch adversarial loss: 0.525686\n",
      "epoch 196; iter: 0; batch classifier loss: 0.312324; batch adversarial loss: 0.544686\n",
      "epoch 197; iter: 0; batch classifier loss: 0.298290; batch adversarial loss: 0.455245\n",
      "epoch 198; iter: 0; batch classifier loss: 0.341951; batch adversarial loss: 0.561508\n",
      "epoch 199; iter: 0; batch classifier loss: 0.297837; batch adversarial loss: 0.571778\n",
      "epoch 0; iter: 0; batch classifier loss: 0.702769; batch adversarial loss: 0.632359\n",
      "epoch 1; iter: 0; batch classifier loss: 0.534427; batch adversarial loss: 0.654794\n",
      "epoch 2; iter: 0; batch classifier loss: 0.604368; batch adversarial loss: 0.659398\n",
      "epoch 3; iter: 0; batch classifier loss: 0.627855; batch adversarial loss: 0.655164\n",
      "epoch 4; iter: 0; batch classifier loss: 0.579300; batch adversarial loss: 0.645003\n",
      "epoch 5; iter: 0; batch classifier loss: 0.617707; batch adversarial loss: 0.643669\n",
      "epoch 6; iter: 0; batch classifier loss: 0.501822; batch adversarial loss: 0.630677\n",
      "epoch 7; iter: 0; batch classifier loss: 0.614033; batch adversarial loss: 0.607958\n",
      "epoch 8; iter: 0; batch classifier loss: 0.555906; batch adversarial loss: 0.620323\n",
      "epoch 9; iter: 0; batch classifier loss: 0.618989; batch adversarial loss: 0.575013\n",
      "epoch 10; iter: 0; batch classifier loss: 0.555770; batch adversarial loss: 0.562324\n",
      "epoch 11; iter: 0; batch classifier loss: 0.586556; batch adversarial loss: 0.548854\n",
      "epoch 12; iter: 0; batch classifier loss: 0.514579; batch adversarial loss: 0.536606\n",
      "epoch 13; iter: 0; batch classifier loss: 0.569626; batch adversarial loss: 0.569277\n",
      "epoch 14; iter: 0; batch classifier loss: 0.537010; batch adversarial loss: 0.568718\n",
      "epoch 15; iter: 0; batch classifier loss: 0.496908; batch adversarial loss: 0.620460\n",
      "epoch 16; iter: 0; batch classifier loss: 0.549767; batch adversarial loss: 0.590053\n",
      "epoch 17; iter: 0; batch classifier loss: 0.511913; batch adversarial loss: 0.579442\n",
      "epoch 18; iter: 0; batch classifier loss: 0.458595; batch adversarial loss: 0.613428\n",
      "epoch 19; iter: 0; batch classifier loss: 0.572627; batch adversarial loss: 0.559532\n",
      "epoch 20; iter: 0; batch classifier loss: 0.480530; batch adversarial loss: 0.569893\n",
      "epoch 21; iter: 0; batch classifier loss: 0.480493; batch adversarial loss: 0.528195\n",
      "epoch 22; iter: 0; batch classifier loss: 0.486252; batch adversarial loss: 0.535353\n",
      "epoch 23; iter: 0; batch classifier loss: 0.537918; batch adversarial loss: 0.534354\n",
      "epoch 24; iter: 0; batch classifier loss: 0.454888; batch adversarial loss: 0.646876\n",
      "epoch 25; iter: 0; batch classifier loss: 0.425269; batch adversarial loss: 0.584457\n",
      "epoch 26; iter: 0; batch classifier loss: 0.486366; batch adversarial loss: 0.557905\n",
      "epoch 27; iter: 0; batch classifier loss: 0.431934; batch adversarial loss: 0.501500\n",
      "epoch 28; iter: 0; batch classifier loss: 0.494759; batch adversarial loss: 0.588280\n",
      "epoch 29; iter: 0; batch classifier loss: 0.434319; batch adversarial loss: 0.508489\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30; iter: 0; batch classifier loss: 0.464286; batch adversarial loss: 0.551561\n",
      "epoch 31; iter: 0; batch classifier loss: 0.472065; batch adversarial loss: 0.472871\n",
      "epoch 32; iter: 0; batch classifier loss: 0.445347; batch adversarial loss: 0.481223\n",
      "epoch 33; iter: 0; batch classifier loss: 0.492350; batch adversarial loss: 0.578558\n",
      "epoch 34; iter: 0; batch classifier loss: 0.421709; batch adversarial loss: 0.491345\n",
      "epoch 35; iter: 0; batch classifier loss: 0.438264; batch adversarial loss: 0.536671\n",
      "epoch 36; iter: 0; batch classifier loss: 0.470638; batch adversarial loss: 0.518097\n",
      "epoch 37; iter: 0; batch classifier loss: 0.479545; batch adversarial loss: 0.561587\n",
      "epoch 38; iter: 0; batch classifier loss: 0.491442; batch adversarial loss: 0.561904\n",
      "epoch 39; iter: 0; batch classifier loss: 0.455215; batch adversarial loss: 0.552221\n",
      "epoch 40; iter: 0; batch classifier loss: 0.408463; batch adversarial loss: 0.474013\n",
      "epoch 41; iter: 0; batch classifier loss: 0.439764; batch adversarial loss: 0.462832\n",
      "epoch 42; iter: 0; batch classifier loss: 0.398403; batch adversarial loss: 0.480519\n",
      "epoch 43; iter: 0; batch classifier loss: 0.492939; batch adversarial loss: 0.479381\n",
      "epoch 44; iter: 0; batch classifier loss: 0.451702; batch adversarial loss: 0.571282\n",
      "epoch 45; iter: 0; batch classifier loss: 0.439797; batch adversarial loss: 0.517066\n",
      "epoch 46; iter: 0; batch classifier loss: 0.476838; batch adversarial loss: 0.553038\n",
      "epoch 47; iter: 0; batch classifier loss: 0.416280; batch adversarial loss: 0.498562\n",
      "epoch 48; iter: 0; batch classifier loss: 0.509769; batch adversarial loss: 0.580234\n",
      "epoch 49; iter: 0; batch classifier loss: 0.380165; batch adversarial loss: 0.517374\n",
      "epoch 50; iter: 0; batch classifier loss: 0.441044; batch adversarial loss: 0.553663\n",
      "epoch 51; iter: 0; batch classifier loss: 0.377223; batch adversarial loss: 0.562592\n",
      "epoch 52; iter: 0; batch classifier loss: 0.369159; batch adversarial loss: 0.534577\n",
      "epoch 53; iter: 0; batch classifier loss: 0.486120; batch adversarial loss: 0.499603\n",
      "epoch 54; iter: 0; batch classifier loss: 0.415452; batch adversarial loss: 0.636189\n",
      "epoch 55; iter: 0; batch classifier loss: 0.430898; batch adversarial loss: 0.508116\n",
      "epoch 56; iter: 0; batch classifier loss: 0.424052; batch adversarial loss: 0.526389\n",
      "epoch 57; iter: 0; batch classifier loss: 0.423607; batch adversarial loss: 0.535143\n",
      "epoch 58; iter: 0; batch classifier loss: 0.473788; batch adversarial loss: 0.526570\n",
      "epoch 59; iter: 0; batch classifier loss: 0.510466; batch adversarial loss: 0.544406\n",
      "epoch 60; iter: 0; batch classifier loss: 0.366564; batch adversarial loss: 0.535371\n",
      "epoch 61; iter: 0; batch classifier loss: 0.428523; batch adversarial loss: 0.535964\n",
      "epoch 62; iter: 0; batch classifier loss: 0.413302; batch adversarial loss: 0.581048\n",
      "epoch 63; iter: 0; batch classifier loss: 0.399915; batch adversarial loss: 0.544834\n",
      "epoch 64; iter: 0; batch classifier loss: 0.438010; batch adversarial loss: 0.562629\n",
      "epoch 65; iter: 0; batch classifier loss: 0.401754; batch adversarial loss: 0.526659\n",
      "epoch 66; iter: 0; batch classifier loss: 0.417193; batch adversarial loss: 0.508290\n",
      "epoch 67; iter: 0; batch classifier loss: 0.478051; batch adversarial loss: 0.589768\n",
      "epoch 68; iter: 0; batch classifier loss: 0.433652; batch adversarial loss: 0.553805\n",
      "epoch 69; iter: 0; batch classifier loss: 0.366936; batch adversarial loss: 0.544630\n",
      "epoch 70; iter: 0; batch classifier loss: 0.471463; batch adversarial loss: 0.480861\n",
      "epoch 71; iter: 0; batch classifier loss: 0.408889; batch adversarial loss: 0.534353\n",
      "epoch 72; iter: 0; batch classifier loss: 0.533549; batch adversarial loss: 0.544053\n",
      "epoch 73; iter: 0; batch classifier loss: 0.407499; batch adversarial loss: 0.636422\n",
      "epoch 74; iter: 0; batch classifier loss: 0.421347; batch adversarial loss: 0.555260\n",
      "epoch 75; iter: 0; batch classifier loss: 0.508611; batch adversarial loss: 0.545111\n",
      "epoch 76; iter: 0; batch classifier loss: 0.434121; batch adversarial loss: 0.489479\n",
      "epoch 77; iter: 0; batch classifier loss: 0.456681; batch adversarial loss: 0.581342\n",
      "epoch 78; iter: 0; batch classifier loss: 0.399328; batch adversarial loss: 0.709147\n",
      "epoch 79; iter: 0; batch classifier loss: 0.373759; batch adversarial loss: 0.581552\n",
      "epoch 80; iter: 0; batch classifier loss: 0.408821; batch adversarial loss: 0.563356\n",
      "epoch 81; iter: 0; batch classifier loss: 0.449981; batch adversarial loss: 0.571283\n",
      "epoch 82; iter: 0; batch classifier loss: 0.404619; batch adversarial loss: 0.572070\n",
      "epoch 83; iter: 0; batch classifier loss: 0.338397; batch adversarial loss: 0.580549\n",
      "epoch 84; iter: 0; batch classifier loss: 0.526692; batch adversarial loss: 0.480441\n",
      "epoch 85; iter: 0; batch classifier loss: 0.448036; batch adversarial loss: 0.524212\n",
      "epoch 86; iter: 0; batch classifier loss: 0.339745; batch adversarial loss: 0.504664\n",
      "epoch 87; iter: 0; batch classifier loss: 0.454972; batch adversarial loss: 0.534765\n",
      "epoch 88; iter: 0; batch classifier loss: 0.408930; batch adversarial loss: 0.495700\n",
      "epoch 89; iter: 0; batch classifier loss: 0.430239; batch adversarial loss: 0.489093\n",
      "epoch 90; iter: 0; batch classifier loss: 0.468055; batch adversarial loss: 0.544668\n",
      "epoch 91; iter: 0; batch classifier loss: 0.363724; batch adversarial loss: 0.536067\n",
      "epoch 92; iter: 0; batch classifier loss: 0.455165; batch adversarial loss: 0.580280\n",
      "epoch 93; iter: 0; batch classifier loss: 0.431058; batch adversarial loss: 0.579436\n",
      "epoch 94; iter: 0; batch classifier loss: 0.435663; batch adversarial loss: 0.580452\n",
      "epoch 95; iter: 0; batch classifier loss: 0.401509; batch adversarial loss: 0.508385\n",
      "epoch 96; iter: 0; batch classifier loss: 0.412557; batch adversarial loss: 0.527699\n",
      "epoch 97; iter: 0; batch classifier loss: 0.346347; batch adversarial loss: 0.571308\n",
      "epoch 98; iter: 0; batch classifier loss: 0.388471; batch adversarial loss: 0.544038\n",
      "epoch 99; iter: 0; batch classifier loss: 0.440272; batch adversarial loss: 0.599410\n",
      "epoch 100; iter: 0; batch classifier loss: 0.415694; batch adversarial loss: 0.480536\n",
      "epoch 101; iter: 0; batch classifier loss: 0.370674; batch adversarial loss: 0.572797\n",
      "epoch 102; iter: 0; batch classifier loss: 0.388421; batch adversarial loss: 0.579692\n",
      "epoch 103; iter: 0; batch classifier loss: 0.402818; batch adversarial loss: 0.618390\n",
      "epoch 104; iter: 0; batch classifier loss: 0.365510; batch adversarial loss: 0.538201\n",
      "epoch 105; iter: 0; batch classifier loss: 0.404539; batch adversarial loss: 0.533372\n",
      "epoch 106; iter: 0; batch classifier loss: 0.367710; batch adversarial loss: 0.515657\n",
      "epoch 107; iter: 0; batch classifier loss: 0.407626; batch adversarial loss: 0.608006\n",
      "epoch 108; iter: 0; batch classifier loss: 0.357454; batch adversarial loss: 0.525356\n",
      "epoch 109; iter: 0; batch classifier loss: 0.464318; batch adversarial loss: 0.597264\n",
      "epoch 110; iter: 0; batch classifier loss: 0.316325; batch adversarial loss: 0.498544\n",
      "epoch 111; iter: 0; batch classifier loss: 0.410254; batch adversarial loss: 0.544996\n",
      "epoch 112; iter: 0; batch classifier loss: 0.487320; batch adversarial loss: 0.564094\n",
      "epoch 113; iter: 0; batch classifier loss: 0.390470; batch adversarial loss: 0.434504\n",
      "epoch 114; iter: 0; batch classifier loss: 0.348624; batch adversarial loss: 0.642429\n",
      "epoch 115; iter: 0; batch classifier loss: 0.445495; batch adversarial loss: 0.570307\n",
      "epoch 116; iter: 0; batch classifier loss: 0.453089; batch adversarial loss: 0.502730\n",
      "epoch 117; iter: 0; batch classifier loss: 0.444692; batch adversarial loss: 0.562989\n",
      "epoch 118; iter: 0; batch classifier loss: 0.366044; batch adversarial loss: 0.574892\n",
      "epoch 119; iter: 0; batch classifier loss: 0.407687; batch adversarial loss: 0.573593\n",
      "epoch 120; iter: 0; batch classifier loss: 0.397700; batch adversarial loss: 0.481785\n",
      "epoch 121; iter: 0; batch classifier loss: 0.433459; batch adversarial loss: 0.507201\n",
      "epoch 122; iter: 0; batch classifier loss: 0.435054; batch adversarial loss: 0.545828\n",
      "epoch 123; iter: 0; batch classifier loss: 0.425343; batch adversarial loss: 0.662832\n",
      "epoch 124; iter: 0; batch classifier loss: 0.364372; batch adversarial loss: 0.634969\n",
      "epoch 125; iter: 0; batch classifier loss: 0.382131; batch adversarial loss: 0.563486\n",
      "epoch 126; iter: 0; batch classifier loss: 0.318304; batch adversarial loss: 0.607694\n",
      "epoch 127; iter: 0; batch classifier loss: 0.367085; batch adversarial loss: 0.562898\n",
      "epoch 128; iter: 0; batch classifier loss: 0.382169; batch adversarial loss: 0.490453\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 129; iter: 0; batch classifier loss: 0.375357; batch adversarial loss: 0.572760\n",
      "epoch 130; iter: 0; batch classifier loss: 0.373917; batch adversarial loss: 0.490468\n",
      "epoch 131; iter: 0; batch classifier loss: 0.382885; batch adversarial loss: 0.497308\n",
      "epoch 132; iter: 0; batch classifier loss: 0.416585; batch adversarial loss: 0.582375\n",
      "epoch 133; iter: 0; batch classifier loss: 0.376235; batch adversarial loss: 0.497722\n",
      "epoch 134; iter: 0; batch classifier loss: 0.401533; batch adversarial loss: 0.580984\n",
      "epoch 135; iter: 0; batch classifier loss: 0.481929; batch adversarial loss: 0.556300\n",
      "epoch 136; iter: 0; batch classifier loss: 0.381369; batch adversarial loss: 0.569373\n",
      "epoch 137; iter: 0; batch classifier loss: 0.423687; batch adversarial loss: 0.517441\n",
      "epoch 138; iter: 0; batch classifier loss: 0.402018; batch adversarial loss: 0.515367\n",
      "epoch 139; iter: 0; batch classifier loss: 0.398350; batch adversarial loss: 0.582126\n",
      "epoch 140; iter: 0; batch classifier loss: 0.342366; batch adversarial loss: 0.554622\n",
      "epoch 141; iter: 0; batch classifier loss: 0.471109; batch adversarial loss: 0.551103\n",
      "epoch 142; iter: 0; batch classifier loss: 0.404150; batch adversarial loss: 0.499641\n",
      "epoch 143; iter: 0; batch classifier loss: 0.404213; batch adversarial loss: 0.562098\n",
      "epoch 144; iter: 0; batch classifier loss: 0.327672; batch adversarial loss: 0.589967\n",
      "epoch 145; iter: 0; batch classifier loss: 0.426275; batch adversarial loss: 0.509317\n",
      "epoch 146; iter: 0; batch classifier loss: 0.406167; batch adversarial loss: 0.572434\n",
      "epoch 147; iter: 0; batch classifier loss: 0.360750; batch adversarial loss: 0.526829\n",
      "epoch 148; iter: 0; batch classifier loss: 0.330893; batch adversarial loss: 0.508608\n",
      "epoch 149; iter: 0; batch classifier loss: 0.352120; batch adversarial loss: 0.528541\n",
      "epoch 150; iter: 0; batch classifier loss: 0.346821; batch adversarial loss: 0.482536\n",
      "epoch 151; iter: 0; batch classifier loss: 0.338140; batch adversarial loss: 0.545081\n",
      "epoch 152; iter: 0; batch classifier loss: 0.358890; batch adversarial loss: 0.553418\n",
      "epoch 153; iter: 0; batch classifier loss: 0.361056; batch adversarial loss: 0.571558\n",
      "epoch 154; iter: 0; batch classifier loss: 0.382304; batch adversarial loss: 0.535677\n",
      "epoch 155; iter: 0; batch classifier loss: 0.416707; batch adversarial loss: 0.562486\n",
      "epoch 156; iter: 0; batch classifier loss: 0.385092; batch adversarial loss: 0.535981\n",
      "epoch 157; iter: 0; batch classifier loss: 0.383092; batch adversarial loss: 0.562455\n",
      "epoch 158; iter: 0; batch classifier loss: 0.345106; batch adversarial loss: 0.544229\n",
      "epoch 159; iter: 0; batch classifier loss: 0.426062; batch adversarial loss: 0.490148\n",
      "epoch 160; iter: 0; batch classifier loss: 0.412398; batch adversarial loss: 0.545048\n",
      "epoch 161; iter: 0; batch classifier loss: 0.426437; batch adversarial loss: 0.517406\n",
      "epoch 162; iter: 0; batch classifier loss: 0.333697; batch adversarial loss: 0.517011\n",
      "epoch 163; iter: 0; batch classifier loss: 0.358671; batch adversarial loss: 0.626641\n",
      "epoch 164; iter: 0; batch classifier loss: 0.366481; batch adversarial loss: 0.517337\n",
      "epoch 165; iter: 0; batch classifier loss: 0.364291; batch adversarial loss: 0.626286\n",
      "epoch 166; iter: 0; batch classifier loss: 0.419178; batch adversarial loss: 0.526597\n",
      "epoch 167; iter: 0; batch classifier loss: 0.460048; batch adversarial loss: 0.563122\n",
      "epoch 168; iter: 0; batch classifier loss: 0.438816; batch adversarial loss: 0.544862\n",
      "epoch 169; iter: 0; batch classifier loss: 0.324743; batch adversarial loss: 0.562922\n",
      "epoch 170; iter: 0; batch classifier loss: 0.408575; batch adversarial loss: 0.554184\n",
      "epoch 171; iter: 0; batch classifier loss: 0.364749; batch adversarial loss: 0.580647\n",
      "epoch 172; iter: 0; batch classifier loss: 0.407378; batch adversarial loss: 0.526700\n",
      "epoch 173; iter: 0; batch classifier loss: 0.319371; batch adversarial loss: 0.517195\n",
      "epoch 174; iter: 0; batch classifier loss: 0.402427; batch adversarial loss: 0.580579\n",
      "epoch 175; iter: 0; batch classifier loss: 0.434033; batch adversarial loss: 0.508037\n",
      "epoch 176; iter: 0; batch classifier loss: 0.401650; batch adversarial loss: 0.544371\n",
      "epoch 177; iter: 0; batch classifier loss: 0.399449; batch adversarial loss: 0.580649\n",
      "epoch 178; iter: 0; batch classifier loss: 0.392342; batch adversarial loss: 0.552866\n",
      "epoch 179; iter: 0; batch classifier loss: 0.401112; batch adversarial loss: 0.488893\n",
      "epoch 180; iter: 0; batch classifier loss: 0.374499; batch adversarial loss: 0.534719\n",
      "epoch 181; iter: 0; batch classifier loss: 0.383179; batch adversarial loss: 0.535622\n",
      "epoch 182; iter: 0; batch classifier loss: 0.424475; batch adversarial loss: 0.541933\n",
      "epoch 183; iter: 0; batch classifier loss: 0.395607; batch adversarial loss: 0.561240\n",
      "epoch 184; iter: 0; batch classifier loss: 0.397447; batch adversarial loss: 0.517712\n",
      "epoch 185; iter: 0; batch classifier loss: 0.329248; batch adversarial loss: 0.570854\n",
      "epoch 186; iter: 0; batch classifier loss: 0.296010; batch adversarial loss: 0.488259\n",
      "epoch 187; iter: 0; batch classifier loss: 0.485297; batch adversarial loss: 0.507185\n",
      "epoch 188; iter: 0; batch classifier loss: 0.381130; batch adversarial loss: 0.569818\n",
      "epoch 189; iter: 0; batch classifier loss: 0.430135; batch adversarial loss: 0.535508\n",
      "epoch 190; iter: 0; batch classifier loss: 0.409086; batch adversarial loss: 0.505629\n",
      "epoch 191; iter: 0; batch classifier loss: 0.435870; batch adversarial loss: 0.568236\n",
      "epoch 192; iter: 0; batch classifier loss: 0.273816; batch adversarial loss: 0.609724\n",
      "epoch 193; iter: 0; batch classifier loss: 0.323811; batch adversarial loss: 0.473514\n",
      "epoch 194; iter: 0; batch classifier loss: 0.364023; batch adversarial loss: 0.518963\n",
      "epoch 195; iter: 0; batch classifier loss: 0.432525; batch adversarial loss: 0.535688\n",
      "epoch 196; iter: 0; batch classifier loss: 0.382317; batch adversarial loss: 0.499409\n",
      "epoch 197; iter: 0; batch classifier loss: 0.326793; batch adversarial loss: 0.609140\n",
      "epoch 198; iter: 0; batch classifier loss: 0.416920; batch adversarial loss: 0.553815\n",
      "epoch 199; iter: 0; batch classifier loss: 0.325296; batch adversarial loss: 0.508543\n",
      "epoch 0; iter: 0; batch classifier loss: 0.717270; batch adversarial loss: 0.652094\n",
      "epoch 1; iter: 0; batch classifier loss: 0.546146; batch adversarial loss: 0.643174\n",
      "epoch 2; iter: 0; batch classifier loss: 0.580236; batch adversarial loss: 0.605062\n",
      "epoch 3; iter: 0; batch classifier loss: 0.666909; batch adversarial loss: 0.619922\n",
      "epoch 4; iter: 0; batch classifier loss: 0.637020; batch adversarial loss: 0.643770\n",
      "epoch 5; iter: 0; batch classifier loss: 0.486104; batch adversarial loss: 0.621574\n",
      "epoch 6; iter: 0; batch classifier loss: 0.492230; batch adversarial loss: 0.616124\n",
      "epoch 7; iter: 0; batch classifier loss: 0.559498; batch adversarial loss: 0.601801\n",
      "epoch 8; iter: 0; batch classifier loss: 0.571104; batch adversarial loss: 0.594831\n",
      "epoch 9; iter: 0; batch classifier loss: 0.607627; batch adversarial loss: 0.633111\n",
      "epoch 10; iter: 0; batch classifier loss: 0.507538; batch adversarial loss: 0.610991\n",
      "epoch 11; iter: 0; batch classifier loss: 0.570221; batch adversarial loss: 0.674216\n",
      "epoch 12; iter: 0; batch classifier loss: 0.482274; batch adversarial loss: 0.586086\n",
      "epoch 13; iter: 0; batch classifier loss: 0.505858; batch adversarial loss: 0.578530\n",
      "epoch 14; iter: 0; batch classifier loss: 0.571976; batch adversarial loss: 0.604918\n",
      "epoch 15; iter: 0; batch classifier loss: 0.535992; batch adversarial loss: 0.591163\n",
      "epoch 16; iter: 0; batch classifier loss: 0.526496; batch adversarial loss: 0.548928\n",
      "epoch 17; iter: 0; batch classifier loss: 0.511555; batch adversarial loss: 0.615659\n",
      "epoch 18; iter: 0; batch classifier loss: 0.469557; batch adversarial loss: 0.606465\n",
      "epoch 19; iter: 0; batch classifier loss: 0.476307; batch adversarial loss: 0.612851\n",
      "epoch 20; iter: 0; batch classifier loss: 0.532526; batch adversarial loss: 0.567518\n",
      "epoch 21; iter: 0; batch classifier loss: 0.450103; batch adversarial loss: 0.558327\n",
      "epoch 22; iter: 0; batch classifier loss: 0.454939; batch adversarial loss: 0.580016\n",
      "epoch 23; iter: 0; batch classifier loss: 0.438437; batch adversarial loss: 0.524759\n",
      "epoch 24; iter: 0; batch classifier loss: 0.538432; batch adversarial loss: 0.539030\n",
      "epoch 25; iter: 0; batch classifier loss: 0.527910; batch adversarial loss: 0.530721\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 26; iter: 0; batch classifier loss: 0.535816; batch adversarial loss: 0.538104\n",
      "epoch 27; iter: 0; batch classifier loss: 0.462693; batch adversarial loss: 0.537909\n",
      "epoch 28; iter: 0; batch classifier loss: 0.474571; batch adversarial loss: 0.504101\n",
      "epoch 29; iter: 0; batch classifier loss: 0.475651; batch adversarial loss: 0.501543\n",
      "epoch 30; iter: 0; batch classifier loss: 0.370144; batch adversarial loss: 0.518743\n",
      "epoch 31; iter: 0; batch classifier loss: 0.440364; batch adversarial loss: 0.504492\n",
      "epoch 32; iter: 0; batch classifier loss: 0.512309; batch adversarial loss: 0.579245\n",
      "epoch 33; iter: 0; batch classifier loss: 0.458903; batch adversarial loss: 0.567485\n",
      "epoch 34; iter: 0; batch classifier loss: 0.437024; batch adversarial loss: 0.603588\n",
      "epoch 35; iter: 0; batch classifier loss: 0.474531; batch adversarial loss: 0.536036\n",
      "epoch 36; iter: 0; batch classifier loss: 0.428400; batch adversarial loss: 0.456050\n",
      "epoch 37; iter: 0; batch classifier loss: 0.457776; batch adversarial loss: 0.558951\n",
      "epoch 38; iter: 0; batch classifier loss: 0.459285; batch adversarial loss: 0.526524\n",
      "epoch 39; iter: 0; batch classifier loss: 0.433868; batch adversarial loss: 0.500416\n",
      "epoch 40; iter: 0; batch classifier loss: 0.476066; batch adversarial loss: 0.472582\n",
      "epoch 41; iter: 0; batch classifier loss: 0.418977; batch adversarial loss: 0.543671\n",
      "epoch 42; iter: 0; batch classifier loss: 0.484247; batch adversarial loss: 0.518673\n",
      "epoch 43; iter: 0; batch classifier loss: 0.450908; batch adversarial loss: 0.572371\n",
      "epoch 44; iter: 0; batch classifier loss: 0.326871; batch adversarial loss: 0.469808\n",
      "epoch 45; iter: 0; batch classifier loss: 0.420827; batch adversarial loss: 0.562973\n",
      "epoch 46; iter: 0; batch classifier loss: 0.422730; batch adversarial loss: 0.551994\n",
      "epoch 47; iter: 0; batch classifier loss: 0.369088; batch adversarial loss: 0.583304\n",
      "epoch 48; iter: 0; batch classifier loss: 0.448598; batch adversarial loss: 0.516408\n",
      "epoch 49; iter: 0; batch classifier loss: 0.417695; batch adversarial loss: 0.583541\n",
      "epoch 50; iter: 0; batch classifier loss: 0.393688; batch adversarial loss: 0.478444\n",
      "epoch 51; iter: 0; batch classifier loss: 0.369957; batch adversarial loss: 0.535163\n",
      "epoch 52; iter: 0; batch classifier loss: 0.419263; batch adversarial loss: 0.468929\n",
      "epoch 53; iter: 0; batch classifier loss: 0.465139; batch adversarial loss: 0.570756\n",
      "epoch 54; iter: 0; batch classifier loss: 0.419801; batch adversarial loss: 0.545526\n",
      "epoch 55; iter: 0; batch classifier loss: 0.421657; batch adversarial loss: 0.563390\n",
      "epoch 56; iter: 0; batch classifier loss: 0.380235; batch adversarial loss: 0.507888\n",
      "epoch 57; iter: 0; batch classifier loss: 0.452606; batch adversarial loss: 0.534801\n",
      "epoch 58; iter: 0; batch classifier loss: 0.410432; batch adversarial loss: 0.526243\n",
      "epoch 59; iter: 0; batch classifier loss: 0.371742; batch adversarial loss: 0.500577\n",
      "epoch 60; iter: 0; batch classifier loss: 0.373994; batch adversarial loss: 0.570434\n",
      "epoch 61; iter: 0; batch classifier loss: 0.369383; batch adversarial loss: 0.569121\n",
      "epoch 62; iter: 0; batch classifier loss: 0.386943; batch adversarial loss: 0.455949\n",
      "epoch 63; iter: 0; batch classifier loss: 0.438736; batch adversarial loss: 0.553088\n",
      "epoch 64; iter: 0; batch classifier loss: 0.407955; batch adversarial loss: 0.571279\n",
      "epoch 65; iter: 0; batch classifier loss: 0.416579; batch adversarial loss: 0.544056\n",
      "epoch 66; iter: 0; batch classifier loss: 0.428396; batch adversarial loss: 0.573486\n",
      "epoch 67; iter: 0; batch classifier loss: 0.396633; batch adversarial loss: 0.607010\n",
      "epoch 68; iter: 0; batch classifier loss: 0.361271; batch adversarial loss: 0.515364\n",
      "epoch 69; iter: 0; batch classifier loss: 0.359984; batch adversarial loss: 0.541831\n",
      "epoch 70; iter: 0; batch classifier loss: 0.390664; batch adversarial loss: 0.584711\n",
      "epoch 71; iter: 0; batch classifier loss: 0.381296; batch adversarial loss: 0.573226\n",
      "epoch 72; iter: 0; batch classifier loss: 0.359415; batch adversarial loss: 0.563763\n",
      "epoch 73; iter: 0; batch classifier loss: 0.369901; batch adversarial loss: 0.587768\n",
      "epoch 74; iter: 0; batch classifier loss: 0.464120; batch adversarial loss: 0.517584\n",
      "epoch 75; iter: 0; batch classifier loss: 0.377627; batch adversarial loss: 0.585844\n",
      "epoch 76; iter: 0; batch classifier loss: 0.443831; batch adversarial loss: 0.528131\n",
      "epoch 77; iter: 0; batch classifier loss: 0.407501; batch adversarial loss: 0.570910\n",
      "epoch 78; iter: 0; batch classifier loss: 0.423521; batch adversarial loss: 0.532389\n",
      "epoch 79; iter: 0; batch classifier loss: 0.387947; batch adversarial loss: 0.580640\n",
      "epoch 80; iter: 0; batch classifier loss: 0.440234; batch adversarial loss: 0.619343\n",
      "epoch 81; iter: 0; batch classifier loss: 0.446634; batch adversarial loss: 0.487796\n",
      "epoch 82; iter: 0; batch classifier loss: 0.506180; batch adversarial loss: 0.556195\n",
      "epoch 83; iter: 0; batch classifier loss: 0.396565; batch adversarial loss: 0.513389\n",
      "epoch 84; iter: 0; batch classifier loss: 0.447888; batch adversarial loss: 0.507763\n",
      "epoch 85; iter: 0; batch classifier loss: 0.362601; batch adversarial loss: 0.525164\n",
      "epoch 86; iter: 0; batch classifier loss: 0.372385; batch adversarial loss: 0.498317\n",
      "epoch 87; iter: 0; batch classifier loss: 0.325661; batch adversarial loss: 0.582675\n",
      "epoch 88; iter: 0; batch classifier loss: 0.387346; batch adversarial loss: 0.541924\n",
      "epoch 89; iter: 0; batch classifier loss: 0.397933; batch adversarial loss: 0.517174\n",
      "epoch 90; iter: 0; batch classifier loss: 0.448381; batch adversarial loss: 0.559290\n",
      "epoch 91; iter: 0; batch classifier loss: 0.400382; batch adversarial loss: 0.534289\n",
      "epoch 92; iter: 0; batch classifier loss: 0.472667; batch adversarial loss: 0.607956\n",
      "epoch 93; iter: 0; batch classifier loss: 0.366198; batch adversarial loss: 0.643969\n",
      "epoch 94; iter: 0; batch classifier loss: 0.353070; batch adversarial loss: 0.542246\n",
      "epoch 95; iter: 0; batch classifier loss: 0.439508; batch adversarial loss: 0.581795\n",
      "epoch 96; iter: 0; batch classifier loss: 0.368460; batch adversarial loss: 0.544542\n",
      "epoch 97; iter: 0; batch classifier loss: 0.417140; batch adversarial loss: 0.488982\n",
      "epoch 98; iter: 0; batch classifier loss: 0.442348; batch adversarial loss: 0.545071\n",
      "epoch 99; iter: 0; batch classifier loss: 0.380335; batch adversarial loss: 0.629011\n",
      "epoch 100; iter: 0; batch classifier loss: 0.510021; batch adversarial loss: 0.556157\n",
      "epoch 101; iter: 0; batch classifier loss: 0.303865; batch adversarial loss: 0.569687\n",
      "epoch 102; iter: 0; batch classifier loss: 0.449798; batch adversarial loss: 0.501037\n",
      "epoch 103; iter: 0; batch classifier loss: 0.459390; batch adversarial loss: 0.514435\n",
      "epoch 104; iter: 0; batch classifier loss: 0.372828; batch adversarial loss: 0.499827\n",
      "epoch 105; iter: 0; batch classifier loss: 0.441532; batch adversarial loss: 0.505611\n",
      "epoch 106; iter: 0; batch classifier loss: 0.322717; batch adversarial loss: 0.515642\n",
      "epoch 107; iter: 0; batch classifier loss: 0.361141; batch adversarial loss: 0.553956\n",
      "epoch 108; iter: 0; batch classifier loss: 0.423488; batch adversarial loss: 0.609748\n",
      "epoch 109; iter: 0; batch classifier loss: 0.347204; batch adversarial loss: 0.487299\n",
      "epoch 110; iter: 0; batch classifier loss: 0.453954; batch adversarial loss: 0.473029\n",
      "epoch 111; iter: 0; batch classifier loss: 0.280179; batch adversarial loss: 0.459603\n",
      "epoch 112; iter: 0; batch classifier loss: 0.366269; batch adversarial loss: 0.504436\n",
      "epoch 113; iter: 0; batch classifier loss: 0.360674; batch adversarial loss: 0.600520\n",
      "epoch 114; iter: 0; batch classifier loss: 0.490068; batch adversarial loss: 0.514813\n",
      "epoch 115; iter: 0; batch classifier loss: 0.403838; batch adversarial loss: 0.554129\n",
      "epoch 116; iter: 0; batch classifier loss: 0.367376; batch adversarial loss: 0.562282\n",
      "epoch 117; iter: 0; batch classifier loss: 0.254937; batch adversarial loss: 0.480670\n",
      "epoch 118; iter: 0; batch classifier loss: 0.392959; batch adversarial loss: 0.508700\n",
      "epoch 119; iter: 0; batch classifier loss: 0.332556; batch adversarial loss: 0.501037\n",
      "epoch 120; iter: 0; batch classifier loss: 0.332123; batch adversarial loss: 0.582138\n",
      "epoch 121; iter: 0; batch classifier loss: 0.373340; batch adversarial loss: 0.517093\n",
      "epoch 122; iter: 0; batch classifier loss: 0.355402; batch adversarial loss: 0.538343\n",
      "epoch 123; iter: 0; batch classifier loss: 0.501199; batch adversarial loss: 0.571605\n",
      "epoch 124; iter: 0; batch classifier loss: 0.447214; batch adversarial loss: 0.544560\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 125; iter: 0; batch classifier loss: 0.400370; batch adversarial loss: 0.554900\n",
      "epoch 126; iter: 0; batch classifier loss: 0.365852; batch adversarial loss: 0.547390\n",
      "epoch 127; iter: 0; batch classifier loss: 0.403380; batch adversarial loss: 0.556844\n",
      "epoch 128; iter: 0; batch classifier loss: 0.396945; batch adversarial loss: 0.570590\n",
      "epoch 129; iter: 0; batch classifier loss: 0.405962; batch adversarial loss: 0.528872\n",
      "epoch 130; iter: 0; batch classifier loss: 0.361688; batch adversarial loss: 0.504968\n",
      "epoch 131; iter: 0; batch classifier loss: 0.437955; batch adversarial loss: 0.527465\n",
      "epoch 132; iter: 0; batch classifier loss: 0.461290; batch adversarial loss: 0.557073\n",
      "epoch 133; iter: 0; batch classifier loss: 0.427646; batch adversarial loss: 0.525764\n",
      "epoch 134; iter: 0; batch classifier loss: 0.420386; batch adversarial loss: 0.578209\n",
      "epoch 135; iter: 0; batch classifier loss: 0.400017; batch adversarial loss: 0.499684\n",
      "epoch 136; iter: 0; batch classifier loss: 0.339614; batch adversarial loss: 0.517863\n",
      "epoch 137; iter: 0; batch classifier loss: 0.370862; batch adversarial loss: 0.545218\n",
      "epoch 138; iter: 0; batch classifier loss: 0.273568; batch adversarial loss: 0.501844\n",
      "epoch 139; iter: 0; batch classifier loss: 0.414742; batch adversarial loss: 0.575239\n",
      "epoch 140; iter: 0; batch classifier loss: 0.363655; batch adversarial loss: 0.544690\n",
      "epoch 141; iter: 0; batch classifier loss: 0.358720; batch adversarial loss: 0.487499\n",
      "epoch 142; iter: 0; batch classifier loss: 0.362314; batch adversarial loss: 0.546158\n",
      "epoch 143; iter: 0; batch classifier loss: 0.378470; batch adversarial loss: 0.495332\n",
      "epoch 144; iter: 0; batch classifier loss: 0.368296; batch adversarial loss: 0.498222\n",
      "epoch 145; iter: 0; batch classifier loss: 0.355318; batch adversarial loss: 0.490494\n",
      "epoch 146; iter: 0; batch classifier loss: 0.359886; batch adversarial loss: 0.580835\n",
      "epoch 147; iter: 0; batch classifier loss: 0.435874; batch adversarial loss: 0.579174\n",
      "epoch 148; iter: 0; batch classifier loss: 0.341878; batch adversarial loss: 0.477573\n",
      "epoch 149; iter: 0; batch classifier loss: 0.350782; batch adversarial loss: 0.528634\n",
      "epoch 150; iter: 0; batch classifier loss: 0.365504; batch adversarial loss: 0.508887\n",
      "epoch 151; iter: 0; batch classifier loss: 0.366790; batch adversarial loss: 0.582146\n",
      "epoch 152; iter: 0; batch classifier loss: 0.332750; batch adversarial loss: 0.599969\n",
      "epoch 153; iter: 0; batch classifier loss: 0.370049; batch adversarial loss: 0.471417\n",
      "epoch 154; iter: 0; batch classifier loss: 0.271190; batch adversarial loss: 0.489134\n",
      "epoch 155; iter: 0; batch classifier loss: 0.384194; batch adversarial loss: 0.447776\n",
      "epoch 156; iter: 0; batch classifier loss: 0.328033; batch adversarial loss: 0.517510\n",
      "epoch 157; iter: 0; batch classifier loss: 0.359217; batch adversarial loss: 0.549797\n",
      "epoch 158; iter: 0; batch classifier loss: 0.425985; batch adversarial loss: 0.540353\n",
      "epoch 159; iter: 0; batch classifier loss: 0.393195; batch adversarial loss: 0.508524\n",
      "epoch 160; iter: 0; batch classifier loss: 0.354833; batch adversarial loss: 0.507868\n",
      "epoch 161; iter: 0; batch classifier loss: 0.420071; batch adversarial loss: 0.461777\n",
      "epoch 162; iter: 0; batch classifier loss: 0.292891; batch adversarial loss: 0.510708\n",
      "epoch 163; iter: 0; batch classifier loss: 0.350166; batch adversarial loss: 0.506434\n",
      "epoch 164; iter: 0; batch classifier loss: 0.415427; batch adversarial loss: 0.585538\n",
      "epoch 165; iter: 0; batch classifier loss: 0.323854; batch adversarial loss: 0.536906\n",
      "epoch 166; iter: 0; batch classifier loss: 0.324005; batch adversarial loss: 0.539789\n",
      "epoch 167; iter: 0; batch classifier loss: 0.428091; batch adversarial loss: 0.508946\n",
      "epoch 168; iter: 0; batch classifier loss: 0.424824; batch adversarial loss: 0.533795\n",
      "epoch 169; iter: 0; batch classifier loss: 0.315891; batch adversarial loss: 0.448779\n",
      "epoch 170; iter: 0; batch classifier loss: 0.361426; batch adversarial loss: 0.500400\n",
      "epoch 171; iter: 0; batch classifier loss: 0.367549; batch adversarial loss: 0.519664\n",
      "epoch 172; iter: 0; batch classifier loss: 0.323394; batch adversarial loss: 0.551827\n",
      "epoch 173; iter: 0; batch classifier loss: 0.378317; batch adversarial loss: 0.633853\n",
      "epoch 174; iter: 0; batch classifier loss: 0.317644; batch adversarial loss: 0.554412\n",
      "epoch 175; iter: 0; batch classifier loss: 0.322301; batch adversarial loss: 0.524016\n",
      "epoch 176; iter: 0; batch classifier loss: 0.387033; batch adversarial loss: 0.678609\n",
      "epoch 177; iter: 0; batch classifier loss: 0.371314; batch adversarial loss: 0.581102\n",
      "epoch 178; iter: 0; batch classifier loss: 0.343436; batch adversarial loss: 0.463644\n",
      "epoch 179; iter: 0; batch classifier loss: 0.390464; batch adversarial loss: 0.576988\n",
      "epoch 180; iter: 0; batch classifier loss: 0.424508; batch adversarial loss: 0.524277\n",
      "epoch 181; iter: 0; batch classifier loss: 0.238751; batch adversarial loss: 0.610949\n",
      "epoch 182; iter: 0; batch classifier loss: 0.333398; batch adversarial loss: 0.503972\n",
      "epoch 183; iter: 0; batch classifier loss: 0.391055; batch adversarial loss: 0.530055\n",
      "epoch 184; iter: 0; batch classifier loss: 0.426184; batch adversarial loss: 0.534605\n",
      "epoch 185; iter: 0; batch classifier loss: 0.367694; batch adversarial loss: 0.570693\n",
      "epoch 186; iter: 0; batch classifier loss: 0.289002; batch adversarial loss: 0.472714\n",
      "epoch 187; iter: 0; batch classifier loss: 0.322737; batch adversarial loss: 0.554273\n",
      "epoch 188; iter: 0; batch classifier loss: 0.370114; batch adversarial loss: 0.504766\n",
      "epoch 189; iter: 0; batch classifier loss: 0.429719; batch adversarial loss: 0.660037\n",
      "epoch 190; iter: 0; batch classifier loss: 0.422488; batch adversarial loss: 0.588396\n",
      "epoch 191; iter: 0; batch classifier loss: 0.334067; batch adversarial loss: 0.535251\n",
      "epoch 192; iter: 0; batch classifier loss: 0.308812; batch adversarial loss: 0.523602\n",
      "epoch 193; iter: 0; batch classifier loss: 0.391378; batch adversarial loss: 0.574014\n",
      "epoch 194; iter: 0; batch classifier loss: 0.298564; batch adversarial loss: 0.572700\n",
      "epoch 195; iter: 0; batch classifier loss: 0.272818; batch adversarial loss: 0.492312\n",
      "epoch 196; iter: 0; batch classifier loss: 0.313724; batch adversarial loss: 0.526926\n",
      "epoch 197; iter: 0; batch classifier loss: 0.347120; batch adversarial loss: 0.579999\n",
      "epoch 198; iter: 0; batch classifier loss: 0.339854; batch adversarial loss: 0.569839\n",
      "epoch 199; iter: 0; batch classifier loss: 0.262937; batch adversarial loss: 0.630825\n",
      "epoch 0; iter: 0; batch classifier loss: 0.666427; batch adversarial loss: 0.652222\n",
      "epoch 1; iter: 0; batch classifier loss: 0.622937; batch adversarial loss: 0.659208\n",
      "epoch 2; iter: 0; batch classifier loss: 0.605088; batch adversarial loss: 0.671046\n",
      "epoch 3; iter: 0; batch classifier loss: 0.557230; batch adversarial loss: 0.664241\n",
      "epoch 4; iter: 0; batch classifier loss: 0.563651; batch adversarial loss: 0.644088\n",
      "epoch 5; iter: 0; batch classifier loss: 0.589615; batch adversarial loss: 0.648332\n",
      "epoch 6; iter: 0; batch classifier loss: 0.579563; batch adversarial loss: 0.643916\n",
      "epoch 7; iter: 0; batch classifier loss: 0.555263; batch adversarial loss: 0.623701\n",
      "epoch 8; iter: 0; batch classifier loss: 0.556499; batch adversarial loss: 0.596428\n",
      "epoch 9; iter: 0; batch classifier loss: 0.586321; batch adversarial loss: 0.591725\n",
      "epoch 10; iter: 0; batch classifier loss: 0.580124; batch adversarial loss: 0.559010\n",
      "epoch 11; iter: 0; batch classifier loss: 0.485738; batch adversarial loss: 0.577029\n",
      "epoch 12; iter: 0; batch classifier loss: 0.545939; batch adversarial loss: 0.609840\n",
      "epoch 13; iter: 0; batch classifier loss: 0.535575; batch adversarial loss: 0.530423\n",
      "epoch 14; iter: 0; batch classifier loss: 0.476443; batch adversarial loss: 0.593521\n",
      "epoch 15; iter: 0; batch classifier loss: 0.538824; batch adversarial loss: 0.548877\n",
      "epoch 16; iter: 0; batch classifier loss: 0.444706; batch adversarial loss: 0.585626\n",
      "epoch 17; iter: 0; batch classifier loss: 0.543938; batch adversarial loss: 0.583539\n",
      "epoch 18; iter: 0; batch classifier loss: 0.479823; batch adversarial loss: 0.578268\n",
      "epoch 19; iter: 0; batch classifier loss: 0.514278; batch adversarial loss: 0.556866\n",
      "epoch 20; iter: 0; batch classifier loss: 0.502252; batch adversarial loss: 0.592063\n",
      "epoch 21; iter: 0; batch classifier loss: 0.516789; batch adversarial loss: 0.612033\n",
      "epoch 22; iter: 0; batch classifier loss: 0.543013; batch adversarial loss: 0.627143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 23; iter: 0; batch classifier loss: 0.505705; batch adversarial loss: 0.508017\n",
      "epoch 24; iter: 0; batch classifier loss: 0.508381; batch adversarial loss: 0.540744\n",
      "epoch 25; iter: 0; batch classifier loss: 0.458019; batch adversarial loss: 0.550486\n",
      "epoch 26; iter: 0; batch classifier loss: 0.506026; batch adversarial loss: 0.492483\n",
      "epoch 27; iter: 0; batch classifier loss: 0.445298; batch adversarial loss: 0.586788\n",
      "epoch 28; iter: 0; batch classifier loss: 0.465978; batch adversarial loss: 0.602168\n",
      "epoch 29; iter: 0; batch classifier loss: 0.460841; batch adversarial loss: 0.626023\n",
      "epoch 30; iter: 0; batch classifier loss: 0.480267; batch adversarial loss: 0.604310\n",
      "epoch 31; iter: 0; batch classifier loss: 0.505033; batch adversarial loss: 0.556649\n",
      "epoch 32; iter: 0; batch classifier loss: 0.494647; batch adversarial loss: 0.565801\n",
      "epoch 33; iter: 0; batch classifier loss: 0.430051; batch adversarial loss: 0.559500\n",
      "epoch 34; iter: 0; batch classifier loss: 0.429593; batch adversarial loss: 0.630557\n",
      "epoch 35; iter: 0; batch classifier loss: 0.507677; batch adversarial loss: 0.540330\n",
      "epoch 36; iter: 0; batch classifier loss: 0.451250; batch adversarial loss: 0.622558\n",
      "epoch 37; iter: 0; batch classifier loss: 0.442271; batch adversarial loss: 0.571577\n",
      "epoch 38; iter: 0; batch classifier loss: 0.402187; batch adversarial loss: 0.487059\n",
      "epoch 39; iter: 0; batch classifier loss: 0.456167; batch adversarial loss: 0.596275\n",
      "epoch 40; iter: 0; batch classifier loss: 0.441593; batch adversarial loss: 0.570167\n",
      "epoch 41; iter: 0; batch classifier loss: 0.447192; batch adversarial loss: 0.570293\n",
      "epoch 42; iter: 0; batch classifier loss: 0.428102; batch adversarial loss: 0.537242\n",
      "epoch 43; iter: 0; batch classifier loss: 0.414231; batch adversarial loss: 0.571045\n",
      "epoch 44; iter: 0; batch classifier loss: 0.446337; batch adversarial loss: 0.484447\n",
      "epoch 45; iter: 0; batch classifier loss: 0.414020; batch adversarial loss: 0.597704\n",
      "epoch 46; iter: 0; batch classifier loss: 0.425508; batch adversarial loss: 0.554172\n",
      "epoch 47; iter: 0; batch classifier loss: 0.420375; batch adversarial loss: 0.465407\n",
      "epoch 48; iter: 0; batch classifier loss: 0.417597; batch adversarial loss: 0.525201\n",
      "epoch 49; iter: 0; batch classifier loss: 0.432427; batch adversarial loss: 0.555871\n",
      "epoch 50; iter: 0; batch classifier loss: 0.408756; batch adversarial loss: 0.580116\n",
      "epoch 51; iter: 0; batch classifier loss: 0.450106; batch adversarial loss: 0.536723\n",
      "epoch 52; iter: 0; batch classifier loss: 0.451146; batch adversarial loss: 0.545047\n",
      "epoch 53; iter: 0; batch classifier loss: 0.488796; batch adversarial loss: 0.477497\n",
      "epoch 54; iter: 0; batch classifier loss: 0.436804; batch adversarial loss: 0.544981\n",
      "epoch 55; iter: 0; batch classifier loss: 0.579816; batch adversarial loss: 0.527538\n",
      "epoch 56; iter: 0; batch classifier loss: 0.498334; batch adversarial loss: 0.519118\n",
      "epoch 57; iter: 0; batch classifier loss: 0.456847; batch adversarial loss: 0.511734\n",
      "epoch 58; iter: 0; batch classifier loss: 0.434237; batch adversarial loss: 0.551539\n",
      "epoch 59; iter: 0; batch classifier loss: 0.377860; batch adversarial loss: 0.598748\n",
      "epoch 60; iter: 0; batch classifier loss: 0.415868; batch adversarial loss: 0.597987\n",
      "epoch 61; iter: 0; batch classifier loss: 0.349634; batch adversarial loss: 0.592711\n",
      "epoch 62; iter: 0; batch classifier loss: 0.441401; batch adversarial loss: 0.581294\n",
      "epoch 63; iter: 0; batch classifier loss: 0.365631; batch adversarial loss: 0.575737\n",
      "epoch 64; iter: 0; batch classifier loss: 0.430227; batch adversarial loss: 0.570167\n",
      "epoch 65; iter: 0; batch classifier loss: 0.437106; batch adversarial loss: 0.586478\n",
      "epoch 66; iter: 0; batch classifier loss: 0.437561; batch adversarial loss: 0.582590\n",
      "epoch 67; iter: 0; batch classifier loss: 0.444376; batch adversarial loss: 0.598266\n",
      "epoch 68; iter: 0; batch classifier loss: 0.437803; batch adversarial loss: 0.542795\n",
      "epoch 69; iter: 0; batch classifier loss: 0.394682; batch adversarial loss: 0.591356\n",
      "epoch 70; iter: 0; batch classifier loss: 0.409422; batch adversarial loss: 0.589967\n",
      "epoch 71; iter: 0; batch classifier loss: 0.416110; batch adversarial loss: 0.554388\n",
      "epoch 72; iter: 0; batch classifier loss: 0.500276; batch adversarial loss: 0.572319\n",
      "epoch 73; iter: 0; batch classifier loss: 0.474448; batch adversarial loss: 0.598392\n",
      "epoch 74; iter: 0; batch classifier loss: 0.423627; batch adversarial loss: 0.535941\n",
      "epoch 75; iter: 0; batch classifier loss: 0.389479; batch adversarial loss: 0.572329\n",
      "epoch 76; iter: 0; batch classifier loss: 0.418026; batch adversarial loss: 0.571484\n",
      "epoch 77; iter: 0; batch classifier loss: 0.431113; batch adversarial loss: 0.535429\n",
      "epoch 78; iter: 0; batch classifier loss: 0.396280; batch adversarial loss: 0.440437\n",
      "epoch 79; iter: 0; batch classifier loss: 0.416075; batch adversarial loss: 0.526621\n",
      "epoch 80; iter: 0; batch classifier loss: 0.435497; batch adversarial loss: 0.527989\n",
      "epoch 81; iter: 0; batch classifier loss: 0.402402; batch adversarial loss: 0.587519\n",
      "epoch 82; iter: 0; batch classifier loss: 0.446617; batch adversarial loss: 0.544262\n",
      "epoch 83; iter: 0; batch classifier loss: 0.396266; batch adversarial loss: 0.651547\n",
      "epoch 84; iter: 0; batch classifier loss: 0.418306; batch adversarial loss: 0.560361\n",
      "epoch 85; iter: 0; batch classifier loss: 0.366849; batch adversarial loss: 0.545120\n",
      "epoch 86; iter: 0; batch classifier loss: 0.364559; batch adversarial loss: 0.598276\n",
      "epoch 87; iter: 0; batch classifier loss: 0.341631; batch adversarial loss: 0.554694\n",
      "epoch 88; iter: 0; batch classifier loss: 0.395412; batch adversarial loss: 0.624919\n",
      "epoch 89; iter: 0; batch classifier loss: 0.364735; batch adversarial loss: 0.560405\n",
      "epoch 90; iter: 0; batch classifier loss: 0.330749; batch adversarial loss: 0.580484\n",
      "epoch 91; iter: 0; batch classifier loss: 0.414438; batch adversarial loss: 0.543233\n",
      "epoch 92; iter: 0; batch classifier loss: 0.496268; batch adversarial loss: 0.493375\n",
      "epoch 93; iter: 0; batch classifier loss: 0.420824; batch adversarial loss: 0.554754\n",
      "epoch 94; iter: 0; batch classifier loss: 0.416060; batch adversarial loss: 0.614376\n",
      "epoch 95; iter: 0; batch classifier loss: 0.398388; batch adversarial loss: 0.632203\n",
      "epoch 96; iter: 0; batch classifier loss: 0.340481; batch adversarial loss: 0.564292\n",
      "epoch 97; iter: 0; batch classifier loss: 0.401915; batch adversarial loss: 0.572520\n",
      "epoch 98; iter: 0; batch classifier loss: 0.439576; batch adversarial loss: 0.573328\n",
      "epoch 99; iter: 0; batch classifier loss: 0.452180; batch adversarial loss: 0.677525\n",
      "epoch 100; iter: 0; batch classifier loss: 0.373561; batch adversarial loss: 0.589927\n",
      "epoch 101; iter: 0; batch classifier loss: 0.473694; batch adversarial loss: 0.579789\n",
      "epoch 102; iter: 0; batch classifier loss: 0.412999; batch adversarial loss: 0.526377\n",
      "epoch 103; iter: 0; batch classifier loss: 0.426918; batch adversarial loss: 0.491176\n",
      "epoch 104; iter: 0; batch classifier loss: 0.386478; batch adversarial loss: 0.535219\n",
      "epoch 105; iter: 0; batch classifier loss: 0.423380; batch adversarial loss: 0.519842\n",
      "epoch 106; iter: 0; batch classifier loss: 0.420696; batch adversarial loss: 0.613754\n",
      "epoch 107; iter: 0; batch classifier loss: 0.343622; batch adversarial loss: 0.562616\n",
      "epoch 108; iter: 0; batch classifier loss: 0.462850; batch adversarial loss: 0.535422\n",
      "epoch 109; iter: 0; batch classifier loss: 0.452459; batch adversarial loss: 0.581351\n",
      "epoch 110; iter: 0; batch classifier loss: 0.443220; batch adversarial loss: 0.554088\n",
      "epoch 111; iter: 0; batch classifier loss: 0.391749; batch adversarial loss: 0.518426\n",
      "epoch 112; iter: 0; batch classifier loss: 0.338286; batch adversarial loss: 0.518810\n",
      "epoch 113; iter: 0; batch classifier loss: 0.397318; batch adversarial loss: 0.553457\n",
      "epoch 114; iter: 0; batch classifier loss: 0.366691; batch adversarial loss: 0.605150\n",
      "epoch 115; iter: 0; batch classifier loss: 0.332353; batch adversarial loss: 0.587429\n",
      "epoch 116; iter: 0; batch classifier loss: 0.442137; batch adversarial loss: 0.561389\n",
      "epoch 117; iter: 0; batch classifier loss: 0.482892; batch adversarial loss: 0.542000\n",
      "epoch 118; iter: 0; batch classifier loss: 0.325788; batch adversarial loss: 0.649180\n",
      "epoch 119; iter: 0; batch classifier loss: 0.389581; batch adversarial loss: 0.474083\n",
      "epoch 120; iter: 0; batch classifier loss: 0.474770; batch adversarial loss: 0.510848\n",
      "epoch 121; iter: 0; batch classifier loss: 0.389621; batch adversarial loss: 0.562391\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 122; iter: 0; batch classifier loss: 0.362932; batch adversarial loss: 0.553757\n",
      "epoch 123; iter: 0; batch classifier loss: 0.436768; batch adversarial loss: 0.607471\n",
      "epoch 124; iter: 0; batch classifier loss: 0.375873; batch adversarial loss: 0.624428\n",
      "epoch 125; iter: 0; batch classifier loss: 0.366223; batch adversarial loss: 0.562394\n",
      "epoch 126; iter: 0; batch classifier loss: 0.435282; batch adversarial loss: 0.632092\n",
      "epoch 127; iter: 0; batch classifier loss: 0.349612; batch adversarial loss: 0.509612\n",
      "epoch 128; iter: 0; batch classifier loss: 0.387436; batch adversarial loss: 0.465432\n",
      "epoch 129; iter: 0; batch classifier loss: 0.408679; batch adversarial loss: 0.570706\n",
      "epoch 130; iter: 0; batch classifier loss: 0.385521; batch adversarial loss: 0.482936\n",
      "epoch 131; iter: 0; batch classifier loss: 0.421161; batch adversarial loss: 0.535230\n",
      "epoch 132; iter: 0; batch classifier loss: 0.365245; batch adversarial loss: 0.578775\n",
      "epoch 133; iter: 0; batch classifier loss: 0.371927; batch adversarial loss: 0.553313\n",
      "epoch 134; iter: 0; batch classifier loss: 0.309599; batch adversarial loss: 0.562370\n",
      "epoch 135; iter: 0; batch classifier loss: 0.407297; batch adversarial loss: 0.545319\n",
      "epoch 136; iter: 0; batch classifier loss: 0.417383; batch adversarial loss: 0.606296\n",
      "epoch 137; iter: 0; batch classifier loss: 0.398586; batch adversarial loss: 0.526692\n",
      "epoch 138; iter: 0; batch classifier loss: 0.317298; batch adversarial loss: 0.668001\n",
      "epoch 139; iter: 0; batch classifier loss: 0.340976; batch adversarial loss: 0.563534\n",
      "epoch 140; iter: 0; batch classifier loss: 0.387365; batch adversarial loss: 0.570057\n",
      "epoch 141; iter: 0; batch classifier loss: 0.340336; batch adversarial loss: 0.579337\n",
      "epoch 142; iter: 0; batch classifier loss: 0.333911; batch adversarial loss: 0.502529\n",
      "epoch 143; iter: 0; batch classifier loss: 0.328295; batch adversarial loss: 0.589456\n",
      "epoch 144; iter: 0; batch classifier loss: 0.350329; batch adversarial loss: 0.552539\n",
      "epoch 145; iter: 0; batch classifier loss: 0.372383; batch adversarial loss: 0.545309\n",
      "epoch 146; iter: 0; batch classifier loss: 0.332269; batch adversarial loss: 0.543711\n",
      "epoch 147; iter: 0; batch classifier loss: 0.327603; batch adversarial loss: 0.510854\n",
      "epoch 148; iter: 0; batch classifier loss: 0.376995; batch adversarial loss: 0.562264\n",
      "epoch 149; iter: 0; batch classifier loss: 0.403957; batch adversarial loss: 0.483194\n",
      "epoch 150; iter: 0; batch classifier loss: 0.351089; batch adversarial loss: 0.561881\n",
      "epoch 151; iter: 0; batch classifier loss: 0.399001; batch adversarial loss: 0.534575\n",
      "epoch 152; iter: 0; batch classifier loss: 0.416760; batch adversarial loss: 0.597724\n",
      "epoch 153; iter: 0; batch classifier loss: 0.391081; batch adversarial loss: 0.536092\n",
      "epoch 154; iter: 0; batch classifier loss: 0.448388; batch adversarial loss: 0.536602\n",
      "epoch 155; iter: 0; batch classifier loss: 0.391661; batch adversarial loss: 0.563197\n",
      "epoch 156; iter: 0; batch classifier loss: 0.351510; batch adversarial loss: 0.544503\n",
      "epoch 157; iter: 0; batch classifier loss: 0.435210; batch adversarial loss: 0.579774\n",
      "epoch 158; iter: 0; batch classifier loss: 0.367334; batch adversarial loss: 0.562492\n",
      "epoch 159; iter: 0; batch classifier loss: 0.361450; batch adversarial loss: 0.509630\n",
      "epoch 160; iter: 0; batch classifier loss: 0.428526; batch adversarial loss: 0.544337\n",
      "epoch 161; iter: 0; batch classifier loss: 0.404972; batch adversarial loss: 0.597747\n",
      "epoch 162; iter: 0; batch classifier loss: 0.349739; batch adversarial loss: 0.606208\n",
      "epoch 163; iter: 0; batch classifier loss: 0.385789; batch adversarial loss: 0.570779\n",
      "epoch 164; iter: 0; batch classifier loss: 0.291599; batch adversarial loss: 0.526727\n",
      "epoch 165; iter: 0; batch classifier loss: 0.418982; batch adversarial loss: 0.597554\n",
      "epoch 166; iter: 0; batch classifier loss: 0.347205; batch adversarial loss: 0.562657\n",
      "epoch 167; iter: 0; batch classifier loss: 0.366152; batch adversarial loss: 0.579541\n",
      "epoch 168; iter: 0; batch classifier loss: 0.371798; batch adversarial loss: 0.579569\n",
      "epoch 169; iter: 0; batch classifier loss: 0.431384; batch adversarial loss: 0.553514\n",
      "epoch 170; iter: 0; batch classifier loss: 0.345505; batch adversarial loss: 0.553788\n",
      "epoch 171; iter: 0; batch classifier loss: 0.380056; batch adversarial loss: 0.588752\n",
      "epoch 172; iter: 0; batch classifier loss: 0.476648; batch adversarial loss: 0.535892\n",
      "epoch 173; iter: 0; batch classifier loss: 0.296349; batch adversarial loss: 0.492034\n",
      "epoch 174; iter: 0; batch classifier loss: 0.333820; batch adversarial loss: 0.518680\n",
      "epoch 175; iter: 0; batch classifier loss: 0.400811; batch adversarial loss: 0.536312\n",
      "epoch 176; iter: 0; batch classifier loss: 0.428117; batch adversarial loss: 0.536308\n",
      "epoch 177; iter: 0; batch classifier loss: 0.392818; batch adversarial loss: 0.510131\n",
      "epoch 178; iter: 0; batch classifier loss: 0.338432; batch adversarial loss: 0.509925\n",
      "epoch 179; iter: 0; batch classifier loss: 0.378210; batch adversarial loss: 0.632461\n",
      "epoch 180; iter: 0; batch classifier loss: 0.372640; batch adversarial loss: 0.571089\n",
      "epoch 181; iter: 0; batch classifier loss: 0.414708; batch adversarial loss: 0.571135\n",
      "epoch 182; iter: 0; batch classifier loss: 0.352418; batch adversarial loss: 0.570869\n",
      "epoch 183; iter: 0; batch classifier loss: 0.393736; batch adversarial loss: 0.588474\n",
      "epoch 184; iter: 0; batch classifier loss: 0.408911; batch adversarial loss: 0.518680\n",
      "epoch 185; iter: 0; batch classifier loss: 0.390822; batch adversarial loss: 0.500963\n",
      "epoch 186; iter: 0; batch classifier loss: 0.413560; batch adversarial loss: 0.553590\n",
      "epoch 187; iter: 0; batch classifier loss: 0.372897; batch adversarial loss: 0.562632\n",
      "epoch 188; iter: 0; batch classifier loss: 0.275343; batch adversarial loss: 0.562227\n",
      "epoch 189; iter: 0; batch classifier loss: 0.315181; batch adversarial loss: 0.553463\n",
      "epoch 190; iter: 0; batch classifier loss: 0.390250; batch adversarial loss: 0.571603\n",
      "epoch 191; iter: 0; batch classifier loss: 0.336732; batch adversarial loss: 0.588380\n",
      "epoch 192; iter: 0; batch classifier loss: 0.427416; batch adversarial loss: 0.492402\n",
      "epoch 193; iter: 0; batch classifier loss: 0.349269; batch adversarial loss: 0.510282\n",
      "epoch 194; iter: 0; batch classifier loss: 0.366310; batch adversarial loss: 0.579982\n",
      "epoch 195; iter: 0; batch classifier loss: 0.343006; batch adversarial loss: 0.527790\n",
      "epoch 196; iter: 0; batch classifier loss: 0.339201; batch adversarial loss: 0.544861\n",
      "epoch 197; iter: 0; batch classifier loss: 0.426594; batch adversarial loss: 0.483750\n",
      "epoch 198; iter: 0; batch classifier loss: 0.368460; batch adversarial loss: 0.640888\n",
      "epoch 199; iter: 0; batch classifier loss: 0.371753; batch adversarial loss: 0.570978\n",
      "epoch 0; iter: 0; batch classifier loss: 0.642496; batch adversarial loss: 0.698397\n",
      "epoch 1; iter: 0; batch classifier loss: 0.599889; batch adversarial loss: 0.667886\n",
      "epoch 2; iter: 0; batch classifier loss: 0.580080; batch adversarial loss: 0.653229\n",
      "epoch 3; iter: 0; batch classifier loss: 0.602490; batch adversarial loss: 0.631704\n",
      "epoch 4; iter: 0; batch classifier loss: 0.520576; batch adversarial loss: 0.634722\n",
      "epoch 5; iter: 0; batch classifier loss: 0.594321; batch adversarial loss: 0.622236\n",
      "epoch 6; iter: 0; batch classifier loss: 0.573963; batch adversarial loss: 0.641031\n",
      "epoch 7; iter: 0; batch classifier loss: 0.614220; batch adversarial loss: 0.628971\n",
      "epoch 8; iter: 0; batch classifier loss: 0.555532; batch adversarial loss: 0.551098\n",
      "epoch 9; iter: 0; batch classifier loss: 0.476059; batch adversarial loss: 0.577013\n",
      "epoch 10; iter: 0; batch classifier loss: 0.635204; batch adversarial loss: 0.601000\n",
      "epoch 11; iter: 0; batch classifier loss: 0.595494; batch adversarial loss: 0.583421\n",
      "epoch 12; iter: 0; batch classifier loss: 0.530019; batch adversarial loss: 0.575481\n",
      "epoch 13; iter: 0; batch classifier loss: 0.497717; batch adversarial loss: 0.520175\n",
      "epoch 14; iter: 0; batch classifier loss: 0.576929; batch adversarial loss: 0.535243\n",
      "epoch 15; iter: 0; batch classifier loss: 0.428953; batch adversarial loss: 0.557281\n",
      "epoch 16; iter: 0; batch classifier loss: 0.480566; batch adversarial loss: 0.588288\n",
      "epoch 17; iter: 0; batch classifier loss: 0.540826; batch adversarial loss: 0.615887\n",
      "epoch 18; iter: 0; batch classifier loss: 0.499129; batch adversarial loss: 0.550003\n",
      "epoch 19; iter: 0; batch classifier loss: 0.510567; batch adversarial loss: 0.546569\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20; iter: 0; batch classifier loss: 0.505261; batch adversarial loss: 0.569570\n",
      "epoch 21; iter: 0; batch classifier loss: 0.436515; batch adversarial loss: 0.591976\n",
      "epoch 22; iter: 0; batch classifier loss: 0.473456; batch adversarial loss: 0.596524\n",
      "epoch 23; iter: 0; batch classifier loss: 0.488506; batch adversarial loss: 0.583424\n",
      "epoch 24; iter: 0; batch classifier loss: 0.488501; batch adversarial loss: 0.537449\n",
      "epoch 25; iter: 0; batch classifier loss: 0.461645; batch adversarial loss: 0.580772\n",
      "epoch 26; iter: 0; batch classifier loss: 0.450445; batch adversarial loss: 0.604105\n",
      "epoch 27; iter: 0; batch classifier loss: 0.416412; batch adversarial loss: 0.560765\n",
      "epoch 28; iter: 0; batch classifier loss: 0.407926; batch adversarial loss: 0.525901\n",
      "epoch 29; iter: 0; batch classifier loss: 0.455663; batch adversarial loss: 0.565716\n",
      "epoch 30; iter: 0; batch classifier loss: 0.452090; batch adversarial loss: 0.609919\n",
      "epoch 31; iter: 0; batch classifier loss: 0.478841; batch adversarial loss: 0.573585\n",
      "epoch 32; iter: 0; batch classifier loss: 0.455204; batch adversarial loss: 0.521949\n",
      "epoch 33; iter: 0; batch classifier loss: 0.391307; batch adversarial loss: 0.573617\n",
      "epoch 34; iter: 0; batch classifier loss: 0.436513; batch adversarial loss: 0.514387\n",
      "epoch 35; iter: 0; batch classifier loss: 0.420016; batch adversarial loss: 0.529843\n",
      "epoch 36; iter: 0; batch classifier loss: 0.422112; batch adversarial loss: 0.573158\n",
      "epoch 37; iter: 0; batch classifier loss: 0.473219; batch adversarial loss: 0.553142\n",
      "epoch 38; iter: 0; batch classifier loss: 0.367626; batch adversarial loss: 0.643394\n",
      "epoch 39; iter: 0; batch classifier loss: 0.417289; batch adversarial loss: 0.595044\n",
      "epoch 40; iter: 0; batch classifier loss: 0.419363; batch adversarial loss: 0.556868\n",
      "epoch 41; iter: 0; batch classifier loss: 0.388123; batch adversarial loss: 0.554747\n",
      "epoch 42; iter: 0; batch classifier loss: 0.462878; batch adversarial loss: 0.608312\n",
      "epoch 43; iter: 0; batch classifier loss: 0.420465; batch adversarial loss: 0.564047\n",
      "epoch 44; iter: 0; batch classifier loss: 0.420636; batch adversarial loss: 0.529007\n",
      "epoch 45; iter: 0; batch classifier loss: 0.482989; batch adversarial loss: 0.598266\n",
      "epoch 46; iter: 0; batch classifier loss: 0.426505; batch adversarial loss: 0.562270\n",
      "epoch 47; iter: 0; batch classifier loss: 0.438750; batch adversarial loss: 0.580150\n",
      "epoch 48; iter: 0; batch classifier loss: 0.475745; batch adversarial loss: 0.571138\n",
      "epoch 49; iter: 0; batch classifier loss: 0.465016; batch adversarial loss: 0.588987\n",
      "epoch 50; iter: 0; batch classifier loss: 0.378960; batch adversarial loss: 0.553682\n",
      "epoch 51; iter: 0; batch classifier loss: 0.407622; batch adversarial loss: 0.597849\n",
      "epoch 52; iter: 0; batch classifier loss: 0.431176; batch adversarial loss: 0.535999\n",
      "epoch 53; iter: 0; batch classifier loss: 0.449306; batch adversarial loss: 0.499883\n",
      "epoch 54; iter: 0; batch classifier loss: 0.448921; batch adversarial loss: 0.517996\n",
      "epoch 55; iter: 0; batch classifier loss: 0.382696; batch adversarial loss: 0.500259\n",
      "epoch 56; iter: 0; batch classifier loss: 0.441058; batch adversarial loss: 0.598205\n",
      "epoch 57; iter: 0; batch classifier loss: 0.361689; batch adversarial loss: 0.536091\n",
      "epoch 58; iter: 0; batch classifier loss: 0.379656; batch adversarial loss: 0.571109\n",
      "epoch 59; iter: 0; batch classifier loss: 0.402570; batch adversarial loss: 0.553278\n",
      "epoch 60; iter: 0; batch classifier loss: 0.414688; batch adversarial loss: 0.571280\n",
      "epoch 61; iter: 0; batch classifier loss: 0.404768; batch adversarial loss: 0.643598\n",
      "epoch 62; iter: 0; batch classifier loss: 0.433284; batch adversarial loss: 0.517709\n",
      "epoch 63; iter: 0; batch classifier loss: 0.320015; batch adversarial loss: 0.588639\n",
      "epoch 64; iter: 0; batch classifier loss: 0.463179; batch adversarial loss: 0.544685\n",
      "epoch 65; iter: 0; batch classifier loss: 0.349084; batch adversarial loss: 0.688569\n",
      "epoch 66; iter: 0; batch classifier loss: 0.448845; batch adversarial loss: 0.536065\n",
      "epoch 67; iter: 0; batch classifier loss: 0.421572; batch adversarial loss: 0.481711\n",
      "epoch 68; iter: 0; batch classifier loss: 0.378235; batch adversarial loss: 0.508693\n",
      "epoch 69; iter: 0; batch classifier loss: 0.353041; batch adversarial loss: 0.472966\n",
      "epoch 70; iter: 0; batch classifier loss: 0.282258; batch adversarial loss: 0.580257\n",
      "epoch 71; iter: 0; batch classifier loss: 0.417370; batch adversarial loss: 0.588283\n",
      "epoch 72; iter: 0; batch classifier loss: 0.361701; batch adversarial loss: 0.535910\n",
      "epoch 73; iter: 0; batch classifier loss: 0.417641; batch adversarial loss: 0.535369\n",
      "epoch 74; iter: 0; batch classifier loss: 0.478142; batch adversarial loss: 0.544853\n",
      "epoch 75; iter: 0; batch classifier loss: 0.354420; batch adversarial loss: 0.518673\n",
      "epoch 76; iter: 0; batch classifier loss: 0.362399; batch adversarial loss: 0.553901\n",
      "epoch 77; iter: 0; batch classifier loss: 0.338481; batch adversarial loss: 0.517658\n",
      "epoch 78; iter: 0; batch classifier loss: 0.431928; batch adversarial loss: 0.527363\n",
      "epoch 79; iter: 0; batch classifier loss: 0.403863; batch adversarial loss: 0.553406\n",
      "epoch 80; iter: 0; batch classifier loss: 0.342632; batch adversarial loss: 0.571992\n",
      "epoch 81; iter: 0; batch classifier loss: 0.508989; batch adversarial loss: 0.544130\n",
      "epoch 82; iter: 0; batch classifier loss: 0.331052; batch adversarial loss: 0.500976\n",
      "epoch 83; iter: 0; batch classifier loss: 0.444142; batch adversarial loss: 0.554326\n",
      "epoch 84; iter: 0; batch classifier loss: 0.436696; batch adversarial loss: 0.625743\n",
      "epoch 85; iter: 0; batch classifier loss: 0.419008; batch adversarial loss: 0.598009\n",
      "epoch 86; iter: 0; batch classifier loss: 0.299633; batch adversarial loss: 0.598038\n",
      "epoch 87; iter: 0; batch classifier loss: 0.433522; batch adversarial loss: 0.517753\n",
      "epoch 88; iter: 0; batch classifier loss: 0.385472; batch adversarial loss: 0.535491\n",
      "epoch 89; iter: 0; batch classifier loss: 0.412669; batch adversarial loss: 0.589610\n",
      "epoch 90; iter: 0; batch classifier loss: 0.371943; batch adversarial loss: 0.624887\n",
      "epoch 91; iter: 0; batch classifier loss: 0.348216; batch adversarial loss: 0.499449\n",
      "epoch 92; iter: 0; batch classifier loss: 0.410177; batch adversarial loss: 0.534894\n",
      "epoch 93; iter: 0; batch classifier loss: 0.386738; batch adversarial loss: 0.508925\n",
      "epoch 94; iter: 0; batch classifier loss: 0.356150; batch adversarial loss: 0.562198\n",
      "epoch 95; iter: 0; batch classifier loss: 0.322303; batch adversarial loss: 0.599062\n",
      "epoch 96; iter: 0; batch classifier loss: 0.386689; batch adversarial loss: 0.491162\n",
      "epoch 97; iter: 0; batch classifier loss: 0.363346; batch adversarial loss: 0.571365\n",
      "epoch 98; iter: 0; batch classifier loss: 0.351305; batch adversarial loss: 0.553986\n",
      "epoch 99; iter: 0; batch classifier loss: 0.358015; batch adversarial loss: 0.598440\n",
      "epoch 100; iter: 0; batch classifier loss: 0.378714; batch adversarial loss: 0.545249\n",
      "epoch 101; iter: 0; batch classifier loss: 0.394269; batch adversarial loss: 0.653358\n",
      "epoch 102; iter: 0; batch classifier loss: 0.377645; batch adversarial loss: 0.473280\n",
      "epoch 103; iter: 0; batch classifier loss: 0.443116; batch adversarial loss: 0.500119\n",
      "epoch 104; iter: 0; batch classifier loss: 0.354223; batch adversarial loss: 0.536075\n",
      "epoch 105; iter: 0; batch classifier loss: 0.364973; batch adversarial loss: 0.607581\n",
      "epoch 106; iter: 0; batch classifier loss: 0.419799; batch adversarial loss: 0.606669\n",
      "epoch 107; iter: 0; batch classifier loss: 0.392262; batch adversarial loss: 0.526965\n",
      "epoch 108; iter: 0; batch classifier loss: 0.368720; batch adversarial loss: 0.509169\n",
      "epoch 109; iter: 0; batch classifier loss: 0.364246; batch adversarial loss: 0.518471\n",
      "epoch 110; iter: 0; batch classifier loss: 0.403165; batch adversarial loss: 0.553891\n",
      "epoch 111; iter: 0; batch classifier loss: 0.367300; batch adversarial loss: 0.536304\n",
      "epoch 112; iter: 0; batch classifier loss: 0.363468; batch adversarial loss: 0.562602\n",
      "epoch 113; iter: 0; batch classifier loss: 0.385267; batch adversarial loss: 0.562512\n",
      "epoch 114; iter: 0; batch classifier loss: 0.294359; batch adversarial loss: 0.544341\n",
      "epoch 115; iter: 0; batch classifier loss: 0.435741; batch adversarial loss: 0.544827\n",
      "epoch 116; iter: 0; batch classifier loss: 0.368918; batch adversarial loss: 0.571969\n",
      "epoch 117; iter: 0; batch classifier loss: 0.375212; batch adversarial loss: 0.483196\n",
      "epoch 118; iter: 0; batch classifier loss: 0.370878; batch adversarial loss: 0.534368\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 119; iter: 0; batch classifier loss: 0.378826; batch adversarial loss: 0.534691\n",
      "epoch 120; iter: 0; batch classifier loss: 0.387343; batch adversarial loss: 0.535051\n",
      "epoch 121; iter: 0; batch classifier loss: 0.423943; batch adversarial loss: 0.508145\n",
      "epoch 122; iter: 0; batch classifier loss: 0.356529; batch adversarial loss: 0.553379\n",
      "epoch 123; iter: 0; batch classifier loss: 0.382964; batch adversarial loss: 0.545027\n",
      "epoch 124; iter: 0; batch classifier loss: 0.353617; batch adversarial loss: 0.624889\n",
      "epoch 125; iter: 0; batch classifier loss: 0.390429; batch adversarial loss: 0.490256\n",
      "epoch 126; iter: 0; batch classifier loss: 0.405088; batch adversarial loss: 0.526806\n",
      "epoch 127; iter: 0; batch classifier loss: 0.415635; batch adversarial loss: 0.580631\n",
      "epoch 128; iter: 0; batch classifier loss: 0.355533; batch adversarial loss: 0.492056\n",
      "epoch 129; iter: 0; batch classifier loss: 0.314668; batch adversarial loss: 0.561634\n",
      "epoch 130; iter: 0; batch classifier loss: 0.366455; batch adversarial loss: 0.481863\n",
      "epoch 131; iter: 0; batch classifier loss: 0.382603; batch adversarial loss: 0.517193\n",
      "epoch 132; iter: 0; batch classifier loss: 0.302406; batch adversarial loss: 0.581624\n",
      "epoch 133; iter: 0; batch classifier loss: 0.341324; batch adversarial loss: 0.490786\n",
      "epoch 134; iter: 0; batch classifier loss: 0.374711; batch adversarial loss: 0.526120\n",
      "epoch 135; iter: 0; batch classifier loss: 0.402521; batch adversarial loss: 0.553943\n",
      "epoch 136; iter: 0; batch classifier loss: 0.357126; batch adversarial loss: 0.545386\n",
      "epoch 137; iter: 0; batch classifier loss: 0.444363; batch adversarial loss: 0.527524\n",
      "epoch 138; iter: 0; batch classifier loss: 0.437389; batch adversarial loss: 0.526565\n",
      "epoch 139; iter: 0; batch classifier loss: 0.403543; batch adversarial loss: 0.572072\n",
      "epoch 140; iter: 0; batch classifier loss: 0.325808; batch adversarial loss: 0.536427\n",
      "epoch 141; iter: 0; batch classifier loss: 0.376264; batch adversarial loss: 0.499179\n",
      "epoch 142; iter: 0; batch classifier loss: 0.368994; batch adversarial loss: 0.580964\n",
      "epoch 143; iter: 0; batch classifier loss: 0.327765; batch adversarial loss: 0.616069\n",
      "epoch 144; iter: 0; batch classifier loss: 0.460711; batch adversarial loss: 0.500102\n",
      "epoch 145; iter: 0; batch classifier loss: 0.349324; batch adversarial loss: 0.543895\n",
      "epoch 146; iter: 0; batch classifier loss: 0.351163; batch adversarial loss: 0.500187\n",
      "epoch 147; iter: 0; batch classifier loss: 0.341442; batch adversarial loss: 0.508522\n",
      "epoch 148; iter: 0; batch classifier loss: 0.412700; batch adversarial loss: 0.518420\n",
      "epoch 149; iter: 0; batch classifier loss: 0.316369; batch adversarial loss: 0.599762\n",
      "epoch 150; iter: 0; batch classifier loss: 0.376398; batch adversarial loss: 0.543414\n",
      "epoch 151; iter: 0; batch classifier loss: 0.421077; batch adversarial loss: 0.553537\n",
      "epoch 152; iter: 0; batch classifier loss: 0.396176; batch adversarial loss: 0.526795\n",
      "epoch 153; iter: 0; batch classifier loss: 0.350571; batch adversarial loss: 0.526013\n",
      "epoch 154; iter: 0; batch classifier loss: 0.421165; batch adversarial loss: 0.697045\n",
      "epoch 155; iter: 0; batch classifier loss: 0.419063; batch adversarial loss: 0.518545\n",
      "epoch 156; iter: 0; batch classifier loss: 0.381270; batch adversarial loss: 0.500811\n",
      "epoch 157; iter: 0; batch classifier loss: 0.342232; batch adversarial loss: 0.525420\n",
      "epoch 158; iter: 0; batch classifier loss: 0.390261; batch adversarial loss: 0.507714\n",
      "epoch 159; iter: 0; batch classifier loss: 0.356913; batch adversarial loss: 0.490836\n",
      "epoch 160; iter: 0; batch classifier loss: 0.363499; batch adversarial loss: 0.517445\n",
      "epoch 161; iter: 0; batch classifier loss: 0.308515; batch adversarial loss: 0.543882\n",
      "epoch 162; iter: 0; batch classifier loss: 0.401515; batch adversarial loss: 0.535545\n",
      "epoch 163; iter: 0; batch classifier loss: 0.409397; batch adversarial loss: 0.590100\n",
      "epoch 164; iter: 0; batch classifier loss: 0.318767; batch adversarial loss: 0.608144\n",
      "epoch 165; iter: 0; batch classifier loss: 0.365474; batch adversarial loss: 0.481953\n",
      "epoch 166; iter: 0; batch classifier loss: 0.344717; batch adversarial loss: 0.561545\n",
      "epoch 167; iter: 0; batch classifier loss: 0.343557; batch adversarial loss: 0.580151\n",
      "epoch 168; iter: 0; batch classifier loss: 0.363311; batch adversarial loss: 0.535257\n",
      "epoch 169; iter: 0; batch classifier loss: 0.447103; batch adversarial loss: 0.481352\n",
      "epoch 170; iter: 0; batch classifier loss: 0.368973; batch adversarial loss: 0.553083\n",
      "epoch 171; iter: 0; batch classifier loss: 0.329597; batch adversarial loss: 0.555060\n",
      "epoch 172; iter: 0; batch classifier loss: 0.393057; batch adversarial loss: 0.607580\n",
      "epoch 173; iter: 0; batch classifier loss: 0.317839; batch adversarial loss: 0.509025\n",
      "epoch 174; iter: 0; batch classifier loss: 0.331016; batch adversarial loss: 0.536131\n",
      "epoch 175; iter: 0; batch classifier loss: 0.342007; batch adversarial loss: 0.644911\n",
      "epoch 176; iter: 0; batch classifier loss: 0.292733; batch adversarial loss: 0.581214\n",
      "epoch 177; iter: 0; batch classifier loss: 0.368415; batch adversarial loss: 0.508612\n",
      "epoch 178; iter: 0; batch classifier loss: 0.411684; batch adversarial loss: 0.517753\n",
      "epoch 179; iter: 0; batch classifier loss: 0.322260; batch adversarial loss: 0.572054\n",
      "epoch 180; iter: 0; batch classifier loss: 0.378583; batch adversarial loss: 0.580961\n",
      "epoch 181; iter: 0; batch classifier loss: 0.350318; batch adversarial loss: 0.571816\n",
      "epoch 182; iter: 0; batch classifier loss: 0.298262; batch adversarial loss: 0.581523\n",
      "epoch 183; iter: 0; batch classifier loss: 0.320875; batch adversarial loss: 0.581651\n",
      "epoch 184; iter: 0; batch classifier loss: 0.331917; batch adversarial loss: 0.535676\n",
      "epoch 185; iter: 0; batch classifier loss: 0.326398; batch adversarial loss: 0.580747\n",
      "epoch 186; iter: 0; batch classifier loss: 0.384616; batch adversarial loss: 0.517921\n",
      "epoch 187; iter: 0; batch classifier loss: 0.341385; batch adversarial loss: 0.562386\n",
      "epoch 188; iter: 0; batch classifier loss: 0.419028; batch adversarial loss: 0.498950\n",
      "epoch 189; iter: 0; batch classifier loss: 0.506090; batch adversarial loss: 0.609002\n",
      "epoch 190; iter: 0; batch classifier loss: 0.343350; batch adversarial loss: 0.535719\n",
      "epoch 191; iter: 0; batch classifier loss: 0.318385; batch adversarial loss: 0.553215\n",
      "epoch 192; iter: 0; batch classifier loss: 0.342054; batch adversarial loss: 0.580736\n",
      "epoch 193; iter: 0; batch classifier loss: 0.379260; batch adversarial loss: 0.606883\n",
      "epoch 194; iter: 0; batch classifier loss: 0.325859; batch adversarial loss: 0.508762\n",
      "epoch 195; iter: 0; batch classifier loss: 0.323337; batch adversarial loss: 0.598216\n",
      "epoch 196; iter: 0; batch classifier loss: 0.327735; batch adversarial loss: 0.597946\n",
      "epoch 197; iter: 0; batch classifier loss: 0.381772; batch adversarial loss: 0.464345\n",
      "epoch 198; iter: 0; batch classifier loss: 0.396992; batch adversarial loss: 0.570378\n",
      "epoch 199; iter: 0; batch classifier loss: 0.378739; batch adversarial loss: 0.508330\n",
      "epoch 0; iter: 0; batch classifier loss: 0.671227; batch adversarial loss: 0.714324\n",
      "epoch 1; iter: 0; batch classifier loss: 0.687570; batch adversarial loss: 0.692114\n",
      "epoch 2; iter: 0; batch classifier loss: 0.586322; batch adversarial loss: 0.656654\n",
      "epoch 3; iter: 0; batch classifier loss: 0.551908; batch adversarial loss: 0.644018\n",
      "epoch 4; iter: 0; batch classifier loss: 0.606928; batch adversarial loss: 0.647618\n",
      "epoch 5; iter: 0; batch classifier loss: 0.628457; batch adversarial loss: 0.613255\n",
      "epoch 6; iter: 0; batch classifier loss: 0.576941; batch adversarial loss: 0.629723\n",
      "epoch 7; iter: 0; batch classifier loss: 0.569762; batch adversarial loss: 0.610935\n",
      "epoch 8; iter: 0; batch classifier loss: 0.564239; batch adversarial loss: 0.581095\n",
      "epoch 9; iter: 0; batch classifier loss: 0.581758; batch adversarial loss: 0.567820\n",
      "epoch 10; iter: 0; batch classifier loss: 0.542363; batch adversarial loss: 0.576828\n",
      "epoch 11; iter: 0; batch classifier loss: 0.554441; batch adversarial loss: 0.604747\n",
      "epoch 12; iter: 0; batch classifier loss: 0.552950; batch adversarial loss: 0.512638\n",
      "epoch 13; iter: 0; batch classifier loss: 0.553385; batch adversarial loss: 0.617126\n",
      "epoch 14; iter: 0; batch classifier loss: 0.540386; batch adversarial loss: 0.566858\n",
      "epoch 15; iter: 0; batch classifier loss: 0.529267; batch adversarial loss: 0.559419\n",
      "epoch 16; iter: 0; batch classifier loss: 0.538302; batch adversarial loss: 0.574149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 17; iter: 0; batch classifier loss: 0.564545; batch adversarial loss: 0.608941\n",
      "epoch 18; iter: 0; batch classifier loss: 0.460566; batch adversarial loss: 0.599087\n",
      "epoch 19; iter: 0; batch classifier loss: 0.484288; batch adversarial loss: 0.585879\n",
      "epoch 20; iter: 0; batch classifier loss: 0.500249; batch adversarial loss: 0.490870\n",
      "epoch 21; iter: 0; batch classifier loss: 0.547402; batch adversarial loss: 0.556180\n",
      "epoch 22; iter: 0; batch classifier loss: 0.464070; batch adversarial loss: 0.512621\n",
      "epoch 23; iter: 0; batch classifier loss: 0.516625; batch adversarial loss: 0.632534\n",
      "epoch 24; iter: 0; batch classifier loss: 0.501819; batch adversarial loss: 0.535588\n",
      "epoch 25; iter: 0; batch classifier loss: 0.561582; batch adversarial loss: 0.541631\n",
      "epoch 26; iter: 0; batch classifier loss: 0.584852; batch adversarial loss: 0.600337\n",
      "epoch 27; iter: 0; batch classifier loss: 0.448138; batch adversarial loss: 0.533070\n",
      "epoch 28; iter: 0; batch classifier loss: 0.488360; batch adversarial loss: 0.525590\n",
      "epoch 29; iter: 0; batch classifier loss: 0.463370; batch adversarial loss: 0.570008\n",
      "epoch 30; iter: 0; batch classifier loss: 0.456271; batch adversarial loss: 0.596037\n",
      "epoch 31; iter: 0; batch classifier loss: 0.406577; batch adversarial loss: 0.588701\n",
      "epoch 32; iter: 0; batch classifier loss: 0.504303; batch adversarial loss: 0.547224\n",
      "epoch 33; iter: 0; batch classifier loss: 0.432125; batch adversarial loss: 0.578821\n",
      "epoch 34; iter: 0; batch classifier loss: 0.463527; batch adversarial loss: 0.494706\n",
      "epoch 35; iter: 0; batch classifier loss: 0.441755; batch adversarial loss: 0.493743\n",
      "epoch 36; iter: 0; batch classifier loss: 0.442570; batch adversarial loss: 0.554085\n",
      "epoch 37; iter: 0; batch classifier loss: 0.489363; batch adversarial loss: 0.661409\n",
      "epoch 38; iter: 0; batch classifier loss: 0.445606; batch adversarial loss: 0.546892\n",
      "epoch 39; iter: 0; batch classifier loss: 0.432423; batch adversarial loss: 0.535558\n",
      "epoch 40; iter: 0; batch classifier loss: 0.488572; batch adversarial loss: 0.563361\n",
      "epoch 41; iter: 0; batch classifier loss: 0.430936; batch adversarial loss: 0.555113\n",
      "epoch 42; iter: 0; batch classifier loss: 0.345404; batch adversarial loss: 0.632081\n",
      "epoch 43; iter: 0; batch classifier loss: 0.381832; batch adversarial loss: 0.589557\n",
      "epoch 44; iter: 0; batch classifier loss: 0.474886; batch adversarial loss: 0.597494\n",
      "epoch 45; iter: 0; batch classifier loss: 0.475240; batch adversarial loss: 0.581071\n",
      "epoch 46; iter: 0; batch classifier loss: 0.458166; batch adversarial loss: 0.501106\n",
      "epoch 47; iter: 0; batch classifier loss: 0.517106; batch adversarial loss: 0.528332\n",
      "epoch 48; iter: 0; batch classifier loss: 0.478199; batch adversarial loss: 0.492693\n",
      "epoch 49; iter: 0; batch classifier loss: 0.404470; batch adversarial loss: 0.536096\n",
      "epoch 50; iter: 0; batch classifier loss: 0.433095; batch adversarial loss: 0.553095\n",
      "epoch 51; iter: 0; batch classifier loss: 0.509913; batch adversarial loss: 0.536638\n",
      "epoch 52; iter: 0; batch classifier loss: 0.407552; batch adversarial loss: 0.617061\n",
      "epoch 53; iter: 0; batch classifier loss: 0.437355; batch adversarial loss: 0.580690\n",
      "epoch 54; iter: 0; batch classifier loss: 0.400815; batch adversarial loss: 0.642971\n",
      "epoch 55; iter: 0; batch classifier loss: 0.424108; batch adversarial loss: 0.479861\n",
      "epoch 56; iter: 0; batch classifier loss: 0.438312; batch adversarial loss: 0.508739\n",
      "epoch 57; iter: 0; batch classifier loss: 0.423392; batch adversarial loss: 0.588182\n",
      "epoch 58; iter: 0; batch classifier loss: 0.527777; batch adversarial loss: 0.570887\n",
      "epoch 59; iter: 0; batch classifier loss: 0.456093; batch adversarial loss: 0.492531\n",
      "epoch 60; iter: 0; batch classifier loss: 0.428604; batch adversarial loss: 0.527545\n",
      "epoch 61; iter: 0; batch classifier loss: 0.457749; batch adversarial loss: 0.578990\n",
      "epoch 62; iter: 0; batch classifier loss: 0.415498; batch adversarial loss: 0.518003\n",
      "epoch 63; iter: 0; batch classifier loss: 0.420057; batch adversarial loss: 0.471924\n",
      "epoch 64; iter: 0; batch classifier loss: 0.419051; batch adversarial loss: 0.571611\n",
      "epoch 65; iter: 0; batch classifier loss: 0.519727; batch adversarial loss: 0.598411\n",
      "epoch 66; iter: 0; batch classifier loss: 0.455325; batch adversarial loss: 0.561072\n",
      "epoch 67; iter: 0; batch classifier loss: 0.434308; batch adversarial loss: 0.608270\n",
      "epoch 68; iter: 0; batch classifier loss: 0.461979; batch adversarial loss: 0.488734\n",
      "epoch 69; iter: 0; batch classifier loss: 0.497310; batch adversarial loss: 0.596509\n",
      "epoch 70; iter: 0; batch classifier loss: 0.453694; batch adversarial loss: 0.481070\n",
      "epoch 71; iter: 0; batch classifier loss: 0.479133; batch adversarial loss: 0.518505\n",
      "epoch 72; iter: 0; batch classifier loss: 0.496914; batch adversarial loss: 0.471352\n",
      "epoch 73; iter: 0; batch classifier loss: 0.374158; batch adversarial loss: 0.604978\n",
      "epoch 74; iter: 0; batch classifier loss: 0.461350; batch adversarial loss: 0.540449\n",
      "epoch 75; iter: 0; batch classifier loss: 0.426190; batch adversarial loss: 0.518707\n",
      "epoch 76; iter: 0; batch classifier loss: 0.387163; batch adversarial loss: 0.592687\n",
      "epoch 77; iter: 0; batch classifier loss: 0.345846; batch adversarial loss: 0.533492\n",
      "epoch 78; iter: 0; batch classifier loss: 0.340922; batch adversarial loss: 0.616726\n",
      "epoch 79; iter: 0; batch classifier loss: 0.369814; batch adversarial loss: 0.571284\n",
      "epoch 80; iter: 0; batch classifier loss: 0.365986; batch adversarial loss: 0.572738\n",
      "epoch 81; iter: 0; batch classifier loss: 0.414308; batch adversarial loss: 0.588671\n",
      "epoch 82; iter: 0; batch classifier loss: 0.412238; batch adversarial loss: 0.473170\n",
      "epoch 83; iter: 0; batch classifier loss: 0.443111; batch adversarial loss: 0.613083\n",
      "epoch 84; iter: 0; batch classifier loss: 0.411138; batch adversarial loss: 0.588905\n",
      "epoch 85; iter: 0; batch classifier loss: 0.471903; batch adversarial loss: 0.509907\n",
      "epoch 86; iter: 0; batch classifier loss: 0.290665; batch adversarial loss: 0.547073\n",
      "epoch 87; iter: 0; batch classifier loss: 0.385892; batch adversarial loss: 0.553180\n",
      "epoch 88; iter: 0; batch classifier loss: 0.422452; batch adversarial loss: 0.526625\n",
      "epoch 89; iter: 0; batch classifier loss: 0.466048; batch adversarial loss: 0.544116\n",
      "epoch 90; iter: 0; batch classifier loss: 0.385711; batch adversarial loss: 0.516179\n",
      "epoch 91; iter: 0; batch classifier loss: 0.388038; batch adversarial loss: 0.536424\n",
      "epoch 92; iter: 0; batch classifier loss: 0.384209; batch adversarial loss: 0.545047\n",
      "epoch 93; iter: 0; batch classifier loss: 0.397567; batch adversarial loss: 0.619828\n",
      "epoch 94; iter: 0; batch classifier loss: 0.435861; batch adversarial loss: 0.534731\n",
      "epoch 95; iter: 0; batch classifier loss: 0.432386; batch adversarial loss: 0.580976\n",
      "epoch 96; iter: 0; batch classifier loss: 0.343735; batch adversarial loss: 0.618725\n",
      "epoch 97; iter: 0; batch classifier loss: 0.418404; batch adversarial loss: 0.516779\n",
      "epoch 98; iter: 0; batch classifier loss: 0.483382; batch adversarial loss: 0.481170\n",
      "epoch 99; iter: 0; batch classifier loss: 0.428092; batch adversarial loss: 0.590963\n",
      "epoch 100; iter: 0; batch classifier loss: 0.420916; batch adversarial loss: 0.526739\n",
      "epoch 101; iter: 0; batch classifier loss: 0.362638; batch adversarial loss: 0.591303\n",
      "epoch 102; iter: 0; batch classifier loss: 0.446147; batch adversarial loss: 0.513542\n",
      "epoch 103; iter: 0; batch classifier loss: 0.399394; batch adversarial loss: 0.509395\n",
      "epoch 104; iter: 0; batch classifier loss: 0.445349; batch adversarial loss: 0.518990\n",
      "epoch 105; iter: 0; batch classifier loss: 0.400398; batch adversarial loss: 0.544380\n",
      "epoch 106; iter: 0; batch classifier loss: 0.413870; batch adversarial loss: 0.498826\n",
      "epoch 107; iter: 0; batch classifier loss: 0.468180; batch adversarial loss: 0.554866\n",
      "epoch 108; iter: 0; batch classifier loss: 0.424443; batch adversarial loss: 0.515275\n",
      "epoch 109; iter: 0; batch classifier loss: 0.398358; batch adversarial loss: 0.471395\n",
      "epoch 110; iter: 0; batch classifier loss: 0.380098; batch adversarial loss: 0.591291\n",
      "epoch 111; iter: 0; batch classifier loss: 0.488442; batch adversarial loss: 0.628052\n",
      "epoch 112; iter: 0; batch classifier loss: 0.403401; batch adversarial loss: 0.620154\n",
      "epoch 113; iter: 0; batch classifier loss: 0.414230; batch adversarial loss: 0.547139\n",
      "epoch 114; iter: 0; batch classifier loss: 0.400454; batch adversarial loss: 0.597977\n",
      "epoch 115; iter: 0; batch classifier loss: 0.345729; batch adversarial loss: 0.508838\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 116; iter: 0; batch classifier loss: 0.294897; batch adversarial loss: 0.509306\n",
      "epoch 117; iter: 0; batch classifier loss: 0.418203; batch adversarial loss: 0.579228\n",
      "epoch 118; iter: 0; batch classifier loss: 0.409425; batch adversarial loss: 0.489366\n",
      "epoch 119; iter: 0; batch classifier loss: 0.409405; batch adversarial loss: 0.581074\n",
      "epoch 120; iter: 0; batch classifier loss: 0.361358; batch adversarial loss: 0.626902\n",
      "epoch 121; iter: 0; batch classifier loss: 0.414777; batch adversarial loss: 0.533587\n",
      "epoch 122; iter: 0; batch classifier loss: 0.365871; batch adversarial loss: 0.516669\n",
      "epoch 123; iter: 0; batch classifier loss: 0.430943; batch adversarial loss: 0.516356\n",
      "epoch 124; iter: 0; batch classifier loss: 0.364870; batch adversarial loss: 0.547977\n",
      "epoch 125; iter: 0; batch classifier loss: 0.379274; batch adversarial loss: 0.644818\n",
      "epoch 126; iter: 0; batch classifier loss: 0.381886; batch adversarial loss: 0.526727\n",
      "epoch 127; iter: 0; batch classifier loss: 0.379322; batch adversarial loss: 0.500336\n",
      "epoch 128; iter: 0; batch classifier loss: 0.392320; batch adversarial loss: 0.580069\n",
      "epoch 129; iter: 0; batch classifier loss: 0.378473; batch adversarial loss: 0.578219\n",
      "epoch 130; iter: 0; batch classifier loss: 0.385691; batch adversarial loss: 0.480909\n",
      "epoch 131; iter: 0; batch classifier loss: 0.413013; batch adversarial loss: 0.517757\n",
      "epoch 132; iter: 0; batch classifier loss: 0.364311; batch adversarial loss: 0.563131\n",
      "epoch 133; iter: 0; batch classifier loss: 0.394829; batch adversarial loss: 0.593360\n",
      "epoch 134; iter: 0; batch classifier loss: 0.437726; batch adversarial loss: 0.499234\n",
      "epoch 135; iter: 0; batch classifier loss: 0.418335; batch adversarial loss: 0.578317\n",
      "epoch 136; iter: 0; batch classifier loss: 0.367171; batch adversarial loss: 0.508012\n",
      "epoch 137; iter: 0; batch classifier loss: 0.347394; batch adversarial loss: 0.452909\n",
      "epoch 138; iter: 0; batch classifier loss: 0.464279; batch adversarial loss: 0.552869\n",
      "epoch 139; iter: 0; batch classifier loss: 0.430819; batch adversarial loss: 0.589430\n",
      "epoch 140; iter: 0; batch classifier loss: 0.365887; batch adversarial loss: 0.608742\n",
      "epoch 141; iter: 0; batch classifier loss: 0.323742; batch adversarial loss: 0.648890\n",
      "epoch 142; iter: 0; batch classifier loss: 0.353998; batch adversarial loss: 0.570561\n",
      "epoch 143; iter: 0; batch classifier loss: 0.383123; batch adversarial loss: 0.591520\n",
      "epoch 144; iter: 0; batch classifier loss: 0.411200; batch adversarial loss: 0.661265\n",
      "epoch 145; iter: 0; batch classifier loss: 0.397202; batch adversarial loss: 0.500813\n",
      "epoch 146; iter: 0; batch classifier loss: 0.314670; batch adversarial loss: 0.507221\n",
      "epoch 147; iter: 0; batch classifier loss: 0.429631; batch adversarial loss: 0.600076\n",
      "epoch 148; iter: 0; batch classifier loss: 0.386645; batch adversarial loss: 0.544855\n",
      "epoch 149; iter: 0; batch classifier loss: 0.379311; batch adversarial loss: 0.572992\n",
      "epoch 150; iter: 0; batch classifier loss: 0.407962; batch adversarial loss: 0.579979\n",
      "epoch 151; iter: 0; batch classifier loss: 0.341727; batch adversarial loss: 0.600216\n",
      "epoch 152; iter: 0; batch classifier loss: 0.381561; batch adversarial loss: 0.550599\n",
      "epoch 153; iter: 0; batch classifier loss: 0.496200; batch adversarial loss: 0.595877\n",
      "epoch 154; iter: 0; batch classifier loss: 0.344514; batch adversarial loss: 0.552443\n",
      "epoch 155; iter: 0; batch classifier loss: 0.308600; batch adversarial loss: 0.540629\n",
      "epoch 156; iter: 0; batch classifier loss: 0.315885; batch adversarial loss: 0.543945\n",
      "epoch 157; iter: 0; batch classifier loss: 0.372146; batch adversarial loss: 0.634953\n",
      "epoch 158; iter: 0; batch classifier loss: 0.321526; batch adversarial loss: 0.518361\n",
      "epoch 159; iter: 0; batch classifier loss: 0.447162; batch adversarial loss: 0.560596\n",
      "epoch 160; iter: 0; batch classifier loss: 0.383914; batch adversarial loss: 0.553185\n",
      "epoch 161; iter: 0; batch classifier loss: 0.346753; batch adversarial loss: 0.535272\n",
      "epoch 162; iter: 0; batch classifier loss: 0.381894; batch adversarial loss: 0.544441\n",
      "epoch 163; iter: 0; batch classifier loss: 0.317149; batch adversarial loss: 0.501576\n",
      "epoch 164; iter: 0; batch classifier loss: 0.314033; batch adversarial loss: 0.527323\n",
      "epoch 165; iter: 0; batch classifier loss: 0.408459; batch adversarial loss: 0.535868\n",
      "epoch 166; iter: 0; batch classifier loss: 0.404301; batch adversarial loss: 0.607539\n",
      "epoch 167; iter: 0; batch classifier loss: 0.323326; batch adversarial loss: 0.552025\n",
      "epoch 168; iter: 0; batch classifier loss: 0.383347; batch adversarial loss: 0.573310\n",
      "epoch 169; iter: 0; batch classifier loss: 0.436348; batch adversarial loss: 0.544045\n",
      "epoch 170; iter: 0; batch classifier loss: 0.438792; batch adversarial loss: 0.461514\n",
      "epoch 171; iter: 0; batch classifier loss: 0.288645; batch adversarial loss: 0.542715\n",
      "epoch 172; iter: 0; batch classifier loss: 0.362088; batch adversarial loss: 0.526245\n",
      "epoch 173; iter: 0; batch classifier loss: 0.412173; batch adversarial loss: 0.617162\n",
      "epoch 174; iter: 0; batch classifier loss: 0.355148; batch adversarial loss: 0.542636\n",
      "epoch 175; iter: 0; batch classifier loss: 0.329980; batch adversarial loss: 0.527748\n",
      "epoch 176; iter: 0; batch classifier loss: 0.372520; batch adversarial loss: 0.500489\n",
      "epoch 177; iter: 0; batch classifier loss: 0.342370; batch adversarial loss: 0.554737\n",
      "epoch 178; iter: 0; batch classifier loss: 0.354813; batch adversarial loss: 0.515845\n",
      "epoch 179; iter: 0; batch classifier loss: 0.396876; batch adversarial loss: 0.625284\n",
      "epoch 180; iter: 0; batch classifier loss: 0.442251; batch adversarial loss: 0.541388\n",
      "epoch 181; iter: 0; batch classifier loss: 0.333907; batch adversarial loss: 0.508411\n",
      "epoch 182; iter: 0; batch classifier loss: 0.357358; batch adversarial loss: 0.559480\n",
      "epoch 183; iter: 0; batch classifier loss: 0.306008; batch adversarial loss: 0.563572\n",
      "epoch 184; iter: 0; batch classifier loss: 0.349004; batch adversarial loss: 0.515407\n",
      "epoch 185; iter: 0; batch classifier loss: 0.407515; batch adversarial loss: 0.568285\n",
      "epoch 186; iter: 0; batch classifier loss: 0.312389; batch adversarial loss: 0.571592\n",
      "epoch 187; iter: 0; batch classifier loss: 0.425659; batch adversarial loss: 0.554455\n",
      "epoch 188; iter: 0; batch classifier loss: 0.332797; batch adversarial loss: 0.562934\n",
      "epoch 189; iter: 0; batch classifier loss: 0.397208; batch adversarial loss: 0.517133\n",
      "epoch 190; iter: 0; batch classifier loss: 0.357181; batch adversarial loss: 0.553412\n",
      "epoch 191; iter: 0; batch classifier loss: 0.425236; batch adversarial loss: 0.500901\n",
      "epoch 192; iter: 0; batch classifier loss: 0.332956; batch adversarial loss: 0.587651\n",
      "epoch 193; iter: 0; batch classifier loss: 0.365380; batch adversarial loss: 0.508459\n",
      "epoch 194; iter: 0; batch classifier loss: 0.334907; batch adversarial loss: 0.635266\n",
      "epoch 195; iter: 0; batch classifier loss: 0.401965; batch adversarial loss: 0.471109\n",
      "epoch 196; iter: 0; batch classifier loss: 0.460841; batch adversarial loss: 0.552631\n",
      "epoch 197; iter: 0; batch classifier loss: 0.396448; batch adversarial loss: 0.590295\n",
      "epoch 198; iter: 0; batch classifier loss: 0.332989; batch adversarial loss: 0.573095\n",
      "epoch 199; iter: 0; batch classifier loss: 0.360830; batch adversarial loss: 0.553385\n",
      "epoch 0; iter: 0; batch classifier loss: 0.719526; batch adversarial loss: 0.755864\n",
      "epoch 1; iter: 0; batch classifier loss: 0.869524; batch adversarial loss: 1.295063\n",
      "epoch 2; iter: 0; batch classifier loss: 1.014706; batch adversarial loss: 1.316249\n",
      "epoch 3; iter: 0; batch classifier loss: 1.054525; batch adversarial loss: 1.189668\n",
      "epoch 4; iter: 0; batch classifier loss: 1.230884; batch adversarial loss: 1.116504\n",
      "epoch 5; iter: 0; batch classifier loss: 1.121750; batch adversarial loss: 1.019434\n",
      "epoch 6; iter: 0; batch classifier loss: 1.117859; batch adversarial loss: 0.929026\n",
      "epoch 7; iter: 0; batch classifier loss: 1.005370; batch adversarial loss: 0.867699\n",
      "epoch 8; iter: 0; batch classifier loss: 1.134762; batch adversarial loss: 0.802799\n",
      "epoch 9; iter: 0; batch classifier loss: 0.958603; batch adversarial loss: 0.748968\n",
      "epoch 10; iter: 0; batch classifier loss: 0.893156; batch adversarial loss: 0.720376\n",
      "epoch 11; iter: 0; batch classifier loss: 0.794751; batch adversarial loss: 0.662029\n",
      "epoch 12; iter: 0; batch classifier loss: 0.660453; batch adversarial loss: 0.630118\n",
      "epoch 13; iter: 0; batch classifier loss: 0.522941; batch adversarial loss: 0.609835\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14; iter: 0; batch classifier loss: 0.609518; batch adversarial loss: 0.590373\n",
      "epoch 15; iter: 0; batch classifier loss: 0.510186; batch adversarial loss: 0.587466\n",
      "epoch 16; iter: 0; batch classifier loss: 0.492702; batch adversarial loss: 0.577051\n",
      "epoch 17; iter: 0; batch classifier loss: 0.569973; batch adversarial loss: 0.559505\n",
      "epoch 18; iter: 0; batch classifier loss: 0.490249; batch adversarial loss: 0.566505\n",
      "epoch 19; iter: 0; batch classifier loss: 0.495299; batch adversarial loss: 0.558692\n",
      "epoch 20; iter: 0; batch classifier loss: 0.512823; batch adversarial loss: 0.601303\n",
      "epoch 21; iter: 0; batch classifier loss: 0.536266; batch adversarial loss: 0.560244\n",
      "epoch 22; iter: 0; batch classifier loss: 0.514332; batch adversarial loss: 0.546423\n",
      "epoch 23; iter: 0; batch classifier loss: 0.445711; batch adversarial loss: 0.558307\n",
      "epoch 24; iter: 0; batch classifier loss: 0.457909; batch adversarial loss: 0.538505\n",
      "epoch 25; iter: 0; batch classifier loss: 0.558444; batch adversarial loss: 0.568002\n",
      "epoch 26; iter: 0; batch classifier loss: 0.464592; batch adversarial loss: 0.531256\n",
      "epoch 27; iter: 0; batch classifier loss: 0.460539; batch adversarial loss: 0.472341\n",
      "epoch 28; iter: 0; batch classifier loss: 0.474132; batch adversarial loss: 0.537153\n",
      "epoch 29; iter: 0; batch classifier loss: 0.507064; batch adversarial loss: 0.577636\n",
      "epoch 30; iter: 0; batch classifier loss: 0.514727; batch adversarial loss: 0.546208\n",
      "epoch 31; iter: 0; batch classifier loss: 0.523331; batch adversarial loss: 0.530114\n",
      "epoch 32; iter: 0; batch classifier loss: 0.466783; batch adversarial loss: 0.475367\n",
      "epoch 33; iter: 0; batch classifier loss: 0.421052; batch adversarial loss: 0.634897\n",
      "epoch 34; iter: 0; batch classifier loss: 0.394574; batch adversarial loss: 0.504213\n",
      "epoch 35; iter: 0; batch classifier loss: 0.459322; batch adversarial loss: 0.600326\n",
      "epoch 36; iter: 0; batch classifier loss: 0.460478; batch adversarial loss: 0.553674\n",
      "epoch 37; iter: 0; batch classifier loss: 0.470782; batch adversarial loss: 0.498070\n",
      "epoch 38; iter: 0; batch classifier loss: 0.446423; batch adversarial loss: 0.562321\n",
      "epoch 39; iter: 0; batch classifier loss: 0.464117; batch adversarial loss: 0.617656\n",
      "epoch 40; iter: 0; batch classifier loss: 0.450427; batch adversarial loss: 0.517851\n",
      "epoch 41; iter: 0; batch classifier loss: 0.446429; batch adversarial loss: 0.541844\n",
      "epoch 42; iter: 0; batch classifier loss: 0.405580; batch adversarial loss: 0.586820\n",
      "epoch 43; iter: 0; batch classifier loss: 0.392148; batch adversarial loss: 0.545334\n",
      "epoch 44; iter: 0; batch classifier loss: 0.431451; batch adversarial loss: 0.543619\n",
      "epoch 45; iter: 0; batch classifier loss: 0.429893; batch adversarial loss: 0.483723\n",
      "epoch 46; iter: 0; batch classifier loss: 0.407493; batch adversarial loss: 0.581912\n",
      "epoch 47; iter: 0; batch classifier loss: 0.408526; batch adversarial loss: 0.579524\n",
      "epoch 48; iter: 0; batch classifier loss: 0.446219; batch adversarial loss: 0.534213\n",
      "epoch 49; iter: 0; batch classifier loss: 0.439865; batch adversarial loss: 0.498414\n",
      "epoch 50; iter: 0; batch classifier loss: 0.467964; batch adversarial loss: 0.517893\n",
      "epoch 51; iter: 0; batch classifier loss: 0.453952; batch adversarial loss: 0.560973\n",
      "epoch 52; iter: 0; batch classifier loss: 0.450300; batch adversarial loss: 0.544722\n",
      "epoch 53; iter: 0; batch classifier loss: 0.441790; batch adversarial loss: 0.698225\n",
      "epoch 54; iter: 0; batch classifier loss: 0.482033; batch adversarial loss: 0.544715\n",
      "epoch 55; iter: 0; batch classifier loss: 0.444739; batch adversarial loss: 0.518190\n",
      "epoch 56; iter: 0; batch classifier loss: 0.371707; batch adversarial loss: 0.527077\n",
      "epoch 57; iter: 0; batch classifier loss: 0.431053; batch adversarial loss: 0.508779\n",
      "epoch 58; iter: 0; batch classifier loss: 0.428078; batch adversarial loss: 0.552889\n",
      "epoch 59; iter: 0; batch classifier loss: 0.470566; batch adversarial loss: 0.562952\n",
      "epoch 60; iter: 0; batch classifier loss: 0.370892; batch adversarial loss: 0.480359\n",
      "epoch 61; iter: 0; batch classifier loss: 0.420819; batch adversarial loss: 0.498340\n",
      "epoch 62; iter: 0; batch classifier loss: 0.385788; batch adversarial loss: 0.590173\n",
      "epoch 63; iter: 0; batch classifier loss: 0.422728; batch adversarial loss: 0.664438\n",
      "epoch 64; iter: 0; batch classifier loss: 0.369478; batch adversarial loss: 0.563971\n",
      "epoch 65; iter: 0; batch classifier loss: 0.375390; batch adversarial loss: 0.553570\n",
      "epoch 66; iter: 0; batch classifier loss: 0.388390; batch adversarial loss: 0.553979\n",
      "epoch 67; iter: 0; batch classifier loss: 0.436241; batch adversarial loss: 0.553768\n",
      "epoch 68; iter: 0; batch classifier loss: 0.387173; batch adversarial loss: 0.562530\n",
      "epoch 69; iter: 0; batch classifier loss: 0.406246; batch adversarial loss: 0.554375\n",
      "epoch 70; iter: 0; batch classifier loss: 0.445826; batch adversarial loss: 0.535988\n",
      "epoch 71; iter: 0; batch classifier loss: 0.407815; batch adversarial loss: 0.636042\n",
      "epoch 72; iter: 0; batch classifier loss: 0.400752; batch adversarial loss: 0.590346\n",
      "epoch 73; iter: 0; batch classifier loss: 0.391350; batch adversarial loss: 0.617189\n",
      "epoch 74; iter: 0; batch classifier loss: 0.432387; batch adversarial loss: 0.562819\n",
      "epoch 75; iter: 0; batch classifier loss: 0.398613; batch adversarial loss: 0.471217\n",
      "epoch 76; iter: 0; batch classifier loss: 0.478601; batch adversarial loss: 0.481305\n",
      "epoch 77; iter: 0; batch classifier loss: 0.338708; batch adversarial loss: 0.535240\n",
      "epoch 78; iter: 0; batch classifier loss: 0.317736; batch adversarial loss: 0.581191\n",
      "epoch 79; iter: 0; batch classifier loss: 0.366149; batch adversarial loss: 0.571620\n",
      "epoch 80; iter: 0; batch classifier loss: 0.470056; batch adversarial loss: 0.589386\n",
      "epoch 81; iter: 0; batch classifier loss: 0.483517; batch adversarial loss: 0.562499\n",
      "epoch 82; iter: 0; batch classifier loss: 0.397752; batch adversarial loss: 0.553314\n",
      "epoch 83; iter: 0; batch classifier loss: 0.432576; batch adversarial loss: 0.653381\n",
      "epoch 84; iter: 0; batch classifier loss: 0.435055; batch adversarial loss: 0.589599\n",
      "epoch 85; iter: 0; batch classifier loss: 0.414701; batch adversarial loss: 0.554166\n",
      "epoch 86; iter: 0; batch classifier loss: 0.459968; batch adversarial loss: 0.526215\n",
      "epoch 87; iter: 0; batch classifier loss: 0.427901; batch adversarial loss: 0.526794\n",
      "epoch 88; iter: 0; batch classifier loss: 0.362682; batch adversarial loss: 0.462540\n",
      "epoch 89; iter: 0; batch classifier loss: 0.371745; batch adversarial loss: 0.571650\n",
      "epoch 90; iter: 0; batch classifier loss: 0.420624; batch adversarial loss: 0.571603\n",
      "epoch 91; iter: 0; batch classifier loss: 0.372524; batch adversarial loss: 0.553566\n",
      "epoch 92; iter: 0; batch classifier loss: 0.344675; batch adversarial loss: 0.589969\n",
      "epoch 93; iter: 0; batch classifier loss: 0.353366; batch adversarial loss: 0.507937\n",
      "epoch 94; iter: 0; batch classifier loss: 0.373353; batch adversarial loss: 0.508328\n",
      "epoch 95; iter: 0; batch classifier loss: 0.474006; batch adversarial loss: 0.589392\n",
      "epoch 96; iter: 0; batch classifier loss: 0.312233; batch adversarial loss: 0.535674\n",
      "epoch 97; iter: 0; batch classifier loss: 0.410385; batch adversarial loss: 0.499235\n",
      "epoch 98; iter: 0; batch classifier loss: 0.326324; batch adversarial loss: 0.508410\n",
      "epoch 99; iter: 0; batch classifier loss: 0.380642; batch adversarial loss: 0.498974\n",
      "epoch 100; iter: 0; batch classifier loss: 0.462094; batch adversarial loss: 0.562560\n",
      "epoch 101; iter: 0; batch classifier loss: 0.368460; batch adversarial loss: 0.562717\n",
      "epoch 102; iter: 0; batch classifier loss: 0.475308; batch adversarial loss: 0.499406\n",
      "epoch 103; iter: 0; batch classifier loss: 0.456049; batch adversarial loss: 0.599068\n",
      "epoch 104; iter: 0; batch classifier loss: 0.410931; batch adversarial loss: 0.489899\n",
      "epoch 105; iter: 0; batch classifier loss: 0.404412; batch adversarial loss: 0.508273\n",
      "epoch 106; iter: 0; batch classifier loss: 0.349013; batch adversarial loss: 0.535457\n",
      "epoch 107; iter: 0; batch classifier loss: 0.419527; batch adversarial loss: 0.580723\n",
      "epoch 108; iter: 0; batch classifier loss: 0.303752; batch adversarial loss: 0.598900\n",
      "epoch 109; iter: 0; batch classifier loss: 0.416547; batch adversarial loss: 0.463537\n",
      "epoch 110; iter: 0; batch classifier loss: 0.370365; batch adversarial loss: 0.572399\n",
      "epoch 111; iter: 0; batch classifier loss: 0.374007; batch adversarial loss: 0.599181\n",
      "epoch 112; iter: 0; batch classifier loss: 0.427549; batch adversarial loss: 0.517654\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 113; iter: 0; batch classifier loss: 0.328864; batch adversarial loss: 0.590198\n",
      "epoch 114; iter: 0; batch classifier loss: 0.381923; batch adversarial loss: 0.571835\n",
      "epoch 115; iter: 0; batch classifier loss: 0.300998; batch adversarial loss: 0.480938\n",
      "epoch 116; iter: 0; batch classifier loss: 0.354791; batch adversarial loss: 0.480638\n",
      "epoch 117; iter: 0; batch classifier loss: 0.378933; batch adversarial loss: 0.598866\n",
      "epoch 118; iter: 0; batch classifier loss: 0.403535; batch adversarial loss: 0.579687\n",
      "epoch 119; iter: 0; batch classifier loss: 0.313930; batch adversarial loss: 0.560757\n",
      "epoch 120; iter: 0; batch classifier loss: 0.326145; batch adversarial loss: 0.598544\n",
      "epoch 121; iter: 0; batch classifier loss: 0.353175; batch adversarial loss: 0.527182\n",
      "epoch 122; iter: 0; batch classifier loss: 0.391099; batch adversarial loss: 0.542733\n",
      "epoch 123; iter: 0; batch classifier loss: 0.361055; batch adversarial loss: 0.562113\n",
      "epoch 124; iter: 0; batch classifier loss: 0.326357; batch adversarial loss: 0.532815\n",
      "epoch 125; iter: 0; batch classifier loss: 0.297497; batch adversarial loss: 0.544071\n",
      "epoch 126; iter: 0; batch classifier loss: 0.372397; batch adversarial loss: 0.665490\n",
      "epoch 127; iter: 0; batch classifier loss: 0.309939; batch adversarial loss: 0.544891\n",
      "epoch 128; iter: 0; batch classifier loss: 0.366469; batch adversarial loss: 0.561156\n",
      "epoch 129; iter: 0; batch classifier loss: 0.358294; batch adversarial loss: 0.579464\n",
      "epoch 130; iter: 0; batch classifier loss: 0.398646; batch adversarial loss: 0.597198\n",
      "epoch 131; iter: 0; batch classifier loss: 0.367735; batch adversarial loss: 0.571845\n",
      "epoch 132; iter: 0; batch classifier loss: 0.351091; batch adversarial loss: 0.490764\n",
      "epoch 133; iter: 0; batch classifier loss: 0.344938; batch adversarial loss: 0.517615\n",
      "epoch 134; iter: 0; batch classifier loss: 0.381887; batch adversarial loss: 0.573414\n",
      "epoch 135; iter: 0; batch classifier loss: 0.389770; batch adversarial loss: 0.588943\n",
      "epoch 136; iter: 0; batch classifier loss: 0.364760; batch adversarial loss: 0.526812\n",
      "epoch 137; iter: 0; batch classifier loss: 0.317670; batch adversarial loss: 0.514948\n",
      "epoch 138; iter: 0; batch classifier loss: 0.276917; batch adversarial loss: 0.515308\n",
      "epoch 139; iter: 0; batch classifier loss: 0.408173; batch adversarial loss: 0.509212\n",
      "epoch 140; iter: 0; batch classifier loss: 0.391423; batch adversarial loss: 0.633190\n",
      "epoch 141; iter: 0; batch classifier loss: 0.447849; batch adversarial loss: 0.573903\n",
      "epoch 142; iter: 0; batch classifier loss: 0.336056; batch adversarial loss: 0.589172\n",
      "epoch 143; iter: 0; batch classifier loss: 0.365072; batch adversarial loss: 0.544822\n",
      "epoch 144; iter: 0; batch classifier loss: 0.423461; batch adversarial loss: 0.490894\n",
      "epoch 145; iter: 0; batch classifier loss: 0.350116; batch adversarial loss: 0.489580\n",
      "epoch 146; iter: 0; batch classifier loss: 0.343021; batch adversarial loss: 0.606313\n",
      "epoch 147; iter: 0; batch classifier loss: 0.373224; batch adversarial loss: 0.572926\n",
      "epoch 148; iter: 0; batch classifier loss: 0.351117; batch adversarial loss: 0.554394\n",
      "epoch 149; iter: 0; batch classifier loss: 0.391917; batch adversarial loss: 0.555174\n",
      "epoch 150; iter: 0; batch classifier loss: 0.333489; batch adversarial loss: 0.616497\n",
      "epoch 151; iter: 0; batch classifier loss: 0.344436; batch adversarial loss: 0.624597\n",
      "epoch 152; iter: 0; batch classifier loss: 0.340539; batch adversarial loss: 0.606528\n",
      "epoch 153; iter: 0; batch classifier loss: 0.323046; batch adversarial loss: 0.525606\n",
      "epoch 154; iter: 0; batch classifier loss: 0.324050; batch adversarial loss: 0.589398\n",
      "epoch 155; iter: 0; batch classifier loss: 0.333821; batch adversarial loss: 0.543411\n",
      "epoch 156; iter: 0; batch classifier loss: 0.412342; batch adversarial loss: 0.552884\n",
      "epoch 157; iter: 0; batch classifier loss: 0.436712; batch adversarial loss: 0.571380\n",
      "epoch 158; iter: 0; batch classifier loss: 0.392968; batch adversarial loss: 0.551892\n",
      "epoch 159; iter: 0; batch classifier loss: 0.341486; batch adversarial loss: 0.515403\n",
      "epoch 160; iter: 0; batch classifier loss: 0.336728; batch adversarial loss: 0.528080\n",
      "epoch 161; iter: 0; batch classifier loss: 0.357372; batch adversarial loss: 0.570223\n",
      "epoch 162; iter: 0; batch classifier loss: 0.328194; batch adversarial loss: 0.590587\n",
      "epoch 163; iter: 0; batch classifier loss: 0.264067; batch adversarial loss: 0.608358\n",
      "epoch 164; iter: 0; batch classifier loss: 0.324252; batch adversarial loss: 0.533615\n",
      "epoch 165; iter: 0; batch classifier loss: 0.408102; batch adversarial loss: 0.587213\n",
      "epoch 166; iter: 0; batch classifier loss: 0.426414; batch adversarial loss: 0.599290\n",
      "epoch 167; iter: 0; batch classifier loss: 0.392334; batch adversarial loss: 0.478533\n",
      "epoch 168; iter: 0; batch classifier loss: 0.365249; batch adversarial loss: 0.451594\n",
      "epoch 169; iter: 0; batch classifier loss: 0.363035; batch adversarial loss: 0.498481\n",
      "epoch 170; iter: 0; batch classifier loss: 0.383608; batch adversarial loss: 0.552233\n",
      "epoch 171; iter: 0; batch classifier loss: 0.278402; batch adversarial loss: 0.529600\n",
      "epoch 172; iter: 0; batch classifier loss: 0.389468; batch adversarial loss: 0.552380\n",
      "epoch 173; iter: 0; batch classifier loss: 0.332557; batch adversarial loss: 0.617750\n",
      "epoch 174; iter: 0; batch classifier loss: 0.438200; batch adversarial loss: 0.626113\n",
      "epoch 175; iter: 0; batch classifier loss: 0.382895; batch adversarial loss: 0.509601\n",
      "epoch 176; iter: 0; batch classifier loss: 0.341357; batch adversarial loss: 0.536227\n",
      "epoch 177; iter: 0; batch classifier loss: 0.303130; batch adversarial loss: 0.500706\n",
      "epoch 178; iter: 0; batch classifier loss: 0.367392; batch adversarial loss: 0.588538\n",
      "epoch 179; iter: 0; batch classifier loss: 0.332567; batch adversarial loss: 0.545895\n",
      "epoch 180; iter: 0; batch classifier loss: 0.338263; batch adversarial loss: 0.517044\n",
      "epoch 181; iter: 0; batch classifier loss: 0.362972; batch adversarial loss: 0.551186\n",
      "epoch 182; iter: 0; batch classifier loss: 0.282033; batch adversarial loss: 0.602480\n",
      "epoch 183; iter: 0; batch classifier loss: 0.366366; batch adversarial loss: 0.637201\n",
      "epoch 184; iter: 0; batch classifier loss: 0.428954; batch adversarial loss: 0.573284\n",
      "epoch 185; iter: 0; batch classifier loss: 0.283234; batch adversarial loss: 0.563469\n",
      "epoch 186; iter: 0; batch classifier loss: 0.341951; batch adversarial loss: 0.554259\n",
      "epoch 187; iter: 0; batch classifier loss: 0.393845; batch adversarial loss: 0.624143\n",
      "epoch 188; iter: 0; batch classifier loss: 0.320863; batch adversarial loss: 0.552825\n",
      "epoch 189; iter: 0; batch classifier loss: 0.364317; batch adversarial loss: 0.508521\n",
      "epoch 190; iter: 0; batch classifier loss: 0.358092; batch adversarial loss: 0.507910\n",
      "epoch 191; iter: 0; batch classifier loss: 0.425722; batch adversarial loss: 0.555121\n",
      "epoch 192; iter: 0; batch classifier loss: 0.412016; batch adversarial loss: 0.545140\n",
      "epoch 193; iter: 0; batch classifier loss: 0.304627; batch adversarial loss: 0.534170\n",
      "epoch 194; iter: 0; batch classifier loss: 0.301611; batch adversarial loss: 0.554335\n",
      "epoch 195; iter: 0; batch classifier loss: 0.321000; batch adversarial loss: 0.465690\n",
      "epoch 196; iter: 0; batch classifier loss: 0.323206; batch adversarial loss: 0.607659\n",
      "epoch 197; iter: 0; batch classifier loss: 0.303864; batch adversarial loss: 0.635508\n",
      "epoch 198; iter: 0; batch classifier loss: 0.333090; batch adversarial loss: 0.588876\n",
      "epoch 199; iter: 0; batch classifier loss: 0.363041; batch adversarial loss: 0.507995\n",
      "epoch 0; iter: 0; batch classifier loss: 0.648917; batch adversarial loss: 0.765252\n",
      "epoch 1; iter: 0; batch classifier loss: 0.853694; batch adversarial loss: 0.918427\n",
      "epoch 2; iter: 0; batch classifier loss: 1.060867; batch adversarial loss: 0.923181\n",
      "epoch 3; iter: 0; batch classifier loss: 0.816789; batch adversarial loss: 0.761049\n",
      "epoch 4; iter: 0; batch classifier loss: 0.756650; batch adversarial loss: 0.700271\n",
      "epoch 5; iter: 0; batch classifier loss: 0.669916; batch adversarial loss: 0.664686\n",
      "epoch 6; iter: 0; batch classifier loss: 0.559342; batch adversarial loss: 0.635665\n",
      "epoch 7; iter: 0; batch classifier loss: 0.539219; batch adversarial loss: 0.628567\n",
      "epoch 8; iter: 0; batch classifier loss: 0.514872; batch adversarial loss: 0.629040\n",
      "epoch 9; iter: 0; batch classifier loss: 0.527689; batch adversarial loss: 0.616494\n",
      "epoch 10; iter: 0; batch classifier loss: 0.557311; batch adversarial loss: 0.583802\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11; iter: 0; batch classifier loss: 0.502431; batch adversarial loss: 0.611716\n",
      "epoch 12; iter: 0; batch classifier loss: 0.530129; batch adversarial loss: 0.604451\n",
      "epoch 13; iter: 0; batch classifier loss: 0.543184; batch adversarial loss: 0.613397\n",
      "epoch 14; iter: 0; batch classifier loss: 0.518914; batch adversarial loss: 0.582064\n",
      "epoch 15; iter: 0; batch classifier loss: 0.481644; batch adversarial loss: 0.631632\n",
      "epoch 16; iter: 0; batch classifier loss: 0.465269; batch adversarial loss: 0.565775\n",
      "epoch 17; iter: 0; batch classifier loss: 0.513806; batch adversarial loss: 0.597311\n",
      "epoch 18; iter: 0; batch classifier loss: 0.454969; batch adversarial loss: 0.566423\n",
      "epoch 19; iter: 0; batch classifier loss: 0.459439; batch adversarial loss: 0.619724\n",
      "epoch 20; iter: 0; batch classifier loss: 0.470684; batch adversarial loss: 0.601524\n",
      "epoch 21; iter: 0; batch classifier loss: 0.482407; batch adversarial loss: 0.575846\n",
      "epoch 22; iter: 0; batch classifier loss: 0.494982; batch adversarial loss: 0.590025\n",
      "epoch 23; iter: 0; batch classifier loss: 0.420645; batch adversarial loss: 0.529220\n",
      "epoch 24; iter: 0; batch classifier loss: 0.450858; batch adversarial loss: 0.575952\n",
      "epoch 25; iter: 0; batch classifier loss: 0.411286; batch adversarial loss: 0.597009\n",
      "epoch 26; iter: 0; batch classifier loss: 0.496073; batch adversarial loss: 0.552544\n",
      "epoch 27; iter: 0; batch classifier loss: 0.444655; batch adversarial loss: 0.580140\n",
      "epoch 28; iter: 0; batch classifier loss: 0.386992; batch adversarial loss: 0.622137\n",
      "epoch 29; iter: 0; batch classifier loss: 0.437437; batch adversarial loss: 0.547227\n",
      "epoch 30; iter: 0; batch classifier loss: 0.457726; batch adversarial loss: 0.562604\n",
      "epoch 31; iter: 0; batch classifier loss: 0.388728; batch adversarial loss: 0.567783\n",
      "epoch 32; iter: 0; batch classifier loss: 0.491536; batch adversarial loss: 0.598861\n",
      "epoch 33; iter: 0; batch classifier loss: 0.447292; batch adversarial loss: 0.560768\n",
      "epoch 34; iter: 0; batch classifier loss: 0.410303; batch adversarial loss: 0.590311\n",
      "epoch 35; iter: 0; batch classifier loss: 0.427031; batch adversarial loss: 0.544161\n",
      "epoch 36; iter: 0; batch classifier loss: 0.367839; batch adversarial loss: 0.547154\n",
      "epoch 37; iter: 0; batch classifier loss: 0.454883; batch adversarial loss: 0.518217\n",
      "epoch 38; iter: 0; batch classifier loss: 0.467160; batch adversarial loss: 0.549549\n",
      "epoch 39; iter: 0; batch classifier loss: 0.459136; batch adversarial loss: 0.546178\n",
      "epoch 40; iter: 0; batch classifier loss: 0.431930; batch adversarial loss: 0.549146\n",
      "epoch 41; iter: 0; batch classifier loss: 0.466098; batch adversarial loss: 0.530395\n",
      "epoch 42; iter: 0; batch classifier loss: 0.379387; batch adversarial loss: 0.596016\n",
      "epoch 43; iter: 0; batch classifier loss: 0.344132; batch adversarial loss: 0.580421\n",
      "epoch 44; iter: 0; batch classifier loss: 0.438222; batch adversarial loss: 0.572067\n",
      "epoch 45; iter: 0; batch classifier loss: 0.355328; batch adversarial loss: 0.536544\n",
      "epoch 46; iter: 0; batch classifier loss: 0.360979; batch adversarial loss: 0.623500\n",
      "epoch 47; iter: 0; batch classifier loss: 0.469852; batch adversarial loss: 0.527304\n",
      "epoch 48; iter: 0; batch classifier loss: 0.412578; batch adversarial loss: 0.569885\n",
      "epoch 49; iter: 0; batch classifier loss: 0.466276; batch adversarial loss: 0.546414\n",
      "epoch 50; iter: 0; batch classifier loss: 0.523124; batch adversarial loss: 0.561423\n",
      "epoch 51; iter: 0; batch classifier loss: 0.477218; batch adversarial loss: 0.554698\n",
      "epoch 52; iter: 0; batch classifier loss: 0.400395; batch adversarial loss: 0.492613\n",
      "epoch 53; iter: 0; batch classifier loss: 0.487617; batch adversarial loss: 0.474522\n",
      "epoch 54; iter: 0; batch classifier loss: 0.407956; batch adversarial loss: 0.588986\n",
      "epoch 55; iter: 0; batch classifier loss: 0.442077; batch adversarial loss: 0.474211\n",
      "epoch 56; iter: 0; batch classifier loss: 0.427389; batch adversarial loss: 0.622746\n",
      "epoch 57; iter: 0; batch classifier loss: 0.409807; batch adversarial loss: 0.589213\n",
      "epoch 58; iter: 0; batch classifier loss: 0.429837; batch adversarial loss: 0.481868\n",
      "epoch 59; iter: 0; batch classifier loss: 0.309529; batch adversarial loss: 0.553399\n",
      "epoch 60; iter: 0; batch classifier loss: 0.368593; batch adversarial loss: 0.615164\n",
      "epoch 61; iter: 0; batch classifier loss: 0.360887; batch adversarial loss: 0.581309\n",
      "epoch 62; iter: 0; batch classifier loss: 0.461758; batch adversarial loss: 0.596411\n",
      "epoch 63; iter: 0; batch classifier loss: 0.378543; batch adversarial loss: 0.590192\n",
      "epoch 64; iter: 0; batch classifier loss: 0.327541; batch adversarial loss: 0.586642\n",
      "epoch 65; iter: 0; batch classifier loss: 0.419061; batch adversarial loss: 0.560528\n",
      "epoch 66; iter: 0; batch classifier loss: 0.428302; batch adversarial loss: 0.594077\n",
      "epoch 67; iter: 0; batch classifier loss: 0.440983; batch adversarial loss: 0.525010\n",
      "epoch 68; iter: 0; batch classifier loss: 0.413886; batch adversarial loss: 0.576189\n",
      "epoch 69; iter: 0; batch classifier loss: 0.363181; batch adversarial loss: 0.544146\n",
      "epoch 70; iter: 0; batch classifier loss: 0.359337; batch adversarial loss: 0.572762\n",
      "epoch 71; iter: 0; batch classifier loss: 0.332283; batch adversarial loss: 0.633485\n",
      "epoch 72; iter: 0; batch classifier loss: 0.365946; batch adversarial loss: 0.534222\n",
      "epoch 73; iter: 0; batch classifier loss: 0.413363; batch adversarial loss: 0.456722\n",
      "epoch 74; iter: 0; batch classifier loss: 0.383032; batch adversarial loss: 0.580104\n",
      "epoch 75; iter: 0; batch classifier loss: 0.444128; batch adversarial loss: 0.584611\n",
      "epoch 76; iter: 0; batch classifier loss: 0.309285; batch adversarial loss: 0.546059\n",
      "epoch 77; iter: 0; batch classifier loss: 0.389912; batch adversarial loss: 0.585763\n",
      "epoch 78; iter: 0; batch classifier loss: 0.352995; batch adversarial loss: 0.549482\n",
      "epoch 79; iter: 0; batch classifier loss: 0.346289; batch adversarial loss: 0.569533\n",
      "epoch 80; iter: 0; batch classifier loss: 0.378919; batch adversarial loss: 0.551971\n",
      "epoch 81; iter: 0; batch classifier loss: 0.419287; batch adversarial loss: 0.485835\n",
      "epoch 82; iter: 0; batch classifier loss: 0.393021; batch adversarial loss: 0.542473\n",
      "epoch 83; iter: 0; batch classifier loss: 0.395298; batch adversarial loss: 0.608413\n",
      "epoch 84; iter: 0; batch classifier loss: 0.364559; batch adversarial loss: 0.521948\n",
      "epoch 85; iter: 0; batch classifier loss: 0.431202; batch adversarial loss: 0.514521\n",
      "epoch 86; iter: 0; batch classifier loss: 0.395345; batch adversarial loss: 0.524369\n",
      "epoch 87; iter: 0; batch classifier loss: 0.344265; batch adversarial loss: 0.565770\n",
      "epoch 88; iter: 0; batch classifier loss: 0.365943; batch adversarial loss: 0.553877\n",
      "epoch 89; iter: 0; batch classifier loss: 0.412080; batch adversarial loss: 0.579011\n",
      "epoch 90; iter: 0; batch classifier loss: 0.413383; batch adversarial loss: 0.569590\n",
      "epoch 91; iter: 0; batch classifier loss: 0.405722; batch adversarial loss: 0.483620\n",
      "epoch 92; iter: 0; batch classifier loss: 0.399200; batch adversarial loss: 0.580069\n",
      "epoch 93; iter: 0; batch classifier loss: 0.353359; batch adversarial loss: 0.591341\n",
      "epoch 94; iter: 0; batch classifier loss: 0.476834; batch adversarial loss: 0.565968\n",
      "epoch 95; iter: 0; batch classifier loss: 0.287442; batch adversarial loss: 0.607406\n",
      "epoch 96; iter: 0; batch classifier loss: 0.382692; batch adversarial loss: 0.553154\n",
      "epoch 97; iter: 0; batch classifier loss: 0.366652; batch adversarial loss: 0.599688\n",
      "epoch 98; iter: 0; batch classifier loss: 0.362106; batch adversarial loss: 0.572640\n",
      "epoch 99; iter: 0; batch classifier loss: 0.307122; batch adversarial loss: 0.524934\n",
      "epoch 100; iter: 0; batch classifier loss: 0.381295; batch adversarial loss: 0.545406\n",
      "epoch 101; iter: 0; batch classifier loss: 0.344710; batch adversarial loss: 0.527064\n",
      "epoch 102; iter: 0; batch classifier loss: 0.391923; batch adversarial loss: 0.561464\n",
      "epoch 103; iter: 0; batch classifier loss: 0.464555; batch adversarial loss: 0.505575\n",
      "epoch 104; iter: 0; batch classifier loss: 0.390855; batch adversarial loss: 0.493086\n",
      "epoch 105; iter: 0; batch classifier loss: 0.334329; batch adversarial loss: 0.497861\n",
      "epoch 106; iter: 0; batch classifier loss: 0.347059; batch adversarial loss: 0.586060\n",
      "epoch 107; iter: 0; batch classifier loss: 0.400307; batch adversarial loss: 0.568089\n",
      "epoch 108; iter: 0; batch classifier loss: 0.399370; batch adversarial loss: 0.560621\n",
      "epoch 109; iter: 0; batch classifier loss: 0.359255; batch adversarial loss: 0.558902\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 110; iter: 0; batch classifier loss: 0.355973; batch adversarial loss: 0.574025\n",
      "epoch 111; iter: 0; batch classifier loss: 0.368725; batch adversarial loss: 0.573995\n",
      "epoch 112; iter: 0; batch classifier loss: 0.363729; batch adversarial loss: 0.589758\n",
      "epoch 113; iter: 0; batch classifier loss: 0.311305; batch adversarial loss: 0.536931\n",
      "epoch 114; iter: 0; batch classifier loss: 0.286806; batch adversarial loss: 0.575366\n",
      "epoch 115; iter: 0; batch classifier loss: 0.356828; batch adversarial loss: 0.498772\n",
      "epoch 116; iter: 0; batch classifier loss: 0.411354; batch adversarial loss: 0.501035\n",
      "epoch 117; iter: 0; batch classifier loss: 0.356667; batch adversarial loss: 0.507651\n",
      "epoch 118; iter: 0; batch classifier loss: 0.349778; batch adversarial loss: 0.492739\n",
      "epoch 119; iter: 0; batch classifier loss: 0.324681; batch adversarial loss: 0.462339\n",
      "epoch 120; iter: 0; batch classifier loss: 0.315652; batch adversarial loss: 0.594509\n",
      "epoch 121; iter: 0; batch classifier loss: 0.404119; batch adversarial loss: 0.535490\n",
      "epoch 122; iter: 0; batch classifier loss: 0.333769; batch adversarial loss: 0.551559\n",
      "epoch 123; iter: 0; batch classifier loss: 0.382569; batch adversarial loss: 0.529942\n",
      "epoch 124; iter: 0; batch classifier loss: 0.343607; batch adversarial loss: 0.550582\n",
      "epoch 125; iter: 0; batch classifier loss: 0.369171; batch adversarial loss: 0.552604\n",
      "epoch 126; iter: 0; batch classifier loss: 0.358442; batch adversarial loss: 0.519642\n",
      "epoch 127; iter: 0; batch classifier loss: 0.266894; batch adversarial loss: 0.525182\n",
      "epoch 128; iter: 0; batch classifier loss: 0.390719; batch adversarial loss: 0.538795\n",
      "epoch 129; iter: 0; batch classifier loss: 0.382564; batch adversarial loss: 0.574273\n",
      "epoch 130; iter: 0; batch classifier loss: 0.292019; batch adversarial loss: 0.578796\n",
      "epoch 131; iter: 0; batch classifier loss: 0.367428; batch adversarial loss: 0.575377\n",
      "epoch 132; iter: 0; batch classifier loss: 0.340845; batch adversarial loss: 0.515311\n",
      "epoch 133; iter: 0; batch classifier loss: 0.325478; batch adversarial loss: 0.544820\n",
      "epoch 134; iter: 0; batch classifier loss: 0.403214; batch adversarial loss: 0.551360\n",
      "epoch 135; iter: 0; batch classifier loss: 0.264415; batch adversarial loss: 0.485736\n",
      "epoch 136; iter: 0; batch classifier loss: 0.328250; batch adversarial loss: 0.523478\n",
      "epoch 137; iter: 0; batch classifier loss: 0.490651; batch adversarial loss: 0.745949\n",
      "epoch 138; iter: 0; batch classifier loss: 0.432827; batch adversarial loss: 0.568551\n",
      "epoch 139; iter: 0; batch classifier loss: 0.346703; batch adversarial loss: 0.553665\n",
      "epoch 140; iter: 0; batch classifier loss: 0.287911; batch adversarial loss: 0.587138\n",
      "epoch 141; iter: 0; batch classifier loss: 0.342118; batch adversarial loss: 0.579927\n",
      "epoch 142; iter: 0; batch classifier loss: 0.452691; batch adversarial loss: 0.598631\n",
      "epoch 143; iter: 0; batch classifier loss: 0.284919; batch adversarial loss: 0.579589\n",
      "epoch 144; iter: 0; batch classifier loss: 0.359179; batch adversarial loss: 0.534022\n",
      "epoch 145; iter: 0; batch classifier loss: 0.357786; batch adversarial loss: 0.574897\n",
      "epoch 146; iter: 0; batch classifier loss: 0.315331; batch adversarial loss: 0.526280\n",
      "epoch 147; iter: 0; batch classifier loss: 0.414242; batch adversarial loss: 0.504206\n",
      "epoch 148; iter: 0; batch classifier loss: 0.339147; batch adversarial loss: 0.528543\n",
      "epoch 149; iter: 0; batch classifier loss: 0.396356; batch adversarial loss: 0.574773\n",
      "epoch 150; iter: 0; batch classifier loss: 0.376754; batch adversarial loss: 0.580593\n",
      "epoch 151; iter: 0; batch classifier loss: 0.340203; batch adversarial loss: 0.592797\n",
      "epoch 152; iter: 0; batch classifier loss: 0.354794; batch adversarial loss: 0.539746\n",
      "epoch 153; iter: 0; batch classifier loss: 0.387963; batch adversarial loss: 0.593567\n",
      "epoch 154; iter: 0; batch classifier loss: 0.311999; batch adversarial loss: 0.590134\n",
      "epoch 155; iter: 0; batch classifier loss: 0.307775; batch adversarial loss: 0.556894\n",
      "epoch 156; iter: 0; batch classifier loss: 0.388976; batch adversarial loss: 0.520186\n",
      "epoch 157; iter: 0; batch classifier loss: 0.328427; batch adversarial loss: 0.475174\n",
      "epoch 158; iter: 0; batch classifier loss: 0.331759; batch adversarial loss: 0.525432\n",
      "epoch 159; iter: 0; batch classifier loss: 0.329241; batch adversarial loss: 0.581807\n",
      "epoch 160; iter: 0; batch classifier loss: 0.307511; batch adversarial loss: 0.564042\n",
      "epoch 161; iter: 0; batch classifier loss: 0.349752; batch adversarial loss: 0.568759\n",
      "epoch 162; iter: 0; batch classifier loss: 0.329185; batch adversarial loss: 0.556517\n",
      "epoch 163; iter: 0; batch classifier loss: 0.409534; batch adversarial loss: 0.581093\n",
      "epoch 164; iter: 0; batch classifier loss: 0.360466; batch adversarial loss: 0.527967\n",
      "epoch 165; iter: 0; batch classifier loss: 0.355051; batch adversarial loss: 0.515166\n",
      "epoch 166; iter: 0; batch classifier loss: 0.424530; batch adversarial loss: 0.596499\n",
      "epoch 167; iter: 0; batch classifier loss: 0.387467; batch adversarial loss: 0.631947\n",
      "epoch 168; iter: 0; batch classifier loss: 0.277979; batch adversarial loss: 0.641168\n",
      "epoch 169; iter: 0; batch classifier loss: 0.302900; batch adversarial loss: 0.588037\n",
      "epoch 170; iter: 0; batch classifier loss: 0.329414; batch adversarial loss: 0.604424\n",
      "epoch 171; iter: 0; batch classifier loss: 0.320319; batch adversarial loss: 0.660366\n",
      "epoch 172; iter: 0; batch classifier loss: 0.322782; batch adversarial loss: 0.561863\n",
      "epoch 173; iter: 0; batch classifier loss: 0.303991; batch adversarial loss: 0.590757\n",
      "epoch 174; iter: 0; batch classifier loss: 0.351302; batch adversarial loss: 0.607649\n",
      "epoch 175; iter: 0; batch classifier loss: 0.276861; batch adversarial loss: 0.528254\n",
      "epoch 176; iter: 0; batch classifier loss: 0.300511; batch adversarial loss: 0.555960\n",
      "epoch 177; iter: 0; batch classifier loss: 0.358198; batch adversarial loss: 0.507375\n",
      "epoch 178; iter: 0; batch classifier loss: 0.378919; batch adversarial loss: 0.604691\n",
      "epoch 179; iter: 0; batch classifier loss: 0.318150; batch adversarial loss: 0.591729\n",
      "epoch 180; iter: 0; batch classifier loss: 0.297956; batch adversarial loss: 0.502767\n",
      "epoch 181; iter: 0; batch classifier loss: 0.307331; batch adversarial loss: 0.508560\n",
      "epoch 182; iter: 0; batch classifier loss: 0.280914; batch adversarial loss: 0.629331\n",
      "epoch 183; iter: 0; batch classifier loss: 0.336274; batch adversarial loss: 0.542106\n",
      "epoch 184; iter: 0; batch classifier loss: 0.261220; batch adversarial loss: 0.509223\n",
      "epoch 185; iter: 0; batch classifier loss: 0.338829; batch adversarial loss: 0.536121\n",
      "epoch 186; iter: 0; batch classifier loss: 0.388319; batch adversarial loss: 0.572196\n",
      "epoch 187; iter: 0; batch classifier loss: 0.371088; batch adversarial loss: 0.622928\n",
      "epoch 188; iter: 0; batch classifier loss: 0.378216; batch adversarial loss: 0.568959\n",
      "epoch 189; iter: 0; batch classifier loss: 0.298597; batch adversarial loss: 0.607045\n",
      "epoch 190; iter: 0; batch classifier loss: 0.309389; batch adversarial loss: 0.526198\n",
      "epoch 191; iter: 0; batch classifier loss: 0.300221; batch adversarial loss: 0.486265\n",
      "epoch 192; iter: 0; batch classifier loss: 0.359955; batch adversarial loss: 0.562608\n",
      "epoch 193; iter: 0; batch classifier loss: 0.332089; batch adversarial loss: 0.622805\n",
      "epoch 194; iter: 0; batch classifier loss: 0.404571; batch adversarial loss: 0.548150\n",
      "epoch 195; iter: 0; batch classifier loss: 0.350221; batch adversarial loss: 0.509048\n",
      "epoch 196; iter: 0; batch classifier loss: 0.370287; batch adversarial loss: 0.610331\n",
      "epoch 197; iter: 0; batch classifier loss: 0.287893; batch adversarial loss: 0.652401\n",
      "epoch 198; iter: 0; batch classifier loss: 0.328228; batch adversarial loss: 0.577819\n",
      "epoch 199; iter: 0; batch classifier loss: 0.346760; batch adversarial loss: 0.431900\n",
      "epoch 0; iter: 0; batch classifier loss: 0.659260; batch adversarial loss: 0.688698\n",
      "epoch 1; iter: 0; batch classifier loss: 0.681247; batch adversarial loss: 0.663557\n",
      "epoch 2; iter: 0; batch classifier loss: 0.664340; batch adversarial loss: 0.639767\n",
      "epoch 3; iter: 0; batch classifier loss: 0.590702; batch adversarial loss: 0.609556\n",
      "epoch 4; iter: 0; batch classifier loss: 0.486470; batch adversarial loss: 0.624481\n",
      "epoch 5; iter: 0; batch classifier loss: 0.630550; batch adversarial loss: 0.611088\n",
      "epoch 6; iter: 0; batch classifier loss: 0.525723; batch adversarial loss: 0.588705\n",
      "epoch 7; iter: 0; batch classifier loss: 0.481414; batch adversarial loss: 0.611099\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8; iter: 0; batch classifier loss: 0.523866; batch adversarial loss: 0.586884\n",
      "epoch 9; iter: 0; batch classifier loss: 0.527680; batch adversarial loss: 0.555277\n",
      "epoch 10; iter: 0; batch classifier loss: 0.525619; batch adversarial loss: 0.577917\n",
      "epoch 11; iter: 0; batch classifier loss: 0.530362; batch adversarial loss: 0.564440\n",
      "epoch 12; iter: 0; batch classifier loss: 0.531238; batch adversarial loss: 0.574433\n",
      "epoch 13; iter: 0; batch classifier loss: 0.538580; batch adversarial loss: 0.551342\n",
      "epoch 14; iter: 0; batch classifier loss: 0.507333; batch adversarial loss: 0.521817\n",
      "epoch 15; iter: 0; batch classifier loss: 0.508565; batch adversarial loss: 0.524261\n",
      "epoch 16; iter: 0; batch classifier loss: 0.545027; batch adversarial loss: 0.543991\n",
      "epoch 17; iter: 0; batch classifier loss: 0.516739; batch adversarial loss: 0.535420\n",
      "epoch 18; iter: 0; batch classifier loss: 0.489131; batch adversarial loss: 0.622988\n",
      "epoch 19; iter: 0; batch classifier loss: 0.557193; batch adversarial loss: 0.592297\n",
      "epoch 20; iter: 0; batch classifier loss: 0.394841; batch adversarial loss: 0.588433\n",
      "epoch 21; iter: 0; batch classifier loss: 0.423629; batch adversarial loss: 0.602425\n",
      "epoch 22; iter: 0; batch classifier loss: 0.555169; batch adversarial loss: 0.533015\n",
      "epoch 23; iter: 0; batch classifier loss: 0.515005; batch adversarial loss: 0.581898\n",
      "epoch 24; iter: 0; batch classifier loss: 0.442248; batch adversarial loss: 0.546098\n",
      "epoch 25; iter: 0; batch classifier loss: 0.451376; batch adversarial loss: 0.622745\n",
      "epoch 26; iter: 0; batch classifier loss: 0.487276; batch adversarial loss: 0.521270\n",
      "epoch 27; iter: 0; batch classifier loss: 0.457032; batch adversarial loss: 0.573906\n",
      "epoch 28; iter: 0; batch classifier loss: 0.460776; batch adversarial loss: 0.499366\n",
      "epoch 29; iter: 0; batch classifier loss: 0.530692; batch adversarial loss: 0.506506\n",
      "epoch 30; iter: 0; batch classifier loss: 0.500282; batch adversarial loss: 0.570695\n",
      "epoch 31; iter: 0; batch classifier loss: 0.455060; batch adversarial loss: 0.551765\n",
      "epoch 32; iter: 0; batch classifier loss: 0.503383; batch adversarial loss: 0.646775\n",
      "epoch 33; iter: 0; batch classifier loss: 0.440183; batch adversarial loss: 0.521423\n",
      "epoch 34; iter: 0; batch classifier loss: 0.476449; batch adversarial loss: 0.519814\n",
      "epoch 35; iter: 0; batch classifier loss: 0.488335; batch adversarial loss: 0.608058\n",
      "epoch 36; iter: 0; batch classifier loss: 0.478093; batch adversarial loss: 0.562625\n",
      "epoch 37; iter: 0; batch classifier loss: 0.457144; batch adversarial loss: 0.582931\n",
      "epoch 38; iter: 0; batch classifier loss: 0.464430; batch adversarial loss: 0.521814\n",
      "epoch 39; iter: 0; batch classifier loss: 0.477489; batch adversarial loss: 0.564312\n",
      "epoch 40; iter: 0; batch classifier loss: 0.498685; batch adversarial loss: 0.623003\n",
      "epoch 41; iter: 0; batch classifier loss: 0.374509; batch adversarial loss: 0.509881\n",
      "epoch 42; iter: 0; batch classifier loss: 0.490719; batch adversarial loss: 0.572542\n",
      "epoch 43; iter: 0; batch classifier loss: 0.431013; batch adversarial loss: 0.517344\n",
      "epoch 44; iter: 0; batch classifier loss: 0.471913; batch adversarial loss: 0.587473\n",
      "epoch 45; iter: 0; batch classifier loss: 0.391832; batch adversarial loss: 0.535078\n",
      "epoch 46; iter: 0; batch classifier loss: 0.404498; batch adversarial loss: 0.544143\n",
      "epoch 47; iter: 0; batch classifier loss: 0.469510; batch adversarial loss: 0.545042\n",
      "epoch 48; iter: 0; batch classifier loss: 0.383475; batch adversarial loss: 0.526459\n",
      "epoch 49; iter: 0; batch classifier loss: 0.368358; batch adversarial loss: 0.572177\n",
      "epoch 50; iter: 0; batch classifier loss: 0.432878; batch adversarial loss: 0.581360\n",
      "epoch 51; iter: 0; batch classifier loss: 0.399558; batch adversarial loss: 0.464538\n",
      "epoch 52; iter: 0; batch classifier loss: 0.346355; batch adversarial loss: 0.626404\n",
      "epoch 53; iter: 0; batch classifier loss: 0.450348; batch adversarial loss: 0.534809\n",
      "epoch 54; iter: 0; batch classifier loss: 0.430830; batch adversarial loss: 0.507577\n",
      "epoch 55; iter: 0; batch classifier loss: 0.404395; batch adversarial loss: 0.600034\n",
      "epoch 56; iter: 0; batch classifier loss: 0.409060; batch adversarial loss: 0.469687\n",
      "epoch 57; iter: 0; batch classifier loss: 0.376630; batch adversarial loss: 0.489206\n",
      "epoch 58; iter: 0; batch classifier loss: 0.492888; batch adversarial loss: 0.535380\n",
      "epoch 59; iter: 0; batch classifier loss: 0.410050; batch adversarial loss: 0.527123\n",
      "epoch 60; iter: 0; batch classifier loss: 0.433789; batch adversarial loss: 0.482168\n",
      "epoch 61; iter: 0; batch classifier loss: 0.404229; batch adversarial loss: 0.535529\n",
      "epoch 62; iter: 0; batch classifier loss: 0.419310; batch adversarial loss: 0.563295\n",
      "epoch 63; iter: 0; batch classifier loss: 0.405721; batch adversarial loss: 0.644410\n",
      "epoch 64; iter: 0; batch classifier loss: 0.414976; batch adversarial loss: 0.626047\n",
      "epoch 65; iter: 0; batch classifier loss: 0.423487; batch adversarial loss: 0.564297\n",
      "epoch 66; iter: 0; batch classifier loss: 0.369566; batch adversarial loss: 0.499398\n",
      "epoch 67; iter: 0; batch classifier loss: 0.383674; batch adversarial loss: 0.535594\n",
      "epoch 68; iter: 0; batch classifier loss: 0.432134; batch adversarial loss: 0.553584\n",
      "epoch 69; iter: 0; batch classifier loss: 0.432575; batch adversarial loss: 0.490191\n",
      "epoch 70; iter: 0; batch classifier loss: 0.430170; batch adversarial loss: 0.535344\n",
      "epoch 71; iter: 0; batch classifier loss: 0.376156; batch adversarial loss: 0.589947\n",
      "epoch 72; iter: 0; batch classifier loss: 0.388071; batch adversarial loss: 0.481138\n",
      "epoch 73; iter: 0; batch classifier loss: 0.392621; batch adversarial loss: 0.599063\n",
      "epoch 74; iter: 0; batch classifier loss: 0.454915; batch adversarial loss: 0.553566\n",
      "epoch 75; iter: 0; batch classifier loss: 0.356178; batch adversarial loss: 0.517214\n",
      "epoch 76; iter: 0; batch classifier loss: 0.395611; batch adversarial loss: 0.490185\n",
      "epoch 77; iter: 0; batch classifier loss: 0.416846; batch adversarial loss: 0.580544\n",
      "epoch 78; iter: 0; batch classifier loss: 0.458497; batch adversarial loss: 0.535383\n",
      "epoch 79; iter: 0; batch classifier loss: 0.408868; batch adversarial loss: 0.535328\n",
      "epoch 80; iter: 0; batch classifier loss: 0.375062; batch adversarial loss: 0.526150\n",
      "epoch 81; iter: 0; batch classifier loss: 0.405252; batch adversarial loss: 0.572108\n",
      "epoch 82; iter: 0; batch classifier loss: 0.384628; batch adversarial loss: 0.544276\n",
      "epoch 83; iter: 0; batch classifier loss: 0.397810; batch adversarial loss: 0.516926\n",
      "epoch 84; iter: 0; batch classifier loss: 0.407026; batch adversarial loss: 0.582134\n",
      "epoch 85; iter: 0; batch classifier loss: 0.398282; batch adversarial loss: 0.563433\n",
      "epoch 86; iter: 0; batch classifier loss: 0.410400; batch adversarial loss: 0.574194\n",
      "epoch 87; iter: 0; batch classifier loss: 0.349270; batch adversarial loss: 0.526675\n",
      "epoch 88; iter: 0; batch classifier loss: 0.340444; batch adversarial loss: 0.545836\n",
      "epoch 89; iter: 0; batch classifier loss: 0.305608; batch adversarial loss: 0.517432\n",
      "epoch 90; iter: 0; batch classifier loss: 0.374226; batch adversarial loss: 0.562136\n",
      "epoch 91; iter: 0; batch classifier loss: 0.413077; batch adversarial loss: 0.552864\n",
      "epoch 92; iter: 0; batch classifier loss: 0.390656; batch adversarial loss: 0.507161\n",
      "epoch 93; iter: 0; batch classifier loss: 0.377774; batch adversarial loss: 0.532780\n",
      "epoch 94; iter: 0; batch classifier loss: 0.393642; batch adversarial loss: 0.619147\n",
      "epoch 95; iter: 0; batch classifier loss: 0.443760; batch adversarial loss: 0.487202\n",
      "epoch 96; iter: 0; batch classifier loss: 0.442639; batch adversarial loss: 0.553595\n",
      "epoch 97; iter: 0; batch classifier loss: 0.395490; batch adversarial loss: 0.581393\n",
      "epoch 98; iter: 0; batch classifier loss: 0.411039; batch adversarial loss: 0.626664\n",
      "epoch 99; iter: 0; batch classifier loss: 0.539544; batch adversarial loss: 0.599438\n",
      "epoch 100; iter: 0; batch classifier loss: 0.334549; batch adversarial loss: 0.535896\n",
      "epoch 101; iter: 0; batch classifier loss: 0.344961; batch adversarial loss: 0.544579\n",
      "epoch 102; iter: 0; batch classifier loss: 0.385762; batch adversarial loss: 0.508545\n",
      "epoch 103; iter: 0; batch classifier loss: 0.445556; batch adversarial loss: 0.490474\n",
      "epoch 104; iter: 0; batch classifier loss: 0.327286; batch adversarial loss: 0.535464\n",
      "epoch 105; iter: 0; batch classifier loss: 0.431617; batch adversarial loss: 0.553496\n",
      "epoch 106; iter: 0; batch classifier loss: 0.431679; batch adversarial loss: 0.526180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 107; iter: 0; batch classifier loss: 0.356801; batch adversarial loss: 0.562365\n",
      "epoch 108; iter: 0; batch classifier loss: 0.458692; batch adversarial loss: 0.489936\n",
      "epoch 109; iter: 0; batch classifier loss: 0.383272; batch adversarial loss: 0.508750\n",
      "epoch 110; iter: 0; batch classifier loss: 0.310466; batch adversarial loss: 0.435169\n",
      "epoch 111; iter: 0; batch classifier loss: 0.406759; batch adversarial loss: 0.499726\n",
      "epoch 112; iter: 0; batch classifier loss: 0.327574; batch adversarial loss: 0.544888\n",
      "epoch 113; iter: 0; batch classifier loss: 0.396046; batch adversarial loss: 0.589817\n",
      "epoch 114; iter: 0; batch classifier loss: 0.437785; batch adversarial loss: 0.589643\n",
      "epoch 115; iter: 0; batch classifier loss: 0.379170; batch adversarial loss: 0.544526\n",
      "epoch 116; iter: 0; batch classifier loss: 0.429356; batch adversarial loss: 0.653422\n",
      "epoch 117; iter: 0; batch classifier loss: 0.337168; batch adversarial loss: 0.508203\n",
      "epoch 118; iter: 0; batch classifier loss: 0.395015; batch adversarial loss: 0.489964\n",
      "epoch 119; iter: 0; batch classifier loss: 0.379755; batch adversarial loss: 0.608440\n",
      "epoch 120; iter: 0; batch classifier loss: 0.356711; batch adversarial loss: 0.525737\n",
      "epoch 121; iter: 0; batch classifier loss: 0.442031; batch adversarial loss: 0.553165\n",
      "epoch 122; iter: 0; batch classifier loss: 0.406397; batch adversarial loss: 0.582003\n",
      "epoch 123; iter: 0; batch classifier loss: 0.428273; batch adversarial loss: 0.525526\n",
      "epoch 124; iter: 0; batch classifier loss: 0.340148; batch adversarial loss: 0.498460\n",
      "epoch 125; iter: 0; batch classifier loss: 0.363455; batch adversarial loss: 0.490532\n",
      "epoch 126; iter: 0; batch classifier loss: 0.373612; batch adversarial loss: 0.616919\n",
      "epoch 127; iter: 0; batch classifier loss: 0.358130; batch adversarial loss: 0.444340\n",
      "epoch 128; iter: 0; batch classifier loss: 0.418273; batch adversarial loss: 0.462638\n",
      "epoch 129; iter: 0; batch classifier loss: 0.368034; batch adversarial loss: 0.526253\n",
      "epoch 130; iter: 0; batch classifier loss: 0.421135; batch adversarial loss: 0.626602\n",
      "epoch 131; iter: 0; batch classifier loss: 0.325566; batch adversarial loss: 0.553496\n",
      "epoch 132; iter: 0; batch classifier loss: 0.350509; batch adversarial loss: 0.526578\n",
      "epoch 133; iter: 0; batch classifier loss: 0.399884; batch adversarial loss: 0.499054\n",
      "epoch 134; iter: 0; batch classifier loss: 0.370363; batch adversarial loss: 0.553711\n",
      "epoch 135; iter: 0; batch classifier loss: 0.434915; batch adversarial loss: 0.544596\n",
      "epoch 136; iter: 0; batch classifier loss: 0.428782; batch adversarial loss: 0.517011\n",
      "epoch 137; iter: 0; batch classifier loss: 0.355782; batch adversarial loss: 0.498860\n",
      "epoch 138; iter: 0; batch classifier loss: 0.353773; batch adversarial loss: 0.580787\n",
      "epoch 139; iter: 0; batch classifier loss: 0.461410; batch adversarial loss: 0.525577\n",
      "epoch 140; iter: 0; batch classifier loss: 0.355732; batch adversarial loss: 0.572338\n",
      "epoch 141; iter: 0; batch classifier loss: 0.379671; batch adversarial loss: 0.553727\n",
      "epoch 142; iter: 0; batch classifier loss: 0.404162; batch adversarial loss: 0.562721\n",
      "epoch 143; iter: 0; batch classifier loss: 0.401319; batch adversarial loss: 0.580589\n",
      "epoch 144; iter: 0; batch classifier loss: 0.464461; batch adversarial loss: 0.580644\n",
      "epoch 145; iter: 0; batch classifier loss: 0.377104; batch adversarial loss: 0.544521\n",
      "epoch 146; iter: 0; batch classifier loss: 0.415813; batch adversarial loss: 0.571828\n",
      "epoch 147; iter: 0; batch classifier loss: 0.330850; batch adversarial loss: 0.562757\n",
      "epoch 148; iter: 0; batch classifier loss: 0.397951; batch adversarial loss: 0.471528\n",
      "epoch 149; iter: 0; batch classifier loss: 0.373260; batch adversarial loss: 0.507794\n",
      "epoch 150; iter: 0; batch classifier loss: 0.299246; batch adversarial loss: 0.645345\n",
      "epoch 151; iter: 0; batch classifier loss: 0.316836; batch adversarial loss: 0.553188\n",
      "epoch 152; iter: 0; batch classifier loss: 0.367392; batch adversarial loss: 0.599295\n",
      "epoch 153; iter: 0; batch classifier loss: 0.357690; batch adversarial loss: 0.553522\n",
      "epoch 154; iter: 0; batch classifier loss: 0.398871; batch adversarial loss: 0.544522\n",
      "epoch 155; iter: 0; batch classifier loss: 0.313653; batch adversarial loss: 0.607874\n",
      "epoch 156; iter: 0; batch classifier loss: 0.419822; batch adversarial loss: 0.572239\n",
      "epoch 157; iter: 0; batch classifier loss: 0.306363; batch adversarial loss: 0.517341\n",
      "epoch 158; iter: 0; batch classifier loss: 0.344885; batch adversarial loss: 0.525815\n",
      "epoch 159; iter: 0; batch classifier loss: 0.468185; batch adversarial loss: 0.563046\n",
      "epoch 160; iter: 0; batch classifier loss: 0.423957; batch adversarial loss: 0.490123\n",
      "epoch 161; iter: 0; batch classifier loss: 0.418874; batch adversarial loss: 0.544630\n",
      "epoch 162; iter: 0; batch classifier loss: 0.368383; batch adversarial loss: 0.499196\n",
      "epoch 163; iter: 0; batch classifier loss: 0.398659; batch adversarial loss: 0.489923\n",
      "epoch 164; iter: 0; batch classifier loss: 0.353011; batch adversarial loss: 0.517393\n",
      "epoch 165; iter: 0; batch classifier loss: 0.319712; batch adversarial loss: 0.617658\n",
      "epoch 166; iter: 0; batch classifier loss: 0.320917; batch adversarial loss: 0.562981\n",
      "epoch 167; iter: 0; batch classifier loss: 0.307817; batch adversarial loss: 0.490021\n",
      "epoch 168; iter: 0; batch classifier loss: 0.272239; batch adversarial loss: 0.526415\n",
      "epoch 169; iter: 0; batch classifier loss: 0.372066; batch adversarial loss: 0.581091\n",
      "epoch 170; iter: 0; batch classifier loss: 0.339185; batch adversarial loss: 0.517065\n",
      "epoch 171; iter: 0; batch classifier loss: 0.359610; batch adversarial loss: 0.498959\n",
      "epoch 172; iter: 0; batch classifier loss: 0.423221; batch adversarial loss: 0.535519\n",
      "epoch 173; iter: 0; batch classifier loss: 0.428551; batch adversarial loss: 0.581214\n",
      "epoch 174; iter: 0; batch classifier loss: 0.332091; batch adversarial loss: 0.571712\n",
      "epoch 175; iter: 0; batch classifier loss: 0.389545; batch adversarial loss: 0.498917\n",
      "epoch 176; iter: 0; batch classifier loss: 0.312683; batch adversarial loss: 0.672104\n",
      "epoch 177; iter: 0; batch classifier loss: 0.343399; batch adversarial loss: 0.462400\n",
      "epoch 178; iter: 0; batch classifier loss: 0.323680; batch adversarial loss: 0.498980\n",
      "epoch 179; iter: 0; batch classifier loss: 0.411724; batch adversarial loss: 0.590137\n",
      "epoch 180; iter: 0; batch classifier loss: 0.344887; batch adversarial loss: 0.498903\n",
      "epoch 181; iter: 0; batch classifier loss: 0.423564; batch adversarial loss: 0.526246\n",
      "epoch 182; iter: 0; batch classifier loss: 0.381652; batch adversarial loss: 0.655115\n",
      "epoch 183; iter: 0; batch classifier loss: 0.386302; batch adversarial loss: 0.553305\n",
      "epoch 184; iter: 0; batch classifier loss: 0.361593; batch adversarial loss: 0.581296\n",
      "epoch 185; iter: 0; batch classifier loss: 0.408933; batch adversarial loss: 0.490113\n",
      "epoch 186; iter: 0; batch classifier loss: 0.291282; batch adversarial loss: 0.626451\n",
      "epoch 187; iter: 0; batch classifier loss: 0.351442; batch adversarial loss: 0.481062\n",
      "epoch 188; iter: 0; batch classifier loss: 0.408030; batch adversarial loss: 0.581084\n",
      "epoch 189; iter: 0; batch classifier loss: 0.357854; batch adversarial loss: 0.635308\n",
      "epoch 190; iter: 0; batch classifier loss: 0.433005; batch adversarial loss: 0.544612\n",
      "epoch 191; iter: 0; batch classifier loss: 0.387609; batch adversarial loss: 0.562867\n",
      "epoch 192; iter: 0; batch classifier loss: 0.301676; batch adversarial loss: 0.581009\n",
      "epoch 193; iter: 0; batch classifier loss: 0.383832; batch adversarial loss: 0.526198\n",
      "epoch 194; iter: 0; batch classifier loss: 0.298455; batch adversarial loss: 0.589890\n",
      "epoch 195; iter: 0; batch classifier loss: 0.334788; batch adversarial loss: 0.544676\n",
      "epoch 196; iter: 0; batch classifier loss: 0.383970; batch adversarial loss: 0.626682\n",
      "epoch 197; iter: 0; batch classifier loss: 0.309877; batch adversarial loss: 0.599251\n",
      "epoch 198; iter: 0; batch classifier loss: 0.287428; batch adversarial loss: 0.535644\n",
      "epoch 199; iter: 0; batch classifier loss: 0.300090; batch adversarial loss: 0.498916\n",
      "epoch 0; iter: 0; batch classifier loss: 0.643054; batch adversarial loss: 0.704101\n",
      "epoch 1; iter: 0; batch classifier loss: 0.668453; batch adversarial loss: 0.708380\n",
      "epoch 2; iter: 0; batch classifier loss: 0.619826; batch adversarial loss: 0.685289\n",
      "epoch 3; iter: 0; batch classifier loss: 0.553240; batch adversarial loss: 0.674799\n",
      "epoch 4; iter: 0; batch classifier loss: 0.570753; batch adversarial loss: 0.610046\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5; iter: 0; batch classifier loss: 0.535860; batch adversarial loss: 0.621944\n",
      "epoch 6; iter: 0; batch classifier loss: 0.570624; batch adversarial loss: 0.583830\n",
      "epoch 7; iter: 0; batch classifier loss: 0.543900; batch adversarial loss: 0.583355\n",
      "epoch 8; iter: 0; batch classifier loss: 0.508254; batch adversarial loss: 0.600399\n",
      "epoch 9; iter: 0; batch classifier loss: 0.499538; batch adversarial loss: 0.605573\n",
      "epoch 10; iter: 0; batch classifier loss: 0.537231; batch adversarial loss: 0.612367\n",
      "epoch 11; iter: 0; batch classifier loss: 0.581196; batch adversarial loss: 0.593780\n",
      "epoch 12; iter: 0; batch classifier loss: 0.498301; batch adversarial loss: 0.606767\n",
      "epoch 13; iter: 0; batch classifier loss: 0.499065; batch adversarial loss: 0.535803\n",
      "epoch 14; iter: 0; batch classifier loss: 0.448304; batch adversarial loss: 0.600285\n",
      "epoch 15; iter: 0; batch classifier loss: 0.534553; batch adversarial loss: 0.608990\n",
      "epoch 16; iter: 0; batch classifier loss: 0.528520; batch adversarial loss: 0.590075\n",
      "epoch 17; iter: 0; batch classifier loss: 0.500002; batch adversarial loss: 0.603290\n",
      "epoch 18; iter: 0; batch classifier loss: 0.511648; batch adversarial loss: 0.537199\n",
      "epoch 19; iter: 0; batch classifier loss: 0.540653; batch adversarial loss: 0.540382\n",
      "epoch 20; iter: 0; batch classifier loss: 0.510911; batch adversarial loss: 0.516931\n",
      "epoch 21; iter: 0; batch classifier loss: 0.453786; batch adversarial loss: 0.618346\n",
      "epoch 22; iter: 0; batch classifier loss: 0.524666; batch adversarial loss: 0.559723\n",
      "epoch 23; iter: 0; batch classifier loss: 0.480474; batch adversarial loss: 0.617630\n",
      "epoch 24; iter: 0; batch classifier loss: 0.451040; batch adversarial loss: 0.533650\n",
      "epoch 25; iter: 0; batch classifier loss: 0.400277; batch adversarial loss: 0.456024\n",
      "epoch 26; iter: 0; batch classifier loss: 0.465832; batch adversarial loss: 0.559734\n",
      "epoch 27; iter: 0; batch classifier loss: 0.526386; batch adversarial loss: 0.582099\n",
      "epoch 28; iter: 0; batch classifier loss: 0.510335; batch adversarial loss: 0.571029\n",
      "epoch 29; iter: 0; batch classifier loss: 0.459432; batch adversarial loss: 0.545018\n",
      "epoch 30; iter: 0; batch classifier loss: 0.449033; batch adversarial loss: 0.550741\n",
      "epoch 31; iter: 0; batch classifier loss: 0.451850; batch adversarial loss: 0.598560\n",
      "epoch 32; iter: 0; batch classifier loss: 0.422453; batch adversarial loss: 0.506903\n",
      "epoch 33; iter: 0; batch classifier loss: 0.474836; batch adversarial loss: 0.520672\n",
      "epoch 34; iter: 0; batch classifier loss: 0.468179; batch adversarial loss: 0.545650\n",
      "epoch 35; iter: 0; batch classifier loss: 0.534187; batch adversarial loss: 0.606937\n",
      "epoch 36; iter: 0; batch classifier loss: 0.418791; batch adversarial loss: 0.546680\n",
      "epoch 37; iter: 0; batch classifier loss: 0.459740; batch adversarial loss: 0.546019\n",
      "epoch 38; iter: 0; batch classifier loss: 0.443721; batch adversarial loss: 0.510058\n",
      "epoch 39; iter: 0; batch classifier loss: 0.382138; batch adversarial loss: 0.570954\n",
      "epoch 40; iter: 0; batch classifier loss: 0.448824; batch adversarial loss: 0.527478\n",
      "epoch 41; iter: 0; batch classifier loss: 0.472720; batch adversarial loss: 0.536684\n",
      "epoch 42; iter: 0; batch classifier loss: 0.453652; batch adversarial loss: 0.500283\n",
      "epoch 43; iter: 0; batch classifier loss: 0.427795; batch adversarial loss: 0.625047\n",
      "epoch 44; iter: 0; batch classifier loss: 0.367557; batch adversarial loss: 0.580514\n",
      "epoch 45; iter: 0; batch classifier loss: 0.440183; batch adversarial loss: 0.526139\n",
      "epoch 46; iter: 0; batch classifier loss: 0.460124; batch adversarial loss: 0.571606\n",
      "epoch 47; iter: 0; batch classifier loss: 0.469866; batch adversarial loss: 0.598852\n",
      "epoch 48; iter: 0; batch classifier loss: 0.503871; batch adversarial loss: 0.496313\n",
      "epoch 49; iter: 0; batch classifier loss: 0.475453; batch adversarial loss: 0.610036\n",
      "epoch 50; iter: 0; batch classifier loss: 0.470100; batch adversarial loss: 0.517002\n",
      "epoch 51; iter: 0; batch classifier loss: 0.453782; batch adversarial loss: 0.571910\n",
      "epoch 52; iter: 0; batch classifier loss: 0.375788; batch adversarial loss: 0.563826\n",
      "epoch 53; iter: 0; batch classifier loss: 0.375630; batch adversarial loss: 0.590247\n",
      "epoch 54; iter: 0; batch classifier loss: 0.386908; batch adversarial loss: 0.590238\n",
      "epoch 55; iter: 0; batch classifier loss: 0.450188; batch adversarial loss: 0.630180\n",
      "epoch 56; iter: 0; batch classifier loss: 0.438416; batch adversarial loss: 0.481887\n",
      "epoch 57; iter: 0; batch classifier loss: 0.403304; batch adversarial loss: 0.563055\n",
      "epoch 58; iter: 0; batch classifier loss: 0.454833; batch adversarial loss: 0.527839\n",
      "epoch 59; iter: 0; batch classifier loss: 0.402302; batch adversarial loss: 0.571692\n",
      "epoch 60; iter: 0; batch classifier loss: 0.403758; batch adversarial loss: 0.544333\n",
      "epoch 61; iter: 0; batch classifier loss: 0.454440; batch adversarial loss: 0.527142\n",
      "epoch 62; iter: 0; batch classifier loss: 0.411727; batch adversarial loss: 0.508773\n",
      "epoch 63; iter: 0; batch classifier loss: 0.453348; batch adversarial loss: 0.534151\n",
      "epoch 64; iter: 0; batch classifier loss: 0.438272; batch adversarial loss: 0.598004\n",
      "epoch 65; iter: 0; batch classifier loss: 0.447066; batch adversarial loss: 0.525521\n",
      "epoch 66; iter: 0; batch classifier loss: 0.417139; batch adversarial loss: 0.517980\n",
      "epoch 67; iter: 0; batch classifier loss: 0.336473; batch adversarial loss: 0.527753\n",
      "epoch 68; iter: 0; batch classifier loss: 0.403324; batch adversarial loss: 0.589194\n",
      "epoch 69; iter: 0; batch classifier loss: 0.366574; batch adversarial loss: 0.508812\n",
      "epoch 70; iter: 0; batch classifier loss: 0.472392; batch adversarial loss: 0.580979\n",
      "epoch 71; iter: 0; batch classifier loss: 0.484807; batch adversarial loss: 0.552643\n",
      "epoch 72; iter: 0; batch classifier loss: 0.331559; batch adversarial loss: 0.571382\n",
      "epoch 73; iter: 0; batch classifier loss: 0.379337; batch adversarial loss: 0.580382\n",
      "epoch 74; iter: 0; batch classifier loss: 0.389375; batch adversarial loss: 0.572036\n",
      "epoch 75; iter: 0; batch classifier loss: 0.479281; batch adversarial loss: 0.536312\n",
      "epoch 76; iter: 0; batch classifier loss: 0.421664; batch adversarial loss: 0.507290\n",
      "epoch 77; iter: 0; batch classifier loss: 0.396460; batch adversarial loss: 0.541894\n",
      "epoch 78; iter: 0; batch classifier loss: 0.379747; batch adversarial loss: 0.478935\n",
      "epoch 79; iter: 0; batch classifier loss: 0.398505; batch adversarial loss: 0.507644\n",
      "epoch 80; iter: 0; batch classifier loss: 0.424595; batch adversarial loss: 0.523944\n",
      "epoch 81; iter: 0; batch classifier loss: 0.501494; batch adversarial loss: 0.618315\n",
      "epoch 82; iter: 0; batch classifier loss: 0.499501; batch adversarial loss: 0.551335\n",
      "epoch 83; iter: 0; batch classifier loss: 0.406200; batch adversarial loss: 0.511271\n",
      "epoch 84; iter: 0; batch classifier loss: 0.399828; batch adversarial loss: 0.605802\n",
      "epoch 85; iter: 0; batch classifier loss: 0.439496; batch adversarial loss: 0.481465\n",
      "epoch 86; iter: 0; batch classifier loss: 0.426996; batch adversarial loss: 0.565486\n",
      "epoch 87; iter: 0; batch classifier loss: 0.351438; batch adversarial loss: 0.576253\n",
      "epoch 88; iter: 0; batch classifier loss: 0.392434; batch adversarial loss: 0.475943\n",
      "epoch 89; iter: 0; batch classifier loss: 0.435140; batch adversarial loss: 0.594851\n",
      "epoch 90; iter: 0; batch classifier loss: 0.318310; batch adversarial loss: 0.529717\n",
      "epoch 91; iter: 0; batch classifier loss: 0.390399; batch adversarial loss: 0.521011\n",
      "epoch 92; iter: 0; batch classifier loss: 0.393238; batch adversarial loss: 0.574516\n",
      "epoch 93; iter: 0; batch classifier loss: 0.332529; batch adversarial loss: 0.614749\n",
      "epoch 94; iter: 0; batch classifier loss: 0.425201; batch adversarial loss: 0.572485\n",
      "epoch 95; iter: 0; batch classifier loss: 0.435322; batch adversarial loss: 0.553570\n",
      "epoch 96; iter: 0; batch classifier loss: 0.303657; batch adversarial loss: 0.606095\n",
      "epoch 97; iter: 0; batch classifier loss: 0.350772; batch adversarial loss: 0.544490\n",
      "epoch 98; iter: 0; batch classifier loss: 0.386153; batch adversarial loss: 0.526124\n",
      "epoch 99; iter: 0; batch classifier loss: 0.400773; batch adversarial loss: 0.543523\n",
      "epoch 100; iter: 0; batch classifier loss: 0.422752; batch adversarial loss: 0.517435\n",
      "epoch 101; iter: 0; batch classifier loss: 0.455798; batch adversarial loss: 0.578521\n",
      "epoch 102; iter: 0; batch classifier loss: 0.333074; batch adversarial loss: 0.561596\n",
      "epoch 103; iter: 0; batch classifier loss: 0.396908; batch adversarial loss: 0.617067\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 104; iter: 0; batch classifier loss: 0.382132; batch adversarial loss: 0.509608\n",
      "epoch 105; iter: 0; batch classifier loss: 0.373975; batch adversarial loss: 0.570528\n",
      "epoch 106; iter: 0; batch classifier loss: 0.397205; batch adversarial loss: 0.563245\n",
      "epoch 107; iter: 0; batch classifier loss: 0.458913; batch adversarial loss: 0.536378\n",
      "epoch 108; iter: 0; batch classifier loss: 0.373883; batch adversarial loss: 0.572289\n",
      "epoch 109; iter: 0; batch classifier loss: 0.347558; batch adversarial loss: 0.524414\n",
      "epoch 110; iter: 0; batch classifier loss: 0.361487; batch adversarial loss: 0.554818\n",
      "epoch 111; iter: 0; batch classifier loss: 0.345899; batch adversarial loss: 0.577507\n",
      "epoch 112; iter: 0; batch classifier loss: 0.367161; batch adversarial loss: 0.547135\n",
      "epoch 113; iter: 0; batch classifier loss: 0.456989; batch adversarial loss: 0.536309\n",
      "epoch 114; iter: 0; batch classifier loss: 0.355184; batch adversarial loss: 0.509308\n",
      "epoch 115; iter: 0; batch classifier loss: 0.363732; batch adversarial loss: 0.608309\n",
      "epoch 116; iter: 0; batch classifier loss: 0.354770; batch adversarial loss: 0.580598\n",
      "epoch 117; iter: 0; batch classifier loss: 0.407821; batch adversarial loss: 0.554004\n",
      "epoch 118; iter: 0; batch classifier loss: 0.357960; batch adversarial loss: 0.534806\n",
      "epoch 119; iter: 0; batch classifier loss: 0.364917; batch adversarial loss: 0.509158\n",
      "epoch 120; iter: 0; batch classifier loss: 0.421738; batch adversarial loss: 0.515679\n",
      "epoch 121; iter: 0; batch classifier loss: 0.424541; batch adversarial loss: 0.579586\n",
      "epoch 122; iter: 0; batch classifier loss: 0.406374; batch adversarial loss: 0.588802\n",
      "epoch 123; iter: 0; batch classifier loss: 0.446620; batch adversarial loss: 0.574987\n",
      "epoch 124; iter: 0; batch classifier loss: 0.331237; batch adversarial loss: 0.571954\n",
      "epoch 125; iter: 0; batch classifier loss: 0.392217; batch adversarial loss: 0.533385\n",
      "epoch 126; iter: 0; batch classifier loss: 0.424876; batch adversarial loss: 0.577670\n",
      "epoch 127; iter: 0; batch classifier loss: 0.321836; batch adversarial loss: 0.626003\n",
      "epoch 128; iter: 0; batch classifier loss: 0.354303; batch adversarial loss: 0.508469\n",
      "epoch 129; iter: 0; batch classifier loss: 0.375175; batch adversarial loss: 0.491365\n",
      "epoch 130; iter: 0; batch classifier loss: 0.363735; batch adversarial loss: 0.486563\n",
      "epoch 131; iter: 0; batch classifier loss: 0.378264; batch adversarial loss: 0.617389\n",
      "epoch 132; iter: 0; batch classifier loss: 0.420102; batch adversarial loss: 0.463980\n",
      "epoch 133; iter: 0; batch classifier loss: 0.405637; batch adversarial loss: 0.553752\n",
      "epoch 134; iter: 0; batch classifier loss: 0.345291; batch adversarial loss: 0.527924\n",
      "epoch 135; iter: 0; batch classifier loss: 0.335755; batch adversarial loss: 0.572714\n",
      "epoch 136; iter: 0; batch classifier loss: 0.369858; batch adversarial loss: 0.534368\n",
      "epoch 137; iter: 0; batch classifier loss: 0.371552; batch adversarial loss: 0.596528\n",
      "epoch 138; iter: 0; batch classifier loss: 0.359273; batch adversarial loss: 0.544415\n",
      "epoch 139; iter: 0; batch classifier loss: 0.451746; batch adversarial loss: 0.536230\n",
      "epoch 140; iter: 0; batch classifier loss: 0.403665; batch adversarial loss: 0.546591\n",
      "epoch 141; iter: 0; batch classifier loss: 0.334761; batch adversarial loss: 0.545608\n",
      "epoch 142; iter: 0; batch classifier loss: 0.362128; batch adversarial loss: 0.535874\n",
      "epoch 143; iter: 0; batch classifier loss: 0.367088; batch adversarial loss: 0.561498\n",
      "epoch 144; iter: 0; batch classifier loss: 0.493269; batch adversarial loss: 0.544413\n",
      "epoch 145; iter: 0; batch classifier loss: 0.407639; batch adversarial loss: 0.553594\n",
      "epoch 146; iter: 0; batch classifier loss: 0.416652; batch adversarial loss: 0.524362\n",
      "epoch 147; iter: 0; batch classifier loss: 0.368039; batch adversarial loss: 0.543730\n",
      "epoch 148; iter: 0; batch classifier loss: 0.421369; batch adversarial loss: 0.642833\n",
      "epoch 149; iter: 0; batch classifier loss: 0.425804; batch adversarial loss: 0.614225\n",
      "epoch 150; iter: 0; batch classifier loss: 0.363520; batch adversarial loss: 0.562301\n",
      "epoch 151; iter: 0; batch classifier loss: 0.362578; batch adversarial loss: 0.599243\n",
      "epoch 152; iter: 0; batch classifier loss: 0.391284; batch adversarial loss: 0.526855\n",
      "epoch 153; iter: 0; batch classifier loss: 0.402031; batch adversarial loss: 0.638450\n",
      "epoch 154; iter: 0; batch classifier loss: 0.344183; batch adversarial loss: 0.563652\n",
      "epoch 155; iter: 0; batch classifier loss: 0.324190; batch adversarial loss: 0.600694\n",
      "epoch 156; iter: 0; batch classifier loss: 0.369148; batch adversarial loss: 0.507659\n",
      "epoch 157; iter: 0; batch classifier loss: 0.419058; batch adversarial loss: 0.580925\n",
      "epoch 158; iter: 0; batch classifier loss: 0.348250; batch adversarial loss: 0.544062\n",
      "epoch 159; iter: 0; batch classifier loss: 0.353707; batch adversarial loss: 0.551978\n",
      "epoch 160; iter: 0; batch classifier loss: 0.405152; batch adversarial loss: 0.545001\n",
      "epoch 161; iter: 0; batch classifier loss: 0.393916; batch adversarial loss: 0.526092\n",
      "epoch 162; iter: 0; batch classifier loss: 0.355903; batch adversarial loss: 0.515446\n",
      "epoch 163; iter: 0; batch classifier loss: 0.454674; batch adversarial loss: 0.438567\n",
      "epoch 164; iter: 0; batch classifier loss: 0.386124; batch adversarial loss: 0.444877\n",
      "epoch 165; iter: 0; batch classifier loss: 0.297539; batch adversarial loss: 0.619722\n",
      "epoch 166; iter: 0; batch classifier loss: 0.381202; batch adversarial loss: 0.571907\n",
      "epoch 167; iter: 0; batch classifier loss: 0.415192; batch adversarial loss: 0.553828\n",
      "epoch 168; iter: 0; batch classifier loss: 0.374620; batch adversarial loss: 0.590249\n",
      "epoch 169; iter: 0; batch classifier loss: 0.468958; batch adversarial loss: 0.599207\n",
      "epoch 170; iter: 0; batch classifier loss: 0.383771; batch adversarial loss: 0.571423\n",
      "epoch 171; iter: 0; batch classifier loss: 0.316917; batch adversarial loss: 0.470691\n",
      "epoch 172; iter: 0; batch classifier loss: 0.404727; batch adversarial loss: 0.635155\n",
      "epoch 173; iter: 0; batch classifier loss: 0.338454; batch adversarial loss: 0.544633\n",
      "epoch 174; iter: 0; batch classifier loss: 0.369230; batch adversarial loss: 0.554653\n",
      "epoch 175; iter: 0; batch classifier loss: 0.398516; batch adversarial loss: 0.499160\n",
      "epoch 176; iter: 0; batch classifier loss: 0.289448; batch adversarial loss: 0.489361\n",
      "epoch 177; iter: 0; batch classifier loss: 0.407605; batch adversarial loss: 0.616500\n",
      "epoch 178; iter: 0; batch classifier loss: 0.314309; batch adversarial loss: 0.471328\n",
      "epoch 179; iter: 0; batch classifier loss: 0.351264; batch adversarial loss: 0.543171\n",
      "epoch 180; iter: 0; batch classifier loss: 0.356387; batch adversarial loss: 0.577169\n",
      "epoch 181; iter: 0; batch classifier loss: 0.344218; batch adversarial loss: 0.506615\n",
      "epoch 182; iter: 0; batch classifier loss: 0.299527; batch adversarial loss: 0.544655\n",
      "epoch 183; iter: 0; batch classifier loss: 0.366529; batch adversarial loss: 0.578443\n",
      "epoch 184; iter: 0; batch classifier loss: 0.319495; batch adversarial loss: 0.596765\n",
      "epoch 185; iter: 0; batch classifier loss: 0.351229; batch adversarial loss: 0.570291\n",
      "epoch 186; iter: 0; batch classifier loss: 0.404469; batch adversarial loss: 0.584991\n",
      "epoch 187; iter: 0; batch classifier loss: 0.410732; batch adversarial loss: 0.599721\n",
      "epoch 188; iter: 0; batch classifier loss: 0.315630; batch adversarial loss: 0.646504\n",
      "epoch 189; iter: 0; batch classifier loss: 0.328855; batch adversarial loss: 0.535848\n",
      "epoch 190; iter: 0; batch classifier loss: 0.419206; batch adversarial loss: 0.599882\n",
      "epoch 191; iter: 0; batch classifier loss: 0.374208; batch adversarial loss: 0.600339\n",
      "epoch 192; iter: 0; batch classifier loss: 0.309113; batch adversarial loss: 0.514930\n",
      "epoch 193; iter: 0; batch classifier loss: 0.415978; batch adversarial loss: 0.553408\n",
      "epoch 194; iter: 0; batch classifier loss: 0.313801; batch adversarial loss: 0.544526\n",
      "epoch 195; iter: 0; batch classifier loss: 0.333435; batch adversarial loss: 0.536418\n",
      "epoch 196; iter: 0; batch classifier loss: 0.387618; batch adversarial loss: 0.527391\n",
      "epoch 197; iter: 0; batch classifier loss: 0.436440; batch adversarial loss: 0.471891\n",
      "epoch 198; iter: 0; batch classifier loss: 0.326642; batch adversarial loss: 0.546461\n",
      "epoch 199; iter: 0; batch classifier loss: 0.389493; batch adversarial loss: 0.560263\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.686197; batch adversarial loss: 0.803158\n",
      "epoch 1; iter: 0; batch classifier loss: 0.775192; batch adversarial loss: 0.831442\n",
      "epoch 2; iter: 0; batch classifier loss: 0.836670; batch adversarial loss: 0.769555\n",
      "epoch 3; iter: 0; batch classifier loss: 0.767673; batch adversarial loss: 0.724935\n",
      "epoch 4; iter: 0; batch classifier loss: 0.706458; batch adversarial loss: 0.662501\n",
      "epoch 5; iter: 0; batch classifier loss: 0.613452; batch adversarial loss: 0.629555\n",
      "epoch 6; iter: 0; batch classifier loss: 0.515219; batch adversarial loss: 0.618466\n",
      "epoch 7; iter: 0; batch classifier loss: 0.557913; batch adversarial loss: 0.609285\n",
      "epoch 8; iter: 0; batch classifier loss: 0.536440; batch adversarial loss: 0.594847\n",
      "epoch 9; iter: 0; batch classifier loss: 0.513474; batch adversarial loss: 0.595017\n",
      "epoch 10; iter: 0; batch classifier loss: 0.535015; batch adversarial loss: 0.612102\n",
      "epoch 11; iter: 0; batch classifier loss: 0.565931; batch adversarial loss: 0.583432\n",
      "epoch 12; iter: 0; batch classifier loss: 0.523753; batch adversarial loss: 0.589714\n",
      "epoch 13; iter: 0; batch classifier loss: 0.500430; batch adversarial loss: 0.534632\n",
      "epoch 14; iter: 0; batch classifier loss: 0.529796; batch adversarial loss: 0.616212\n",
      "epoch 15; iter: 0; batch classifier loss: 0.532113; batch adversarial loss: 0.532164\n",
      "epoch 16; iter: 0; batch classifier loss: 0.525861; batch adversarial loss: 0.538033\n",
      "epoch 17; iter: 0; batch classifier loss: 0.466311; batch adversarial loss: 0.542396\n",
      "epoch 18; iter: 0; batch classifier loss: 0.532728; batch adversarial loss: 0.590568\n",
      "epoch 19; iter: 0; batch classifier loss: 0.527450; batch adversarial loss: 0.562110\n",
      "epoch 20; iter: 0; batch classifier loss: 0.439324; batch adversarial loss: 0.606265\n",
      "epoch 21; iter: 0; batch classifier loss: 0.412303; batch adversarial loss: 0.576394\n",
      "epoch 22; iter: 0; batch classifier loss: 0.463836; batch adversarial loss: 0.540750\n",
      "epoch 23; iter: 0; batch classifier loss: 0.437418; batch adversarial loss: 0.522879\n",
      "epoch 24; iter: 0; batch classifier loss: 0.418292; batch adversarial loss: 0.482355\n",
      "epoch 25; iter: 0; batch classifier loss: 0.473773; batch adversarial loss: 0.580521\n",
      "epoch 26; iter: 0; batch classifier loss: 0.468678; batch adversarial loss: 0.531045\n",
      "epoch 27; iter: 0; batch classifier loss: 0.501182; batch adversarial loss: 0.476975\n",
      "epoch 28; iter: 0; batch classifier loss: 0.464014; batch adversarial loss: 0.622205\n",
      "epoch 29; iter: 0; batch classifier loss: 0.445773; batch adversarial loss: 0.557215\n",
      "epoch 30; iter: 0; batch classifier loss: 0.431149; batch adversarial loss: 0.501264\n",
      "epoch 31; iter: 0; batch classifier loss: 0.407302; batch adversarial loss: 0.520519\n",
      "epoch 32; iter: 0; batch classifier loss: 0.475340; batch adversarial loss: 0.470029\n",
      "epoch 33; iter: 0; batch classifier loss: 0.492327; batch adversarial loss: 0.519338\n",
      "epoch 34; iter: 0; batch classifier loss: 0.449136; batch adversarial loss: 0.510325\n",
      "epoch 35; iter: 0; batch classifier loss: 0.394771; batch adversarial loss: 0.506367\n",
      "epoch 36; iter: 0; batch classifier loss: 0.457580; batch adversarial loss: 0.576422\n",
      "epoch 37; iter: 0; batch classifier loss: 0.513907; batch adversarial loss: 0.572297\n",
      "epoch 38; iter: 0; batch classifier loss: 0.402997; batch adversarial loss: 0.478270\n",
      "epoch 39; iter: 0; batch classifier loss: 0.393900; batch adversarial loss: 0.556574\n",
      "epoch 40; iter: 0; batch classifier loss: 0.471984; batch adversarial loss: 0.562113\n",
      "epoch 41; iter: 0; batch classifier loss: 0.451171; batch adversarial loss: 0.604106\n",
      "epoch 42; iter: 0; batch classifier loss: 0.405989; batch adversarial loss: 0.646525\n",
      "epoch 43; iter: 0; batch classifier loss: 0.504507; batch adversarial loss: 0.572918\n",
      "epoch 44; iter: 0; batch classifier loss: 0.426122; batch adversarial loss: 0.670755\n",
      "epoch 45; iter: 0; batch classifier loss: 0.428005; batch adversarial loss: 0.471928\n",
      "epoch 46; iter: 0; batch classifier loss: 0.399110; batch adversarial loss: 0.450019\n",
      "epoch 47; iter: 0; batch classifier loss: 0.461294; batch adversarial loss: 0.515665\n",
      "epoch 48; iter: 0; batch classifier loss: 0.382747; batch adversarial loss: 0.574927\n",
      "epoch 49; iter: 0; batch classifier loss: 0.428346; batch adversarial loss: 0.563261\n",
      "epoch 50; iter: 0; batch classifier loss: 0.475725; batch adversarial loss: 0.532455\n",
      "epoch 51; iter: 0; batch classifier loss: 0.357673; batch adversarial loss: 0.572807\n",
      "epoch 52; iter: 0; batch classifier loss: 0.391711; batch adversarial loss: 0.553676\n",
      "epoch 53; iter: 0; batch classifier loss: 0.352857; batch adversarial loss: 0.499660\n",
      "epoch 54; iter: 0; batch classifier loss: 0.428434; batch adversarial loss: 0.544036\n",
      "epoch 55; iter: 0; batch classifier loss: 0.385519; batch adversarial loss: 0.526496\n",
      "epoch 56; iter: 0; batch classifier loss: 0.311209; batch adversarial loss: 0.507870\n",
      "epoch 57; iter: 0; batch classifier loss: 0.426813; batch adversarial loss: 0.516974\n",
      "epoch 58; iter: 0; batch classifier loss: 0.358506; batch adversarial loss: 0.461956\n",
      "epoch 59; iter: 0; batch classifier loss: 0.367637; batch adversarial loss: 0.507450\n",
      "epoch 60; iter: 0; batch classifier loss: 0.421227; batch adversarial loss: 0.572237\n",
      "epoch 61; iter: 0; batch classifier loss: 0.357702; batch adversarial loss: 0.554021\n",
      "epoch 62; iter: 0; batch classifier loss: 0.377615; batch adversarial loss: 0.525808\n",
      "epoch 63; iter: 0; batch classifier loss: 0.414392; batch adversarial loss: 0.535104\n",
      "epoch 64; iter: 0; batch classifier loss: 0.368671; batch adversarial loss: 0.610351\n",
      "epoch 65; iter: 0; batch classifier loss: 0.378322; batch adversarial loss: 0.525613\n",
      "epoch 66; iter: 0; batch classifier loss: 0.394971; batch adversarial loss: 0.581778\n",
      "epoch 67; iter: 0; batch classifier loss: 0.513921; batch adversarial loss: 0.469863\n",
      "epoch 68; iter: 0; batch classifier loss: 0.397643; batch adversarial loss: 0.572945\n",
      "epoch 69; iter: 0; batch classifier loss: 0.449366; batch adversarial loss: 0.516634\n",
      "epoch 70; iter: 0; batch classifier loss: 0.388812; batch adversarial loss: 0.487974\n",
      "epoch 71; iter: 0; batch classifier loss: 0.480366; batch adversarial loss: 0.460398\n",
      "epoch 72; iter: 0; batch classifier loss: 0.388787; batch adversarial loss: 0.563239\n",
      "epoch 73; iter: 0; batch classifier loss: 0.390781; batch adversarial loss: 0.582127\n",
      "epoch 74; iter: 0; batch classifier loss: 0.348273; batch adversarial loss: 0.478611\n",
      "epoch 75; iter: 0; batch classifier loss: 0.377044; batch adversarial loss: 0.468758\n",
      "epoch 76; iter: 0; batch classifier loss: 0.380313; batch adversarial loss: 0.591464\n",
      "epoch 77; iter: 0; batch classifier loss: 0.435145; batch adversarial loss: 0.544612\n",
      "epoch 78; iter: 0; batch classifier loss: 0.448156; batch adversarial loss: 0.497225\n",
      "epoch 79; iter: 0; batch classifier loss: 0.410962; batch adversarial loss: 0.554140\n",
      "epoch 80; iter: 0; batch classifier loss: 0.371440; batch adversarial loss: 0.544764\n",
      "epoch 81; iter: 0; batch classifier loss: 0.343113; batch adversarial loss: 0.497493\n",
      "epoch 82; iter: 0; batch classifier loss: 0.457101; batch adversarial loss: 0.591651\n",
      "epoch 83; iter: 0; batch classifier loss: 0.426919; batch adversarial loss: 0.591144\n",
      "epoch 84; iter: 0; batch classifier loss: 0.423740; batch adversarial loss: 0.609756\n",
      "epoch 85; iter: 0; batch classifier loss: 0.437397; batch adversarial loss: 0.544099\n",
      "epoch 86; iter: 0; batch classifier loss: 0.381299; batch adversarial loss: 0.571948\n",
      "epoch 87; iter: 0; batch classifier loss: 0.488864; batch adversarial loss: 0.525821\n",
      "epoch 88; iter: 0; batch classifier loss: 0.361177; batch adversarial loss: 0.478790\n",
      "epoch 89; iter: 0; batch classifier loss: 0.377315; batch adversarial loss: 0.562648\n",
      "epoch 90; iter: 0; batch classifier loss: 0.415769; batch adversarial loss: 0.524796\n",
      "epoch 91; iter: 0; batch classifier loss: 0.375658; batch adversarial loss: 0.469236\n",
      "epoch 92; iter: 0; batch classifier loss: 0.427941; batch adversarial loss: 0.384146\n",
      "epoch 93; iter: 0; batch classifier loss: 0.361580; batch adversarial loss: 0.478676\n",
      "epoch 94; iter: 0; batch classifier loss: 0.377765; batch adversarial loss: 0.619834\n",
      "epoch 95; iter: 0; batch classifier loss: 0.418065; batch adversarial loss: 0.535088\n",
      "epoch 96; iter: 0; batch classifier loss: 0.342578; batch adversarial loss: 0.516121\n",
      "epoch 97; iter: 0; batch classifier loss: 0.320006; batch adversarial loss: 0.450010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 98; iter: 0; batch classifier loss: 0.421720; batch adversarial loss: 0.563309\n",
      "epoch 99; iter: 0; batch classifier loss: 0.377710; batch adversarial loss: 0.497611\n",
      "epoch 100; iter: 0; batch classifier loss: 0.397521; batch adversarial loss: 0.544029\n",
      "epoch 101; iter: 0; batch classifier loss: 0.268147; batch adversarial loss: 0.553846\n",
      "epoch 102; iter: 0; batch classifier loss: 0.374884; batch adversarial loss: 0.516421\n",
      "epoch 103; iter: 0; batch classifier loss: 0.371657; batch adversarial loss: 0.562482\n",
      "epoch 104; iter: 0; batch classifier loss: 0.338195; batch adversarial loss: 0.619628\n",
      "epoch 105; iter: 0; batch classifier loss: 0.305170; batch adversarial loss: 0.563645\n",
      "epoch 106; iter: 0; batch classifier loss: 0.366115; batch adversarial loss: 0.563814\n",
      "epoch 107; iter: 0; batch classifier loss: 0.302322; batch adversarial loss: 0.525900\n",
      "epoch 108; iter: 0; batch classifier loss: 0.413207; batch adversarial loss: 0.535111\n",
      "epoch 109; iter: 0; batch classifier loss: 0.319438; batch adversarial loss: 0.488077\n",
      "epoch 110; iter: 0; batch classifier loss: 0.448099; batch adversarial loss: 0.572690\n",
      "epoch 111; iter: 0; batch classifier loss: 0.282192; batch adversarial loss: 0.440960\n",
      "epoch 112; iter: 0; batch classifier loss: 0.360987; batch adversarial loss: 0.581394\n",
      "epoch 113; iter: 0; batch classifier loss: 0.360424; batch adversarial loss: 0.563379\n",
      "epoch 114; iter: 0; batch classifier loss: 0.282095; batch adversarial loss: 0.488193\n",
      "epoch 115; iter: 0; batch classifier loss: 0.418830; batch adversarial loss: 0.516648\n",
      "epoch 116; iter: 0; batch classifier loss: 0.421684; batch adversarial loss: 0.572553\n",
      "epoch 117; iter: 0; batch classifier loss: 0.432681; batch adversarial loss: 0.497539\n",
      "epoch 118; iter: 0; batch classifier loss: 0.391959; batch adversarial loss: 0.478447\n",
      "epoch 119; iter: 0; batch classifier loss: 0.379401; batch adversarial loss: 0.516476\n",
      "epoch 120; iter: 0; batch classifier loss: 0.336412; batch adversarial loss: 0.619753\n",
      "epoch 121; iter: 0; batch classifier loss: 0.463772; batch adversarial loss: 0.478580\n",
      "epoch 122; iter: 0; batch classifier loss: 0.393131; batch adversarial loss: 0.582129\n",
      "epoch 123; iter: 0; batch classifier loss: 0.409573; batch adversarial loss: 0.600948\n",
      "epoch 124; iter: 0; batch classifier loss: 0.343033; batch adversarial loss: 0.506694\n",
      "epoch 125; iter: 0; batch classifier loss: 0.386087; batch adversarial loss: 0.515716\n",
      "epoch 126; iter: 0; batch classifier loss: 0.360494; batch adversarial loss: 0.600956\n",
      "epoch 127; iter: 0; batch classifier loss: 0.404185; batch adversarial loss: 0.666600\n",
      "epoch 128; iter: 0; batch classifier loss: 0.310411; batch adversarial loss: 0.497327\n",
      "epoch 129; iter: 0; batch classifier loss: 0.406059; batch adversarial loss: 0.573438\n",
      "epoch 130; iter: 0; batch classifier loss: 0.325993; batch adversarial loss: 0.544914\n",
      "epoch 131; iter: 0; batch classifier loss: 0.442036; batch adversarial loss: 0.544691\n",
      "epoch 132; iter: 0; batch classifier loss: 0.330734; batch adversarial loss: 0.545081\n",
      "epoch 133; iter: 0; batch classifier loss: 0.352774; batch adversarial loss: 0.544150\n",
      "epoch 134; iter: 0; batch classifier loss: 0.330938; batch adversarial loss: 0.497575\n",
      "epoch 135; iter: 0; batch classifier loss: 0.301785; batch adversarial loss: 0.488655\n",
      "epoch 136; iter: 0; batch classifier loss: 0.386535; batch adversarial loss: 0.535682\n",
      "epoch 137; iter: 0; batch classifier loss: 0.305412; batch adversarial loss: 0.535652\n",
      "epoch 138; iter: 0; batch classifier loss: 0.439885; batch adversarial loss: 0.506824\n",
      "epoch 139; iter: 0; batch classifier loss: 0.405154; batch adversarial loss: 0.545362\n",
      "epoch 140; iter: 0; batch classifier loss: 0.456583; batch adversarial loss: 0.553450\n",
      "epoch 141; iter: 0; batch classifier loss: 0.377607; batch adversarial loss: 0.610736\n",
      "epoch 142; iter: 0; batch classifier loss: 0.381595; batch adversarial loss: 0.601504\n",
      "epoch 143; iter: 0; batch classifier loss: 0.367099; batch adversarial loss: 0.488285\n",
      "epoch 144; iter: 0; batch classifier loss: 0.371108; batch adversarial loss: 0.572487\n",
      "epoch 145; iter: 0; batch classifier loss: 0.351776; batch adversarial loss: 0.526035\n",
      "epoch 146; iter: 0; batch classifier loss: 0.330686; batch adversarial loss: 0.544669\n",
      "epoch 147; iter: 0; batch classifier loss: 0.472460; batch adversarial loss: 0.479179\n",
      "epoch 148; iter: 0; batch classifier loss: 0.392904; batch adversarial loss: 0.554285\n",
      "epoch 149; iter: 0; batch classifier loss: 0.321621; batch adversarial loss: 0.656912\n",
      "epoch 150; iter: 0; batch classifier loss: 0.305156; batch adversarial loss: 0.535153\n",
      "epoch 151; iter: 0; batch classifier loss: 0.453810; batch adversarial loss: 0.487521\n",
      "epoch 152; iter: 0; batch classifier loss: 0.451097; batch adversarial loss: 0.591344\n",
      "epoch 153; iter: 0; batch classifier loss: 0.387282; batch adversarial loss: 0.488382\n",
      "epoch 154; iter: 0; batch classifier loss: 0.342607; batch adversarial loss: 0.535148\n",
      "epoch 155; iter: 0; batch classifier loss: 0.420237; batch adversarial loss: 0.553750\n",
      "epoch 156; iter: 0; batch classifier loss: 0.407449; batch adversarial loss: 0.469297\n",
      "epoch 157; iter: 0; batch classifier loss: 0.310992; batch adversarial loss: 0.563003\n",
      "epoch 158; iter: 0; batch classifier loss: 0.412763; batch adversarial loss: 0.526579\n",
      "epoch 159; iter: 0; batch classifier loss: 0.394000; batch adversarial loss: 0.525867\n",
      "epoch 160; iter: 0; batch classifier loss: 0.300275; batch adversarial loss: 0.639031\n",
      "epoch 161; iter: 0; batch classifier loss: 0.408491; batch adversarial loss: 0.525356\n",
      "epoch 162; iter: 0; batch classifier loss: 0.282459; batch adversarial loss: 0.478425\n",
      "epoch 163; iter: 0; batch classifier loss: 0.363934; batch adversarial loss: 0.554323\n",
      "epoch 164; iter: 0; batch classifier loss: 0.308668; batch adversarial loss: 0.524544\n",
      "epoch 165; iter: 0; batch classifier loss: 0.374191; batch adversarial loss: 0.534874\n",
      "epoch 166; iter: 0; batch classifier loss: 0.343949; batch adversarial loss: 0.554433\n",
      "epoch 167; iter: 0; batch classifier loss: 0.305348; batch adversarial loss: 0.506650\n",
      "epoch 168; iter: 0; batch classifier loss: 0.397474; batch adversarial loss: 0.516219\n",
      "epoch 169; iter: 0; batch classifier loss: 0.316671; batch adversarial loss: 0.506569\n",
      "epoch 170; iter: 0; batch classifier loss: 0.347508; batch adversarial loss: 0.544739\n",
      "epoch 171; iter: 0; batch classifier loss: 0.350396; batch adversarial loss: 0.515503\n",
      "epoch 172; iter: 0; batch classifier loss: 0.440094; batch adversarial loss: 0.611039\n",
      "epoch 173; iter: 0; batch classifier loss: 0.328984; batch adversarial loss: 0.658033\n",
      "epoch 174; iter: 0; batch classifier loss: 0.292636; batch adversarial loss: 0.506572\n",
      "epoch 175; iter: 0; batch classifier loss: 0.287937; batch adversarial loss: 0.487697\n",
      "epoch 176; iter: 0; batch classifier loss: 0.383263; batch adversarial loss: 0.488005\n",
      "epoch 177; iter: 0; batch classifier loss: 0.285065; batch adversarial loss: 0.562604\n",
      "epoch 178; iter: 0; batch classifier loss: 0.283804; batch adversarial loss: 0.554133\n",
      "epoch 179; iter: 0; batch classifier loss: 0.434842; batch adversarial loss: 0.609821\n",
      "epoch 180; iter: 0; batch classifier loss: 0.366051; batch adversarial loss: 0.591386\n",
      "epoch 181; iter: 0; batch classifier loss: 0.322937; batch adversarial loss: 0.506877\n",
      "epoch 182; iter: 0; batch classifier loss: 0.332373; batch adversarial loss: 0.516318\n",
      "epoch 183; iter: 0; batch classifier loss: 0.316450; batch adversarial loss: 0.545182\n",
      "epoch 184; iter: 0; batch classifier loss: 0.285240; batch adversarial loss: 0.535880\n",
      "epoch 185; iter: 0; batch classifier loss: 0.352278; batch adversarial loss: 0.441108\n",
      "epoch 186; iter: 0; batch classifier loss: 0.313125; batch adversarial loss: 0.516272\n",
      "epoch 187; iter: 0; batch classifier loss: 0.328652; batch adversarial loss: 0.601375\n",
      "epoch 188; iter: 0; batch classifier loss: 0.240490; batch adversarial loss: 0.525435\n",
      "epoch 189; iter: 0; batch classifier loss: 0.421915; batch adversarial loss: 0.506593\n",
      "epoch 190; iter: 0; batch classifier loss: 0.289289; batch adversarial loss: 0.544624\n",
      "epoch 191; iter: 0; batch classifier loss: 0.331737; batch adversarial loss: 0.563659\n",
      "epoch 192; iter: 0; batch classifier loss: 0.381839; batch adversarial loss: 0.553598\n",
      "epoch 193; iter: 0; batch classifier loss: 0.333617; batch adversarial loss: 0.478497\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 194; iter: 0; batch classifier loss: 0.311199; batch adversarial loss: 0.449780\n",
      "epoch 195; iter: 0; batch classifier loss: 0.288814; batch adversarial loss: 0.591292\n",
      "epoch 196; iter: 0; batch classifier loss: 0.379879; batch adversarial loss: 0.460144\n",
      "epoch 197; iter: 0; batch classifier loss: 0.284618; batch adversarial loss: 0.563524\n",
      "epoch 198; iter: 0; batch classifier loss: 0.301615; batch adversarial loss: 0.601192\n",
      "epoch 199; iter: 0; batch classifier loss: 0.282239; batch adversarial loss: 0.583173\n",
      "epoch 0; iter: 0; batch classifier loss: 0.669260; batch adversarial loss: 0.788306\n",
      "epoch 1; iter: 0; batch classifier loss: 0.828980; batch adversarial loss: 1.026799\n",
      "epoch 2; iter: 0; batch classifier loss: 1.019460; batch adversarial loss: 0.989642\n",
      "epoch 3; iter: 0; batch classifier loss: 1.129705; batch adversarial loss: 0.925541\n",
      "epoch 4; iter: 0; batch classifier loss: 1.096126; batch adversarial loss: 0.844116\n",
      "epoch 5; iter: 0; batch classifier loss: 0.981891; batch adversarial loss: 0.776368\n",
      "epoch 6; iter: 0; batch classifier loss: 1.009307; batch adversarial loss: 0.708710\n",
      "epoch 7; iter: 0; batch classifier loss: 0.912935; batch adversarial loss: 0.671632\n",
      "epoch 8; iter: 0; batch classifier loss: 0.831006; batch adversarial loss: 0.640028\n",
      "epoch 9; iter: 0; batch classifier loss: 0.628373; batch adversarial loss: 0.589817\n",
      "epoch 10; iter: 0; batch classifier loss: 0.568301; batch adversarial loss: 0.592325\n",
      "epoch 11; iter: 0; batch classifier loss: 0.490983; batch adversarial loss: 0.601888\n",
      "epoch 12; iter: 0; batch classifier loss: 0.475274; batch adversarial loss: 0.601406\n",
      "epoch 13; iter: 0; batch classifier loss: 0.551594; batch adversarial loss: 0.630234\n",
      "epoch 14; iter: 0; batch classifier loss: 0.472034; batch adversarial loss: 0.563841\n",
      "epoch 15; iter: 0; batch classifier loss: 0.606567; batch adversarial loss: 0.602241\n",
      "epoch 16; iter: 0; batch classifier loss: 0.552930; batch adversarial loss: 0.567027\n",
      "epoch 17; iter: 0; batch classifier loss: 0.504983; batch adversarial loss: 0.565644\n",
      "epoch 18; iter: 0; batch classifier loss: 0.496268; batch adversarial loss: 0.589052\n",
      "epoch 19; iter: 0; batch classifier loss: 0.579434; batch adversarial loss: 0.540315\n",
      "epoch 20; iter: 0; batch classifier loss: 0.577904; batch adversarial loss: 0.617437\n",
      "epoch 21; iter: 0; batch classifier loss: 0.462735; batch adversarial loss: 0.561033\n",
      "epoch 22; iter: 0; batch classifier loss: 0.472852; batch adversarial loss: 0.567134\n",
      "epoch 23; iter: 0; batch classifier loss: 0.527304; batch adversarial loss: 0.518503\n",
      "epoch 24; iter: 0; batch classifier loss: 0.513786; batch adversarial loss: 0.558487\n",
      "epoch 25; iter: 0; batch classifier loss: 0.553545; batch adversarial loss: 0.529901\n",
      "epoch 26; iter: 0; batch classifier loss: 0.408434; batch adversarial loss: 0.577143\n",
      "epoch 27; iter: 0; batch classifier loss: 0.415079; batch adversarial loss: 0.602789\n",
      "epoch 28; iter: 0; batch classifier loss: 0.536916; batch adversarial loss: 0.529068\n",
      "epoch 29; iter: 0; batch classifier loss: 0.439377; batch adversarial loss: 0.467564\n",
      "epoch 30; iter: 0; batch classifier loss: 0.417634; batch adversarial loss: 0.592035\n",
      "epoch 31; iter: 0; batch classifier loss: 0.430657; batch adversarial loss: 0.500328\n",
      "epoch 32; iter: 0; batch classifier loss: 0.444724; batch adversarial loss: 0.560069\n",
      "epoch 33; iter: 0; batch classifier loss: 0.430394; batch adversarial loss: 0.490511\n",
      "epoch 34; iter: 0; batch classifier loss: 0.420007; batch adversarial loss: 0.576595\n",
      "epoch 35; iter: 0; batch classifier loss: 0.448998; batch adversarial loss: 0.521650\n",
      "epoch 36; iter: 0; batch classifier loss: 0.462296; batch adversarial loss: 0.464518\n",
      "epoch 37; iter: 0; batch classifier loss: 0.427154; batch adversarial loss: 0.590202\n",
      "epoch 38; iter: 0; batch classifier loss: 0.510221; batch adversarial loss: 0.555604\n",
      "epoch 39; iter: 0; batch classifier loss: 0.428906; batch adversarial loss: 0.527463\n",
      "epoch 40; iter: 0; batch classifier loss: 0.388385; batch adversarial loss: 0.573880\n",
      "epoch 41; iter: 0; batch classifier loss: 0.473441; batch adversarial loss: 0.536150\n",
      "epoch 42; iter: 0; batch classifier loss: 0.447264; batch adversarial loss: 0.564262\n",
      "epoch 43; iter: 0; batch classifier loss: 0.414240; batch adversarial loss: 0.544890\n",
      "epoch 44; iter: 0; batch classifier loss: 0.388003; batch adversarial loss: 0.571292\n",
      "epoch 45; iter: 0; batch classifier loss: 0.420797; batch adversarial loss: 0.564530\n",
      "epoch 46; iter: 0; batch classifier loss: 0.368885; batch adversarial loss: 0.615956\n",
      "epoch 47; iter: 0; batch classifier loss: 0.440753; batch adversarial loss: 0.481117\n",
      "epoch 48; iter: 0; batch classifier loss: 0.407114; batch adversarial loss: 0.560853\n",
      "epoch 49; iter: 0; batch classifier loss: 0.439773; batch adversarial loss: 0.554296\n",
      "epoch 50; iter: 0; batch classifier loss: 0.403528; batch adversarial loss: 0.553533\n",
      "epoch 51; iter: 0; batch classifier loss: 0.398605; batch adversarial loss: 0.563187\n",
      "epoch 52; iter: 0; batch classifier loss: 0.421484; batch adversarial loss: 0.498437\n",
      "epoch 53; iter: 0; batch classifier loss: 0.464242; batch adversarial loss: 0.516642\n",
      "epoch 54; iter: 0; batch classifier loss: 0.352930; batch adversarial loss: 0.536260\n",
      "epoch 55; iter: 0; batch classifier loss: 0.405085; batch adversarial loss: 0.607574\n",
      "epoch 56; iter: 0; batch classifier loss: 0.448517; batch adversarial loss: 0.525316\n",
      "epoch 57; iter: 0; batch classifier loss: 0.386993; batch adversarial loss: 0.489228\n",
      "epoch 58; iter: 0; batch classifier loss: 0.392856; batch adversarial loss: 0.526141\n",
      "epoch 59; iter: 0; batch classifier loss: 0.441729; batch adversarial loss: 0.590417\n",
      "epoch 60; iter: 0; batch classifier loss: 0.481328; batch adversarial loss: 0.590409\n",
      "epoch 61; iter: 0; batch classifier loss: 0.406140; batch adversarial loss: 0.536723\n",
      "epoch 62; iter: 0; batch classifier loss: 0.383605; batch adversarial loss: 0.536074\n",
      "epoch 63; iter: 0; batch classifier loss: 0.419759; batch adversarial loss: 0.571514\n",
      "epoch 64; iter: 0; batch classifier loss: 0.439709; batch adversarial loss: 0.577725\n",
      "epoch 65; iter: 0; batch classifier loss: 0.416782; batch adversarial loss: 0.489663\n",
      "epoch 66; iter: 0; batch classifier loss: 0.400237; batch adversarial loss: 0.498572\n",
      "epoch 67; iter: 0; batch classifier loss: 0.398735; batch adversarial loss: 0.517989\n",
      "epoch 68; iter: 0; batch classifier loss: 0.455901; batch adversarial loss: 0.544825\n",
      "epoch 69; iter: 0; batch classifier loss: 0.431827; batch adversarial loss: 0.478302\n",
      "epoch 70; iter: 0; batch classifier loss: 0.402245; batch adversarial loss: 0.542851\n",
      "epoch 71; iter: 0; batch classifier loss: 0.419411; batch adversarial loss: 0.563977\n",
      "epoch 72; iter: 0; batch classifier loss: 0.345370; batch adversarial loss: 0.616714\n",
      "epoch 73; iter: 0; batch classifier loss: 0.379831; batch adversarial loss: 0.551546\n",
      "epoch 74; iter: 0; batch classifier loss: 0.494413; batch adversarial loss: 0.553610\n",
      "epoch 75; iter: 0; batch classifier loss: 0.424797; batch adversarial loss: 0.571958\n",
      "epoch 76; iter: 0; batch classifier loss: 0.382884; batch adversarial loss: 0.490854\n",
      "epoch 77; iter: 0; batch classifier loss: 0.397968; batch adversarial loss: 0.533274\n",
      "epoch 78; iter: 0; batch classifier loss: 0.381913; batch adversarial loss: 0.595836\n",
      "epoch 79; iter: 0; batch classifier loss: 0.390680; batch adversarial loss: 0.542914\n",
      "epoch 80; iter: 0; batch classifier loss: 0.330744; batch adversarial loss: 0.581848\n",
      "epoch 81; iter: 0; batch classifier loss: 0.408661; batch adversarial loss: 0.587793\n",
      "epoch 82; iter: 0; batch classifier loss: 0.306227; batch adversarial loss: 0.615081\n",
      "epoch 83; iter: 0; batch classifier loss: 0.301033; batch adversarial loss: 0.526097\n",
      "epoch 84; iter: 0; batch classifier loss: 0.407570; batch adversarial loss: 0.517866\n",
      "epoch 85; iter: 0; batch classifier loss: 0.405175; batch adversarial loss: 0.665928\n",
      "epoch 86; iter: 0; batch classifier loss: 0.332087; batch adversarial loss: 0.550660\n",
      "epoch 87; iter: 0; batch classifier loss: 0.383203; batch adversarial loss: 0.649378\n",
      "epoch 88; iter: 0; batch classifier loss: 0.309590; batch adversarial loss: 0.480316\n",
      "epoch 89; iter: 0; batch classifier loss: 0.312485; batch adversarial loss: 0.598769\n",
      "epoch 90; iter: 0; batch classifier loss: 0.409150; batch adversarial loss: 0.564642\n",
      "epoch 91; iter: 0; batch classifier loss: 0.404448; batch adversarial loss: 0.600213\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 92; iter: 0; batch classifier loss: 0.337166; batch adversarial loss: 0.509482\n",
      "epoch 93; iter: 0; batch classifier loss: 0.380112; batch adversarial loss: 0.563661\n",
      "epoch 94; iter: 0; batch classifier loss: 0.335203; batch adversarial loss: 0.513946\n",
      "epoch 95; iter: 0; batch classifier loss: 0.374662; batch adversarial loss: 0.533151\n",
      "epoch 96; iter: 0; batch classifier loss: 0.404310; batch adversarial loss: 0.524241\n",
      "epoch 97; iter: 0; batch classifier loss: 0.410195; batch adversarial loss: 0.578854\n",
      "epoch 98; iter: 0; batch classifier loss: 0.341867; batch adversarial loss: 0.522851\n",
      "epoch 99; iter: 0; batch classifier loss: 0.323539; batch adversarial loss: 0.557451\n",
      "epoch 100; iter: 0; batch classifier loss: 0.259020; batch adversarial loss: 0.470917\n",
      "epoch 101; iter: 0; batch classifier loss: 0.318852; batch adversarial loss: 0.630100\n",
      "epoch 102; iter: 0; batch classifier loss: 0.363870; batch adversarial loss: 0.573429\n",
      "epoch 103; iter: 0; batch classifier loss: 0.299908; batch adversarial loss: 0.507717\n",
      "epoch 104; iter: 0; batch classifier loss: 0.301521; batch adversarial loss: 0.527314\n",
      "epoch 105; iter: 0; batch classifier loss: 0.359112; batch adversarial loss: 0.687946\n",
      "epoch 106; iter: 0; batch classifier loss: 0.447229; batch adversarial loss: 0.560425\n",
      "epoch 107; iter: 0; batch classifier loss: 0.328389; batch adversarial loss: 0.570921\n",
      "epoch 108; iter: 0; batch classifier loss: 0.441023; batch adversarial loss: 0.569648\n",
      "epoch 109; iter: 0; batch classifier loss: 0.323045; batch adversarial loss: 0.524541\n",
      "epoch 110; iter: 0; batch classifier loss: 0.326798; batch adversarial loss: 0.526186\n",
      "epoch 111; iter: 0; batch classifier loss: 0.303445; batch adversarial loss: 0.535905\n",
      "epoch 112; iter: 0; batch classifier loss: 0.285124; batch adversarial loss: 0.546393\n",
      "epoch 113; iter: 0; batch classifier loss: 0.395600; batch adversarial loss: 0.524014\n",
      "epoch 114; iter: 0; batch classifier loss: 0.343261; batch adversarial loss: 0.616612\n",
      "epoch 115; iter: 0; batch classifier loss: 0.338827; batch adversarial loss: 0.553532\n",
      "epoch 116; iter: 0; batch classifier loss: 0.301267; batch adversarial loss: 0.514902\n",
      "epoch 117; iter: 0; batch classifier loss: 0.385028; batch adversarial loss: 0.463110\n",
      "epoch 118; iter: 0; batch classifier loss: 0.444620; batch adversarial loss: 0.629582\n",
      "epoch 119; iter: 0; batch classifier loss: 0.344207; batch adversarial loss: 0.478249\n",
      "epoch 120; iter: 0; batch classifier loss: 0.345325; batch adversarial loss: 0.486965\n",
      "epoch 121; iter: 0; batch classifier loss: 0.315660; batch adversarial loss: 0.579396\n",
      "epoch 122; iter: 0; batch classifier loss: 0.434965; batch adversarial loss: 0.499220\n",
      "epoch 123; iter: 0; batch classifier loss: 0.364411; batch adversarial loss: 0.564241\n",
      "epoch 124; iter: 0; batch classifier loss: 0.352213; batch adversarial loss: 0.552305\n",
      "epoch 125; iter: 0; batch classifier loss: 0.371912; batch adversarial loss: 0.609965\n",
      "epoch 126; iter: 0; batch classifier loss: 0.323758; batch adversarial loss: 0.499734\n",
      "epoch 127; iter: 0; batch classifier loss: 0.314454; batch adversarial loss: 0.542287\n",
      "epoch 128; iter: 0; batch classifier loss: 0.314432; batch adversarial loss: 0.499723\n",
      "epoch 129; iter: 0; batch classifier loss: 0.388427; batch adversarial loss: 0.534525\n",
      "epoch 130; iter: 0; batch classifier loss: 0.296804; batch adversarial loss: 0.591252\n",
      "epoch 131; iter: 0; batch classifier loss: 0.393853; batch adversarial loss: 0.612227\n",
      "epoch 132; iter: 0; batch classifier loss: 0.345572; batch adversarial loss: 0.629983\n",
      "epoch 133; iter: 0; batch classifier loss: 0.315859; batch adversarial loss: 0.562387\n",
      "epoch 134; iter: 0; batch classifier loss: 0.356457; batch adversarial loss: 0.488853\n",
      "epoch 135; iter: 0; batch classifier loss: 0.294312; batch adversarial loss: 0.518300\n",
      "epoch 136; iter: 0; batch classifier loss: 0.287434; batch adversarial loss: 0.535144\n",
      "epoch 137; iter: 0; batch classifier loss: 0.359004; batch adversarial loss: 0.515124\n",
      "epoch 138; iter: 0; batch classifier loss: 0.337173; batch adversarial loss: 0.477959\n",
      "epoch 139; iter: 0; batch classifier loss: 0.405964; batch adversarial loss: 0.552039\n",
      "epoch 140; iter: 0; batch classifier loss: 0.274925; batch adversarial loss: 0.457155\n",
      "epoch 141; iter: 0; batch classifier loss: 0.339519; batch adversarial loss: 0.555420\n",
      "epoch 142; iter: 0; batch classifier loss: 0.302861; batch adversarial loss: 0.543543\n",
      "epoch 143; iter: 0; batch classifier loss: 0.334426; batch adversarial loss: 0.518123\n",
      "epoch 144; iter: 0; batch classifier loss: 0.384305; batch adversarial loss: 0.570594\n",
      "epoch 145; iter: 0; batch classifier loss: 0.271476; batch adversarial loss: 0.515720\n",
      "epoch 146; iter: 0; batch classifier loss: 0.291895; batch adversarial loss: 0.609608\n",
      "epoch 147; iter: 0; batch classifier loss: 0.343484; batch adversarial loss: 0.498840\n",
      "epoch 148; iter: 0; batch classifier loss: 0.287531; batch adversarial loss: 0.473175\n",
      "epoch 149; iter: 0; batch classifier loss: 0.353224; batch adversarial loss: 0.636043\n",
      "epoch 150; iter: 0; batch classifier loss: 0.334702; batch adversarial loss: 0.597639\n",
      "epoch 151; iter: 0; batch classifier loss: 0.305620; batch adversarial loss: 0.507176\n",
      "epoch 152; iter: 0; batch classifier loss: 0.297839; batch adversarial loss: 0.549029\n",
      "epoch 153; iter: 0; batch classifier loss: 0.390246; batch adversarial loss: 0.490179\n",
      "epoch 154; iter: 0; batch classifier loss: 0.249711; batch adversarial loss: 0.573479\n",
      "epoch 155; iter: 0; batch classifier loss: 0.424470; batch adversarial loss: 0.622028\n",
      "epoch 156; iter: 0; batch classifier loss: 0.287651; batch adversarial loss: 0.539245\n",
      "epoch 157; iter: 0; batch classifier loss: 0.380295; batch adversarial loss: 0.516332\n",
      "epoch 158; iter: 0; batch classifier loss: 0.333472; batch adversarial loss: 0.561601\n",
      "epoch 159; iter: 0; batch classifier loss: 0.346809; batch adversarial loss: 0.573162\n",
      "epoch 160; iter: 0; batch classifier loss: 0.379739; batch adversarial loss: 0.558870\n",
      "epoch 161; iter: 0; batch classifier loss: 0.330432; batch adversarial loss: 0.489376\n",
      "epoch 162; iter: 0; batch classifier loss: 0.348287; batch adversarial loss: 0.453086\n",
      "epoch 163; iter: 0; batch classifier loss: 0.297836; batch adversarial loss: 0.544535\n",
      "epoch 164; iter: 0; batch classifier loss: 0.303705; batch adversarial loss: 0.575549\n",
      "epoch 165; iter: 0; batch classifier loss: 0.303815; batch adversarial loss: 0.562010\n",
      "epoch 166; iter: 0; batch classifier loss: 0.299097; batch adversarial loss: 0.538513\n",
      "epoch 167; iter: 0; batch classifier loss: 0.420673; batch adversarial loss: 0.561362\n",
      "epoch 168; iter: 0; batch classifier loss: 0.398881; batch adversarial loss: 0.602067\n",
      "epoch 169; iter: 0; batch classifier loss: 0.309473; batch adversarial loss: 0.480056\n",
      "epoch 170; iter: 0; batch classifier loss: 0.297165; batch adversarial loss: 0.579776\n",
      "epoch 171; iter: 0; batch classifier loss: 0.241649; batch adversarial loss: 0.526652\n",
      "epoch 172; iter: 0; batch classifier loss: 0.313148; batch adversarial loss: 0.578003\n",
      "epoch 173; iter: 0; batch classifier loss: 0.330171; batch adversarial loss: 0.526357\n",
      "epoch 174; iter: 0; batch classifier loss: 0.399313; batch adversarial loss: 0.590027\n",
      "epoch 175; iter: 0; batch classifier loss: 0.294485; batch adversarial loss: 0.534561\n",
      "epoch 176; iter: 0; batch classifier loss: 0.413897; batch adversarial loss: 0.605122\n",
      "epoch 177; iter: 0; batch classifier loss: 0.321891; batch adversarial loss: 0.468833\n",
      "epoch 178; iter: 0; batch classifier loss: 0.352685; batch adversarial loss: 0.415122\n",
      "epoch 179; iter: 0; batch classifier loss: 0.361836; batch adversarial loss: 0.523448\n",
      "epoch 180; iter: 0; batch classifier loss: 0.348741; batch adversarial loss: 0.600107\n",
      "epoch 181; iter: 0; batch classifier loss: 0.376730; batch adversarial loss: 0.509308\n",
      "epoch 182; iter: 0; batch classifier loss: 0.379295; batch adversarial loss: 0.491153\n",
      "epoch 183; iter: 0; batch classifier loss: 0.359812; batch adversarial loss: 0.514966\n",
      "epoch 184; iter: 0; batch classifier loss: 0.300892; batch adversarial loss: 0.497886\n",
      "epoch 185; iter: 0; batch classifier loss: 0.336201; batch adversarial loss: 0.584338\n",
      "epoch 186; iter: 0; batch classifier loss: 0.274512; batch adversarial loss: 0.582667\n",
      "epoch 187; iter: 0; batch classifier loss: 0.339438; batch adversarial loss: 0.581543\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 188; iter: 0; batch classifier loss: 0.272697; batch adversarial loss: 0.534249\n",
      "epoch 189; iter: 0; batch classifier loss: 0.453771; batch adversarial loss: 0.527380\n",
      "epoch 190; iter: 0; batch classifier loss: 0.307639; batch adversarial loss: 0.607229\n",
      "epoch 191; iter: 0; batch classifier loss: 0.385248; batch adversarial loss: 0.537035\n",
      "epoch 192; iter: 0; batch classifier loss: 0.355844; batch adversarial loss: 0.544637\n",
      "epoch 193; iter: 0; batch classifier loss: 0.313623; batch adversarial loss: 0.554542\n",
      "epoch 194; iter: 0; batch classifier loss: 0.344451; batch adversarial loss: 0.523765\n",
      "epoch 195; iter: 0; batch classifier loss: 0.264592; batch adversarial loss: 0.620485\n",
      "epoch 196; iter: 0; batch classifier loss: 0.370251; batch adversarial loss: 0.524256\n",
      "epoch 197; iter: 0; batch classifier loss: 0.287685; batch adversarial loss: 0.489875\n",
      "epoch 198; iter: 0; batch classifier loss: 0.319168; batch adversarial loss: 0.627756\n",
      "epoch 199; iter: 0; batch classifier loss: 0.349513; batch adversarial loss: 0.549550\n",
      "epoch 0; iter: 0; batch classifier loss: 0.755419; batch adversarial loss: 0.528124\n",
      "epoch 1; iter: 0; batch classifier loss: 0.606007; batch adversarial loss: 0.688849\n",
      "epoch 2; iter: 0; batch classifier loss: 0.518088; batch adversarial loss: 0.657849\n",
      "epoch 3; iter: 0; batch classifier loss: 0.590848; batch adversarial loss: 0.663616\n",
      "epoch 4; iter: 0; batch classifier loss: 0.562686; batch adversarial loss: 0.691887\n",
      "epoch 5; iter: 0; batch classifier loss: 0.601463; batch adversarial loss: 0.637745\n",
      "epoch 6; iter: 0; batch classifier loss: 0.586701; batch adversarial loss: 0.622362\n",
      "epoch 7; iter: 0; batch classifier loss: 0.599232; batch adversarial loss: 0.594453\n",
      "epoch 8; iter: 0; batch classifier loss: 0.631696; batch adversarial loss: 0.642491\n",
      "epoch 9; iter: 0; batch classifier loss: 0.556023; batch adversarial loss: 0.615176\n",
      "epoch 10; iter: 0; batch classifier loss: 0.529888; batch adversarial loss: 0.588756\n",
      "epoch 11; iter: 0; batch classifier loss: 0.543910; batch adversarial loss: 0.591043\n",
      "epoch 12; iter: 0; batch classifier loss: 0.552058; batch adversarial loss: 0.614034\n",
      "epoch 13; iter: 0; batch classifier loss: 0.564496; batch adversarial loss: 0.614046\n",
      "epoch 14; iter: 0; batch classifier loss: 0.437220; batch adversarial loss: 0.601360\n",
      "epoch 15; iter: 0; batch classifier loss: 0.503476; batch adversarial loss: 0.557482\n",
      "epoch 16; iter: 0; batch classifier loss: 0.560489; batch adversarial loss: 0.527969\n",
      "epoch 17; iter: 0; batch classifier loss: 0.512983; batch adversarial loss: 0.531201\n",
      "epoch 18; iter: 0; batch classifier loss: 0.607954; batch adversarial loss: 0.455867\n",
      "epoch 19; iter: 0; batch classifier loss: 0.488970; batch adversarial loss: 0.549857\n",
      "epoch 20; iter: 0; batch classifier loss: 0.512537; batch adversarial loss: 0.599371\n",
      "epoch 21; iter: 0; batch classifier loss: 0.454997; batch adversarial loss: 0.571445\n",
      "epoch 22; iter: 0; batch classifier loss: 0.571523; batch adversarial loss: 0.506237\n",
      "epoch 23; iter: 0; batch classifier loss: 0.578832; batch adversarial loss: 0.512333\n",
      "epoch 24; iter: 0; batch classifier loss: 0.459448; batch adversarial loss: 0.589106\n",
      "epoch 25; iter: 0; batch classifier loss: 0.475987; batch adversarial loss: 0.488744\n",
      "epoch 26; iter: 0; batch classifier loss: 0.464020; batch adversarial loss: 0.641098\n",
      "epoch 27; iter: 0; batch classifier loss: 0.453691; batch adversarial loss: 0.563956\n",
      "epoch 28; iter: 0; batch classifier loss: 0.473761; batch adversarial loss: 0.599238\n",
      "epoch 29; iter: 0; batch classifier loss: 0.493666; batch adversarial loss: 0.544504\n",
      "epoch 30; iter: 0; batch classifier loss: 0.456280; batch adversarial loss: 0.519010\n",
      "epoch 31; iter: 0; batch classifier loss: 0.508242; batch adversarial loss: 0.534370\n",
      "epoch 32; iter: 0; batch classifier loss: 0.459220; batch adversarial loss: 0.526146\n",
      "epoch 33; iter: 0; batch classifier loss: 0.398398; batch adversarial loss: 0.570866\n",
      "epoch 34; iter: 0; batch classifier loss: 0.482503; batch adversarial loss: 0.475515\n",
      "epoch 35; iter: 0; batch classifier loss: 0.492123; batch adversarial loss: 0.525981\n",
      "epoch 36; iter: 0; batch classifier loss: 0.440628; batch adversarial loss: 0.551834\n",
      "epoch 37; iter: 0; batch classifier loss: 0.476040; batch adversarial loss: 0.482125\n",
      "epoch 38; iter: 0; batch classifier loss: 0.476427; batch adversarial loss: 0.562527\n",
      "epoch 39; iter: 0; batch classifier loss: 0.486895; batch adversarial loss: 0.570976\n",
      "epoch 40; iter: 0; batch classifier loss: 0.562482; batch adversarial loss: 0.544512\n",
      "epoch 41; iter: 0; batch classifier loss: 0.426463; batch adversarial loss: 0.517905\n",
      "epoch 42; iter: 0; batch classifier loss: 0.441244; batch adversarial loss: 0.544393\n",
      "epoch 43; iter: 0; batch classifier loss: 0.393918; batch adversarial loss: 0.553055\n",
      "epoch 44; iter: 0; batch classifier loss: 0.501270; batch adversarial loss: 0.491074\n",
      "epoch 45; iter: 0; batch classifier loss: 0.452385; batch adversarial loss: 0.590001\n",
      "epoch 46; iter: 0; batch classifier loss: 0.388510; batch adversarial loss: 0.543162\n",
      "epoch 47; iter: 0; batch classifier loss: 0.403072; batch adversarial loss: 0.489711\n",
      "epoch 48; iter: 0; batch classifier loss: 0.383314; batch adversarial loss: 0.590019\n",
      "epoch 49; iter: 0; batch classifier loss: 0.392130; batch adversarial loss: 0.480748\n",
      "epoch 50; iter: 0; batch classifier loss: 0.304475; batch adversarial loss: 0.519789\n",
      "epoch 51; iter: 0; batch classifier loss: 0.461729; batch adversarial loss: 0.507864\n",
      "epoch 52; iter: 0; batch classifier loss: 0.475893; batch adversarial loss: 0.489849\n",
      "epoch 53; iter: 0; batch classifier loss: 0.395771; batch adversarial loss: 0.498399\n",
      "epoch 54; iter: 0; batch classifier loss: 0.419899; batch adversarial loss: 0.571335\n",
      "epoch 55; iter: 0; batch classifier loss: 0.367925; batch adversarial loss: 0.534922\n",
      "epoch 56; iter: 0; batch classifier loss: 0.432373; batch adversarial loss: 0.634927\n",
      "epoch 57; iter: 0; batch classifier loss: 0.440334; batch adversarial loss: 0.564100\n",
      "epoch 58; iter: 0; batch classifier loss: 0.481007; batch adversarial loss: 0.544202\n",
      "epoch 59; iter: 0; batch classifier loss: 0.429023; batch adversarial loss: 0.598777\n",
      "epoch 60; iter: 0; batch classifier loss: 0.349598; batch adversarial loss: 0.526484\n",
      "epoch 61; iter: 0; batch classifier loss: 0.425617; batch adversarial loss: 0.526507\n",
      "epoch 62; iter: 0; batch classifier loss: 0.502980; batch adversarial loss: 0.490497\n",
      "epoch 63; iter: 0; batch classifier loss: 0.473986; batch adversarial loss: 0.463048\n",
      "epoch 64; iter: 0; batch classifier loss: 0.422376; batch adversarial loss: 0.516870\n",
      "epoch 65; iter: 0; batch classifier loss: 0.406043; batch adversarial loss: 0.597257\n",
      "epoch 66; iter: 0; batch classifier loss: 0.363504; batch adversarial loss: 0.481653\n",
      "epoch 67; iter: 0; batch classifier loss: 0.341196; batch adversarial loss: 0.499778\n",
      "epoch 68; iter: 0; batch classifier loss: 0.337226; batch adversarial loss: 0.560858\n",
      "epoch 69; iter: 0; batch classifier loss: 0.407827; batch adversarial loss: 0.535728\n",
      "epoch 70; iter: 0; batch classifier loss: 0.474824; batch adversarial loss: 0.491065\n",
      "epoch 71; iter: 0; batch classifier loss: 0.353811; batch adversarial loss: 0.508071\n",
      "epoch 72; iter: 0; batch classifier loss: 0.427357; batch adversarial loss: 0.600166\n",
      "epoch 73; iter: 0; batch classifier loss: 0.407505; batch adversarial loss: 0.591166\n",
      "epoch 74; iter: 0; batch classifier loss: 0.387321; batch adversarial loss: 0.598038\n",
      "epoch 75; iter: 0; batch classifier loss: 0.399016; batch adversarial loss: 0.497239\n",
      "epoch 76; iter: 0; batch classifier loss: 0.434450; batch adversarial loss: 0.506864\n",
      "epoch 77; iter: 0; batch classifier loss: 0.400219; batch adversarial loss: 0.598492\n",
      "epoch 78; iter: 0; batch classifier loss: 0.411204; batch adversarial loss: 0.534142\n",
      "epoch 79; iter: 0; batch classifier loss: 0.409791; batch adversarial loss: 0.545131\n",
      "epoch 80; iter: 0; batch classifier loss: 0.357254; batch adversarial loss: 0.516907\n",
      "epoch 81; iter: 0; batch classifier loss: 0.450856; batch adversarial loss: 0.600165\n",
      "epoch 82; iter: 0; batch classifier loss: 0.386204; batch adversarial loss: 0.579271\n",
      "epoch 83; iter: 0; batch classifier loss: 0.317258; batch adversarial loss: 0.616596\n",
      "epoch 84; iter: 0; batch classifier loss: 0.464643; batch adversarial loss: 0.608235\n",
      "epoch 85; iter: 0; batch classifier loss: 0.364435; batch adversarial loss: 0.480923\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 86; iter: 0; batch classifier loss: 0.362609; batch adversarial loss: 0.524723\n",
      "epoch 87; iter: 0; batch classifier loss: 0.468218; batch adversarial loss: 0.553449\n",
      "epoch 88; iter: 0; batch classifier loss: 0.418339; batch adversarial loss: 0.564129\n",
      "epoch 89; iter: 0; batch classifier loss: 0.424860; batch adversarial loss: 0.473313\n",
      "epoch 90; iter: 0; batch classifier loss: 0.375859; batch adversarial loss: 0.582193\n",
      "epoch 91; iter: 0; batch classifier loss: 0.495093; batch adversarial loss: 0.581389\n",
      "epoch 92; iter: 0; batch classifier loss: 0.358716; batch adversarial loss: 0.618466\n",
      "epoch 93; iter: 0; batch classifier loss: 0.390348; batch adversarial loss: 0.608729\n",
      "epoch 94; iter: 0; batch classifier loss: 0.431344; batch adversarial loss: 0.526019\n",
      "epoch 95; iter: 0; batch classifier loss: 0.464435; batch adversarial loss: 0.509250\n",
      "epoch 96; iter: 0; batch classifier loss: 0.441144; batch adversarial loss: 0.535760\n",
      "epoch 97; iter: 0; batch classifier loss: 0.433266; batch adversarial loss: 0.607627\n",
      "epoch 98; iter: 0; batch classifier loss: 0.421042; batch adversarial loss: 0.525959\n",
      "epoch 99; iter: 0; batch classifier loss: 0.407380; batch adversarial loss: 0.454264\n",
      "epoch 100; iter: 0; batch classifier loss: 0.398528; batch adversarial loss: 0.535168\n",
      "epoch 101; iter: 0; batch classifier loss: 0.357545; batch adversarial loss: 0.544255\n",
      "epoch 102; iter: 0; batch classifier loss: 0.342083; batch adversarial loss: 0.554153\n",
      "epoch 103; iter: 0; batch classifier loss: 0.479923; batch adversarial loss: 0.481749\n",
      "epoch 104; iter: 0; batch classifier loss: 0.479466; batch adversarial loss: 0.535713\n",
      "epoch 105; iter: 0; batch classifier loss: 0.421478; batch adversarial loss: 0.517311\n",
      "epoch 106; iter: 0; batch classifier loss: 0.471979; batch adversarial loss: 0.616749\n",
      "epoch 107; iter: 0; batch classifier loss: 0.370738; batch adversarial loss: 0.599920\n",
      "epoch 108; iter: 0; batch classifier loss: 0.403032; batch adversarial loss: 0.537358\n",
      "epoch 109; iter: 0; batch classifier loss: 0.387837; batch adversarial loss: 0.544490\n",
      "epoch 110; iter: 0; batch classifier loss: 0.390461; batch adversarial loss: 0.562896\n",
      "epoch 111; iter: 0; batch classifier loss: 0.391595; batch adversarial loss: 0.572619\n",
      "epoch 112; iter: 0; batch classifier loss: 0.435002; batch adversarial loss: 0.543596\n",
      "epoch 113; iter: 0; batch classifier loss: 0.418437; batch adversarial loss: 0.454871\n",
      "epoch 114; iter: 0; batch classifier loss: 0.349063; batch adversarial loss: 0.544791\n",
      "epoch 115; iter: 0; batch classifier loss: 0.380299; batch adversarial loss: 0.508130\n",
      "epoch 116; iter: 0; batch classifier loss: 0.371652; batch adversarial loss: 0.536190\n",
      "epoch 117; iter: 0; batch classifier loss: 0.396482; batch adversarial loss: 0.553611\n",
      "epoch 118; iter: 0; batch classifier loss: 0.428463; batch adversarial loss: 0.498856\n",
      "epoch 119; iter: 0; batch classifier loss: 0.447125; batch adversarial loss: 0.471110\n",
      "epoch 120; iter: 0; batch classifier loss: 0.441974; batch adversarial loss: 0.482909\n",
      "epoch 121; iter: 0; batch classifier loss: 0.419820; batch adversarial loss: 0.525417\n",
      "epoch 122; iter: 0; batch classifier loss: 0.423039; batch adversarial loss: 0.545872\n",
      "epoch 123; iter: 0; batch classifier loss: 0.392630; batch adversarial loss: 0.497724\n",
      "epoch 124; iter: 0; batch classifier loss: 0.432841; batch adversarial loss: 0.491183\n",
      "epoch 125; iter: 0; batch classifier loss: 0.416400; batch adversarial loss: 0.581035\n",
      "epoch 126; iter: 0; batch classifier loss: 0.342076; batch adversarial loss: 0.582106\n",
      "epoch 127; iter: 0; batch classifier loss: 0.387395; batch adversarial loss: 0.543847\n",
      "epoch 128; iter: 0; batch classifier loss: 0.408212; batch adversarial loss: 0.553207\n",
      "epoch 129; iter: 0; batch classifier loss: 0.327095; batch adversarial loss: 0.645632\n",
      "epoch 130; iter: 0; batch classifier loss: 0.315187; batch adversarial loss: 0.545265\n",
      "epoch 131; iter: 0; batch classifier loss: 0.348784; batch adversarial loss: 0.498836\n",
      "epoch 132; iter: 0; batch classifier loss: 0.407096; batch adversarial loss: 0.534493\n",
      "epoch 133; iter: 0; batch classifier loss: 0.420555; batch adversarial loss: 0.627010\n",
      "epoch 134; iter: 0; batch classifier loss: 0.328924; batch adversarial loss: 0.525845\n",
      "epoch 135; iter: 0; batch classifier loss: 0.361974; batch adversarial loss: 0.525960\n",
      "epoch 136; iter: 0; batch classifier loss: 0.379758; batch adversarial loss: 0.480793\n",
      "epoch 137; iter: 0; batch classifier loss: 0.405285; batch adversarial loss: 0.580869\n",
      "epoch 138; iter: 0; batch classifier loss: 0.337509; batch adversarial loss: 0.562845\n",
      "epoch 139; iter: 0; batch classifier loss: 0.474621; batch adversarial loss: 0.571533\n",
      "epoch 140; iter: 0; batch classifier loss: 0.329100; batch adversarial loss: 0.471047\n",
      "epoch 141; iter: 0; batch classifier loss: 0.363121; batch adversarial loss: 0.535320\n",
      "epoch 142; iter: 0; batch classifier loss: 0.343187; batch adversarial loss: 0.498914\n",
      "epoch 143; iter: 0; batch classifier loss: 0.366448; batch adversarial loss: 0.516985\n",
      "epoch 144; iter: 0; batch classifier loss: 0.331955; batch adversarial loss: 0.599213\n",
      "epoch 145; iter: 0; batch classifier loss: 0.348124; batch adversarial loss: 0.544572\n",
      "epoch 146; iter: 0; batch classifier loss: 0.400337; batch adversarial loss: 0.498884\n",
      "epoch 147; iter: 0; batch classifier loss: 0.427837; batch adversarial loss: 0.581329\n",
      "epoch 148; iter: 0; batch classifier loss: 0.377519; batch adversarial loss: 0.571843\n",
      "epoch 149; iter: 0; batch classifier loss: 0.331816; batch adversarial loss: 0.490381\n",
      "epoch 150; iter: 0; batch classifier loss: 0.350330; batch adversarial loss: 0.662761\n",
      "epoch 151; iter: 0; batch classifier loss: 0.415201; batch adversarial loss: 0.562740\n",
      "epoch 152; iter: 0; batch classifier loss: 0.481885; batch adversarial loss: 0.526015\n",
      "epoch 153; iter: 0; batch classifier loss: 0.371420; batch adversarial loss: 0.543756\n",
      "epoch 154; iter: 0; batch classifier loss: 0.319624; batch adversarial loss: 0.607435\n",
      "epoch 155; iter: 0; batch classifier loss: 0.273347; batch adversarial loss: 0.525855\n",
      "epoch 156; iter: 0; batch classifier loss: 0.385890; batch adversarial loss: 0.499079\n",
      "epoch 157; iter: 0; batch classifier loss: 0.443280; batch adversarial loss: 0.509328\n",
      "epoch 158; iter: 0; batch classifier loss: 0.389406; batch adversarial loss: 0.480221\n",
      "epoch 159; iter: 0; batch classifier loss: 0.380555; batch adversarial loss: 0.527380\n",
      "epoch 160; iter: 0; batch classifier loss: 0.306419; batch adversarial loss: 0.572408\n",
      "epoch 161; iter: 0; batch classifier loss: 0.347760; batch adversarial loss: 0.554217\n",
      "epoch 162; iter: 0; batch classifier loss: 0.382236; batch adversarial loss: 0.609463\n",
      "epoch 163; iter: 0; batch classifier loss: 0.338365; batch adversarial loss: 0.600044\n",
      "epoch 164; iter: 0; batch classifier loss: 0.387743; batch adversarial loss: 0.571785\n",
      "epoch 165; iter: 0; batch classifier loss: 0.363661; batch adversarial loss: 0.554087\n",
      "epoch 166; iter: 0; batch classifier loss: 0.426122; batch adversarial loss: 0.626901\n",
      "epoch 167; iter: 0; batch classifier loss: 0.360352; batch adversarial loss: 0.553987\n",
      "epoch 168; iter: 0; batch classifier loss: 0.350254; batch adversarial loss: 0.535348\n",
      "epoch 169; iter: 0; batch classifier loss: 0.356099; batch adversarial loss: 0.544380\n",
      "epoch 170; iter: 0; batch classifier loss: 0.332023; batch adversarial loss: 0.608450\n",
      "epoch 171; iter: 0; batch classifier loss: 0.347306; batch adversarial loss: 0.508222\n",
      "epoch 172; iter: 0; batch classifier loss: 0.344513; batch adversarial loss: 0.589492\n",
      "epoch 173; iter: 0; batch classifier loss: 0.344482; batch adversarial loss: 0.517034\n",
      "epoch 174; iter: 0; batch classifier loss: 0.337754; batch adversarial loss: 0.552925\n",
      "epoch 175; iter: 0; batch classifier loss: 0.359799; batch adversarial loss: 0.553294\n",
      "epoch 176; iter: 0; batch classifier loss: 0.332225; batch adversarial loss: 0.507571\n",
      "epoch 177; iter: 0; batch classifier loss: 0.386952; batch adversarial loss: 0.524543\n",
      "epoch 178; iter: 0; batch classifier loss: 0.411266; batch adversarial loss: 0.598485\n",
      "epoch 179; iter: 0; batch classifier loss: 0.356205; batch adversarial loss: 0.546777\n",
      "epoch 180; iter: 0; batch classifier loss: 0.334736; batch adversarial loss: 0.581697\n",
      "epoch 181; iter: 0; batch classifier loss: 0.375555; batch adversarial loss: 0.581935\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 182; iter: 0; batch classifier loss: 0.441906; batch adversarial loss: 0.582047\n",
      "epoch 183; iter: 0; batch classifier loss: 0.357695; batch adversarial loss: 0.498764\n",
      "epoch 184; iter: 0; batch classifier loss: 0.395569; batch adversarial loss: 0.562085\n",
      "epoch 185; iter: 0; batch classifier loss: 0.378215; batch adversarial loss: 0.526728\n",
      "epoch 186; iter: 0; batch classifier loss: 0.325855; batch adversarial loss: 0.553288\n",
      "epoch 187; iter: 0; batch classifier loss: 0.324669; batch adversarial loss: 0.507995\n",
      "epoch 188; iter: 0; batch classifier loss: 0.294302; batch adversarial loss: 0.553916\n",
      "epoch 189; iter: 0; batch classifier loss: 0.308373; batch adversarial loss: 0.590223\n",
      "epoch 190; iter: 0; batch classifier loss: 0.308119; batch adversarial loss: 0.499986\n",
      "epoch 191; iter: 0; batch classifier loss: 0.430727; batch adversarial loss: 0.480879\n",
      "epoch 192; iter: 0; batch classifier loss: 0.320880; batch adversarial loss: 0.517438\n",
      "epoch 193; iter: 0; batch classifier loss: 0.327908; batch adversarial loss: 0.480253\n",
      "epoch 194; iter: 0; batch classifier loss: 0.377328; batch adversarial loss: 0.508332\n",
      "epoch 195; iter: 0; batch classifier loss: 0.467550; batch adversarial loss: 0.581038\n",
      "epoch 196; iter: 0; batch classifier loss: 0.405255; batch adversarial loss: 0.600047\n",
      "epoch 197; iter: 0; batch classifier loss: 0.329762; batch adversarial loss: 0.572050\n",
      "epoch 198; iter: 0; batch classifier loss: 0.331113; batch adversarial loss: 0.580595\n",
      "epoch 199; iter: 0; batch classifier loss: 0.277347; batch adversarial loss: 0.534763\n",
      "epoch 0; iter: 0; batch classifier loss: 0.687135; batch adversarial loss: 0.662140\n",
      "epoch 1; iter: 0; batch classifier loss: 0.575247; batch adversarial loss: 0.650556\n",
      "epoch 2; iter: 0; batch classifier loss: 0.599038; batch adversarial loss: 0.626693\n",
      "epoch 3; iter: 0; batch classifier loss: 0.568383; batch adversarial loss: 0.665753\n",
      "epoch 4; iter: 0; batch classifier loss: 0.539913; batch adversarial loss: 0.620151\n",
      "epoch 5; iter: 0; batch classifier loss: 0.575886; batch adversarial loss: 0.634175\n",
      "epoch 6; iter: 0; batch classifier loss: 0.470536; batch adversarial loss: 0.600892\n",
      "epoch 7; iter: 0; batch classifier loss: 0.607203; batch adversarial loss: 0.641513\n",
      "epoch 8; iter: 0; batch classifier loss: 0.571887; batch adversarial loss: 0.636547\n",
      "epoch 9; iter: 0; batch classifier loss: 0.631503; batch adversarial loss: 0.573114\n",
      "epoch 10; iter: 0; batch classifier loss: 0.492473; batch adversarial loss: 0.561644\n",
      "epoch 11; iter: 0; batch classifier loss: 0.615506; batch adversarial loss: 0.586432\n",
      "epoch 12; iter: 0; batch classifier loss: 0.522246; batch adversarial loss: 0.596453\n",
      "epoch 13; iter: 0; batch classifier loss: 0.562915; batch adversarial loss: 0.555124\n",
      "epoch 14; iter: 0; batch classifier loss: 0.532120; batch adversarial loss: 0.596386\n",
      "epoch 15; iter: 0; batch classifier loss: 0.535400; batch adversarial loss: 0.547515\n",
      "epoch 16; iter: 0; batch classifier loss: 0.500011; batch adversarial loss: 0.583608\n",
      "epoch 17; iter: 0; batch classifier loss: 0.638544; batch adversarial loss: 0.531460\n",
      "epoch 18; iter: 0; batch classifier loss: 0.524782; batch adversarial loss: 0.622481\n",
      "epoch 19; iter: 0; batch classifier loss: 0.457310; batch adversarial loss: 0.588334\n",
      "epoch 20; iter: 0; batch classifier loss: 0.504336; batch adversarial loss: 0.538865\n",
      "epoch 21; iter: 0; batch classifier loss: 0.453277; batch adversarial loss: 0.509624\n",
      "epoch 22; iter: 0; batch classifier loss: 0.504609; batch adversarial loss: 0.538353\n",
      "epoch 23; iter: 0; batch classifier loss: 0.442876; batch adversarial loss: 0.568233\n",
      "epoch 24; iter: 0; batch classifier loss: 0.540108; batch adversarial loss: 0.552559\n",
      "epoch 25; iter: 0; batch classifier loss: 0.479887; batch adversarial loss: 0.536370\n",
      "epoch 26; iter: 0; batch classifier loss: 0.473430; batch adversarial loss: 0.634914\n",
      "epoch 27; iter: 0; batch classifier loss: 0.430098; batch adversarial loss: 0.550692\n",
      "epoch 28; iter: 0; batch classifier loss: 0.565181; batch adversarial loss: 0.533821\n",
      "epoch 29; iter: 0; batch classifier loss: 0.419404; batch adversarial loss: 0.587761\n",
      "epoch 30; iter: 0; batch classifier loss: 0.454297; batch adversarial loss: 0.570608\n",
      "epoch 31; iter: 0; batch classifier loss: 0.405584; batch adversarial loss: 0.581980\n",
      "epoch 32; iter: 0; batch classifier loss: 0.379156; batch adversarial loss: 0.566673\n",
      "epoch 33; iter: 0; batch classifier loss: 0.528137; batch adversarial loss: 0.540011\n",
      "epoch 34; iter: 0; batch classifier loss: 0.468790; batch adversarial loss: 0.536843\n",
      "epoch 35; iter: 0; batch classifier loss: 0.454618; batch adversarial loss: 0.535923\n",
      "epoch 36; iter: 0; batch classifier loss: 0.503251; batch adversarial loss: 0.530080\n",
      "epoch 37; iter: 0; batch classifier loss: 0.420081; batch adversarial loss: 0.545459\n",
      "epoch 38; iter: 0; batch classifier loss: 0.390072; batch adversarial loss: 0.570034\n",
      "epoch 39; iter: 0; batch classifier loss: 0.409043; batch adversarial loss: 0.528308\n",
      "epoch 40; iter: 0; batch classifier loss: 0.453811; batch adversarial loss: 0.528339\n",
      "epoch 41; iter: 0; batch classifier loss: 0.388821; batch adversarial loss: 0.571697\n",
      "epoch 42; iter: 0; batch classifier loss: 0.516072; batch adversarial loss: 0.517308\n",
      "epoch 43; iter: 0; batch classifier loss: 0.384542; batch adversarial loss: 0.491013\n",
      "epoch 44; iter: 0; batch classifier loss: 0.451902; batch adversarial loss: 0.571905\n",
      "epoch 45; iter: 0; batch classifier loss: 0.498225; batch adversarial loss: 0.435230\n",
      "epoch 46; iter: 0; batch classifier loss: 0.384278; batch adversarial loss: 0.544402\n",
      "epoch 47; iter: 0; batch classifier loss: 0.403587; batch adversarial loss: 0.525691\n",
      "epoch 48; iter: 0; batch classifier loss: 0.405397; batch adversarial loss: 0.516807\n",
      "epoch 49; iter: 0; batch classifier loss: 0.432694; batch adversarial loss: 0.545331\n",
      "epoch 50; iter: 0; batch classifier loss: 0.441071; batch adversarial loss: 0.479967\n",
      "epoch 51; iter: 0; batch classifier loss: 0.416913; batch adversarial loss: 0.581521\n",
      "epoch 52; iter: 0; batch classifier loss: 0.467998; batch adversarial loss: 0.589469\n",
      "epoch 53; iter: 0; batch classifier loss: 0.437717; batch adversarial loss: 0.544643\n",
      "epoch 54; iter: 0; batch classifier loss: 0.440917; batch adversarial loss: 0.461264\n",
      "epoch 55; iter: 0; batch classifier loss: 0.395938; batch adversarial loss: 0.581355\n",
      "epoch 56; iter: 0; batch classifier loss: 0.549774; batch adversarial loss: 0.507779\n",
      "epoch 57; iter: 0; batch classifier loss: 0.416605; batch adversarial loss: 0.477920\n",
      "epoch 58; iter: 0; batch classifier loss: 0.492741; batch adversarial loss: 0.599660\n",
      "epoch 59; iter: 0; batch classifier loss: 0.476372; batch adversarial loss: 0.526436\n",
      "epoch 60; iter: 0; batch classifier loss: 0.452666; batch adversarial loss: 0.507623\n",
      "epoch 61; iter: 0; batch classifier loss: 0.424893; batch adversarial loss: 0.555740\n",
      "epoch 62; iter: 0; batch classifier loss: 0.431833; batch adversarial loss: 0.561471\n",
      "epoch 63; iter: 0; batch classifier loss: 0.428391; batch adversarial loss: 0.553229\n",
      "epoch 64; iter: 0; batch classifier loss: 0.419060; batch adversarial loss: 0.532146\n",
      "epoch 65; iter: 0; batch classifier loss: 0.371440; batch adversarial loss: 0.492087\n",
      "epoch 66; iter: 0; batch classifier loss: 0.492317; batch adversarial loss: 0.508421\n",
      "epoch 67; iter: 0; batch classifier loss: 0.391954; batch adversarial loss: 0.505624\n",
      "epoch 68; iter: 0; batch classifier loss: 0.397236; batch adversarial loss: 0.567645\n",
      "epoch 69; iter: 0; batch classifier loss: 0.357612; batch adversarial loss: 0.566917\n",
      "epoch 70; iter: 0; batch classifier loss: 0.388993; batch adversarial loss: 0.535401\n",
      "epoch 71; iter: 0; batch classifier loss: 0.471492; batch adversarial loss: 0.536223\n",
      "epoch 72; iter: 0; batch classifier loss: 0.388762; batch adversarial loss: 0.554031\n",
      "epoch 73; iter: 0; batch classifier loss: 0.380212; batch adversarial loss: 0.553917\n",
      "epoch 74; iter: 0; batch classifier loss: 0.395288; batch adversarial loss: 0.544998\n",
      "epoch 75; iter: 0; batch classifier loss: 0.344807; batch adversarial loss: 0.605639\n",
      "epoch 76; iter: 0; batch classifier loss: 0.414919; batch adversarial loss: 0.474567\n",
      "epoch 77; iter: 0; batch classifier loss: 0.398166; batch adversarial loss: 0.480992\n",
      "epoch 78; iter: 0; batch classifier loss: 0.460653; batch adversarial loss: 0.535742\n",
      "epoch 79; iter: 0; batch classifier loss: 0.424072; batch adversarial loss: 0.591657\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 80; iter: 0; batch classifier loss: 0.479067; batch adversarial loss: 0.516227\n",
      "epoch 81; iter: 0; batch classifier loss: 0.360221; batch adversarial loss: 0.572418\n",
      "epoch 82; iter: 0; batch classifier loss: 0.351929; batch adversarial loss: 0.552970\n",
      "epoch 83; iter: 0; batch classifier loss: 0.406711; batch adversarial loss: 0.536366\n",
      "epoch 84; iter: 0; batch classifier loss: 0.388224; batch adversarial loss: 0.581591\n",
      "epoch 85; iter: 0; batch classifier loss: 0.375469; batch adversarial loss: 0.582057\n",
      "epoch 86; iter: 0; batch classifier loss: 0.411594; batch adversarial loss: 0.609018\n",
      "epoch 87; iter: 0; batch classifier loss: 0.384998; batch adversarial loss: 0.525051\n",
      "epoch 88; iter: 0; batch classifier loss: 0.426818; batch adversarial loss: 0.598043\n",
      "epoch 89; iter: 0; batch classifier loss: 0.362504; batch adversarial loss: 0.562840\n",
      "epoch 90; iter: 0; batch classifier loss: 0.417617; batch adversarial loss: 0.590066\n",
      "epoch 91; iter: 0; batch classifier loss: 0.365796; batch adversarial loss: 0.562562\n",
      "epoch 92; iter: 0; batch classifier loss: 0.397829; batch adversarial loss: 0.524414\n",
      "epoch 93; iter: 0; batch classifier loss: 0.292716; batch adversarial loss: 0.553943\n",
      "epoch 94; iter: 0; batch classifier loss: 0.461261; batch adversarial loss: 0.590590\n",
      "epoch 95; iter: 0; batch classifier loss: 0.364067; batch adversarial loss: 0.506805\n",
      "epoch 96; iter: 0; batch classifier loss: 0.326269; batch adversarial loss: 0.544520\n",
      "epoch 97; iter: 0; batch classifier loss: 0.422460; batch adversarial loss: 0.470142\n",
      "epoch 98; iter: 0; batch classifier loss: 0.403582; batch adversarial loss: 0.535551\n",
      "epoch 99; iter: 0; batch classifier loss: 0.390786; batch adversarial loss: 0.535845\n",
      "epoch 100; iter: 0; batch classifier loss: 0.407974; batch adversarial loss: 0.535913\n",
      "epoch 101; iter: 0; batch classifier loss: 0.402806; batch adversarial loss: 0.553152\n",
      "epoch 102; iter: 0; batch classifier loss: 0.349169; batch adversarial loss: 0.580962\n",
      "epoch 103; iter: 0; batch classifier loss: 0.380815; batch adversarial loss: 0.581274\n",
      "epoch 104; iter: 0; batch classifier loss: 0.434070; batch adversarial loss: 0.617181\n",
      "epoch 105; iter: 0; batch classifier loss: 0.331545; batch adversarial loss: 0.498835\n",
      "epoch 106; iter: 0; batch classifier loss: 0.421865; batch adversarial loss: 0.590024\n",
      "epoch 107; iter: 0; batch classifier loss: 0.483270; batch adversarial loss: 0.534146\n",
      "epoch 108; iter: 0; batch classifier loss: 0.401988; batch adversarial loss: 0.560662\n",
      "epoch 109; iter: 0; batch classifier loss: 0.440237; batch adversarial loss: 0.498334\n",
      "epoch 110; iter: 0; batch classifier loss: 0.388919; batch adversarial loss: 0.528997\n",
      "epoch 111; iter: 0; batch classifier loss: 0.333726; batch adversarial loss: 0.516036\n",
      "epoch 112; iter: 0; batch classifier loss: 0.398425; batch adversarial loss: 0.645538\n",
      "epoch 113; iter: 0; batch classifier loss: 0.441854; batch adversarial loss: 0.479396\n",
      "epoch 114; iter: 0; batch classifier loss: 0.329868; batch adversarial loss: 0.498801\n",
      "epoch 115; iter: 0; batch classifier loss: 0.356542; batch adversarial loss: 0.507164\n",
      "epoch 116; iter: 0; batch classifier loss: 0.346227; batch adversarial loss: 0.479778\n",
      "epoch 117; iter: 0; batch classifier loss: 0.350253; batch adversarial loss: 0.544005\n",
      "epoch 118; iter: 0; batch classifier loss: 0.315349; batch adversarial loss: 0.525296\n",
      "epoch 119; iter: 0; batch classifier loss: 0.393813; batch adversarial loss: 0.563396\n",
      "epoch 120; iter: 0; batch classifier loss: 0.338352; batch adversarial loss: 0.515546\n",
      "epoch 121; iter: 0; batch classifier loss: 0.400984; batch adversarial loss: 0.590314\n",
      "epoch 122; iter: 0; batch classifier loss: 0.442235; batch adversarial loss: 0.479568\n",
      "epoch 123; iter: 0; batch classifier loss: 0.390820; batch adversarial loss: 0.479836\n",
      "epoch 124; iter: 0; batch classifier loss: 0.340268; batch adversarial loss: 0.527038\n",
      "epoch 125; iter: 0; batch classifier loss: 0.364942; batch adversarial loss: 0.572769\n",
      "epoch 126; iter: 0; batch classifier loss: 0.305940; batch adversarial loss: 0.581412\n",
      "epoch 127; iter: 0; batch classifier loss: 0.421646; batch adversarial loss: 0.638278\n",
      "epoch 128; iter: 0; batch classifier loss: 0.351775; batch adversarial loss: 0.610094\n",
      "epoch 129; iter: 0; batch classifier loss: 0.352400; batch adversarial loss: 0.535710\n",
      "epoch 130; iter: 0; batch classifier loss: 0.455669; batch adversarial loss: 0.506970\n",
      "epoch 131; iter: 0; batch classifier loss: 0.338354; batch adversarial loss: 0.525115\n",
      "epoch 132; iter: 0; batch classifier loss: 0.441377; batch adversarial loss: 0.572441\n",
      "epoch 133; iter: 0; batch classifier loss: 0.351952; batch adversarial loss: 0.599004\n",
      "epoch 134; iter: 0; batch classifier loss: 0.397347; batch adversarial loss: 0.535935\n",
      "epoch 135; iter: 0; batch classifier loss: 0.410190; batch adversarial loss: 0.498366\n",
      "epoch 136; iter: 0; batch classifier loss: 0.369513; batch adversarial loss: 0.563257\n",
      "epoch 137; iter: 0; batch classifier loss: 0.324875; batch adversarial loss: 0.506004\n",
      "epoch 138; iter: 0; batch classifier loss: 0.321790; batch adversarial loss: 0.517404\n",
      "epoch 139; iter: 0; batch classifier loss: 0.316247; batch adversarial loss: 0.525309\n",
      "epoch 140; iter: 0; batch classifier loss: 0.480789; batch adversarial loss: 0.527981\n",
      "epoch 141; iter: 0; batch classifier loss: 0.430456; batch adversarial loss: 0.598147\n",
      "epoch 142; iter: 0; batch classifier loss: 0.358110; batch adversarial loss: 0.562855\n",
      "epoch 143; iter: 0; batch classifier loss: 0.436843; batch adversarial loss: 0.637632\n",
      "epoch 144; iter: 0; batch classifier loss: 0.347855; batch adversarial loss: 0.516130\n",
      "epoch 145; iter: 0; batch classifier loss: 0.384044; batch adversarial loss: 0.506713\n",
      "epoch 146; iter: 0; batch classifier loss: 0.487982; batch adversarial loss: 0.490649\n",
      "epoch 147; iter: 0; batch classifier loss: 0.271010; batch adversarial loss: 0.526972\n",
      "epoch 148; iter: 0; batch classifier loss: 0.502007; batch adversarial loss: 0.516348\n",
      "epoch 149; iter: 0; batch classifier loss: 0.322542; batch adversarial loss: 0.544266\n",
      "epoch 150; iter: 0; batch classifier loss: 0.397137; batch adversarial loss: 0.517389\n",
      "epoch 151; iter: 0; batch classifier loss: 0.371431; batch adversarial loss: 0.506625\n",
      "epoch 152; iter: 0; batch classifier loss: 0.347899; batch adversarial loss: 0.561865\n",
      "epoch 153; iter: 0; batch classifier loss: 0.248411; batch adversarial loss: 0.543712\n",
      "epoch 154; iter: 0; batch classifier loss: 0.360142; batch adversarial loss: 0.516710\n",
      "epoch 155; iter: 0; batch classifier loss: 0.358609; batch adversarial loss: 0.516293\n",
      "epoch 156; iter: 0; batch classifier loss: 0.347198; batch adversarial loss: 0.534705\n",
      "epoch 157; iter: 0; batch classifier loss: 0.329694; batch adversarial loss: 0.441723\n",
      "epoch 158; iter: 0; batch classifier loss: 0.396145; batch adversarial loss: 0.543196\n",
      "epoch 159; iter: 0; batch classifier loss: 0.442827; batch adversarial loss: 0.526211\n",
      "epoch 160; iter: 0; batch classifier loss: 0.455666; batch adversarial loss: 0.516801\n",
      "epoch 161; iter: 0; batch classifier loss: 0.410875; batch adversarial loss: 0.591739\n",
      "epoch 162; iter: 0; batch classifier loss: 0.378879; batch adversarial loss: 0.524713\n",
      "epoch 163; iter: 0; batch classifier loss: 0.374233; batch adversarial loss: 0.563177\n",
      "epoch 164; iter: 0; batch classifier loss: 0.390778; batch adversarial loss: 0.498569\n",
      "epoch 165; iter: 0; batch classifier loss: 0.377691; batch adversarial loss: 0.562701\n",
      "epoch 166; iter: 0; batch classifier loss: 0.346433; batch adversarial loss: 0.543335\n",
      "epoch 167; iter: 0; batch classifier loss: 0.377019; batch adversarial loss: 0.580984\n",
      "epoch 168; iter: 0; batch classifier loss: 0.333276; batch adversarial loss: 0.489528\n",
      "epoch 169; iter: 0; batch classifier loss: 0.375838; batch adversarial loss: 0.572715\n",
      "epoch 170; iter: 0; batch classifier loss: 0.314811; batch adversarial loss: 0.553958\n",
      "epoch 171; iter: 0; batch classifier loss: 0.374952; batch adversarial loss: 0.535452\n",
      "epoch 172; iter: 0; batch classifier loss: 0.358455; batch adversarial loss: 0.572319\n",
      "epoch 173; iter: 0; batch classifier loss: 0.350988; batch adversarial loss: 0.507404\n",
      "epoch 174; iter: 0; batch classifier loss: 0.326461; batch adversarial loss: 0.477754\n",
      "epoch 175; iter: 0; batch classifier loss: 0.355103; batch adversarial loss: 0.598994\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 176; iter: 0; batch classifier loss: 0.355364; batch adversarial loss: 0.554132\n",
      "epoch 177; iter: 0; batch classifier loss: 0.324790; batch adversarial loss: 0.573815\n",
      "epoch 178; iter: 0; batch classifier loss: 0.330534; batch adversarial loss: 0.554377\n",
      "epoch 179; iter: 0; batch classifier loss: 0.399388; batch adversarial loss: 0.480586\n",
      "epoch 180; iter: 0; batch classifier loss: 0.390223; batch adversarial loss: 0.553893\n",
      "epoch 181; iter: 0; batch classifier loss: 0.402975; batch adversarial loss: 0.617365\n",
      "epoch 182; iter: 0; batch classifier loss: 0.363944; batch adversarial loss: 0.515523\n",
      "epoch 183; iter: 0; batch classifier loss: 0.408890; batch adversarial loss: 0.526008\n",
      "epoch 184; iter: 0; batch classifier loss: 0.353014; batch adversarial loss: 0.414555\n",
      "epoch 185; iter: 0; batch classifier loss: 0.393859; batch adversarial loss: 0.506687\n",
      "epoch 186; iter: 0; batch classifier loss: 0.450334; batch adversarial loss: 0.544588\n",
      "epoch 187; iter: 0; batch classifier loss: 0.411685; batch adversarial loss: 0.562827\n",
      "epoch 188; iter: 0; batch classifier loss: 0.401066; batch adversarial loss: 0.470213\n",
      "epoch 189; iter: 0; batch classifier loss: 0.315420; batch adversarial loss: 0.525518\n",
      "epoch 190; iter: 0; batch classifier loss: 0.387844; batch adversarial loss: 0.526779\n",
      "epoch 191; iter: 0; batch classifier loss: 0.305043; batch adversarial loss: 0.601054\n",
      "epoch 192; iter: 0; batch classifier loss: 0.453636; batch adversarial loss: 0.498589\n",
      "epoch 193; iter: 0; batch classifier loss: 0.366929; batch adversarial loss: 0.590532\n",
      "epoch 194; iter: 0; batch classifier loss: 0.424371; batch adversarial loss: 0.488553\n",
      "epoch 195; iter: 0; batch classifier loss: 0.348015; batch adversarial loss: 0.571358\n",
      "epoch 196; iter: 0; batch classifier loss: 0.320330; batch adversarial loss: 0.470373\n",
      "epoch 197; iter: 0; batch classifier loss: 0.349099; batch adversarial loss: 0.497293\n",
      "epoch 198; iter: 0; batch classifier loss: 0.354177; batch adversarial loss: 0.516502\n",
      "epoch 199; iter: 0; batch classifier loss: 0.385430; batch adversarial loss: 0.516521\n",
      "epoch 0; iter: 0; batch classifier loss: 0.721178; batch adversarial loss: 0.662766\n",
      "epoch 1; iter: 0; batch classifier loss: 0.522282; batch adversarial loss: 0.673589\n",
      "epoch 2; iter: 0; batch classifier loss: 0.542175; batch adversarial loss: 0.627024\n",
      "epoch 3; iter: 0; batch classifier loss: 0.521332; batch adversarial loss: 0.639440\n",
      "epoch 4; iter: 0; batch classifier loss: 0.570592; batch adversarial loss: 0.624499\n",
      "epoch 5; iter: 0; batch classifier loss: 0.515330; batch adversarial loss: 0.625379\n",
      "epoch 6; iter: 0; batch classifier loss: 0.543890; batch adversarial loss: 0.640986\n",
      "epoch 7; iter: 0; batch classifier loss: 0.598950; batch adversarial loss: 0.597967\n",
      "epoch 8; iter: 0; batch classifier loss: 0.508410; batch adversarial loss: 0.579781\n",
      "epoch 9; iter: 0; batch classifier loss: 0.509365; batch adversarial loss: 0.633812\n",
      "epoch 10; iter: 0; batch classifier loss: 0.608949; batch adversarial loss: 0.607939\n",
      "epoch 11; iter: 0; batch classifier loss: 0.588054; batch adversarial loss: 0.534165\n",
      "epoch 12; iter: 0; batch classifier loss: 0.586965; batch adversarial loss: 0.584522\n",
      "epoch 13; iter: 0; batch classifier loss: 0.486763; batch adversarial loss: 0.575526\n",
      "epoch 14; iter: 0; batch classifier loss: 0.527636; batch adversarial loss: 0.609499\n",
      "epoch 15; iter: 0; batch classifier loss: 0.482111; batch adversarial loss: 0.548063\n",
      "epoch 16; iter: 0; batch classifier loss: 0.497004; batch adversarial loss: 0.556320\n",
      "epoch 17; iter: 0; batch classifier loss: 0.527261; batch adversarial loss: 0.490749\n",
      "epoch 18; iter: 0; batch classifier loss: 0.508890; batch adversarial loss: 0.566968\n",
      "epoch 19; iter: 0; batch classifier loss: 0.583640; batch adversarial loss: 0.531529\n",
      "epoch 20; iter: 0; batch classifier loss: 0.508965; batch adversarial loss: 0.551216\n",
      "epoch 21; iter: 0; batch classifier loss: 0.517511; batch adversarial loss: 0.589049\n",
      "epoch 22; iter: 0; batch classifier loss: 0.480475; batch adversarial loss: 0.516855\n",
      "epoch 23; iter: 0; batch classifier loss: 0.520484; batch adversarial loss: 0.467692\n",
      "epoch 24; iter: 0; batch classifier loss: 0.482040; batch adversarial loss: 0.547976\n",
      "epoch 25; iter: 0; batch classifier loss: 0.360715; batch adversarial loss: 0.540736\n",
      "epoch 26; iter: 0; batch classifier loss: 0.479398; batch adversarial loss: 0.498565\n",
      "epoch 27; iter: 0; batch classifier loss: 0.479201; batch adversarial loss: 0.530367\n",
      "epoch 28; iter: 0; batch classifier loss: 0.431574; batch adversarial loss: 0.562180\n",
      "epoch 29; iter: 0; batch classifier loss: 0.481864; batch adversarial loss: 0.554572\n",
      "epoch 30; iter: 0; batch classifier loss: 0.485845; batch adversarial loss: 0.571010\n",
      "epoch 31; iter: 0; batch classifier loss: 0.440527; batch adversarial loss: 0.614991\n",
      "epoch 32; iter: 0; batch classifier loss: 0.501920; batch adversarial loss: 0.580014\n",
      "epoch 33; iter: 0; batch classifier loss: 0.428196; batch adversarial loss: 0.535865\n",
      "epoch 34; iter: 0; batch classifier loss: 0.472875; batch adversarial loss: 0.544846\n",
      "epoch 35; iter: 0; batch classifier loss: 0.437915; batch adversarial loss: 0.526879\n",
      "epoch 36; iter: 0; batch classifier loss: 0.466357; batch adversarial loss: 0.580449\n",
      "epoch 37; iter: 0; batch classifier loss: 0.415947; batch adversarial loss: 0.634783\n",
      "epoch 38; iter: 0; batch classifier loss: 0.420178; batch adversarial loss: 0.706212\n",
      "epoch 39; iter: 0; batch classifier loss: 0.422139; batch adversarial loss: 0.535022\n",
      "epoch 40; iter: 0; batch classifier loss: 0.460682; batch adversarial loss: 0.580653\n",
      "epoch 41; iter: 0; batch classifier loss: 0.446631; batch adversarial loss: 0.608742\n",
      "epoch 42; iter: 0; batch classifier loss: 0.510193; batch adversarial loss: 0.517151\n",
      "epoch 43; iter: 0; batch classifier loss: 0.420424; batch adversarial loss: 0.489825\n",
      "epoch 44; iter: 0; batch classifier loss: 0.461646; batch adversarial loss: 0.462385\n",
      "epoch 45; iter: 0; batch classifier loss: 0.484569; batch adversarial loss: 0.526172\n",
      "epoch 46; iter: 0; batch classifier loss: 0.429352; batch adversarial loss: 0.572861\n",
      "epoch 47; iter: 0; batch classifier loss: 0.483348; batch adversarial loss: 0.572303\n",
      "epoch 48; iter: 0; batch classifier loss: 0.482723; batch adversarial loss: 0.525791\n",
      "epoch 49; iter: 0; batch classifier loss: 0.450993; batch adversarial loss: 0.572618\n",
      "epoch 50; iter: 0; batch classifier loss: 0.488866; batch adversarial loss: 0.517231\n",
      "epoch 51; iter: 0; batch classifier loss: 0.375048; batch adversarial loss: 0.553670\n",
      "epoch 52; iter: 0; batch classifier loss: 0.422297; batch adversarial loss: 0.581292\n",
      "epoch 53; iter: 0; batch classifier loss: 0.458793; batch adversarial loss: 0.507869\n",
      "epoch 54; iter: 0; batch classifier loss: 0.419113; batch adversarial loss: 0.609220\n",
      "epoch 55; iter: 0; batch classifier loss: 0.420417; batch adversarial loss: 0.489674\n",
      "epoch 56; iter: 0; batch classifier loss: 0.476185; batch adversarial loss: 0.636069\n",
      "epoch 57; iter: 0; batch classifier loss: 0.502480; batch adversarial loss: 0.498409\n",
      "epoch 58; iter: 0; batch classifier loss: 0.464153; batch adversarial loss: 0.581207\n",
      "epoch 59; iter: 0; batch classifier loss: 0.392610; batch adversarial loss: 0.552840\n",
      "epoch 60; iter: 0; batch classifier loss: 0.455197; batch adversarial loss: 0.508215\n",
      "epoch 61; iter: 0; batch classifier loss: 0.402596; batch adversarial loss: 0.617793\n",
      "epoch 62; iter: 0; batch classifier loss: 0.463952; batch adversarial loss: 0.572165\n",
      "epoch 63; iter: 0; batch classifier loss: 0.335316; batch adversarial loss: 0.480690\n",
      "epoch 64; iter: 0; batch classifier loss: 0.405095; batch adversarial loss: 0.552880\n",
      "epoch 65; iter: 0; batch classifier loss: 0.425231; batch adversarial loss: 0.571752\n",
      "epoch 66; iter: 0; batch classifier loss: 0.444930; batch adversarial loss: 0.535788\n",
      "epoch 67; iter: 0; batch classifier loss: 0.420878; batch adversarial loss: 0.589625\n",
      "epoch 68; iter: 0; batch classifier loss: 0.417439; batch adversarial loss: 0.516983\n",
      "epoch 69; iter: 0; batch classifier loss: 0.411736; batch adversarial loss: 0.543774\n",
      "epoch 70; iter: 0; batch classifier loss: 0.352619; batch adversarial loss: 0.434088\n",
      "epoch 71; iter: 0; batch classifier loss: 0.386329; batch adversarial loss: 0.563467\n",
      "epoch 72; iter: 0; batch classifier loss: 0.398944; batch adversarial loss: 0.516690\n",
      "epoch 73; iter: 0; batch classifier loss: 0.419850; batch adversarial loss: 0.489509\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 74; iter: 0; batch classifier loss: 0.392295; batch adversarial loss: 0.536034\n",
      "epoch 75; iter: 0; batch classifier loss: 0.470299; batch adversarial loss: 0.535869\n",
      "epoch 76; iter: 0; batch classifier loss: 0.392167; batch adversarial loss: 0.461081\n",
      "epoch 77; iter: 0; batch classifier loss: 0.391773; batch adversarial loss: 0.479528\n",
      "epoch 78; iter: 0; batch classifier loss: 0.450627; batch adversarial loss: 0.516884\n",
      "epoch 79; iter: 0; batch classifier loss: 0.404710; batch adversarial loss: 0.608883\n",
      "epoch 80; iter: 0; batch classifier loss: 0.415483; batch adversarial loss: 0.600361\n",
      "epoch 81; iter: 0; batch classifier loss: 0.384978; batch adversarial loss: 0.489109\n",
      "epoch 82; iter: 0; batch classifier loss: 0.394545; batch adversarial loss: 0.443377\n",
      "epoch 83; iter: 0; batch classifier loss: 0.399375; batch adversarial loss: 0.498873\n",
      "epoch 84; iter: 0; batch classifier loss: 0.508940; batch adversarial loss: 0.526000\n",
      "epoch 85; iter: 0; batch classifier loss: 0.383132; batch adversarial loss: 0.562751\n",
      "epoch 86; iter: 0; batch classifier loss: 0.426598; batch adversarial loss: 0.527123\n",
      "epoch 87; iter: 0; batch classifier loss: 0.402719; batch adversarial loss: 0.554593\n",
      "epoch 88; iter: 0; batch classifier loss: 0.370859; batch adversarial loss: 0.544139\n",
      "epoch 89; iter: 0; batch classifier loss: 0.448807; batch adversarial loss: 0.544480\n",
      "epoch 90; iter: 0; batch classifier loss: 0.425036; batch adversarial loss: 0.562655\n",
      "epoch 91; iter: 0; batch classifier loss: 0.367908; batch adversarial loss: 0.516372\n",
      "epoch 92; iter: 0; batch classifier loss: 0.394020; batch adversarial loss: 0.525590\n",
      "epoch 93; iter: 0; batch classifier loss: 0.391559; batch adversarial loss: 0.572256\n",
      "epoch 94; iter: 0; batch classifier loss: 0.319172; batch adversarial loss: 0.480534\n",
      "epoch 95; iter: 0; batch classifier loss: 0.332395; batch adversarial loss: 0.508246\n",
      "epoch 96; iter: 0; batch classifier loss: 0.441851; batch adversarial loss: 0.597653\n",
      "epoch 97; iter: 0; batch classifier loss: 0.505481; batch adversarial loss: 0.553599\n",
      "epoch 98; iter: 0; batch classifier loss: 0.347944; batch adversarial loss: 0.536393\n",
      "epoch 99; iter: 0; batch classifier loss: 0.416029; batch adversarial loss: 0.553275\n",
      "epoch 100; iter: 0; batch classifier loss: 0.366794; batch adversarial loss: 0.506861\n",
      "epoch 101; iter: 0; batch classifier loss: 0.389648; batch adversarial loss: 0.498430\n",
      "epoch 102; iter: 0; batch classifier loss: 0.406958; batch adversarial loss: 0.507551\n",
      "epoch 103; iter: 0; batch classifier loss: 0.409076; batch adversarial loss: 0.563203\n",
      "epoch 104; iter: 0; batch classifier loss: 0.442958; batch adversarial loss: 0.498081\n",
      "epoch 105; iter: 0; batch classifier loss: 0.298914; batch adversarial loss: 0.544248\n",
      "epoch 106; iter: 0; batch classifier loss: 0.372939; batch adversarial loss: 0.572308\n",
      "epoch 107; iter: 0; batch classifier loss: 0.283904; batch adversarial loss: 0.469972\n",
      "epoch 108; iter: 0; batch classifier loss: 0.421363; batch adversarial loss: 0.582058\n",
      "epoch 109; iter: 0; batch classifier loss: 0.427492; batch adversarial loss: 0.478609\n",
      "epoch 110; iter: 0; batch classifier loss: 0.316589; batch adversarial loss: 0.607086\n",
      "epoch 111; iter: 0; batch classifier loss: 0.368602; batch adversarial loss: 0.525388\n",
      "epoch 112; iter: 0; batch classifier loss: 0.401728; batch adversarial loss: 0.541151\n",
      "epoch 113; iter: 0; batch classifier loss: 0.363195; batch adversarial loss: 0.627435\n",
      "epoch 114; iter: 0; batch classifier loss: 0.324900; batch adversarial loss: 0.581347\n",
      "epoch 115; iter: 0; batch classifier loss: 0.359308; batch adversarial loss: 0.591275\n",
      "epoch 116; iter: 0; batch classifier loss: 0.387039; batch adversarial loss: 0.461182\n",
      "epoch 117; iter: 0; batch classifier loss: 0.413832; batch adversarial loss: 0.561380\n",
      "epoch 118; iter: 0; batch classifier loss: 0.441475; batch adversarial loss: 0.598371\n",
      "epoch 119; iter: 0; batch classifier loss: 0.401136; batch adversarial loss: 0.637681\n",
      "epoch 120; iter: 0; batch classifier loss: 0.342518; batch adversarial loss: 0.489312\n",
      "epoch 121; iter: 0; batch classifier loss: 0.458335; batch adversarial loss: 0.523596\n",
      "epoch 122; iter: 0; batch classifier loss: 0.356630; batch adversarial loss: 0.563032\n",
      "epoch 123; iter: 0; batch classifier loss: 0.367406; batch adversarial loss: 0.554002\n",
      "epoch 124; iter: 0; batch classifier loss: 0.403527; batch adversarial loss: 0.497752\n",
      "epoch 125; iter: 0; batch classifier loss: 0.287038; batch adversarial loss: 0.544122\n",
      "epoch 126; iter: 0; batch classifier loss: 0.369294; batch adversarial loss: 0.488942\n",
      "epoch 127; iter: 0; batch classifier loss: 0.395306; batch adversarial loss: 0.553701\n",
      "epoch 128; iter: 0; batch classifier loss: 0.357050; batch adversarial loss: 0.608001\n",
      "epoch 129; iter: 0; batch classifier loss: 0.352027; batch adversarial loss: 0.508365\n",
      "epoch 130; iter: 0; batch classifier loss: 0.350655; batch adversarial loss: 0.588417\n",
      "epoch 131; iter: 0; batch classifier loss: 0.304676; batch adversarial loss: 0.507886\n",
      "epoch 132; iter: 0; batch classifier loss: 0.436589; batch adversarial loss: 0.490467\n",
      "epoch 133; iter: 0; batch classifier loss: 0.370082; batch adversarial loss: 0.525539\n",
      "epoch 134; iter: 0; batch classifier loss: 0.366391; batch adversarial loss: 0.599282\n",
      "epoch 135; iter: 0; batch classifier loss: 0.343766; batch adversarial loss: 0.517746\n",
      "epoch 136; iter: 0; batch classifier loss: 0.435176; batch adversarial loss: 0.616480\n",
      "epoch 137; iter: 0; batch classifier loss: 0.430226; batch adversarial loss: 0.562123\n",
      "epoch 138; iter: 0; batch classifier loss: 0.467788; batch adversarial loss: 0.555701\n",
      "epoch 139; iter: 0; batch classifier loss: 0.359305; batch adversarial loss: 0.582499\n",
      "epoch 140; iter: 0; batch classifier loss: 0.301615; batch adversarial loss: 0.525994\n",
      "epoch 141; iter: 0; batch classifier loss: 0.428591; batch adversarial loss: 0.598648\n",
      "epoch 142; iter: 0; batch classifier loss: 0.398107; batch adversarial loss: 0.560538\n",
      "epoch 143; iter: 0; batch classifier loss: 0.446967; batch adversarial loss: 0.591646\n",
      "epoch 144; iter: 0; batch classifier loss: 0.356325; batch adversarial loss: 0.562452\n",
      "epoch 145; iter: 0; batch classifier loss: 0.412932; batch adversarial loss: 0.565546\n",
      "epoch 146; iter: 0; batch classifier loss: 0.527438; batch adversarial loss: 0.496030\n",
      "epoch 147; iter: 0; batch classifier loss: 0.413020; batch adversarial loss: 0.590277\n",
      "epoch 148; iter: 0; batch classifier loss: 0.334348; batch adversarial loss: 0.524550\n",
      "epoch 149; iter: 0; batch classifier loss: 0.326251; batch adversarial loss: 0.564761\n",
      "epoch 150; iter: 0; batch classifier loss: 0.340825; batch adversarial loss: 0.545059\n",
      "epoch 151; iter: 0; batch classifier loss: 0.447406; batch adversarial loss: 0.479367\n",
      "epoch 152; iter: 0; batch classifier loss: 0.339146; batch adversarial loss: 0.545824\n",
      "epoch 153; iter: 0; batch classifier loss: 0.349337; batch adversarial loss: 0.536862\n",
      "epoch 154; iter: 0; batch classifier loss: 0.352059; batch adversarial loss: 0.637065\n",
      "epoch 155; iter: 0; batch classifier loss: 0.423200; batch adversarial loss: 0.573151\n",
      "epoch 156; iter: 0; batch classifier loss: 0.405600; batch adversarial loss: 0.537500\n",
      "epoch 157; iter: 0; batch classifier loss: 0.484728; batch adversarial loss: 0.498301\n",
      "epoch 158; iter: 0; batch classifier loss: 0.321715; batch adversarial loss: 0.608781\n",
      "epoch 159; iter: 0; batch classifier loss: 0.350962; batch adversarial loss: 0.517367\n",
      "epoch 160; iter: 0; batch classifier loss: 0.344724; batch adversarial loss: 0.652341\n",
      "epoch 161; iter: 0; batch classifier loss: 0.353571; batch adversarial loss: 0.552220\n",
      "epoch 162; iter: 0; batch classifier loss: 0.406657; batch adversarial loss: 0.515737\n",
      "epoch 163; iter: 0; batch classifier loss: 0.338638; batch adversarial loss: 0.489323\n",
      "epoch 164; iter: 0; batch classifier loss: 0.344597; batch adversarial loss: 0.561842\n",
      "epoch 165; iter: 0; batch classifier loss: 0.413520; batch adversarial loss: 0.479651\n",
      "epoch 166; iter: 0; batch classifier loss: 0.366629; batch adversarial loss: 0.533413\n",
      "epoch 167; iter: 0; batch classifier loss: 0.425203; batch adversarial loss: 0.461964\n",
      "epoch 168; iter: 0; batch classifier loss: 0.373398; batch adversarial loss: 0.542404\n",
      "epoch 169; iter: 0; batch classifier loss: 0.370680; batch adversarial loss: 0.627408\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 170; iter: 0; batch classifier loss: 0.381944; batch adversarial loss: 0.535316\n",
      "epoch 171; iter: 0; batch classifier loss: 0.375142; batch adversarial loss: 0.589516\n",
      "epoch 172; iter: 0; batch classifier loss: 0.313641; batch adversarial loss: 0.554386\n",
      "epoch 173; iter: 0; batch classifier loss: 0.476829; batch adversarial loss: 0.561979\n",
      "epoch 174; iter: 0; batch classifier loss: 0.420006; batch adversarial loss: 0.554077\n",
      "epoch 175; iter: 0; batch classifier loss: 0.273186; batch adversarial loss: 0.589744\n",
      "epoch 176; iter: 0; batch classifier loss: 0.382963; batch adversarial loss: 0.509518\n",
      "epoch 177; iter: 0; batch classifier loss: 0.414514; batch adversarial loss: 0.543472\n",
      "epoch 178; iter: 0; batch classifier loss: 0.306382; batch adversarial loss: 0.489101\n",
      "epoch 179; iter: 0; batch classifier loss: 0.370422; batch adversarial loss: 0.535066\n",
      "epoch 180; iter: 0; batch classifier loss: 0.417091; batch adversarial loss: 0.606028\n",
      "epoch 181; iter: 0; batch classifier loss: 0.402802; batch adversarial loss: 0.609120\n",
      "epoch 182; iter: 0; batch classifier loss: 0.376903; batch adversarial loss: 0.572202\n",
      "epoch 183; iter: 0; batch classifier loss: 0.340811; batch adversarial loss: 0.534550\n",
      "epoch 184; iter: 0; batch classifier loss: 0.340636; batch adversarial loss: 0.552104\n",
      "epoch 185; iter: 0; batch classifier loss: 0.461819; batch adversarial loss: 0.527260\n",
      "epoch 186; iter: 0; batch classifier loss: 0.348107; batch adversarial loss: 0.561054\n",
      "epoch 187; iter: 0; batch classifier loss: 0.442116; batch adversarial loss: 0.582208\n",
      "epoch 188; iter: 0; batch classifier loss: 0.338513; batch adversarial loss: 0.507240\n",
      "epoch 189; iter: 0; batch classifier loss: 0.350014; batch adversarial loss: 0.563593\n",
      "epoch 190; iter: 0; batch classifier loss: 0.343084; batch adversarial loss: 0.554714\n",
      "epoch 191; iter: 0; batch classifier loss: 0.366671; batch adversarial loss: 0.591609\n",
      "epoch 192; iter: 0; batch classifier loss: 0.321720; batch adversarial loss: 0.644850\n",
      "epoch 193; iter: 0; batch classifier loss: 0.362948; batch adversarial loss: 0.555227\n",
      "epoch 194; iter: 0; batch classifier loss: 0.418610; batch adversarial loss: 0.516247\n",
      "epoch 195; iter: 0; batch classifier loss: 0.366835; batch adversarial loss: 0.537340\n",
      "epoch 196; iter: 0; batch classifier loss: 0.351657; batch adversarial loss: 0.534055\n",
      "epoch 197; iter: 0; batch classifier loss: 0.390929; batch adversarial loss: 0.574106\n",
      "epoch 198; iter: 0; batch classifier loss: 0.392130; batch adversarial loss: 0.534335\n",
      "epoch 199; iter: 0; batch classifier loss: 0.335993; batch adversarial loss: 0.515853\n",
      "epoch 0; iter: 0; batch classifier loss: 0.644150; batch adversarial loss: 0.672711\n",
      "epoch 1; iter: 0; batch classifier loss: 0.623172; batch adversarial loss: 0.659748\n",
      "epoch 2; iter: 0; batch classifier loss: 0.539522; batch adversarial loss: 0.640131\n",
      "epoch 3; iter: 0; batch classifier loss: 0.504860; batch adversarial loss: 0.651632\n",
      "epoch 4; iter: 0; batch classifier loss: 0.573741; batch adversarial loss: 0.627741\n",
      "epoch 5; iter: 0; batch classifier loss: 0.662562; batch adversarial loss: 0.650809\n",
      "epoch 6; iter: 0; batch classifier loss: 0.523172; batch adversarial loss: 0.601364\n",
      "epoch 7; iter: 0; batch classifier loss: 0.588055; batch adversarial loss: 0.618412\n",
      "epoch 8; iter: 0; batch classifier loss: 0.558405; batch adversarial loss: 0.588816\n",
      "epoch 9; iter: 0; batch classifier loss: 0.466649; batch adversarial loss: 0.630412\n",
      "epoch 10; iter: 0; batch classifier loss: 0.542902; batch adversarial loss: 0.554318\n",
      "epoch 11; iter: 0; batch classifier loss: 0.429199; batch adversarial loss: 0.548929\n",
      "epoch 12; iter: 0; batch classifier loss: 0.532897; batch adversarial loss: 0.559933\n",
      "epoch 13; iter: 0; batch classifier loss: 0.540260; batch adversarial loss: 0.592355\n",
      "epoch 14; iter: 0; batch classifier loss: 0.457556; batch adversarial loss: 0.538985\n",
      "epoch 15; iter: 0; batch classifier loss: 0.476796; batch adversarial loss: 0.563002\n",
      "epoch 16; iter: 0; batch classifier loss: 0.507342; batch adversarial loss: 0.588347\n",
      "epoch 17; iter: 0; batch classifier loss: 0.416004; batch adversarial loss: 0.554496\n",
      "epoch 18; iter: 0; batch classifier loss: 0.588736; batch adversarial loss: 0.525146\n",
      "epoch 19; iter: 0; batch classifier loss: 0.484690; batch adversarial loss: 0.548351\n",
      "epoch 20; iter: 0; batch classifier loss: 0.438207; batch adversarial loss: 0.526646\n",
      "epoch 21; iter: 0; batch classifier loss: 0.500871; batch adversarial loss: 0.579223\n",
      "epoch 22; iter: 0; batch classifier loss: 0.418286; batch adversarial loss: 0.504307\n",
      "epoch 23; iter: 0; batch classifier loss: 0.459396; batch adversarial loss: 0.513395\n",
      "epoch 24; iter: 0; batch classifier loss: 0.442595; batch adversarial loss: 0.582239\n",
      "epoch 25; iter: 0; batch classifier loss: 0.527208; batch adversarial loss: 0.548661\n",
      "epoch 26; iter: 0; batch classifier loss: 0.460198; batch adversarial loss: 0.512159\n",
      "epoch 27; iter: 0; batch classifier loss: 0.458710; batch adversarial loss: 0.518809\n",
      "epoch 28; iter: 0; batch classifier loss: 0.469269; batch adversarial loss: 0.606853\n",
      "epoch 29; iter: 0; batch classifier loss: 0.512288; batch adversarial loss: 0.505115\n",
      "epoch 30; iter: 0; batch classifier loss: 0.503432; batch adversarial loss: 0.529431\n",
      "epoch 31; iter: 0; batch classifier loss: 0.468724; batch adversarial loss: 0.512005\n",
      "epoch 32; iter: 0; batch classifier loss: 0.485766; batch adversarial loss: 0.546579\n",
      "epoch 33; iter: 0; batch classifier loss: 0.408545; batch adversarial loss: 0.542658\n",
      "epoch 34; iter: 0; batch classifier loss: 0.437435; batch adversarial loss: 0.580153\n",
      "epoch 35; iter: 0; batch classifier loss: 0.422506; batch adversarial loss: 0.562794\n",
      "epoch 36; iter: 0; batch classifier loss: 0.472108; batch adversarial loss: 0.470825\n",
      "epoch 37; iter: 0; batch classifier loss: 0.543045; batch adversarial loss: 0.598605\n",
      "epoch 38; iter: 0; batch classifier loss: 0.507874; batch adversarial loss: 0.561374\n",
      "epoch 39; iter: 0; batch classifier loss: 0.403155; batch adversarial loss: 0.525113\n",
      "epoch 40; iter: 0; batch classifier loss: 0.412293; batch adversarial loss: 0.609929\n",
      "epoch 41; iter: 0; batch classifier loss: 0.456282; batch adversarial loss: 0.572585\n",
      "epoch 42; iter: 0; batch classifier loss: 0.390059; batch adversarial loss: 0.499265\n",
      "epoch 43; iter: 0; batch classifier loss: 0.473274; batch adversarial loss: 0.507689\n",
      "epoch 44; iter: 0; batch classifier loss: 0.492159; batch adversarial loss: 0.590509\n",
      "epoch 45; iter: 0; batch classifier loss: 0.473189; batch adversarial loss: 0.480402\n",
      "epoch 46; iter: 0; batch classifier loss: 0.403971; batch adversarial loss: 0.452869\n",
      "epoch 47; iter: 0; batch classifier loss: 0.408619; batch adversarial loss: 0.553755\n",
      "epoch 48; iter: 0; batch classifier loss: 0.513512; batch adversarial loss: 0.516818\n",
      "epoch 49; iter: 0; batch classifier loss: 0.376861; batch adversarial loss: 0.636887\n",
      "epoch 50; iter: 0; batch classifier loss: 0.433626; batch adversarial loss: 0.571927\n",
      "epoch 51; iter: 0; batch classifier loss: 0.436168; batch adversarial loss: 0.590340\n",
      "epoch 52; iter: 0; batch classifier loss: 0.485190; batch adversarial loss: 0.563263\n",
      "epoch 53; iter: 0; batch classifier loss: 0.468455; batch adversarial loss: 0.535202\n",
      "epoch 54; iter: 0; batch classifier loss: 0.346417; batch adversarial loss: 0.562470\n",
      "epoch 55; iter: 0; batch classifier loss: 0.437611; batch adversarial loss: 0.535768\n",
      "epoch 56; iter: 0; batch classifier loss: 0.599017; batch adversarial loss: 0.525625\n",
      "epoch 57; iter: 0; batch classifier loss: 0.552900; batch adversarial loss: 0.552844\n",
      "epoch 58; iter: 0; batch classifier loss: 0.430275; batch adversarial loss: 0.515919\n",
      "epoch 59; iter: 0; batch classifier loss: 0.462739; batch adversarial loss: 0.552355\n",
      "epoch 60; iter: 0; batch classifier loss: 0.370402; batch adversarial loss: 0.663879\n",
      "epoch 61; iter: 0; batch classifier loss: 0.425467; batch adversarial loss: 0.470719\n",
      "epoch 62; iter: 0; batch classifier loss: 0.421879; batch adversarial loss: 0.514532\n",
      "epoch 63; iter: 0; batch classifier loss: 0.425441; batch adversarial loss: 0.518104\n",
      "epoch 64; iter: 0; batch classifier loss: 0.441950; batch adversarial loss: 0.542397\n",
      "epoch 65; iter: 0; batch classifier loss: 0.425279; batch adversarial loss: 0.525903\n",
      "epoch 66; iter: 0; batch classifier loss: 0.456295; batch adversarial loss: 0.516579\n",
      "epoch 67; iter: 0; batch classifier loss: 0.453541; batch adversarial loss: 0.457948\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 68; iter: 0; batch classifier loss: 0.483293; batch adversarial loss: 0.534148\n",
      "epoch 69; iter: 0; batch classifier loss: 0.413755; batch adversarial loss: 0.491098\n",
      "epoch 70; iter: 0; batch classifier loss: 0.450771; batch adversarial loss: 0.561716\n",
      "epoch 71; iter: 0; batch classifier loss: 0.361709; batch adversarial loss: 0.533048\n",
      "epoch 72; iter: 0; batch classifier loss: 0.470842; batch adversarial loss: 0.507955\n",
      "epoch 73; iter: 0; batch classifier loss: 0.414900; batch adversarial loss: 0.424867\n",
      "epoch 74; iter: 0; batch classifier loss: 0.366281; batch adversarial loss: 0.659087\n",
      "epoch 75; iter: 0; batch classifier loss: 0.399392; batch adversarial loss: 0.545705\n",
      "epoch 76; iter: 0; batch classifier loss: 0.357749; batch adversarial loss: 0.535453\n",
      "epoch 77; iter: 0; batch classifier loss: 0.417939; batch adversarial loss: 0.525598\n",
      "epoch 78; iter: 0; batch classifier loss: 0.368119; batch adversarial loss: 0.563744\n",
      "epoch 79; iter: 0; batch classifier loss: 0.387394; batch adversarial loss: 0.515476\n",
      "epoch 80; iter: 0; batch classifier loss: 0.365843; batch adversarial loss: 0.573042\n",
      "epoch 81; iter: 0; batch classifier loss: 0.441977; batch adversarial loss: 0.553776\n",
      "epoch 82; iter: 0; batch classifier loss: 0.377505; batch adversarial loss: 0.610879\n",
      "epoch 83; iter: 0; batch classifier loss: 0.448166; batch adversarial loss: 0.544046\n",
      "epoch 84; iter: 0; batch classifier loss: 0.323546; batch adversarial loss: 0.525483\n",
      "epoch 85; iter: 0; batch classifier loss: 0.404591; batch adversarial loss: 0.470219\n",
      "epoch 86; iter: 0; batch classifier loss: 0.387313; batch adversarial loss: 0.507605\n",
      "epoch 87; iter: 0; batch classifier loss: 0.387458; batch adversarial loss: 0.479771\n",
      "epoch 88; iter: 0; batch classifier loss: 0.457226; batch adversarial loss: 0.506648\n",
      "epoch 89; iter: 0; batch classifier loss: 0.365528; batch adversarial loss: 0.552535\n",
      "epoch 90; iter: 0; batch classifier loss: 0.419351; batch adversarial loss: 0.571980\n",
      "epoch 91; iter: 0; batch classifier loss: 0.334300; batch adversarial loss: 0.582105\n",
      "epoch 92; iter: 0; batch classifier loss: 0.411936; batch adversarial loss: 0.618707\n",
      "epoch 93; iter: 0; batch classifier loss: 0.349117; batch adversarial loss: 0.507616\n",
      "epoch 94; iter: 0; batch classifier loss: 0.394052; batch adversarial loss: 0.572578\n",
      "epoch 95; iter: 0; batch classifier loss: 0.369763; batch adversarial loss: 0.591059\n",
      "epoch 96; iter: 0; batch classifier loss: 0.397114; batch adversarial loss: 0.563254\n",
      "epoch 97; iter: 0; batch classifier loss: 0.286287; batch adversarial loss: 0.469328\n",
      "epoch 98; iter: 0; batch classifier loss: 0.339404; batch adversarial loss: 0.535266\n",
      "epoch 99; iter: 0; batch classifier loss: 0.413981; batch adversarial loss: 0.543700\n",
      "epoch 100; iter: 0; batch classifier loss: 0.314832; batch adversarial loss: 0.589927\n",
      "epoch 101; iter: 0; batch classifier loss: 0.382151; batch adversarial loss: 0.581629\n",
      "epoch 102; iter: 0; batch classifier loss: 0.394268; batch adversarial loss: 0.525780\n",
      "epoch 103; iter: 0; batch classifier loss: 0.345417; batch adversarial loss: 0.534654\n",
      "epoch 104; iter: 0; batch classifier loss: 0.382789; batch adversarial loss: 0.590248\n",
      "epoch 105; iter: 0; batch classifier loss: 0.400762; batch adversarial loss: 0.552871\n",
      "epoch 106; iter: 0; batch classifier loss: 0.390018; batch adversarial loss: 0.422636\n",
      "epoch 107; iter: 0; batch classifier loss: 0.362692; batch adversarial loss: 0.515387\n",
      "epoch 108; iter: 0; batch classifier loss: 0.384043; batch adversarial loss: 0.526002\n",
      "epoch 109; iter: 0; batch classifier loss: 0.344676; batch adversarial loss: 0.637587\n",
      "epoch 110; iter: 0; batch classifier loss: 0.331074; batch adversarial loss: 0.562603\n",
      "epoch 111; iter: 0; batch classifier loss: 0.436975; batch adversarial loss: 0.515204\n",
      "epoch 112; iter: 0; batch classifier loss: 0.381753; batch adversarial loss: 0.469730\n",
      "epoch 113; iter: 0; batch classifier loss: 0.425222; batch adversarial loss: 0.599579\n",
      "epoch 114; iter: 0; batch classifier loss: 0.423318; batch adversarial loss: 0.489157\n",
      "epoch 115; iter: 0; batch classifier loss: 0.374275; batch adversarial loss: 0.517076\n",
      "epoch 116; iter: 0; batch classifier loss: 0.385146; batch adversarial loss: 0.497959\n",
      "epoch 117; iter: 0; batch classifier loss: 0.374414; batch adversarial loss: 0.462741\n",
      "epoch 118; iter: 0; batch classifier loss: 0.346687; batch adversarial loss: 0.562866\n",
      "epoch 119; iter: 0; batch classifier loss: 0.364534; batch adversarial loss: 0.543331\n",
      "epoch 120; iter: 0; batch classifier loss: 0.328088; batch adversarial loss: 0.571903\n",
      "epoch 121; iter: 0; batch classifier loss: 0.336936; batch adversarial loss: 0.552881\n",
      "epoch 122; iter: 0; batch classifier loss: 0.323641; batch adversarial loss: 0.507065\n",
      "epoch 123; iter: 0; batch classifier loss: 0.389213; batch adversarial loss: 0.544378\n",
      "epoch 124; iter: 0; batch classifier loss: 0.346233; batch adversarial loss: 0.666544\n",
      "epoch 125; iter: 0; batch classifier loss: 0.296976; batch adversarial loss: 0.535256\n",
      "epoch 126; iter: 0; batch classifier loss: 0.326342; batch adversarial loss: 0.544028\n",
      "epoch 127; iter: 0; batch classifier loss: 0.382304; batch adversarial loss: 0.571428\n",
      "epoch 128; iter: 0; batch classifier loss: 0.339499; batch adversarial loss: 0.526024\n",
      "epoch 129; iter: 0; batch classifier loss: 0.392292; batch adversarial loss: 0.563598\n",
      "epoch 130; iter: 0; batch classifier loss: 0.353719; batch adversarial loss: 0.553627\n",
      "epoch 131; iter: 0; batch classifier loss: 0.338446; batch adversarial loss: 0.562099\n",
      "epoch 132; iter: 0; batch classifier loss: 0.492700; batch adversarial loss: 0.525495\n",
      "epoch 133; iter: 0; batch classifier loss: 0.346235; batch adversarial loss: 0.562567\n",
      "epoch 134; iter: 0; batch classifier loss: 0.295940; batch adversarial loss: 0.460432\n",
      "epoch 135; iter: 0; batch classifier loss: 0.314456; batch adversarial loss: 0.571712\n",
      "epoch 136; iter: 0; batch classifier loss: 0.386060; batch adversarial loss: 0.469958\n",
      "epoch 137; iter: 0; batch classifier loss: 0.403585; batch adversarial loss: 0.601184\n",
      "epoch 138; iter: 0; batch classifier loss: 0.466191; batch adversarial loss: 0.563566\n",
      "epoch 139; iter: 0; batch classifier loss: 0.406669; batch adversarial loss: 0.525598\n",
      "epoch 140; iter: 0; batch classifier loss: 0.384983; batch adversarial loss: 0.543682\n",
      "epoch 141; iter: 0; batch classifier loss: 0.425663; batch adversarial loss: 0.553266\n",
      "epoch 142; iter: 0; batch classifier loss: 0.362246; batch adversarial loss: 0.478519\n",
      "epoch 143; iter: 0; batch classifier loss: 0.416671; batch adversarial loss: 0.572065\n",
      "epoch 144; iter: 0; batch classifier loss: 0.343096; batch adversarial loss: 0.488268\n",
      "epoch 145; iter: 0; batch classifier loss: 0.398890; batch adversarial loss: 0.545341\n",
      "epoch 146; iter: 0; batch classifier loss: 0.428208; batch adversarial loss: 0.554922\n",
      "epoch 147; iter: 0; batch classifier loss: 0.322269; batch adversarial loss: 0.488099\n",
      "epoch 148; iter: 0; batch classifier loss: 0.396266; batch adversarial loss: 0.526184\n",
      "epoch 149; iter: 0; batch classifier loss: 0.398733; batch adversarial loss: 0.525946\n",
      "epoch 150; iter: 0; batch classifier loss: 0.311761; batch adversarial loss: 0.497168\n",
      "epoch 151; iter: 0; batch classifier loss: 0.340690; batch adversarial loss: 0.582095\n",
      "epoch 152; iter: 0; batch classifier loss: 0.324264; batch adversarial loss: 0.553669\n",
      "epoch 153; iter: 0; batch classifier loss: 0.385260; batch adversarial loss: 0.498031\n",
      "epoch 154; iter: 0; batch classifier loss: 0.290949; batch adversarial loss: 0.535245\n",
      "epoch 155; iter: 0; batch classifier loss: 0.410340; batch adversarial loss: 0.572429\n",
      "epoch 156; iter: 0; batch classifier loss: 0.328227; batch adversarial loss: 0.563520\n",
      "epoch 157; iter: 0; batch classifier loss: 0.365321; batch adversarial loss: 0.563298\n",
      "epoch 158; iter: 0; batch classifier loss: 0.348707; batch adversarial loss: 0.524621\n",
      "epoch 159; iter: 0; batch classifier loss: 0.367053; batch adversarial loss: 0.499339\n",
      "epoch 160; iter: 0; batch classifier loss: 0.343733; batch adversarial loss: 0.580624\n",
      "epoch 161; iter: 0; batch classifier loss: 0.412914; batch adversarial loss: 0.516084\n",
      "epoch 162; iter: 0; batch classifier loss: 0.358422; batch adversarial loss: 0.470076\n",
      "epoch 163; iter: 0; batch classifier loss: 0.357143; batch adversarial loss: 0.526688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 164; iter: 0; batch classifier loss: 0.350050; batch adversarial loss: 0.498925\n",
      "epoch 165; iter: 0; batch classifier loss: 0.441563; batch adversarial loss: 0.505310\n",
      "epoch 166; iter: 0; batch classifier loss: 0.320487; batch adversarial loss: 0.488230\n",
      "epoch 167; iter: 0; batch classifier loss: 0.414378; batch adversarial loss: 0.543642\n",
      "epoch 168; iter: 0; batch classifier loss: 0.315147; batch adversarial loss: 0.554142\n",
      "epoch 169; iter: 0; batch classifier loss: 0.381815; batch adversarial loss: 0.498033\n",
      "epoch 170; iter: 0; batch classifier loss: 0.349184; batch adversarial loss: 0.563049\n",
      "epoch 171; iter: 0; batch classifier loss: 0.303274; batch adversarial loss: 0.489347\n",
      "epoch 172; iter: 0; batch classifier loss: 0.333185; batch adversarial loss: 0.507428\n",
      "epoch 173; iter: 0; batch classifier loss: 0.437341; batch adversarial loss: 0.507139\n",
      "epoch 174; iter: 0; batch classifier loss: 0.350309; batch adversarial loss: 0.590807\n",
      "epoch 175; iter: 0; batch classifier loss: 0.425648; batch adversarial loss: 0.536569\n",
      "epoch 176; iter: 0; batch classifier loss: 0.364879; batch adversarial loss: 0.562596\n",
      "epoch 177; iter: 0; batch classifier loss: 0.306215; batch adversarial loss: 0.488725\n",
      "epoch 178; iter: 0; batch classifier loss: 0.374070; batch adversarial loss: 0.525924\n",
      "epoch 179; iter: 0; batch classifier loss: 0.329489; batch adversarial loss: 0.533817\n",
      "epoch 180; iter: 0; batch classifier loss: 0.316485; batch adversarial loss: 0.537112\n",
      "epoch 181; iter: 0; batch classifier loss: 0.386428; batch adversarial loss: 0.524159\n",
      "epoch 182; iter: 0; batch classifier loss: 0.385777; batch adversarial loss: 0.506345\n",
      "epoch 183; iter: 0; batch classifier loss: 0.294031; batch adversarial loss: 0.545481\n",
      "epoch 184; iter: 0; batch classifier loss: 0.328139; batch adversarial loss: 0.459776\n",
      "epoch 185; iter: 0; batch classifier loss: 0.287211; batch adversarial loss: 0.534763\n",
      "epoch 186; iter: 0; batch classifier loss: 0.377116; batch adversarial loss: 0.562437\n",
      "epoch 187; iter: 0; batch classifier loss: 0.373057; batch adversarial loss: 0.544572\n",
      "epoch 188; iter: 0; batch classifier loss: 0.445824; batch adversarial loss: 0.646381\n",
      "epoch 189; iter: 0; batch classifier loss: 0.367801; batch adversarial loss: 0.499041\n",
      "epoch 190; iter: 0; batch classifier loss: 0.379125; batch adversarial loss: 0.590654\n",
      "epoch 191; iter: 0; batch classifier loss: 0.409316; batch adversarial loss: 0.524851\n",
      "epoch 192; iter: 0; batch classifier loss: 0.380186; batch adversarial loss: 0.592076\n",
      "epoch 193; iter: 0; batch classifier loss: 0.363728; batch adversarial loss: 0.535058\n",
      "epoch 194; iter: 0; batch classifier loss: 0.422878; batch adversarial loss: 0.543576\n",
      "epoch 195; iter: 0; batch classifier loss: 0.323143; batch adversarial loss: 0.517186\n",
      "epoch 196; iter: 0; batch classifier loss: 0.370345; batch adversarial loss: 0.498407\n",
      "epoch 197; iter: 0; batch classifier loss: 0.291581; batch adversarial loss: 0.525150\n",
      "epoch 198; iter: 0; batch classifier loss: 0.404112; batch adversarial loss: 0.459462\n",
      "epoch 199; iter: 0; batch classifier loss: 0.326411; batch adversarial loss: 0.507053\n",
      "epoch 0; iter: 0; batch classifier loss: 0.692191; batch adversarial loss: 0.754020\n",
      "epoch 1; iter: 0; batch classifier loss: 0.582327; batch adversarial loss: 0.716004\n",
      "epoch 2; iter: 0; batch classifier loss: 0.587327; batch adversarial loss: 0.696753\n",
      "epoch 3; iter: 0; batch classifier loss: 0.569307; batch adversarial loss: 0.662152\n",
      "epoch 4; iter: 0; batch classifier loss: 0.569803; batch adversarial loss: 0.663067\n",
      "epoch 5; iter: 0; batch classifier loss: 0.575840; batch adversarial loss: 0.613460\n",
      "epoch 6; iter: 0; batch classifier loss: 0.566058; batch adversarial loss: 0.597695\n",
      "epoch 7; iter: 0; batch classifier loss: 0.523661; batch adversarial loss: 0.569547\n",
      "epoch 8; iter: 0; batch classifier loss: 0.548215; batch adversarial loss: 0.599992\n",
      "epoch 9; iter: 0; batch classifier loss: 0.556052; batch adversarial loss: 0.604334\n",
      "epoch 10; iter: 0; batch classifier loss: 0.607920; batch adversarial loss: 0.616452\n",
      "epoch 11; iter: 0; batch classifier loss: 0.531338; batch adversarial loss: 0.539687\n",
      "epoch 12; iter: 0; batch classifier loss: 0.544945; batch adversarial loss: 0.597020\n",
      "epoch 13; iter: 0; batch classifier loss: 0.530546; batch adversarial loss: 0.556982\n",
      "epoch 14; iter: 0; batch classifier loss: 0.574410; batch adversarial loss: 0.587774\n",
      "epoch 15; iter: 0; batch classifier loss: 0.570930; batch adversarial loss: 0.622859\n",
      "epoch 16; iter: 0; batch classifier loss: 0.493656; batch adversarial loss: 0.625633\n",
      "epoch 17; iter: 0; batch classifier loss: 0.484497; batch adversarial loss: 0.484272\n",
      "epoch 18; iter: 0; batch classifier loss: 0.498761; batch adversarial loss: 0.622710\n",
      "epoch 19; iter: 0; batch classifier loss: 0.596804; batch adversarial loss: 0.552939\n",
      "epoch 20; iter: 0; batch classifier loss: 0.507627; batch adversarial loss: 0.612174\n",
      "epoch 21; iter: 0; batch classifier loss: 0.575286; batch adversarial loss: 0.560689\n",
      "epoch 22; iter: 0; batch classifier loss: 0.473576; batch adversarial loss: 0.653712\n",
      "epoch 23; iter: 0; batch classifier loss: 0.487105; batch adversarial loss: 0.542200\n",
      "epoch 24; iter: 0; batch classifier loss: 0.483620; batch adversarial loss: 0.530969\n",
      "epoch 25; iter: 0; batch classifier loss: 0.556070; batch adversarial loss: 0.560182\n",
      "epoch 26; iter: 0; batch classifier loss: 0.468435; batch adversarial loss: 0.611044\n",
      "epoch 27; iter: 0; batch classifier loss: 0.487195; batch adversarial loss: 0.541143\n",
      "epoch 28; iter: 0; batch classifier loss: 0.392427; batch adversarial loss: 0.455666\n",
      "epoch 29; iter: 0; batch classifier loss: 0.487781; batch adversarial loss: 0.579792\n",
      "epoch 30; iter: 0; batch classifier loss: 0.479812; batch adversarial loss: 0.525295\n",
      "epoch 31; iter: 0; batch classifier loss: 0.366512; batch adversarial loss: 0.519982\n",
      "epoch 32; iter: 0; batch classifier loss: 0.473104; batch adversarial loss: 0.598929\n",
      "epoch 33; iter: 0; batch classifier loss: 0.446523; batch adversarial loss: 0.566957\n",
      "epoch 34; iter: 0; batch classifier loss: 0.448558; batch adversarial loss: 0.548814\n",
      "epoch 35; iter: 0; batch classifier loss: 0.463463; batch adversarial loss: 0.524682\n",
      "epoch 36; iter: 0; batch classifier loss: 0.461759; batch adversarial loss: 0.560156\n",
      "epoch 37; iter: 0; batch classifier loss: 0.495675; batch adversarial loss: 0.509661\n",
      "epoch 38; iter: 0; batch classifier loss: 0.487790; batch adversarial loss: 0.570220\n",
      "epoch 39; iter: 0; batch classifier loss: 0.452207; batch adversarial loss: 0.544738\n",
      "epoch 40; iter: 0; batch classifier loss: 0.484939; batch adversarial loss: 0.581072\n",
      "epoch 41; iter: 0; batch classifier loss: 0.464653; batch adversarial loss: 0.482455\n",
      "epoch 42; iter: 0; batch classifier loss: 0.441051; batch adversarial loss: 0.562280\n",
      "epoch 43; iter: 0; batch classifier loss: 0.511922; batch adversarial loss: 0.579858\n",
      "epoch 44; iter: 0; batch classifier loss: 0.458877; batch adversarial loss: 0.563210\n",
      "epoch 45; iter: 0; batch classifier loss: 0.388029; batch adversarial loss: 0.562981\n",
      "epoch 46; iter: 0; batch classifier loss: 0.520130; batch adversarial loss: 0.444996\n",
      "epoch 47; iter: 0; batch classifier loss: 0.423777; batch adversarial loss: 0.526353\n",
      "epoch 48; iter: 0; batch classifier loss: 0.429442; batch adversarial loss: 0.562900\n",
      "epoch 49; iter: 0; batch classifier loss: 0.432771; batch adversarial loss: 0.571813\n",
      "epoch 50; iter: 0; batch classifier loss: 0.386950; batch adversarial loss: 0.517057\n",
      "epoch 51; iter: 0; batch classifier loss: 0.446200; batch adversarial loss: 0.608069\n",
      "epoch 52; iter: 0; batch classifier loss: 0.419923; batch adversarial loss: 0.571734\n",
      "epoch 53; iter: 0; batch classifier loss: 0.371269; batch adversarial loss: 0.579123\n",
      "epoch 54; iter: 0; batch classifier loss: 0.439306; batch adversarial loss: 0.517106\n",
      "epoch 55; iter: 0; batch classifier loss: 0.401830; batch adversarial loss: 0.527015\n",
      "epoch 56; iter: 0; batch classifier loss: 0.389414; batch adversarial loss: 0.525763\n",
      "epoch 57; iter: 0; batch classifier loss: 0.423393; batch adversarial loss: 0.595185\n",
      "epoch 58; iter: 0; batch classifier loss: 0.350613; batch adversarial loss: 0.480624\n",
      "epoch 59; iter: 0; batch classifier loss: 0.481420; batch adversarial loss: 0.561472\n",
      "epoch 60; iter: 0; batch classifier loss: 0.550908; batch adversarial loss: 0.552880\n",
      "epoch 61; iter: 0; batch classifier loss: 0.443394; batch adversarial loss: 0.487348\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 62; iter: 0; batch classifier loss: 0.439093; batch adversarial loss: 0.573604\n",
      "epoch 63; iter: 0; batch classifier loss: 0.356526; batch adversarial loss: 0.570998\n",
      "epoch 64; iter: 0; batch classifier loss: 0.415298; batch adversarial loss: 0.566975\n",
      "epoch 65; iter: 0; batch classifier loss: 0.436324; batch adversarial loss: 0.553461\n",
      "epoch 66; iter: 0; batch classifier loss: 0.471268; batch adversarial loss: 0.536875\n",
      "epoch 67; iter: 0; batch classifier loss: 0.397655; batch adversarial loss: 0.536188\n",
      "epoch 68; iter: 0; batch classifier loss: 0.402965; batch adversarial loss: 0.568726\n",
      "epoch 69; iter: 0; batch classifier loss: 0.369245; batch adversarial loss: 0.616355\n",
      "epoch 70; iter: 0; batch classifier loss: 0.324239; batch adversarial loss: 0.590328\n",
      "epoch 71; iter: 0; batch classifier loss: 0.397502; batch adversarial loss: 0.452138\n",
      "epoch 72; iter: 0; batch classifier loss: 0.466561; batch adversarial loss: 0.535220\n",
      "epoch 73; iter: 0; batch classifier loss: 0.392080; batch adversarial loss: 0.481143\n",
      "epoch 74; iter: 0; batch classifier loss: 0.427924; batch adversarial loss: 0.509240\n",
      "epoch 75; iter: 0; batch classifier loss: 0.421381; batch adversarial loss: 0.469580\n",
      "epoch 76; iter: 0; batch classifier loss: 0.349888; batch adversarial loss: 0.540386\n",
      "epoch 77; iter: 0; batch classifier loss: 0.471735; batch adversarial loss: 0.498952\n",
      "epoch 78; iter: 0; batch classifier loss: 0.356523; batch adversarial loss: 0.635881\n",
      "epoch 79; iter: 0; batch classifier loss: 0.517017; batch adversarial loss: 0.603246\n",
      "epoch 80; iter: 0; batch classifier loss: 0.449125; batch adversarial loss: 0.572776\n",
      "epoch 81; iter: 0; batch classifier loss: 0.536516; batch adversarial loss: 0.545907\n",
      "epoch 82; iter: 0; batch classifier loss: 0.340968; batch adversarial loss: 0.554604\n",
      "epoch 83; iter: 0; batch classifier loss: 0.346121; batch adversarial loss: 0.572841\n",
      "epoch 84; iter: 0; batch classifier loss: 0.396003; batch adversarial loss: 0.516868\n",
      "epoch 85; iter: 0; batch classifier loss: 0.428637; batch adversarial loss: 0.472008\n",
      "epoch 86; iter: 0; batch classifier loss: 0.403806; batch adversarial loss: 0.515372\n",
      "epoch 87; iter: 0; batch classifier loss: 0.347996; batch adversarial loss: 0.505967\n",
      "epoch 88; iter: 0; batch classifier loss: 0.360252; batch adversarial loss: 0.583063\n",
      "epoch 89; iter: 0; batch classifier loss: 0.440143; batch adversarial loss: 0.592017\n",
      "epoch 90; iter: 0; batch classifier loss: 0.398510; batch adversarial loss: 0.581989\n",
      "epoch 91; iter: 0; batch classifier loss: 0.386770; batch adversarial loss: 0.534576\n",
      "epoch 92; iter: 0; batch classifier loss: 0.411795; batch adversarial loss: 0.573099\n",
      "epoch 93; iter: 0; batch classifier loss: 0.379936; batch adversarial loss: 0.608793\n",
      "epoch 94; iter: 0; batch classifier loss: 0.490531; batch adversarial loss: 0.602073\n",
      "epoch 95; iter: 0; batch classifier loss: 0.401737; batch adversarial loss: 0.543395\n",
      "epoch 96; iter: 0; batch classifier loss: 0.371447; batch adversarial loss: 0.517506\n",
      "epoch 97; iter: 0; batch classifier loss: 0.372800; batch adversarial loss: 0.532856\n",
      "epoch 98; iter: 0; batch classifier loss: 0.404663; batch adversarial loss: 0.525498\n",
      "epoch 99; iter: 0; batch classifier loss: 0.377302; batch adversarial loss: 0.526959\n",
      "epoch 100; iter: 0; batch classifier loss: 0.420672; batch adversarial loss: 0.567564\n",
      "epoch 101; iter: 0; batch classifier loss: 0.387136; batch adversarial loss: 0.551880\n",
      "epoch 102; iter: 0; batch classifier loss: 0.325441; batch adversarial loss: 0.561434\n",
      "epoch 103; iter: 0; batch classifier loss: 0.431526; batch adversarial loss: 0.540737\n",
      "epoch 104; iter: 0; batch classifier loss: 0.344674; batch adversarial loss: 0.580828\n",
      "epoch 105; iter: 0; batch classifier loss: 0.337569; batch adversarial loss: 0.589564\n",
      "epoch 106; iter: 0; batch classifier loss: 0.381105; batch adversarial loss: 0.542793\n",
      "epoch 107; iter: 0; batch classifier loss: 0.414904; batch adversarial loss: 0.570864\n",
      "epoch 108; iter: 0; batch classifier loss: 0.362663; batch adversarial loss: 0.588895\n",
      "epoch 109; iter: 0; batch classifier loss: 0.347114; batch adversarial loss: 0.506215\n",
      "epoch 110; iter: 0; batch classifier loss: 0.437915; batch adversarial loss: 0.562595\n",
      "epoch 111; iter: 0; batch classifier loss: 0.415736; batch adversarial loss: 0.529856\n",
      "epoch 112; iter: 0; batch classifier loss: 0.462582; batch adversarial loss: 0.591901\n",
      "epoch 113; iter: 0; batch classifier loss: 0.313416; batch adversarial loss: 0.517225\n",
      "epoch 114; iter: 0; batch classifier loss: 0.415820; batch adversarial loss: 0.563535\n",
      "epoch 115; iter: 0; batch classifier loss: 0.357847; batch adversarial loss: 0.469416\n",
      "epoch 116; iter: 0; batch classifier loss: 0.450656; batch adversarial loss: 0.526636\n",
      "epoch 117; iter: 0; batch classifier loss: 0.464740; batch adversarial loss: 0.609872\n",
      "epoch 118; iter: 0; batch classifier loss: 0.355927; batch adversarial loss: 0.553472\n",
      "epoch 119; iter: 0; batch classifier loss: 0.354012; batch adversarial loss: 0.488949\n",
      "epoch 120; iter: 0; batch classifier loss: 0.384860; batch adversarial loss: 0.526604\n",
      "epoch 121; iter: 0; batch classifier loss: 0.434570; batch adversarial loss: 0.507992\n",
      "epoch 122; iter: 0; batch classifier loss: 0.382653; batch adversarial loss: 0.608777\n",
      "epoch 123; iter: 0; batch classifier loss: 0.345660; batch adversarial loss: 0.559940\n",
      "epoch 124; iter: 0; batch classifier loss: 0.387180; batch adversarial loss: 0.543861\n",
      "epoch 125; iter: 0; batch classifier loss: 0.351814; batch adversarial loss: 0.532217\n",
      "epoch 126; iter: 0; batch classifier loss: 0.376379; batch adversarial loss: 0.573897\n",
      "epoch 127; iter: 0; batch classifier loss: 0.431588; batch adversarial loss: 0.636585\n",
      "epoch 128; iter: 0; batch classifier loss: 0.380181; batch adversarial loss: 0.509404\n",
      "epoch 129; iter: 0; batch classifier loss: 0.394525; batch adversarial loss: 0.489644\n",
      "epoch 130; iter: 0; batch classifier loss: 0.360737; batch adversarial loss: 0.573706\n",
      "epoch 131; iter: 0; batch classifier loss: 0.375998; batch adversarial loss: 0.489299\n",
      "epoch 132; iter: 0; batch classifier loss: 0.312030; batch adversarial loss: 0.496926\n",
      "epoch 133; iter: 0; batch classifier loss: 0.299710; batch adversarial loss: 0.599828\n",
      "epoch 134; iter: 0; batch classifier loss: 0.320576; batch adversarial loss: 0.555351\n",
      "epoch 135; iter: 0; batch classifier loss: 0.357503; batch adversarial loss: 0.553980\n",
      "epoch 136; iter: 0; batch classifier loss: 0.427740; batch adversarial loss: 0.528602\n",
      "epoch 137; iter: 0; batch classifier loss: 0.402975; batch adversarial loss: 0.590161\n",
      "epoch 138; iter: 0; batch classifier loss: 0.415198; batch adversarial loss: 0.542387\n",
      "epoch 139; iter: 0; batch classifier loss: 0.458915; batch adversarial loss: 0.582099\n",
      "epoch 140; iter: 0; batch classifier loss: 0.447122; batch adversarial loss: 0.545970\n",
      "epoch 141; iter: 0; batch classifier loss: 0.392636; batch adversarial loss: 0.516555\n",
      "epoch 142; iter: 0; batch classifier loss: 0.329592; batch adversarial loss: 0.592699\n",
      "epoch 143; iter: 0; batch classifier loss: 0.332583; batch adversarial loss: 0.555235\n",
      "epoch 144; iter: 0; batch classifier loss: 0.333210; batch adversarial loss: 0.626994\n",
      "epoch 145; iter: 0; batch classifier loss: 0.356518; batch adversarial loss: 0.627105\n",
      "epoch 146; iter: 0; batch classifier loss: 0.418152; batch adversarial loss: 0.572619\n",
      "epoch 147; iter: 0; batch classifier loss: 0.463296; batch adversarial loss: 0.602800\n",
      "epoch 148; iter: 0; batch classifier loss: 0.345229; batch adversarial loss: 0.564845\n",
      "epoch 149; iter: 0; batch classifier loss: 0.403311; batch adversarial loss: 0.517286\n",
      "epoch 150; iter: 0; batch classifier loss: 0.434607; batch adversarial loss: 0.619281\n",
      "epoch 151; iter: 0; batch classifier loss: 0.370697; batch adversarial loss: 0.518384\n",
      "epoch 152; iter: 0; batch classifier loss: 0.339328; batch adversarial loss: 0.591514\n",
      "epoch 153; iter: 0; batch classifier loss: 0.365988; batch adversarial loss: 0.499627\n",
      "epoch 154; iter: 0; batch classifier loss: 0.434587; batch adversarial loss: 0.627572\n",
      "epoch 155; iter: 0; batch classifier loss: 0.412535; batch adversarial loss: 0.582316\n",
      "epoch 156; iter: 0; batch classifier loss: 0.386697; batch adversarial loss: 0.552404\n",
      "epoch 157; iter: 0; batch classifier loss: 0.312459; batch adversarial loss: 0.591284\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 158; iter: 0; batch classifier loss: 0.465050; batch adversarial loss: 0.661105\n",
      "epoch 159; iter: 0; batch classifier loss: 0.374115; batch adversarial loss: 0.488379\n",
      "epoch 160; iter: 0; batch classifier loss: 0.372176; batch adversarial loss: 0.569959\n",
      "epoch 161; iter: 0; batch classifier loss: 0.370709; batch adversarial loss: 0.479915\n",
      "epoch 162; iter: 0; batch classifier loss: 0.384011; batch adversarial loss: 0.569287\n",
      "epoch 163; iter: 0; batch classifier loss: 0.460100; batch adversarial loss: 0.625766\n",
      "epoch 164; iter: 0; batch classifier loss: 0.399780; batch adversarial loss: 0.562588\n",
      "epoch 165; iter: 0; batch classifier loss: 0.345202; batch adversarial loss: 0.554891\n",
      "epoch 166; iter: 0; batch classifier loss: 0.326730; batch adversarial loss: 0.516410\n",
      "epoch 167; iter: 0; batch classifier loss: 0.436079; batch adversarial loss: 0.480290\n",
      "epoch 168; iter: 0; batch classifier loss: 0.286532; batch adversarial loss: 0.554261\n",
      "epoch 169; iter: 0; batch classifier loss: 0.353643; batch adversarial loss: 0.544576\n",
      "epoch 170; iter: 0; batch classifier loss: 0.411546; batch adversarial loss: 0.493526\n",
      "epoch 171; iter: 0; batch classifier loss: 0.346148; batch adversarial loss: 0.477991\n",
      "epoch 172; iter: 0; batch classifier loss: 0.370059; batch adversarial loss: 0.526975\n",
      "epoch 173; iter: 0; batch classifier loss: 0.398929; batch adversarial loss: 0.563258\n",
      "epoch 174; iter: 0; batch classifier loss: 0.348806; batch adversarial loss: 0.573575\n",
      "epoch 175; iter: 0; batch classifier loss: 0.324968; batch adversarial loss: 0.526319\n",
      "epoch 176; iter: 0; batch classifier loss: 0.406029; batch adversarial loss: 0.490161\n",
      "epoch 177; iter: 0; batch classifier loss: 0.356472; batch adversarial loss: 0.602414\n",
      "epoch 178; iter: 0; batch classifier loss: 0.363706; batch adversarial loss: 0.527505\n",
      "epoch 179; iter: 0; batch classifier loss: 0.425703; batch adversarial loss: 0.487028\n",
      "epoch 180; iter: 0; batch classifier loss: 0.368141; batch adversarial loss: 0.497604\n",
      "epoch 181; iter: 0; batch classifier loss: 0.383102; batch adversarial loss: 0.627527\n",
      "epoch 182; iter: 0; batch classifier loss: 0.330854; batch adversarial loss: 0.525609\n",
      "epoch 183; iter: 0; batch classifier loss: 0.343880; batch adversarial loss: 0.517047\n",
      "epoch 184; iter: 0; batch classifier loss: 0.374384; batch adversarial loss: 0.517719\n",
      "epoch 185; iter: 0; batch classifier loss: 0.343202; batch adversarial loss: 0.562071\n",
      "epoch 186; iter: 0; batch classifier loss: 0.341839; batch adversarial loss: 0.545755\n",
      "epoch 187; iter: 0; batch classifier loss: 0.425165; batch adversarial loss: 0.546032\n",
      "epoch 188; iter: 0; batch classifier loss: 0.333589; batch adversarial loss: 0.560626\n",
      "epoch 189; iter: 0; batch classifier loss: 0.362114; batch adversarial loss: 0.590998\n",
      "epoch 190; iter: 0; batch classifier loss: 0.391853; batch adversarial loss: 0.629602\n",
      "epoch 191; iter: 0; batch classifier loss: 0.407799; batch adversarial loss: 0.525936\n",
      "epoch 192; iter: 0; batch classifier loss: 0.402080; batch adversarial loss: 0.471677\n",
      "epoch 193; iter: 0; batch classifier loss: 0.336076; batch adversarial loss: 0.553811\n",
      "epoch 194; iter: 0; batch classifier loss: 0.356673; batch adversarial loss: 0.462407\n",
      "epoch 195; iter: 0; batch classifier loss: 0.368619; batch adversarial loss: 0.561629\n",
      "epoch 196; iter: 0; batch classifier loss: 0.336288; batch adversarial loss: 0.508453\n",
      "epoch 197; iter: 0; batch classifier loss: 0.442566; batch adversarial loss: 0.489424\n",
      "epoch 198; iter: 0; batch classifier loss: 0.338023; batch adversarial loss: 0.534524\n",
      "epoch 199; iter: 0; batch classifier loss: 0.378287; batch adversarial loss: 0.471993\n",
      "epoch 0; iter: 0; batch classifier loss: 0.693263; batch adversarial loss: 0.620251\n",
      "epoch 1; iter: 0; batch classifier loss: 0.600668; batch adversarial loss: 0.651149\n",
      "epoch 2; iter: 0; batch classifier loss: 0.586203; batch adversarial loss: 0.657776\n",
      "epoch 3; iter: 0; batch classifier loss: 0.582742; batch adversarial loss: 0.578383\n",
      "epoch 4; iter: 0; batch classifier loss: 0.506474; batch adversarial loss: 0.630307\n",
      "epoch 5; iter: 0; batch classifier loss: 0.547453; batch adversarial loss: 0.617225\n",
      "epoch 6; iter: 0; batch classifier loss: 0.538397; batch adversarial loss: 0.586126\n",
      "epoch 7; iter: 0; batch classifier loss: 0.524963; batch adversarial loss: 0.646197\n",
      "epoch 8; iter: 0; batch classifier loss: 0.571798; batch adversarial loss: 0.577077\n",
      "epoch 9; iter: 0; batch classifier loss: 0.519180; batch adversarial loss: 0.614699\n",
      "epoch 10; iter: 0; batch classifier loss: 0.508051; batch adversarial loss: 0.636712\n",
      "epoch 11; iter: 0; batch classifier loss: 0.571402; batch adversarial loss: 0.552874\n",
      "epoch 12; iter: 0; batch classifier loss: 0.447334; batch adversarial loss: 0.597308\n",
      "epoch 13; iter: 0; batch classifier loss: 0.448862; batch adversarial loss: 0.591906\n",
      "epoch 14; iter: 0; batch classifier loss: 0.438734; batch adversarial loss: 0.568899\n",
      "epoch 15; iter: 0; batch classifier loss: 0.441460; batch adversarial loss: 0.615451\n",
      "epoch 16; iter: 0; batch classifier loss: 0.517370; batch adversarial loss: 0.623243\n",
      "epoch 17; iter: 0; batch classifier loss: 0.479372; batch adversarial loss: 0.485925\n",
      "epoch 18; iter: 0; batch classifier loss: 0.479340; batch adversarial loss: 0.549340\n",
      "epoch 19; iter: 0; batch classifier loss: 0.469501; batch adversarial loss: 0.525329\n",
      "epoch 20; iter: 0; batch classifier loss: 0.463793; batch adversarial loss: 0.519829\n",
      "epoch 21; iter: 0; batch classifier loss: 0.439054; batch adversarial loss: 0.612611\n",
      "epoch 22; iter: 0; batch classifier loss: 0.529286; batch adversarial loss: 0.568220\n",
      "epoch 23; iter: 0; batch classifier loss: 0.421775; batch adversarial loss: 0.536704\n",
      "epoch 24; iter: 0; batch classifier loss: 0.456142; batch adversarial loss: 0.529054\n",
      "epoch 25; iter: 0; batch classifier loss: 0.371793; batch adversarial loss: 0.621541\n",
      "epoch 26; iter: 0; batch classifier loss: 0.452040; batch adversarial loss: 0.605192\n",
      "epoch 27; iter: 0; batch classifier loss: 0.461907; batch adversarial loss: 0.590059\n",
      "epoch 28; iter: 0; batch classifier loss: 0.462560; batch adversarial loss: 0.634154\n",
      "epoch 29; iter: 0; batch classifier loss: 0.444841; batch adversarial loss: 0.610343\n",
      "epoch 30; iter: 0; batch classifier loss: 0.469753; batch adversarial loss: 0.585438\n",
      "epoch 31; iter: 0; batch classifier loss: 0.406323; batch adversarial loss: 0.551345\n",
      "epoch 32; iter: 0; batch classifier loss: 0.401098; batch adversarial loss: 0.580200\n",
      "epoch 33; iter: 0; batch classifier loss: 0.519506; batch adversarial loss: 0.593793\n",
      "epoch 34; iter: 0; batch classifier loss: 0.427913; batch adversarial loss: 0.573577\n",
      "epoch 35; iter: 0; batch classifier loss: 0.481335; batch adversarial loss: 0.546486\n",
      "epoch 36; iter: 0; batch classifier loss: 0.416260; batch adversarial loss: 0.606574\n",
      "epoch 37; iter: 0; batch classifier loss: 0.378645; batch adversarial loss: 0.571464\n",
      "epoch 38; iter: 0; batch classifier loss: 0.505403; batch adversarial loss: 0.606897\n",
      "epoch 39; iter: 0; batch classifier loss: 0.452691; batch adversarial loss: 0.550220\n",
      "epoch 40; iter: 0; batch classifier loss: 0.412318; batch adversarial loss: 0.588897\n",
      "epoch 41; iter: 0; batch classifier loss: 0.437327; batch adversarial loss: 0.553358\n",
      "epoch 42; iter: 0; batch classifier loss: 0.452576; batch adversarial loss: 0.511062\n",
      "epoch 43; iter: 0; batch classifier loss: 0.402537; batch adversarial loss: 0.551571\n",
      "epoch 44; iter: 0; batch classifier loss: 0.414877; batch adversarial loss: 0.524300\n",
      "epoch 45; iter: 0; batch classifier loss: 0.459485; batch adversarial loss: 0.552976\n",
      "epoch 46; iter: 0; batch classifier loss: 0.454842; batch adversarial loss: 0.579857\n",
      "epoch 47; iter: 0; batch classifier loss: 0.506009; batch adversarial loss: 0.552531\n",
      "epoch 48; iter: 0; batch classifier loss: 0.442954; batch adversarial loss: 0.460362\n",
      "epoch 49; iter: 0; batch classifier loss: 0.389485; batch adversarial loss: 0.535458\n",
      "epoch 50; iter: 0; batch classifier loss: 0.463438; batch adversarial loss: 0.579901\n",
      "epoch 51; iter: 0; batch classifier loss: 0.428302; batch adversarial loss: 0.643504\n",
      "epoch 52; iter: 0; batch classifier loss: 0.434225; batch adversarial loss: 0.474263\n",
      "epoch 53; iter: 0; batch classifier loss: 0.410689; batch adversarial loss: 0.586001\n",
      "epoch 54; iter: 0; batch classifier loss: 0.425338; batch adversarial loss: 0.565476\n",
      "epoch 55; iter: 0; batch classifier loss: 0.476670; batch adversarial loss: 0.572678\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 56; iter: 0; batch classifier loss: 0.401954; batch adversarial loss: 0.537551\n",
      "epoch 57; iter: 0; batch classifier loss: 0.464590; batch adversarial loss: 0.583841\n",
      "epoch 58; iter: 0; batch classifier loss: 0.411072; batch adversarial loss: 0.599901\n",
      "epoch 59; iter: 0; batch classifier loss: 0.424719; batch adversarial loss: 0.628414\n",
      "epoch 60; iter: 0; batch classifier loss: 0.410625; batch adversarial loss: 0.678874\n",
      "epoch 61; iter: 0; batch classifier loss: 0.305291; batch adversarial loss: 0.498013\n",
      "epoch 62; iter: 0; batch classifier loss: 0.459768; batch adversarial loss: 0.661020\n",
      "epoch 63; iter: 0; batch classifier loss: 0.387811; batch adversarial loss: 0.532846\n",
      "epoch 64; iter: 0; batch classifier loss: 0.388283; batch adversarial loss: 0.536597\n",
      "epoch 65; iter: 0; batch classifier loss: 0.422950; batch adversarial loss: 0.539866\n",
      "epoch 66; iter: 0; batch classifier loss: 0.380367; batch adversarial loss: 0.579532\n",
      "epoch 67; iter: 0; batch classifier loss: 0.408354; batch adversarial loss: 0.505690\n",
      "epoch 68; iter: 0; batch classifier loss: 0.389299; batch adversarial loss: 0.554239\n",
      "epoch 69; iter: 0; batch classifier loss: 0.397824; batch adversarial loss: 0.452816\n",
      "epoch 70; iter: 0; batch classifier loss: 0.398041; batch adversarial loss: 0.578890\n",
      "epoch 71; iter: 0; batch classifier loss: 0.342851; batch adversarial loss: 0.491442\n",
      "epoch 72; iter: 0; batch classifier loss: 0.399501; batch adversarial loss: 0.547178\n",
      "epoch 73; iter: 0; batch classifier loss: 0.372528; batch adversarial loss: 0.570493\n",
      "epoch 74; iter: 0; batch classifier loss: 0.394690; batch adversarial loss: 0.464738\n",
      "epoch 75; iter: 0; batch classifier loss: 0.445204; batch adversarial loss: 0.527557\n",
      "epoch 76; iter: 0; batch classifier loss: 0.422562; batch adversarial loss: 0.491069\n",
      "epoch 77; iter: 0; batch classifier loss: 0.406739; batch adversarial loss: 0.626648\n",
      "epoch 78; iter: 0; batch classifier loss: 0.433079; batch adversarial loss: 0.544209\n",
      "epoch 79; iter: 0; batch classifier loss: 0.349966; batch adversarial loss: 0.508115\n",
      "epoch 80; iter: 0; batch classifier loss: 0.375393; batch adversarial loss: 0.500451\n",
      "epoch 81; iter: 0; batch classifier loss: 0.311488; batch adversarial loss: 0.552981\n",
      "epoch 82; iter: 0; batch classifier loss: 0.309873; batch adversarial loss: 0.553269\n",
      "epoch 83; iter: 0; batch classifier loss: 0.337540; batch adversarial loss: 0.571400\n",
      "epoch 84; iter: 0; batch classifier loss: 0.352833; batch adversarial loss: 0.536378\n",
      "epoch 85; iter: 0; batch classifier loss: 0.382009; batch adversarial loss: 0.527348\n",
      "epoch 86; iter: 0; batch classifier loss: 0.335081; batch adversarial loss: 0.536332\n",
      "epoch 87; iter: 0; batch classifier loss: 0.412729; batch adversarial loss: 0.561618\n",
      "epoch 88; iter: 0; batch classifier loss: 0.358618; batch adversarial loss: 0.510127\n",
      "epoch 89; iter: 0; batch classifier loss: 0.370576; batch adversarial loss: 0.525883\n",
      "epoch 90; iter: 0; batch classifier loss: 0.418538; batch adversarial loss: 0.581860\n",
      "epoch 91; iter: 0; batch classifier loss: 0.464732; batch adversarial loss: 0.552742\n",
      "epoch 92; iter: 0; batch classifier loss: 0.383405; batch adversarial loss: 0.587709\n",
      "epoch 93; iter: 0; batch classifier loss: 0.389662; batch adversarial loss: 0.632957\n",
      "epoch 94; iter: 0; batch classifier loss: 0.438396; batch adversarial loss: 0.536370\n",
      "epoch 95; iter: 0; batch classifier loss: 0.471568; batch adversarial loss: 0.638507\n",
      "epoch 96; iter: 0; batch classifier loss: 0.360147; batch adversarial loss: 0.604195\n",
      "epoch 97; iter: 0; batch classifier loss: 0.562938; batch adversarial loss: 0.623005\n",
      "epoch 98; iter: 0; batch classifier loss: 0.458316; batch adversarial loss: 0.509807\n",
      "epoch 99; iter: 0; batch classifier loss: 0.312027; batch adversarial loss: 0.544327\n",
      "epoch 100; iter: 0; batch classifier loss: 0.412090; batch adversarial loss: 0.552379\n",
      "epoch 101; iter: 0; batch classifier loss: 0.392949; batch adversarial loss: 0.675249\n",
      "epoch 102; iter: 0; batch classifier loss: 0.428250; batch adversarial loss: 0.483903\n",
      "epoch 103; iter: 0; batch classifier loss: 0.386913; batch adversarial loss: 0.482061\n",
      "epoch 104; iter: 0; batch classifier loss: 0.416349; batch adversarial loss: 0.519759\n",
      "epoch 105; iter: 0; batch classifier loss: 0.347525; batch adversarial loss: 0.614306\n",
      "epoch 106; iter: 0; batch classifier loss: 0.477694; batch adversarial loss: 0.613931\n",
      "epoch 107; iter: 0; batch classifier loss: 0.356983; batch adversarial loss: 0.455696\n",
      "epoch 108; iter: 0; batch classifier loss: 0.387629; batch adversarial loss: 0.544209\n",
      "epoch 109; iter: 0; batch classifier loss: 0.388764; batch adversarial loss: 0.578562\n",
      "epoch 110; iter: 0; batch classifier loss: 0.426439; batch adversarial loss: 0.580948\n",
      "epoch 111; iter: 0; batch classifier loss: 0.383026; batch adversarial loss: 0.466828\n",
      "epoch 112; iter: 0; batch classifier loss: 0.331593; batch adversarial loss: 0.543789\n",
      "epoch 113; iter: 0; batch classifier loss: 0.401126; batch adversarial loss: 0.570205\n",
      "epoch 114; iter: 0; batch classifier loss: 0.383172; batch adversarial loss: 0.547585\n",
      "epoch 115; iter: 0; batch classifier loss: 0.299604; batch adversarial loss: 0.649178\n",
      "epoch 116; iter: 0; batch classifier loss: 0.374206; batch adversarial loss: 0.518049\n",
      "epoch 117; iter: 0; batch classifier loss: 0.326261; batch adversarial loss: 0.474775\n",
      "epoch 118; iter: 0; batch classifier loss: 0.327109; batch adversarial loss: 0.547196\n",
      "epoch 119; iter: 0; batch classifier loss: 0.401160; batch adversarial loss: 0.518668\n",
      "epoch 120; iter: 0; batch classifier loss: 0.415785; batch adversarial loss: 0.607261\n",
      "epoch 121; iter: 0; batch classifier loss: 0.393490; batch adversarial loss: 0.524186\n",
      "epoch 122; iter: 0; batch classifier loss: 0.402121; batch adversarial loss: 0.528356\n",
      "epoch 123; iter: 0; batch classifier loss: 0.384087; batch adversarial loss: 0.545870\n",
      "epoch 124; iter: 0; batch classifier loss: 0.343033; batch adversarial loss: 0.550749\n",
      "epoch 125; iter: 0; batch classifier loss: 0.347514; batch adversarial loss: 0.604377\n",
      "epoch 126; iter: 0; batch classifier loss: 0.322298; batch adversarial loss: 0.590198\n",
      "epoch 127; iter: 0; batch classifier loss: 0.443931; batch adversarial loss: 0.571133\n",
      "epoch 128; iter: 0; batch classifier loss: 0.466921; batch adversarial loss: 0.535144\n",
      "epoch 129; iter: 0; batch classifier loss: 0.350947; batch adversarial loss: 0.527078\n",
      "epoch 130; iter: 0; batch classifier loss: 0.402597; batch adversarial loss: 0.503261\n",
      "epoch 131; iter: 0; batch classifier loss: 0.366010; batch adversarial loss: 0.581178\n",
      "epoch 132; iter: 0; batch classifier loss: 0.331469; batch adversarial loss: 0.600186\n",
      "epoch 133; iter: 0; batch classifier loss: 0.431162; batch adversarial loss: 0.603907\n",
      "epoch 134; iter: 0; batch classifier loss: 0.294755; batch adversarial loss: 0.517203\n",
      "epoch 135; iter: 0; batch classifier loss: 0.356327; batch adversarial loss: 0.598692\n",
      "epoch 136; iter: 0; batch classifier loss: 0.365687; batch adversarial loss: 0.571468\n",
      "epoch 137; iter: 0; batch classifier loss: 0.356730; batch adversarial loss: 0.545575\n",
      "epoch 138; iter: 0; batch classifier loss: 0.392788; batch adversarial loss: 0.605149\n",
      "epoch 139; iter: 0; batch classifier loss: 0.466264; batch adversarial loss: 0.625758\n",
      "epoch 140; iter: 0; batch classifier loss: 0.295200; batch adversarial loss: 0.579600\n",
      "epoch 141; iter: 0; batch classifier loss: 0.355485; batch adversarial loss: 0.526320\n",
      "epoch 142; iter: 0; batch classifier loss: 0.268661; batch adversarial loss: 0.604568\n",
      "epoch 143; iter: 0; batch classifier loss: 0.370811; batch adversarial loss: 0.587805\n",
      "epoch 144; iter: 0; batch classifier loss: 0.387263; batch adversarial loss: 0.580247\n",
      "epoch 145; iter: 0; batch classifier loss: 0.319598; batch adversarial loss: 0.598067\n",
      "epoch 146; iter: 0; batch classifier loss: 0.334192; batch adversarial loss: 0.562372\n",
      "epoch 147; iter: 0; batch classifier loss: 0.355277; batch adversarial loss: 0.509126\n",
      "epoch 148; iter: 0; batch classifier loss: 0.342508; batch adversarial loss: 0.582441\n",
      "epoch 149; iter: 0; batch classifier loss: 0.432901; batch adversarial loss: 0.576137\n",
      "epoch 150; iter: 0; batch classifier loss: 0.428216; batch adversarial loss: 0.445817\n",
      "epoch 151; iter: 0; batch classifier loss: 0.352041; batch adversarial loss: 0.592883\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 152; iter: 0; batch classifier loss: 0.381178; batch adversarial loss: 0.561746\n",
      "epoch 153; iter: 0; batch classifier loss: 0.432782; batch adversarial loss: 0.535475\n",
      "epoch 154; iter: 0; batch classifier loss: 0.299446; batch adversarial loss: 0.569577\n",
      "epoch 155; iter: 0; batch classifier loss: 0.371399; batch adversarial loss: 0.467802\n",
      "epoch 156; iter: 0; batch classifier loss: 0.369358; batch adversarial loss: 0.573810\n",
      "epoch 157; iter: 0; batch classifier loss: 0.364589; batch adversarial loss: 0.527461\n",
      "epoch 158; iter: 0; batch classifier loss: 0.258328; batch adversarial loss: 0.542827\n",
      "epoch 159; iter: 0; batch classifier loss: 0.337730; batch adversarial loss: 0.645464\n",
      "epoch 160; iter: 0; batch classifier loss: 0.318850; batch adversarial loss: 0.553221\n",
      "epoch 161; iter: 0; batch classifier loss: 0.365890; batch adversarial loss: 0.544967\n",
      "epoch 162; iter: 0; batch classifier loss: 0.325456; batch adversarial loss: 0.575053\n",
      "epoch 163; iter: 0; batch classifier loss: 0.309847; batch adversarial loss: 0.549755\n",
      "epoch 164; iter: 0; batch classifier loss: 0.493881; batch adversarial loss: 0.512923\n",
      "epoch 165; iter: 0; batch classifier loss: 0.388271; batch adversarial loss: 0.538624\n",
      "epoch 166; iter: 0; batch classifier loss: 0.290995; batch adversarial loss: 0.599273\n",
      "epoch 167; iter: 0; batch classifier loss: 0.406347; batch adversarial loss: 0.600116\n",
      "epoch 168; iter: 0; batch classifier loss: 0.386538; batch adversarial loss: 0.627111\n",
      "epoch 169; iter: 0; batch classifier loss: 0.392270; batch adversarial loss: 0.634559\n",
      "epoch 170; iter: 0; batch classifier loss: 0.388901; batch adversarial loss: 0.547395\n",
      "epoch 171; iter: 0; batch classifier loss: 0.381396; batch adversarial loss: 0.526644\n",
      "epoch 172; iter: 0; batch classifier loss: 0.467341; batch adversarial loss: 0.579160\n",
      "epoch 173; iter: 0; batch classifier loss: 0.356226; batch adversarial loss: 0.541827\n",
      "epoch 174; iter: 0; batch classifier loss: 0.350726; batch adversarial loss: 0.525221\n",
      "epoch 175; iter: 0; batch classifier loss: 0.364892; batch adversarial loss: 0.481642\n",
      "epoch 176; iter: 0; batch classifier loss: 0.315754; batch adversarial loss: 0.467125\n",
      "epoch 177; iter: 0; batch classifier loss: 0.341918; batch adversarial loss: 0.529118\n",
      "epoch 178; iter: 0; batch classifier loss: 0.399687; batch adversarial loss: 0.574301\n",
      "epoch 179; iter: 0; batch classifier loss: 0.343960; batch adversarial loss: 0.585525\n",
      "epoch 180; iter: 0; batch classifier loss: 0.324568; batch adversarial loss: 0.632017\n",
      "epoch 181; iter: 0; batch classifier loss: 0.320461; batch adversarial loss: 0.579800\n",
      "epoch 182; iter: 0; batch classifier loss: 0.335413; batch adversarial loss: 0.566120\n",
      "epoch 183; iter: 0; batch classifier loss: 0.468231; batch adversarial loss: 0.558900\n",
      "epoch 184; iter: 0; batch classifier loss: 0.294348; batch adversarial loss: 0.502528\n",
      "epoch 185; iter: 0; batch classifier loss: 0.364711; batch adversarial loss: 0.593482\n",
      "epoch 186; iter: 0; batch classifier loss: 0.375533; batch adversarial loss: 0.519058\n",
      "epoch 187; iter: 0; batch classifier loss: 0.334937; batch adversarial loss: 0.495506\n",
      "epoch 188; iter: 0; batch classifier loss: 0.395725; batch adversarial loss: 0.541968\n",
      "epoch 189; iter: 0; batch classifier loss: 0.350550; batch adversarial loss: 0.606092\n",
      "epoch 190; iter: 0; batch classifier loss: 0.353844; batch adversarial loss: 0.608619\n",
      "epoch 191; iter: 0; batch classifier loss: 0.390014; batch adversarial loss: 0.513673\n",
      "epoch 192; iter: 0; batch classifier loss: 0.344639; batch adversarial loss: 0.623608\n",
      "epoch 193; iter: 0; batch classifier loss: 0.367942; batch adversarial loss: 0.557430\n",
      "epoch 194; iter: 0; batch classifier loss: 0.325861; batch adversarial loss: 0.639305\n",
      "epoch 195; iter: 0; batch classifier loss: 0.359450; batch adversarial loss: 0.499307\n",
      "epoch 196; iter: 0; batch classifier loss: 0.372765; batch adversarial loss: 0.464240\n",
      "epoch 197; iter: 0; batch classifier loss: 0.332960; batch adversarial loss: 0.603377\n",
      "epoch 198; iter: 0; batch classifier loss: 0.403504; batch adversarial loss: 0.521364\n",
      "epoch 199; iter: 0; batch classifier loss: 0.369378; batch adversarial loss: 0.485247\n",
      "epoch 0; iter: 0; batch classifier loss: 0.695218; batch adversarial loss: 0.773292\n",
      "epoch 1; iter: 0; batch classifier loss: 0.541366; batch adversarial loss: 0.767435\n",
      "epoch 2; iter: 0; batch classifier loss: 0.573643; batch adversarial loss: 0.748548\n",
      "epoch 3; iter: 0; batch classifier loss: 0.519182; batch adversarial loss: 0.678320\n",
      "epoch 4; iter: 0; batch classifier loss: 0.605189; batch adversarial loss: 0.704406\n",
      "epoch 5; iter: 0; batch classifier loss: 0.593250; batch adversarial loss: 0.668694\n",
      "epoch 6; iter: 0; batch classifier loss: 0.532635; batch adversarial loss: 0.643562\n",
      "epoch 7; iter: 0; batch classifier loss: 0.578833; batch adversarial loss: 0.609260\n",
      "epoch 8; iter: 0; batch classifier loss: 0.538573; batch adversarial loss: 0.602608\n",
      "epoch 9; iter: 0; batch classifier loss: 0.456139; batch adversarial loss: 0.588842\n",
      "epoch 10; iter: 0; batch classifier loss: 0.591114; batch adversarial loss: 0.580121\n",
      "epoch 11; iter: 0; batch classifier loss: 0.570588; batch adversarial loss: 0.564307\n",
      "epoch 12; iter: 0; batch classifier loss: 0.474918; batch adversarial loss: 0.552994\n",
      "epoch 13; iter: 0; batch classifier loss: 0.547681; batch adversarial loss: 0.540176\n",
      "epoch 14; iter: 0; batch classifier loss: 0.541341; batch adversarial loss: 0.552436\n",
      "epoch 15; iter: 0; batch classifier loss: 0.516393; batch adversarial loss: 0.543846\n",
      "epoch 16; iter: 0; batch classifier loss: 0.441272; batch adversarial loss: 0.478178\n",
      "epoch 17; iter: 0; batch classifier loss: 0.465355; batch adversarial loss: 0.524352\n",
      "epoch 18; iter: 0; batch classifier loss: 0.506779; batch adversarial loss: 0.579148\n",
      "epoch 19; iter: 0; batch classifier loss: 0.511839; batch adversarial loss: 0.546046\n",
      "epoch 20; iter: 0; batch classifier loss: 0.548100; batch adversarial loss: 0.603992\n",
      "epoch 21; iter: 0; batch classifier loss: 0.521091; batch adversarial loss: 0.537556\n",
      "epoch 22; iter: 0; batch classifier loss: 0.482276; batch adversarial loss: 0.585568\n",
      "epoch 23; iter: 0; batch classifier loss: 0.487521; batch adversarial loss: 0.578343\n",
      "epoch 24; iter: 0; batch classifier loss: 0.556504; batch adversarial loss: 0.544680\n",
      "epoch 25; iter: 0; batch classifier loss: 0.472989; batch adversarial loss: 0.576424\n",
      "epoch 26; iter: 0; batch classifier loss: 0.410814; batch adversarial loss: 0.544451\n",
      "epoch 27; iter: 0; batch classifier loss: 0.412769; batch adversarial loss: 0.597328\n",
      "epoch 28; iter: 0; batch classifier loss: 0.440529; batch adversarial loss: 0.559542\n",
      "epoch 29; iter: 0; batch classifier loss: 0.483677; batch adversarial loss: 0.609842\n",
      "epoch 30; iter: 0; batch classifier loss: 0.348069; batch adversarial loss: 0.514394\n",
      "epoch 31; iter: 0; batch classifier loss: 0.428807; batch adversarial loss: 0.593037\n",
      "epoch 32; iter: 0; batch classifier loss: 0.500858; batch adversarial loss: 0.577939\n",
      "epoch 33; iter: 0; batch classifier loss: 0.486674; batch adversarial loss: 0.517626\n",
      "epoch 34; iter: 0; batch classifier loss: 0.476299; batch adversarial loss: 0.594677\n",
      "epoch 35; iter: 0; batch classifier loss: 0.438114; batch adversarial loss: 0.590839\n",
      "epoch 36; iter: 0; batch classifier loss: 0.410022; batch adversarial loss: 0.581807\n",
      "epoch 37; iter: 0; batch classifier loss: 0.460841; batch adversarial loss: 0.485289\n",
      "epoch 38; iter: 0; batch classifier loss: 0.424933; batch adversarial loss: 0.621843\n",
      "epoch 39; iter: 0; batch classifier loss: 0.447852; batch adversarial loss: 0.539985\n",
      "epoch 40; iter: 0; batch classifier loss: 0.474716; batch adversarial loss: 0.549074\n",
      "epoch 41; iter: 0; batch classifier loss: 0.456510; batch adversarial loss: 0.590782\n",
      "epoch 42; iter: 0; batch classifier loss: 0.478703; batch adversarial loss: 0.543904\n",
      "epoch 43; iter: 0; batch classifier loss: 0.368285; batch adversarial loss: 0.564939\n",
      "epoch 44; iter: 0; batch classifier loss: 0.423264; batch adversarial loss: 0.520950\n",
      "epoch 45; iter: 0; batch classifier loss: 0.476518; batch adversarial loss: 0.497999\n",
      "epoch 46; iter: 0; batch classifier loss: 0.370243; batch adversarial loss: 0.544170\n",
      "epoch 47; iter: 0; batch classifier loss: 0.446865; batch adversarial loss: 0.570424\n",
      "epoch 48; iter: 0; batch classifier loss: 0.397017; batch adversarial loss: 0.580650\n",
      "epoch 49; iter: 0; batch classifier loss: 0.429729; batch adversarial loss: 0.562000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 50; iter: 0; batch classifier loss: 0.431837; batch adversarial loss: 0.535404\n",
      "epoch 51; iter: 0; batch classifier loss: 0.445969; batch adversarial loss: 0.489091\n",
      "epoch 52; iter: 0; batch classifier loss: 0.372011; batch adversarial loss: 0.571563\n",
      "epoch 53; iter: 0; batch classifier loss: 0.393064; batch adversarial loss: 0.572860\n",
      "epoch 54; iter: 0; batch classifier loss: 0.421431; batch adversarial loss: 0.554405\n",
      "epoch 55; iter: 0; batch classifier loss: 0.504004; batch adversarial loss: 0.581450\n",
      "epoch 56; iter: 0; batch classifier loss: 0.422049; batch adversarial loss: 0.543258\n",
      "epoch 57; iter: 0; batch classifier loss: 0.371780; batch adversarial loss: 0.571940\n",
      "epoch 58; iter: 0; batch classifier loss: 0.378487; batch adversarial loss: 0.553532\n",
      "epoch 59; iter: 0; batch classifier loss: 0.426226; batch adversarial loss: 0.553478\n",
      "epoch 60; iter: 0; batch classifier loss: 0.382210; batch adversarial loss: 0.553748\n",
      "epoch 61; iter: 0; batch classifier loss: 0.453565; batch adversarial loss: 0.571741\n",
      "epoch 62; iter: 0; batch classifier loss: 0.388614; batch adversarial loss: 0.517107\n",
      "epoch 63; iter: 0; batch classifier loss: 0.374505; batch adversarial loss: 0.470699\n",
      "epoch 64; iter: 0; batch classifier loss: 0.377093; batch adversarial loss: 0.581446\n",
      "epoch 65; iter: 0; batch classifier loss: 0.423120; batch adversarial loss: 0.599772\n",
      "epoch 66; iter: 0; batch classifier loss: 0.368208; batch adversarial loss: 0.581299\n",
      "epoch 67; iter: 0; batch classifier loss: 0.391653; batch adversarial loss: 0.646102\n",
      "epoch 68; iter: 0; batch classifier loss: 0.368067; batch adversarial loss: 0.535012\n",
      "epoch 69; iter: 0; batch classifier loss: 0.395688; batch adversarial loss: 0.461334\n",
      "epoch 70; iter: 0; batch classifier loss: 0.465311; batch adversarial loss: 0.572049\n",
      "epoch 71; iter: 0; batch classifier loss: 0.446988; batch adversarial loss: 0.498929\n",
      "epoch 72; iter: 0; batch classifier loss: 0.400497; batch adversarial loss: 0.508111\n",
      "epoch 73; iter: 0; batch classifier loss: 0.426160; batch adversarial loss: 0.572537\n",
      "epoch 74; iter: 0; batch classifier loss: 0.348834; batch adversarial loss: 0.626296\n",
      "epoch 75; iter: 0; batch classifier loss: 0.428497; batch adversarial loss: 0.517022\n",
      "epoch 76; iter: 0; batch classifier loss: 0.373457; batch adversarial loss: 0.563248\n",
      "epoch 77; iter: 0; batch classifier loss: 0.347803; batch adversarial loss: 0.553477\n",
      "epoch 78; iter: 0; batch classifier loss: 0.414804; batch adversarial loss: 0.600085\n",
      "epoch 79; iter: 0; batch classifier loss: 0.389990; batch adversarial loss: 0.525521\n",
      "epoch 80; iter: 0; batch classifier loss: 0.300974; batch adversarial loss: 0.552568\n",
      "epoch 81; iter: 0; batch classifier loss: 0.375193; batch adversarial loss: 0.517361\n",
      "epoch 82; iter: 0; batch classifier loss: 0.343255; batch adversarial loss: 0.613917\n",
      "epoch 83; iter: 0; batch classifier loss: 0.395948; batch adversarial loss: 0.560346\n",
      "epoch 84; iter: 0; batch classifier loss: 0.472170; batch adversarial loss: 0.607676\n",
      "epoch 85; iter: 0; batch classifier loss: 0.397909; batch adversarial loss: 0.506680\n",
      "epoch 86; iter: 0; batch classifier loss: 0.428503; batch adversarial loss: 0.564530\n",
      "epoch 87; iter: 0; batch classifier loss: 0.314791; batch adversarial loss: 0.554171\n",
      "epoch 88; iter: 0; batch classifier loss: 0.354309; batch adversarial loss: 0.591279\n",
      "epoch 89; iter: 0; batch classifier loss: 0.379655; batch adversarial loss: 0.618396\n",
      "epoch 90; iter: 0; batch classifier loss: 0.334021; batch adversarial loss: 0.588342\n",
      "epoch 91; iter: 0; batch classifier loss: 0.342559; batch adversarial loss: 0.581020\n",
      "epoch 92; iter: 0; batch classifier loss: 0.424937; batch adversarial loss: 0.627761\n",
      "epoch 93; iter: 0; batch classifier loss: 0.380657; batch adversarial loss: 0.608949\n",
      "epoch 94; iter: 0; batch classifier loss: 0.366225; batch adversarial loss: 0.499074\n",
      "epoch 95; iter: 0; batch classifier loss: 0.359641; batch adversarial loss: 0.536246\n",
      "epoch 96; iter: 0; batch classifier loss: 0.368884; batch adversarial loss: 0.525419\n",
      "epoch 97; iter: 0; batch classifier loss: 0.360434; batch adversarial loss: 0.534294\n",
      "epoch 98; iter: 0; batch classifier loss: 0.413878; batch adversarial loss: 0.545741\n",
      "epoch 99; iter: 0; batch classifier loss: 0.406849; batch adversarial loss: 0.516475\n",
      "epoch 100; iter: 0; batch classifier loss: 0.396159; batch adversarial loss: 0.619346\n",
      "epoch 101; iter: 0; batch classifier loss: 0.347726; batch adversarial loss: 0.519078\n",
      "epoch 102; iter: 0; batch classifier loss: 0.433182; batch adversarial loss: 0.544589\n",
      "epoch 103; iter: 0; batch classifier loss: 0.385633; batch adversarial loss: 0.480489\n",
      "epoch 104; iter: 0; batch classifier loss: 0.455868; batch adversarial loss: 0.490248\n",
      "epoch 105; iter: 0; batch classifier loss: 0.380733; batch adversarial loss: 0.599574\n",
      "epoch 106; iter: 0; batch classifier loss: 0.390074; batch adversarial loss: 0.534765\n",
      "epoch 107; iter: 0; batch classifier loss: 0.421994; batch adversarial loss: 0.589946\n",
      "epoch 108; iter: 0; batch classifier loss: 0.444408; batch adversarial loss: 0.564754\n",
      "epoch 109; iter: 0; batch classifier loss: 0.345637; batch adversarial loss: 0.526116\n",
      "epoch 110; iter: 0; batch classifier loss: 0.356895; batch adversarial loss: 0.553782\n",
      "epoch 111; iter: 0; batch classifier loss: 0.465207; batch adversarial loss: 0.526824\n",
      "epoch 112; iter: 0; batch classifier loss: 0.409586; batch adversarial loss: 0.619034\n",
      "epoch 113; iter: 0; batch classifier loss: 0.377792; batch adversarial loss: 0.619000\n",
      "epoch 114; iter: 0; batch classifier loss: 0.420559; batch adversarial loss: 0.573618\n",
      "epoch 115; iter: 0; batch classifier loss: 0.390763; batch adversarial loss: 0.646704\n",
      "epoch 116; iter: 0; batch classifier loss: 0.375358; batch adversarial loss: 0.545091\n",
      "epoch 117; iter: 0; batch classifier loss: 0.403772; batch adversarial loss: 0.571145\n",
      "epoch 118; iter: 0; batch classifier loss: 0.398065; batch adversarial loss: 0.579870\n",
      "epoch 119; iter: 0; batch classifier loss: 0.317762; batch adversarial loss: 0.581159\n",
      "epoch 120; iter: 0; batch classifier loss: 0.306872; batch adversarial loss: 0.572551\n",
      "epoch 121; iter: 0; batch classifier loss: 0.334859; batch adversarial loss: 0.497822\n",
      "epoch 122; iter: 0; batch classifier loss: 0.375238; batch adversarial loss: 0.535266\n",
      "epoch 123; iter: 0; batch classifier loss: 0.426903; batch adversarial loss: 0.634059\n",
      "epoch 124; iter: 0; batch classifier loss: 0.403052; batch adversarial loss: 0.508675\n",
      "epoch 125; iter: 0; batch classifier loss: 0.379191; batch adversarial loss: 0.554170\n",
      "epoch 126; iter: 0; batch classifier loss: 0.441752; batch adversarial loss: 0.515771\n",
      "epoch 127; iter: 0; batch classifier loss: 0.322695; batch adversarial loss: 0.514914\n",
      "epoch 128; iter: 0; batch classifier loss: 0.276477; batch adversarial loss: 0.516887\n",
      "epoch 129; iter: 0; batch classifier loss: 0.375727; batch adversarial loss: 0.517052\n",
      "epoch 130; iter: 0; batch classifier loss: 0.464072; batch adversarial loss: 0.544787\n",
      "epoch 131; iter: 0; batch classifier loss: 0.321183; batch adversarial loss: 0.657336\n",
      "epoch 132; iter: 0; batch classifier loss: 0.354396; batch adversarial loss: 0.586931\n",
      "epoch 133; iter: 0; batch classifier loss: 0.293982; batch adversarial loss: 0.602349\n",
      "epoch 134; iter: 0; batch classifier loss: 0.349615; batch adversarial loss: 0.552617\n",
      "epoch 135; iter: 0; batch classifier loss: 0.384178; batch adversarial loss: 0.507709\n",
      "epoch 136; iter: 0; batch classifier loss: 0.342929; batch adversarial loss: 0.544554\n",
      "epoch 137; iter: 0; batch classifier loss: 0.319076; batch adversarial loss: 0.581968\n",
      "epoch 138; iter: 0; batch classifier loss: 0.358981; batch adversarial loss: 0.535891\n",
      "epoch 139; iter: 0; batch classifier loss: 0.399365; batch adversarial loss: 0.625360\n",
      "epoch 140; iter: 0; batch classifier loss: 0.334201; batch adversarial loss: 0.544732\n",
      "epoch 141; iter: 0; batch classifier loss: 0.386398; batch adversarial loss: 0.544132\n",
      "epoch 142; iter: 0; batch classifier loss: 0.414759; batch adversarial loss: 0.544984\n",
      "epoch 143; iter: 0; batch classifier loss: 0.353215; batch adversarial loss: 0.571627\n",
      "epoch 144; iter: 0; batch classifier loss: 0.359647; batch adversarial loss: 0.599610\n",
      "epoch 145; iter: 0; batch classifier loss: 0.331198; batch adversarial loss: 0.681355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 146; iter: 0; batch classifier loss: 0.298452; batch adversarial loss: 0.608126\n",
      "epoch 147; iter: 0; batch classifier loss: 0.360462; batch adversarial loss: 0.599253\n",
      "epoch 148; iter: 0; batch classifier loss: 0.375637; batch adversarial loss: 0.563154\n",
      "epoch 149; iter: 0; batch classifier loss: 0.494700; batch adversarial loss: 0.571667\n",
      "epoch 150; iter: 0; batch classifier loss: 0.408431; batch adversarial loss: 0.579311\n",
      "epoch 151; iter: 0; batch classifier loss: 0.362480; batch adversarial loss: 0.553976\n",
      "epoch 152; iter: 0; batch classifier loss: 0.360989; batch adversarial loss: 0.498666\n",
      "epoch 153; iter: 0; batch classifier loss: 0.324598; batch adversarial loss: 0.460135\n",
      "epoch 154; iter: 0; batch classifier loss: 0.369291; batch adversarial loss: 0.479979\n",
      "epoch 155; iter: 0; batch classifier loss: 0.328878; batch adversarial loss: 0.553093\n",
      "epoch 156; iter: 0; batch classifier loss: 0.344984; batch adversarial loss: 0.545354\n",
      "epoch 157; iter: 0; batch classifier loss: 0.262353; batch adversarial loss: 0.534875\n",
      "epoch 158; iter: 0; batch classifier loss: 0.374978; batch adversarial loss: 0.689890\n",
      "epoch 159; iter: 0; batch classifier loss: 0.400268; batch adversarial loss: 0.499719\n",
      "epoch 160; iter: 0; batch classifier loss: 0.321483; batch adversarial loss: 0.479611\n",
      "epoch 161; iter: 0; batch classifier loss: 0.346696; batch adversarial loss: 0.498415\n",
      "epoch 162; iter: 0; batch classifier loss: 0.357364; batch adversarial loss: 0.571113\n",
      "epoch 163; iter: 0; batch classifier loss: 0.305508; batch adversarial loss: 0.609381\n",
      "epoch 164; iter: 0; batch classifier loss: 0.399727; batch adversarial loss: 0.616670\n",
      "epoch 165; iter: 0; batch classifier loss: 0.333730; batch adversarial loss: 0.570040\n",
      "epoch 166; iter: 0; batch classifier loss: 0.347918; batch adversarial loss: 0.553066\n",
      "epoch 167; iter: 0; batch classifier loss: 0.321937; batch adversarial loss: 0.562860\n",
      "epoch 168; iter: 0; batch classifier loss: 0.383156; batch adversarial loss: 0.552384\n",
      "epoch 169; iter: 0; batch classifier loss: 0.371559; batch adversarial loss: 0.582515\n",
      "epoch 170; iter: 0; batch classifier loss: 0.305274; batch adversarial loss: 0.451497\n",
      "epoch 171; iter: 0; batch classifier loss: 0.390763; batch adversarial loss: 0.546368\n",
      "epoch 172; iter: 0; batch classifier loss: 0.354969; batch adversarial loss: 0.569220\n",
      "epoch 173; iter: 0; batch classifier loss: 0.388037; batch adversarial loss: 0.533947\n",
      "epoch 174; iter: 0; batch classifier loss: 0.350937; batch adversarial loss: 0.442685\n",
      "epoch 175; iter: 0; batch classifier loss: 0.304549; batch adversarial loss: 0.609151\n",
      "epoch 176; iter: 0; batch classifier loss: 0.344285; batch adversarial loss: 0.499178\n",
      "epoch 177; iter: 0; batch classifier loss: 0.365127; batch adversarial loss: 0.562457\n",
      "epoch 178; iter: 0; batch classifier loss: 0.355481; batch adversarial loss: 0.608926\n",
      "epoch 179; iter: 0; batch classifier loss: 0.433819; batch adversarial loss: 0.506998\n",
      "epoch 180; iter: 0; batch classifier loss: 0.363125; batch adversarial loss: 0.524734\n",
      "epoch 181; iter: 0; batch classifier loss: 0.325868; batch adversarial loss: 0.563837\n",
      "epoch 182; iter: 0; batch classifier loss: 0.336171; batch adversarial loss: 0.507625\n",
      "epoch 183; iter: 0; batch classifier loss: 0.372686; batch adversarial loss: 0.571828\n",
      "epoch 184; iter: 0; batch classifier loss: 0.421153; batch adversarial loss: 0.600437\n",
      "epoch 185; iter: 0; batch classifier loss: 0.375987; batch adversarial loss: 0.581166\n",
      "epoch 186; iter: 0; batch classifier loss: 0.364243; batch adversarial loss: 0.526467\n",
      "epoch 187; iter: 0; batch classifier loss: 0.307882; batch adversarial loss: 0.442250\n",
      "epoch 188; iter: 0; batch classifier loss: 0.439233; batch adversarial loss: 0.600488\n",
      "epoch 189; iter: 0; batch classifier loss: 0.370572; batch adversarial loss: 0.553591\n",
      "epoch 190; iter: 0; batch classifier loss: 0.271510; batch adversarial loss: 0.563671\n",
      "epoch 191; iter: 0; batch classifier loss: 0.364512; batch adversarial loss: 0.516205\n",
      "epoch 192; iter: 0; batch classifier loss: 0.312552; batch adversarial loss: 0.544460\n",
      "epoch 193; iter: 0; batch classifier loss: 0.381570; batch adversarial loss: 0.544791\n",
      "epoch 194; iter: 0; batch classifier loss: 0.283041; batch adversarial loss: 0.515857\n",
      "epoch 195; iter: 0; batch classifier loss: 0.305330; batch adversarial loss: 0.516875\n",
      "epoch 196; iter: 0; batch classifier loss: 0.338247; batch adversarial loss: 0.572715\n",
      "epoch 197; iter: 0; batch classifier loss: 0.277246; batch adversarial loss: 0.525680\n",
      "epoch 198; iter: 0; batch classifier loss: 0.420025; batch adversarial loss: 0.598783\n",
      "epoch 199; iter: 0; batch classifier loss: 0.436861; batch adversarial loss: 0.589740\n",
      "epoch 0; iter: 0; batch classifier loss: 0.700813; batch adversarial loss: 0.693547\n",
      "epoch 1; iter: 0; batch classifier loss: 0.616842; batch adversarial loss: 0.666826\n",
      "epoch 2; iter: 0; batch classifier loss: 0.616180; batch adversarial loss: 0.629281\n",
      "epoch 3; iter: 0; batch classifier loss: 0.578787; batch adversarial loss: 0.614269\n",
      "epoch 4; iter: 0; batch classifier loss: 0.585308; batch adversarial loss: 0.585586\n",
      "epoch 5; iter: 0; batch classifier loss: 0.508717; batch adversarial loss: 0.589824\n",
      "epoch 6; iter: 0; batch classifier loss: 0.465909; batch adversarial loss: 0.584073\n",
      "epoch 7; iter: 0; batch classifier loss: 0.438553; batch adversarial loss: 0.623862\n",
      "epoch 8; iter: 0; batch classifier loss: 0.553212; batch adversarial loss: 0.642140\n",
      "epoch 9; iter: 0; batch classifier loss: 0.546682; batch adversarial loss: 0.552817\n",
      "epoch 10; iter: 0; batch classifier loss: 0.483935; batch adversarial loss: 0.584724\n",
      "epoch 11; iter: 0; batch classifier loss: 0.465389; batch adversarial loss: 0.609152\n",
      "epoch 12; iter: 0; batch classifier loss: 0.533909; batch adversarial loss: 0.545515\n",
      "epoch 13; iter: 0; batch classifier loss: 0.560281; batch adversarial loss: 0.616980\n",
      "epoch 14; iter: 0; batch classifier loss: 0.542711; batch adversarial loss: 0.564478\n",
      "epoch 15; iter: 0; batch classifier loss: 0.509914; batch adversarial loss: 0.560340\n",
      "epoch 16; iter: 0; batch classifier loss: 0.598277; batch adversarial loss: 0.600610\n",
      "epoch 17; iter: 0; batch classifier loss: 0.500254; batch adversarial loss: 0.532833\n",
      "epoch 18; iter: 0; batch classifier loss: 0.469225; batch adversarial loss: 0.607078\n",
      "epoch 19; iter: 0; batch classifier loss: 0.441728; batch adversarial loss: 0.571633\n",
      "epoch 20; iter: 0; batch classifier loss: 0.525962; batch adversarial loss: 0.571098\n",
      "epoch 21; iter: 0; batch classifier loss: 0.525663; batch adversarial loss: 0.605032\n",
      "epoch 22; iter: 0; batch classifier loss: 0.473060; batch adversarial loss: 0.545610\n",
      "epoch 23; iter: 0; batch classifier loss: 0.423583; batch adversarial loss: 0.550477\n",
      "epoch 24; iter: 0; batch classifier loss: 0.465420; batch adversarial loss: 0.542250\n",
      "epoch 25; iter: 0; batch classifier loss: 0.499691; batch adversarial loss: 0.517927\n",
      "epoch 26; iter: 0; batch classifier loss: 0.425962; batch adversarial loss: 0.547457\n",
      "epoch 27; iter: 0; batch classifier loss: 0.501056; batch adversarial loss: 0.515245\n",
      "epoch 28; iter: 0; batch classifier loss: 0.437227; batch adversarial loss: 0.596427\n",
      "epoch 29; iter: 0; batch classifier loss: 0.446885; batch adversarial loss: 0.630573\n",
      "epoch 30; iter: 0; batch classifier loss: 0.473933; batch adversarial loss: 0.554099\n",
      "epoch 31; iter: 0; batch classifier loss: 0.493768; batch adversarial loss: 0.495294\n",
      "epoch 32; iter: 0; batch classifier loss: 0.391652; batch adversarial loss: 0.545389\n",
      "epoch 33; iter: 0; batch classifier loss: 0.396487; batch adversarial loss: 0.605327\n",
      "epoch 34; iter: 0; batch classifier loss: 0.415419; batch adversarial loss: 0.528431\n",
      "epoch 35; iter: 0; batch classifier loss: 0.447430; batch adversarial loss: 0.588394\n",
      "epoch 36; iter: 0; batch classifier loss: 0.443228; batch adversarial loss: 0.527578\n",
      "epoch 37; iter: 0; batch classifier loss: 0.489303; batch adversarial loss: 0.553836\n",
      "epoch 38; iter: 0; batch classifier loss: 0.340263; batch adversarial loss: 0.614531\n",
      "epoch 39; iter: 0; batch classifier loss: 0.352528; batch adversarial loss: 0.492505\n",
      "epoch 40; iter: 0; batch classifier loss: 0.472559; batch adversarial loss: 0.579959\n",
      "epoch 41; iter: 0; batch classifier loss: 0.396478; batch adversarial loss: 0.579499\n",
      "epoch 42; iter: 0; batch classifier loss: 0.481461; batch adversarial loss: 0.561028\n",
      "epoch 43; iter: 0; batch classifier loss: 0.434942; batch adversarial loss: 0.524322\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 44; iter: 0; batch classifier loss: 0.408292; batch adversarial loss: 0.569659\n",
      "epoch 45; iter: 0; batch classifier loss: 0.421603; batch adversarial loss: 0.554906\n",
      "epoch 46; iter: 0; batch classifier loss: 0.389571; batch adversarial loss: 0.536763\n",
      "epoch 47; iter: 0; batch classifier loss: 0.370294; batch adversarial loss: 0.577952\n",
      "epoch 48; iter: 0; batch classifier loss: 0.402946; batch adversarial loss: 0.644560\n",
      "epoch 49; iter: 0; batch classifier loss: 0.460726; batch adversarial loss: 0.514192\n",
      "epoch 50; iter: 0; batch classifier loss: 0.440576; batch adversarial loss: 0.499859\n",
      "epoch 51; iter: 0; batch classifier loss: 0.370419; batch adversarial loss: 0.561503\n",
      "epoch 52; iter: 0; batch classifier loss: 0.407516; batch adversarial loss: 0.608265\n",
      "epoch 53; iter: 0; batch classifier loss: 0.462681; batch adversarial loss: 0.516317\n",
      "epoch 54; iter: 0; batch classifier loss: 0.454659; batch adversarial loss: 0.509328\n",
      "epoch 55; iter: 0; batch classifier loss: 0.483251; batch adversarial loss: 0.574829\n",
      "epoch 56; iter: 0; batch classifier loss: 0.490954; batch adversarial loss: 0.553798\n",
      "epoch 57; iter: 0; batch classifier loss: 0.468525; batch adversarial loss: 0.615920\n",
      "epoch 58; iter: 0; batch classifier loss: 0.426997; batch adversarial loss: 0.497849\n",
      "epoch 59; iter: 0; batch classifier loss: 0.401083; batch adversarial loss: 0.581147\n",
      "epoch 60; iter: 0; batch classifier loss: 0.372064; batch adversarial loss: 0.481828\n",
      "epoch 61; iter: 0; batch classifier loss: 0.412310; batch adversarial loss: 0.635686\n",
      "epoch 62; iter: 0; batch classifier loss: 0.398762; batch adversarial loss: 0.526696\n",
      "epoch 63; iter: 0; batch classifier loss: 0.390926; batch adversarial loss: 0.572417\n",
      "epoch 64; iter: 0; batch classifier loss: 0.389258; batch adversarial loss: 0.590379\n",
      "epoch 65; iter: 0; batch classifier loss: 0.445144; batch adversarial loss: 0.580583\n",
      "epoch 66; iter: 0; batch classifier loss: 0.436614; batch adversarial loss: 0.535460\n",
      "epoch 67; iter: 0; batch classifier loss: 0.393199; batch adversarial loss: 0.624493\n",
      "epoch 68; iter: 0; batch classifier loss: 0.342698; batch adversarial loss: 0.615706\n",
      "epoch 69; iter: 0; batch classifier loss: 0.386070; batch adversarial loss: 0.553428\n",
      "epoch 70; iter: 0; batch classifier loss: 0.343362; batch adversarial loss: 0.589214\n",
      "epoch 71; iter: 0; batch classifier loss: 0.412454; batch adversarial loss: 0.571133\n",
      "epoch 72; iter: 0; batch classifier loss: 0.409756; batch adversarial loss: 0.571351\n",
      "epoch 73; iter: 0; batch classifier loss: 0.365909; batch adversarial loss: 0.526586\n",
      "epoch 74; iter: 0; batch classifier loss: 0.456747; batch adversarial loss: 0.658229\n",
      "epoch 75; iter: 0; batch classifier loss: 0.327452; batch adversarial loss: 0.596952\n",
      "epoch 76; iter: 0; batch classifier loss: 0.344147; batch adversarial loss: 0.553266\n",
      "epoch 77; iter: 0; batch classifier loss: 0.440146; batch adversarial loss: 0.490928\n",
      "epoch 78; iter: 0; batch classifier loss: 0.377676; batch adversarial loss: 0.516053\n",
      "epoch 79; iter: 0; batch classifier loss: 0.358638; batch adversarial loss: 0.562440\n",
      "epoch 80; iter: 0; batch classifier loss: 0.370088; batch adversarial loss: 0.563092\n",
      "epoch 81; iter: 0; batch classifier loss: 0.412981; batch adversarial loss: 0.526695\n",
      "epoch 82; iter: 0; batch classifier loss: 0.346095; batch adversarial loss: 0.571811\n",
      "epoch 83; iter: 0; batch classifier loss: 0.417894; batch adversarial loss: 0.536185\n",
      "epoch 84; iter: 0; batch classifier loss: 0.359461; batch adversarial loss: 0.615278\n",
      "epoch 85; iter: 0; batch classifier loss: 0.361615; batch adversarial loss: 0.499502\n",
      "epoch 86; iter: 0; batch classifier loss: 0.471167; batch adversarial loss: 0.527771\n",
      "epoch 87; iter: 0; batch classifier loss: 0.365375; batch adversarial loss: 0.517186\n",
      "epoch 88; iter: 0; batch classifier loss: 0.342810; batch adversarial loss: 0.661809\n",
      "epoch 89; iter: 0; batch classifier loss: 0.280211; batch adversarial loss: 0.562860\n",
      "epoch 90; iter: 0; batch classifier loss: 0.388047; batch adversarial loss: 0.526704\n",
      "epoch 91; iter: 0; batch classifier loss: 0.373550; batch adversarial loss: 0.544636\n",
      "epoch 92; iter: 0; batch classifier loss: 0.384032; batch adversarial loss: 0.633811\n",
      "epoch 93; iter: 0; batch classifier loss: 0.437103; batch adversarial loss: 0.572128\n",
      "epoch 94; iter: 0; batch classifier loss: 0.474200; batch adversarial loss: 0.508476\n",
      "epoch 95; iter: 0; batch classifier loss: 0.319270; batch adversarial loss: 0.580011\n",
      "epoch 96; iter: 0; batch classifier loss: 0.480962; batch adversarial loss: 0.526284\n",
      "epoch 97; iter: 0; batch classifier loss: 0.472629; batch adversarial loss: 0.473480\n",
      "epoch 98; iter: 0; batch classifier loss: 0.389605; batch adversarial loss: 0.607019\n",
      "epoch 99; iter: 0; batch classifier loss: 0.366554; batch adversarial loss: 0.554128\n",
      "epoch 100; iter: 0; batch classifier loss: 0.425317; batch adversarial loss: 0.552742\n",
      "epoch 101; iter: 0; batch classifier loss: 0.393598; batch adversarial loss: 0.517410\n",
      "epoch 102; iter: 0; batch classifier loss: 0.363345; batch adversarial loss: 0.571232\n",
      "epoch 103; iter: 0; batch classifier loss: 0.445804; batch adversarial loss: 0.464437\n",
      "epoch 104; iter: 0; batch classifier loss: 0.412282; batch adversarial loss: 0.535582\n",
      "epoch 105; iter: 0; batch classifier loss: 0.451007; batch adversarial loss: 0.536325\n",
      "epoch 106; iter: 0; batch classifier loss: 0.400282; batch adversarial loss: 0.562050\n",
      "epoch 107; iter: 0; batch classifier loss: 0.385375; batch adversarial loss: 0.517949\n",
      "epoch 108; iter: 0; batch classifier loss: 0.407350; batch adversarial loss: 0.616409\n",
      "epoch 109; iter: 0; batch classifier loss: 0.380460; batch adversarial loss: 0.535245\n",
      "epoch 110; iter: 0; batch classifier loss: 0.377346; batch adversarial loss: 0.553057\n",
      "epoch 111; iter: 0; batch classifier loss: 0.332317; batch adversarial loss: 0.489542\n",
      "epoch 112; iter: 0; batch classifier loss: 0.397830; batch adversarial loss: 0.543800\n",
      "epoch 113; iter: 0; batch classifier loss: 0.355300; batch adversarial loss: 0.517437\n",
      "epoch 114; iter: 0; batch classifier loss: 0.351837; batch adversarial loss: 0.580170\n",
      "epoch 115; iter: 0; batch classifier loss: 0.324565; batch adversarial loss: 0.609723\n",
      "epoch 116; iter: 0; batch classifier loss: 0.365274; batch adversarial loss: 0.552753\n",
      "epoch 117; iter: 0; batch classifier loss: 0.412713; batch adversarial loss: 0.589050\n",
      "epoch 118; iter: 0; batch classifier loss: 0.384045; batch adversarial loss: 0.518003\n",
      "epoch 119; iter: 0; batch classifier loss: 0.386378; batch adversarial loss: 0.501283\n",
      "epoch 120; iter: 0; batch classifier loss: 0.405191; batch adversarial loss: 0.606692\n",
      "epoch 121; iter: 0; batch classifier loss: 0.400731; batch adversarial loss: 0.456748\n",
      "epoch 122; iter: 0; batch classifier loss: 0.436113; batch adversarial loss: 0.553234\n",
      "epoch 123; iter: 0; batch classifier loss: 0.300643; batch adversarial loss: 0.543401\n",
      "epoch 124; iter: 0; batch classifier loss: 0.360582; batch adversarial loss: 0.482424\n",
      "epoch 125; iter: 0; batch classifier loss: 0.461685; batch adversarial loss: 0.631486\n",
      "epoch 126; iter: 0; batch classifier loss: 0.323363; batch adversarial loss: 0.604650\n",
      "epoch 127; iter: 0; batch classifier loss: 0.346042; batch adversarial loss: 0.560860\n",
      "epoch 128; iter: 0; batch classifier loss: 0.307080; batch adversarial loss: 0.631498\n",
      "epoch 129; iter: 0; batch classifier loss: 0.398675; batch adversarial loss: 0.598965\n",
      "epoch 130; iter: 0; batch classifier loss: 0.416292; batch adversarial loss: 0.571668\n",
      "epoch 131; iter: 0; batch classifier loss: 0.334729; batch adversarial loss: 0.580637\n",
      "epoch 132; iter: 0; batch classifier loss: 0.378122; batch adversarial loss: 0.634635\n",
      "epoch 133; iter: 0; batch classifier loss: 0.383017; batch adversarial loss: 0.516758\n",
      "epoch 134; iter: 0; batch classifier loss: 0.410438; batch adversarial loss: 0.571557\n",
      "epoch 135; iter: 0; batch classifier loss: 0.330405; batch adversarial loss: 0.596478\n",
      "epoch 136; iter: 0; batch classifier loss: 0.448551; batch adversarial loss: 0.508579\n",
      "epoch 137; iter: 0; batch classifier loss: 0.349944; batch adversarial loss: 0.536146\n",
      "epoch 138; iter: 0; batch classifier loss: 0.365899; batch adversarial loss: 0.543417\n",
      "epoch 139; iter: 0; batch classifier loss: 0.390927; batch adversarial loss: 0.553094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 140; iter: 0; batch classifier loss: 0.577219; batch adversarial loss: 0.499564\n",
      "epoch 141; iter: 0; batch classifier loss: 0.378733; batch adversarial loss: 0.561831\n",
      "epoch 142; iter: 0; batch classifier loss: 0.353286; batch adversarial loss: 0.571398\n",
      "epoch 143; iter: 0; batch classifier loss: 0.376287; batch adversarial loss: 0.509751\n",
      "epoch 144; iter: 0; batch classifier loss: 0.364376; batch adversarial loss: 0.587960\n",
      "epoch 145; iter: 0; batch classifier loss: 0.276650; batch adversarial loss: 0.571342\n",
      "epoch 146; iter: 0; batch classifier loss: 0.400002; batch adversarial loss: 0.606619\n",
      "epoch 147; iter: 0; batch classifier loss: 0.350304; batch adversarial loss: 0.571689\n",
      "epoch 148; iter: 0; batch classifier loss: 0.348393; batch adversarial loss: 0.501422\n",
      "epoch 149; iter: 0; batch classifier loss: 0.396628; batch adversarial loss: 0.607766\n",
      "epoch 150; iter: 0; batch classifier loss: 0.389600; batch adversarial loss: 0.527010\n",
      "epoch 151; iter: 0; batch classifier loss: 0.424191; batch adversarial loss: 0.464080\n",
      "epoch 152; iter: 0; batch classifier loss: 0.305335; batch adversarial loss: 0.475422\n",
      "epoch 153; iter: 0; batch classifier loss: 0.371313; batch adversarial loss: 0.457002\n",
      "epoch 154; iter: 0; batch classifier loss: 0.386469; batch adversarial loss: 0.571016\n",
      "epoch 155; iter: 0; batch classifier loss: 0.341625; batch adversarial loss: 0.526588\n",
      "epoch 156; iter: 0; batch classifier loss: 0.401441; batch adversarial loss: 0.508959\n",
      "epoch 157; iter: 0; batch classifier loss: 0.336521; batch adversarial loss: 0.626500\n",
      "epoch 158; iter: 0; batch classifier loss: 0.489544; batch adversarial loss: 0.544683\n",
      "epoch 159; iter: 0; batch classifier loss: 0.390919; batch adversarial loss: 0.562067\n",
      "epoch 160; iter: 0; batch classifier loss: 0.395087; batch adversarial loss: 0.553213\n",
      "epoch 161; iter: 0; batch classifier loss: 0.437166; batch adversarial loss: 0.623787\n",
      "epoch 162; iter: 0; batch classifier loss: 0.465205; batch adversarial loss: 0.580268\n",
      "epoch 163; iter: 0; batch classifier loss: 0.315472; batch adversarial loss: 0.509285\n",
      "epoch 164; iter: 0; batch classifier loss: 0.396252; batch adversarial loss: 0.580165\n",
      "epoch 165; iter: 0; batch classifier loss: 0.327987; batch adversarial loss: 0.624954\n",
      "epoch 166; iter: 0; batch classifier loss: 0.398324; batch adversarial loss: 0.518913\n",
      "epoch 167; iter: 0; batch classifier loss: 0.327378; batch adversarial loss: 0.552256\n",
      "epoch 168; iter: 0; batch classifier loss: 0.355652; batch adversarial loss: 0.572070\n",
      "epoch 169; iter: 0; batch classifier loss: 0.419550; batch adversarial loss: 0.535492\n",
      "epoch 170; iter: 0; batch classifier loss: 0.405985; batch adversarial loss: 0.614672\n",
      "epoch 171; iter: 0; batch classifier loss: 0.267682; batch adversarial loss: 0.455253\n",
      "epoch 172; iter: 0; batch classifier loss: 0.404171; batch adversarial loss: 0.528739\n",
      "epoch 173; iter: 0; batch classifier loss: 0.334207; batch adversarial loss: 0.606602\n",
      "epoch 174; iter: 0; batch classifier loss: 0.379921; batch adversarial loss: 0.526818\n",
      "epoch 175; iter: 0; batch classifier loss: 0.340655; batch adversarial loss: 0.554429\n",
      "epoch 176; iter: 0; batch classifier loss: 0.354395; batch adversarial loss: 0.553279\n",
      "epoch 177; iter: 0; batch classifier loss: 0.401235; batch adversarial loss: 0.553587\n",
      "epoch 178; iter: 0; batch classifier loss: 0.334815; batch adversarial loss: 0.509790\n",
      "epoch 179; iter: 0; batch classifier loss: 0.301866; batch adversarial loss: 0.500533\n",
      "epoch 180; iter: 0; batch classifier loss: 0.377734; batch adversarial loss: 0.552870\n",
      "epoch 181; iter: 0; batch classifier loss: 0.320739; batch adversarial loss: 0.580159\n",
      "epoch 182; iter: 0; batch classifier loss: 0.303027; batch adversarial loss: 0.588527\n",
      "epoch 183; iter: 0; batch classifier loss: 0.478270; batch adversarial loss: 0.581630\n",
      "epoch 184; iter: 0; batch classifier loss: 0.387408; batch adversarial loss: 0.597565\n",
      "epoch 185; iter: 0; batch classifier loss: 0.297731; batch adversarial loss: 0.535810\n",
      "epoch 186; iter: 0; batch classifier loss: 0.319747; batch adversarial loss: 0.544703\n",
      "epoch 187; iter: 0; batch classifier loss: 0.309988; batch adversarial loss: 0.616272\n",
      "epoch 188; iter: 0; batch classifier loss: 0.354497; batch adversarial loss: 0.508309\n",
      "epoch 189; iter: 0; batch classifier loss: 0.307542; batch adversarial loss: 0.579156\n",
      "epoch 190; iter: 0; batch classifier loss: 0.408528; batch adversarial loss: 0.598161\n",
      "epoch 191; iter: 0; batch classifier loss: 0.378302; batch adversarial loss: 0.570570\n",
      "epoch 192; iter: 0; batch classifier loss: 0.365479; batch adversarial loss: 0.471850\n",
      "epoch 193; iter: 0; batch classifier loss: 0.275172; batch adversarial loss: 0.517546\n",
      "epoch 194; iter: 0; batch classifier loss: 0.347426; batch adversarial loss: 0.643534\n",
      "epoch 195; iter: 0; batch classifier loss: 0.366038; batch adversarial loss: 0.561461\n",
      "epoch 196; iter: 0; batch classifier loss: 0.277794; batch adversarial loss: 0.526718\n",
      "epoch 197; iter: 0; batch classifier loss: 0.309773; batch adversarial loss: 0.561957\n",
      "epoch 198; iter: 0; batch classifier loss: 0.311031; batch adversarial loss: 0.543755\n",
      "epoch 199; iter: 0; batch classifier loss: 0.289464; batch adversarial loss: 0.633303\n",
      "epoch 0; iter: 0; batch classifier loss: 0.668607; batch adversarial loss: 0.674594\n",
      "epoch 1; iter: 0; batch classifier loss: 0.595591; batch adversarial loss: 0.661572\n",
      "epoch 2; iter: 0; batch classifier loss: 0.544486; batch adversarial loss: 0.632610\n",
      "epoch 3; iter: 0; batch classifier loss: 0.566693; batch adversarial loss: 0.639954\n",
      "epoch 4; iter: 0; batch classifier loss: 0.605513; batch adversarial loss: 0.618139\n",
      "epoch 5; iter: 0; batch classifier loss: 0.572003; batch adversarial loss: 0.618929\n",
      "epoch 6; iter: 0; batch classifier loss: 0.582768; batch adversarial loss: 0.628217\n",
      "epoch 7; iter: 0; batch classifier loss: 0.543576; batch adversarial loss: 0.548340\n",
      "epoch 8; iter: 0; batch classifier loss: 0.583022; batch adversarial loss: 0.585799\n",
      "epoch 9; iter: 0; batch classifier loss: 0.539358; batch adversarial loss: 0.591506\n",
      "epoch 10; iter: 0; batch classifier loss: 0.550239; batch adversarial loss: 0.581538\n",
      "epoch 11; iter: 0; batch classifier loss: 0.483479; batch adversarial loss: 0.610774\n",
      "epoch 12; iter: 0; batch classifier loss: 0.575992; batch adversarial loss: 0.592478\n",
      "epoch 13; iter: 0; batch classifier loss: 0.548080; batch adversarial loss: 0.535961\n",
      "epoch 14; iter: 0; batch classifier loss: 0.404769; batch adversarial loss: 0.620583\n",
      "epoch 15; iter: 0; batch classifier loss: 0.527193; batch adversarial loss: 0.570052\n",
      "epoch 16; iter: 0; batch classifier loss: 0.533632; batch adversarial loss: 0.534457\n",
      "epoch 17; iter: 0; batch classifier loss: 0.423220; batch adversarial loss: 0.586405\n",
      "epoch 18; iter: 0; batch classifier loss: 0.570693; batch adversarial loss: 0.494995\n",
      "epoch 19; iter: 0; batch classifier loss: 0.510058; batch adversarial loss: 0.606098\n",
      "epoch 20; iter: 0; batch classifier loss: 0.444041; batch adversarial loss: 0.638645\n",
      "epoch 21; iter: 0; batch classifier loss: 0.515954; batch adversarial loss: 0.469495\n",
      "epoch 22; iter: 0; batch classifier loss: 0.547022; batch adversarial loss: 0.527356\n",
      "epoch 23; iter: 0; batch classifier loss: 0.542206; batch adversarial loss: 0.604067\n",
      "epoch 24; iter: 0; batch classifier loss: 0.497702; batch adversarial loss: 0.507807\n",
      "epoch 25; iter: 0; batch classifier loss: 0.474520; batch adversarial loss: 0.566837\n",
      "epoch 26; iter: 0; batch classifier loss: 0.474111; batch adversarial loss: 0.554123\n",
      "epoch 27; iter: 0; batch classifier loss: 0.505346; batch adversarial loss: 0.533349\n",
      "epoch 28; iter: 0; batch classifier loss: 0.413862; batch adversarial loss: 0.578760\n",
      "epoch 29; iter: 0; batch classifier loss: 0.420015; batch adversarial loss: 0.536155\n",
      "epoch 30; iter: 0; batch classifier loss: 0.479227; batch adversarial loss: 0.537825\n",
      "epoch 31; iter: 0; batch classifier loss: 0.414716; batch adversarial loss: 0.477213\n",
      "epoch 32; iter: 0; batch classifier loss: 0.515680; batch adversarial loss: 0.509524\n",
      "epoch 33; iter: 0; batch classifier loss: 0.424923; batch adversarial loss: 0.518279\n",
      "epoch 34; iter: 0; batch classifier loss: 0.432746; batch adversarial loss: 0.597929\n",
      "epoch 35; iter: 0; batch classifier loss: 0.450926; batch adversarial loss: 0.475576\n",
      "epoch 36; iter: 0; batch classifier loss: 0.445394; batch adversarial loss: 0.545104\n",
      "epoch 37; iter: 0; batch classifier loss: 0.544623; batch adversarial loss: 0.606621\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 38; iter: 0; batch classifier loss: 0.483992; batch adversarial loss: 0.508914\n",
      "epoch 39; iter: 0; batch classifier loss: 0.434487; batch adversarial loss: 0.562549\n",
      "epoch 40; iter: 0; batch classifier loss: 0.458451; batch adversarial loss: 0.571559\n",
      "epoch 41; iter: 0; batch classifier loss: 0.435216; batch adversarial loss: 0.571601\n",
      "epoch 42; iter: 0; batch classifier loss: 0.393077; batch adversarial loss: 0.535483\n",
      "epoch 43; iter: 0; batch classifier loss: 0.477864; batch adversarial loss: 0.508329\n",
      "epoch 44; iter: 0; batch classifier loss: 0.432691; batch adversarial loss: 0.508650\n",
      "epoch 45; iter: 0; batch classifier loss: 0.426003; batch adversarial loss: 0.544428\n",
      "epoch 46; iter: 0; batch classifier loss: 0.432363; batch adversarial loss: 0.617227\n",
      "epoch 47; iter: 0; batch classifier loss: 0.470354; batch adversarial loss: 0.617481\n",
      "epoch 48; iter: 0; batch classifier loss: 0.435473; batch adversarial loss: 0.535632\n",
      "epoch 49; iter: 0; batch classifier loss: 0.371764; batch adversarial loss: 0.434704\n",
      "epoch 50; iter: 0; batch classifier loss: 0.485544; batch adversarial loss: 0.553574\n",
      "epoch 51; iter: 0; batch classifier loss: 0.419384; batch adversarial loss: 0.581730\n",
      "epoch 52; iter: 0; batch classifier loss: 0.476433; batch adversarial loss: 0.562280\n",
      "epoch 53; iter: 0; batch classifier loss: 0.409675; batch adversarial loss: 0.497823\n",
      "epoch 54; iter: 0; batch classifier loss: 0.407335; batch adversarial loss: 0.563407\n",
      "epoch 55; iter: 0; batch classifier loss: 0.459762; batch adversarial loss: 0.507333\n",
      "epoch 56; iter: 0; batch classifier loss: 0.467037; batch adversarial loss: 0.581315\n",
      "epoch 57; iter: 0; batch classifier loss: 0.428579; batch adversarial loss: 0.571781\n",
      "epoch 58; iter: 0; batch classifier loss: 0.404820; batch adversarial loss: 0.610015\n",
      "epoch 59; iter: 0; batch classifier loss: 0.423945; batch adversarial loss: 0.516894\n",
      "epoch 60; iter: 0; batch classifier loss: 0.392593; batch adversarial loss: 0.571401\n",
      "epoch 61; iter: 0; batch classifier loss: 0.364845; batch adversarial loss: 0.590449\n",
      "epoch 62; iter: 0; batch classifier loss: 0.382088; batch adversarial loss: 0.444178\n",
      "epoch 63; iter: 0; batch classifier loss: 0.401672; batch adversarial loss: 0.615954\n",
      "epoch 64; iter: 0; batch classifier loss: 0.394020; batch adversarial loss: 0.599662\n",
      "epoch 65; iter: 0; batch classifier loss: 0.373416; batch adversarial loss: 0.571295\n",
      "epoch 66; iter: 0; batch classifier loss: 0.462565; batch adversarial loss: 0.600269\n",
      "epoch 67; iter: 0; batch classifier loss: 0.448460; batch adversarial loss: 0.507812\n",
      "epoch 68; iter: 0; batch classifier loss: 0.364144; batch adversarial loss: 0.544042\n",
      "epoch 69; iter: 0; batch classifier loss: 0.410195; batch adversarial loss: 0.581374\n",
      "epoch 70; iter: 0; batch classifier loss: 0.391960; batch adversarial loss: 0.599898\n",
      "epoch 71; iter: 0; batch classifier loss: 0.414224; batch adversarial loss: 0.543242\n",
      "epoch 72; iter: 0; batch classifier loss: 0.371155; batch adversarial loss: 0.544490\n",
      "epoch 73; iter: 0; batch classifier loss: 0.320813; batch adversarial loss: 0.636261\n",
      "epoch 74; iter: 0; batch classifier loss: 0.424627; batch adversarial loss: 0.543619\n",
      "epoch 75; iter: 0; batch classifier loss: 0.448475; batch adversarial loss: 0.472192\n",
      "epoch 76; iter: 0; batch classifier loss: 0.383647; batch adversarial loss: 0.508801\n",
      "epoch 77; iter: 0; batch classifier loss: 0.350921; batch adversarial loss: 0.607109\n",
      "epoch 78; iter: 0; batch classifier loss: 0.420932; batch adversarial loss: 0.543951\n",
      "epoch 79; iter: 0; batch classifier loss: 0.349683; batch adversarial loss: 0.517430\n",
      "epoch 80; iter: 0; batch classifier loss: 0.411824; batch adversarial loss: 0.488588\n",
      "epoch 81; iter: 0; batch classifier loss: 0.386426; batch adversarial loss: 0.524896\n",
      "epoch 82; iter: 0; batch classifier loss: 0.356659; batch adversarial loss: 0.674307\n",
      "epoch 83; iter: 0; batch classifier loss: 0.457203; batch adversarial loss: 0.573232\n",
      "epoch 84; iter: 0; batch classifier loss: 0.430085; batch adversarial loss: 0.599648\n",
      "epoch 85; iter: 0; batch classifier loss: 0.402520; batch adversarial loss: 0.526013\n",
      "epoch 86; iter: 0; batch classifier loss: 0.421164; batch adversarial loss: 0.479417\n",
      "epoch 87; iter: 0; batch classifier loss: 0.346820; batch adversarial loss: 0.534641\n",
      "epoch 88; iter: 0; batch classifier loss: 0.373557; batch adversarial loss: 0.544950\n",
      "epoch 89; iter: 0; batch classifier loss: 0.350526; batch adversarial loss: 0.516883\n",
      "epoch 90; iter: 0; batch classifier loss: 0.354718; batch adversarial loss: 0.598679\n",
      "epoch 91; iter: 0; batch classifier loss: 0.409451; batch adversarial loss: 0.525207\n",
      "epoch 92; iter: 0; batch classifier loss: 0.370406; batch adversarial loss: 0.451283\n",
      "epoch 93; iter: 0; batch classifier loss: 0.479019; batch adversarial loss: 0.552161\n",
      "epoch 94; iter: 0; batch classifier loss: 0.425856; batch adversarial loss: 0.461486\n",
      "epoch 95; iter: 0; batch classifier loss: 0.442753; batch adversarial loss: 0.516635\n",
      "epoch 96; iter: 0; batch classifier loss: 0.449148; batch adversarial loss: 0.553140\n",
      "epoch 97; iter: 0; batch classifier loss: 0.382573; batch adversarial loss: 0.553353\n",
      "epoch 98; iter: 0; batch classifier loss: 0.415613; batch adversarial loss: 0.527525\n",
      "epoch 99; iter: 0; batch classifier loss: 0.427814; batch adversarial loss: 0.534539\n",
      "epoch 100; iter: 0; batch classifier loss: 0.357977; batch adversarial loss: 0.517287\n",
      "epoch 101; iter: 0; batch classifier loss: 0.415027; batch adversarial loss: 0.517859\n",
      "epoch 102; iter: 0; batch classifier loss: 0.423497; batch adversarial loss: 0.542971\n",
      "epoch 103; iter: 0; batch classifier loss: 0.391463; batch adversarial loss: 0.534367\n",
      "epoch 104; iter: 0; batch classifier loss: 0.400814; batch adversarial loss: 0.591304\n",
      "epoch 105; iter: 0; batch classifier loss: 0.379370; batch adversarial loss: 0.497952\n",
      "epoch 106; iter: 0; batch classifier loss: 0.372656; batch adversarial loss: 0.470726\n",
      "epoch 107; iter: 0; batch classifier loss: 0.443089; batch adversarial loss: 0.545328\n",
      "epoch 108; iter: 0; batch classifier loss: 0.363593; batch adversarial loss: 0.487951\n",
      "epoch 109; iter: 0; batch classifier loss: 0.401870; batch adversarial loss: 0.534568\n",
      "epoch 110; iter: 0; batch classifier loss: 0.460489; batch adversarial loss: 0.527109\n",
      "epoch 111; iter: 0; batch classifier loss: 0.417037; batch adversarial loss: 0.536749\n",
      "epoch 112; iter: 0; batch classifier loss: 0.405268; batch adversarial loss: 0.544523\n",
      "epoch 113; iter: 0; batch classifier loss: 0.451063; batch adversarial loss: 0.460462\n",
      "epoch 114; iter: 0; batch classifier loss: 0.397027; batch adversarial loss: 0.572240\n",
      "epoch 115; iter: 0; batch classifier loss: 0.470354; batch adversarial loss: 0.562966\n",
      "epoch 116; iter: 0; batch classifier loss: 0.407858; batch adversarial loss: 0.517810\n",
      "epoch 117; iter: 0; batch classifier loss: 0.415663; batch adversarial loss: 0.553230\n",
      "epoch 118; iter: 0; batch classifier loss: 0.337463; batch adversarial loss: 0.572833\n",
      "epoch 119; iter: 0; batch classifier loss: 0.382878; batch adversarial loss: 0.600966\n",
      "epoch 120; iter: 0; batch classifier loss: 0.396021; batch adversarial loss: 0.526611\n",
      "epoch 121; iter: 0; batch classifier loss: 0.361695; batch adversarial loss: 0.535478\n",
      "epoch 122; iter: 0; batch classifier loss: 0.403308; batch adversarial loss: 0.508806\n",
      "epoch 123; iter: 0; batch classifier loss: 0.320896; batch adversarial loss: 0.506350\n",
      "epoch 124; iter: 0; batch classifier loss: 0.336763; batch adversarial loss: 0.470323\n",
      "epoch 125; iter: 0; batch classifier loss: 0.301791; batch adversarial loss: 0.480123\n",
      "epoch 126; iter: 0; batch classifier loss: 0.348609; batch adversarial loss: 0.553065\n",
      "epoch 127; iter: 0; batch classifier loss: 0.384705; batch adversarial loss: 0.499245\n",
      "epoch 128; iter: 0; batch classifier loss: 0.381120; batch adversarial loss: 0.553064\n",
      "epoch 129; iter: 0; batch classifier loss: 0.449687; batch adversarial loss: 0.535589\n",
      "epoch 130; iter: 0; batch classifier loss: 0.354673; batch adversarial loss: 0.572580\n",
      "epoch 131; iter: 0; batch classifier loss: 0.398909; batch adversarial loss: 0.589929\n",
      "epoch 132; iter: 0; batch classifier loss: 0.401523; batch adversarial loss: 0.564314\n",
      "epoch 133; iter: 0; batch classifier loss: 0.411873; batch adversarial loss: 0.507608\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 134; iter: 0; batch classifier loss: 0.337864; batch adversarial loss: 0.508012\n",
      "epoch 135; iter: 0; batch classifier loss: 0.309236; batch adversarial loss: 0.508261\n",
      "epoch 136; iter: 0; batch classifier loss: 0.348882; batch adversarial loss: 0.545237\n",
      "epoch 137; iter: 0; batch classifier loss: 0.329128; batch adversarial loss: 0.564609\n",
      "epoch 138; iter: 0; batch classifier loss: 0.420841; batch adversarial loss: 0.545534\n",
      "epoch 139; iter: 0; batch classifier loss: 0.417300; batch adversarial loss: 0.544046\n",
      "epoch 140; iter: 0; batch classifier loss: 0.373749; batch adversarial loss: 0.479624\n",
      "epoch 141; iter: 0; batch classifier loss: 0.304208; batch adversarial loss: 0.571946\n",
      "epoch 142; iter: 0; batch classifier loss: 0.379828; batch adversarial loss: 0.591027\n",
      "epoch 143; iter: 0; batch classifier loss: 0.337845; batch adversarial loss: 0.590758\n",
      "epoch 144; iter: 0; batch classifier loss: 0.409774; batch adversarial loss: 0.562628\n",
      "epoch 145; iter: 0; batch classifier loss: 0.290045; batch adversarial loss: 0.507440\n",
      "epoch 146; iter: 0; batch classifier loss: 0.331479; batch adversarial loss: 0.589760\n",
      "epoch 147; iter: 0; batch classifier loss: 0.405595; batch adversarial loss: 0.508700\n",
      "epoch 148; iter: 0; batch classifier loss: 0.415406; batch adversarial loss: 0.497854\n",
      "epoch 149; iter: 0; batch classifier loss: 0.316531; batch adversarial loss: 0.608922\n",
      "epoch 150; iter: 0; batch classifier loss: 0.399620; batch adversarial loss: 0.516975\n",
      "epoch 151; iter: 0; batch classifier loss: 0.351076; batch adversarial loss: 0.535800\n",
      "epoch 152; iter: 0; batch classifier loss: 0.314805; batch adversarial loss: 0.562238\n",
      "epoch 153; iter: 0; batch classifier loss: 0.331862; batch adversarial loss: 0.526345\n",
      "epoch 154; iter: 0; batch classifier loss: 0.370117; batch adversarial loss: 0.506679\n",
      "epoch 155; iter: 0; batch classifier loss: 0.415104; batch adversarial loss: 0.553381\n",
      "epoch 156; iter: 0; batch classifier loss: 0.382565; batch adversarial loss: 0.508391\n",
      "epoch 157; iter: 0; batch classifier loss: 0.381264; batch adversarial loss: 0.544448\n",
      "epoch 158; iter: 0; batch classifier loss: 0.360890; batch adversarial loss: 0.506041\n",
      "epoch 159; iter: 0; batch classifier loss: 0.329060; batch adversarial loss: 0.572764\n",
      "epoch 160; iter: 0; batch classifier loss: 0.413631; batch adversarial loss: 0.442564\n",
      "epoch 161; iter: 0; batch classifier loss: 0.400846; batch adversarial loss: 0.554437\n",
      "epoch 162; iter: 0; batch classifier loss: 0.372208; batch adversarial loss: 0.589890\n",
      "epoch 163; iter: 0; batch classifier loss: 0.379715; batch adversarial loss: 0.554366\n",
      "epoch 164; iter: 0; batch classifier loss: 0.387668; batch adversarial loss: 0.525523\n",
      "epoch 165; iter: 0; batch classifier loss: 0.391927; batch adversarial loss: 0.571920\n",
      "epoch 166; iter: 0; batch classifier loss: 0.359857; batch adversarial loss: 0.508773\n",
      "epoch 167; iter: 0; batch classifier loss: 0.367328; batch adversarial loss: 0.517482\n",
      "epoch 168; iter: 0; batch classifier loss: 0.336318; batch adversarial loss: 0.507288\n",
      "epoch 169; iter: 0; batch classifier loss: 0.402656; batch adversarial loss: 0.498329\n",
      "epoch 170; iter: 0; batch classifier loss: 0.391200; batch adversarial loss: 0.535637\n",
      "epoch 171; iter: 0; batch classifier loss: 0.316903; batch adversarial loss: 0.572279\n",
      "epoch 172; iter: 0; batch classifier loss: 0.383273; batch adversarial loss: 0.515526\n",
      "epoch 173; iter: 0; batch classifier loss: 0.348611; batch adversarial loss: 0.480771\n",
      "epoch 174; iter: 0; batch classifier loss: 0.355920; batch adversarial loss: 0.562685\n",
      "epoch 175; iter: 0; batch classifier loss: 0.326939; batch adversarial loss: 0.535325\n",
      "epoch 176; iter: 0; batch classifier loss: 0.361251; batch adversarial loss: 0.553229\n",
      "epoch 177; iter: 0; batch classifier loss: 0.378275; batch adversarial loss: 0.517012\n",
      "epoch 178; iter: 0; batch classifier loss: 0.353093; batch adversarial loss: 0.544763\n",
      "epoch 179; iter: 0; batch classifier loss: 0.399631; batch adversarial loss: 0.516717\n",
      "epoch 180; iter: 0; batch classifier loss: 0.393053; batch adversarial loss: 0.627138\n",
      "epoch 181; iter: 0; batch classifier loss: 0.378692; batch adversarial loss: 0.635410\n",
      "epoch 182; iter: 0; batch classifier loss: 0.367145; batch adversarial loss: 0.425274\n",
      "epoch 183; iter: 0; batch classifier loss: 0.359179; batch adversarial loss: 0.525894\n",
      "epoch 184; iter: 0; batch classifier loss: 0.321915; batch adversarial loss: 0.434808\n",
      "epoch 185; iter: 0; batch classifier loss: 0.371780; batch adversarial loss: 0.535008\n",
      "epoch 186; iter: 0; batch classifier loss: 0.365893; batch adversarial loss: 0.654051\n",
      "epoch 187; iter: 0; batch classifier loss: 0.317536; batch adversarial loss: 0.599936\n",
      "epoch 188; iter: 0; batch classifier loss: 0.355213; batch adversarial loss: 0.561625\n",
      "epoch 189; iter: 0; batch classifier loss: 0.391509; batch adversarial loss: 0.480573\n",
      "epoch 190; iter: 0; batch classifier loss: 0.354691; batch adversarial loss: 0.588813\n",
      "epoch 191; iter: 0; batch classifier loss: 0.307322; batch adversarial loss: 0.580734\n",
      "epoch 192; iter: 0; batch classifier loss: 0.401766; batch adversarial loss: 0.563068\n",
      "epoch 193; iter: 0; batch classifier loss: 0.402898; batch adversarial loss: 0.506962\n",
      "epoch 194; iter: 0; batch classifier loss: 0.414469; batch adversarial loss: 0.525852\n",
      "epoch 195; iter: 0; batch classifier loss: 0.312161; batch adversarial loss: 0.562598\n",
      "epoch 196; iter: 0; batch classifier loss: 0.338538; batch adversarial loss: 0.590926\n",
      "epoch 197; iter: 0; batch classifier loss: 0.282880; batch adversarial loss: 0.515602\n",
      "epoch 198; iter: 0; batch classifier loss: 0.361153; batch adversarial loss: 0.499263\n",
      "epoch 199; iter: 0; batch classifier loss: 0.340177; batch adversarial loss: 0.472728\n",
      "epoch 0; iter: 0; batch classifier loss: 0.648203; batch adversarial loss: 0.626883\n",
      "epoch 1; iter: 0; batch classifier loss: 0.609030; batch adversarial loss: 0.648236\n",
      "epoch 2; iter: 0; batch classifier loss: 0.677444; batch adversarial loss: 0.661176\n",
      "epoch 3; iter: 0; batch classifier loss: 0.539682; batch adversarial loss: 0.624913\n",
      "epoch 4; iter: 0; batch classifier loss: 0.581565; batch adversarial loss: 0.660873\n",
      "epoch 5; iter: 0; batch classifier loss: 0.606311; batch adversarial loss: 0.666724\n",
      "epoch 6; iter: 0; batch classifier loss: 0.573179; batch adversarial loss: 0.653612\n",
      "epoch 7; iter: 0; batch classifier loss: 0.646015; batch adversarial loss: 0.578636\n",
      "epoch 8; iter: 0; batch classifier loss: 0.561284; batch adversarial loss: 0.614371\n",
      "epoch 9; iter: 0; batch classifier loss: 0.597775; batch adversarial loss: 0.596128\n",
      "epoch 10; iter: 0; batch classifier loss: 0.524040; batch adversarial loss: 0.590698\n",
      "epoch 11; iter: 0; batch classifier loss: 0.539852; batch adversarial loss: 0.570916\n",
      "epoch 12; iter: 0; batch classifier loss: 0.532675; batch adversarial loss: 0.563743\n",
      "epoch 13; iter: 0; batch classifier loss: 0.547293; batch adversarial loss: 0.533925\n",
      "epoch 14; iter: 0; batch classifier loss: 0.492589; batch adversarial loss: 0.513217\n",
      "epoch 15; iter: 0; batch classifier loss: 0.549181; batch adversarial loss: 0.515588\n",
      "epoch 16; iter: 0; batch classifier loss: 0.500611; batch adversarial loss: 0.626233\n",
      "epoch 17; iter: 0; batch classifier loss: 0.520319; batch adversarial loss: 0.590514\n",
      "epoch 18; iter: 0; batch classifier loss: 0.505038; batch adversarial loss: 0.613675\n",
      "epoch 19; iter: 0; batch classifier loss: 0.497119; batch adversarial loss: 0.546715\n",
      "epoch 20; iter: 0; batch classifier loss: 0.469108; batch adversarial loss: 0.562181\n",
      "epoch 21; iter: 0; batch classifier loss: 0.413240; batch adversarial loss: 0.544437\n",
      "epoch 22; iter: 0; batch classifier loss: 0.522956; batch adversarial loss: 0.522576\n",
      "epoch 23; iter: 0; batch classifier loss: 0.508921; batch adversarial loss: 0.566987\n",
      "epoch 24; iter: 0; batch classifier loss: 0.513964; batch adversarial loss: 0.554704\n",
      "epoch 25; iter: 0; batch classifier loss: 0.505682; batch adversarial loss: 0.435193\n",
      "epoch 26; iter: 0; batch classifier loss: 0.524300; batch adversarial loss: 0.512418\n",
      "epoch 27; iter: 0; batch classifier loss: 0.468254; batch adversarial loss: 0.496067\n",
      "epoch 28; iter: 0; batch classifier loss: 0.452638; batch adversarial loss: 0.561595\n",
      "epoch 29; iter: 0; batch classifier loss: 0.438848; batch adversarial loss: 0.527427\n",
      "epoch 30; iter: 0; batch classifier loss: 0.504476; batch adversarial loss: 0.571317\n",
      "epoch 31; iter: 0; batch classifier loss: 0.463386; batch adversarial loss: 0.515381\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 32; iter: 0; batch classifier loss: 0.412898; batch adversarial loss: 0.599156\n",
      "epoch 33; iter: 0; batch classifier loss: 0.519266; batch adversarial loss: 0.634816\n",
      "epoch 34; iter: 0; batch classifier loss: 0.459308; batch adversarial loss: 0.535549\n",
      "epoch 35; iter: 0; batch classifier loss: 0.452698; batch adversarial loss: 0.499959\n",
      "epoch 36; iter: 0; batch classifier loss: 0.465380; batch adversarial loss: 0.534546\n",
      "epoch 37; iter: 0; batch classifier loss: 0.484198; batch adversarial loss: 0.517132\n",
      "epoch 38; iter: 0; batch classifier loss: 0.430136; batch adversarial loss: 0.535680\n",
      "epoch 39; iter: 0; batch classifier loss: 0.451285; batch adversarial loss: 0.581569\n",
      "epoch 40; iter: 0; batch classifier loss: 0.481616; batch adversarial loss: 0.582554\n",
      "epoch 41; iter: 0; batch classifier loss: 0.535451; batch adversarial loss: 0.555439\n",
      "epoch 42; iter: 0; batch classifier loss: 0.495692; batch adversarial loss: 0.608881\n",
      "epoch 43; iter: 0; batch classifier loss: 0.475630; batch adversarial loss: 0.572138\n",
      "epoch 44; iter: 0; batch classifier loss: 0.481224; batch adversarial loss: 0.507116\n",
      "epoch 45; iter: 0; batch classifier loss: 0.486307; batch adversarial loss: 0.544779\n",
      "epoch 46; iter: 0; batch classifier loss: 0.405769; batch adversarial loss: 0.562942\n",
      "epoch 47; iter: 0; batch classifier loss: 0.453546; batch adversarial loss: 0.563327\n",
      "epoch 48; iter: 0; batch classifier loss: 0.482527; batch adversarial loss: 0.516719\n",
      "epoch 49; iter: 0; batch classifier loss: 0.400313; batch adversarial loss: 0.535561\n",
      "epoch 50; iter: 0; batch classifier loss: 0.459056; batch adversarial loss: 0.581267\n",
      "epoch 51; iter: 0; batch classifier loss: 0.387051; batch adversarial loss: 0.498078\n",
      "epoch 52; iter: 0; batch classifier loss: 0.471705; batch adversarial loss: 0.544427\n",
      "epoch 53; iter: 0; batch classifier loss: 0.391751; batch adversarial loss: 0.544366\n",
      "epoch 54; iter: 0; batch classifier loss: 0.451953; batch adversarial loss: 0.517260\n",
      "epoch 55; iter: 0; batch classifier loss: 0.415346; batch adversarial loss: 0.534240\n",
      "epoch 56; iter: 0; batch classifier loss: 0.409310; batch adversarial loss: 0.561687\n",
      "epoch 57; iter: 0; batch classifier loss: 0.391974; batch adversarial loss: 0.591372\n",
      "epoch 58; iter: 0; batch classifier loss: 0.418066; batch adversarial loss: 0.572727\n",
      "epoch 59; iter: 0; batch classifier loss: 0.417226; batch adversarial loss: 0.468159\n",
      "epoch 60; iter: 0; batch classifier loss: 0.460069; batch adversarial loss: 0.629980\n",
      "epoch 61; iter: 0; batch classifier loss: 0.376852; batch adversarial loss: 0.561938\n",
      "epoch 62; iter: 0; batch classifier loss: 0.396525; batch adversarial loss: 0.526562\n",
      "epoch 63; iter: 0; batch classifier loss: 0.432366; batch adversarial loss: 0.621809\n",
      "epoch 64; iter: 0; batch classifier loss: 0.504820; batch adversarial loss: 0.499659\n",
      "epoch 65; iter: 0; batch classifier loss: 0.493617; batch adversarial loss: 0.527062\n",
      "epoch 66; iter: 0; batch classifier loss: 0.395120; batch adversarial loss: 0.506281\n",
      "epoch 67; iter: 0; batch classifier loss: 0.471558; batch adversarial loss: 0.589432\n",
      "epoch 68; iter: 0; batch classifier loss: 0.384839; batch adversarial loss: 0.553575\n",
      "epoch 69; iter: 0; batch classifier loss: 0.426346; batch adversarial loss: 0.516707\n",
      "epoch 70; iter: 0; batch classifier loss: 0.384636; batch adversarial loss: 0.544454\n",
      "epoch 71; iter: 0; batch classifier loss: 0.452412; batch adversarial loss: 0.551023\n",
      "epoch 72; iter: 0; batch classifier loss: 0.362356; batch adversarial loss: 0.514385\n",
      "epoch 73; iter: 0; batch classifier loss: 0.377447; batch adversarial loss: 0.526846\n",
      "epoch 74; iter: 0; batch classifier loss: 0.381939; batch adversarial loss: 0.572682\n",
      "epoch 75; iter: 0; batch classifier loss: 0.435551; batch adversarial loss: 0.608806\n",
      "epoch 76; iter: 0; batch classifier loss: 0.383228; batch adversarial loss: 0.544229\n",
      "epoch 77; iter: 0; batch classifier loss: 0.383145; batch adversarial loss: 0.537267\n",
      "epoch 78; iter: 0; batch classifier loss: 0.349546; batch adversarial loss: 0.545747\n",
      "epoch 79; iter: 0; batch classifier loss: 0.386619; batch adversarial loss: 0.517583\n",
      "epoch 80; iter: 0; batch classifier loss: 0.374400; batch adversarial loss: 0.528895\n",
      "epoch 81; iter: 0; batch classifier loss: 0.420424; batch adversarial loss: 0.649101\n",
      "epoch 82; iter: 0; batch classifier loss: 0.455024; batch adversarial loss: 0.523976\n",
      "epoch 83; iter: 0; batch classifier loss: 0.444291; batch adversarial loss: 0.469085\n",
      "epoch 84; iter: 0; batch classifier loss: 0.441740; batch adversarial loss: 0.592165\n",
      "epoch 85; iter: 0; batch classifier loss: 0.301789; batch adversarial loss: 0.563362\n",
      "epoch 86; iter: 0; batch classifier loss: 0.384949; batch adversarial loss: 0.544207\n",
      "epoch 87; iter: 0; batch classifier loss: 0.351470; batch adversarial loss: 0.485681\n",
      "epoch 88; iter: 0; batch classifier loss: 0.426290; batch adversarial loss: 0.579943\n",
      "epoch 89; iter: 0; batch classifier loss: 0.375517; batch adversarial loss: 0.544179\n",
      "epoch 90; iter: 0; batch classifier loss: 0.383165; batch adversarial loss: 0.553017\n",
      "epoch 91; iter: 0; batch classifier loss: 0.329039; batch adversarial loss: 0.552693\n",
      "epoch 92; iter: 0; batch classifier loss: 0.373185; batch adversarial loss: 0.488472\n",
      "epoch 93; iter: 0; batch classifier loss: 0.470169; batch adversarial loss: 0.516666\n",
      "epoch 94; iter: 0; batch classifier loss: 0.396357; batch adversarial loss: 0.498654\n",
      "epoch 95; iter: 0; batch classifier loss: 0.321442; batch adversarial loss: 0.571848\n",
      "epoch 96; iter: 0; batch classifier loss: 0.410699; batch adversarial loss: 0.637554\n",
      "epoch 97; iter: 0; batch classifier loss: 0.418966; batch adversarial loss: 0.580893\n",
      "epoch 98; iter: 0; batch classifier loss: 0.397932; batch adversarial loss: 0.674786\n",
      "epoch 99; iter: 0; batch classifier loss: 0.340556; batch adversarial loss: 0.516131\n",
      "epoch 100; iter: 0; batch classifier loss: 0.383137; batch adversarial loss: 0.524858\n",
      "epoch 101; iter: 0; batch classifier loss: 0.355735; batch adversarial loss: 0.554042\n",
      "epoch 102; iter: 0; batch classifier loss: 0.420765; batch adversarial loss: 0.544167\n",
      "epoch 103; iter: 0; batch classifier loss: 0.386213; batch adversarial loss: 0.544978\n",
      "epoch 104; iter: 0; batch classifier loss: 0.406772; batch adversarial loss: 0.526296\n",
      "epoch 105; iter: 0; batch classifier loss: 0.395442; batch adversarial loss: 0.657061\n",
      "epoch 106; iter: 0; batch classifier loss: 0.342243; batch adversarial loss: 0.561376\n",
      "epoch 107; iter: 0; batch classifier loss: 0.375485; batch adversarial loss: 0.545256\n",
      "epoch 108; iter: 0; batch classifier loss: 0.396374; batch adversarial loss: 0.545998\n",
      "epoch 109; iter: 0; batch classifier loss: 0.382984; batch adversarial loss: 0.499594\n",
      "epoch 110; iter: 0; batch classifier loss: 0.426638; batch adversarial loss: 0.547734\n",
      "epoch 111; iter: 0; batch classifier loss: 0.389015; batch adversarial loss: 0.590607\n",
      "epoch 112; iter: 0; batch classifier loss: 0.355011; batch adversarial loss: 0.545019\n",
      "epoch 113; iter: 0; batch classifier loss: 0.419326; batch adversarial loss: 0.546436\n",
      "epoch 114; iter: 0; batch classifier loss: 0.394559; batch adversarial loss: 0.545353\n",
      "epoch 115; iter: 0; batch classifier loss: 0.368384; batch adversarial loss: 0.562969\n",
      "epoch 116; iter: 0; batch classifier loss: 0.385787; batch adversarial loss: 0.544588\n",
      "epoch 117; iter: 0; batch classifier loss: 0.379492; batch adversarial loss: 0.572176\n",
      "epoch 118; iter: 0; batch classifier loss: 0.354102; batch adversarial loss: 0.489401\n",
      "epoch 119; iter: 0; batch classifier loss: 0.433147; batch adversarial loss: 0.572029\n",
      "epoch 120; iter: 0; batch classifier loss: 0.390152; batch adversarial loss: 0.507732\n",
      "epoch 121; iter: 0; batch classifier loss: 0.318322; batch adversarial loss: 0.534916\n",
      "epoch 122; iter: 0; batch classifier loss: 0.357947; batch adversarial loss: 0.572551\n",
      "epoch 123; iter: 0; batch classifier loss: 0.438354; batch adversarial loss: 0.478485\n",
      "epoch 124; iter: 0; batch classifier loss: 0.320880; batch adversarial loss: 0.525810\n",
      "epoch 125; iter: 0; batch classifier loss: 0.389838; batch adversarial loss: 0.534739\n",
      "epoch 126; iter: 0; batch classifier loss: 0.353613; batch adversarial loss: 0.478719\n",
      "epoch 127; iter: 0; batch classifier loss: 0.389225; batch adversarial loss: 0.487743\n",
      "epoch 128; iter: 0; batch classifier loss: 0.310339; batch adversarial loss: 0.518660\n",
      "epoch 129; iter: 0; batch classifier loss: 0.325452; batch adversarial loss: 0.591749\n",
      "epoch 130; iter: 0; batch classifier loss: 0.341199; batch adversarial loss: 0.552175\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 131; iter: 0; batch classifier loss: 0.350448; batch adversarial loss: 0.526758\n",
      "epoch 132; iter: 0; batch classifier loss: 0.405937; batch adversarial loss: 0.553935\n",
      "epoch 133; iter: 0; batch classifier loss: 0.432374; batch adversarial loss: 0.470184\n",
      "epoch 134; iter: 0; batch classifier loss: 0.406471; batch adversarial loss: 0.545115\n",
      "epoch 135; iter: 0; batch classifier loss: 0.367851; batch adversarial loss: 0.562356\n",
      "epoch 136; iter: 0; batch classifier loss: 0.306799; batch adversarial loss: 0.477150\n",
      "epoch 137; iter: 0; batch classifier loss: 0.393160; batch adversarial loss: 0.508665\n",
      "epoch 138; iter: 0; batch classifier loss: 0.374566; batch adversarial loss: 0.498686\n",
      "epoch 139; iter: 0; batch classifier loss: 0.363352; batch adversarial loss: 0.535458\n",
      "epoch 140; iter: 0; batch classifier loss: 0.360187; batch adversarial loss: 0.488492\n",
      "epoch 141; iter: 0; batch classifier loss: 0.332550; batch adversarial loss: 0.598989\n",
      "epoch 142; iter: 0; batch classifier loss: 0.356021; batch adversarial loss: 0.497977\n",
      "epoch 143; iter: 0; batch classifier loss: 0.351755; batch adversarial loss: 0.580935\n",
      "epoch 144; iter: 0; batch classifier loss: 0.387169; batch adversarial loss: 0.563763\n",
      "epoch 145; iter: 0; batch classifier loss: 0.384482; batch adversarial loss: 0.572206\n",
      "epoch 146; iter: 0; batch classifier loss: 0.316774; batch adversarial loss: 0.599887\n",
      "epoch 147; iter: 0; batch classifier loss: 0.463546; batch adversarial loss: 0.536087\n",
      "epoch 148; iter: 0; batch classifier loss: 0.383702; batch adversarial loss: 0.599958\n",
      "epoch 149; iter: 0; batch classifier loss: 0.401880; batch adversarial loss: 0.515474\n",
      "epoch 150; iter: 0; batch classifier loss: 0.330006; batch adversarial loss: 0.488526\n",
      "epoch 151; iter: 0; batch classifier loss: 0.442243; batch adversarial loss: 0.552615\n",
      "epoch 152; iter: 0; batch classifier loss: 0.370496; batch adversarial loss: 0.478700\n",
      "epoch 153; iter: 0; batch classifier loss: 0.345100; batch adversarial loss: 0.496561\n",
      "epoch 154; iter: 0; batch classifier loss: 0.328546; batch adversarial loss: 0.553953\n",
      "epoch 155; iter: 0; batch classifier loss: 0.376368; batch adversarial loss: 0.535995\n",
      "epoch 156; iter: 0; batch classifier loss: 0.371559; batch adversarial loss: 0.618184\n",
      "epoch 157; iter: 0; batch classifier loss: 0.388394; batch adversarial loss: 0.452990\n",
      "epoch 158; iter: 0; batch classifier loss: 0.459906; batch adversarial loss: 0.562931\n",
      "epoch 159; iter: 0; batch classifier loss: 0.416227; batch adversarial loss: 0.636858\n",
      "epoch 160; iter: 0; batch classifier loss: 0.282382; batch adversarial loss: 0.553779\n",
      "epoch 161; iter: 0; batch classifier loss: 0.349496; batch adversarial loss: 0.573033\n",
      "epoch 162; iter: 0; batch classifier loss: 0.384175; batch adversarial loss: 0.572658\n",
      "epoch 163; iter: 0; batch classifier loss: 0.374520; batch adversarial loss: 0.600978\n",
      "epoch 164; iter: 0; batch classifier loss: 0.373849; batch adversarial loss: 0.544120\n",
      "epoch 165; iter: 0; batch classifier loss: 0.357552; batch adversarial loss: 0.526758\n",
      "epoch 166; iter: 0; batch classifier loss: 0.380790; batch adversarial loss: 0.543840\n",
      "epoch 167; iter: 0; batch classifier loss: 0.409269; batch adversarial loss: 0.480502\n",
      "epoch 168; iter: 0; batch classifier loss: 0.366473; batch adversarial loss: 0.478169\n",
      "epoch 169; iter: 0; batch classifier loss: 0.361182; batch adversarial loss: 0.497362\n",
      "epoch 170; iter: 0; batch classifier loss: 0.337541; batch adversarial loss: 0.571634\n",
      "epoch 171; iter: 0; batch classifier loss: 0.359620; batch adversarial loss: 0.553579\n",
      "epoch 172; iter: 0; batch classifier loss: 0.291854; batch adversarial loss: 0.534415\n",
      "epoch 173; iter: 0; batch classifier loss: 0.346904; batch adversarial loss: 0.543697\n",
      "epoch 174; iter: 0; batch classifier loss: 0.373844; batch adversarial loss: 0.546248\n",
      "epoch 175; iter: 0; batch classifier loss: 0.340021; batch adversarial loss: 0.525119\n",
      "epoch 176; iter: 0; batch classifier loss: 0.358186; batch adversarial loss: 0.508644\n",
      "epoch 177; iter: 0; batch classifier loss: 0.377855; batch adversarial loss: 0.547049\n",
      "epoch 178; iter: 0; batch classifier loss: 0.382109; batch adversarial loss: 0.562776\n",
      "epoch 179; iter: 0; batch classifier loss: 0.330597; batch adversarial loss: 0.498030\n",
      "epoch 180; iter: 0; batch classifier loss: 0.474637; batch adversarial loss: 0.534396\n",
      "epoch 181; iter: 0; batch classifier loss: 0.355147; batch adversarial loss: 0.487762\n",
      "epoch 182; iter: 0; batch classifier loss: 0.336964; batch adversarial loss: 0.580681\n",
      "epoch 183; iter: 0; batch classifier loss: 0.396295; batch adversarial loss: 0.598826\n",
      "epoch 184; iter: 0; batch classifier loss: 0.375575; batch adversarial loss: 0.609311\n",
      "epoch 185; iter: 0; batch classifier loss: 0.301897; batch adversarial loss: 0.525769\n",
      "epoch 186; iter: 0; batch classifier loss: 0.339098; batch adversarial loss: 0.527573\n",
      "epoch 187; iter: 0; batch classifier loss: 0.381487; batch adversarial loss: 0.506229\n",
      "epoch 188; iter: 0; batch classifier loss: 0.383884; batch adversarial loss: 0.646040\n",
      "epoch 189; iter: 0; batch classifier loss: 0.383456; batch adversarial loss: 0.479981\n",
      "epoch 190; iter: 0; batch classifier loss: 0.356991; batch adversarial loss: 0.546270\n",
      "epoch 191; iter: 0; batch classifier loss: 0.307043; batch adversarial loss: 0.553660\n",
      "epoch 192; iter: 0; batch classifier loss: 0.321719; batch adversarial loss: 0.563344\n",
      "epoch 193; iter: 0; batch classifier loss: 0.375773; batch adversarial loss: 0.590598\n",
      "epoch 194; iter: 0; batch classifier loss: 0.305438; batch adversarial loss: 0.599043\n",
      "epoch 195; iter: 0; batch classifier loss: 0.362350; batch adversarial loss: 0.554037\n",
      "epoch 196; iter: 0; batch classifier loss: 0.392493; batch adversarial loss: 0.542165\n",
      "epoch 197; iter: 0; batch classifier loss: 0.304075; batch adversarial loss: 0.553429\n",
      "epoch 198; iter: 0; batch classifier loss: 0.367436; batch adversarial loss: 0.593206\n",
      "epoch 199; iter: 0; batch classifier loss: 0.362310; batch adversarial loss: 0.499608\n",
      "epoch 0; iter: 0; batch classifier loss: 0.752544; batch adversarial loss: 0.653675\n",
      "epoch 1; iter: 0; batch classifier loss: 0.633447; batch adversarial loss: 0.654118\n",
      "epoch 2; iter: 0; batch classifier loss: 0.598092; batch adversarial loss: 0.641447\n",
      "epoch 3; iter: 0; batch classifier loss: 0.513353; batch adversarial loss: 0.614530\n",
      "epoch 4; iter: 0; batch classifier loss: 0.575511; batch adversarial loss: 0.599463\n",
      "epoch 5; iter: 0; batch classifier loss: 0.537416; batch adversarial loss: 0.623155\n",
      "epoch 6; iter: 0; batch classifier loss: 0.506920; batch adversarial loss: 0.538989\n",
      "epoch 7; iter: 0; batch classifier loss: 0.605995; batch adversarial loss: 0.595075\n",
      "epoch 8; iter: 0; batch classifier loss: 0.522410; batch adversarial loss: 0.604736\n",
      "epoch 9; iter: 0; batch classifier loss: 0.581278; batch adversarial loss: 0.622308\n",
      "epoch 10; iter: 0; batch classifier loss: 0.578066; batch adversarial loss: 0.636973\n",
      "epoch 11; iter: 0; batch classifier loss: 0.481398; batch adversarial loss: 0.607205\n",
      "epoch 12; iter: 0; batch classifier loss: 0.528645; batch adversarial loss: 0.632031\n",
      "epoch 13; iter: 0; batch classifier loss: 0.535855; batch adversarial loss: 0.557880\n",
      "epoch 14; iter: 0; batch classifier loss: 0.617350; batch adversarial loss: 0.620857\n",
      "epoch 15; iter: 0; batch classifier loss: 0.465233; batch adversarial loss: 0.613515\n",
      "epoch 16; iter: 0; batch classifier loss: 0.515794; batch adversarial loss: 0.598317\n",
      "epoch 17; iter: 0; batch classifier loss: 0.585125; batch adversarial loss: 0.622628\n",
      "epoch 18; iter: 0; batch classifier loss: 0.538674; batch adversarial loss: 0.529810\n",
      "epoch 19; iter: 0; batch classifier loss: 0.497807; batch adversarial loss: 0.546320\n",
      "epoch 20; iter: 0; batch classifier loss: 0.511454; batch adversarial loss: 0.625199\n",
      "epoch 21; iter: 0; batch classifier loss: 0.603057; batch adversarial loss: 0.600196\n",
      "epoch 22; iter: 0; batch classifier loss: 0.480331; batch adversarial loss: 0.585279\n",
      "epoch 23; iter: 0; batch classifier loss: 0.506669; batch adversarial loss: 0.597884\n",
      "epoch 24; iter: 0; batch classifier loss: 0.498602; batch adversarial loss: 0.528740\n",
      "epoch 25; iter: 0; batch classifier loss: 0.489024; batch adversarial loss: 0.586737\n",
      "epoch 26; iter: 0; batch classifier loss: 0.498508; batch adversarial loss: 0.548105\n",
      "epoch 27; iter: 0; batch classifier loss: 0.563539; batch adversarial loss: 0.580205\n",
      "epoch 28; iter: 0; batch classifier loss: 0.481691; batch adversarial loss: 0.587771\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 29; iter: 0; batch classifier loss: 0.480491; batch adversarial loss: 0.538518\n",
      "epoch 30; iter: 0; batch classifier loss: 0.472960; batch adversarial loss: 0.578386\n",
      "epoch 31; iter: 0; batch classifier loss: 0.503461; batch adversarial loss: 0.528769\n",
      "epoch 32; iter: 0; batch classifier loss: 0.474355; batch adversarial loss: 0.454552\n",
      "epoch 33; iter: 0; batch classifier loss: 0.427607; batch adversarial loss: 0.511520\n",
      "epoch 34; iter: 0; batch classifier loss: 0.437086; batch adversarial loss: 0.511749\n",
      "epoch 35; iter: 0; batch classifier loss: 0.505615; batch adversarial loss: 0.554265\n",
      "epoch 36; iter: 0; batch classifier loss: 0.442533; batch adversarial loss: 0.527205\n",
      "epoch 37; iter: 0; batch classifier loss: 0.388074; batch adversarial loss: 0.673672\n",
      "epoch 38; iter: 0; batch classifier loss: 0.474043; batch adversarial loss: 0.510344\n",
      "epoch 39; iter: 0; batch classifier loss: 0.438133; batch adversarial loss: 0.605122\n",
      "epoch 40; iter: 0; batch classifier loss: 0.472166; batch adversarial loss: 0.474599\n",
      "epoch 41; iter: 0; batch classifier loss: 0.440028; batch adversarial loss: 0.578472\n",
      "epoch 42; iter: 0; batch classifier loss: 0.471144; batch adversarial loss: 0.606323\n",
      "epoch 43; iter: 0; batch classifier loss: 0.495314; batch adversarial loss: 0.533938\n",
      "epoch 44; iter: 0; batch classifier loss: 0.466409; batch adversarial loss: 0.525167\n",
      "epoch 45; iter: 0; batch classifier loss: 0.401694; batch adversarial loss: 0.588055\n",
      "epoch 46; iter: 0; batch classifier loss: 0.496950; batch adversarial loss: 0.580191\n",
      "epoch 47; iter: 0; batch classifier loss: 0.467052; batch adversarial loss: 0.554148\n",
      "epoch 48; iter: 0; batch classifier loss: 0.366889; batch adversarial loss: 0.572149\n",
      "epoch 49; iter: 0; batch classifier loss: 0.509285; batch adversarial loss: 0.534264\n",
      "epoch 50; iter: 0; batch classifier loss: 0.493527; batch adversarial loss: 0.544279\n",
      "epoch 51; iter: 0; batch classifier loss: 0.364208; batch adversarial loss: 0.534714\n",
      "epoch 52; iter: 0; batch classifier loss: 0.411992; batch adversarial loss: 0.528417\n",
      "epoch 53; iter: 0; batch classifier loss: 0.438315; batch adversarial loss: 0.509903\n",
      "epoch 54; iter: 0; batch classifier loss: 0.412857; batch adversarial loss: 0.581626\n",
      "epoch 55; iter: 0; batch classifier loss: 0.479952; batch adversarial loss: 0.563330\n",
      "epoch 56; iter: 0; batch classifier loss: 0.517553; batch adversarial loss: 0.554821\n",
      "epoch 57; iter: 0; batch classifier loss: 0.383825; batch adversarial loss: 0.508580\n",
      "epoch 58; iter: 0; batch classifier loss: 0.393950; batch adversarial loss: 0.580344\n",
      "epoch 59; iter: 0; batch classifier loss: 0.401781; batch adversarial loss: 0.500403\n",
      "epoch 60; iter: 0; batch classifier loss: 0.429892; batch adversarial loss: 0.536773\n",
      "epoch 61; iter: 0; batch classifier loss: 0.382737; batch adversarial loss: 0.561736\n",
      "epoch 62; iter: 0; batch classifier loss: 0.445234; batch adversarial loss: 0.518915\n",
      "epoch 63; iter: 0; batch classifier loss: 0.416850; batch adversarial loss: 0.526398\n",
      "epoch 64; iter: 0; batch classifier loss: 0.386430; batch adversarial loss: 0.605119\n",
      "epoch 65; iter: 0; batch classifier loss: 0.355174; batch adversarial loss: 0.484223\n",
      "epoch 66; iter: 0; batch classifier loss: 0.506418; batch adversarial loss: 0.589935\n",
      "epoch 67; iter: 0; batch classifier loss: 0.466492; batch adversarial loss: 0.527336\n",
      "epoch 68; iter: 0; batch classifier loss: 0.454942; batch adversarial loss: 0.606468\n",
      "epoch 69; iter: 0; batch classifier loss: 0.364086; batch adversarial loss: 0.517835\n",
      "epoch 70; iter: 0; batch classifier loss: 0.414169; batch adversarial loss: 0.498868\n",
      "epoch 71; iter: 0; batch classifier loss: 0.439239; batch adversarial loss: 0.526495\n",
      "epoch 72; iter: 0; batch classifier loss: 0.440701; batch adversarial loss: 0.562799\n",
      "epoch 73; iter: 0; batch classifier loss: 0.495813; batch adversarial loss: 0.615076\n",
      "epoch 74; iter: 0; batch classifier loss: 0.417228; batch adversarial loss: 0.482113\n",
      "epoch 75; iter: 0; batch classifier loss: 0.413522; batch adversarial loss: 0.579984\n",
      "epoch 76; iter: 0; batch classifier loss: 0.340328; batch adversarial loss: 0.437496\n",
      "epoch 77; iter: 0; batch classifier loss: 0.425571; batch adversarial loss: 0.571102\n",
      "epoch 78; iter: 0; batch classifier loss: 0.382627; batch adversarial loss: 0.598567\n",
      "epoch 79; iter: 0; batch classifier loss: 0.455093; batch adversarial loss: 0.571920\n",
      "epoch 80; iter: 0; batch classifier loss: 0.371472; batch adversarial loss: 0.562453\n",
      "epoch 81; iter: 0; batch classifier loss: 0.405552; batch adversarial loss: 0.589119\n",
      "epoch 82; iter: 0; batch classifier loss: 0.395681; batch adversarial loss: 0.554263\n",
      "epoch 83; iter: 0; batch classifier loss: 0.419100; batch adversarial loss: 0.534574\n",
      "epoch 84; iter: 0; batch classifier loss: 0.401079; batch adversarial loss: 0.535222\n",
      "epoch 85; iter: 0; batch classifier loss: 0.412011; batch adversarial loss: 0.491129\n",
      "epoch 86; iter: 0; batch classifier loss: 0.399657; batch adversarial loss: 0.687401\n",
      "epoch 87; iter: 0; batch classifier loss: 0.465175; batch adversarial loss: 0.597978\n",
      "epoch 88; iter: 0; batch classifier loss: 0.383024; batch adversarial loss: 0.545252\n",
      "epoch 89; iter: 0; batch classifier loss: 0.344037; batch adversarial loss: 0.526721\n",
      "epoch 90; iter: 0; batch classifier loss: 0.373734; batch adversarial loss: 0.597872\n",
      "epoch 91; iter: 0; batch classifier loss: 0.360346; batch adversarial loss: 0.553360\n",
      "epoch 92; iter: 0; batch classifier loss: 0.420825; batch adversarial loss: 0.570747\n",
      "epoch 93; iter: 0; batch classifier loss: 0.414661; batch adversarial loss: 0.589848\n",
      "epoch 94; iter: 0; batch classifier loss: 0.348126; batch adversarial loss: 0.491039\n",
      "epoch 95; iter: 0; batch classifier loss: 0.332668; batch adversarial loss: 0.526704\n",
      "epoch 96; iter: 0; batch classifier loss: 0.440352; batch adversarial loss: 0.544477\n",
      "epoch 97; iter: 0; batch classifier loss: 0.375333; batch adversarial loss: 0.481433\n",
      "epoch 98; iter: 0; batch classifier loss: 0.375060; batch adversarial loss: 0.661032\n",
      "epoch 99; iter: 0; batch classifier loss: 0.364139; batch adversarial loss: 0.562297\n",
      "epoch 100; iter: 0; batch classifier loss: 0.357592; batch adversarial loss: 0.544310\n",
      "epoch 101; iter: 0; batch classifier loss: 0.336398; batch adversarial loss: 0.526815\n",
      "epoch 102; iter: 0; batch classifier loss: 0.363641; batch adversarial loss: 0.553194\n",
      "epoch 103; iter: 0; batch classifier loss: 0.383645; batch adversarial loss: 0.624726\n",
      "epoch 104; iter: 0; batch classifier loss: 0.435545; batch adversarial loss: 0.598230\n",
      "epoch 105; iter: 0; batch classifier loss: 0.467161; batch adversarial loss: 0.527148\n",
      "epoch 106; iter: 0; batch classifier loss: 0.467096; batch adversarial loss: 0.615436\n",
      "epoch 107; iter: 0; batch classifier loss: 0.407239; batch adversarial loss: 0.509916\n",
      "epoch 108; iter: 0; batch classifier loss: 0.364543; batch adversarial loss: 0.545482\n",
      "epoch 109; iter: 0; batch classifier loss: 0.335626; batch adversarial loss: 0.492689\n",
      "epoch 110; iter: 0; batch classifier loss: 0.364163; batch adversarial loss: 0.553685\n",
      "epoch 111; iter: 0; batch classifier loss: 0.485039; batch adversarial loss: 0.597023\n",
      "epoch 112; iter: 0; batch classifier loss: 0.305047; batch adversarial loss: 0.527906\n",
      "epoch 113; iter: 0; batch classifier loss: 0.443544; batch adversarial loss: 0.614370\n",
      "epoch 114; iter: 0; batch classifier loss: 0.438423; batch adversarial loss: 0.518270\n",
      "epoch 115; iter: 0; batch classifier loss: 0.458275; batch adversarial loss: 0.588031\n",
      "epoch 116; iter: 0; batch classifier loss: 0.427651; batch adversarial loss: 0.535522\n",
      "epoch 117; iter: 0; batch classifier loss: 0.431332; batch adversarial loss: 0.643084\n",
      "epoch 118; iter: 0; batch classifier loss: 0.476040; batch adversarial loss: 0.553653\n",
      "epoch 119; iter: 0; batch classifier loss: 0.358638; batch adversarial loss: 0.499957\n",
      "epoch 120; iter: 0; batch classifier loss: 0.462304; batch adversarial loss: 0.570847\n",
      "epoch 121; iter: 0; batch classifier loss: 0.436550; batch adversarial loss: 0.553445\n",
      "epoch 122; iter: 0; batch classifier loss: 0.349906; batch adversarial loss: 0.562770\n",
      "epoch 123; iter: 0; batch classifier loss: 0.369479; batch adversarial loss: 0.509558\n",
      "epoch 124; iter: 0; batch classifier loss: 0.402256; batch adversarial loss: 0.544718\n",
      "epoch 125; iter: 0; batch classifier loss: 0.329034; batch adversarial loss: 0.492208\n",
      "epoch 126; iter: 0; batch classifier loss: 0.366217; batch adversarial loss: 0.517558\n",
      "epoch 127; iter: 0; batch classifier loss: 0.377130; batch adversarial loss: 0.623786\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 128; iter: 0; batch classifier loss: 0.352160; batch adversarial loss: 0.587957\n",
      "epoch 129; iter: 0; batch classifier loss: 0.522501; batch adversarial loss: 0.552719\n",
      "epoch 130; iter: 0; batch classifier loss: 0.421470; batch adversarial loss: 0.589931\n",
      "epoch 131; iter: 0; batch classifier loss: 0.366724; batch adversarial loss: 0.581248\n",
      "epoch 132; iter: 0; batch classifier loss: 0.360482; batch adversarial loss: 0.552885\n",
      "epoch 133; iter: 0; batch classifier loss: 0.387596; batch adversarial loss: 0.472930\n",
      "epoch 134; iter: 0; batch classifier loss: 0.454120; batch adversarial loss: 0.553886\n",
      "epoch 135; iter: 0; batch classifier loss: 0.432518; batch adversarial loss: 0.571822\n",
      "epoch 136; iter: 0; batch classifier loss: 0.422838; batch adversarial loss: 0.544864\n",
      "epoch 137; iter: 0; batch classifier loss: 0.368428; batch adversarial loss: 0.553334\n",
      "epoch 138; iter: 0; batch classifier loss: 0.410115; batch adversarial loss: 0.481918\n",
      "epoch 139; iter: 0; batch classifier loss: 0.401300; batch adversarial loss: 0.508972\n",
      "epoch 140; iter: 0; batch classifier loss: 0.329457; batch adversarial loss: 0.597771\n",
      "epoch 141; iter: 0; batch classifier loss: 0.380646; batch adversarial loss: 0.562659\n",
      "epoch 142; iter: 0; batch classifier loss: 0.365062; batch adversarial loss: 0.509185\n",
      "epoch 143; iter: 0; batch classifier loss: 0.323947; batch adversarial loss: 0.598408\n",
      "epoch 144; iter: 0; batch classifier loss: 0.448474; batch adversarial loss: 0.553815\n",
      "epoch 145; iter: 0; batch classifier loss: 0.332290; batch adversarial loss: 0.526759\n",
      "epoch 146; iter: 0; batch classifier loss: 0.366475; batch adversarial loss: 0.508572\n",
      "epoch 147; iter: 0; batch classifier loss: 0.348787; batch adversarial loss: 0.571764\n",
      "epoch 148; iter: 0; batch classifier loss: 0.332470; batch adversarial loss: 0.491326\n",
      "epoch 149; iter: 0; batch classifier loss: 0.345168; batch adversarial loss: 0.580781\n",
      "epoch 150; iter: 0; batch classifier loss: 0.391708; batch adversarial loss: 0.500246\n",
      "epoch 151; iter: 0; batch classifier loss: 0.330692; batch adversarial loss: 0.526414\n",
      "epoch 152; iter: 0; batch classifier loss: 0.327315; batch adversarial loss: 0.580263\n",
      "epoch 153; iter: 0; batch classifier loss: 0.370604; batch adversarial loss: 0.589132\n",
      "epoch 154; iter: 0; batch classifier loss: 0.429727; batch adversarial loss: 0.579887\n",
      "epoch 155; iter: 0; batch classifier loss: 0.301080; batch adversarial loss: 0.491942\n",
      "epoch 156; iter: 0; batch classifier loss: 0.354100; batch adversarial loss: 0.544871\n",
      "epoch 157; iter: 0; batch classifier loss: 0.384914; batch adversarial loss: 0.526655\n",
      "epoch 158; iter: 0; batch classifier loss: 0.372588; batch adversarial loss: 0.555260\n",
      "epoch 159; iter: 0; batch classifier loss: 0.390682; batch adversarial loss: 0.517210\n",
      "epoch 160; iter: 0; batch classifier loss: 0.474503; batch adversarial loss: 0.598159\n",
      "epoch 161; iter: 0; batch classifier loss: 0.433681; batch adversarial loss: 0.562723\n",
      "epoch 162; iter: 0; batch classifier loss: 0.348955; batch adversarial loss: 0.571543\n",
      "epoch 163; iter: 0; batch classifier loss: 0.389763; batch adversarial loss: 0.526515\n",
      "epoch 164; iter: 0; batch classifier loss: 0.316564; batch adversarial loss: 0.499388\n",
      "epoch 165; iter: 0; batch classifier loss: 0.444497; batch adversarial loss: 0.562420\n",
      "epoch 166; iter: 0; batch classifier loss: 0.424498; batch adversarial loss: 0.554440\n",
      "epoch 167; iter: 0; batch classifier loss: 0.437676; batch adversarial loss: 0.579934\n",
      "epoch 168; iter: 0; batch classifier loss: 0.369103; batch adversarial loss: 0.625603\n",
      "epoch 169; iter: 0; batch classifier loss: 0.392775; batch adversarial loss: 0.535423\n",
      "epoch 170; iter: 0; batch classifier loss: 0.306379; batch adversarial loss: 0.455445\n",
      "epoch 171; iter: 0; batch classifier loss: 0.338722; batch adversarial loss: 0.500808\n",
      "epoch 172; iter: 0; batch classifier loss: 0.398498; batch adversarial loss: 0.553038\n",
      "epoch 173; iter: 0; batch classifier loss: 0.388547; batch adversarial loss: 0.579764\n",
      "epoch 174; iter: 0; batch classifier loss: 0.442312; batch adversarial loss: 0.596796\n",
      "epoch 175; iter: 0; batch classifier loss: 0.318208; batch adversarial loss: 0.562437\n",
      "epoch 176; iter: 0; batch classifier loss: 0.275172; batch adversarial loss: 0.577881\n",
      "epoch 177; iter: 0; batch classifier loss: 0.421969; batch adversarial loss: 0.526949\n",
      "epoch 178; iter: 0; batch classifier loss: 0.350016; batch adversarial loss: 0.525246\n",
      "epoch 179; iter: 0; batch classifier loss: 0.383412; batch adversarial loss: 0.528522\n",
      "epoch 180; iter: 0; batch classifier loss: 0.451210; batch adversarial loss: 0.553558\n",
      "epoch 181; iter: 0; batch classifier loss: 0.340541; batch adversarial loss: 0.509147\n",
      "epoch 182; iter: 0; batch classifier loss: 0.427372; batch adversarial loss: 0.533589\n",
      "epoch 183; iter: 0; batch classifier loss: 0.396866; batch adversarial loss: 0.464795\n",
      "epoch 184; iter: 0; batch classifier loss: 0.317095; batch adversarial loss: 0.589482\n",
      "epoch 185; iter: 0; batch classifier loss: 0.280268; batch adversarial loss: 0.553381\n",
      "epoch 186; iter: 0; batch classifier loss: 0.359937; batch adversarial loss: 0.554841\n",
      "epoch 187; iter: 0; batch classifier loss: 0.395891; batch adversarial loss: 0.563465\n",
      "epoch 188; iter: 0; batch classifier loss: 0.431559; batch adversarial loss: 0.481555\n",
      "epoch 189; iter: 0; batch classifier loss: 0.352283; batch adversarial loss: 0.562663\n",
      "epoch 190; iter: 0; batch classifier loss: 0.349663; batch adversarial loss: 0.517886\n",
      "epoch 191; iter: 0; batch classifier loss: 0.338014; batch adversarial loss: 0.544497\n",
      "epoch 192; iter: 0; batch classifier loss: 0.399408; batch adversarial loss: 0.535564\n",
      "epoch 193; iter: 0; batch classifier loss: 0.458914; batch adversarial loss: 0.544842\n",
      "epoch 194; iter: 0; batch classifier loss: 0.385971; batch adversarial loss: 0.625616\n",
      "epoch 195; iter: 0; batch classifier loss: 0.469416; batch adversarial loss: 0.517734\n",
      "epoch 196; iter: 0; batch classifier loss: 0.320187; batch adversarial loss: 0.661110\n",
      "epoch 197; iter: 0; batch classifier loss: 0.318841; batch adversarial loss: 0.571711\n",
      "epoch 198; iter: 0; batch classifier loss: 0.397434; batch adversarial loss: 0.553243\n",
      "epoch 199; iter: 0; batch classifier loss: 0.436778; batch adversarial loss: 0.544658\n",
      "epoch 0; iter: 0; batch classifier loss: 0.671429; batch adversarial loss: 0.734497\n",
      "epoch 1; iter: 0; batch classifier loss: 0.761010; batch adversarial loss: 0.767044\n",
      "epoch 2; iter: 0; batch classifier loss: 0.713413; batch adversarial loss: 0.702095\n",
      "epoch 3; iter: 0; batch classifier loss: 0.665642; batch adversarial loss: 0.670797\n",
      "epoch 4; iter: 0; batch classifier loss: 0.576101; batch adversarial loss: 0.612900\n",
      "epoch 5; iter: 0; batch classifier loss: 0.558385; batch adversarial loss: 0.622728\n",
      "epoch 6; iter: 0; batch classifier loss: 0.550125; batch adversarial loss: 0.588088\n",
      "epoch 7; iter: 0; batch classifier loss: 0.527936; batch adversarial loss: 0.611883\n",
      "epoch 8; iter: 0; batch classifier loss: 0.561414; batch adversarial loss: 0.606550\n",
      "epoch 9; iter: 0; batch classifier loss: 0.500639; batch adversarial loss: 0.616265\n",
      "epoch 10; iter: 0; batch classifier loss: 0.490791; batch adversarial loss: 0.636692\n",
      "epoch 11; iter: 0; batch classifier loss: 0.533335; batch adversarial loss: 0.539013\n",
      "epoch 12; iter: 0; batch classifier loss: 0.528735; batch adversarial loss: 0.538750\n",
      "epoch 13; iter: 0; batch classifier loss: 0.473019; batch adversarial loss: 0.563081\n",
      "epoch 14; iter: 0; batch classifier loss: 0.503887; batch adversarial loss: 0.551494\n",
      "epoch 15; iter: 0; batch classifier loss: 0.477830; batch adversarial loss: 0.530353\n",
      "epoch 16; iter: 0; batch classifier loss: 0.608777; batch adversarial loss: 0.556458\n",
      "epoch 17; iter: 0; batch classifier loss: 0.537676; batch adversarial loss: 0.518852\n",
      "epoch 18; iter: 0; batch classifier loss: 0.474023; batch adversarial loss: 0.587500\n",
      "epoch 19; iter: 0; batch classifier loss: 0.493865; batch adversarial loss: 0.579846\n",
      "epoch 20; iter: 0; batch classifier loss: 0.525576; batch adversarial loss: 0.493499\n",
      "epoch 21; iter: 0; batch classifier loss: 0.608832; batch adversarial loss: 0.585543\n",
      "epoch 22; iter: 0; batch classifier loss: 0.462969; batch adversarial loss: 0.667926\n",
      "epoch 23; iter: 0; batch classifier loss: 0.569712; batch adversarial loss: 0.602746\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 24; iter: 0; batch classifier loss: 0.408017; batch adversarial loss: 0.636940\n",
      "epoch 25; iter: 0; batch classifier loss: 0.505227; batch adversarial loss: 0.486112\n",
      "epoch 26; iter: 0; batch classifier loss: 0.419316; batch adversarial loss: 0.547390\n",
      "epoch 27; iter: 0; batch classifier loss: 0.453227; batch adversarial loss: 0.606333\n",
      "epoch 28; iter: 0; batch classifier loss: 0.459405; batch adversarial loss: 0.527342\n",
      "epoch 29; iter: 0; batch classifier loss: 0.436489; batch adversarial loss: 0.599760\n",
      "epoch 30; iter: 0; batch classifier loss: 0.465140; batch adversarial loss: 0.562632\n",
      "epoch 31; iter: 0; batch classifier loss: 0.410830; batch adversarial loss: 0.465342\n",
      "epoch 32; iter: 0; batch classifier loss: 0.499321; batch adversarial loss: 0.555468\n",
      "epoch 33; iter: 0; batch classifier loss: 0.429271; batch adversarial loss: 0.625094\n",
      "epoch 34; iter: 0; batch classifier loss: 0.470906; batch adversarial loss: 0.570714\n",
      "epoch 35; iter: 0; batch classifier loss: 0.523708; batch adversarial loss: 0.589158\n",
      "epoch 36; iter: 0; batch classifier loss: 0.491843; batch adversarial loss: 0.508816\n",
      "epoch 37; iter: 0; batch classifier loss: 0.509637; batch adversarial loss: 0.583786\n",
      "epoch 38; iter: 0; batch classifier loss: 0.390052; batch adversarial loss: 0.534867\n",
      "epoch 39; iter: 0; batch classifier loss: 0.450436; batch adversarial loss: 0.533913\n",
      "epoch 40; iter: 0; batch classifier loss: 0.512213; batch adversarial loss: 0.567104\n",
      "epoch 41; iter: 0; batch classifier loss: 0.406100; batch adversarial loss: 0.529044\n",
      "epoch 42; iter: 0; batch classifier loss: 0.453718; batch adversarial loss: 0.543264\n",
      "epoch 43; iter: 0; batch classifier loss: 0.453173; batch adversarial loss: 0.516752\n",
      "epoch 44; iter: 0; batch classifier loss: 0.454048; batch adversarial loss: 0.562645\n",
      "epoch 45; iter: 0; batch classifier loss: 0.367499; batch adversarial loss: 0.639902\n",
      "epoch 46; iter: 0; batch classifier loss: 0.454742; batch adversarial loss: 0.552508\n",
      "epoch 47; iter: 0; batch classifier loss: 0.449445; batch adversarial loss: 0.567860\n",
      "epoch 48; iter: 0; batch classifier loss: 0.376531; batch adversarial loss: 0.531872\n",
      "epoch 49; iter: 0; batch classifier loss: 0.467467; batch adversarial loss: 0.626989\n",
      "epoch 50; iter: 0; batch classifier loss: 0.482904; batch adversarial loss: 0.536867\n",
      "epoch 51; iter: 0; batch classifier loss: 0.440381; batch adversarial loss: 0.570653\n",
      "epoch 52; iter: 0; batch classifier loss: 0.478304; batch adversarial loss: 0.493677\n",
      "epoch 53; iter: 0; batch classifier loss: 0.458549; batch adversarial loss: 0.527826\n",
      "epoch 54; iter: 0; batch classifier loss: 0.460000; batch adversarial loss: 0.640849\n",
      "epoch 55; iter: 0; batch classifier loss: 0.434433; batch adversarial loss: 0.509877\n",
      "epoch 56; iter: 0; batch classifier loss: 0.351110; batch adversarial loss: 0.536520\n",
      "epoch 57; iter: 0; batch classifier loss: 0.435177; batch adversarial loss: 0.527249\n",
      "epoch 58; iter: 0; batch classifier loss: 0.399688; batch adversarial loss: 0.571283\n",
      "epoch 59; iter: 0; batch classifier loss: 0.419918; batch adversarial loss: 0.571743\n",
      "epoch 60; iter: 0; batch classifier loss: 0.388393; batch adversarial loss: 0.624655\n",
      "epoch 61; iter: 0; batch classifier loss: 0.395742; batch adversarial loss: 0.526671\n",
      "epoch 62; iter: 0; batch classifier loss: 0.361359; batch adversarial loss: 0.570809\n",
      "epoch 63; iter: 0; batch classifier loss: 0.371974; batch adversarial loss: 0.544766\n",
      "epoch 64; iter: 0; batch classifier loss: 0.458295; batch adversarial loss: 0.508707\n",
      "epoch 65; iter: 0; batch classifier loss: 0.331546; batch adversarial loss: 0.571468\n",
      "epoch 66; iter: 0; batch classifier loss: 0.439961; batch adversarial loss: 0.518146\n",
      "epoch 67; iter: 0; batch classifier loss: 0.412855; batch adversarial loss: 0.606349\n",
      "epoch 68; iter: 0; batch classifier loss: 0.440557; batch adversarial loss: 0.588876\n",
      "epoch 69; iter: 0; batch classifier loss: 0.516175; batch adversarial loss: 0.518483\n",
      "epoch 70; iter: 0; batch classifier loss: 0.378918; batch adversarial loss: 0.518091\n",
      "epoch 71; iter: 0; batch classifier loss: 0.474016; batch adversarial loss: 0.615739\n",
      "epoch 72; iter: 0; batch classifier loss: 0.384370; batch adversarial loss: 0.526810\n",
      "epoch 73; iter: 0; batch classifier loss: 0.487576; batch adversarial loss: 0.553893\n",
      "epoch 74; iter: 0; batch classifier loss: 0.387091; batch adversarial loss: 0.517936\n",
      "epoch 75; iter: 0; batch classifier loss: 0.458529; batch adversarial loss: 0.553589\n",
      "epoch 76; iter: 0; batch classifier loss: 0.410622; batch adversarial loss: 0.517726\n",
      "epoch 77; iter: 0; batch classifier loss: 0.392098; batch adversarial loss: 0.571240\n",
      "epoch 78; iter: 0; batch classifier loss: 0.396211; batch adversarial loss: 0.562481\n",
      "epoch 79; iter: 0; batch classifier loss: 0.339686; batch adversarial loss: 0.544760\n",
      "epoch 80; iter: 0; batch classifier loss: 0.438620; batch adversarial loss: 0.589191\n",
      "epoch 81; iter: 0; batch classifier loss: 0.462883; batch adversarial loss: 0.509135\n",
      "epoch 82; iter: 0; batch classifier loss: 0.389599; batch adversarial loss: 0.553904\n",
      "epoch 83; iter: 0; batch classifier loss: 0.298733; batch adversarial loss: 0.482003\n",
      "epoch 84; iter: 0; batch classifier loss: 0.368370; batch adversarial loss: 0.605782\n",
      "epoch 85; iter: 0; batch classifier loss: 0.446950; batch adversarial loss: 0.569084\n",
      "epoch 86; iter: 0; batch classifier loss: 0.405240; batch adversarial loss: 0.551509\n",
      "epoch 87; iter: 0; batch classifier loss: 0.334889; batch adversarial loss: 0.568607\n",
      "epoch 88; iter: 0; batch classifier loss: 0.373267; batch adversarial loss: 0.475222\n",
      "epoch 89; iter: 0; batch classifier loss: 0.374515; batch adversarial loss: 0.537045\n",
      "epoch 90; iter: 0; batch classifier loss: 0.407879; batch adversarial loss: 0.564023\n",
      "epoch 91; iter: 0; batch classifier loss: 0.388869; batch adversarial loss: 0.628338\n",
      "epoch 92; iter: 0; batch classifier loss: 0.421431; batch adversarial loss: 0.617044\n",
      "epoch 93; iter: 0; batch classifier loss: 0.364731; batch adversarial loss: 0.491115\n",
      "epoch 94; iter: 0; batch classifier loss: 0.336304; batch adversarial loss: 0.664165\n",
      "epoch 95; iter: 0; batch classifier loss: 0.378302; batch adversarial loss: 0.587708\n",
      "epoch 96; iter: 0; batch classifier loss: 0.363609; batch adversarial loss: 0.562903\n",
      "epoch 97; iter: 0; batch classifier loss: 0.422145; batch adversarial loss: 0.589424\n",
      "epoch 98; iter: 0; batch classifier loss: 0.432936; batch adversarial loss: 0.580551\n",
      "epoch 99; iter: 0; batch classifier loss: 0.388762; batch adversarial loss: 0.535823\n",
      "epoch 100; iter: 0; batch classifier loss: 0.317068; batch adversarial loss: 0.599415\n",
      "epoch 101; iter: 0; batch classifier loss: 0.358526; batch adversarial loss: 0.508214\n",
      "epoch 102; iter: 0; batch classifier loss: 0.350253; batch adversarial loss: 0.481741\n",
      "epoch 103; iter: 0; batch classifier loss: 0.420714; batch adversarial loss: 0.572480\n",
      "epoch 104; iter: 0; batch classifier loss: 0.402086; batch adversarial loss: 0.518120\n",
      "epoch 105; iter: 0; batch classifier loss: 0.407730; batch adversarial loss: 0.508381\n",
      "epoch 106; iter: 0; batch classifier loss: 0.425898; batch adversarial loss: 0.481853\n",
      "epoch 107; iter: 0; batch classifier loss: 0.372297; batch adversarial loss: 0.589201\n",
      "epoch 108; iter: 0; batch classifier loss: 0.469519; batch adversarial loss: 0.535184\n",
      "epoch 109; iter: 0; batch classifier loss: 0.364274; batch adversarial loss: 0.607039\n",
      "epoch 110; iter: 0; batch classifier loss: 0.365458; batch adversarial loss: 0.535662\n",
      "epoch 111; iter: 0; batch classifier loss: 0.386731; batch adversarial loss: 0.535159\n",
      "epoch 112; iter: 0; batch classifier loss: 0.363742; batch adversarial loss: 0.553227\n",
      "epoch 113; iter: 0; batch classifier loss: 0.383996; batch adversarial loss: 0.517481\n",
      "epoch 114; iter: 0; batch classifier loss: 0.298283; batch adversarial loss: 0.508979\n",
      "epoch 115; iter: 0; batch classifier loss: 0.399407; batch adversarial loss: 0.554318\n",
      "epoch 116; iter: 0; batch classifier loss: 0.397285; batch adversarial loss: 0.526289\n",
      "epoch 117; iter: 0; batch classifier loss: 0.359297; batch adversarial loss: 0.526180\n",
      "epoch 118; iter: 0; batch classifier loss: 0.377107; batch adversarial loss: 0.615625\n",
      "epoch 119; iter: 0; batch classifier loss: 0.311502; batch adversarial loss: 0.500206\n",
      "epoch 120; iter: 0; batch classifier loss: 0.349814; batch adversarial loss: 0.624414\n",
      "epoch 121; iter: 0; batch classifier loss: 0.380608; batch adversarial loss: 0.536044\n",
      "epoch 122; iter: 0; batch classifier loss: 0.313961; batch adversarial loss: 0.650439\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 123; iter: 0; batch classifier loss: 0.382299; batch adversarial loss: 0.499195\n",
      "epoch 124; iter: 0; batch classifier loss: 0.350554; batch adversarial loss: 0.542826\n",
      "epoch 125; iter: 0; batch classifier loss: 0.380236; batch adversarial loss: 0.569854\n",
      "epoch 126; iter: 0; batch classifier loss: 0.354255; batch adversarial loss: 0.570788\n",
      "epoch 127; iter: 0; batch classifier loss: 0.406373; batch adversarial loss: 0.500222\n",
      "epoch 128; iter: 0; batch classifier loss: 0.347856; batch adversarial loss: 0.546378\n",
      "epoch 129; iter: 0; batch classifier loss: 0.428838; batch adversarial loss: 0.580845\n",
      "epoch 130; iter: 0; batch classifier loss: 0.404708; batch adversarial loss: 0.526862\n",
      "epoch 131; iter: 0; batch classifier loss: 0.322109; batch adversarial loss: 0.607655\n",
      "epoch 132; iter: 0; batch classifier loss: 0.412259; batch adversarial loss: 0.590458\n",
      "epoch 133; iter: 0; batch classifier loss: 0.350633; batch adversarial loss: 0.535255\n",
      "epoch 134; iter: 0; batch classifier loss: 0.352831; batch adversarial loss: 0.499165\n",
      "epoch 135; iter: 0; batch classifier loss: 0.329156; batch adversarial loss: 0.552284\n",
      "epoch 136; iter: 0; batch classifier loss: 0.387372; batch adversarial loss: 0.598657\n",
      "epoch 137; iter: 0; batch classifier loss: 0.367239; batch adversarial loss: 0.519005\n",
      "epoch 138; iter: 0; batch classifier loss: 0.450494; batch adversarial loss: 0.536659\n",
      "epoch 139; iter: 0; batch classifier loss: 0.405671; batch adversarial loss: 0.551486\n",
      "epoch 140; iter: 0; batch classifier loss: 0.407942; batch adversarial loss: 0.572919\n",
      "epoch 141; iter: 0; batch classifier loss: 0.392645; batch adversarial loss: 0.579486\n",
      "epoch 142; iter: 0; batch classifier loss: 0.334367; batch adversarial loss: 0.500731\n",
      "epoch 143; iter: 0; batch classifier loss: 0.356846; batch adversarial loss: 0.546604\n",
      "epoch 144; iter: 0; batch classifier loss: 0.373137; batch adversarial loss: 0.569600\n",
      "epoch 145; iter: 0; batch classifier loss: 0.371816; batch adversarial loss: 0.689097\n",
      "epoch 146; iter: 0; batch classifier loss: 0.299518; batch adversarial loss: 0.545127\n",
      "epoch 147; iter: 0; batch classifier loss: 0.371827; batch adversarial loss: 0.534963\n",
      "epoch 148; iter: 0; batch classifier loss: 0.397044; batch adversarial loss: 0.669756\n",
      "epoch 149; iter: 0; batch classifier loss: 0.313742; batch adversarial loss: 0.544005\n",
      "epoch 150; iter: 0; batch classifier loss: 0.323200; batch adversarial loss: 0.571098\n",
      "epoch 151; iter: 0; batch classifier loss: 0.352817; batch adversarial loss: 0.571525\n",
      "epoch 152; iter: 0; batch classifier loss: 0.396605; batch adversarial loss: 0.526533\n",
      "epoch 153; iter: 0; batch classifier loss: 0.358389; batch adversarial loss: 0.543959\n",
      "epoch 154; iter: 0; batch classifier loss: 0.370722; batch adversarial loss: 0.617107\n",
      "epoch 155; iter: 0; batch classifier loss: 0.376555; batch adversarial loss: 0.544011\n",
      "epoch 156; iter: 0; batch classifier loss: 0.416005; batch adversarial loss: 0.579885\n",
      "epoch 157; iter: 0; batch classifier loss: 0.293542; batch adversarial loss: 0.561923\n",
      "epoch 158; iter: 0; batch classifier loss: 0.301061; batch adversarial loss: 0.563234\n",
      "epoch 159; iter: 0; batch classifier loss: 0.277151; batch adversarial loss: 0.572158\n",
      "epoch 160; iter: 0; batch classifier loss: 0.363155; batch adversarial loss: 0.580538\n",
      "epoch 161; iter: 0; batch classifier loss: 0.424617; batch adversarial loss: 0.553765\n",
      "epoch 162; iter: 0; batch classifier loss: 0.335213; batch adversarial loss: 0.597909\n",
      "epoch 163; iter: 0; batch classifier loss: 0.319240; batch adversarial loss: 0.571559\n",
      "epoch 164; iter: 0; batch classifier loss: 0.328560; batch adversarial loss: 0.562493\n",
      "epoch 165; iter: 0; batch classifier loss: 0.389637; batch adversarial loss: 0.570762\n",
      "epoch 166; iter: 0; batch classifier loss: 0.376272; batch adversarial loss: 0.544479\n",
      "epoch 167; iter: 0; batch classifier loss: 0.328816; batch adversarial loss: 0.580518\n",
      "epoch 168; iter: 0; batch classifier loss: 0.322977; batch adversarial loss: 0.580295\n",
      "epoch 169; iter: 0; batch classifier loss: 0.360934; batch adversarial loss: 0.562420\n",
      "epoch 170; iter: 0; batch classifier loss: 0.337264; batch adversarial loss: 0.607190\n",
      "epoch 171; iter: 0; batch classifier loss: 0.417859; batch adversarial loss: 0.615061\n",
      "epoch 172; iter: 0; batch classifier loss: 0.373395; batch adversarial loss: 0.580319\n",
      "epoch 173; iter: 0; batch classifier loss: 0.364997; batch adversarial loss: 0.563207\n",
      "epoch 174; iter: 0; batch classifier loss: 0.371936; batch adversarial loss: 0.518192\n",
      "epoch 175; iter: 0; batch classifier loss: 0.387836; batch adversarial loss: 0.535953\n",
      "epoch 176; iter: 0; batch classifier loss: 0.386229; batch adversarial loss: 0.545144\n",
      "epoch 177; iter: 0; batch classifier loss: 0.380919; batch adversarial loss: 0.571108\n",
      "epoch 178; iter: 0; batch classifier loss: 0.352655; batch adversarial loss: 0.571140\n",
      "epoch 179; iter: 0; batch classifier loss: 0.326122; batch adversarial loss: 0.616170\n",
      "epoch 180; iter: 0; batch classifier loss: 0.329264; batch adversarial loss: 0.563516\n",
      "epoch 181; iter: 0; batch classifier loss: 0.411976; batch adversarial loss: 0.526716\n",
      "epoch 182; iter: 0; batch classifier loss: 0.451524; batch adversarial loss: 0.463682\n",
      "epoch 183; iter: 0; batch classifier loss: 0.325023; batch adversarial loss: 0.544477\n",
      "epoch 184; iter: 0; batch classifier loss: 0.435966; batch adversarial loss: 0.580656\n",
      "epoch 185; iter: 0; batch classifier loss: 0.367110; batch adversarial loss: 0.526638\n",
      "epoch 186; iter: 0; batch classifier loss: 0.337863; batch adversarial loss: 0.518086\n",
      "epoch 187; iter: 0; batch classifier loss: 0.361120; batch adversarial loss: 0.534697\n",
      "epoch 188; iter: 0; batch classifier loss: 0.365210; batch adversarial loss: 0.517418\n",
      "epoch 189; iter: 0; batch classifier loss: 0.406179; batch adversarial loss: 0.562324\n",
      "epoch 190; iter: 0; batch classifier loss: 0.364122; batch adversarial loss: 0.598664\n",
      "epoch 191; iter: 0; batch classifier loss: 0.366668; batch adversarial loss: 0.517694\n",
      "epoch 192; iter: 0; batch classifier loss: 0.340512; batch adversarial loss: 0.571785\n",
      "epoch 193; iter: 0; batch classifier loss: 0.348092; batch adversarial loss: 0.571785\n",
      "epoch 194; iter: 0; batch classifier loss: 0.364683; batch adversarial loss: 0.596580\n",
      "epoch 195; iter: 0; batch classifier loss: 0.329963; batch adversarial loss: 0.553124\n",
      "epoch 196; iter: 0; batch classifier loss: 0.334471; batch adversarial loss: 0.598187\n",
      "epoch 197; iter: 0; batch classifier loss: 0.352075; batch adversarial loss: 0.544338\n",
      "epoch 198; iter: 0; batch classifier loss: 0.345527; batch adversarial loss: 0.543419\n",
      "epoch 199; iter: 0; batch classifier loss: 0.296025; batch adversarial loss: 0.571623\n",
      "epoch 0; iter: 0; batch classifier loss: 0.707431; batch adversarial loss: 0.701401\n",
      "epoch 1; iter: 0; batch classifier loss: 0.643491; batch adversarial loss: 0.681722\n",
      "epoch 2; iter: 0; batch classifier loss: 0.586155; batch adversarial loss: 0.648632\n",
      "epoch 3; iter: 0; batch classifier loss: 0.603768; batch adversarial loss: 0.642578\n",
      "epoch 4; iter: 0; batch classifier loss: 0.591436; batch adversarial loss: 0.615539\n",
      "epoch 5; iter: 0; batch classifier loss: 0.524814; batch adversarial loss: 0.620774\n",
      "epoch 6; iter: 0; batch classifier loss: 0.555119; batch adversarial loss: 0.579858\n",
      "epoch 7; iter: 0; batch classifier loss: 0.564109; batch adversarial loss: 0.622075\n",
      "epoch 8; iter: 0; batch classifier loss: 0.585390; batch adversarial loss: 0.606032\n",
      "epoch 9; iter: 0; batch classifier loss: 0.576062; batch adversarial loss: 0.586814\n",
      "epoch 10; iter: 0; batch classifier loss: 0.514806; batch adversarial loss: 0.593560\n",
      "epoch 11; iter: 0; batch classifier loss: 0.490671; batch adversarial loss: 0.606639\n",
      "epoch 12; iter: 0; batch classifier loss: 0.507953; batch adversarial loss: 0.504107\n",
      "epoch 13; iter: 0; batch classifier loss: 0.575194; batch adversarial loss: 0.634019\n",
      "epoch 14; iter: 0; batch classifier loss: 0.440726; batch adversarial loss: 0.507999\n",
      "epoch 15; iter: 0; batch classifier loss: 0.573908; batch adversarial loss: 0.605617\n",
      "epoch 16; iter: 0; batch classifier loss: 0.527942; batch adversarial loss: 0.637967\n",
      "epoch 17; iter: 0; batch classifier loss: 0.589007; batch adversarial loss: 0.521725\n",
      "epoch 18; iter: 0; batch classifier loss: 0.476548; batch adversarial loss: 0.563257\n",
      "epoch 19; iter: 0; batch classifier loss: 0.439789; batch adversarial loss: 0.543559\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20; iter: 0; batch classifier loss: 0.447612; batch adversarial loss: 0.493830\n",
      "epoch 21; iter: 0; batch classifier loss: 0.492392; batch adversarial loss: 0.568388\n",
      "epoch 22; iter: 0; batch classifier loss: 0.486290; batch adversarial loss: 0.508615\n",
      "epoch 23; iter: 0; batch classifier loss: 0.411408; batch adversarial loss: 0.614720\n",
      "epoch 24; iter: 0; batch classifier loss: 0.468633; batch adversarial loss: 0.565721\n",
      "epoch 25; iter: 0; batch classifier loss: 0.454833; batch adversarial loss: 0.542569\n",
      "epoch 26; iter: 0; batch classifier loss: 0.397902; batch adversarial loss: 0.590740\n",
      "epoch 27; iter: 0; batch classifier loss: 0.472673; batch adversarial loss: 0.549104\n",
      "epoch 28; iter: 0; batch classifier loss: 0.376687; batch adversarial loss: 0.539620\n",
      "epoch 29; iter: 0; batch classifier loss: 0.434693; batch adversarial loss: 0.513097\n",
      "epoch 30; iter: 0; batch classifier loss: 0.488073; batch adversarial loss: 0.527824\n",
      "epoch 31; iter: 0; batch classifier loss: 0.450482; batch adversarial loss: 0.586731\n",
      "epoch 32; iter: 0; batch classifier loss: 0.426897; batch adversarial loss: 0.598654\n",
      "epoch 33; iter: 0; batch classifier loss: 0.377974; batch adversarial loss: 0.572049\n",
      "epoch 34; iter: 0; batch classifier loss: 0.421960; batch adversarial loss: 0.539297\n",
      "epoch 35; iter: 0; batch classifier loss: 0.459879; batch adversarial loss: 0.614997\n",
      "epoch 36; iter: 0; batch classifier loss: 0.436105; batch adversarial loss: 0.553514\n",
      "epoch 37; iter: 0; batch classifier loss: 0.392660; batch adversarial loss: 0.553187\n",
      "epoch 38; iter: 0; batch classifier loss: 0.523031; batch adversarial loss: 0.509216\n",
      "epoch 39; iter: 0; batch classifier loss: 0.465187; batch adversarial loss: 0.642507\n",
      "epoch 40; iter: 0; batch classifier loss: 0.377626; batch adversarial loss: 0.605311\n",
      "epoch 41; iter: 0; batch classifier loss: 0.414099; batch adversarial loss: 0.598328\n",
      "epoch 42; iter: 0; batch classifier loss: 0.469798; batch adversarial loss: 0.535882\n",
      "epoch 43; iter: 0; batch classifier loss: 0.468657; batch adversarial loss: 0.553137\n",
      "epoch 44; iter: 0; batch classifier loss: 0.500807; batch adversarial loss: 0.582115\n",
      "epoch 45; iter: 0; batch classifier loss: 0.557773; batch adversarial loss: 0.591437\n",
      "epoch 46; iter: 0; batch classifier loss: 0.455739; batch adversarial loss: 0.642779\n",
      "epoch 47; iter: 0; batch classifier loss: 0.392841; batch adversarial loss: 0.517980\n",
      "epoch 48; iter: 0; batch classifier loss: 0.449364; batch adversarial loss: 0.580377\n",
      "epoch 49; iter: 0; batch classifier loss: 0.519025; batch adversarial loss: 0.509540\n",
      "epoch 50; iter: 0; batch classifier loss: 0.486693; batch adversarial loss: 0.507656\n",
      "epoch 51; iter: 0; batch classifier loss: 0.350293; batch adversarial loss: 0.579024\n",
      "epoch 52; iter: 0; batch classifier loss: 0.392394; batch adversarial loss: 0.482699\n",
      "epoch 53; iter: 0; batch classifier loss: 0.430293; batch adversarial loss: 0.507043\n",
      "epoch 54; iter: 0; batch classifier loss: 0.408618; batch adversarial loss: 0.558468\n",
      "epoch 55; iter: 0; batch classifier loss: 0.372891; batch adversarial loss: 0.551137\n",
      "epoch 56; iter: 0; batch classifier loss: 0.422794; batch adversarial loss: 0.601129\n",
      "epoch 57; iter: 0; batch classifier loss: 0.403264; batch adversarial loss: 0.597648\n",
      "epoch 58; iter: 0; batch classifier loss: 0.421511; batch adversarial loss: 0.490017\n",
      "epoch 59; iter: 0; batch classifier loss: 0.494493; batch adversarial loss: 0.565165\n",
      "epoch 60; iter: 0; batch classifier loss: 0.409280; batch adversarial loss: 0.541751\n",
      "epoch 61; iter: 0; batch classifier loss: 0.489072; batch adversarial loss: 0.558955\n",
      "epoch 62; iter: 0; batch classifier loss: 0.462440; batch adversarial loss: 0.582755\n",
      "epoch 63; iter: 0; batch classifier loss: 0.500683; batch adversarial loss: 0.567437\n",
      "epoch 64; iter: 0; batch classifier loss: 0.498509; batch adversarial loss: 0.507835\n",
      "epoch 65; iter: 0; batch classifier loss: 0.466536; batch adversarial loss: 0.600967\n",
      "epoch 66; iter: 0; batch classifier loss: 0.461444; batch adversarial loss: 0.603186\n",
      "epoch 67; iter: 0; batch classifier loss: 0.463402; batch adversarial loss: 0.559161\n",
      "epoch 68; iter: 0; batch classifier loss: 0.425925; batch adversarial loss: 0.539308\n",
      "epoch 69; iter: 0; batch classifier loss: 0.485889; batch adversarial loss: 0.601188\n",
      "epoch 70; iter: 0; batch classifier loss: 0.459222; batch adversarial loss: 0.589334\n",
      "epoch 71; iter: 0; batch classifier loss: 0.412530; batch adversarial loss: 0.539288\n",
      "epoch 72; iter: 0; batch classifier loss: 0.455676; batch adversarial loss: 0.592295\n",
      "epoch 73; iter: 0; batch classifier loss: 0.383906; batch adversarial loss: 0.593699\n",
      "epoch 74; iter: 0; batch classifier loss: 0.503348; batch adversarial loss: 0.591705\n",
      "epoch 75; iter: 0; batch classifier loss: 0.335287; batch adversarial loss: 0.553307\n",
      "epoch 76; iter: 0; batch classifier loss: 0.351202; batch adversarial loss: 0.582090\n",
      "epoch 77; iter: 0; batch classifier loss: 0.388924; batch adversarial loss: 0.564248\n",
      "epoch 78; iter: 0; batch classifier loss: 0.410317; batch adversarial loss: 0.645781\n",
      "epoch 79; iter: 0; batch classifier loss: 0.379310; batch adversarial loss: 0.480602\n",
      "epoch 80; iter: 0; batch classifier loss: 0.426171; batch adversarial loss: 0.532939\n",
      "epoch 81; iter: 0; batch classifier loss: 0.351697; batch adversarial loss: 0.576907\n",
      "epoch 82; iter: 0; batch classifier loss: 0.411563; batch adversarial loss: 0.499237\n",
      "epoch 83; iter: 0; batch classifier loss: 0.414159; batch adversarial loss: 0.608339\n",
      "epoch 84; iter: 0; batch classifier loss: 0.445617; batch adversarial loss: 0.488380\n",
      "epoch 85; iter: 0; batch classifier loss: 0.417213; batch adversarial loss: 0.507490\n",
      "epoch 86; iter: 0; batch classifier loss: 0.304481; batch adversarial loss: 0.541006\n",
      "epoch 87; iter: 0; batch classifier loss: 0.452409; batch adversarial loss: 0.483195\n",
      "epoch 88; iter: 0; batch classifier loss: 0.413201; batch adversarial loss: 0.485095\n",
      "epoch 89; iter: 0; batch classifier loss: 0.477545; batch adversarial loss: 0.563607\n",
      "epoch 90; iter: 0; batch classifier loss: 0.409545; batch adversarial loss: 0.520236\n",
      "epoch 91; iter: 0; batch classifier loss: 0.403959; batch adversarial loss: 0.453993\n",
      "epoch 92; iter: 0; batch classifier loss: 0.410071; batch adversarial loss: 0.478765\n",
      "epoch 93; iter: 0; batch classifier loss: 0.421298; batch adversarial loss: 0.531843\n",
      "epoch 94; iter: 0; batch classifier loss: 0.452704; batch adversarial loss: 0.458402\n",
      "epoch 95; iter: 0; batch classifier loss: 0.446315; batch adversarial loss: 0.424927\n",
      "epoch 96; iter: 0; batch classifier loss: 0.359650; batch adversarial loss: 0.481282\n",
      "epoch 97; iter: 0; batch classifier loss: 0.386503; batch adversarial loss: 0.496506\n",
      "epoch 98; iter: 0; batch classifier loss: 0.407925; batch adversarial loss: 0.580118\n",
      "epoch 99; iter: 0; batch classifier loss: 0.367552; batch adversarial loss: 0.647073\n",
      "epoch 100; iter: 0; batch classifier loss: 0.434489; batch adversarial loss: 0.552245\n",
      "epoch 101; iter: 0; batch classifier loss: 0.334623; batch adversarial loss: 0.606413\n",
      "epoch 102; iter: 0; batch classifier loss: 0.411117; batch adversarial loss: 0.563078\n",
      "epoch 103; iter: 0; batch classifier loss: 0.355065; batch adversarial loss: 0.536346\n",
      "epoch 104; iter: 0; batch classifier loss: 0.366365; batch adversarial loss: 0.601628\n",
      "epoch 105; iter: 0; batch classifier loss: 0.344043; batch adversarial loss: 0.613497\n",
      "epoch 106; iter: 0; batch classifier loss: 0.405320; batch adversarial loss: 0.484876\n",
      "epoch 107; iter: 0; batch classifier loss: 0.328729; batch adversarial loss: 0.531408\n",
      "epoch 108; iter: 0; batch classifier loss: 0.360990; batch adversarial loss: 0.559027\n",
      "epoch 109; iter: 0; batch classifier loss: 0.430430; batch adversarial loss: 0.479796\n",
      "epoch 110; iter: 0; batch classifier loss: 0.384443; batch adversarial loss: 0.492308\n",
      "epoch 111; iter: 0; batch classifier loss: 0.350087; batch adversarial loss: 0.563030\n",
      "epoch 112; iter: 0; batch classifier loss: 0.423694; batch adversarial loss: 0.559699\n",
      "epoch 113; iter: 0; batch classifier loss: 0.400387; batch adversarial loss: 0.538172\n",
      "epoch 114; iter: 0; batch classifier loss: 0.417996; batch adversarial loss: 0.558221\n",
      "epoch 115; iter: 0; batch classifier loss: 0.330665; batch adversarial loss: 0.544544\n",
      "epoch 116; iter: 0; batch classifier loss: 0.325451; batch adversarial loss: 0.544591\n",
      "epoch 117; iter: 0; batch classifier loss: 0.367343; batch adversarial loss: 0.616415\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 118; iter: 0; batch classifier loss: 0.350032; batch adversarial loss: 0.551771\n",
      "epoch 119; iter: 0; batch classifier loss: 0.344083; batch adversarial loss: 0.561552\n",
      "epoch 120; iter: 0; batch classifier loss: 0.386356; batch adversarial loss: 0.534561\n",
      "epoch 121; iter: 0; batch classifier loss: 0.341360; batch adversarial loss: 0.535087\n",
      "epoch 122; iter: 0; batch classifier loss: 0.343378; batch adversarial loss: 0.579627\n",
      "epoch 123; iter: 0; batch classifier loss: 0.369203; batch adversarial loss: 0.668562\n",
      "epoch 124; iter: 0; batch classifier loss: 0.410340; batch adversarial loss: 0.599580\n",
      "epoch 125; iter: 0; batch classifier loss: 0.375952; batch adversarial loss: 0.499259\n",
      "epoch 126; iter: 0; batch classifier loss: 0.354027; batch adversarial loss: 0.531738\n",
      "epoch 127; iter: 0; batch classifier loss: 0.377355; batch adversarial loss: 0.511774\n",
      "epoch 128; iter: 0; batch classifier loss: 0.353974; batch adversarial loss: 0.568647\n",
      "epoch 129; iter: 0; batch classifier loss: 0.355030; batch adversarial loss: 0.614350\n",
      "epoch 130; iter: 0; batch classifier loss: 0.425399; batch adversarial loss: 0.481809\n",
      "epoch 131; iter: 0; batch classifier loss: 0.392593; batch adversarial loss: 0.493437\n",
      "epoch 132; iter: 0; batch classifier loss: 0.405836; batch adversarial loss: 0.552784\n",
      "epoch 133; iter: 0; batch classifier loss: 0.395689; batch adversarial loss: 0.531677\n",
      "epoch 134; iter: 0; batch classifier loss: 0.384489; batch adversarial loss: 0.515109\n",
      "epoch 135; iter: 0; batch classifier loss: 0.301397; batch adversarial loss: 0.547401\n",
      "epoch 136; iter: 0; batch classifier loss: 0.487851; batch adversarial loss: 0.491731\n",
      "epoch 137; iter: 0; batch classifier loss: 0.386648; batch adversarial loss: 0.506839\n",
      "epoch 138; iter: 0; batch classifier loss: 0.373411; batch adversarial loss: 0.594861\n",
      "epoch 139; iter: 0; batch classifier loss: 0.302034; batch adversarial loss: 0.555391\n",
      "epoch 140; iter: 0; batch classifier loss: 0.438325; batch adversarial loss: 0.617439\n",
      "epoch 141; iter: 0; batch classifier loss: 0.381488; batch adversarial loss: 0.570941\n",
      "epoch 142; iter: 0; batch classifier loss: 0.287086; batch adversarial loss: 0.535262\n",
      "epoch 143; iter: 0; batch classifier loss: 0.403447; batch adversarial loss: 0.525011\n",
      "epoch 144; iter: 0; batch classifier loss: 0.420447; batch adversarial loss: 0.527140\n",
      "epoch 145; iter: 0; batch classifier loss: 0.404654; batch adversarial loss: 0.512117\n",
      "epoch 146; iter: 0; batch classifier loss: 0.371327; batch adversarial loss: 0.660207\n",
      "epoch 147; iter: 0; batch classifier loss: 0.397222; batch adversarial loss: 0.585427\n",
      "epoch 148; iter: 0; batch classifier loss: 0.351144; batch adversarial loss: 0.450471\n",
      "epoch 149; iter: 0; batch classifier loss: 0.319468; batch adversarial loss: 0.581293\n",
      "epoch 150; iter: 0; batch classifier loss: 0.415290; batch adversarial loss: 0.561647\n",
      "epoch 151; iter: 0; batch classifier loss: 0.349301; batch adversarial loss: 0.595930\n",
      "epoch 152; iter: 0; batch classifier loss: 0.330268; batch adversarial loss: 0.577966\n",
      "epoch 153; iter: 0; batch classifier loss: 0.407940; batch adversarial loss: 0.610152\n",
      "epoch 154; iter: 0; batch classifier loss: 0.294953; batch adversarial loss: 0.615451\n",
      "epoch 155; iter: 0; batch classifier loss: 0.355725; batch adversarial loss: 0.576890\n",
      "epoch 156; iter: 0; batch classifier loss: 0.368250; batch adversarial loss: 0.590860\n",
      "epoch 157; iter: 0; batch classifier loss: 0.418512; batch adversarial loss: 0.528851\n",
      "epoch 158; iter: 0; batch classifier loss: 0.321356; batch adversarial loss: 0.601775\n",
      "epoch 159; iter: 0; batch classifier loss: 0.369604; batch adversarial loss: 0.552991\n",
      "epoch 160; iter: 0; batch classifier loss: 0.404635; batch adversarial loss: 0.572102\n",
      "epoch 161; iter: 0; batch classifier loss: 0.405806; batch adversarial loss: 0.589845\n",
      "epoch 162; iter: 0; batch classifier loss: 0.292819; batch adversarial loss: 0.567636\n",
      "epoch 163; iter: 0; batch classifier loss: 0.338174; batch adversarial loss: 0.526275\n",
      "epoch 164; iter: 0; batch classifier loss: 0.330393; batch adversarial loss: 0.593030\n",
      "epoch 165; iter: 0; batch classifier loss: 0.352279; batch adversarial loss: 0.580538\n",
      "epoch 166; iter: 0; batch classifier loss: 0.352294; batch adversarial loss: 0.554583\n",
      "epoch 167; iter: 0; batch classifier loss: 0.344061; batch adversarial loss: 0.571294\n",
      "epoch 168; iter: 0; batch classifier loss: 0.420498; batch adversarial loss: 0.582004\n",
      "epoch 169; iter: 0; batch classifier loss: 0.376385; batch adversarial loss: 0.533087\n",
      "epoch 170; iter: 0; batch classifier loss: 0.330582; batch adversarial loss: 0.573737\n",
      "epoch 171; iter: 0; batch classifier loss: 0.409445; batch adversarial loss: 0.578483\n",
      "epoch 172; iter: 0; batch classifier loss: 0.346258; batch adversarial loss: 0.556708\n",
      "epoch 173; iter: 0; batch classifier loss: 0.314998; batch adversarial loss: 0.533654\n",
      "epoch 174; iter: 0; batch classifier loss: 0.358383; batch adversarial loss: 0.569097\n",
      "epoch 175; iter: 0; batch classifier loss: 0.390864; batch adversarial loss: 0.654110\n",
      "epoch 176; iter: 0; batch classifier loss: 0.411933; batch adversarial loss: 0.490350\n",
      "epoch 177; iter: 0; batch classifier loss: 0.331579; batch adversarial loss: 0.492119\n",
      "epoch 178; iter: 0; batch classifier loss: 0.390141; batch adversarial loss: 0.541458\n",
      "epoch 179; iter: 0; batch classifier loss: 0.413362; batch adversarial loss: 0.607834\n",
      "epoch 180; iter: 0; batch classifier loss: 0.396085; batch adversarial loss: 0.588306\n",
      "epoch 181; iter: 0; batch classifier loss: 0.382824; batch adversarial loss: 0.586849\n",
      "epoch 182; iter: 0; batch classifier loss: 0.397059; batch adversarial loss: 0.554049\n",
      "epoch 183; iter: 0; batch classifier loss: 0.330435; batch adversarial loss: 0.569339\n",
      "epoch 184; iter: 0; batch classifier loss: 0.352021; batch adversarial loss: 0.533248\n",
      "epoch 185; iter: 0; batch classifier loss: 0.413455; batch adversarial loss: 0.514277\n",
      "epoch 186; iter: 0; batch classifier loss: 0.379439; batch adversarial loss: 0.500191\n",
      "epoch 187; iter: 0; batch classifier loss: 0.429130; batch adversarial loss: 0.540614\n",
      "epoch 188; iter: 0; batch classifier loss: 0.348519; batch adversarial loss: 0.534625\n",
      "epoch 189; iter: 0; batch classifier loss: 0.427872; batch adversarial loss: 0.504109\n",
      "epoch 190; iter: 0; batch classifier loss: 0.312022; batch adversarial loss: 0.603192\n",
      "epoch 191; iter: 0; batch classifier loss: 0.324187; batch adversarial loss: 0.561226\n",
      "epoch 192; iter: 0; batch classifier loss: 0.320459; batch adversarial loss: 0.593612\n",
      "epoch 193; iter: 0; batch classifier loss: 0.409072; batch adversarial loss: 0.516612\n",
      "epoch 194; iter: 0; batch classifier loss: 0.362970; batch adversarial loss: 0.590253\n",
      "epoch 195; iter: 0; batch classifier loss: 0.329838; batch adversarial loss: 0.529392\n",
      "epoch 196; iter: 0; batch classifier loss: 0.298218; batch adversarial loss: 0.567333\n",
      "epoch 197; iter: 0; batch classifier loss: 0.389959; batch adversarial loss: 0.517594\n",
      "epoch 198; iter: 0; batch classifier loss: 0.369684; batch adversarial loss: 0.597377\n",
      "epoch 199; iter: 0; batch classifier loss: 0.348084; batch adversarial loss: 0.498824\n",
      "epoch 0; iter: 0; batch classifier loss: 0.727664; batch adversarial loss: 0.586405\n",
      "epoch 1; iter: 0; batch classifier loss: 0.560531; batch adversarial loss: 0.653840\n",
      "epoch 2; iter: 0; batch classifier loss: 0.536842; batch adversarial loss: 0.692323\n",
      "epoch 3; iter: 0; batch classifier loss: 0.577776; batch adversarial loss: 0.657617\n",
      "epoch 4; iter: 0; batch classifier loss: 0.524320; batch adversarial loss: 0.596297\n",
      "epoch 5; iter: 0; batch classifier loss: 0.543742; batch adversarial loss: 0.623191\n",
      "epoch 6; iter: 0; batch classifier loss: 0.483229; batch adversarial loss: 0.613982\n",
      "epoch 7; iter: 0; batch classifier loss: 0.471095; batch adversarial loss: 0.633276\n",
      "epoch 8; iter: 0; batch classifier loss: 0.663674; batch adversarial loss: 0.645089\n",
      "epoch 9; iter: 0; batch classifier loss: 0.499468; batch adversarial loss: 0.637779\n",
      "epoch 10; iter: 0; batch classifier loss: 0.564139; batch adversarial loss: 0.627613\n",
      "epoch 11; iter: 0; batch classifier loss: 0.519501; batch adversarial loss: 0.628536\n",
      "epoch 12; iter: 0; batch classifier loss: 0.550786; batch adversarial loss: 0.552862\n",
      "epoch 13; iter: 0; batch classifier loss: 0.552218; batch adversarial loss: 0.605236\n",
      "epoch 14; iter: 0; batch classifier loss: 0.480767; batch adversarial loss: 0.564236\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 15; iter: 0; batch classifier loss: 0.536737; batch adversarial loss: 0.635962\n",
      "epoch 16; iter: 0; batch classifier loss: 0.510170; batch adversarial loss: 0.555674\n",
      "epoch 17; iter: 0; batch classifier loss: 0.568343; batch adversarial loss: 0.607720\n",
      "epoch 18; iter: 0; batch classifier loss: 0.514692; batch adversarial loss: 0.521711\n",
      "epoch 19; iter: 0; batch classifier loss: 0.500026; batch adversarial loss: 0.513414\n",
      "epoch 20; iter: 0; batch classifier loss: 0.487142; batch adversarial loss: 0.601843\n",
      "epoch 21; iter: 0; batch classifier loss: 0.471154; batch adversarial loss: 0.574942\n",
      "epoch 22; iter: 0; batch classifier loss: 0.486597; batch adversarial loss: 0.530127\n",
      "epoch 23; iter: 0; batch classifier loss: 0.511752; batch adversarial loss: 0.487932\n",
      "epoch 24; iter: 0; batch classifier loss: 0.528147; batch adversarial loss: 0.546530\n",
      "epoch 25; iter: 0; batch classifier loss: 0.463297; batch adversarial loss: 0.554289\n",
      "epoch 26; iter: 0; batch classifier loss: 0.444632; batch adversarial loss: 0.547129\n",
      "epoch 27; iter: 0; batch classifier loss: 0.478220; batch adversarial loss: 0.529366\n",
      "epoch 28; iter: 0; batch classifier loss: 0.424808; batch adversarial loss: 0.639351\n",
      "epoch 29; iter: 0; batch classifier loss: 0.472710; batch adversarial loss: 0.612288\n",
      "epoch 30; iter: 0; batch classifier loss: 0.447402; batch adversarial loss: 0.451664\n",
      "epoch 31; iter: 0; batch classifier loss: 0.424075; batch adversarial loss: 0.485585\n",
      "epoch 32; iter: 0; batch classifier loss: 0.485440; batch adversarial loss: 0.588198\n",
      "epoch 33; iter: 0; batch classifier loss: 0.494055; batch adversarial loss: 0.571142\n",
      "epoch 34; iter: 0; batch classifier loss: 0.437587; batch adversarial loss: 0.570685\n",
      "epoch 35; iter: 0; batch classifier loss: 0.430387; batch adversarial loss: 0.562066\n",
      "epoch 36; iter: 0; batch classifier loss: 0.424261; batch adversarial loss: 0.508054\n",
      "epoch 37; iter: 0; batch classifier loss: 0.503220; batch adversarial loss: 0.606636\n",
      "epoch 38; iter: 0; batch classifier loss: 0.420060; batch adversarial loss: 0.580430\n",
      "epoch 39; iter: 0; batch classifier loss: 0.470491; batch adversarial loss: 0.464378\n",
      "epoch 40; iter: 0; batch classifier loss: 0.596526; batch adversarial loss: 0.500267\n",
      "epoch 41; iter: 0; batch classifier loss: 0.492883; batch adversarial loss: 0.555492\n",
      "epoch 42; iter: 0; batch classifier loss: 0.464045; batch adversarial loss: 0.606187\n",
      "epoch 43; iter: 0; batch classifier loss: 0.436742; batch adversarial loss: 0.615649\n",
      "epoch 44; iter: 0; batch classifier loss: 0.463071; batch adversarial loss: 0.535777\n",
      "epoch 45; iter: 0; batch classifier loss: 0.487714; batch adversarial loss: 0.518622\n",
      "epoch 46; iter: 0; batch classifier loss: 0.368819; batch adversarial loss: 0.562537\n",
      "epoch 47; iter: 0; batch classifier loss: 0.446596; batch adversarial loss: 0.588787\n",
      "epoch 48; iter: 0; batch classifier loss: 0.402208; batch adversarial loss: 0.606872\n",
      "epoch 49; iter: 0; batch classifier loss: 0.372837; batch adversarial loss: 0.473358\n",
      "epoch 50; iter: 0; batch classifier loss: 0.352069; batch adversarial loss: 0.508919\n",
      "epoch 51; iter: 0; batch classifier loss: 0.373368; batch adversarial loss: 0.589218\n",
      "epoch 52; iter: 0; batch classifier loss: 0.388786; batch adversarial loss: 0.491101\n",
      "epoch 53; iter: 0; batch classifier loss: 0.444857; batch adversarial loss: 0.535805\n",
      "epoch 54; iter: 0; batch classifier loss: 0.376722; batch adversarial loss: 0.473463\n",
      "epoch 55; iter: 0; batch classifier loss: 0.356577; batch adversarial loss: 0.508765\n",
      "epoch 56; iter: 0; batch classifier loss: 0.474463; batch adversarial loss: 0.526706\n",
      "epoch 57; iter: 0; batch classifier loss: 0.506984; batch adversarial loss: 0.526410\n",
      "epoch 58; iter: 0; batch classifier loss: 0.367280; batch adversarial loss: 0.597962\n",
      "epoch 59; iter: 0; batch classifier loss: 0.407151; batch adversarial loss: 0.499591\n",
      "epoch 60; iter: 0; batch classifier loss: 0.394786; batch adversarial loss: 0.490841\n",
      "epoch 61; iter: 0; batch classifier loss: 0.411177; batch adversarial loss: 0.661623\n",
      "epoch 62; iter: 0; batch classifier loss: 0.443151; batch adversarial loss: 0.535964\n",
      "epoch 63; iter: 0; batch classifier loss: 0.378945; batch adversarial loss: 0.563102\n",
      "epoch 64; iter: 0; batch classifier loss: 0.405406; batch adversarial loss: 0.580864\n",
      "epoch 65; iter: 0; batch classifier loss: 0.442331; batch adversarial loss: 0.535543\n",
      "epoch 66; iter: 0; batch classifier loss: 0.387468; batch adversarial loss: 0.526766\n",
      "epoch 67; iter: 0; batch classifier loss: 0.407528; batch adversarial loss: 0.553913\n",
      "epoch 68; iter: 0; batch classifier loss: 0.493007; batch adversarial loss: 0.562724\n",
      "epoch 69; iter: 0; batch classifier loss: 0.406332; batch adversarial loss: 0.562807\n",
      "epoch 70; iter: 0; batch classifier loss: 0.423979; batch adversarial loss: 0.571676\n",
      "epoch 71; iter: 0; batch classifier loss: 0.450855; batch adversarial loss: 0.527709\n",
      "epoch 72; iter: 0; batch classifier loss: 0.437032; batch adversarial loss: 0.544457\n",
      "epoch 73; iter: 0; batch classifier loss: 0.434241; batch adversarial loss: 0.561991\n",
      "epoch 74; iter: 0; batch classifier loss: 0.431060; batch adversarial loss: 0.474899\n",
      "epoch 75; iter: 0; batch classifier loss: 0.329082; batch adversarial loss: 0.526183\n",
      "epoch 76; iter: 0; batch classifier loss: 0.348260; batch adversarial loss: 0.553358\n",
      "epoch 77; iter: 0; batch classifier loss: 0.458668; batch adversarial loss: 0.553463\n",
      "epoch 78; iter: 0; batch classifier loss: 0.471207; batch adversarial loss: 0.517133\n",
      "epoch 79; iter: 0; batch classifier loss: 0.416608; batch adversarial loss: 0.562740\n",
      "epoch 80; iter: 0; batch classifier loss: 0.357362; batch adversarial loss: 0.543964\n",
      "epoch 81; iter: 0; batch classifier loss: 0.374316; batch adversarial loss: 0.545311\n",
      "epoch 82; iter: 0; batch classifier loss: 0.394081; batch adversarial loss: 0.598246\n",
      "epoch 83; iter: 0; batch classifier loss: 0.398335; batch adversarial loss: 0.572236\n",
      "epoch 84; iter: 0; batch classifier loss: 0.381075; batch adversarial loss: 0.580818\n",
      "epoch 85; iter: 0; batch classifier loss: 0.393760; batch adversarial loss: 0.527092\n",
      "epoch 86; iter: 0; batch classifier loss: 0.376157; batch adversarial loss: 0.499728\n",
      "epoch 87; iter: 0; batch classifier loss: 0.423019; batch adversarial loss: 0.509516\n",
      "epoch 88; iter: 0; batch classifier loss: 0.440305; batch adversarial loss: 0.516791\n",
      "epoch 89; iter: 0; batch classifier loss: 0.464251; batch adversarial loss: 0.517975\n",
      "epoch 90; iter: 0; batch classifier loss: 0.396803; batch adversarial loss: 0.472813\n",
      "epoch 91; iter: 0; batch classifier loss: 0.434131; batch adversarial loss: 0.563049\n",
      "epoch 92; iter: 0; batch classifier loss: 0.375853; batch adversarial loss: 0.498482\n",
      "epoch 93; iter: 0; batch classifier loss: 0.392163; batch adversarial loss: 0.543856\n",
      "epoch 94; iter: 0; batch classifier loss: 0.408450; batch adversarial loss: 0.570900\n",
      "epoch 95; iter: 0; batch classifier loss: 0.387516; batch adversarial loss: 0.525929\n",
      "epoch 96; iter: 0; batch classifier loss: 0.385470; batch adversarial loss: 0.563703\n",
      "epoch 97; iter: 0; batch classifier loss: 0.396497; batch adversarial loss: 0.606464\n",
      "epoch 98; iter: 0; batch classifier loss: 0.385079; batch adversarial loss: 0.543542\n",
      "epoch 99; iter: 0; batch classifier loss: 0.461969; batch adversarial loss: 0.625096\n",
      "epoch 100; iter: 0; batch classifier loss: 0.392012; batch adversarial loss: 0.490362\n",
      "epoch 101; iter: 0; batch classifier loss: 0.401090; batch adversarial loss: 0.589973\n",
      "epoch 102; iter: 0; batch classifier loss: 0.475632; batch adversarial loss: 0.579760\n",
      "epoch 103; iter: 0; batch classifier loss: 0.470530; batch adversarial loss: 0.572306\n",
      "epoch 104; iter: 0; batch classifier loss: 0.433208; batch adversarial loss: 0.509299\n",
      "epoch 105; iter: 0; batch classifier loss: 0.379662; batch adversarial loss: 0.580900\n",
      "epoch 106; iter: 0; batch classifier loss: 0.416858; batch adversarial loss: 0.571464\n",
      "epoch 107; iter: 0; batch classifier loss: 0.347671; batch adversarial loss: 0.607437\n",
      "epoch 108; iter: 0; batch classifier loss: 0.363295; batch adversarial loss: 0.508573\n",
      "epoch 109; iter: 0; batch classifier loss: 0.415894; batch adversarial loss: 0.626162\n",
      "epoch 110; iter: 0; batch classifier loss: 0.333489; batch adversarial loss: 0.482070\n",
      "epoch 111; iter: 0; batch classifier loss: 0.359429; batch adversarial loss: 0.535937\n",
      "epoch 112; iter: 0; batch classifier loss: 0.381876; batch adversarial loss: 0.571871\n",
      "epoch 113; iter: 0; batch classifier loss: 0.395165; batch adversarial loss: 0.498151\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 114; iter: 0; batch classifier loss: 0.413097; batch adversarial loss: 0.545118\n",
      "epoch 115; iter: 0; batch classifier loss: 0.415782; batch adversarial loss: 0.625428\n",
      "epoch 116; iter: 0; batch classifier loss: 0.368606; batch adversarial loss: 0.517362\n",
      "epoch 117; iter: 0; batch classifier loss: 0.446802; batch adversarial loss: 0.533907\n",
      "epoch 118; iter: 0; batch classifier loss: 0.433015; batch adversarial loss: 0.527945\n",
      "epoch 119; iter: 0; batch classifier loss: 0.380335; batch adversarial loss: 0.544395\n",
      "epoch 120; iter: 0; batch classifier loss: 0.422464; batch adversarial loss: 0.579125\n",
      "epoch 121; iter: 0; batch classifier loss: 0.375717; batch adversarial loss: 0.563422\n",
      "epoch 122; iter: 0; batch classifier loss: 0.313066; batch adversarial loss: 0.508211\n",
      "epoch 123; iter: 0; batch classifier loss: 0.439072; batch adversarial loss: 0.552207\n",
      "epoch 124; iter: 0; batch classifier loss: 0.391316; batch adversarial loss: 0.598004\n",
      "epoch 125; iter: 0; batch classifier loss: 0.386358; batch adversarial loss: 0.562006\n",
      "epoch 126; iter: 0; batch classifier loss: 0.383617; batch adversarial loss: 0.652346\n",
      "epoch 127; iter: 0; batch classifier loss: 0.289941; batch adversarial loss: 0.570770\n",
      "epoch 128; iter: 0; batch classifier loss: 0.368758; batch adversarial loss: 0.641338\n",
      "epoch 129; iter: 0; batch classifier loss: 0.437184; batch adversarial loss: 0.588909\n",
      "epoch 130; iter: 0; batch classifier loss: 0.475671; batch adversarial loss: 0.598039\n",
      "epoch 131; iter: 0; batch classifier loss: 0.331685; batch adversarial loss: 0.545130\n",
      "epoch 132; iter: 0; batch classifier loss: 0.402079; batch adversarial loss: 0.525609\n",
      "epoch 133; iter: 0; batch classifier loss: 0.414797; batch adversarial loss: 0.517544\n",
      "epoch 134; iter: 0; batch classifier loss: 0.323517; batch adversarial loss: 0.535781\n",
      "epoch 135; iter: 0; batch classifier loss: 0.341913; batch adversarial loss: 0.535298\n",
      "epoch 136; iter: 0; batch classifier loss: 0.396672; batch adversarial loss: 0.499290\n",
      "epoch 137; iter: 0; batch classifier loss: 0.447088; batch adversarial loss: 0.535041\n",
      "epoch 138; iter: 0; batch classifier loss: 0.376030; batch adversarial loss: 0.571465\n",
      "epoch 139; iter: 0; batch classifier loss: 0.378836; batch adversarial loss: 0.491520\n",
      "epoch 140; iter: 0; batch classifier loss: 0.355540; batch adversarial loss: 0.489543\n",
      "epoch 141; iter: 0; batch classifier loss: 0.386749; batch adversarial loss: 0.525980\n",
      "epoch 142; iter: 0; batch classifier loss: 0.384571; batch adversarial loss: 0.572445\n",
      "epoch 143; iter: 0; batch classifier loss: 0.369212; batch adversarial loss: 0.563387\n",
      "epoch 144; iter: 0; batch classifier loss: 0.492632; batch adversarial loss: 0.544974\n",
      "epoch 145; iter: 0; batch classifier loss: 0.327728; batch adversarial loss: 0.536232\n",
      "epoch 146; iter: 0; batch classifier loss: 0.321948; batch adversarial loss: 0.571120\n",
      "epoch 147; iter: 0; batch classifier loss: 0.296704; batch adversarial loss: 0.580372\n",
      "epoch 148; iter: 0; batch classifier loss: 0.426022; batch adversarial loss: 0.516090\n",
      "epoch 149; iter: 0; batch classifier loss: 0.336452; batch adversarial loss: 0.518859\n",
      "epoch 150; iter: 0; batch classifier loss: 0.317851; batch adversarial loss: 0.508968\n",
      "epoch 151; iter: 0; batch classifier loss: 0.275993; batch adversarial loss: 0.562190\n",
      "epoch 152; iter: 0; batch classifier loss: 0.372303; batch adversarial loss: 0.518152\n",
      "epoch 153; iter: 0; batch classifier loss: 0.399659; batch adversarial loss: 0.527716\n",
      "epoch 154; iter: 0; batch classifier loss: 0.358082; batch adversarial loss: 0.544266\n",
      "epoch 155; iter: 0; batch classifier loss: 0.373700; batch adversarial loss: 0.500751\n",
      "epoch 156; iter: 0; batch classifier loss: 0.390460; batch adversarial loss: 0.535847\n",
      "epoch 157; iter: 0; batch classifier loss: 0.397374; batch adversarial loss: 0.535905\n",
      "epoch 158; iter: 0; batch classifier loss: 0.317124; batch adversarial loss: 0.624700\n",
      "epoch 159; iter: 0; batch classifier loss: 0.353354; batch adversarial loss: 0.554513\n",
      "epoch 160; iter: 0; batch classifier loss: 0.309220; batch adversarial loss: 0.516509\n",
      "epoch 161; iter: 0; batch classifier loss: 0.385666; batch adversarial loss: 0.527550\n",
      "epoch 162; iter: 0; batch classifier loss: 0.342828; batch adversarial loss: 0.553845\n",
      "epoch 163; iter: 0; batch classifier loss: 0.320468; batch adversarial loss: 0.588490\n",
      "epoch 164; iter: 0; batch classifier loss: 0.440958; batch adversarial loss: 0.526131\n",
      "epoch 165; iter: 0; batch classifier loss: 0.350177; batch adversarial loss: 0.552178\n",
      "epoch 166; iter: 0; batch classifier loss: 0.364135; batch adversarial loss: 0.607522\n",
      "epoch 167; iter: 0; batch classifier loss: 0.383605; batch adversarial loss: 0.598150\n",
      "epoch 168; iter: 0; batch classifier loss: 0.400976; batch adversarial loss: 0.544474\n",
      "epoch 169; iter: 0; batch classifier loss: 0.317254; batch adversarial loss: 0.518517\n",
      "epoch 170; iter: 0; batch classifier loss: 0.379082; batch adversarial loss: 0.542563\n",
      "epoch 171; iter: 0; batch classifier loss: 0.267632; batch adversarial loss: 0.490791\n",
      "epoch 172; iter: 0; batch classifier loss: 0.332965; batch adversarial loss: 0.651664\n",
      "epoch 173; iter: 0; batch classifier loss: 0.364094; batch adversarial loss: 0.588549\n",
      "epoch 174; iter: 0; batch classifier loss: 0.363632; batch adversarial loss: 0.578443\n",
      "epoch 175; iter: 0; batch classifier loss: 0.437413; batch adversarial loss: 0.536565\n",
      "epoch 176; iter: 0; batch classifier loss: 0.439155; batch adversarial loss: 0.635781\n",
      "epoch 177; iter: 0; batch classifier loss: 0.407289; batch adversarial loss: 0.561347\n",
      "epoch 178; iter: 0; batch classifier loss: 0.411656; batch adversarial loss: 0.554236\n",
      "epoch 179; iter: 0; batch classifier loss: 0.405647; batch adversarial loss: 0.545756\n",
      "epoch 180; iter: 0; batch classifier loss: 0.375191; batch adversarial loss: 0.571863\n",
      "epoch 181; iter: 0; batch classifier loss: 0.361787; batch adversarial loss: 0.573068\n",
      "epoch 182; iter: 0; batch classifier loss: 0.318380; batch adversarial loss: 0.554715\n",
      "epoch 183; iter: 0; batch classifier loss: 0.397211; batch adversarial loss: 0.561488\n",
      "epoch 184; iter: 0; batch classifier loss: 0.334439; batch adversarial loss: 0.526963\n",
      "epoch 185; iter: 0; batch classifier loss: 0.409738; batch adversarial loss: 0.523850\n",
      "epoch 186; iter: 0; batch classifier loss: 0.400596; batch adversarial loss: 0.526600\n",
      "epoch 187; iter: 0; batch classifier loss: 0.390139; batch adversarial loss: 0.519002\n",
      "epoch 188; iter: 0; batch classifier loss: 0.351322; batch adversarial loss: 0.500318\n",
      "epoch 189; iter: 0; batch classifier loss: 0.429039; batch adversarial loss: 0.598617\n",
      "epoch 190; iter: 0; batch classifier loss: 0.460911; batch adversarial loss: 0.536482\n",
      "epoch 191; iter: 0; batch classifier loss: 0.402535; batch adversarial loss: 0.544203\n",
      "epoch 192; iter: 0; batch classifier loss: 0.427665; batch adversarial loss: 0.546234\n",
      "epoch 193; iter: 0; batch classifier loss: 0.390256; batch adversarial loss: 0.560892\n",
      "epoch 194; iter: 0; batch classifier loss: 0.416860; batch adversarial loss: 0.554536\n",
      "epoch 195; iter: 0; batch classifier loss: 0.367335; batch adversarial loss: 0.571933\n",
      "epoch 196; iter: 0; batch classifier loss: 0.274422; batch adversarial loss: 0.563639\n",
      "epoch 197; iter: 0; batch classifier loss: 0.368529; batch adversarial loss: 0.562700\n",
      "epoch 198; iter: 0; batch classifier loss: 0.393732; batch adversarial loss: 0.553779\n",
      "epoch 199; iter: 0; batch classifier loss: 0.390036; batch adversarial loss: 0.464208\n",
      "epoch 0; iter: 0; batch classifier loss: 0.667455; batch adversarial loss: 0.705054\n",
      "epoch 1; iter: 0; batch classifier loss: 0.578284; batch adversarial loss: 0.662813\n",
      "epoch 2; iter: 0; batch classifier loss: 0.586014; batch adversarial loss: 0.658660\n",
      "epoch 3; iter: 0; batch classifier loss: 0.555586; batch adversarial loss: 0.665580\n",
      "epoch 4; iter: 0; batch classifier loss: 0.571904; batch adversarial loss: 0.638499\n",
      "epoch 5; iter: 0; batch classifier loss: 0.624911; batch adversarial loss: 0.631087\n",
      "epoch 6; iter: 0; batch classifier loss: 0.659145; batch adversarial loss: 0.634176\n",
      "epoch 7; iter: 0; batch classifier loss: 0.568775; batch adversarial loss: 0.608560\n",
      "epoch 8; iter: 0; batch classifier loss: 0.511602; batch adversarial loss: 0.606949\n",
      "epoch 9; iter: 0; batch classifier loss: 0.514823; batch adversarial loss: 0.607543\n",
      "epoch 10; iter: 0; batch classifier loss: 0.562282; batch adversarial loss: 0.600715\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11; iter: 0; batch classifier loss: 0.545421; batch adversarial loss: 0.578991\n",
      "epoch 12; iter: 0; batch classifier loss: 0.518591; batch adversarial loss: 0.520328\n",
      "epoch 13; iter: 0; batch classifier loss: 0.528061; batch adversarial loss: 0.504138\n",
      "epoch 14; iter: 0; batch classifier loss: 0.436707; batch adversarial loss: 0.548201\n",
      "epoch 15; iter: 0; batch classifier loss: 0.546334; batch adversarial loss: 0.614569\n",
      "epoch 16; iter: 0; batch classifier loss: 0.564860; batch adversarial loss: 0.441522\n",
      "epoch 17; iter: 0; batch classifier loss: 0.409111; batch adversarial loss: 0.525128\n",
      "epoch 18; iter: 0; batch classifier loss: 0.539925; batch adversarial loss: 0.500851\n",
      "epoch 19; iter: 0; batch classifier loss: 0.502562; batch adversarial loss: 0.577451\n",
      "epoch 20; iter: 0; batch classifier loss: 0.516219; batch adversarial loss: 0.570086\n",
      "epoch 21; iter: 0; batch classifier loss: 0.504523; batch adversarial loss: 0.586330\n",
      "epoch 22; iter: 0; batch classifier loss: 0.506097; batch adversarial loss: 0.537309\n",
      "epoch 23; iter: 0; batch classifier loss: 0.501571; batch adversarial loss: 0.522767\n",
      "epoch 24; iter: 0; batch classifier loss: 0.498485; batch adversarial loss: 0.455840\n",
      "epoch 25; iter: 0; batch classifier loss: 0.435255; batch adversarial loss: 0.596229\n",
      "epoch 26; iter: 0; batch classifier loss: 0.480266; batch adversarial loss: 0.607560\n",
      "epoch 27; iter: 0; batch classifier loss: 0.485362; batch adversarial loss: 0.563821\n",
      "epoch 28; iter: 0; batch classifier loss: 0.547140; batch adversarial loss: 0.551849\n",
      "epoch 29; iter: 0; batch classifier loss: 0.444754; batch adversarial loss: 0.503879\n",
      "epoch 30; iter: 0; batch classifier loss: 0.442584; batch adversarial loss: 0.530409\n",
      "epoch 31; iter: 0; batch classifier loss: 0.449654; batch adversarial loss: 0.506002\n",
      "epoch 32; iter: 0; batch classifier loss: 0.514123; batch adversarial loss: 0.520747\n",
      "epoch 33; iter: 0; batch classifier loss: 0.564269; batch adversarial loss: 0.579740\n",
      "epoch 34; iter: 0; batch classifier loss: 0.481440; batch adversarial loss: 0.527562\n",
      "epoch 35; iter: 0; batch classifier loss: 0.484114; batch adversarial loss: 0.518080\n",
      "epoch 36; iter: 0; batch classifier loss: 0.414739; batch adversarial loss: 0.466052\n",
      "epoch 37; iter: 0; batch classifier loss: 0.514342; batch adversarial loss: 0.571555\n",
      "epoch 38; iter: 0; batch classifier loss: 0.473360; batch adversarial loss: 0.580086\n",
      "epoch 39; iter: 0; batch classifier loss: 0.551428; batch adversarial loss: 0.642258\n",
      "epoch 40; iter: 0; batch classifier loss: 0.514803; batch adversarial loss: 0.598931\n",
      "epoch 41; iter: 0; batch classifier loss: 0.399538; batch adversarial loss: 0.526828\n",
      "epoch 42; iter: 0; batch classifier loss: 0.433293; batch adversarial loss: 0.562447\n",
      "epoch 43; iter: 0; batch classifier loss: 0.385908; batch adversarial loss: 0.517622\n",
      "epoch 44; iter: 0; batch classifier loss: 0.517899; batch adversarial loss: 0.417151\n",
      "epoch 45; iter: 0; batch classifier loss: 0.444963; batch adversarial loss: 0.526692\n",
      "epoch 46; iter: 0; batch classifier loss: 0.504151; batch adversarial loss: 0.553456\n",
      "epoch 47; iter: 0; batch classifier loss: 0.439772; batch adversarial loss: 0.507403\n",
      "epoch 48; iter: 0; batch classifier loss: 0.401024; batch adversarial loss: 0.580424\n",
      "epoch 49; iter: 0; batch classifier loss: 0.455778; batch adversarial loss: 0.489941\n",
      "epoch 50; iter: 0; batch classifier loss: 0.461715; batch adversarial loss: 0.553548\n",
      "epoch 51; iter: 0; batch classifier loss: 0.418572; batch adversarial loss: 0.489728\n",
      "epoch 52; iter: 0; batch classifier loss: 0.448710; batch adversarial loss: 0.562525\n",
      "epoch 53; iter: 0; batch classifier loss: 0.437695; batch adversarial loss: 0.607813\n",
      "epoch 54; iter: 0; batch classifier loss: 0.428621; batch adversarial loss: 0.489927\n",
      "epoch 55; iter: 0; batch classifier loss: 0.415614; batch adversarial loss: 0.516844\n",
      "epoch 56; iter: 0; batch classifier loss: 0.394482; batch adversarial loss: 0.599384\n",
      "epoch 57; iter: 0; batch classifier loss: 0.366081; batch adversarial loss: 0.525462\n",
      "epoch 58; iter: 0; batch classifier loss: 0.429587; batch adversarial loss: 0.535804\n",
      "epoch 59; iter: 0; batch classifier loss: 0.404523; batch adversarial loss: 0.544815\n",
      "epoch 60; iter: 0; batch classifier loss: 0.368865; batch adversarial loss: 0.489814\n",
      "epoch 61; iter: 0; batch classifier loss: 0.417256; batch adversarial loss: 0.553398\n",
      "epoch 62; iter: 0; batch classifier loss: 0.369433; batch adversarial loss: 0.526709\n",
      "epoch 63; iter: 0; batch classifier loss: 0.413844; batch adversarial loss: 0.598837\n",
      "epoch 64; iter: 0; batch classifier loss: 0.422916; batch adversarial loss: 0.443595\n",
      "epoch 65; iter: 0; batch classifier loss: 0.376485; batch adversarial loss: 0.571387\n",
      "epoch 66; iter: 0; batch classifier loss: 0.360273; batch adversarial loss: 0.499279\n",
      "epoch 67; iter: 0; batch classifier loss: 0.391617; batch adversarial loss: 0.591662\n",
      "epoch 68; iter: 0; batch classifier loss: 0.392641; batch adversarial loss: 0.553639\n",
      "epoch 69; iter: 0; batch classifier loss: 0.436783; batch adversarial loss: 0.489836\n",
      "epoch 70; iter: 0; batch classifier loss: 0.394929; batch adversarial loss: 0.554228\n",
      "epoch 71; iter: 0; batch classifier loss: 0.411868; batch adversarial loss: 0.553313\n",
      "epoch 72; iter: 0; batch classifier loss: 0.371359; batch adversarial loss: 0.552861\n",
      "epoch 73; iter: 0; batch classifier loss: 0.380982; batch adversarial loss: 0.462396\n",
      "epoch 74; iter: 0; batch classifier loss: 0.408072; batch adversarial loss: 0.544196\n",
      "epoch 75; iter: 0; batch classifier loss: 0.395921; batch adversarial loss: 0.525368\n",
      "epoch 76; iter: 0; batch classifier loss: 0.429794; batch adversarial loss: 0.636087\n",
      "epoch 77; iter: 0; batch classifier loss: 0.327731; batch adversarial loss: 0.572794\n",
      "epoch 78; iter: 0; batch classifier loss: 0.428347; batch adversarial loss: 0.561915\n",
      "epoch 79; iter: 0; batch classifier loss: 0.376326; batch adversarial loss: 0.554361\n",
      "epoch 80; iter: 0; batch classifier loss: 0.476244; batch adversarial loss: 0.608415\n",
      "epoch 81; iter: 0; batch classifier loss: 0.340216; batch adversarial loss: 0.545990\n",
      "epoch 82; iter: 0; batch classifier loss: 0.339718; batch adversarial loss: 0.571393\n",
      "epoch 83; iter: 0; batch classifier loss: 0.381563; batch adversarial loss: 0.607945\n",
      "epoch 84; iter: 0; batch classifier loss: 0.363734; batch adversarial loss: 0.581262\n",
      "epoch 85; iter: 0; batch classifier loss: 0.399785; batch adversarial loss: 0.517550\n",
      "epoch 86; iter: 0; batch classifier loss: 0.449414; batch adversarial loss: 0.507239\n",
      "epoch 87; iter: 0; batch classifier loss: 0.448050; batch adversarial loss: 0.525780\n",
      "epoch 88; iter: 0; batch classifier loss: 0.395382; batch adversarial loss: 0.532917\n",
      "epoch 89; iter: 0; batch classifier loss: 0.408685; batch adversarial loss: 0.535372\n",
      "epoch 90; iter: 0; batch classifier loss: 0.351100; batch adversarial loss: 0.553395\n",
      "epoch 91; iter: 0; batch classifier loss: 0.348788; batch adversarial loss: 0.544069\n",
      "epoch 92; iter: 0; batch classifier loss: 0.353116; batch adversarial loss: 0.580713\n",
      "epoch 93; iter: 0; batch classifier loss: 0.349489; batch adversarial loss: 0.536205\n",
      "epoch 94; iter: 0; batch classifier loss: 0.385712; batch adversarial loss: 0.563543\n",
      "epoch 95; iter: 0; batch classifier loss: 0.380533; batch adversarial loss: 0.597946\n",
      "epoch 96; iter: 0; batch classifier loss: 0.350033; batch adversarial loss: 0.553455\n",
      "epoch 97; iter: 0; batch classifier loss: 0.359270; batch adversarial loss: 0.554881\n",
      "epoch 98; iter: 0; batch classifier loss: 0.343338; batch adversarial loss: 0.534019\n",
      "epoch 99; iter: 0; batch classifier loss: 0.412849; batch adversarial loss: 0.553167\n",
      "epoch 100; iter: 0; batch classifier loss: 0.470851; batch adversarial loss: 0.562523\n",
      "epoch 101; iter: 0; batch classifier loss: 0.388665; batch adversarial loss: 0.554346\n",
      "epoch 102; iter: 0; batch classifier loss: 0.383342; batch adversarial loss: 0.518195\n",
      "epoch 103; iter: 0; batch classifier loss: 0.387280; batch adversarial loss: 0.580773\n",
      "epoch 104; iter: 0; batch classifier loss: 0.321092; batch adversarial loss: 0.553316\n",
      "epoch 105; iter: 0; batch classifier loss: 0.337933; batch adversarial loss: 0.600431\n",
      "epoch 106; iter: 0; batch classifier loss: 0.388481; batch adversarial loss: 0.489622\n",
      "epoch 107; iter: 0; batch classifier loss: 0.331720; batch adversarial loss: 0.545119\n",
      "epoch 108; iter: 0; batch classifier loss: 0.421295; batch adversarial loss: 0.572757\n",
      "epoch 109; iter: 0; batch classifier loss: 0.326648; batch adversarial loss: 0.645818\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 110; iter: 0; batch classifier loss: 0.365011; batch adversarial loss: 0.526448\n",
      "epoch 111; iter: 0; batch classifier loss: 0.342363; batch adversarial loss: 0.554106\n",
      "epoch 112; iter: 0; batch classifier loss: 0.367969; batch adversarial loss: 0.578389\n",
      "epoch 113; iter: 0; batch classifier loss: 0.360364; batch adversarial loss: 0.571847\n",
      "epoch 114; iter: 0; batch classifier loss: 0.349722; batch adversarial loss: 0.479948\n",
      "epoch 115; iter: 0; batch classifier loss: 0.378187; batch adversarial loss: 0.590492\n",
      "epoch 116; iter: 0; batch classifier loss: 0.403560; batch adversarial loss: 0.591422\n",
      "epoch 117; iter: 0; batch classifier loss: 0.385429; batch adversarial loss: 0.591006\n",
      "epoch 118; iter: 0; batch classifier loss: 0.394397; batch adversarial loss: 0.553676\n",
      "epoch 119; iter: 0; batch classifier loss: 0.300401; batch adversarial loss: 0.544885\n",
      "epoch 120; iter: 0; batch classifier loss: 0.415415; batch adversarial loss: 0.497924\n",
      "epoch 121; iter: 0; batch classifier loss: 0.308504; batch adversarial loss: 0.498320\n",
      "epoch 122; iter: 0; batch classifier loss: 0.417375; batch adversarial loss: 0.489702\n",
      "epoch 123; iter: 0; batch classifier loss: 0.385426; batch adversarial loss: 0.489524\n",
      "epoch 124; iter: 0; batch classifier loss: 0.397644; batch adversarial loss: 0.571706\n",
      "epoch 125; iter: 0; batch classifier loss: 0.343290; batch adversarial loss: 0.562628\n",
      "epoch 126; iter: 0; batch classifier loss: 0.413354; batch adversarial loss: 0.580852\n",
      "epoch 127; iter: 0; batch classifier loss: 0.399633; batch adversarial loss: 0.546513\n",
      "epoch 128; iter: 0; batch classifier loss: 0.331574; batch adversarial loss: 0.488759\n",
      "epoch 129; iter: 0; batch classifier loss: 0.422315; batch adversarial loss: 0.526409\n",
      "epoch 130; iter: 0; batch classifier loss: 0.437252; batch adversarial loss: 0.479653\n",
      "epoch 131; iter: 0; batch classifier loss: 0.391938; batch adversarial loss: 0.554459\n",
      "epoch 132; iter: 0; batch classifier loss: 0.375125; batch adversarial loss: 0.635752\n",
      "epoch 133; iter: 0; batch classifier loss: 0.384965; batch adversarial loss: 0.498370\n",
      "epoch 134; iter: 0; batch classifier loss: 0.390193; batch adversarial loss: 0.461302\n",
      "epoch 135; iter: 0; batch classifier loss: 0.438081; batch adversarial loss: 0.555080\n",
      "epoch 136; iter: 0; batch classifier loss: 0.369495; batch adversarial loss: 0.572987\n",
      "epoch 137; iter: 0; batch classifier loss: 0.373868; batch adversarial loss: 0.525140\n",
      "epoch 138; iter: 0; batch classifier loss: 0.373325; batch adversarial loss: 0.545427\n",
      "epoch 139; iter: 0; batch classifier loss: 0.409648; batch adversarial loss: 0.545948\n",
      "epoch 140; iter: 0; batch classifier loss: 0.285195; batch adversarial loss: 0.525764\n",
      "epoch 141; iter: 0; batch classifier loss: 0.419656; batch adversarial loss: 0.561153\n",
      "epoch 142; iter: 0; batch classifier loss: 0.277360; batch adversarial loss: 0.480489\n",
      "epoch 143; iter: 0; batch classifier loss: 0.351368; batch adversarial loss: 0.443717\n",
      "epoch 144; iter: 0; batch classifier loss: 0.315359; batch adversarial loss: 0.626365\n",
      "epoch 145; iter: 0; batch classifier loss: 0.316439; batch adversarial loss: 0.554563\n",
      "epoch 146; iter: 0; batch classifier loss: 0.403452; batch adversarial loss: 0.506273\n",
      "epoch 147; iter: 0; batch classifier loss: 0.365886; batch adversarial loss: 0.625950\n",
      "epoch 148; iter: 0; batch classifier loss: 0.285789; batch adversarial loss: 0.551656\n",
      "epoch 149; iter: 0; batch classifier loss: 0.374681; batch adversarial loss: 0.515890\n",
      "epoch 150; iter: 0; batch classifier loss: 0.300405; batch adversarial loss: 0.497784\n",
      "epoch 151; iter: 0; batch classifier loss: 0.413680; batch adversarial loss: 0.507115\n",
      "epoch 152; iter: 0; batch classifier loss: 0.333171; batch adversarial loss: 0.626245\n",
      "epoch 153; iter: 0; batch classifier loss: 0.305759; batch adversarial loss: 0.537087\n",
      "epoch 154; iter: 0; batch classifier loss: 0.412666; batch adversarial loss: 0.563410\n",
      "epoch 155; iter: 0; batch classifier loss: 0.373915; batch adversarial loss: 0.555809\n",
      "epoch 156; iter: 0; batch classifier loss: 0.410194; batch adversarial loss: 0.563578\n",
      "epoch 157; iter: 0; batch classifier loss: 0.310639; batch adversarial loss: 0.536261\n",
      "epoch 158; iter: 0; batch classifier loss: 0.376596; batch adversarial loss: 0.580919\n",
      "epoch 159; iter: 0; batch classifier loss: 0.352949; batch adversarial loss: 0.526879\n",
      "epoch 160; iter: 0; batch classifier loss: 0.433610; batch adversarial loss: 0.519290\n",
      "epoch 161; iter: 0; batch classifier loss: 0.334416; batch adversarial loss: 0.564090\n",
      "epoch 162; iter: 0; batch classifier loss: 0.369946; batch adversarial loss: 0.588831\n",
      "epoch 163; iter: 0; batch classifier loss: 0.276959; batch adversarial loss: 0.551042\n",
      "epoch 164; iter: 0; batch classifier loss: 0.324417; batch adversarial loss: 0.569129\n",
      "epoch 165; iter: 0; batch classifier loss: 0.371954; batch adversarial loss: 0.561834\n",
      "epoch 166; iter: 0; batch classifier loss: 0.358627; batch adversarial loss: 0.563087\n",
      "epoch 167; iter: 0; batch classifier loss: 0.455842; batch adversarial loss: 0.508140\n",
      "epoch 168; iter: 0; batch classifier loss: 0.353746; batch adversarial loss: 0.534101\n",
      "epoch 169; iter: 0; batch classifier loss: 0.334948; batch adversarial loss: 0.526377\n",
      "epoch 170; iter: 0; batch classifier loss: 0.341500; batch adversarial loss: 0.504758\n",
      "epoch 171; iter: 0; batch classifier loss: 0.275758; batch adversarial loss: 0.599211\n",
      "epoch 172; iter: 0; batch classifier loss: 0.345600; batch adversarial loss: 0.525635\n",
      "epoch 173; iter: 0; batch classifier loss: 0.337654; batch adversarial loss: 0.526331\n",
      "epoch 174; iter: 0; batch classifier loss: 0.395103; batch adversarial loss: 0.497178\n",
      "epoch 175; iter: 0; batch classifier loss: 0.351507; batch adversarial loss: 0.562911\n",
      "epoch 176; iter: 0; batch classifier loss: 0.361858; batch adversarial loss: 0.526279\n",
      "epoch 177; iter: 0; batch classifier loss: 0.281194; batch adversarial loss: 0.507610\n",
      "epoch 178; iter: 0; batch classifier loss: 0.314623; batch adversarial loss: 0.562873\n",
      "epoch 179; iter: 0; batch classifier loss: 0.388594; batch adversarial loss: 0.526210\n",
      "epoch 180; iter: 0; batch classifier loss: 0.373859; batch adversarial loss: 0.599215\n",
      "epoch 181; iter: 0; batch classifier loss: 0.373199; batch adversarial loss: 0.542504\n",
      "epoch 182; iter: 0; batch classifier loss: 0.321452; batch adversarial loss: 0.526917\n",
      "epoch 183; iter: 0; batch classifier loss: 0.347205; batch adversarial loss: 0.598087\n",
      "epoch 184; iter: 0; batch classifier loss: 0.424470; batch adversarial loss: 0.571072\n",
      "epoch 185; iter: 0; batch classifier loss: 0.348994; batch adversarial loss: 0.526116\n",
      "epoch 186; iter: 0; batch classifier loss: 0.386728; batch adversarial loss: 0.562558\n",
      "epoch 187; iter: 0; batch classifier loss: 0.368107; batch adversarial loss: 0.577432\n",
      "epoch 188; iter: 0; batch classifier loss: 0.434456; batch adversarial loss: 0.517832\n",
      "epoch 189; iter: 0; batch classifier loss: 0.377054; batch adversarial loss: 0.534126\n",
      "epoch 190; iter: 0; batch classifier loss: 0.383198; batch adversarial loss: 0.554331\n",
      "epoch 191; iter: 0; batch classifier loss: 0.353870; batch adversarial loss: 0.554135\n",
      "epoch 192; iter: 0; batch classifier loss: 0.291149; batch adversarial loss: 0.570347\n",
      "epoch 193; iter: 0; batch classifier loss: 0.428086; batch adversarial loss: 0.581026\n",
      "epoch 194; iter: 0; batch classifier loss: 0.374812; batch adversarial loss: 0.487654\n",
      "epoch 195; iter: 0; batch classifier loss: 0.307664; batch adversarial loss: 0.469527\n",
      "epoch 196; iter: 0; batch classifier loss: 0.345563; batch adversarial loss: 0.609580\n",
      "epoch 197; iter: 0; batch classifier loss: 0.353787; batch adversarial loss: 0.589762\n",
      "epoch 198; iter: 0; batch classifier loss: 0.309288; batch adversarial loss: 0.572635\n",
      "epoch 199; iter: 0; batch classifier loss: 0.387354; batch adversarial loss: 0.600084\n",
      "epoch 0; iter: 0; batch classifier loss: 0.745896; batch adversarial loss: 0.825171\n",
      "epoch 1; iter: 0; batch classifier loss: 0.594129; batch adversarial loss: 0.783837\n",
      "epoch 2; iter: 0; batch classifier loss: 0.503435; batch adversarial loss: 0.700963\n",
      "epoch 3; iter: 0; batch classifier loss: 0.516574; batch adversarial loss: 0.709310\n",
      "epoch 4; iter: 0; batch classifier loss: 0.585073; batch adversarial loss: 0.671324\n",
      "epoch 5; iter: 0; batch classifier loss: 0.555646; batch adversarial loss: 0.654553\n",
      "epoch 6; iter: 0; batch classifier loss: 0.558364; batch adversarial loss: 0.640894\n",
      "epoch 7; iter: 0; batch classifier loss: 0.496228; batch adversarial loss: 0.628940\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8; iter: 0; batch classifier loss: 0.598987; batch adversarial loss: 0.575866\n",
      "epoch 9; iter: 0; batch classifier loss: 0.563555; batch adversarial loss: 0.579062\n",
      "epoch 10; iter: 0; batch classifier loss: 0.560973; batch adversarial loss: 0.593130\n",
      "epoch 11; iter: 0; batch classifier loss: 0.525200; batch adversarial loss: 0.600168\n",
      "epoch 12; iter: 0; batch classifier loss: 0.582486; batch adversarial loss: 0.589145\n",
      "epoch 13; iter: 0; batch classifier loss: 0.566989; batch adversarial loss: 0.564095\n",
      "epoch 14; iter: 0; batch classifier loss: 0.449385; batch adversarial loss: 0.610669\n",
      "epoch 15; iter: 0; batch classifier loss: 0.531102; batch adversarial loss: 0.544473\n",
      "epoch 16; iter: 0; batch classifier loss: 0.521886; batch adversarial loss: 0.575007\n",
      "epoch 17; iter: 0; batch classifier loss: 0.479148; batch adversarial loss: 0.547330\n",
      "epoch 18; iter: 0; batch classifier loss: 0.520312; batch adversarial loss: 0.534433\n",
      "epoch 19; iter: 0; batch classifier loss: 0.502127; batch adversarial loss: 0.560941\n",
      "epoch 20; iter: 0; batch classifier loss: 0.494702; batch adversarial loss: 0.506884\n",
      "epoch 21; iter: 0; batch classifier loss: 0.388113; batch adversarial loss: 0.587157\n",
      "epoch 22; iter: 0; batch classifier loss: 0.546742; batch adversarial loss: 0.578924\n",
      "epoch 23; iter: 0; batch classifier loss: 0.436631; batch adversarial loss: 0.587862\n",
      "epoch 24; iter: 0; batch classifier loss: 0.476928; batch adversarial loss: 0.591449\n",
      "epoch 25; iter: 0; batch classifier loss: 0.438369; batch adversarial loss: 0.562520\n",
      "epoch 26; iter: 0; batch classifier loss: 0.426083; batch adversarial loss: 0.572333\n",
      "epoch 27; iter: 0; batch classifier loss: 0.384419; batch adversarial loss: 0.595446\n",
      "epoch 28; iter: 0; batch classifier loss: 0.416445; batch adversarial loss: 0.555630\n",
      "epoch 29; iter: 0; batch classifier loss: 0.452224; batch adversarial loss: 0.528962\n",
      "epoch 30; iter: 0; batch classifier loss: 0.429220; batch adversarial loss: 0.547196\n",
      "epoch 31; iter: 0; batch classifier loss: 0.447149; batch adversarial loss: 0.533890\n",
      "epoch 32; iter: 0; batch classifier loss: 0.525126; batch adversarial loss: 0.515872\n",
      "epoch 33; iter: 0; batch classifier loss: 0.497981; batch adversarial loss: 0.591633\n",
      "epoch 34; iter: 0; batch classifier loss: 0.425874; batch adversarial loss: 0.571422\n",
      "epoch 35; iter: 0; batch classifier loss: 0.435962; batch adversarial loss: 0.571843\n",
      "epoch 36; iter: 0; batch classifier loss: 0.431114; batch adversarial loss: 0.545712\n",
      "epoch 37; iter: 0; batch classifier loss: 0.389255; batch adversarial loss: 0.524922\n",
      "epoch 38; iter: 0; batch classifier loss: 0.459483; batch adversarial loss: 0.538414\n",
      "epoch 39; iter: 0; batch classifier loss: 0.512193; batch adversarial loss: 0.652796\n",
      "epoch 40; iter: 0; batch classifier loss: 0.428889; batch adversarial loss: 0.527953\n",
      "epoch 41; iter: 0; batch classifier loss: 0.475955; batch adversarial loss: 0.560054\n",
      "epoch 42; iter: 0; batch classifier loss: 0.464978; batch adversarial loss: 0.587820\n",
      "epoch 43; iter: 0; batch classifier loss: 0.382240; batch adversarial loss: 0.562247\n",
      "epoch 44; iter: 0; batch classifier loss: 0.414652; batch adversarial loss: 0.561664\n",
      "epoch 45; iter: 0; batch classifier loss: 0.406543; batch adversarial loss: 0.611607\n",
      "epoch 46; iter: 0; batch classifier loss: 0.510931; batch adversarial loss: 0.568596\n",
      "epoch 47; iter: 0; batch classifier loss: 0.412008; batch adversarial loss: 0.552068\n",
      "epoch 48; iter: 0; batch classifier loss: 0.395499; batch adversarial loss: 0.548123\n",
      "epoch 49; iter: 0; batch classifier loss: 0.373100; batch adversarial loss: 0.519349\n",
      "epoch 50; iter: 0; batch classifier loss: 0.381773; batch adversarial loss: 0.553036\n",
      "epoch 51; iter: 0; batch classifier loss: 0.489016; batch adversarial loss: 0.535044\n",
      "epoch 52; iter: 0; batch classifier loss: 0.440877; batch adversarial loss: 0.570554\n",
      "epoch 53; iter: 0; batch classifier loss: 0.402348; batch adversarial loss: 0.546032\n",
      "epoch 54; iter: 0; batch classifier loss: 0.426558; batch adversarial loss: 0.571804\n",
      "epoch 55; iter: 0; batch classifier loss: 0.460001; batch adversarial loss: 0.606336\n",
      "epoch 56; iter: 0; batch classifier loss: 0.434222; batch adversarial loss: 0.528345\n",
      "epoch 57; iter: 0; batch classifier loss: 0.367795; batch adversarial loss: 0.579792\n",
      "epoch 58; iter: 0; batch classifier loss: 0.410297; batch adversarial loss: 0.554626\n",
      "epoch 59; iter: 0; batch classifier loss: 0.411878; batch adversarial loss: 0.438851\n",
      "epoch 60; iter: 0; batch classifier loss: 0.379871; batch adversarial loss: 0.605413\n",
      "epoch 61; iter: 0; batch classifier loss: 0.435238; batch adversarial loss: 0.507905\n",
      "epoch 62; iter: 0; batch classifier loss: 0.383831; batch adversarial loss: 0.524420\n",
      "epoch 63; iter: 0; batch classifier loss: 0.401949; batch adversarial loss: 0.597617\n",
      "epoch 64; iter: 0; batch classifier loss: 0.370523; batch adversarial loss: 0.518640\n",
      "epoch 65; iter: 0; batch classifier loss: 0.448315; batch adversarial loss: 0.556128\n",
      "epoch 66; iter: 0; batch classifier loss: 0.355070; batch adversarial loss: 0.501427\n",
      "epoch 67; iter: 0; batch classifier loss: 0.391617; batch adversarial loss: 0.626126\n",
      "epoch 68; iter: 0; batch classifier loss: 0.375815; batch adversarial loss: 0.562877\n",
      "epoch 69; iter: 0; batch classifier loss: 0.442589; batch adversarial loss: 0.555121\n",
      "epoch 70; iter: 0; batch classifier loss: 0.451060; batch adversarial loss: 0.615221\n",
      "epoch 71; iter: 0; batch classifier loss: 0.506905; batch adversarial loss: 0.520240\n",
      "epoch 72; iter: 0; batch classifier loss: 0.403408; batch adversarial loss: 0.598797\n",
      "epoch 73; iter: 0; batch classifier loss: 0.436941; batch adversarial loss: 0.597202\n",
      "epoch 74; iter: 0; batch classifier loss: 0.348976; batch adversarial loss: 0.548334\n",
      "epoch 75; iter: 0; batch classifier loss: 0.289199; batch adversarial loss: 0.582186\n",
      "epoch 76; iter: 0; batch classifier loss: 0.409969; batch adversarial loss: 0.617469\n",
      "epoch 77; iter: 0; batch classifier loss: 0.472733; batch adversarial loss: 0.534291\n",
      "epoch 78; iter: 0; batch classifier loss: 0.366295; batch adversarial loss: 0.551808\n",
      "epoch 79; iter: 0; batch classifier loss: 0.369184; batch adversarial loss: 0.509469\n",
      "epoch 80; iter: 0; batch classifier loss: 0.372960; batch adversarial loss: 0.583453\n",
      "epoch 81; iter: 0; batch classifier loss: 0.269728; batch adversarial loss: 0.533289\n",
      "epoch 82; iter: 0; batch classifier loss: 0.410486; batch adversarial loss: 0.464240\n",
      "epoch 83; iter: 0; batch classifier loss: 0.420848; batch adversarial loss: 0.572056\n",
      "epoch 84; iter: 0; batch classifier loss: 0.365081; batch adversarial loss: 0.557333\n",
      "epoch 85; iter: 0; batch classifier loss: 0.415234; batch adversarial loss: 0.624234\n",
      "epoch 86; iter: 0; batch classifier loss: 0.328686; batch adversarial loss: 0.534919\n",
      "epoch 87; iter: 0; batch classifier loss: 0.322585; batch adversarial loss: 0.531866\n",
      "epoch 88; iter: 0; batch classifier loss: 0.397558; batch adversarial loss: 0.596006\n",
      "epoch 89; iter: 0; batch classifier loss: 0.423818; batch adversarial loss: 0.622000\n",
      "epoch 90; iter: 0; batch classifier loss: 0.412353; batch adversarial loss: 0.615965\n",
      "epoch 91; iter: 0; batch classifier loss: 0.362082; batch adversarial loss: 0.528832\n",
      "epoch 92; iter: 0; batch classifier loss: 0.386252; batch adversarial loss: 0.613953\n",
      "epoch 93; iter: 0; batch classifier loss: 0.383832; batch adversarial loss: 0.497166\n",
      "epoch 94; iter: 0; batch classifier loss: 0.414204; batch adversarial loss: 0.580814\n",
      "epoch 95; iter: 0; batch classifier loss: 0.318905; batch adversarial loss: 0.561123\n",
      "epoch 96; iter: 0; batch classifier loss: 0.422261; batch adversarial loss: 0.609079\n",
      "epoch 97; iter: 0; batch classifier loss: 0.425802; batch adversarial loss: 0.580098\n",
      "epoch 98; iter: 0; batch classifier loss: 0.335245; batch adversarial loss: 0.483397\n",
      "epoch 99; iter: 0; batch classifier loss: 0.317868; batch adversarial loss: 0.537427\n",
      "epoch 100; iter: 0; batch classifier loss: 0.453274; batch adversarial loss: 0.500083\n",
      "epoch 101; iter: 0; batch classifier loss: 0.360973; batch adversarial loss: 0.563703\n",
      "epoch 102; iter: 0; batch classifier loss: 0.355637; batch adversarial loss: 0.553990\n",
      "epoch 103; iter: 0; batch classifier loss: 0.354299; batch adversarial loss: 0.687584\n",
      "epoch 104; iter: 0; batch classifier loss: 0.415420; batch adversarial loss: 0.656128\n",
      "epoch 105; iter: 0; batch classifier loss: 0.398893; batch adversarial loss: 0.588196\n",
      "epoch 106; iter: 0; batch classifier loss: 0.396326; batch adversarial loss: 0.494715\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 107; iter: 0; batch classifier loss: 0.498444; batch adversarial loss: 0.569353\n",
      "epoch 108; iter: 0; batch classifier loss: 0.318192; batch adversarial loss: 0.543740\n",
      "epoch 109; iter: 0; batch classifier loss: 0.415747; batch adversarial loss: 0.644016\n",
      "epoch 110; iter: 0; batch classifier loss: 0.361940; batch adversarial loss: 0.518377\n",
      "epoch 111; iter: 0; batch classifier loss: 0.355475; batch adversarial loss: 0.606721\n",
      "epoch 112; iter: 0; batch classifier loss: 0.352968; batch adversarial loss: 0.534893\n",
      "epoch 113; iter: 0; batch classifier loss: 0.310426; batch adversarial loss: 0.546281\n",
      "epoch 114; iter: 0; batch classifier loss: 0.372604; batch adversarial loss: 0.560160\n",
      "epoch 115; iter: 0; batch classifier loss: 0.425836; batch adversarial loss: 0.571843\n",
      "epoch 116; iter: 0; batch classifier loss: 0.407755; batch adversarial loss: 0.538622\n",
      "epoch 117; iter: 0; batch classifier loss: 0.325250; batch adversarial loss: 0.499436\n",
      "epoch 118; iter: 0; batch classifier loss: 0.426790; batch adversarial loss: 0.509281\n",
      "epoch 119; iter: 0; batch classifier loss: 0.381674; batch adversarial loss: 0.544476\n",
      "epoch 120; iter: 0; batch classifier loss: 0.361587; batch adversarial loss: 0.554023\n",
      "epoch 121; iter: 0; batch classifier loss: 0.394809; batch adversarial loss: 0.572552\n",
      "epoch 122; iter: 0; batch classifier loss: 0.406133; batch adversarial loss: 0.516554\n",
      "epoch 123; iter: 0; batch classifier loss: 0.372581; batch adversarial loss: 0.503220\n",
      "epoch 124; iter: 0; batch classifier loss: 0.312229; batch adversarial loss: 0.536279\n",
      "epoch 125; iter: 0; batch classifier loss: 0.359840; batch adversarial loss: 0.521229\n",
      "epoch 126; iter: 0; batch classifier loss: 0.388554; batch adversarial loss: 0.554960\n",
      "epoch 127; iter: 0; batch classifier loss: 0.380166; batch adversarial loss: 0.569610\n",
      "epoch 128; iter: 0; batch classifier loss: 0.391381; batch adversarial loss: 0.518048\n",
      "epoch 129; iter: 0; batch classifier loss: 0.388133; batch adversarial loss: 0.562209\n",
      "epoch 130; iter: 0; batch classifier loss: 0.316498; batch adversarial loss: 0.500570\n",
      "epoch 131; iter: 0; batch classifier loss: 0.375070; batch adversarial loss: 0.467943\n",
      "epoch 132; iter: 0; batch classifier loss: 0.395141; batch adversarial loss: 0.516582\n",
      "epoch 133; iter: 0; batch classifier loss: 0.311692; batch adversarial loss: 0.519220\n",
      "epoch 134; iter: 0; batch classifier loss: 0.441516; batch adversarial loss: 0.429517\n",
      "epoch 135; iter: 0; batch classifier loss: 0.430094; batch adversarial loss: 0.604824\n",
      "epoch 136; iter: 0; batch classifier loss: 0.364414; batch adversarial loss: 0.534300\n",
      "epoch 137; iter: 0; batch classifier loss: 0.367594; batch adversarial loss: 0.579080\n",
      "epoch 138; iter: 0; batch classifier loss: 0.421841; batch adversarial loss: 0.496230\n",
      "epoch 139; iter: 0; batch classifier loss: 0.416641; batch adversarial loss: 0.587644\n",
      "epoch 140; iter: 0; batch classifier loss: 0.345707; batch adversarial loss: 0.543381\n",
      "epoch 141; iter: 0; batch classifier loss: 0.393723; batch adversarial loss: 0.489756\n",
      "epoch 142; iter: 0; batch classifier loss: 0.304786; batch adversarial loss: 0.540149\n",
      "epoch 143; iter: 0; batch classifier loss: 0.338855; batch adversarial loss: 0.580008\n",
      "epoch 144; iter: 0; batch classifier loss: 0.381248; batch adversarial loss: 0.561596\n",
      "epoch 145; iter: 0; batch classifier loss: 0.346141; batch adversarial loss: 0.639847\n",
      "epoch 146; iter: 0; batch classifier loss: 0.351301; batch adversarial loss: 0.621852\n",
      "epoch 147; iter: 0; batch classifier loss: 0.337876; batch adversarial loss: 0.519081\n",
      "epoch 148; iter: 0; batch classifier loss: 0.391582; batch adversarial loss: 0.500922\n",
      "epoch 149; iter: 0; batch classifier loss: 0.351040; batch adversarial loss: 0.553907\n",
      "epoch 150; iter: 0; batch classifier loss: 0.354613; batch adversarial loss: 0.509151\n",
      "epoch 151; iter: 0; batch classifier loss: 0.408708; batch adversarial loss: 0.653693\n",
      "epoch 152; iter: 0; batch classifier loss: 0.350636; batch adversarial loss: 0.500115\n",
      "epoch 153; iter: 0; batch classifier loss: 0.429418; batch adversarial loss: 0.542214\n",
      "epoch 154; iter: 0; batch classifier loss: 0.350047; batch adversarial loss: 0.534410\n",
      "epoch 155; iter: 0; batch classifier loss: 0.427795; batch adversarial loss: 0.558715\n",
      "epoch 156; iter: 0; batch classifier loss: 0.406833; batch adversarial loss: 0.605317\n",
      "epoch 157; iter: 0; batch classifier loss: 0.296379; batch adversarial loss: 0.554492\n",
      "epoch 158; iter: 0; batch classifier loss: 0.386680; batch adversarial loss: 0.529561\n",
      "epoch 159; iter: 0; batch classifier loss: 0.391049; batch adversarial loss: 0.517872\n",
      "epoch 160; iter: 0; batch classifier loss: 0.345564; batch adversarial loss: 0.517650\n",
      "epoch 161; iter: 0; batch classifier loss: 0.410671; batch adversarial loss: 0.633351\n",
      "epoch 162; iter: 0; batch classifier loss: 0.364355; batch adversarial loss: 0.534455\n",
      "epoch 163; iter: 0; batch classifier loss: 0.315081; batch adversarial loss: 0.662218\n",
      "epoch 164; iter: 0; batch classifier loss: 0.375861; batch adversarial loss: 0.537875\n",
      "epoch 165; iter: 0; batch classifier loss: 0.299581; batch adversarial loss: 0.564867\n",
      "epoch 166; iter: 0; batch classifier loss: 0.333878; batch adversarial loss: 0.491584\n",
      "epoch 167; iter: 0; batch classifier loss: 0.342000; batch adversarial loss: 0.551526\n",
      "epoch 168; iter: 0; batch classifier loss: 0.441519; batch adversarial loss: 0.462452\n",
      "epoch 169; iter: 0; batch classifier loss: 0.275618; batch adversarial loss: 0.527936\n",
      "epoch 170; iter: 0; batch classifier loss: 0.330142; batch adversarial loss: 0.503016\n",
      "epoch 171; iter: 0; batch classifier loss: 0.313671; batch adversarial loss: 0.507964\n",
      "epoch 172; iter: 0; batch classifier loss: 0.306463; batch adversarial loss: 0.550981\n",
      "epoch 173; iter: 0; batch classifier loss: 0.330536; batch adversarial loss: 0.535042\n",
      "epoch 174; iter: 0; batch classifier loss: 0.359916; batch adversarial loss: 0.605184\n",
      "epoch 175; iter: 0; batch classifier loss: 0.412146; batch adversarial loss: 0.552385\n",
      "epoch 176; iter: 0; batch classifier loss: 0.320500; batch adversarial loss: 0.499556\n",
      "epoch 177; iter: 0; batch classifier loss: 0.334334; batch adversarial loss: 0.507411\n",
      "epoch 178; iter: 0; batch classifier loss: 0.302909; batch adversarial loss: 0.559945\n",
      "epoch 179; iter: 0; batch classifier loss: 0.402258; batch adversarial loss: 0.533391\n",
      "epoch 180; iter: 0; batch classifier loss: 0.374887; batch adversarial loss: 0.507085\n",
      "epoch 181; iter: 0; batch classifier loss: 0.331831; batch adversarial loss: 0.564687\n",
      "epoch 182; iter: 0; batch classifier loss: 0.337731; batch adversarial loss: 0.455997\n",
      "epoch 183; iter: 0; batch classifier loss: 0.375558; batch adversarial loss: 0.526683\n",
      "epoch 184; iter: 0; batch classifier loss: 0.409611; batch adversarial loss: 0.580691\n",
      "epoch 185; iter: 0; batch classifier loss: 0.390181; batch adversarial loss: 0.474834\n",
      "epoch 186; iter: 0; batch classifier loss: 0.331286; batch adversarial loss: 0.562605\n",
      "epoch 187; iter: 0; batch classifier loss: 0.382753; batch adversarial loss: 0.553924\n",
      "epoch 188; iter: 0; batch classifier loss: 0.393438; batch adversarial loss: 0.556093\n",
      "epoch 189; iter: 0; batch classifier loss: 0.339394; batch adversarial loss: 0.537343\n",
      "epoch 190; iter: 0; batch classifier loss: 0.342867; batch adversarial loss: 0.537166\n",
      "epoch 191; iter: 0; batch classifier loss: 0.323632; batch adversarial loss: 0.579596\n",
      "epoch 192; iter: 0; batch classifier loss: 0.398819; batch adversarial loss: 0.531349\n",
      "epoch 193; iter: 0; batch classifier loss: 0.301616; batch adversarial loss: 0.535353\n",
      "epoch 194; iter: 0; batch classifier loss: 0.335948; batch adversarial loss: 0.577975\n",
      "epoch 195; iter: 0; batch classifier loss: 0.339074; batch adversarial loss: 0.580501\n",
      "epoch 196; iter: 0; batch classifier loss: 0.319429; batch adversarial loss: 0.510920\n",
      "epoch 197; iter: 0; batch classifier loss: 0.304232; batch adversarial loss: 0.534682\n",
      "epoch 198; iter: 0; batch classifier loss: 0.423048; batch adversarial loss: 0.580485\n",
      "epoch 199; iter: 0; batch classifier loss: 0.296418; batch adversarial loss: 0.627759\n",
      "epoch 0; iter: 0; batch classifier loss: 0.762411; batch adversarial loss: 0.802081\n",
      "epoch 1; iter: 0; batch classifier loss: 0.586049; batch adversarial loss: 0.741582\n",
      "epoch 2; iter: 0; batch classifier loss: 0.593795; batch adversarial loss: 0.692404\n",
      "epoch 3; iter: 0; batch classifier loss: 0.610599; batch adversarial loss: 0.665948\n",
      "epoch 4; iter: 0; batch classifier loss: 0.600563; batch adversarial loss: 0.658774\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5; iter: 0; batch classifier loss: 0.589848; batch adversarial loss: 0.653336\n",
      "epoch 6; iter: 0; batch classifier loss: 0.551269; batch adversarial loss: 0.629834\n",
      "epoch 7; iter: 0; batch classifier loss: 0.544133; batch adversarial loss: 0.589500\n",
      "epoch 8; iter: 0; batch classifier loss: 0.541471; batch adversarial loss: 0.627365\n",
      "epoch 9; iter: 0; batch classifier loss: 0.545435; batch adversarial loss: 0.573140\n",
      "epoch 10; iter: 0; batch classifier loss: 0.505761; batch adversarial loss: 0.570571\n",
      "epoch 11; iter: 0; batch classifier loss: 0.572960; batch adversarial loss: 0.608790\n",
      "epoch 12; iter: 0; batch classifier loss: 0.485338; batch adversarial loss: 0.574853\n",
      "epoch 13; iter: 0; batch classifier loss: 0.539394; batch adversarial loss: 0.612257\n",
      "epoch 14; iter: 0; batch classifier loss: 0.498085; batch adversarial loss: 0.562997\n",
      "epoch 15; iter: 0; batch classifier loss: 0.522899; batch adversarial loss: 0.612238\n",
      "epoch 16; iter: 0; batch classifier loss: 0.528831; batch adversarial loss: 0.576026\n",
      "epoch 17; iter: 0; batch classifier loss: 0.481181; batch adversarial loss: 0.573146\n",
      "epoch 18; iter: 0; batch classifier loss: 0.460557; batch adversarial loss: 0.589979\n",
      "epoch 19; iter: 0; batch classifier loss: 0.502211; batch adversarial loss: 0.584446\n",
      "epoch 20; iter: 0; batch classifier loss: 0.513098; batch adversarial loss: 0.578158\n",
      "epoch 21; iter: 0; batch classifier loss: 0.514727; batch adversarial loss: 0.571339\n",
      "epoch 22; iter: 0; batch classifier loss: 0.423222; batch adversarial loss: 0.562509\n",
      "epoch 23; iter: 0; batch classifier loss: 0.426743; batch adversarial loss: 0.587354\n",
      "epoch 24; iter: 0; batch classifier loss: 0.522689; batch adversarial loss: 0.566996\n",
      "epoch 25; iter: 0; batch classifier loss: 0.493564; batch adversarial loss: 0.612240\n",
      "epoch 26; iter: 0; batch classifier loss: 0.539955; batch adversarial loss: 0.547456\n",
      "epoch 27; iter: 0; batch classifier loss: 0.464685; batch adversarial loss: 0.576832\n",
      "epoch 28; iter: 0; batch classifier loss: 0.465563; batch adversarial loss: 0.578331\n",
      "epoch 29; iter: 0; batch classifier loss: 0.468334; batch adversarial loss: 0.508796\n",
      "epoch 30; iter: 0; batch classifier loss: 0.480840; batch adversarial loss: 0.542430\n",
      "epoch 31; iter: 0; batch classifier loss: 0.446163; batch adversarial loss: 0.546308\n",
      "epoch 32; iter: 0; batch classifier loss: 0.500531; batch adversarial loss: 0.537553\n",
      "epoch 33; iter: 0; batch classifier loss: 0.531605; batch adversarial loss: 0.621137\n",
      "epoch 34; iter: 0; batch classifier loss: 0.406859; batch adversarial loss: 0.551939\n",
      "epoch 35; iter: 0; batch classifier loss: 0.474820; batch adversarial loss: 0.663484\n",
      "epoch 36; iter: 0; batch classifier loss: 0.452544; batch adversarial loss: 0.560974\n",
      "epoch 37; iter: 0; batch classifier loss: 0.445745; batch adversarial loss: 0.560349\n",
      "epoch 38; iter: 0; batch classifier loss: 0.534080; batch adversarial loss: 0.519132\n",
      "epoch 39; iter: 0; batch classifier loss: 0.392871; batch adversarial loss: 0.606853\n",
      "epoch 40; iter: 0; batch classifier loss: 0.522754; batch adversarial loss: 0.555040\n",
      "epoch 41; iter: 0; batch classifier loss: 0.432131; batch adversarial loss: 0.492340\n",
      "epoch 42; iter: 0; batch classifier loss: 0.415528; batch adversarial loss: 0.561721\n",
      "epoch 43; iter: 0; batch classifier loss: 0.425004; batch adversarial loss: 0.536618\n",
      "epoch 44; iter: 0; batch classifier loss: 0.439261; batch adversarial loss: 0.570443\n",
      "epoch 45; iter: 0; batch classifier loss: 0.408528; batch adversarial loss: 0.544453\n",
      "epoch 46; iter: 0; batch classifier loss: 0.401589; batch adversarial loss: 0.573257\n",
      "epoch 47; iter: 0; batch classifier loss: 0.436368; batch adversarial loss: 0.569637\n",
      "epoch 48; iter: 0; batch classifier loss: 0.393021; batch adversarial loss: 0.591344\n",
      "epoch 49; iter: 0; batch classifier loss: 0.441891; batch adversarial loss: 0.549918\n",
      "epoch 50; iter: 0; batch classifier loss: 0.364768; batch adversarial loss: 0.510404\n",
      "epoch 51; iter: 0; batch classifier loss: 0.350830; batch adversarial loss: 0.609283\n",
      "epoch 52; iter: 0; batch classifier loss: 0.451265; batch adversarial loss: 0.534647\n",
      "epoch 53; iter: 0; batch classifier loss: 0.480680; batch adversarial loss: 0.552827\n",
      "epoch 54; iter: 0; batch classifier loss: 0.423176; batch adversarial loss: 0.475075\n",
      "epoch 55; iter: 0; batch classifier loss: 0.375591; batch adversarial loss: 0.490743\n",
      "epoch 56; iter: 0; batch classifier loss: 0.377047; batch adversarial loss: 0.580649\n",
      "epoch 57; iter: 0; batch classifier loss: 0.448270; batch adversarial loss: 0.581622\n",
      "epoch 58; iter: 0; batch classifier loss: 0.355925; batch adversarial loss: 0.633860\n",
      "epoch 59; iter: 0; batch classifier loss: 0.489120; batch adversarial loss: 0.487896\n",
      "epoch 60; iter: 0; batch classifier loss: 0.377287; batch adversarial loss: 0.595307\n",
      "epoch 61; iter: 0; batch classifier loss: 0.383432; batch adversarial loss: 0.518689\n",
      "epoch 62; iter: 0; batch classifier loss: 0.359379; batch adversarial loss: 0.520847\n",
      "epoch 63; iter: 0; batch classifier loss: 0.465577; batch adversarial loss: 0.570248\n",
      "epoch 64; iter: 0; batch classifier loss: 0.478302; batch adversarial loss: 0.545502\n",
      "epoch 65; iter: 0; batch classifier loss: 0.483521; batch adversarial loss: 0.559330\n",
      "epoch 66; iter: 0; batch classifier loss: 0.379196; batch adversarial loss: 0.544900\n",
      "epoch 67; iter: 0; batch classifier loss: 0.522669; batch adversarial loss: 0.607403\n",
      "epoch 68; iter: 0; batch classifier loss: 0.448526; batch adversarial loss: 0.534966\n",
      "epoch 69; iter: 0; batch classifier loss: 0.442444; batch adversarial loss: 0.572630\n",
      "epoch 70; iter: 0; batch classifier loss: 0.412047; batch adversarial loss: 0.507385\n",
      "epoch 71; iter: 0; batch classifier loss: 0.494178; batch adversarial loss: 0.506974\n",
      "epoch 72; iter: 0; batch classifier loss: 0.405878; batch adversarial loss: 0.485523\n",
      "epoch 73; iter: 0; batch classifier loss: 0.401820; batch adversarial loss: 0.574290\n",
      "epoch 74; iter: 0; batch classifier loss: 0.406942; batch adversarial loss: 0.490838\n",
      "epoch 75; iter: 0; batch classifier loss: 0.345873; batch adversarial loss: 0.562478\n",
      "epoch 76; iter: 0; batch classifier loss: 0.403831; batch adversarial loss: 0.554730\n",
      "epoch 77; iter: 0; batch classifier loss: 0.335330; batch adversarial loss: 0.572518\n",
      "epoch 78; iter: 0; batch classifier loss: 0.418527; batch adversarial loss: 0.641626\n",
      "epoch 79; iter: 0; batch classifier loss: 0.447036; batch adversarial loss: 0.513907\n",
      "epoch 80; iter: 0; batch classifier loss: 0.406604; batch adversarial loss: 0.604231\n",
      "epoch 81; iter: 0; batch classifier loss: 0.421847; batch adversarial loss: 0.528614\n",
      "epoch 82; iter: 0; batch classifier loss: 0.467356; batch adversarial loss: 0.582014\n",
      "epoch 83; iter: 0; batch classifier loss: 0.372241; batch adversarial loss: 0.544552\n",
      "epoch 84; iter: 0; batch classifier loss: 0.419952; batch adversarial loss: 0.543982\n",
      "epoch 85; iter: 0; batch classifier loss: 0.407016; batch adversarial loss: 0.581511\n",
      "epoch 86; iter: 0; batch classifier loss: 0.392905; batch adversarial loss: 0.497321\n",
      "epoch 87; iter: 0; batch classifier loss: 0.405440; batch adversarial loss: 0.500256\n",
      "epoch 88; iter: 0; batch classifier loss: 0.406890; batch adversarial loss: 0.622053\n",
      "epoch 89; iter: 0; batch classifier loss: 0.375068; batch adversarial loss: 0.524693\n",
      "epoch 90; iter: 0; batch classifier loss: 0.330589; batch adversarial loss: 0.495831\n",
      "epoch 91; iter: 0; batch classifier loss: 0.407063; batch adversarial loss: 0.517619\n",
      "epoch 92; iter: 0; batch classifier loss: 0.441454; batch adversarial loss: 0.591211\n",
      "epoch 93; iter: 0; batch classifier loss: 0.368275; batch adversarial loss: 0.542456\n",
      "epoch 94; iter: 0; batch classifier loss: 0.398478; batch adversarial loss: 0.516434\n",
      "epoch 95; iter: 0; batch classifier loss: 0.374221; batch adversarial loss: 0.604735\n",
      "epoch 96; iter: 0; batch classifier loss: 0.511869; batch adversarial loss: 0.562884\n",
      "epoch 97; iter: 0; batch classifier loss: 0.462634; batch adversarial loss: 0.572042\n",
      "epoch 98; iter: 0; batch classifier loss: 0.398286; batch adversarial loss: 0.619475\n",
      "epoch 99; iter: 0; batch classifier loss: 0.407540; batch adversarial loss: 0.472925\n",
      "epoch 100; iter: 0; batch classifier loss: 0.428818; batch adversarial loss: 0.509360\n",
      "epoch 101; iter: 0; batch classifier loss: 0.304847; batch adversarial loss: 0.580220\n",
      "epoch 102; iter: 0; batch classifier loss: 0.383760; batch adversarial loss: 0.537050\n",
      "epoch 103; iter: 0; batch classifier loss: 0.371955; batch adversarial loss: 0.607888\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 104; iter: 0; batch classifier loss: 0.304410; batch adversarial loss: 0.605583\n",
      "epoch 105; iter: 0; batch classifier loss: 0.322278; batch adversarial loss: 0.556368\n",
      "epoch 106; iter: 0; batch classifier loss: 0.365744; batch adversarial loss: 0.508353\n",
      "epoch 107; iter: 0; batch classifier loss: 0.396263; batch adversarial loss: 0.572242\n",
      "epoch 108; iter: 0; batch classifier loss: 0.418894; batch adversarial loss: 0.532374\n",
      "epoch 109; iter: 0; batch classifier loss: 0.392069; batch adversarial loss: 0.597866\n",
      "epoch 110; iter: 0; batch classifier loss: 0.367037; batch adversarial loss: 0.597674\n",
      "epoch 111; iter: 0; batch classifier loss: 0.427047; batch adversarial loss: 0.529061\n",
      "epoch 112; iter: 0; batch classifier loss: 0.289529; batch adversarial loss: 0.506660\n",
      "epoch 113; iter: 0; batch classifier loss: 0.397985; batch adversarial loss: 0.545075\n",
      "epoch 114; iter: 0; batch classifier loss: 0.361129; batch adversarial loss: 0.490410\n",
      "epoch 115; iter: 0; batch classifier loss: 0.358753; batch adversarial loss: 0.517962\n",
      "epoch 116; iter: 0; batch classifier loss: 0.333846; batch adversarial loss: 0.607714\n",
      "epoch 117; iter: 0; batch classifier loss: 0.305300; batch adversarial loss: 0.588883\n",
      "epoch 118; iter: 0; batch classifier loss: 0.377040; batch adversarial loss: 0.528262\n",
      "epoch 119; iter: 0; batch classifier loss: 0.415348; batch adversarial loss: 0.540416\n",
      "epoch 120; iter: 0; batch classifier loss: 0.388919; batch adversarial loss: 0.572590\n",
      "epoch 121; iter: 0; batch classifier loss: 0.386156; batch adversarial loss: 0.584582\n",
      "epoch 122; iter: 0; batch classifier loss: 0.444841; batch adversarial loss: 0.465118\n",
      "epoch 123; iter: 0; batch classifier loss: 0.331199; batch adversarial loss: 0.547170\n",
      "epoch 124; iter: 0; batch classifier loss: 0.346338; batch adversarial loss: 0.587632\n",
      "epoch 125; iter: 0; batch classifier loss: 0.445516; batch adversarial loss: 0.544668\n",
      "epoch 126; iter: 0; batch classifier loss: 0.483782; batch adversarial loss: 0.507308\n",
      "epoch 127; iter: 0; batch classifier loss: 0.509210; batch adversarial loss: 0.525690\n",
      "epoch 128; iter: 0; batch classifier loss: 0.367873; batch adversarial loss: 0.620155\n",
      "epoch 129; iter: 0; batch classifier loss: 0.423019; batch adversarial loss: 0.532186\n",
      "epoch 130; iter: 0; batch classifier loss: 0.402996; batch adversarial loss: 0.535848\n",
      "epoch 131; iter: 0; batch classifier loss: 0.399154; batch adversarial loss: 0.608508\n",
      "epoch 132; iter: 0; batch classifier loss: 0.448767; batch adversarial loss: 0.510592\n",
      "epoch 133; iter: 0; batch classifier loss: 0.388714; batch adversarial loss: 0.687508\n",
      "epoch 134; iter: 0; batch classifier loss: 0.414981; batch adversarial loss: 0.545581\n",
      "epoch 135; iter: 0; batch classifier loss: 0.311156; batch adversarial loss: 0.598847\n",
      "epoch 136; iter: 0; batch classifier loss: 0.345794; batch adversarial loss: 0.542807\n",
      "epoch 137; iter: 0; batch classifier loss: 0.358164; batch adversarial loss: 0.488058\n",
      "epoch 138; iter: 0; batch classifier loss: 0.335000; batch adversarial loss: 0.505921\n",
      "epoch 139; iter: 0; batch classifier loss: 0.477613; batch adversarial loss: 0.488063\n",
      "epoch 140; iter: 0; batch classifier loss: 0.337230; batch adversarial loss: 0.508055\n",
      "epoch 141; iter: 0; batch classifier loss: 0.392431; batch adversarial loss: 0.556262\n",
      "epoch 142; iter: 0; batch classifier loss: 0.374001; batch adversarial loss: 0.545039\n",
      "epoch 143; iter: 0; batch classifier loss: 0.426335; batch adversarial loss: 0.445263\n",
      "epoch 144; iter: 0; batch classifier loss: 0.382907; batch adversarial loss: 0.483968\n",
      "epoch 145; iter: 0; batch classifier loss: 0.428227; batch adversarial loss: 0.542133\n",
      "epoch 146; iter: 0; batch classifier loss: 0.410653; batch adversarial loss: 0.551893\n",
      "epoch 147; iter: 0; batch classifier loss: 0.367330; batch adversarial loss: 0.590292\n",
      "epoch 148; iter: 0; batch classifier loss: 0.394508; batch adversarial loss: 0.523355\n",
      "epoch 149; iter: 0; batch classifier loss: 0.372789; batch adversarial loss: 0.604984\n",
      "epoch 150; iter: 0; batch classifier loss: 0.271266; batch adversarial loss: 0.533984\n",
      "epoch 151; iter: 0; batch classifier loss: 0.409157; batch adversarial loss: 0.518435\n",
      "epoch 152; iter: 0; batch classifier loss: 0.383516; batch adversarial loss: 0.545068\n",
      "epoch 153; iter: 0; batch classifier loss: 0.389432; batch adversarial loss: 0.551438\n",
      "epoch 154; iter: 0; batch classifier loss: 0.337230; batch adversarial loss: 0.548816\n",
      "epoch 155; iter: 0; batch classifier loss: 0.444849; batch adversarial loss: 0.529094\n",
      "epoch 156; iter: 0; batch classifier loss: 0.421858; batch adversarial loss: 0.564902\n",
      "epoch 157; iter: 0; batch classifier loss: 0.329390; batch adversarial loss: 0.489987\n",
      "epoch 158; iter: 0; batch classifier loss: 0.370715; batch adversarial loss: 0.552541\n",
      "epoch 159; iter: 0; batch classifier loss: 0.374073; batch adversarial loss: 0.570084\n",
      "epoch 160; iter: 0; batch classifier loss: 0.405973; batch adversarial loss: 0.507457\n",
      "epoch 161; iter: 0; batch classifier loss: 0.350867; batch adversarial loss: 0.533080\n",
      "epoch 162; iter: 0; batch classifier loss: 0.452869; batch adversarial loss: 0.452508\n",
      "epoch 163; iter: 0; batch classifier loss: 0.319912; batch adversarial loss: 0.555464\n",
      "epoch 164; iter: 0; batch classifier loss: 0.398103; batch adversarial loss: 0.519046\n",
      "epoch 165; iter: 0; batch classifier loss: 0.417087; batch adversarial loss: 0.558720\n",
      "epoch 166; iter: 0; batch classifier loss: 0.486449; batch adversarial loss: 0.566902\n",
      "epoch 167; iter: 0; batch classifier loss: 0.352197; batch adversarial loss: 0.506574\n",
      "epoch 168; iter: 0; batch classifier loss: 0.347589; batch adversarial loss: 0.635683\n",
      "epoch 169; iter: 0; batch classifier loss: 0.298022; batch adversarial loss: 0.579020\n",
      "epoch 170; iter: 0; batch classifier loss: 0.421806; batch adversarial loss: 0.516750\n",
      "epoch 171; iter: 0; batch classifier loss: 0.332981; batch adversarial loss: 0.631218\n",
      "epoch 172; iter: 0; batch classifier loss: 0.312156; batch adversarial loss: 0.591996\n",
      "epoch 173; iter: 0; batch classifier loss: 0.393066; batch adversarial loss: 0.579039\n",
      "epoch 174; iter: 0; batch classifier loss: 0.417149; batch adversarial loss: 0.532348\n",
      "epoch 175; iter: 0; batch classifier loss: 0.430245; batch adversarial loss: 0.583444\n",
      "epoch 176; iter: 0; batch classifier loss: 0.356628; batch adversarial loss: 0.508529\n",
      "epoch 177; iter: 0; batch classifier loss: 0.395915; batch adversarial loss: 0.590746\n",
      "epoch 178; iter: 0; batch classifier loss: 0.486343; batch adversarial loss: 0.578528\n",
      "epoch 179; iter: 0; batch classifier loss: 0.367248; batch adversarial loss: 0.480467\n",
      "epoch 180; iter: 0; batch classifier loss: 0.339388; batch adversarial loss: 0.561035\n",
      "epoch 181; iter: 0; batch classifier loss: 0.468842; batch adversarial loss: 0.588316\n",
      "epoch 182; iter: 0; batch classifier loss: 0.368572; batch adversarial loss: 0.570834\n",
      "epoch 183; iter: 0; batch classifier loss: 0.359862; batch adversarial loss: 0.508060\n",
      "epoch 184; iter: 0; batch classifier loss: 0.436992; batch adversarial loss: 0.508918\n",
      "epoch 185; iter: 0; batch classifier loss: 0.358114; batch adversarial loss: 0.542248\n",
      "epoch 186; iter: 0; batch classifier loss: 0.416530; batch adversarial loss: 0.472061\n",
      "epoch 187; iter: 0; batch classifier loss: 0.338702; batch adversarial loss: 0.561713\n",
      "epoch 188; iter: 0; batch classifier loss: 0.428204; batch adversarial loss: 0.552479\n",
      "epoch 189; iter: 0; batch classifier loss: 0.380970; batch adversarial loss: 0.528909\n",
      "epoch 190; iter: 0; batch classifier loss: 0.332394; batch adversarial loss: 0.509649\n",
      "epoch 191; iter: 0; batch classifier loss: 0.390492; batch adversarial loss: 0.551866\n",
      "epoch 192; iter: 0; batch classifier loss: 0.407352; batch adversarial loss: 0.526077\n",
      "epoch 193; iter: 0; batch classifier loss: 0.342927; batch adversarial loss: 0.596443\n",
      "epoch 194; iter: 0; batch classifier loss: 0.440226; batch adversarial loss: 0.572709\n",
      "epoch 195; iter: 0; batch classifier loss: 0.281877; batch adversarial loss: 0.536260\n",
      "epoch 196; iter: 0; batch classifier loss: 0.410976; batch adversarial loss: 0.525230\n",
      "epoch 197; iter: 0; batch classifier loss: 0.293336; batch adversarial loss: 0.592509\n",
      "epoch 198; iter: 0; batch classifier loss: 0.361643; batch adversarial loss: 0.549483\n",
      "epoch 199; iter: 0; batch classifier loss: 0.351788; batch adversarial loss: 0.543930\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.747674; batch adversarial loss: 0.719325\n",
      "epoch 1; iter: 0; batch classifier loss: 0.608847; batch adversarial loss: 0.688472\n",
      "epoch 2; iter: 0; batch classifier loss: 0.587810; batch adversarial loss: 0.653576\n",
      "epoch 3; iter: 0; batch classifier loss: 0.552745; batch adversarial loss: 0.613220\n",
      "epoch 4; iter: 0; batch classifier loss: 0.549587; batch adversarial loss: 0.610280\n",
      "epoch 5; iter: 0; batch classifier loss: 0.544309; batch adversarial loss: 0.577744\n",
      "epoch 6; iter: 0; batch classifier loss: 0.497137; batch adversarial loss: 0.576507\n",
      "epoch 7; iter: 0; batch classifier loss: 0.640359; batch adversarial loss: 0.586634\n",
      "epoch 8; iter: 0; batch classifier loss: 0.528896; batch adversarial loss: 0.570449\n",
      "epoch 9; iter: 0; batch classifier loss: 0.412262; batch adversarial loss: 0.588191\n",
      "epoch 10; iter: 0; batch classifier loss: 0.571109; batch adversarial loss: 0.615089\n",
      "epoch 11; iter: 0; batch classifier loss: 0.556374; batch adversarial loss: 0.594808\n",
      "epoch 12; iter: 0; batch classifier loss: 0.472516; batch adversarial loss: 0.587654\n",
      "epoch 13; iter: 0; batch classifier loss: 0.578422; batch adversarial loss: 0.566282\n",
      "epoch 14; iter: 0; batch classifier loss: 0.595011; batch adversarial loss: 0.676721\n",
      "epoch 15; iter: 0; batch classifier loss: 0.550000; batch adversarial loss: 0.613800\n",
      "epoch 16; iter: 0; batch classifier loss: 0.499968; batch adversarial loss: 0.571268\n",
      "epoch 17; iter: 0; batch classifier loss: 0.518612; batch adversarial loss: 0.564975\n",
      "epoch 18; iter: 0; batch classifier loss: 0.529600; batch adversarial loss: 0.544311\n",
      "epoch 19; iter: 0; batch classifier loss: 0.462628; batch adversarial loss: 0.536876\n",
      "epoch 20; iter: 0; batch classifier loss: 0.539714; batch adversarial loss: 0.549858\n",
      "epoch 21; iter: 0; batch classifier loss: 0.504817; batch adversarial loss: 0.596672\n",
      "epoch 22; iter: 0; batch classifier loss: 0.558765; batch adversarial loss: 0.580779\n",
      "epoch 23; iter: 0; batch classifier loss: 0.448667; batch adversarial loss: 0.621248\n",
      "epoch 24; iter: 0; batch classifier loss: 0.468232; batch adversarial loss: 0.544763\n",
      "epoch 25; iter: 0; batch classifier loss: 0.500341; batch adversarial loss: 0.566949\n",
      "epoch 26; iter: 0; batch classifier loss: 0.460994; batch adversarial loss: 0.581628\n",
      "epoch 27; iter: 0; batch classifier loss: 0.478992; batch adversarial loss: 0.587731\n",
      "epoch 28; iter: 0; batch classifier loss: 0.512973; batch adversarial loss: 0.518860\n",
      "epoch 29; iter: 0; batch classifier loss: 0.451142; batch adversarial loss: 0.516246\n",
      "epoch 30; iter: 0; batch classifier loss: 0.454933; batch adversarial loss: 0.554894\n",
      "epoch 31; iter: 0; batch classifier loss: 0.417536; batch adversarial loss: 0.570967\n",
      "epoch 32; iter: 0; batch classifier loss: 0.449668; batch adversarial loss: 0.579214\n",
      "epoch 33; iter: 0; batch classifier loss: 0.544961; batch adversarial loss: 0.544779\n",
      "epoch 34; iter: 0; batch classifier loss: 0.487536; batch adversarial loss: 0.561246\n",
      "epoch 35; iter: 0; batch classifier loss: 0.493533; batch adversarial loss: 0.629556\n",
      "epoch 36; iter: 0; batch classifier loss: 0.539944; batch adversarial loss: 0.607353\n",
      "epoch 37; iter: 0; batch classifier loss: 0.442434; batch adversarial loss: 0.518710\n",
      "epoch 38; iter: 0; batch classifier loss: 0.452985; batch adversarial loss: 0.553316\n",
      "epoch 39; iter: 0; batch classifier loss: 0.467506; batch adversarial loss: 0.571691\n",
      "epoch 40; iter: 0; batch classifier loss: 0.484540; batch adversarial loss: 0.536721\n",
      "epoch 41; iter: 0; batch classifier loss: 0.417227; batch adversarial loss: 0.527222\n",
      "epoch 42; iter: 0; batch classifier loss: 0.414692; batch adversarial loss: 0.546444\n",
      "epoch 43; iter: 0; batch classifier loss: 0.430807; batch adversarial loss: 0.554046\n",
      "epoch 44; iter: 0; batch classifier loss: 0.462277; batch adversarial loss: 0.622576\n",
      "epoch 45; iter: 0; batch classifier loss: 0.416256; batch adversarial loss: 0.528005\n",
      "epoch 46; iter: 0; batch classifier loss: 0.403865; batch adversarial loss: 0.580121\n",
      "epoch 47; iter: 0; batch classifier loss: 0.457616; batch adversarial loss: 0.561150\n",
      "epoch 48; iter: 0; batch classifier loss: 0.431679; batch adversarial loss: 0.561705\n",
      "epoch 49; iter: 0; batch classifier loss: 0.425678; batch adversarial loss: 0.632069\n",
      "epoch 50; iter: 0; batch classifier loss: 0.416382; batch adversarial loss: 0.606549\n",
      "epoch 51; iter: 0; batch classifier loss: 0.493593; batch adversarial loss: 0.501111\n",
      "epoch 52; iter: 0; batch classifier loss: 0.379893; batch adversarial loss: 0.598235\n",
      "epoch 53; iter: 0; batch classifier loss: 0.404970; batch adversarial loss: 0.544524\n",
      "epoch 54; iter: 0; batch classifier loss: 0.460234; batch adversarial loss: 0.484497\n",
      "epoch 55; iter: 0; batch classifier loss: 0.442741; batch adversarial loss: 0.561080\n",
      "epoch 56; iter: 0; batch classifier loss: 0.435320; batch adversarial loss: 0.588476\n",
      "epoch 57; iter: 0; batch classifier loss: 0.504558; batch adversarial loss: 0.537278\n",
      "epoch 58; iter: 0; batch classifier loss: 0.440275; batch adversarial loss: 0.518557\n",
      "epoch 59; iter: 0; batch classifier loss: 0.415007; batch adversarial loss: 0.474800\n",
      "epoch 60; iter: 0; batch classifier loss: 0.412538; batch adversarial loss: 0.537130\n",
      "epoch 61; iter: 0; batch classifier loss: 0.411559; batch adversarial loss: 0.598297\n",
      "epoch 62; iter: 0; batch classifier loss: 0.451458; batch adversarial loss: 0.588110\n",
      "epoch 63; iter: 0; batch classifier loss: 0.399555; batch adversarial loss: 0.518898\n",
      "epoch 64; iter: 0; batch classifier loss: 0.338137; batch adversarial loss: 0.554006\n",
      "epoch 65; iter: 0; batch classifier loss: 0.365651; batch adversarial loss: 0.518272\n",
      "epoch 66; iter: 0; batch classifier loss: 0.378500; batch adversarial loss: 0.510728\n",
      "epoch 67; iter: 0; batch classifier loss: 0.378606; batch adversarial loss: 0.536207\n",
      "epoch 68; iter: 0; batch classifier loss: 0.452117; batch adversarial loss: 0.632479\n",
      "epoch 69; iter: 0; batch classifier loss: 0.451720; batch adversarial loss: 0.519022\n",
      "epoch 70; iter: 0; batch classifier loss: 0.420458; batch adversarial loss: 0.596756\n",
      "epoch 71; iter: 0; batch classifier loss: 0.337876; batch adversarial loss: 0.597649\n",
      "epoch 72; iter: 0; batch classifier loss: 0.374560; batch adversarial loss: 0.596903\n",
      "epoch 73; iter: 0; batch classifier loss: 0.384407; batch adversarial loss: 0.596797\n",
      "epoch 74; iter: 0; batch classifier loss: 0.405515; batch adversarial loss: 0.544622\n",
      "epoch 75; iter: 0; batch classifier loss: 0.432484; batch adversarial loss: 0.570942\n",
      "epoch 76; iter: 0; batch classifier loss: 0.438160; batch adversarial loss: 0.527331\n",
      "epoch 77; iter: 0; batch classifier loss: 0.389903; batch adversarial loss: 0.527101\n",
      "epoch 78; iter: 0; batch classifier loss: 0.456347; batch adversarial loss: 0.580015\n",
      "epoch 79; iter: 0; batch classifier loss: 0.356473; batch adversarial loss: 0.622859\n",
      "epoch 80; iter: 0; batch classifier loss: 0.394798; batch adversarial loss: 0.545239\n",
      "epoch 81; iter: 0; batch classifier loss: 0.369522; batch adversarial loss: 0.553567\n",
      "epoch 82; iter: 0; batch classifier loss: 0.403094; batch adversarial loss: 0.570776\n",
      "epoch 83; iter: 0; batch classifier loss: 0.351558; batch adversarial loss: 0.605793\n",
      "epoch 84; iter: 0; batch classifier loss: 0.452735; batch adversarial loss: 0.562107\n",
      "epoch 85; iter: 0; batch classifier loss: 0.373421; batch adversarial loss: 0.527399\n",
      "epoch 86; iter: 0; batch classifier loss: 0.434278; batch adversarial loss: 0.493052\n",
      "epoch 87; iter: 0; batch classifier loss: 0.410146; batch adversarial loss: 0.597263\n",
      "epoch 88; iter: 0; batch classifier loss: 0.400940; batch adversarial loss: 0.544965\n",
      "epoch 89; iter: 0; batch classifier loss: 0.357133; batch adversarial loss: 0.632535\n",
      "epoch 90; iter: 0; batch classifier loss: 0.367343; batch adversarial loss: 0.553333\n",
      "epoch 91; iter: 0; batch classifier loss: 0.325528; batch adversarial loss: 0.501330\n",
      "epoch 92; iter: 0; batch classifier loss: 0.394168; batch adversarial loss: 0.614515\n",
      "epoch 93; iter: 0; batch classifier loss: 0.336865; batch adversarial loss: 0.588299\n",
      "epoch 94; iter: 0; batch classifier loss: 0.413196; batch adversarial loss: 0.484241\n",
      "epoch 95; iter: 0; batch classifier loss: 0.425942; batch adversarial loss: 0.492191\n",
      "epoch 96; iter: 0; batch classifier loss: 0.401755; batch adversarial loss: 0.483851\n",
      "epoch 97; iter: 0; batch classifier loss: 0.382819; batch adversarial loss: 0.571108\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 98; iter: 0; batch classifier loss: 0.383963; batch adversarial loss: 0.553717\n",
      "epoch 99; iter: 0; batch classifier loss: 0.398235; batch adversarial loss: 0.562622\n",
      "epoch 100; iter: 0; batch classifier loss: 0.380218; batch adversarial loss: 0.571185\n",
      "epoch 101; iter: 0; batch classifier loss: 0.321992; batch adversarial loss: 0.597329\n",
      "epoch 102; iter: 0; batch classifier loss: 0.387143; batch adversarial loss: 0.536197\n",
      "epoch 103; iter: 0; batch classifier loss: 0.427657; batch adversarial loss: 0.510045\n",
      "epoch 104; iter: 0; batch classifier loss: 0.424467; batch adversarial loss: 0.658523\n",
      "epoch 105; iter: 0; batch classifier loss: 0.369744; batch adversarial loss: 0.527137\n",
      "epoch 106; iter: 0; batch classifier loss: 0.365884; batch adversarial loss: 0.570420\n",
      "epoch 107; iter: 0; batch classifier loss: 0.449130; batch adversarial loss: 0.545429\n",
      "epoch 108; iter: 0; batch classifier loss: 0.397922; batch adversarial loss: 0.551931\n",
      "epoch 109; iter: 0; batch classifier loss: 0.368328; batch adversarial loss: 0.580102\n",
      "epoch 110; iter: 0; batch classifier loss: 0.481490; batch adversarial loss: 0.588031\n",
      "epoch 111; iter: 0; batch classifier loss: 0.472301; batch adversarial loss: 0.587253\n",
      "epoch 112; iter: 0; batch classifier loss: 0.465049; batch adversarial loss: 0.573091\n",
      "epoch 113; iter: 0; batch classifier loss: 0.396867; batch adversarial loss: 0.616414\n",
      "epoch 114; iter: 0; batch classifier loss: 0.403107; batch adversarial loss: 0.641550\n",
      "epoch 115; iter: 0; batch classifier loss: 0.381466; batch adversarial loss: 0.554275\n",
      "epoch 116; iter: 0; batch classifier loss: 0.345053; batch adversarial loss: 0.536251\n",
      "epoch 117; iter: 0; batch classifier loss: 0.422524; batch adversarial loss: 0.483301\n",
      "epoch 118; iter: 0; batch classifier loss: 0.362795; batch adversarial loss: 0.545321\n",
      "epoch 119; iter: 0; batch classifier loss: 0.345725; batch adversarial loss: 0.544929\n",
      "epoch 120; iter: 0; batch classifier loss: 0.349440; batch adversarial loss: 0.492424\n",
      "epoch 121; iter: 0; batch classifier loss: 0.362515; batch adversarial loss: 0.527562\n",
      "epoch 122; iter: 0; batch classifier loss: 0.319452; batch adversarial loss: 0.632325\n",
      "epoch 123; iter: 0; batch classifier loss: 0.468046; batch adversarial loss: 0.526847\n",
      "epoch 124; iter: 0; batch classifier loss: 0.352297; batch adversarial loss: 0.623535\n",
      "epoch 125; iter: 0; batch classifier loss: 0.441838; batch adversarial loss: 0.518695\n",
      "epoch 126; iter: 0; batch classifier loss: 0.396180; batch adversarial loss: 0.527178\n",
      "epoch 127; iter: 0; batch classifier loss: 0.378865; batch adversarial loss: 0.552891\n",
      "epoch 128; iter: 0; batch classifier loss: 0.343693; batch adversarial loss: 0.606145\n",
      "epoch 129; iter: 0; batch classifier loss: 0.402465; batch adversarial loss: 0.544659\n",
      "epoch 130; iter: 0; batch classifier loss: 0.488067; batch adversarial loss: 0.614373\n",
      "epoch 131; iter: 0; batch classifier loss: 0.394002; batch adversarial loss: 0.536031\n",
      "epoch 132; iter: 0; batch classifier loss: 0.360380; batch adversarial loss: 0.580263\n",
      "epoch 133; iter: 0; batch classifier loss: 0.419460; batch adversarial loss: 0.562185\n",
      "epoch 134; iter: 0; batch classifier loss: 0.361510; batch adversarial loss: 0.597729\n",
      "epoch 135; iter: 0; batch classifier loss: 0.379084; batch adversarial loss: 0.614525\n",
      "epoch 136; iter: 0; batch classifier loss: 0.401710; batch adversarial loss: 0.588194\n",
      "epoch 137; iter: 0; batch classifier loss: 0.332115; batch adversarial loss: 0.570974\n",
      "epoch 138; iter: 0; batch classifier loss: 0.389656; batch adversarial loss: 0.562367\n",
      "epoch 139; iter: 0; batch classifier loss: 0.422207; batch adversarial loss: 0.527368\n",
      "epoch 140; iter: 0; batch classifier loss: 0.474606; batch adversarial loss: 0.527512\n",
      "epoch 141; iter: 0; batch classifier loss: 0.401131; batch adversarial loss: 0.544879\n",
      "epoch 142; iter: 0; batch classifier loss: 0.320417; batch adversarial loss: 0.631908\n",
      "epoch 143; iter: 0; batch classifier loss: 0.391772; batch adversarial loss: 0.510619\n",
      "epoch 144; iter: 0; batch classifier loss: 0.356262; batch adversarial loss: 0.614330\n",
      "epoch 145; iter: 0; batch classifier loss: 0.342088; batch adversarial loss: 0.588316\n",
      "epoch 146; iter: 0; batch classifier loss: 0.347170; batch adversarial loss: 0.553676\n",
      "epoch 147; iter: 0; batch classifier loss: 0.361866; batch adversarial loss: 0.509610\n",
      "epoch 148; iter: 0; batch classifier loss: 0.397852; batch adversarial loss: 0.553797\n",
      "epoch 149; iter: 0; batch classifier loss: 0.395703; batch adversarial loss: 0.623203\n",
      "epoch 150; iter: 0; batch classifier loss: 0.345579; batch adversarial loss: 0.553919\n",
      "epoch 151; iter: 0; batch classifier loss: 0.354037; batch adversarial loss: 0.543991\n",
      "epoch 152; iter: 0; batch classifier loss: 0.411204; batch adversarial loss: 0.579518\n",
      "epoch 153; iter: 0; batch classifier loss: 0.438896; batch adversarial loss: 0.472956\n",
      "epoch 154; iter: 0; batch classifier loss: 0.342860; batch adversarial loss: 0.509849\n",
      "epoch 155; iter: 0; batch classifier loss: 0.341547; batch adversarial loss: 0.516684\n",
      "epoch 156; iter: 0; batch classifier loss: 0.452105; batch adversarial loss: 0.633732\n",
      "epoch 157; iter: 0; batch classifier loss: 0.342093; batch adversarial loss: 0.602867\n",
      "epoch 158; iter: 0; batch classifier loss: 0.435242; batch adversarial loss: 0.603840\n",
      "epoch 159; iter: 0; batch classifier loss: 0.332312; batch adversarial loss: 0.542566\n",
      "epoch 160; iter: 0; batch classifier loss: 0.414202; batch adversarial loss: 0.525577\n",
      "epoch 161; iter: 0; batch classifier loss: 0.311097; batch adversarial loss: 0.683041\n",
      "epoch 162; iter: 0; batch classifier loss: 0.387823; batch adversarial loss: 0.472071\n",
      "epoch 163; iter: 0; batch classifier loss: 0.307024; batch adversarial loss: 0.501285\n",
      "epoch 164; iter: 0; batch classifier loss: 0.312315; batch adversarial loss: 0.518497\n",
      "epoch 165; iter: 0; batch classifier loss: 0.350117; batch adversarial loss: 0.608145\n",
      "epoch 166; iter: 0; batch classifier loss: 0.408834; batch adversarial loss: 0.578267\n",
      "epoch 167; iter: 0; batch classifier loss: 0.397469; batch adversarial loss: 0.648090\n",
      "epoch 168; iter: 0; batch classifier loss: 0.351161; batch adversarial loss: 0.588721\n",
      "epoch 169; iter: 0; batch classifier loss: 0.445876; batch adversarial loss: 0.622720\n",
      "epoch 170; iter: 0; batch classifier loss: 0.349123; batch adversarial loss: 0.571034\n",
      "epoch 171; iter: 0; batch classifier loss: 0.369666; batch adversarial loss: 0.571805\n",
      "epoch 172; iter: 0; batch classifier loss: 0.406377; batch adversarial loss: 0.510855\n",
      "epoch 173; iter: 0; batch classifier loss: 0.287321; batch adversarial loss: 0.580884\n",
      "epoch 174; iter: 0; batch classifier loss: 0.314789; batch adversarial loss: 0.537189\n",
      "epoch 175; iter: 0; batch classifier loss: 0.437712; batch adversarial loss: 0.546018\n",
      "epoch 176; iter: 0; batch classifier loss: 0.346033; batch adversarial loss: 0.562636\n",
      "epoch 177; iter: 0; batch classifier loss: 0.409896; batch adversarial loss: 0.502576\n",
      "epoch 178; iter: 0; batch classifier loss: 0.397954; batch adversarial loss: 0.536908\n",
      "epoch 179; iter: 0; batch classifier loss: 0.351540; batch adversarial loss: 0.571053\n",
      "epoch 180; iter: 0; batch classifier loss: 0.352582; batch adversarial loss: 0.544762\n",
      "epoch 181; iter: 0; batch classifier loss: 0.379103; batch adversarial loss: 0.579584\n",
      "epoch 182; iter: 0; batch classifier loss: 0.364543; batch adversarial loss: 0.527378\n",
      "epoch 183; iter: 0; batch classifier loss: 0.385371; batch adversarial loss: 0.588568\n",
      "epoch 184; iter: 0; batch classifier loss: 0.355173; batch adversarial loss: 0.701261\n",
      "epoch 185; iter: 0; batch classifier loss: 0.405637; batch adversarial loss: 0.597178\n",
      "epoch 186; iter: 0; batch classifier loss: 0.375693; batch adversarial loss: 0.640151\n",
      "epoch 187; iter: 0; batch classifier loss: 0.301305; batch adversarial loss: 0.614186\n",
      "epoch 188; iter: 0; batch classifier loss: 0.292548; batch adversarial loss: 0.527734\n",
      "epoch 189; iter: 0; batch classifier loss: 0.401076; batch adversarial loss: 0.527694\n",
      "epoch 190; iter: 0; batch classifier loss: 0.327682; batch adversarial loss: 0.536174\n",
      "epoch 191; iter: 0; batch classifier loss: 0.335626; batch adversarial loss: 0.701952\n",
      "epoch 192; iter: 0; batch classifier loss: 0.385342; batch adversarial loss: 0.579862\n",
      "epoch 193; iter: 0; batch classifier loss: 0.338575; batch adversarial loss: 0.553576\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 194; iter: 0; batch classifier loss: 0.372361; batch adversarial loss: 0.527387\n",
      "epoch 195; iter: 0; batch classifier loss: 0.348019; batch adversarial loss: 0.536193\n",
      "epoch 196; iter: 0; batch classifier loss: 0.397229; batch adversarial loss: 0.527783\n",
      "epoch 197; iter: 0; batch classifier loss: 0.337248; batch adversarial loss: 0.605852\n",
      "epoch 198; iter: 0; batch classifier loss: 0.418697; batch adversarial loss: 0.571373\n",
      "epoch 199; iter: 0; batch classifier loss: 0.349751; batch adversarial loss: 0.597512\n",
      "epoch 0; iter: 0; batch classifier loss: 0.677283; batch adversarial loss: 0.646755\n",
      "epoch 1; iter: 0; batch classifier loss: 0.597677; batch adversarial loss: 0.642952\n",
      "epoch 2; iter: 0; batch classifier loss: 0.517667; batch adversarial loss: 0.633883\n",
      "epoch 3; iter: 0; batch classifier loss: 0.513318; batch adversarial loss: 0.634823\n",
      "epoch 4; iter: 0; batch classifier loss: 0.575506; batch adversarial loss: 0.614008\n",
      "epoch 5; iter: 0; batch classifier loss: 0.525937; batch adversarial loss: 0.589505\n",
      "epoch 6; iter: 0; batch classifier loss: 0.509964; batch adversarial loss: 0.633549\n",
      "epoch 7; iter: 0; batch classifier loss: 0.554437; batch adversarial loss: 0.631546\n",
      "epoch 8; iter: 0; batch classifier loss: 0.580614; batch adversarial loss: 0.608096\n",
      "epoch 9; iter: 0; batch classifier loss: 0.547757; batch adversarial loss: 0.550947\n",
      "epoch 10; iter: 0; batch classifier loss: 0.652220; batch adversarial loss: 0.593573\n",
      "epoch 11; iter: 0; batch classifier loss: 0.507665; batch adversarial loss: 0.557290\n",
      "epoch 12; iter: 0; batch classifier loss: 0.480810; batch adversarial loss: 0.578046\n",
      "epoch 13; iter: 0; batch classifier loss: 0.444382; batch adversarial loss: 0.584209\n",
      "epoch 14; iter: 0; batch classifier loss: 0.527646; batch adversarial loss: 0.555852\n",
      "epoch 15; iter: 0; batch classifier loss: 0.514862; batch adversarial loss: 0.626298\n",
      "epoch 16; iter: 0; batch classifier loss: 0.449458; batch adversarial loss: 0.558979\n",
      "epoch 17; iter: 0; batch classifier loss: 0.522756; batch adversarial loss: 0.556973\n",
      "epoch 18; iter: 0; batch classifier loss: 0.513706; batch adversarial loss: 0.601285\n",
      "epoch 19; iter: 0; batch classifier loss: 0.568022; batch adversarial loss: 0.551405\n",
      "epoch 20; iter: 0; batch classifier loss: 0.523449; batch adversarial loss: 0.526128\n",
      "epoch 21; iter: 0; batch classifier loss: 0.517654; batch adversarial loss: 0.521294\n",
      "epoch 22; iter: 0; batch classifier loss: 0.432506; batch adversarial loss: 0.512408\n",
      "epoch 23; iter: 0; batch classifier loss: 0.459732; batch adversarial loss: 0.503823\n",
      "epoch 24; iter: 0; batch classifier loss: 0.410957; batch adversarial loss: 0.580447\n",
      "epoch 25; iter: 0; batch classifier loss: 0.491224; batch adversarial loss: 0.596405\n",
      "epoch 26; iter: 0; batch classifier loss: 0.484866; batch adversarial loss: 0.571709\n",
      "epoch 27; iter: 0; batch classifier loss: 0.459359; batch adversarial loss: 0.586862\n",
      "epoch 28; iter: 0; batch classifier loss: 0.558010; batch adversarial loss: 0.530177\n",
      "epoch 29; iter: 0; batch classifier loss: 0.443941; batch adversarial loss: 0.612507\n",
      "epoch 30; iter: 0; batch classifier loss: 0.445054; batch adversarial loss: 0.520621\n",
      "epoch 31; iter: 0; batch classifier loss: 0.491528; batch adversarial loss: 0.578737\n",
      "epoch 32; iter: 0; batch classifier loss: 0.402842; batch adversarial loss: 0.470618\n",
      "epoch 33; iter: 0; batch classifier loss: 0.435270; batch adversarial loss: 0.596495\n",
      "epoch 34; iter: 0; batch classifier loss: 0.404278; batch adversarial loss: 0.502986\n",
      "epoch 35; iter: 0; batch classifier loss: 0.436561; batch adversarial loss: 0.578320\n",
      "epoch 36; iter: 0; batch classifier loss: 0.437729; batch adversarial loss: 0.520043\n",
      "epoch 37; iter: 0; batch classifier loss: 0.434754; batch adversarial loss: 0.545471\n",
      "epoch 38; iter: 0; batch classifier loss: 0.479173; batch adversarial loss: 0.580417\n",
      "epoch 39; iter: 0; batch classifier loss: 0.435852; batch adversarial loss: 0.545003\n",
      "epoch 40; iter: 0; batch classifier loss: 0.458493; batch adversarial loss: 0.483484\n",
      "epoch 41; iter: 0; batch classifier loss: 0.433446; batch adversarial loss: 0.570741\n",
      "epoch 42; iter: 0; batch classifier loss: 0.433136; batch adversarial loss: 0.648721\n",
      "epoch 43; iter: 0; batch classifier loss: 0.478190; batch adversarial loss: 0.568617\n",
      "epoch 44; iter: 0; batch classifier loss: 0.433616; batch adversarial loss: 0.534765\n",
      "epoch 45; iter: 0; batch classifier loss: 0.431686; batch adversarial loss: 0.535716\n",
      "epoch 46; iter: 0; batch classifier loss: 0.412190; batch adversarial loss: 0.561033\n",
      "epoch 47; iter: 0; batch classifier loss: 0.450650; batch adversarial loss: 0.607523\n",
      "epoch 48; iter: 0; batch classifier loss: 0.457580; batch adversarial loss: 0.552381\n",
      "epoch 49; iter: 0; batch classifier loss: 0.411462; batch adversarial loss: 0.572237\n",
      "epoch 50; iter: 0; batch classifier loss: 0.392429; batch adversarial loss: 0.652178\n",
      "epoch 51; iter: 0; batch classifier loss: 0.457394; batch adversarial loss: 0.569914\n",
      "epoch 52; iter: 0; batch classifier loss: 0.414569; batch adversarial loss: 0.580840\n",
      "epoch 53; iter: 0; batch classifier loss: 0.433794; batch adversarial loss: 0.493292\n",
      "epoch 54; iter: 0; batch classifier loss: 0.450440; batch adversarial loss: 0.579412\n",
      "epoch 55; iter: 0; batch classifier loss: 0.448496; batch adversarial loss: 0.532531\n",
      "epoch 56; iter: 0; batch classifier loss: 0.369135; batch adversarial loss: 0.542317\n",
      "epoch 57; iter: 0; batch classifier loss: 0.497483; batch adversarial loss: 0.581321\n",
      "epoch 58; iter: 0; batch classifier loss: 0.458364; batch adversarial loss: 0.544852\n",
      "epoch 59; iter: 0; batch classifier loss: 0.433803; batch adversarial loss: 0.552277\n",
      "epoch 60; iter: 0; batch classifier loss: 0.451221; batch adversarial loss: 0.591145\n",
      "epoch 61; iter: 0; batch classifier loss: 0.409932; batch adversarial loss: 0.559498\n",
      "epoch 62; iter: 0; batch classifier loss: 0.359076; batch adversarial loss: 0.518980\n",
      "epoch 63; iter: 0; batch classifier loss: 0.361175; batch adversarial loss: 0.537070\n",
      "epoch 64; iter: 0; batch classifier loss: 0.365474; batch adversarial loss: 0.527020\n",
      "epoch 65; iter: 0; batch classifier loss: 0.440646; batch adversarial loss: 0.454720\n",
      "epoch 66; iter: 0; batch classifier loss: 0.396476; batch adversarial loss: 0.598575\n",
      "epoch 67; iter: 0; batch classifier loss: 0.380967; batch adversarial loss: 0.589125\n",
      "epoch 68; iter: 0; batch classifier loss: 0.443473; batch adversarial loss: 0.579504\n",
      "epoch 69; iter: 0; batch classifier loss: 0.390463; batch adversarial loss: 0.510919\n",
      "epoch 70; iter: 0; batch classifier loss: 0.418616; batch adversarial loss: 0.563646\n",
      "epoch 71; iter: 0; batch classifier loss: 0.380652; batch adversarial loss: 0.571663\n",
      "epoch 72; iter: 0; batch classifier loss: 0.356784; batch adversarial loss: 0.526095\n",
      "epoch 73; iter: 0; batch classifier loss: 0.451751; batch adversarial loss: 0.582364\n",
      "epoch 74; iter: 0; batch classifier loss: 0.402392; batch adversarial loss: 0.493257\n",
      "epoch 75; iter: 0; batch classifier loss: 0.377667; batch adversarial loss: 0.501165\n",
      "epoch 76; iter: 0; batch classifier loss: 0.393374; batch adversarial loss: 0.579067\n",
      "epoch 77; iter: 0; batch classifier loss: 0.411397; batch adversarial loss: 0.588216\n",
      "epoch 78; iter: 0; batch classifier loss: 0.449893; batch adversarial loss: 0.647776\n",
      "epoch 79; iter: 0; batch classifier loss: 0.416311; batch adversarial loss: 0.596372\n",
      "epoch 80; iter: 0; batch classifier loss: 0.409554; batch adversarial loss: 0.559239\n",
      "epoch 81; iter: 0; batch classifier loss: 0.434763; batch adversarial loss: 0.519447\n",
      "epoch 82; iter: 0; batch classifier loss: 0.422422; batch adversarial loss: 0.599084\n",
      "epoch 83; iter: 0; batch classifier loss: 0.403598; batch adversarial loss: 0.575442\n",
      "epoch 84; iter: 0; batch classifier loss: 0.413951; batch adversarial loss: 0.571931\n",
      "epoch 85; iter: 0; batch classifier loss: 0.328569; batch adversarial loss: 0.543695\n",
      "epoch 86; iter: 0; batch classifier loss: 0.413452; batch adversarial loss: 0.554000\n",
      "epoch 87; iter: 0; batch classifier loss: 0.352210; batch adversarial loss: 0.531002\n",
      "epoch 88; iter: 0; batch classifier loss: 0.338854; batch adversarial loss: 0.539110\n",
      "epoch 89; iter: 0; batch classifier loss: 0.363537; batch adversarial loss: 0.554217\n",
      "epoch 90; iter: 0; batch classifier loss: 0.377069; batch adversarial loss: 0.537971\n",
      "epoch 91; iter: 0; batch classifier loss: 0.383170; batch adversarial loss: 0.584033\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 92; iter: 0; batch classifier loss: 0.354468; batch adversarial loss: 0.508245\n",
      "epoch 93; iter: 0; batch classifier loss: 0.349185; batch adversarial loss: 0.597880\n",
      "epoch 94; iter: 0; batch classifier loss: 0.421558; batch adversarial loss: 0.571956\n",
      "epoch 95; iter: 0; batch classifier loss: 0.382662; batch adversarial loss: 0.521945\n",
      "epoch 96; iter: 0; batch classifier loss: 0.362758; batch adversarial loss: 0.612754\n",
      "epoch 97; iter: 0; batch classifier loss: 0.422565; batch adversarial loss: 0.570787\n",
      "epoch 98; iter: 0; batch classifier loss: 0.305216; batch adversarial loss: 0.562226\n",
      "epoch 99; iter: 0; batch classifier loss: 0.381119; batch adversarial loss: 0.643227\n",
      "epoch 100; iter: 0; batch classifier loss: 0.379274; batch adversarial loss: 0.560787\n",
      "epoch 101; iter: 0; batch classifier loss: 0.463704; batch adversarial loss: 0.545551\n",
      "epoch 102; iter: 0; batch classifier loss: 0.314083; batch adversarial loss: 0.588892\n",
      "epoch 103; iter: 0; batch classifier loss: 0.386451; batch adversarial loss: 0.588924\n",
      "epoch 104; iter: 0; batch classifier loss: 0.301908; batch adversarial loss: 0.588133\n",
      "epoch 105; iter: 0; batch classifier loss: 0.327629; batch adversarial loss: 0.560667\n",
      "epoch 106; iter: 0; batch classifier loss: 0.352831; batch adversarial loss: 0.586920\n",
      "epoch 107; iter: 0; batch classifier loss: 0.400191; batch adversarial loss: 0.561179\n",
      "epoch 108; iter: 0; batch classifier loss: 0.377631; batch adversarial loss: 0.562347\n",
      "epoch 109; iter: 0; batch classifier loss: 0.466095; batch adversarial loss: 0.553329\n",
      "epoch 110; iter: 0; batch classifier loss: 0.353476; batch adversarial loss: 0.537079\n",
      "epoch 111; iter: 0; batch classifier loss: 0.362325; batch adversarial loss: 0.544750\n",
      "epoch 112; iter: 0; batch classifier loss: 0.379383; batch adversarial loss: 0.456447\n",
      "epoch 113; iter: 0; batch classifier loss: 0.384534; batch adversarial loss: 0.595876\n",
      "epoch 114; iter: 0; batch classifier loss: 0.418198; batch adversarial loss: 0.529237\n",
      "epoch 115; iter: 0; batch classifier loss: 0.339581; batch adversarial loss: 0.526281\n",
      "epoch 116; iter: 0; batch classifier loss: 0.416927; batch adversarial loss: 0.588092\n",
      "epoch 117; iter: 0; batch classifier loss: 0.446895; batch adversarial loss: 0.526835\n",
      "epoch 118; iter: 0; batch classifier loss: 0.391361; batch adversarial loss: 0.590308\n",
      "epoch 119; iter: 0; batch classifier loss: 0.381398; batch adversarial loss: 0.508830\n",
      "epoch 120; iter: 0; batch classifier loss: 0.418482; batch adversarial loss: 0.562440\n",
      "epoch 121; iter: 0; batch classifier loss: 0.314108; batch adversarial loss: 0.552261\n",
      "epoch 122; iter: 0; batch classifier loss: 0.460521; batch adversarial loss: 0.570747\n",
      "epoch 123; iter: 0; batch classifier loss: 0.351149; batch adversarial loss: 0.526004\n",
      "epoch 124; iter: 0; batch classifier loss: 0.353521; batch adversarial loss: 0.589089\n",
      "epoch 125; iter: 0; batch classifier loss: 0.421330; batch adversarial loss: 0.547024\n",
      "epoch 126; iter: 0; batch classifier loss: 0.414639; batch adversarial loss: 0.527340\n",
      "epoch 127; iter: 0; batch classifier loss: 0.371865; batch adversarial loss: 0.591550\n",
      "epoch 128; iter: 0; batch classifier loss: 0.387573; batch adversarial loss: 0.528923\n",
      "epoch 129; iter: 0; batch classifier loss: 0.319986; batch adversarial loss: 0.562584\n",
      "epoch 130; iter: 0; batch classifier loss: 0.360215; batch adversarial loss: 0.529061\n",
      "epoch 131; iter: 0; batch classifier loss: 0.416984; batch adversarial loss: 0.588120\n",
      "epoch 132; iter: 0; batch classifier loss: 0.372326; batch adversarial loss: 0.542860\n",
      "epoch 133; iter: 0; batch classifier loss: 0.332671; batch adversarial loss: 0.571270\n",
      "epoch 134; iter: 0; batch classifier loss: 0.351659; batch adversarial loss: 0.552962\n",
      "epoch 135; iter: 0; batch classifier loss: 0.386324; batch adversarial loss: 0.597947\n",
      "epoch 136; iter: 0; batch classifier loss: 0.383124; batch adversarial loss: 0.579105\n",
      "epoch 137; iter: 0; batch classifier loss: 0.384429; batch adversarial loss: 0.534425\n",
      "epoch 138; iter: 0; batch classifier loss: 0.318507; batch adversarial loss: 0.590970\n",
      "epoch 139; iter: 0; batch classifier loss: 0.348157; batch adversarial loss: 0.591509\n",
      "epoch 140; iter: 0; batch classifier loss: 0.379788; batch adversarial loss: 0.520841\n",
      "epoch 141; iter: 0; batch classifier loss: 0.424871; batch adversarial loss: 0.491225\n",
      "epoch 142; iter: 0; batch classifier loss: 0.358745; batch adversarial loss: 0.544317\n",
      "epoch 143; iter: 0; batch classifier loss: 0.402358; batch adversarial loss: 0.615240\n",
      "epoch 144; iter: 0; batch classifier loss: 0.371798; batch adversarial loss: 0.483701\n",
      "epoch 145; iter: 0; batch classifier loss: 0.387529; batch adversarial loss: 0.536968\n",
      "epoch 146; iter: 0; batch classifier loss: 0.317757; batch adversarial loss: 0.541891\n",
      "epoch 147; iter: 0; batch classifier loss: 0.403851; batch adversarial loss: 0.598908\n",
      "epoch 148; iter: 0; batch classifier loss: 0.349657; batch adversarial loss: 0.590594\n",
      "epoch 149; iter: 0; batch classifier loss: 0.405157; batch adversarial loss: 0.590958\n",
      "epoch 150; iter: 0; batch classifier loss: 0.338062; batch adversarial loss: 0.511188\n",
      "epoch 151; iter: 0; batch classifier loss: 0.338189; batch adversarial loss: 0.536472\n",
      "epoch 152; iter: 0; batch classifier loss: 0.439594; batch adversarial loss: 0.587218\n",
      "epoch 153; iter: 0; batch classifier loss: 0.348729; batch adversarial loss: 0.607886\n",
      "epoch 154; iter: 0; batch classifier loss: 0.434630; batch adversarial loss: 0.546218\n",
      "epoch 155; iter: 0; batch classifier loss: 0.389483; batch adversarial loss: 0.548714\n",
      "epoch 156; iter: 0; batch classifier loss: 0.332900; batch adversarial loss: 0.533831\n",
      "epoch 157; iter: 0; batch classifier loss: 0.365529; batch adversarial loss: 0.543290\n",
      "epoch 158; iter: 0; batch classifier loss: 0.396484; batch adversarial loss: 0.533856\n",
      "epoch 159; iter: 0; batch classifier loss: 0.350238; batch adversarial loss: 0.482871\n",
      "epoch 160; iter: 0; batch classifier loss: 0.343308; batch adversarial loss: 0.581193\n",
      "epoch 161; iter: 0; batch classifier loss: 0.238778; batch adversarial loss: 0.587301\n",
      "epoch 162; iter: 0; batch classifier loss: 0.352732; batch adversarial loss: 0.596133\n",
      "epoch 163; iter: 0; batch classifier loss: 0.403237; batch adversarial loss: 0.625341\n",
      "epoch 164; iter: 0; batch classifier loss: 0.341504; batch adversarial loss: 0.619374\n",
      "epoch 165; iter: 0; batch classifier loss: 0.336778; batch adversarial loss: 0.601201\n",
      "epoch 166; iter: 0; batch classifier loss: 0.363525; batch adversarial loss: 0.497964\n",
      "epoch 167; iter: 0; batch classifier loss: 0.398974; batch adversarial loss: 0.638244\n",
      "epoch 168; iter: 0; batch classifier loss: 0.371347; batch adversarial loss: 0.555626\n",
      "epoch 169; iter: 0; batch classifier loss: 0.335521; batch adversarial loss: 0.534160\n",
      "epoch 170; iter: 0; batch classifier loss: 0.373830; batch adversarial loss: 0.550784\n",
      "epoch 171; iter: 0; batch classifier loss: 0.368099; batch adversarial loss: 0.517774\n",
      "epoch 172; iter: 0; batch classifier loss: 0.354279; batch adversarial loss: 0.547307\n",
      "epoch 173; iter: 0; batch classifier loss: 0.315681; batch adversarial loss: 0.639419\n",
      "epoch 174; iter: 0; batch classifier loss: 0.377362; batch adversarial loss: 0.624094\n",
      "epoch 175; iter: 0; batch classifier loss: 0.292498; batch adversarial loss: 0.544118\n",
      "epoch 176; iter: 0; batch classifier loss: 0.348647; batch adversarial loss: 0.534675\n",
      "epoch 177; iter: 0; batch classifier loss: 0.380271; batch adversarial loss: 0.632984\n",
      "epoch 178; iter: 0; batch classifier loss: 0.411250; batch adversarial loss: 0.535747\n",
      "epoch 179; iter: 0; batch classifier loss: 0.344709; batch adversarial loss: 0.570238\n",
      "epoch 180; iter: 0; batch classifier loss: 0.339945; batch adversarial loss: 0.554080\n",
      "epoch 181; iter: 0; batch classifier loss: 0.361666; batch adversarial loss: 0.531964\n",
      "epoch 182; iter: 0; batch classifier loss: 0.374268; batch adversarial loss: 0.606649\n",
      "epoch 183; iter: 0; batch classifier loss: 0.346385; batch adversarial loss: 0.522247\n",
      "epoch 184; iter: 0; batch classifier loss: 0.411071; batch adversarial loss: 0.590016\n",
      "epoch 185; iter: 0; batch classifier loss: 0.376990; batch adversarial loss: 0.509778\n",
      "epoch 186; iter: 0; batch classifier loss: 0.297788; batch adversarial loss: 0.574330\n",
      "epoch 187; iter: 0; batch classifier loss: 0.345318; batch adversarial loss: 0.544959\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 188; iter: 0; batch classifier loss: 0.285133; batch adversarial loss: 0.523466\n",
      "epoch 189; iter: 0; batch classifier loss: 0.332513; batch adversarial loss: 0.534474\n",
      "epoch 190; iter: 0; batch classifier loss: 0.360180; batch adversarial loss: 0.624421\n",
      "epoch 191; iter: 0; batch classifier loss: 0.347430; batch adversarial loss: 0.546617\n",
      "epoch 192; iter: 0; batch classifier loss: 0.389631; batch adversarial loss: 0.507933\n",
      "epoch 193; iter: 0; batch classifier loss: 0.290836; batch adversarial loss: 0.510772\n",
      "epoch 194; iter: 0; batch classifier loss: 0.327182; batch adversarial loss: 0.599864\n",
      "epoch 195; iter: 0; batch classifier loss: 0.333095; batch adversarial loss: 0.591657\n",
      "epoch 196; iter: 0; batch classifier loss: 0.280009; batch adversarial loss: 0.557408\n",
      "epoch 197; iter: 0; batch classifier loss: 0.390243; batch adversarial loss: 0.654364\n",
      "epoch 198; iter: 0; batch classifier loss: 0.334384; batch adversarial loss: 0.606185\n",
      "epoch 199; iter: 0; batch classifier loss: 0.377693; batch adversarial loss: 0.544915\n",
      "epoch 0; iter: 0; batch classifier loss: 0.669216; batch adversarial loss: 0.610566\n",
      "epoch 1; iter: 0; batch classifier loss: 0.517505; batch adversarial loss: 0.665965\n",
      "epoch 2; iter: 0; batch classifier loss: 0.572378; batch adversarial loss: 0.605108\n",
      "epoch 3; iter: 0; batch classifier loss: 0.544984; batch adversarial loss: 0.708441\n",
      "epoch 4; iter: 0; batch classifier loss: 0.589019; batch adversarial loss: 0.637743\n",
      "epoch 5; iter: 0; batch classifier loss: 0.561478; batch adversarial loss: 0.612676\n",
      "epoch 6; iter: 0; batch classifier loss: 0.630662; batch adversarial loss: 0.602297\n",
      "epoch 7; iter: 0; batch classifier loss: 0.622319; batch adversarial loss: 0.639564\n",
      "epoch 8; iter: 0; batch classifier loss: 0.556904; batch adversarial loss: 0.575305\n",
      "epoch 9; iter: 0; batch classifier loss: 0.533443; batch adversarial loss: 0.558833\n",
      "epoch 10; iter: 0; batch classifier loss: 0.499442; batch adversarial loss: 0.579789\n",
      "epoch 11; iter: 0; batch classifier loss: 0.588611; batch adversarial loss: 0.567170\n",
      "epoch 12; iter: 0; batch classifier loss: 0.539106; batch adversarial loss: 0.600223\n",
      "epoch 13; iter: 0; batch classifier loss: 0.543859; batch adversarial loss: 0.504739\n",
      "epoch 14; iter: 0; batch classifier loss: 0.591541; batch adversarial loss: 0.589790\n",
      "epoch 15; iter: 0; batch classifier loss: 0.456724; batch adversarial loss: 0.539978\n",
      "epoch 16; iter: 0; batch classifier loss: 0.472904; batch adversarial loss: 0.509840\n",
      "epoch 17; iter: 0; batch classifier loss: 0.525484; batch adversarial loss: 0.553519\n",
      "epoch 18; iter: 0; batch classifier loss: 0.547505; batch adversarial loss: 0.543877\n",
      "epoch 19; iter: 0; batch classifier loss: 0.448654; batch adversarial loss: 0.572629\n",
      "epoch 20; iter: 0; batch classifier loss: 0.505528; batch adversarial loss: 0.539559\n",
      "epoch 21; iter: 0; batch classifier loss: 0.478978; batch adversarial loss: 0.557791\n",
      "epoch 22; iter: 0; batch classifier loss: 0.516287; batch adversarial loss: 0.514726\n",
      "epoch 23; iter: 0; batch classifier loss: 0.462447; batch adversarial loss: 0.521865\n",
      "epoch 24; iter: 0; batch classifier loss: 0.449006; batch adversarial loss: 0.588594\n",
      "epoch 25; iter: 0; batch classifier loss: 0.467060; batch adversarial loss: 0.533513\n",
      "epoch 26; iter: 0; batch classifier loss: 0.472656; batch adversarial loss: 0.589959\n",
      "epoch 27; iter: 0; batch classifier loss: 0.531598; batch adversarial loss: 0.555471\n",
      "epoch 28; iter: 0; batch classifier loss: 0.435806; batch adversarial loss: 0.554318\n",
      "epoch 29; iter: 0; batch classifier loss: 0.476191; batch adversarial loss: 0.540431\n",
      "epoch 30; iter: 0; batch classifier loss: 0.413471; batch adversarial loss: 0.536497\n",
      "epoch 31; iter: 0; batch classifier loss: 0.441866; batch adversarial loss: 0.595805\n",
      "epoch 32; iter: 0; batch classifier loss: 0.465614; batch adversarial loss: 0.535176\n",
      "epoch 33; iter: 0; batch classifier loss: 0.453993; batch adversarial loss: 0.576430\n",
      "epoch 34; iter: 0; batch classifier loss: 0.466716; batch adversarial loss: 0.483984\n",
      "epoch 35; iter: 0; batch classifier loss: 0.458570; batch adversarial loss: 0.491315\n",
      "epoch 36; iter: 0; batch classifier loss: 0.389941; batch adversarial loss: 0.586090\n",
      "epoch 37; iter: 0; batch classifier loss: 0.463836; batch adversarial loss: 0.509799\n",
      "epoch 38; iter: 0; batch classifier loss: 0.458229; batch adversarial loss: 0.522863\n",
      "epoch 39; iter: 0; batch classifier loss: 0.444963; batch adversarial loss: 0.455542\n",
      "epoch 40; iter: 0; batch classifier loss: 0.484304; batch adversarial loss: 0.619688\n",
      "epoch 41; iter: 0; batch classifier loss: 0.453342; batch adversarial loss: 0.603730\n",
      "epoch 42; iter: 0; batch classifier loss: 0.449570; batch adversarial loss: 0.576596\n",
      "epoch 43; iter: 0; batch classifier loss: 0.453002; batch adversarial loss: 0.546055\n",
      "epoch 44; iter: 0; batch classifier loss: 0.402853; batch adversarial loss: 0.559309\n",
      "epoch 45; iter: 0; batch classifier loss: 0.456647; batch adversarial loss: 0.549043\n",
      "epoch 46; iter: 0; batch classifier loss: 0.412014; batch adversarial loss: 0.561625\n",
      "epoch 47; iter: 0; batch classifier loss: 0.382328; batch adversarial loss: 0.459191\n",
      "epoch 48; iter: 0; batch classifier loss: 0.440367; batch adversarial loss: 0.537672\n",
      "epoch 49; iter: 0; batch classifier loss: 0.421188; batch adversarial loss: 0.501764\n",
      "epoch 50; iter: 0; batch classifier loss: 0.454428; batch adversarial loss: 0.659331\n",
      "epoch 51; iter: 0; batch classifier loss: 0.459743; batch adversarial loss: 0.455998\n",
      "epoch 52; iter: 0; batch classifier loss: 0.428360; batch adversarial loss: 0.570114\n",
      "epoch 53; iter: 0; batch classifier loss: 0.464588; batch adversarial loss: 0.490303\n",
      "epoch 54; iter: 0; batch classifier loss: 0.388962; batch adversarial loss: 0.607876\n",
      "epoch 55; iter: 0; batch classifier loss: 0.408949; batch adversarial loss: 0.580723\n",
      "epoch 56; iter: 0; batch classifier loss: 0.383204; batch adversarial loss: 0.538090\n",
      "epoch 57; iter: 0; batch classifier loss: 0.434697; batch adversarial loss: 0.589317\n",
      "epoch 58; iter: 0; batch classifier loss: 0.484937; batch adversarial loss: 0.552677\n",
      "epoch 59; iter: 0; batch classifier loss: 0.455244; batch adversarial loss: 0.517002\n",
      "epoch 60; iter: 0; batch classifier loss: 0.361377; batch adversarial loss: 0.536239\n",
      "epoch 61; iter: 0; batch classifier loss: 0.440751; batch adversarial loss: 0.640596\n",
      "epoch 62; iter: 0; batch classifier loss: 0.458374; batch adversarial loss: 0.550920\n",
      "epoch 63; iter: 0; batch classifier loss: 0.426393; batch adversarial loss: 0.630410\n",
      "epoch 64; iter: 0; batch classifier loss: 0.348104; batch adversarial loss: 0.534483\n",
      "epoch 65; iter: 0; batch classifier loss: 0.415604; batch adversarial loss: 0.550495\n",
      "epoch 66; iter: 0; batch classifier loss: 0.411493; batch adversarial loss: 0.522902\n",
      "epoch 67; iter: 0; batch classifier loss: 0.422537; batch adversarial loss: 0.464507\n",
      "epoch 68; iter: 0; batch classifier loss: 0.428409; batch adversarial loss: 0.572140\n",
      "epoch 69; iter: 0; batch classifier loss: 0.370139; batch adversarial loss: 0.576151\n",
      "epoch 70; iter: 0; batch classifier loss: 0.375040; batch adversarial loss: 0.559088\n",
      "epoch 71; iter: 0; batch classifier loss: 0.417362; batch adversarial loss: 0.617013\n",
      "epoch 72; iter: 0; batch classifier loss: 0.501201; batch adversarial loss: 0.479163\n",
      "epoch 73; iter: 0; batch classifier loss: 0.368392; batch adversarial loss: 0.516530\n",
      "epoch 74; iter: 0; batch classifier loss: 0.441690; batch adversarial loss: 0.544557\n",
      "epoch 75; iter: 0; batch classifier loss: 0.426040; batch adversarial loss: 0.591375\n",
      "epoch 76; iter: 0; batch classifier loss: 0.421590; batch adversarial loss: 0.463551\n",
      "epoch 77; iter: 0; batch classifier loss: 0.419517; batch adversarial loss: 0.539497\n",
      "epoch 78; iter: 0; batch classifier loss: 0.328083; batch adversarial loss: 0.552326\n",
      "epoch 79; iter: 0; batch classifier loss: 0.405682; batch adversarial loss: 0.473183\n",
      "epoch 80; iter: 0; batch classifier loss: 0.385858; batch adversarial loss: 0.572809\n",
      "epoch 81; iter: 0; batch classifier loss: 0.389133; batch adversarial loss: 0.581481\n",
      "epoch 82; iter: 0; batch classifier loss: 0.445503; batch adversarial loss: 0.553562\n",
      "epoch 83; iter: 0; batch classifier loss: 0.355368; batch adversarial loss: 0.615914\n",
      "epoch 84; iter: 0; batch classifier loss: 0.411347; batch adversarial loss: 0.527080\n",
      "epoch 85; iter: 0; batch classifier loss: 0.433099; batch adversarial loss: 0.633037\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 86; iter: 0; batch classifier loss: 0.448455; batch adversarial loss: 0.562160\n",
      "epoch 87; iter: 0; batch classifier loss: 0.398720; batch adversarial loss: 0.526315\n",
      "epoch 88; iter: 0; batch classifier loss: 0.320980; batch adversarial loss: 0.526375\n",
      "epoch 89; iter: 0; batch classifier loss: 0.457450; batch adversarial loss: 0.517395\n",
      "epoch 90; iter: 0; batch classifier loss: 0.449050; batch adversarial loss: 0.535685\n",
      "epoch 91; iter: 0; batch classifier loss: 0.394233; batch adversarial loss: 0.626139\n",
      "epoch 92; iter: 0; batch classifier loss: 0.408677; batch adversarial loss: 0.589392\n",
      "epoch 93; iter: 0; batch classifier loss: 0.464722; batch adversarial loss: 0.563303\n",
      "epoch 94; iter: 0; batch classifier loss: 0.373811; batch adversarial loss: 0.507192\n",
      "epoch 95; iter: 0; batch classifier loss: 0.408433; batch adversarial loss: 0.571769\n",
      "epoch 96; iter: 0; batch classifier loss: 0.356356; batch adversarial loss: 0.616467\n",
      "epoch 97; iter: 0; batch classifier loss: 0.366106; batch adversarial loss: 0.589683\n",
      "epoch 98; iter: 0; batch classifier loss: 0.434380; batch adversarial loss: 0.526606\n",
      "epoch 99; iter: 0; batch classifier loss: 0.426233; batch adversarial loss: 0.524834\n",
      "epoch 100; iter: 0; batch classifier loss: 0.381123; batch adversarial loss: 0.436870\n",
      "epoch 101; iter: 0; batch classifier loss: 0.396749; batch adversarial loss: 0.589602\n",
      "epoch 102; iter: 0; batch classifier loss: 0.371482; batch adversarial loss: 0.572303\n",
      "epoch 103; iter: 0; batch classifier loss: 0.317893; batch adversarial loss: 0.536255\n",
      "epoch 104; iter: 0; batch classifier loss: 0.405901; batch adversarial loss: 0.545434\n",
      "epoch 105; iter: 0; batch classifier loss: 0.373239; batch adversarial loss: 0.517784\n",
      "epoch 106; iter: 0; batch classifier loss: 0.373650; batch adversarial loss: 0.551966\n",
      "epoch 107; iter: 0; batch classifier loss: 0.389703; batch adversarial loss: 0.508354\n",
      "epoch 108; iter: 0; batch classifier loss: 0.381064; batch adversarial loss: 0.581397\n",
      "epoch 109; iter: 0; batch classifier loss: 0.374107; batch adversarial loss: 0.628243\n",
      "epoch 110; iter: 0; batch classifier loss: 0.404789; batch adversarial loss: 0.579912\n",
      "epoch 111; iter: 0; batch classifier loss: 0.330002; batch adversarial loss: 0.552053\n",
      "epoch 112; iter: 0; batch classifier loss: 0.385121; batch adversarial loss: 0.561002\n",
      "epoch 113; iter: 0; batch classifier loss: 0.406036; batch adversarial loss: 0.589053\n",
      "epoch 114; iter: 0; batch classifier loss: 0.369437; batch adversarial loss: 0.480138\n",
      "epoch 115; iter: 0; batch classifier loss: 0.326940; batch adversarial loss: 0.561974\n",
      "epoch 116; iter: 0; batch classifier loss: 0.387538; batch adversarial loss: 0.541939\n",
      "epoch 117; iter: 0; batch classifier loss: 0.363859; batch adversarial loss: 0.591609\n",
      "epoch 118; iter: 0; batch classifier loss: 0.368975; batch adversarial loss: 0.552883\n",
      "epoch 119; iter: 0; batch classifier loss: 0.414330; batch adversarial loss: 0.553176\n",
      "epoch 120; iter: 0; batch classifier loss: 0.428888; batch adversarial loss: 0.573899\n",
      "epoch 121; iter: 0; batch classifier loss: 0.412626; batch adversarial loss: 0.500078\n",
      "epoch 122; iter: 0; batch classifier loss: 0.403652; batch adversarial loss: 0.545076\n",
      "epoch 123; iter: 0; batch classifier loss: 0.370706; batch adversarial loss: 0.526250\n",
      "epoch 124; iter: 0; batch classifier loss: 0.339752; batch adversarial loss: 0.525613\n",
      "epoch 125; iter: 0; batch classifier loss: 0.383995; batch adversarial loss: 0.508320\n",
      "epoch 126; iter: 0; batch classifier loss: 0.389706; batch adversarial loss: 0.617724\n",
      "epoch 127; iter: 0; batch classifier loss: 0.419000; batch adversarial loss: 0.526545\n",
      "epoch 128; iter: 0; batch classifier loss: 0.423132; batch adversarial loss: 0.545190\n",
      "epoch 129; iter: 0; batch classifier loss: 0.359995; batch adversarial loss: 0.562348\n",
      "epoch 130; iter: 0; batch classifier loss: 0.343250; batch adversarial loss: 0.571949\n",
      "epoch 131; iter: 0; batch classifier loss: 0.362015; batch adversarial loss: 0.572379\n",
      "epoch 132; iter: 0; batch classifier loss: 0.413649; batch adversarial loss: 0.534869\n",
      "epoch 133; iter: 0; batch classifier loss: 0.304110; batch adversarial loss: 0.672121\n",
      "epoch 134; iter: 0; batch classifier loss: 0.344902; batch adversarial loss: 0.517255\n",
      "epoch 135; iter: 0; batch classifier loss: 0.402272; batch adversarial loss: 0.598402\n",
      "epoch 136; iter: 0; batch classifier loss: 0.357416; batch adversarial loss: 0.551979\n",
      "epoch 137; iter: 0; batch classifier loss: 0.376507; batch adversarial loss: 0.515929\n",
      "epoch 138; iter: 0; batch classifier loss: 0.410706; batch adversarial loss: 0.488216\n",
      "epoch 139; iter: 0; batch classifier loss: 0.360872; batch adversarial loss: 0.497743\n",
      "epoch 140; iter: 0; batch classifier loss: 0.366698; batch adversarial loss: 0.581106\n",
      "epoch 141; iter: 0; batch classifier loss: 0.472882; batch adversarial loss: 0.553157\n",
      "epoch 142; iter: 0; batch classifier loss: 0.381376; batch adversarial loss: 0.553823\n",
      "epoch 143; iter: 0; batch classifier loss: 0.452497; batch adversarial loss: 0.570321\n",
      "epoch 144; iter: 0; batch classifier loss: 0.374718; batch adversarial loss: 0.515962\n",
      "epoch 145; iter: 0; batch classifier loss: 0.339768; batch adversarial loss: 0.544393\n",
      "epoch 146; iter: 0; batch classifier loss: 0.365239; batch adversarial loss: 0.507734\n",
      "epoch 147; iter: 0; batch classifier loss: 0.403767; batch adversarial loss: 0.535995\n",
      "epoch 148; iter: 0; batch classifier loss: 0.424517; batch adversarial loss: 0.527459\n",
      "epoch 149; iter: 0; batch classifier loss: 0.404649; batch adversarial loss: 0.589026\n",
      "epoch 150; iter: 0; batch classifier loss: 0.336070; batch adversarial loss: 0.543838\n",
      "epoch 151; iter: 0; batch classifier loss: 0.309937; batch adversarial loss: 0.534844\n",
      "epoch 152; iter: 0; batch classifier loss: 0.411164; batch adversarial loss: 0.470299\n",
      "epoch 153; iter: 0; batch classifier loss: 0.396524; batch adversarial loss: 0.581737\n",
      "epoch 154; iter: 0; batch classifier loss: 0.374499; batch adversarial loss: 0.453773\n",
      "epoch 155; iter: 0; batch classifier loss: 0.387203; batch adversarial loss: 0.536247\n",
      "epoch 156; iter: 0; batch classifier loss: 0.340199; batch adversarial loss: 0.526364\n",
      "epoch 157; iter: 0; batch classifier loss: 0.439436; batch adversarial loss: 0.533869\n",
      "epoch 158; iter: 0; batch classifier loss: 0.404750; batch adversarial loss: 0.554174\n",
      "epoch 159; iter: 0; batch classifier loss: 0.469806; batch adversarial loss: 0.479939\n",
      "epoch 160; iter: 0; batch classifier loss: 0.353152; batch adversarial loss: 0.518828\n",
      "epoch 161; iter: 0; batch classifier loss: 0.396185; batch adversarial loss: 0.535746\n",
      "epoch 162; iter: 0; batch classifier loss: 0.371394; batch adversarial loss: 0.573948\n",
      "epoch 163; iter: 0; batch classifier loss: 0.384481; batch adversarial loss: 0.582164\n",
      "epoch 164; iter: 0; batch classifier loss: 0.311591; batch adversarial loss: 0.516819\n",
      "epoch 165; iter: 0; batch classifier loss: 0.315395; batch adversarial loss: 0.617682\n",
      "epoch 166; iter: 0; batch classifier loss: 0.292392; batch adversarial loss: 0.589351\n",
      "epoch 167; iter: 0; batch classifier loss: 0.421885; batch adversarial loss: 0.489223\n",
      "epoch 168; iter: 0; batch classifier loss: 0.429807; batch adversarial loss: 0.545764\n",
      "epoch 169; iter: 0; batch classifier loss: 0.429991; batch adversarial loss: 0.553422\n",
      "epoch 170; iter: 0; batch classifier loss: 0.363893; batch adversarial loss: 0.600421\n",
      "epoch 171; iter: 0; batch classifier loss: 0.391801; batch adversarial loss: 0.628172\n",
      "epoch 172; iter: 0; batch classifier loss: 0.332966; batch adversarial loss: 0.553999\n",
      "epoch 173; iter: 0; batch classifier loss: 0.338920; batch adversarial loss: 0.590433\n",
      "epoch 174; iter: 0; batch classifier loss: 0.405135; batch adversarial loss: 0.508850\n",
      "epoch 175; iter: 0; batch classifier loss: 0.369419; batch adversarial loss: 0.518397\n",
      "epoch 176; iter: 0; batch classifier loss: 0.347274; batch adversarial loss: 0.499661\n",
      "epoch 177; iter: 0; batch classifier loss: 0.241037; batch adversarial loss: 0.489944\n",
      "epoch 178; iter: 0; batch classifier loss: 0.357682; batch adversarial loss: 0.517348\n",
      "epoch 179; iter: 0; batch classifier loss: 0.423906; batch adversarial loss: 0.545227\n",
      "epoch 180; iter: 0; batch classifier loss: 0.333420; batch adversarial loss: 0.553006\n",
      "epoch 181; iter: 0; batch classifier loss: 0.423711; batch adversarial loss: 0.532357\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 182; iter: 0; batch classifier loss: 0.414066; batch adversarial loss: 0.516321\n",
      "epoch 183; iter: 0; batch classifier loss: 0.356857; batch adversarial loss: 0.581868\n",
      "epoch 184; iter: 0; batch classifier loss: 0.402807; batch adversarial loss: 0.635709\n",
      "epoch 185; iter: 0; batch classifier loss: 0.376538; batch adversarial loss: 0.509073\n",
      "epoch 186; iter: 0; batch classifier loss: 0.392966; batch adversarial loss: 0.499364\n",
      "epoch 187; iter: 0; batch classifier loss: 0.328286; batch adversarial loss: 0.517716\n",
      "epoch 188; iter: 0; batch classifier loss: 0.353144; batch adversarial loss: 0.508395\n",
      "epoch 189; iter: 0; batch classifier loss: 0.349639; batch adversarial loss: 0.600650\n",
      "epoch 190; iter: 0; batch classifier loss: 0.385914; batch adversarial loss: 0.562987\n",
      "epoch 191; iter: 0; batch classifier loss: 0.350114; batch adversarial loss: 0.544892\n",
      "epoch 192; iter: 0; batch classifier loss: 0.378256; batch adversarial loss: 0.506679\n",
      "epoch 193; iter: 0; batch classifier loss: 0.347001; batch adversarial loss: 0.554484\n",
      "epoch 194; iter: 0; batch classifier loss: 0.354790; batch adversarial loss: 0.523537\n",
      "epoch 195; iter: 0; batch classifier loss: 0.268958; batch adversarial loss: 0.571800\n",
      "epoch 196; iter: 0; batch classifier loss: 0.396948; batch adversarial loss: 0.562614\n",
      "epoch 197; iter: 0; batch classifier loss: 0.361411; batch adversarial loss: 0.551044\n",
      "epoch 198; iter: 0; batch classifier loss: 0.440134; batch adversarial loss: 0.527277\n",
      "epoch 199; iter: 0; batch classifier loss: 0.345987; batch adversarial loss: 0.452589\n",
      "epoch 0; iter: 0; batch classifier loss: 0.783364; batch adversarial loss: 0.871739\n",
      "epoch 1; iter: 0; batch classifier loss: 0.783778; batch adversarial loss: 0.841992\n",
      "epoch 2; iter: 0; batch classifier loss: 0.898766; batch adversarial loss: 0.808949\n",
      "epoch 3; iter: 0; batch classifier loss: 0.848459; batch adversarial loss: 0.740591\n",
      "epoch 4; iter: 0; batch classifier loss: 0.815465; batch adversarial loss: 0.680050\n",
      "epoch 5; iter: 0; batch classifier loss: 0.883548; batch adversarial loss: 0.640990\n",
      "epoch 6; iter: 0; batch classifier loss: 0.590869; batch adversarial loss: 0.614120\n",
      "epoch 7; iter: 0; batch classifier loss: 0.504373; batch adversarial loss: 0.605037\n",
      "epoch 8; iter: 0; batch classifier loss: 0.545430; batch adversarial loss: 0.588361\n",
      "epoch 9; iter: 0; batch classifier loss: 0.601431; batch adversarial loss: 0.591612\n",
      "epoch 10; iter: 0; batch classifier loss: 0.602038; batch adversarial loss: 0.640958\n",
      "epoch 11; iter: 0; batch classifier loss: 0.541996; batch adversarial loss: 0.556216\n",
      "epoch 12; iter: 0; batch classifier loss: 0.586563; batch adversarial loss: 0.595819\n",
      "epoch 13; iter: 0; batch classifier loss: 0.516108; batch adversarial loss: 0.577882\n",
      "epoch 14; iter: 0; batch classifier loss: 0.503378; batch adversarial loss: 0.579427\n",
      "epoch 15; iter: 0; batch classifier loss: 0.506363; batch adversarial loss: 0.555276\n",
      "epoch 16; iter: 0; batch classifier loss: 0.507626; batch adversarial loss: 0.604247\n",
      "epoch 17; iter: 0; batch classifier loss: 0.514359; batch adversarial loss: 0.548319\n",
      "epoch 18; iter: 0; batch classifier loss: 0.464004; batch adversarial loss: 0.562683\n",
      "epoch 19; iter: 0; batch classifier loss: 0.468329; batch adversarial loss: 0.579335\n",
      "epoch 20; iter: 0; batch classifier loss: 0.621932; batch adversarial loss: 0.561964\n",
      "epoch 21; iter: 0; batch classifier loss: 0.520264; batch adversarial loss: 0.545251\n",
      "epoch 22; iter: 0; batch classifier loss: 0.467767; batch adversarial loss: 0.559052\n",
      "epoch 23; iter: 0; batch classifier loss: 0.455945; batch adversarial loss: 0.596318\n",
      "epoch 24; iter: 0; batch classifier loss: 0.506339; batch adversarial loss: 0.626226\n",
      "epoch 25; iter: 0; batch classifier loss: 0.421985; batch adversarial loss: 0.639996\n",
      "epoch 26; iter: 0; batch classifier loss: 0.483160; batch adversarial loss: 0.581901\n",
      "epoch 27; iter: 0; batch classifier loss: 0.531830; batch adversarial loss: 0.482977\n",
      "epoch 28; iter: 0; batch classifier loss: 0.458126; batch adversarial loss: 0.461203\n",
      "epoch 29; iter: 0; batch classifier loss: 0.406899; batch adversarial loss: 0.537908\n",
      "epoch 30; iter: 0; batch classifier loss: 0.481893; batch adversarial loss: 0.523022\n",
      "epoch 31; iter: 0; batch classifier loss: 0.461923; batch adversarial loss: 0.531012\n",
      "epoch 32; iter: 0; batch classifier loss: 0.443641; batch adversarial loss: 0.500722\n",
      "epoch 33; iter: 0; batch classifier loss: 0.400650; batch adversarial loss: 0.562478\n",
      "epoch 34; iter: 0; batch classifier loss: 0.454456; batch adversarial loss: 0.539010\n",
      "epoch 35; iter: 0; batch classifier loss: 0.417015; batch adversarial loss: 0.495745\n",
      "epoch 36; iter: 0; batch classifier loss: 0.477211; batch adversarial loss: 0.514507\n",
      "epoch 37; iter: 0; batch classifier loss: 0.466078; batch adversarial loss: 0.591702\n",
      "epoch 38; iter: 0; batch classifier loss: 0.399700; batch adversarial loss: 0.505629\n",
      "epoch 39; iter: 0; batch classifier loss: 0.449597; batch adversarial loss: 0.570045\n",
      "epoch 40; iter: 0; batch classifier loss: 0.407232; batch adversarial loss: 0.555160\n",
      "epoch 41; iter: 0; batch classifier loss: 0.444718; batch adversarial loss: 0.564176\n",
      "epoch 42; iter: 0; batch classifier loss: 0.443369; batch adversarial loss: 0.488285\n",
      "epoch 43; iter: 0; batch classifier loss: 0.481703; batch adversarial loss: 0.544868\n",
      "epoch 44; iter: 0; batch classifier loss: 0.450104; batch adversarial loss: 0.537624\n",
      "epoch 45; iter: 0; batch classifier loss: 0.387761; batch adversarial loss: 0.587791\n",
      "epoch 46; iter: 0; batch classifier loss: 0.599932; batch adversarial loss: 0.474881\n",
      "epoch 47; iter: 0; batch classifier loss: 0.411413; batch adversarial loss: 0.553705\n",
      "epoch 48; iter: 0; batch classifier loss: 0.430036; batch adversarial loss: 0.580644\n",
      "epoch 49; iter: 0; batch classifier loss: 0.430906; batch adversarial loss: 0.516102\n",
      "epoch 50; iter: 0; batch classifier loss: 0.411547; batch adversarial loss: 0.570273\n",
      "epoch 51; iter: 0; batch classifier loss: 0.464876; batch adversarial loss: 0.518423\n",
      "epoch 52; iter: 0; batch classifier loss: 0.516356; batch adversarial loss: 0.516394\n",
      "epoch 53; iter: 0; batch classifier loss: 0.361957; batch adversarial loss: 0.506292\n",
      "epoch 54; iter: 0; batch classifier loss: 0.347772; batch adversarial loss: 0.536038\n",
      "epoch 55; iter: 0; batch classifier loss: 0.441292; batch adversarial loss: 0.498945\n",
      "epoch 56; iter: 0; batch classifier loss: 0.427700; batch adversarial loss: 0.580399\n",
      "epoch 57; iter: 0; batch classifier loss: 0.387574; batch adversarial loss: 0.606610\n",
      "epoch 58; iter: 0; batch classifier loss: 0.440934; batch adversarial loss: 0.536355\n",
      "epoch 59; iter: 0; batch classifier loss: 0.398805; batch adversarial loss: 0.545138\n",
      "epoch 60; iter: 0; batch classifier loss: 0.442379; batch adversarial loss: 0.607468\n",
      "epoch 61; iter: 0; batch classifier loss: 0.385984; batch adversarial loss: 0.537009\n",
      "epoch 62; iter: 0; batch classifier loss: 0.383596; batch adversarial loss: 0.599924\n",
      "epoch 63; iter: 0; batch classifier loss: 0.418772; batch adversarial loss: 0.508614\n",
      "epoch 64; iter: 0; batch classifier loss: 0.480415; batch adversarial loss: 0.480625\n",
      "epoch 65; iter: 0; batch classifier loss: 0.347305; batch adversarial loss: 0.544748\n",
      "epoch 66; iter: 0; batch classifier loss: 0.411239; batch adversarial loss: 0.572852\n",
      "epoch 67; iter: 0; batch classifier loss: 0.379561; batch adversarial loss: 0.553507\n",
      "epoch 68; iter: 0; batch classifier loss: 0.432744; batch adversarial loss: 0.581132\n",
      "epoch 69; iter: 0; batch classifier loss: 0.428288; batch adversarial loss: 0.545512\n",
      "epoch 70; iter: 0; batch classifier loss: 0.366146; batch adversarial loss: 0.571911\n",
      "epoch 71; iter: 0; batch classifier loss: 0.499233; batch adversarial loss: 0.525649\n",
      "epoch 72; iter: 0; batch classifier loss: 0.318954; batch adversarial loss: 0.480611\n",
      "epoch 73; iter: 0; batch classifier loss: 0.393324; batch adversarial loss: 0.590544\n",
      "epoch 74; iter: 0; batch classifier loss: 0.377204; batch adversarial loss: 0.581059\n",
      "epoch 75; iter: 0; batch classifier loss: 0.407376; batch adversarial loss: 0.544624\n",
      "epoch 76; iter: 0; batch classifier loss: 0.474255; batch adversarial loss: 0.544646\n",
      "epoch 77; iter: 0; batch classifier loss: 0.351620; batch adversarial loss: 0.636287\n",
      "epoch 78; iter: 0; batch classifier loss: 0.327490; batch adversarial loss: 0.572492\n",
      "epoch 79; iter: 0; batch classifier loss: 0.394038; batch adversarial loss: 0.526500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 80; iter: 0; batch classifier loss: 0.418384; batch adversarial loss: 0.442023\n",
      "epoch 81; iter: 0; batch classifier loss: 0.326415; batch adversarial loss: 0.590581\n",
      "epoch 82; iter: 0; batch classifier loss: 0.506357; batch adversarial loss: 0.526035\n",
      "epoch 83; iter: 0; batch classifier loss: 0.384190; batch adversarial loss: 0.562473\n",
      "epoch 84; iter: 0; batch classifier loss: 0.383612; batch adversarial loss: 0.526698\n",
      "epoch 85; iter: 0; batch classifier loss: 0.333326; batch adversarial loss: 0.532825\n",
      "epoch 86; iter: 0; batch classifier loss: 0.353729; batch adversarial loss: 0.602604\n",
      "epoch 87; iter: 0; batch classifier loss: 0.382573; batch adversarial loss: 0.609960\n",
      "epoch 88; iter: 0; batch classifier loss: 0.394607; batch adversarial loss: 0.470359\n",
      "epoch 89; iter: 0; batch classifier loss: 0.377237; batch adversarial loss: 0.590962\n",
      "epoch 90; iter: 0; batch classifier loss: 0.344881; batch adversarial loss: 0.540489\n",
      "epoch 91; iter: 0; batch classifier loss: 0.367752; batch adversarial loss: 0.590188\n",
      "epoch 92; iter: 0; batch classifier loss: 0.429566; batch adversarial loss: 0.563734\n",
      "epoch 93; iter: 0; batch classifier loss: 0.389616; batch adversarial loss: 0.527788\n",
      "epoch 94; iter: 0; batch classifier loss: 0.346144; batch adversarial loss: 0.581424\n",
      "epoch 95; iter: 0; batch classifier loss: 0.351030; batch adversarial loss: 0.555097\n",
      "epoch 96; iter: 0; batch classifier loss: 0.344598; batch adversarial loss: 0.526781\n",
      "epoch 97; iter: 0; batch classifier loss: 0.326476; batch adversarial loss: 0.608046\n",
      "epoch 98; iter: 0; batch classifier loss: 0.408458; batch adversarial loss: 0.562517\n",
      "epoch 99; iter: 0; batch classifier loss: 0.348576; batch adversarial loss: 0.498357\n",
      "epoch 100; iter: 0; batch classifier loss: 0.357079; batch adversarial loss: 0.572370\n",
      "epoch 101; iter: 0; batch classifier loss: 0.362445; batch adversarial loss: 0.452064\n",
      "epoch 102; iter: 0; batch classifier loss: 0.328219; batch adversarial loss: 0.561694\n",
      "epoch 103; iter: 0; batch classifier loss: 0.339649; batch adversarial loss: 0.579081\n",
      "epoch 104; iter: 0; batch classifier loss: 0.314057; batch adversarial loss: 0.544146\n",
      "epoch 105; iter: 0; batch classifier loss: 0.382967; batch adversarial loss: 0.583154\n",
      "epoch 106; iter: 0; batch classifier loss: 0.347357; batch adversarial loss: 0.574093\n",
      "epoch 107; iter: 0; batch classifier loss: 0.357935; batch adversarial loss: 0.554094\n",
      "epoch 108; iter: 0; batch classifier loss: 0.342238; batch adversarial loss: 0.580294\n",
      "epoch 109; iter: 0; batch classifier loss: 0.422718; batch adversarial loss: 0.489939\n",
      "epoch 110; iter: 0; batch classifier loss: 0.373649; batch adversarial loss: 0.554450\n",
      "epoch 111; iter: 0; batch classifier loss: 0.393896; batch adversarial loss: 0.554856\n",
      "epoch 112; iter: 0; batch classifier loss: 0.424530; batch adversarial loss: 0.617838\n",
      "epoch 113; iter: 0; batch classifier loss: 0.393261; batch adversarial loss: 0.489802\n",
      "epoch 114; iter: 0; batch classifier loss: 0.350753; batch adversarial loss: 0.534672\n",
      "epoch 115; iter: 0; batch classifier loss: 0.394492; batch adversarial loss: 0.590195\n",
      "epoch 116; iter: 0; batch classifier loss: 0.330541; batch adversarial loss: 0.628232\n",
      "epoch 117; iter: 0; batch classifier loss: 0.439206; batch adversarial loss: 0.516935\n",
      "epoch 118; iter: 0; batch classifier loss: 0.295803; batch adversarial loss: 0.489689\n",
      "epoch 119; iter: 0; batch classifier loss: 0.337987; batch adversarial loss: 0.526106\n",
      "epoch 120; iter: 0; batch classifier loss: 0.318972; batch adversarial loss: 0.480134\n",
      "epoch 121; iter: 0; batch classifier loss: 0.266058; batch adversarial loss: 0.517092\n",
      "epoch 122; iter: 0; batch classifier loss: 0.326199; batch adversarial loss: 0.580098\n",
      "epoch 123; iter: 0; batch classifier loss: 0.335911; batch adversarial loss: 0.496833\n",
      "epoch 124; iter: 0; batch classifier loss: 0.425283; batch adversarial loss: 0.516059\n",
      "epoch 125; iter: 0; batch classifier loss: 0.298251; batch adversarial loss: 0.581984\n",
      "epoch 126; iter: 0; batch classifier loss: 0.358251; batch adversarial loss: 0.486550\n",
      "epoch 127; iter: 0; batch classifier loss: 0.396637; batch adversarial loss: 0.525698\n",
      "epoch 128; iter: 0; batch classifier loss: 0.353584; batch adversarial loss: 0.533618\n",
      "epoch 129; iter: 0; batch classifier loss: 0.381658; batch adversarial loss: 0.564014\n",
      "epoch 130; iter: 0; batch classifier loss: 0.353393; batch adversarial loss: 0.609813\n",
      "epoch 131; iter: 0; batch classifier loss: 0.350284; batch adversarial loss: 0.553211\n",
      "epoch 132; iter: 0; batch classifier loss: 0.329917; batch adversarial loss: 0.589603\n",
      "epoch 133; iter: 0; batch classifier loss: 0.354409; batch adversarial loss: 0.488076\n",
      "epoch 134; iter: 0; batch classifier loss: 0.355675; batch adversarial loss: 0.525880\n",
      "epoch 135; iter: 0; batch classifier loss: 0.306665; batch adversarial loss: 0.504965\n",
      "epoch 136; iter: 0; batch classifier loss: 0.312824; batch adversarial loss: 0.498089\n",
      "epoch 137; iter: 0; batch classifier loss: 0.391273; batch adversarial loss: 0.488183\n",
      "epoch 138; iter: 0; batch classifier loss: 0.293359; batch adversarial loss: 0.525374\n",
      "epoch 139; iter: 0; batch classifier loss: 0.324157; batch adversarial loss: 0.554211\n",
      "epoch 140; iter: 0; batch classifier loss: 0.339443; batch adversarial loss: 0.471419\n",
      "epoch 141; iter: 0; batch classifier loss: 0.372063; batch adversarial loss: 0.481384\n",
      "epoch 142; iter: 0; batch classifier loss: 0.352790; batch adversarial loss: 0.507705\n",
      "epoch 143; iter: 0; batch classifier loss: 0.340701; batch adversarial loss: 0.471956\n",
      "epoch 144; iter: 0; batch classifier loss: 0.382808; batch adversarial loss: 0.590440\n",
      "epoch 145; iter: 0; batch classifier loss: 0.357129; batch adversarial loss: 0.535694\n",
      "epoch 146; iter: 0; batch classifier loss: 0.262258; batch adversarial loss: 0.498896\n",
      "epoch 147; iter: 0; batch classifier loss: 0.296812; batch adversarial loss: 0.517092\n",
      "epoch 148; iter: 0; batch classifier loss: 0.377730; batch adversarial loss: 0.489203\n",
      "epoch 149; iter: 0; batch classifier loss: 0.329156; batch adversarial loss: 0.608374\n",
      "epoch 150; iter: 0; batch classifier loss: 0.307850; batch adversarial loss: 0.508327\n",
      "epoch 151; iter: 0; batch classifier loss: 0.281295; batch adversarial loss: 0.626525\n",
      "epoch 152; iter: 0; batch classifier loss: 0.306391; batch adversarial loss: 0.580712\n",
      "epoch 153; iter: 0; batch classifier loss: 0.296336; batch adversarial loss: 0.544251\n",
      "epoch 154; iter: 0; batch classifier loss: 0.393822; batch adversarial loss: 0.617569\n",
      "epoch 155; iter: 0; batch classifier loss: 0.338410; batch adversarial loss: 0.535929\n",
      "epoch 156; iter: 0; batch classifier loss: 0.402084; batch adversarial loss: 0.645177\n",
      "epoch 157; iter: 0; batch classifier loss: 0.384146; batch adversarial loss: 0.535350\n",
      "epoch 158; iter: 0; batch classifier loss: 0.331391; batch adversarial loss: 0.562941\n",
      "epoch 159; iter: 0; batch classifier loss: 0.414802; batch adversarial loss: 0.553898\n",
      "epoch 160; iter: 0; batch classifier loss: 0.369843; batch adversarial loss: 0.480145\n",
      "epoch 161; iter: 0; batch classifier loss: 0.416211; batch adversarial loss: 0.526116\n",
      "epoch 162; iter: 0; batch classifier loss: 0.351454; batch adversarial loss: 0.572108\n",
      "epoch 163; iter: 0; batch classifier loss: 0.380674; batch adversarial loss: 0.553810\n",
      "epoch 164; iter: 0; batch classifier loss: 0.368756; batch adversarial loss: 0.470585\n",
      "epoch 165; iter: 0; batch classifier loss: 0.331786; batch adversarial loss: 0.516431\n",
      "epoch 166; iter: 0; batch classifier loss: 0.308013; batch adversarial loss: 0.553638\n",
      "epoch 167; iter: 0; batch classifier loss: 0.319904; batch adversarial loss: 0.553763\n",
      "epoch 168; iter: 0; batch classifier loss: 0.284941; batch adversarial loss: 0.581381\n",
      "epoch 169; iter: 0; batch classifier loss: 0.316026; batch adversarial loss: 0.571954\n",
      "epoch 170; iter: 0; batch classifier loss: 0.318153; batch adversarial loss: 0.581441\n",
      "epoch 171; iter: 0; batch classifier loss: 0.335408; batch adversarial loss: 0.654774\n",
      "epoch 172; iter: 0; batch classifier loss: 0.371310; batch adversarial loss: 0.526298\n",
      "epoch 173; iter: 0; batch classifier loss: 0.308507; batch adversarial loss: 0.562863\n",
      "epoch 174; iter: 0; batch classifier loss: 0.365712; batch adversarial loss: 0.516735\n",
      "epoch 175; iter: 0; batch classifier loss: 0.321812; batch adversarial loss: 0.433906\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 176; iter: 0; batch classifier loss: 0.353650; batch adversarial loss: 0.507690\n",
      "epoch 177; iter: 0; batch classifier loss: 0.304142; batch adversarial loss: 0.480191\n",
      "epoch 178; iter: 0; batch classifier loss: 0.346973; batch adversarial loss: 0.553788\n",
      "epoch 179; iter: 0; batch classifier loss: 0.303073; batch adversarial loss: 0.618212\n",
      "epoch 180; iter: 0; batch classifier loss: 0.388790; batch adversarial loss: 0.526048\n",
      "epoch 181; iter: 0; batch classifier loss: 0.338431; batch adversarial loss: 0.525915\n",
      "epoch 182; iter: 0; batch classifier loss: 0.371138; batch adversarial loss: 0.489128\n",
      "epoch 183; iter: 0; batch classifier loss: 0.274614; batch adversarial loss: 0.599440\n",
      "epoch 184; iter: 0; batch classifier loss: 0.415091; batch adversarial loss: 0.507789\n",
      "epoch 185; iter: 0; batch classifier loss: 0.343616; batch adversarial loss: 0.515224\n",
      "epoch 186; iter: 0; batch classifier loss: 0.319353; batch adversarial loss: 0.517474\n",
      "epoch 187; iter: 0; batch classifier loss: 0.373689; batch adversarial loss: 0.572207\n",
      "epoch 188; iter: 0; batch classifier loss: 0.359388; batch adversarial loss: 0.470454\n",
      "epoch 189; iter: 0; batch classifier loss: 0.415510; batch adversarial loss: 0.516102\n",
      "epoch 190; iter: 0; batch classifier loss: 0.282951; batch adversarial loss: 0.628004\n",
      "epoch 191; iter: 0; batch classifier loss: 0.330153; batch adversarial loss: 0.460836\n",
      "epoch 192; iter: 0; batch classifier loss: 0.268820; batch adversarial loss: 0.609692\n",
      "epoch 193; iter: 0; batch classifier loss: 0.350968; batch adversarial loss: 0.468750\n",
      "epoch 194; iter: 0; batch classifier loss: 0.318513; batch adversarial loss: 0.516973\n",
      "epoch 195; iter: 0; batch classifier loss: 0.310574; batch adversarial loss: 0.489614\n",
      "epoch 196; iter: 0; batch classifier loss: 0.301652; batch adversarial loss: 0.553035\n",
      "epoch 197; iter: 0; batch classifier loss: 0.348532; batch adversarial loss: 0.581660\n",
      "epoch 198; iter: 0; batch classifier loss: 0.256263; batch adversarial loss: 0.489201\n",
      "epoch 199; iter: 0; batch classifier loss: 0.339692; batch adversarial loss: 0.581848\n",
      "epoch 0; iter: 0; batch classifier loss: 0.924298; batch adversarial loss: 0.716589\n",
      "epoch 1; iter: 0; batch classifier loss: 0.599601; batch adversarial loss: 0.668988\n",
      "epoch 2; iter: 0; batch classifier loss: 0.626124; batch adversarial loss: 0.628378\n",
      "epoch 3; iter: 0; batch classifier loss: 0.549969; batch adversarial loss: 0.650441\n",
      "epoch 4; iter: 0; batch classifier loss: 0.602454; batch adversarial loss: 0.610994\n",
      "epoch 5; iter: 0; batch classifier loss: 0.528527; batch adversarial loss: 0.626264\n",
      "epoch 6; iter: 0; batch classifier loss: 0.529662; batch adversarial loss: 0.597310\n",
      "epoch 7; iter: 0; batch classifier loss: 0.496569; batch adversarial loss: 0.584245\n",
      "epoch 8; iter: 0; batch classifier loss: 0.563960; batch adversarial loss: 0.621359\n",
      "epoch 9; iter: 0; batch classifier loss: 0.506953; batch adversarial loss: 0.624341\n",
      "epoch 10; iter: 0; batch classifier loss: 0.509665; batch adversarial loss: 0.608830\n",
      "epoch 11; iter: 0; batch classifier loss: 0.579835; batch adversarial loss: 0.586908\n",
      "epoch 12; iter: 0; batch classifier loss: 0.467700; batch adversarial loss: 0.675693\n",
      "epoch 13; iter: 0; batch classifier loss: 0.569273; batch adversarial loss: 0.591132\n",
      "epoch 14; iter: 0; batch classifier loss: 0.529250; batch adversarial loss: 0.586903\n",
      "epoch 15; iter: 0; batch classifier loss: 0.449675; batch adversarial loss: 0.600113\n",
      "epoch 16; iter: 0; batch classifier loss: 0.596571; batch adversarial loss: 0.581550\n",
      "epoch 17; iter: 0; batch classifier loss: 0.523951; batch adversarial loss: 0.531180\n",
      "epoch 18; iter: 0; batch classifier loss: 0.522901; batch adversarial loss: 0.592142\n",
      "epoch 19; iter: 0; batch classifier loss: 0.507775; batch adversarial loss: 0.580204\n",
      "epoch 20; iter: 0; batch classifier loss: 0.474162; batch adversarial loss: 0.558129\n",
      "epoch 21; iter: 0; batch classifier loss: 0.501248; batch adversarial loss: 0.601014\n",
      "epoch 22; iter: 0; batch classifier loss: 0.507022; batch adversarial loss: 0.596542\n",
      "epoch 23; iter: 0; batch classifier loss: 0.504882; batch adversarial loss: 0.527579\n",
      "epoch 24; iter: 0; batch classifier loss: 0.455879; batch adversarial loss: 0.542762\n",
      "epoch 25; iter: 0; batch classifier loss: 0.479323; batch adversarial loss: 0.544790\n",
      "epoch 26; iter: 0; batch classifier loss: 0.498433; batch adversarial loss: 0.548989\n",
      "epoch 27; iter: 0; batch classifier loss: 0.467550; batch adversarial loss: 0.600154\n",
      "epoch 28; iter: 0; batch classifier loss: 0.534393; batch adversarial loss: 0.574630\n",
      "epoch 29; iter: 0; batch classifier loss: 0.467979; batch adversarial loss: 0.596618\n",
      "epoch 30; iter: 0; batch classifier loss: 0.448377; batch adversarial loss: 0.542084\n",
      "epoch 31; iter: 0; batch classifier loss: 0.397707; batch adversarial loss: 0.563199\n",
      "epoch 32; iter: 0; batch classifier loss: 0.437637; batch adversarial loss: 0.562262\n",
      "epoch 33; iter: 0; batch classifier loss: 0.411137; batch adversarial loss: 0.588319\n",
      "epoch 34; iter: 0; batch classifier loss: 0.419124; batch adversarial loss: 0.468484\n",
      "epoch 35; iter: 0; batch classifier loss: 0.443615; batch adversarial loss: 0.511093\n",
      "epoch 36; iter: 0; batch classifier loss: 0.452458; batch adversarial loss: 0.547064\n",
      "epoch 37; iter: 0; batch classifier loss: 0.403197; batch adversarial loss: 0.588590\n",
      "epoch 38; iter: 0; batch classifier loss: 0.462667; batch adversarial loss: 0.553816\n",
      "epoch 39; iter: 0; batch classifier loss: 0.461395; batch adversarial loss: 0.510283\n",
      "epoch 40; iter: 0; batch classifier loss: 0.408601; batch adversarial loss: 0.562852\n",
      "epoch 41; iter: 0; batch classifier loss: 0.416576; batch adversarial loss: 0.588284\n",
      "epoch 42; iter: 0; batch classifier loss: 0.450088; batch adversarial loss: 0.554123\n",
      "epoch 43; iter: 0; batch classifier loss: 0.420318; batch adversarial loss: 0.535639\n",
      "epoch 44; iter: 0; batch classifier loss: 0.435100; batch adversarial loss: 0.563048\n",
      "epoch 45; iter: 0; batch classifier loss: 0.489628; batch adversarial loss: 0.509311\n",
      "epoch 46; iter: 0; batch classifier loss: 0.425285; batch adversarial loss: 0.598298\n",
      "epoch 47; iter: 0; batch classifier loss: 0.451183; batch adversarial loss: 0.544531\n",
      "epoch 48; iter: 0; batch classifier loss: 0.382264; batch adversarial loss: 0.553888\n",
      "epoch 49; iter: 0; batch classifier loss: 0.429446; batch adversarial loss: 0.509264\n",
      "epoch 50; iter: 0; batch classifier loss: 0.487394; batch adversarial loss: 0.544527\n",
      "epoch 51; iter: 0; batch classifier loss: 0.453121; batch adversarial loss: 0.595759\n",
      "epoch 52; iter: 0; batch classifier loss: 0.415420; batch adversarial loss: 0.562193\n",
      "epoch 53; iter: 0; batch classifier loss: 0.439618; batch adversarial loss: 0.553372\n",
      "epoch 54; iter: 0; batch classifier loss: 0.471605; batch adversarial loss: 0.587916\n",
      "epoch 55; iter: 0; batch classifier loss: 0.454180; batch adversarial loss: 0.571072\n",
      "epoch 56; iter: 0; batch classifier loss: 0.366856; batch adversarial loss: 0.565816\n",
      "epoch 57; iter: 0; batch classifier loss: 0.391841; batch adversarial loss: 0.520162\n",
      "epoch 58; iter: 0; batch classifier loss: 0.400391; batch adversarial loss: 0.481238\n",
      "epoch 59; iter: 0; batch classifier loss: 0.417071; batch adversarial loss: 0.592094\n",
      "epoch 60; iter: 0; batch classifier loss: 0.463438; batch adversarial loss: 0.582094\n",
      "epoch 61; iter: 0; batch classifier loss: 0.338693; batch adversarial loss: 0.517022\n",
      "epoch 62; iter: 0; batch classifier loss: 0.369322; batch adversarial loss: 0.535686\n",
      "epoch 63; iter: 0; batch classifier loss: 0.358235; batch adversarial loss: 0.599148\n",
      "epoch 64; iter: 0; batch classifier loss: 0.442897; batch adversarial loss: 0.544675\n",
      "epoch 65; iter: 0; batch classifier loss: 0.421205; batch adversarial loss: 0.553736\n",
      "epoch 66; iter: 0; batch classifier loss: 0.371067; batch adversarial loss: 0.553556\n",
      "epoch 67; iter: 0; batch classifier loss: 0.374117; batch adversarial loss: 0.544429\n",
      "epoch 68; iter: 0; batch classifier loss: 0.418861; batch adversarial loss: 0.535501\n",
      "epoch 69; iter: 0; batch classifier loss: 0.409033; batch adversarial loss: 0.616797\n",
      "epoch 70; iter: 0; batch classifier loss: 0.319834; batch adversarial loss: 0.625842\n",
      "epoch 71; iter: 0; batch classifier loss: 0.358215; batch adversarial loss: 0.454617\n",
      "epoch 72; iter: 0; batch classifier loss: 0.355911; batch adversarial loss: 0.580772\n",
      "epoch 73; iter: 0; batch classifier loss: 0.416849; batch adversarial loss: 0.553553\n",
      "epoch 74; iter: 0; batch classifier loss: 0.438021; batch adversarial loss: 0.544564\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 75; iter: 0; batch classifier loss: 0.423744; batch adversarial loss: 0.589680\n",
      "epoch 76; iter: 0; batch classifier loss: 0.380984; batch adversarial loss: 0.589406\n",
      "epoch 77; iter: 0; batch classifier loss: 0.442935; batch adversarial loss: 0.634658\n",
      "epoch 78; iter: 0; batch classifier loss: 0.345996; batch adversarial loss: 0.617626\n",
      "epoch 79; iter: 0; batch classifier loss: 0.340389; batch adversarial loss: 0.521041\n",
      "epoch 80; iter: 0; batch classifier loss: 0.485675; batch adversarial loss: 0.604995\n",
      "epoch 81; iter: 0; batch classifier loss: 0.432606; batch adversarial loss: 0.502623\n",
      "epoch 82; iter: 0; batch classifier loss: 0.466840; batch adversarial loss: 0.524005\n",
      "epoch 83; iter: 0; batch classifier loss: 0.431019; batch adversarial loss: 0.483841\n",
      "epoch 84; iter: 0; batch classifier loss: 0.400492; batch adversarial loss: 0.628014\n",
      "epoch 85; iter: 0; batch classifier loss: 0.392006; batch adversarial loss: 0.528721\n",
      "epoch 86; iter: 0; batch classifier loss: 0.387398; batch adversarial loss: 0.551675\n",
      "epoch 87; iter: 0; batch classifier loss: 0.384684; batch adversarial loss: 0.506652\n",
      "epoch 88; iter: 0; batch classifier loss: 0.397969; batch adversarial loss: 0.545427\n",
      "epoch 89; iter: 0; batch classifier loss: 0.404195; batch adversarial loss: 0.561659\n",
      "epoch 90; iter: 0; batch classifier loss: 0.413394; batch adversarial loss: 0.597607\n",
      "epoch 91; iter: 0; batch classifier loss: 0.358648; batch adversarial loss: 0.529105\n",
      "epoch 92; iter: 0; batch classifier loss: 0.393018; batch adversarial loss: 0.517005\n",
      "epoch 93; iter: 0; batch classifier loss: 0.387235; batch adversarial loss: 0.527993\n",
      "epoch 94; iter: 0; batch classifier loss: 0.392514; batch adversarial loss: 0.518605\n",
      "epoch 95; iter: 0; batch classifier loss: 0.334221; batch adversarial loss: 0.509298\n",
      "epoch 96; iter: 0; batch classifier loss: 0.470020; batch adversarial loss: 0.582254\n",
      "epoch 97; iter: 0; batch classifier loss: 0.404674; batch adversarial loss: 0.536265\n",
      "epoch 98; iter: 0; batch classifier loss: 0.360337; batch adversarial loss: 0.562350\n",
      "epoch 99; iter: 0; batch classifier loss: 0.351586; batch adversarial loss: 0.589029\n",
      "epoch 100; iter: 0; batch classifier loss: 0.406306; batch adversarial loss: 0.570451\n",
      "epoch 101; iter: 0; batch classifier loss: 0.420855; batch adversarial loss: 0.562172\n",
      "epoch 102; iter: 0; batch classifier loss: 0.367762; batch adversarial loss: 0.472835\n",
      "epoch 103; iter: 0; batch classifier loss: 0.432055; batch adversarial loss: 0.499446\n",
      "epoch 104; iter: 0; batch classifier loss: 0.411185; batch adversarial loss: 0.589349\n",
      "epoch 105; iter: 0; batch classifier loss: 0.347838; batch adversarial loss: 0.464319\n",
      "epoch 106; iter: 0; batch classifier loss: 0.394612; batch adversarial loss: 0.545212\n",
      "epoch 107; iter: 0; batch classifier loss: 0.332034; batch adversarial loss: 0.580503\n",
      "epoch 108; iter: 0; batch classifier loss: 0.353838; batch adversarial loss: 0.571944\n",
      "epoch 109; iter: 0; batch classifier loss: 0.390836; batch adversarial loss: 0.535556\n",
      "epoch 110; iter: 0; batch classifier loss: 0.355156; batch adversarial loss: 0.607110\n",
      "epoch 111; iter: 0; batch classifier loss: 0.437615; batch adversarial loss: 0.517619\n",
      "epoch 112; iter: 0; batch classifier loss: 0.324296; batch adversarial loss: 0.526235\n",
      "epoch 113; iter: 0; batch classifier loss: 0.399153; batch adversarial loss: 0.599029\n",
      "epoch 114; iter: 0; batch classifier loss: 0.387218; batch adversarial loss: 0.517701\n",
      "epoch 115; iter: 0; batch classifier loss: 0.412149; batch adversarial loss: 0.554126\n",
      "epoch 116; iter: 0; batch classifier loss: 0.325947; batch adversarial loss: 0.562149\n",
      "epoch 117; iter: 0; batch classifier loss: 0.392223; batch adversarial loss: 0.517654\n",
      "epoch 118; iter: 0; batch classifier loss: 0.308105; batch adversarial loss: 0.652181\n",
      "epoch 119; iter: 0; batch classifier loss: 0.340163; batch adversarial loss: 0.526343\n",
      "epoch 120; iter: 0; batch classifier loss: 0.377473; batch adversarial loss: 0.489985\n",
      "epoch 121; iter: 0; batch classifier loss: 0.395101; batch adversarial loss: 0.579939\n",
      "epoch 122; iter: 0; batch classifier loss: 0.411794; batch adversarial loss: 0.562502\n",
      "epoch 123; iter: 0; batch classifier loss: 0.334064; batch adversarial loss: 0.544773\n",
      "epoch 124; iter: 0; batch classifier loss: 0.279306; batch adversarial loss: 0.507840\n",
      "epoch 125; iter: 0; batch classifier loss: 0.444539; batch adversarial loss: 0.517115\n",
      "epoch 126; iter: 0; batch classifier loss: 0.429564; batch adversarial loss: 0.507524\n",
      "epoch 127; iter: 0; batch classifier loss: 0.432162; batch adversarial loss: 0.598011\n",
      "epoch 128; iter: 0; batch classifier loss: 0.318712; batch adversarial loss: 0.535814\n",
      "epoch 129; iter: 0; batch classifier loss: 0.331428; batch adversarial loss: 0.580464\n",
      "epoch 130; iter: 0; batch classifier loss: 0.385968; batch adversarial loss: 0.543199\n",
      "epoch 131; iter: 0; batch classifier loss: 0.365824; batch adversarial loss: 0.570460\n",
      "epoch 132; iter: 0; batch classifier loss: 0.385009; batch adversarial loss: 0.537312\n",
      "epoch 133; iter: 0; batch classifier loss: 0.363800; batch adversarial loss: 0.554512\n",
      "epoch 134; iter: 0; batch classifier loss: 0.291835; batch adversarial loss: 0.527381\n",
      "epoch 135; iter: 0; batch classifier loss: 0.373657; batch adversarial loss: 0.651916\n",
      "epoch 136; iter: 0; batch classifier loss: 0.406715; batch adversarial loss: 0.526812\n",
      "epoch 137; iter: 0; batch classifier loss: 0.450585; batch adversarial loss: 0.554522\n",
      "epoch 138; iter: 0; batch classifier loss: 0.420283; batch adversarial loss: 0.481324\n",
      "epoch 139; iter: 0; batch classifier loss: 0.362573; batch adversarial loss: 0.499566\n",
      "epoch 140; iter: 0; batch classifier loss: 0.355739; batch adversarial loss: 0.509214\n",
      "epoch 141; iter: 0; batch classifier loss: 0.334058; batch adversarial loss: 0.480745\n",
      "epoch 142; iter: 0; batch classifier loss: 0.469508; batch adversarial loss: 0.571108\n",
      "epoch 143; iter: 0; batch classifier loss: 0.445024; batch adversarial loss: 0.518097\n",
      "epoch 144; iter: 0; batch classifier loss: 0.395076; batch adversarial loss: 0.562276\n",
      "epoch 145; iter: 0; batch classifier loss: 0.299151; batch adversarial loss: 0.536551\n",
      "epoch 146; iter: 0; batch classifier loss: 0.411063; batch adversarial loss: 0.481802\n",
      "epoch 147; iter: 0; batch classifier loss: 0.299500; batch adversarial loss: 0.571999\n",
      "epoch 148; iter: 0; batch classifier loss: 0.304079; batch adversarial loss: 0.554148\n",
      "epoch 149; iter: 0; batch classifier loss: 0.311258; batch adversarial loss: 0.553255\n",
      "epoch 150; iter: 0; batch classifier loss: 0.340742; batch adversarial loss: 0.660788\n",
      "epoch 151; iter: 0; batch classifier loss: 0.456882; batch adversarial loss: 0.561719\n",
      "epoch 152; iter: 0; batch classifier loss: 0.394689; batch adversarial loss: 0.527400\n",
      "epoch 153; iter: 0; batch classifier loss: 0.418222; batch adversarial loss: 0.562222\n",
      "epoch 154; iter: 0; batch classifier loss: 0.346547; batch adversarial loss: 0.518006\n",
      "epoch 155; iter: 0; batch classifier loss: 0.306197; batch adversarial loss: 0.571320\n",
      "epoch 156; iter: 0; batch classifier loss: 0.300084; batch adversarial loss: 0.543520\n",
      "epoch 157; iter: 0; batch classifier loss: 0.434457; batch adversarial loss: 0.499723\n",
      "epoch 158; iter: 0; batch classifier loss: 0.369464; batch adversarial loss: 0.535657\n",
      "epoch 159; iter: 0; batch classifier loss: 0.442534; batch adversarial loss: 0.561371\n",
      "epoch 160; iter: 0; batch classifier loss: 0.393592; batch adversarial loss: 0.544264\n",
      "epoch 161; iter: 0; batch classifier loss: 0.345595; batch adversarial loss: 0.490883\n",
      "epoch 162; iter: 0; batch classifier loss: 0.325328; batch adversarial loss: 0.471378\n",
      "epoch 163; iter: 0; batch classifier loss: 0.344010; batch adversarial loss: 0.507454\n",
      "epoch 164; iter: 0; batch classifier loss: 0.361214; batch adversarial loss: 0.563274\n",
      "epoch 165; iter: 0; batch classifier loss: 0.295240; batch adversarial loss: 0.581091\n",
      "epoch 166; iter: 0; batch classifier loss: 0.406087; batch adversarial loss: 0.562472\n",
      "epoch 167; iter: 0; batch classifier loss: 0.349058; batch adversarial loss: 0.552249\n",
      "epoch 168; iter: 0; batch classifier loss: 0.338412; batch adversarial loss: 0.462401\n",
      "epoch 169; iter: 0; batch classifier loss: 0.333669; batch adversarial loss: 0.635566\n",
      "epoch 170; iter: 0; batch classifier loss: 0.334261; batch adversarial loss: 0.581444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 171; iter: 0; batch classifier loss: 0.282674; batch adversarial loss: 0.510456\n",
      "epoch 172; iter: 0; batch classifier loss: 0.413102; batch adversarial loss: 0.597970\n",
      "epoch 173; iter: 0; batch classifier loss: 0.363769; batch adversarial loss: 0.608878\n",
      "epoch 174; iter: 0; batch classifier loss: 0.343009; batch adversarial loss: 0.490193\n",
      "epoch 175; iter: 0; batch classifier loss: 0.316634; batch adversarial loss: 0.544233\n",
      "epoch 176; iter: 0; batch classifier loss: 0.336987; batch adversarial loss: 0.563246\n",
      "epoch 177; iter: 0; batch classifier loss: 0.467801; batch adversarial loss: 0.590205\n",
      "epoch 178; iter: 0; batch classifier loss: 0.390845; batch adversarial loss: 0.633838\n",
      "epoch 179; iter: 0; batch classifier loss: 0.305156; batch adversarial loss: 0.509590\n",
      "epoch 180; iter: 0; batch classifier loss: 0.262654; batch adversarial loss: 0.554358\n",
      "epoch 181; iter: 0; batch classifier loss: 0.475216; batch adversarial loss: 0.553829\n",
      "epoch 182; iter: 0; batch classifier loss: 0.360825; batch adversarial loss: 0.544705\n",
      "epoch 183; iter: 0; batch classifier loss: 0.283145; batch adversarial loss: 0.517659\n",
      "epoch 184; iter: 0; batch classifier loss: 0.318919; batch adversarial loss: 0.535365\n",
      "epoch 185; iter: 0; batch classifier loss: 0.313261; batch adversarial loss: 0.525984\n",
      "epoch 186; iter: 0; batch classifier loss: 0.303277; batch adversarial loss: 0.571782\n",
      "epoch 187; iter: 0; batch classifier loss: 0.440773; batch adversarial loss: 0.518645\n",
      "epoch 188; iter: 0; batch classifier loss: 0.329091; batch adversarial loss: 0.526612\n",
      "epoch 189; iter: 0; batch classifier loss: 0.358832; batch adversarial loss: 0.589732\n",
      "epoch 190; iter: 0; batch classifier loss: 0.306145; batch adversarial loss: 0.572353\n",
      "epoch 191; iter: 0; batch classifier loss: 0.306649; batch adversarial loss: 0.544047\n",
      "epoch 192; iter: 0; batch classifier loss: 0.334008; batch adversarial loss: 0.543779\n",
      "epoch 193; iter: 0; batch classifier loss: 0.382234; batch adversarial loss: 0.489300\n",
      "epoch 194; iter: 0; batch classifier loss: 0.352889; batch adversarial loss: 0.498728\n",
      "epoch 195; iter: 0; batch classifier loss: 0.429744; batch adversarial loss: 0.444403\n",
      "epoch 196; iter: 0; batch classifier loss: 0.320162; batch adversarial loss: 0.526970\n",
      "epoch 197; iter: 0; batch classifier loss: 0.267614; batch adversarial loss: 0.615082\n",
      "epoch 198; iter: 0; batch classifier loss: 0.319356; batch adversarial loss: 0.551197\n",
      "epoch 199; iter: 0; batch classifier loss: 0.302334; batch adversarial loss: 0.579180\n",
      "epoch 0; iter: 0; batch classifier loss: 0.708758; batch adversarial loss: 0.570308\n",
      "epoch 1; iter: 0; batch classifier loss: 0.602436; batch adversarial loss: 0.651835\n",
      "epoch 2; iter: 0; batch classifier loss: 0.597094; batch adversarial loss: 0.681819\n",
      "epoch 3; iter: 0; batch classifier loss: 0.591173; batch adversarial loss: 0.628504\n",
      "epoch 4; iter: 0; batch classifier loss: 0.643748; batch adversarial loss: 0.692860\n",
      "epoch 5; iter: 0; batch classifier loss: 0.574355; batch adversarial loss: 0.634471\n",
      "epoch 6; iter: 0; batch classifier loss: 0.534317; batch adversarial loss: 0.593310\n",
      "epoch 7; iter: 0; batch classifier loss: 0.574037; batch adversarial loss: 0.624410\n",
      "epoch 8; iter: 0; batch classifier loss: 0.496405; batch adversarial loss: 0.588892\n",
      "epoch 9; iter: 0; batch classifier loss: 0.551887; batch adversarial loss: 0.611385\n",
      "epoch 10; iter: 0; batch classifier loss: 0.578823; batch adversarial loss: 0.590977\n",
      "epoch 11; iter: 0; batch classifier loss: 0.550990; batch adversarial loss: 0.542994\n",
      "epoch 12; iter: 0; batch classifier loss: 0.633098; batch adversarial loss: 0.550662\n",
      "epoch 13; iter: 0; batch classifier loss: 0.493446; batch adversarial loss: 0.553436\n",
      "epoch 14; iter: 0; batch classifier loss: 0.526402; batch adversarial loss: 0.508651\n",
      "epoch 15; iter: 0; batch classifier loss: 0.541454; batch adversarial loss: 0.548504\n",
      "epoch 16; iter: 0; batch classifier loss: 0.440323; batch adversarial loss: 0.614982\n",
      "epoch 17; iter: 0; batch classifier loss: 0.513914; batch adversarial loss: 0.524489\n",
      "epoch 18; iter: 0; batch classifier loss: 0.575949; batch adversarial loss: 0.546038\n",
      "epoch 19; iter: 0; batch classifier loss: 0.452770; batch adversarial loss: 0.563901\n",
      "epoch 20; iter: 0; batch classifier loss: 0.506969; batch adversarial loss: 0.479563\n",
      "epoch 21; iter: 0; batch classifier loss: 0.455233; batch adversarial loss: 0.537918\n",
      "epoch 22; iter: 0; batch classifier loss: 0.477957; batch adversarial loss: 0.498729\n",
      "epoch 23; iter: 0; batch classifier loss: 0.474908; batch adversarial loss: 0.480483\n",
      "epoch 24; iter: 0; batch classifier loss: 0.508007; batch adversarial loss: 0.578796\n",
      "epoch 25; iter: 0; batch classifier loss: 0.457433; batch adversarial loss: 0.554112\n",
      "epoch 26; iter: 0; batch classifier loss: 0.528619; batch adversarial loss: 0.582058\n",
      "epoch 27; iter: 0; batch classifier loss: 0.467167; batch adversarial loss: 0.582442\n",
      "epoch 28; iter: 0; batch classifier loss: 0.511754; batch adversarial loss: 0.510259\n",
      "epoch 29; iter: 0; batch classifier loss: 0.476344; batch adversarial loss: 0.590144\n",
      "epoch 30; iter: 0; batch classifier loss: 0.408433; batch adversarial loss: 0.547667\n",
      "epoch 31; iter: 0; batch classifier loss: 0.429596; batch adversarial loss: 0.571957\n",
      "epoch 32; iter: 0; batch classifier loss: 0.426121; batch adversarial loss: 0.537293\n",
      "epoch 33; iter: 0; batch classifier loss: 0.483501; batch adversarial loss: 0.562221\n",
      "epoch 34; iter: 0; batch classifier loss: 0.499350; batch adversarial loss: 0.554498\n",
      "epoch 35; iter: 0; batch classifier loss: 0.450493; batch adversarial loss: 0.499803\n",
      "epoch 36; iter: 0; batch classifier loss: 0.424380; batch adversarial loss: 0.517704\n",
      "epoch 37; iter: 0; batch classifier loss: 0.446674; batch adversarial loss: 0.561964\n",
      "epoch 38; iter: 0; batch classifier loss: 0.443237; batch adversarial loss: 0.525962\n",
      "epoch 39; iter: 0; batch classifier loss: 0.534873; batch adversarial loss: 0.535540\n",
      "epoch 40; iter: 0; batch classifier loss: 0.428444; batch adversarial loss: 0.480141\n",
      "epoch 41; iter: 0; batch classifier loss: 0.411719; batch adversarial loss: 0.618216\n",
      "epoch 42; iter: 0; batch classifier loss: 0.523947; batch adversarial loss: 0.544508\n",
      "epoch 43; iter: 0; batch classifier loss: 0.521004; batch adversarial loss: 0.479807\n",
      "epoch 44; iter: 0; batch classifier loss: 0.385423; batch adversarial loss: 0.535321\n",
      "epoch 45; iter: 0; batch classifier loss: 0.433782; batch adversarial loss: 0.536004\n",
      "epoch 46; iter: 0; batch classifier loss: 0.474607; batch adversarial loss: 0.524938\n",
      "epoch 47; iter: 0; batch classifier loss: 0.450415; batch adversarial loss: 0.498484\n",
      "epoch 48; iter: 0; batch classifier loss: 0.367291; batch adversarial loss: 0.498729\n",
      "epoch 49; iter: 0; batch classifier loss: 0.424560; batch adversarial loss: 0.470356\n",
      "epoch 50; iter: 0; batch classifier loss: 0.366446; batch adversarial loss: 0.562266\n",
      "epoch 51; iter: 0; batch classifier loss: 0.443355; batch adversarial loss: 0.562662\n",
      "epoch 52; iter: 0; batch classifier loss: 0.468813; batch adversarial loss: 0.564175\n",
      "epoch 53; iter: 0; batch classifier loss: 0.361915; batch adversarial loss: 0.572868\n",
      "epoch 54; iter: 0; batch classifier loss: 0.367070; batch adversarial loss: 0.544843\n",
      "epoch 55; iter: 0; batch classifier loss: 0.447054; batch adversarial loss: 0.532665\n",
      "epoch 56; iter: 0; batch classifier loss: 0.412554; batch adversarial loss: 0.528931\n",
      "epoch 57; iter: 0; batch classifier loss: 0.381590; batch adversarial loss: 0.497936\n",
      "epoch 58; iter: 0; batch classifier loss: 0.423894; batch adversarial loss: 0.528506\n",
      "epoch 59; iter: 0; batch classifier loss: 0.357849; batch adversarial loss: 0.535036\n",
      "epoch 60; iter: 0; batch classifier loss: 0.436961; batch adversarial loss: 0.593376\n",
      "epoch 61; iter: 0; batch classifier loss: 0.409302; batch adversarial loss: 0.468923\n",
      "epoch 62; iter: 0; batch classifier loss: 0.442236; batch adversarial loss: 0.592278\n",
      "epoch 63; iter: 0; batch classifier loss: 0.378791; batch adversarial loss: 0.554136\n",
      "epoch 64; iter: 0; batch classifier loss: 0.424475; batch adversarial loss: 0.525629\n",
      "epoch 65; iter: 0; batch classifier loss: 0.382125; batch adversarial loss: 0.526105\n",
      "epoch 66; iter: 0; batch classifier loss: 0.385177; batch adversarial loss: 0.442352\n",
      "epoch 67; iter: 0; batch classifier loss: 0.433525; batch adversarial loss: 0.479515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 68; iter: 0; batch classifier loss: 0.427785; batch adversarial loss: 0.460473\n",
      "epoch 69; iter: 0; batch classifier loss: 0.440070; batch adversarial loss: 0.525507\n",
      "epoch 70; iter: 0; batch classifier loss: 0.391545; batch adversarial loss: 0.618237\n",
      "epoch 71; iter: 0; batch classifier loss: 0.338002; batch adversarial loss: 0.534980\n",
      "epoch 72; iter: 0; batch classifier loss: 0.347446; batch adversarial loss: 0.523960\n",
      "epoch 73; iter: 0; batch classifier loss: 0.371539; batch adversarial loss: 0.579516\n",
      "epoch 74; iter: 0; batch classifier loss: 0.418842; batch adversarial loss: 0.527471\n",
      "epoch 75; iter: 0; batch classifier loss: 0.441313; batch adversarial loss: 0.562128\n",
      "epoch 76; iter: 0; batch classifier loss: 0.462055; batch adversarial loss: 0.555734\n",
      "epoch 77; iter: 0; batch classifier loss: 0.441116; batch adversarial loss: 0.582466\n",
      "epoch 78; iter: 0; batch classifier loss: 0.341399; batch adversarial loss: 0.536098\n",
      "epoch 79; iter: 0; batch classifier loss: 0.383820; batch adversarial loss: 0.515962\n",
      "epoch 80; iter: 0; batch classifier loss: 0.375004; batch adversarial loss: 0.620726\n",
      "epoch 81; iter: 0; batch classifier loss: 0.503503; batch adversarial loss: 0.648452\n",
      "epoch 82; iter: 0; batch classifier loss: 0.414306; batch adversarial loss: 0.553952\n",
      "epoch 83; iter: 0; batch classifier loss: 0.385223; batch adversarial loss: 0.525333\n",
      "epoch 84; iter: 0; batch classifier loss: 0.387447; batch adversarial loss: 0.609982\n",
      "epoch 85; iter: 0; batch classifier loss: 0.449155; batch adversarial loss: 0.516093\n",
      "epoch 86; iter: 0; batch classifier loss: 0.372048; batch adversarial loss: 0.525548\n",
      "epoch 87; iter: 0; batch classifier loss: 0.483606; batch adversarial loss: 0.535662\n",
      "epoch 88; iter: 0; batch classifier loss: 0.425348; batch adversarial loss: 0.544403\n",
      "epoch 89; iter: 0; batch classifier loss: 0.471337; batch adversarial loss: 0.581338\n",
      "epoch 90; iter: 0; batch classifier loss: 0.392801; batch adversarial loss: 0.470032\n",
      "epoch 91; iter: 0; batch classifier loss: 0.365905; batch adversarial loss: 0.618776\n",
      "epoch 92; iter: 0; batch classifier loss: 0.478840; batch adversarial loss: 0.507391\n",
      "epoch 93; iter: 0; batch classifier loss: 0.366827; batch adversarial loss: 0.563818\n",
      "epoch 94; iter: 0; batch classifier loss: 0.358159; batch adversarial loss: 0.479352\n",
      "epoch 95; iter: 0; batch classifier loss: 0.348551; batch adversarial loss: 0.573247\n",
      "epoch 96; iter: 0; batch classifier loss: 0.435165; batch adversarial loss: 0.582512\n",
      "epoch 97; iter: 0; batch classifier loss: 0.343477; batch adversarial loss: 0.516185\n",
      "epoch 98; iter: 0; batch classifier loss: 0.455558; batch adversarial loss: 0.506942\n",
      "epoch 99; iter: 0; batch classifier loss: 0.409339; batch adversarial loss: 0.489597\n",
      "epoch 100; iter: 0; batch classifier loss: 0.346563; batch adversarial loss: 0.515881\n",
      "epoch 101; iter: 0; batch classifier loss: 0.429709; batch adversarial loss: 0.515315\n",
      "epoch 102; iter: 0; batch classifier loss: 0.391460; batch adversarial loss: 0.544665\n",
      "epoch 103; iter: 0; batch classifier loss: 0.397416; batch adversarial loss: 0.554349\n",
      "epoch 104; iter: 0; batch classifier loss: 0.395841; batch adversarial loss: 0.477828\n",
      "epoch 105; iter: 0; batch classifier loss: 0.398139; batch adversarial loss: 0.525505\n",
      "epoch 106; iter: 0; batch classifier loss: 0.340349; batch adversarial loss: 0.554189\n",
      "epoch 107; iter: 0; batch classifier loss: 0.372578; batch adversarial loss: 0.487961\n",
      "epoch 108; iter: 0; batch classifier loss: 0.410257; batch adversarial loss: 0.515681\n",
      "epoch 109; iter: 0; batch classifier loss: 0.406170; batch adversarial loss: 0.499104\n",
      "epoch 110; iter: 0; batch classifier loss: 0.458776; batch adversarial loss: 0.572365\n",
      "epoch 111; iter: 0; batch classifier loss: 0.385279; batch adversarial loss: 0.562897\n",
      "epoch 112; iter: 0; batch classifier loss: 0.370579; batch adversarial loss: 0.478281\n",
      "epoch 113; iter: 0; batch classifier loss: 0.406778; batch adversarial loss: 0.571894\n",
      "epoch 114; iter: 0; batch classifier loss: 0.367721; batch adversarial loss: 0.524309\n",
      "epoch 115; iter: 0; batch classifier loss: 0.343821; batch adversarial loss: 0.497969\n",
      "epoch 116; iter: 0; batch classifier loss: 0.403319; batch adversarial loss: 0.479944\n",
      "epoch 117; iter: 0; batch classifier loss: 0.342959; batch adversarial loss: 0.554275\n",
      "epoch 118; iter: 0; batch classifier loss: 0.431171; batch adversarial loss: 0.507689\n",
      "epoch 119; iter: 0; batch classifier loss: 0.349715; batch adversarial loss: 0.581530\n",
      "epoch 120; iter: 0; batch classifier loss: 0.483893; batch adversarial loss: 0.553952\n",
      "epoch 121; iter: 0; batch classifier loss: 0.471462; batch adversarial loss: 0.564093\n",
      "epoch 122; iter: 0; batch classifier loss: 0.345506; batch adversarial loss: 0.579436\n",
      "epoch 123; iter: 0; batch classifier loss: 0.402134; batch adversarial loss: 0.526065\n",
      "epoch 124; iter: 0; batch classifier loss: 0.464813; batch adversarial loss: 0.478641\n",
      "epoch 125; iter: 0; batch classifier loss: 0.389551; batch adversarial loss: 0.534026\n",
      "epoch 126; iter: 0; batch classifier loss: 0.407784; batch adversarial loss: 0.572216\n",
      "epoch 127; iter: 0; batch classifier loss: 0.318717; batch adversarial loss: 0.629314\n",
      "epoch 128; iter: 0; batch classifier loss: 0.297336; batch adversarial loss: 0.525501\n",
      "epoch 129; iter: 0; batch classifier loss: 0.401032; batch adversarial loss: 0.563226\n",
      "epoch 130; iter: 0; batch classifier loss: 0.501555; batch adversarial loss: 0.451072\n",
      "epoch 131; iter: 0; batch classifier loss: 0.306434; batch adversarial loss: 0.553929\n",
      "epoch 132; iter: 0; batch classifier loss: 0.404360; batch adversarial loss: 0.580346\n",
      "epoch 133; iter: 0; batch classifier loss: 0.381147; batch adversarial loss: 0.544117\n",
      "epoch 134; iter: 0; batch classifier loss: 0.357178; batch adversarial loss: 0.561819\n",
      "epoch 135; iter: 0; batch classifier loss: 0.349341; batch adversarial loss: 0.461478\n",
      "epoch 136; iter: 0; batch classifier loss: 0.379536; batch adversarial loss: 0.470529\n",
      "epoch 137; iter: 0; batch classifier loss: 0.379820; batch adversarial loss: 0.464941\n",
      "epoch 138; iter: 0; batch classifier loss: 0.330520; batch adversarial loss: 0.525487\n",
      "epoch 139; iter: 0; batch classifier loss: 0.429179; batch adversarial loss: 0.525345\n",
      "epoch 140; iter: 0; batch classifier loss: 0.383934; batch adversarial loss: 0.573194\n",
      "epoch 141; iter: 0; batch classifier loss: 0.404821; batch adversarial loss: 0.506439\n",
      "epoch 142; iter: 0; batch classifier loss: 0.361342; batch adversarial loss: 0.487892\n",
      "epoch 143; iter: 0; batch classifier loss: 0.378923; batch adversarial loss: 0.489408\n",
      "epoch 144; iter: 0; batch classifier loss: 0.310251; batch adversarial loss: 0.517332\n",
      "epoch 145; iter: 0; batch classifier loss: 0.353943; batch adversarial loss: 0.583007\n",
      "epoch 146; iter: 0; batch classifier loss: 0.399811; batch adversarial loss: 0.507427\n",
      "epoch 147; iter: 0; batch classifier loss: 0.398354; batch adversarial loss: 0.573073\n",
      "epoch 148; iter: 0; batch classifier loss: 0.329393; batch adversarial loss: 0.534176\n",
      "epoch 149; iter: 0; batch classifier loss: 0.329551; batch adversarial loss: 0.535646\n",
      "epoch 150; iter: 0; batch classifier loss: 0.272910; batch adversarial loss: 0.488963\n",
      "epoch 151; iter: 0; batch classifier loss: 0.350938; batch adversarial loss: 0.489253\n",
      "epoch 152; iter: 0; batch classifier loss: 0.356218; batch adversarial loss: 0.601493\n",
      "epoch 153; iter: 0; batch classifier loss: 0.370761; batch adversarial loss: 0.572036\n",
      "epoch 154; iter: 0; batch classifier loss: 0.371657; batch adversarial loss: 0.517760\n",
      "epoch 155; iter: 0; batch classifier loss: 0.444516; batch adversarial loss: 0.517177\n",
      "epoch 156; iter: 0; batch classifier loss: 0.358379; batch adversarial loss: 0.515514\n",
      "epoch 157; iter: 0; batch classifier loss: 0.393251; batch adversarial loss: 0.562010\n",
      "epoch 158; iter: 0; batch classifier loss: 0.307800; batch adversarial loss: 0.460625\n",
      "epoch 159; iter: 0; batch classifier loss: 0.294088; batch adversarial loss: 0.562433\n",
      "epoch 160; iter: 0; batch classifier loss: 0.333716; batch adversarial loss: 0.498421\n",
      "epoch 161; iter: 0; batch classifier loss: 0.322420; batch adversarial loss: 0.543703\n",
      "epoch 162; iter: 0; batch classifier loss: 0.373819; batch adversarial loss: 0.487966\n",
      "epoch 163; iter: 0; batch classifier loss: 0.356286; batch adversarial loss: 0.554881\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 164; iter: 0; batch classifier loss: 0.406690; batch adversarial loss: 0.554406\n",
      "epoch 165; iter: 0; batch classifier loss: 0.399095; batch adversarial loss: 0.565230\n",
      "epoch 166; iter: 0; batch classifier loss: 0.339139; batch adversarial loss: 0.544659\n",
      "epoch 167; iter: 0; batch classifier loss: 0.325834; batch adversarial loss: 0.480045\n",
      "epoch 168; iter: 0; batch classifier loss: 0.377026; batch adversarial loss: 0.518947\n",
      "epoch 169; iter: 0; batch classifier loss: 0.375200; batch adversarial loss: 0.601597\n",
      "epoch 170; iter: 0; batch classifier loss: 0.349124; batch adversarial loss: 0.628320\n",
      "epoch 171; iter: 0; batch classifier loss: 0.392209; batch adversarial loss: 0.562571\n",
      "epoch 172; iter: 0; batch classifier loss: 0.372986; batch adversarial loss: 0.572369\n",
      "epoch 173; iter: 0; batch classifier loss: 0.418979; batch adversarial loss: 0.507512\n",
      "epoch 174; iter: 0; batch classifier loss: 0.398721; batch adversarial loss: 0.553203\n",
      "epoch 175; iter: 0; batch classifier loss: 0.324503; batch adversarial loss: 0.581142\n",
      "epoch 176; iter: 0; batch classifier loss: 0.416469; batch adversarial loss: 0.563246\n",
      "epoch 177; iter: 0; batch classifier loss: 0.359004; batch adversarial loss: 0.554094\n",
      "epoch 178; iter: 0; batch classifier loss: 0.381292; batch adversarial loss: 0.553955\n",
      "epoch 179; iter: 0; batch classifier loss: 0.357531; batch adversarial loss: 0.415069\n",
      "epoch 180; iter: 0; batch classifier loss: 0.329661; batch adversarial loss: 0.498257\n",
      "epoch 181; iter: 0; batch classifier loss: 0.310206; batch adversarial loss: 0.610343\n",
      "epoch 182; iter: 0; batch classifier loss: 0.285082; batch adversarial loss: 0.526677\n",
      "epoch 183; iter: 0; batch classifier loss: 0.335676; batch adversarial loss: 0.573070\n",
      "epoch 184; iter: 0; batch classifier loss: 0.325816; batch adversarial loss: 0.591792\n",
      "epoch 185; iter: 0; batch classifier loss: 0.421928; batch adversarial loss: 0.598919\n",
      "epoch 186; iter: 0; batch classifier loss: 0.261433; batch adversarial loss: 0.582525\n",
      "epoch 187; iter: 0; batch classifier loss: 0.364834; batch adversarial loss: 0.527086\n",
      "epoch 188; iter: 0; batch classifier loss: 0.382050; batch adversarial loss: 0.452098\n",
      "epoch 189; iter: 0; batch classifier loss: 0.291541; batch adversarial loss: 0.544042\n",
      "epoch 190; iter: 0; batch classifier loss: 0.314678; batch adversarial loss: 0.629266\n",
      "epoch 191; iter: 0; batch classifier loss: 0.306625; batch adversarial loss: 0.564159\n",
      "epoch 192; iter: 0; batch classifier loss: 0.401512; batch adversarial loss: 0.478625\n",
      "epoch 193; iter: 0; batch classifier loss: 0.318904; batch adversarial loss: 0.515251\n",
      "epoch 194; iter: 0; batch classifier loss: 0.517747; batch adversarial loss: 0.451718\n",
      "epoch 195; iter: 0; batch classifier loss: 0.360302; batch adversarial loss: 0.461540\n",
      "epoch 196; iter: 0; batch classifier loss: 0.414708; batch adversarial loss: 0.487291\n",
      "epoch 197; iter: 0; batch classifier loss: 0.424169; batch adversarial loss: 0.601297\n",
      "epoch 198; iter: 0; batch classifier loss: 0.357153; batch adversarial loss: 0.553021\n",
      "epoch 199; iter: 0; batch classifier loss: 0.322514; batch adversarial loss: 0.570214\n",
      "epoch 0; iter: 0; batch classifier loss: 0.693442; batch adversarial loss: 0.784916\n",
      "epoch 1; iter: 0; batch classifier loss: 0.867760; batch adversarial loss: 0.966873\n",
      "epoch 2; iter: 0; batch classifier loss: 0.848600; batch adversarial loss: 0.881726\n",
      "epoch 3; iter: 0; batch classifier loss: 0.914236; batch adversarial loss: 0.834950\n",
      "epoch 4; iter: 0; batch classifier loss: 0.912116; batch adversarial loss: 0.785484\n",
      "epoch 5; iter: 0; batch classifier loss: 0.726374; batch adversarial loss: 0.712309\n",
      "epoch 6; iter: 0; batch classifier loss: 0.625122; batch adversarial loss: 0.635312\n",
      "epoch 7; iter: 0; batch classifier loss: 0.587011; batch adversarial loss: 0.644495\n",
      "epoch 8; iter: 0; batch classifier loss: 0.615402; batch adversarial loss: 0.605474\n",
      "epoch 9; iter: 0; batch classifier loss: 0.535640; batch adversarial loss: 0.578880\n",
      "epoch 10; iter: 0; batch classifier loss: 0.446571; batch adversarial loss: 0.570333\n",
      "epoch 11; iter: 0; batch classifier loss: 0.511206; batch adversarial loss: 0.578528\n",
      "epoch 12; iter: 0; batch classifier loss: 0.487338; batch adversarial loss: 0.592901\n",
      "epoch 13; iter: 0; batch classifier loss: 0.532548; batch adversarial loss: 0.583112\n",
      "epoch 14; iter: 0; batch classifier loss: 0.506224; batch adversarial loss: 0.606555\n",
      "epoch 15; iter: 0; batch classifier loss: 0.501787; batch adversarial loss: 0.616118\n",
      "epoch 16; iter: 0; batch classifier loss: 0.485853; batch adversarial loss: 0.558282\n",
      "epoch 17; iter: 0; batch classifier loss: 0.472395; batch adversarial loss: 0.550935\n",
      "epoch 18; iter: 0; batch classifier loss: 0.511805; batch adversarial loss: 0.585320\n",
      "epoch 19; iter: 0; batch classifier loss: 0.486900; batch adversarial loss: 0.583247\n",
      "epoch 20; iter: 0; batch classifier loss: 0.478667; batch adversarial loss: 0.547871\n",
      "epoch 21; iter: 0; batch classifier loss: 0.529779; batch adversarial loss: 0.645878\n",
      "epoch 22; iter: 0; batch classifier loss: 0.433314; batch adversarial loss: 0.567970\n",
      "epoch 23; iter: 0; batch classifier loss: 0.531114; batch adversarial loss: 0.574250\n",
      "epoch 24; iter: 0; batch classifier loss: 0.434366; batch adversarial loss: 0.623547\n",
      "epoch 25; iter: 0; batch classifier loss: 0.435844; batch adversarial loss: 0.537348\n",
      "epoch 26; iter: 0; batch classifier loss: 0.494442; batch adversarial loss: 0.543052\n",
      "epoch 27; iter: 0; batch classifier loss: 0.458012; batch adversarial loss: 0.585564\n",
      "epoch 28; iter: 0; batch classifier loss: 0.471823; batch adversarial loss: 0.471255\n",
      "epoch 29; iter: 0; batch classifier loss: 0.462076; batch adversarial loss: 0.601242\n",
      "epoch 30; iter: 0; batch classifier loss: 0.534652; batch adversarial loss: 0.525136\n",
      "epoch 31; iter: 0; batch classifier loss: 0.443554; batch adversarial loss: 0.564416\n",
      "epoch 32; iter: 0; batch classifier loss: 0.506572; batch adversarial loss: 0.532868\n",
      "epoch 33; iter: 0; batch classifier loss: 0.433005; batch adversarial loss: 0.557477\n",
      "epoch 34; iter: 0; batch classifier loss: 0.431764; batch adversarial loss: 0.632422\n",
      "epoch 35; iter: 0; batch classifier loss: 0.464465; batch adversarial loss: 0.593634\n",
      "epoch 36; iter: 0; batch classifier loss: 0.417491; batch adversarial loss: 0.648307\n",
      "epoch 37; iter: 0; batch classifier loss: 0.475146; batch adversarial loss: 0.516614\n",
      "epoch 38; iter: 0; batch classifier loss: 0.429115; batch adversarial loss: 0.541835\n",
      "epoch 39; iter: 0; batch classifier loss: 0.417703; batch adversarial loss: 0.529224\n",
      "epoch 40; iter: 0; batch classifier loss: 0.478360; batch adversarial loss: 0.583472\n",
      "epoch 41; iter: 0; batch classifier loss: 0.463580; batch adversarial loss: 0.630194\n",
      "epoch 42; iter: 0; batch classifier loss: 0.453353; batch adversarial loss: 0.594607\n",
      "epoch 43; iter: 0; batch classifier loss: 0.387400; batch adversarial loss: 0.540206\n",
      "epoch 44; iter: 0; batch classifier loss: 0.484835; batch adversarial loss: 0.530363\n",
      "epoch 45; iter: 0; batch classifier loss: 0.382324; batch adversarial loss: 0.476411\n",
      "epoch 46; iter: 0; batch classifier loss: 0.407774; batch adversarial loss: 0.501153\n",
      "epoch 47; iter: 0; batch classifier loss: 0.393371; batch adversarial loss: 0.563577\n",
      "epoch 48; iter: 0; batch classifier loss: 0.405837; batch adversarial loss: 0.482789\n",
      "epoch 49; iter: 0; batch classifier loss: 0.424004; batch adversarial loss: 0.544328\n",
      "epoch 50; iter: 0; batch classifier loss: 0.416691; batch adversarial loss: 0.473437\n",
      "epoch 51; iter: 0; batch classifier loss: 0.378640; batch adversarial loss: 0.629295\n",
      "epoch 52; iter: 0; batch classifier loss: 0.430609; batch adversarial loss: 0.633655\n",
      "epoch 53; iter: 0; batch classifier loss: 0.399053; batch adversarial loss: 0.501047\n",
      "epoch 54; iter: 0; batch classifier loss: 0.438445; batch adversarial loss: 0.563024\n",
      "epoch 55; iter: 0; batch classifier loss: 0.480433; batch adversarial loss: 0.553045\n",
      "epoch 56; iter: 0; batch classifier loss: 0.390163; batch adversarial loss: 0.559598\n",
      "epoch 57; iter: 0; batch classifier loss: 0.463701; batch adversarial loss: 0.556363\n",
      "epoch 58; iter: 0; batch classifier loss: 0.423126; batch adversarial loss: 0.615738\n",
      "epoch 59; iter: 0; batch classifier loss: 0.437357; batch adversarial loss: 0.535641\n",
      "epoch 60; iter: 0; batch classifier loss: 0.386675; batch adversarial loss: 0.553685\n",
      "epoch 61; iter: 0; batch classifier loss: 0.458355; batch adversarial loss: 0.517294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 62; iter: 0; batch classifier loss: 0.417671; batch adversarial loss: 0.519477\n",
      "epoch 63; iter: 0; batch classifier loss: 0.441605; batch adversarial loss: 0.571530\n",
      "epoch 64; iter: 0; batch classifier loss: 0.464025; batch adversarial loss: 0.563076\n",
      "epoch 65; iter: 0; batch classifier loss: 0.392120; batch adversarial loss: 0.544562\n",
      "epoch 66; iter: 0; batch classifier loss: 0.457805; batch adversarial loss: 0.607117\n",
      "epoch 67; iter: 0; batch classifier loss: 0.384840; batch adversarial loss: 0.544240\n",
      "epoch 68; iter: 0; batch classifier loss: 0.388967; batch adversarial loss: 0.535693\n",
      "epoch 69; iter: 0; batch classifier loss: 0.376896; batch adversarial loss: 0.562627\n",
      "epoch 70; iter: 0; batch classifier loss: 0.377652; batch adversarial loss: 0.598043\n",
      "epoch 71; iter: 0; batch classifier loss: 0.343694; batch adversarial loss: 0.500516\n",
      "epoch 72; iter: 0; batch classifier loss: 0.329035; batch adversarial loss: 0.589157\n",
      "epoch 73; iter: 0; batch classifier loss: 0.349577; batch adversarial loss: 0.527223\n",
      "epoch 74; iter: 0; batch classifier loss: 0.436830; batch adversarial loss: 0.615960\n",
      "epoch 75; iter: 0; batch classifier loss: 0.391316; batch adversarial loss: 0.589452\n",
      "epoch 76; iter: 0; batch classifier loss: 0.471337; batch adversarial loss: 0.509228\n",
      "epoch 77; iter: 0; batch classifier loss: 0.394177; batch adversarial loss: 0.553395\n",
      "epoch 78; iter: 0; batch classifier loss: 0.340107; batch adversarial loss: 0.544254\n",
      "epoch 79; iter: 0; batch classifier loss: 0.351153; batch adversarial loss: 0.500664\n",
      "epoch 80; iter: 0; batch classifier loss: 0.407848; batch adversarial loss: 0.597735\n",
      "epoch 81; iter: 0; batch classifier loss: 0.365223; batch adversarial loss: 0.615544\n",
      "epoch 82; iter: 0; batch classifier loss: 0.429015; batch adversarial loss: 0.616584\n",
      "epoch 83; iter: 0; batch classifier loss: 0.296687; batch adversarial loss: 0.545650\n",
      "epoch 84; iter: 0; batch classifier loss: 0.407759; batch adversarial loss: 0.525786\n",
      "epoch 85; iter: 0; batch classifier loss: 0.416905; batch adversarial loss: 0.570732\n",
      "epoch 86; iter: 0; batch classifier loss: 0.302824; batch adversarial loss: 0.527877\n",
      "epoch 87; iter: 0; batch classifier loss: 0.417489; batch adversarial loss: 0.553990\n",
      "epoch 88; iter: 0; batch classifier loss: 0.351606; batch adversarial loss: 0.562165\n",
      "epoch 89; iter: 0; batch classifier loss: 0.399165; batch adversarial loss: 0.545670\n",
      "epoch 90; iter: 0; batch classifier loss: 0.396661; batch adversarial loss: 0.660811\n",
      "epoch 91; iter: 0; batch classifier loss: 0.340334; batch adversarial loss: 0.552005\n",
      "epoch 92; iter: 0; batch classifier loss: 0.431756; batch adversarial loss: 0.562336\n",
      "epoch 93; iter: 0; batch classifier loss: 0.369812; batch adversarial loss: 0.524342\n",
      "epoch 94; iter: 0; batch classifier loss: 0.380486; batch adversarial loss: 0.608224\n",
      "epoch 95; iter: 0; batch classifier loss: 0.312823; batch adversarial loss: 0.607819\n",
      "epoch 96; iter: 0; batch classifier loss: 0.405897; batch adversarial loss: 0.471764\n",
      "epoch 97; iter: 0; batch classifier loss: 0.401138; batch adversarial loss: 0.553580\n",
      "epoch 98; iter: 0; batch classifier loss: 0.357991; batch adversarial loss: 0.579574\n",
      "epoch 99; iter: 0; batch classifier loss: 0.388753; batch adversarial loss: 0.483024\n",
      "epoch 100; iter: 0; batch classifier loss: 0.422593; batch adversarial loss: 0.607078\n",
      "epoch 101; iter: 0; batch classifier loss: 0.319284; batch adversarial loss: 0.546116\n",
      "epoch 102; iter: 0; batch classifier loss: 0.335513; batch adversarial loss: 0.581301\n",
      "epoch 103; iter: 0; batch classifier loss: 0.358145; batch adversarial loss: 0.650680\n",
      "epoch 104; iter: 0; batch classifier loss: 0.468436; batch adversarial loss: 0.551911\n",
      "epoch 105; iter: 0; batch classifier loss: 0.411420; batch adversarial loss: 0.580488\n",
      "epoch 106; iter: 0; batch classifier loss: 0.404038; batch adversarial loss: 0.616320\n",
      "epoch 107; iter: 0; batch classifier loss: 0.346023; batch adversarial loss: 0.491413\n",
      "epoch 108; iter: 0; batch classifier loss: 0.390245; batch adversarial loss: 0.500744\n",
      "epoch 109; iter: 0; batch classifier loss: 0.424760; batch adversarial loss: 0.598228\n",
      "epoch 110; iter: 0; batch classifier loss: 0.349757; batch adversarial loss: 0.616867\n",
      "epoch 111; iter: 0; batch classifier loss: 0.347222; batch adversarial loss: 0.545006\n",
      "epoch 112; iter: 0; batch classifier loss: 0.345668; batch adversarial loss: 0.544793\n",
      "epoch 113; iter: 0; batch classifier loss: 0.394671; batch adversarial loss: 0.518216\n",
      "epoch 114; iter: 0; batch classifier loss: 0.363327; batch adversarial loss: 0.518733\n",
      "epoch 115; iter: 0; batch classifier loss: 0.310770; batch adversarial loss: 0.509566\n",
      "epoch 116; iter: 0; batch classifier loss: 0.384267; batch adversarial loss: 0.554512\n",
      "epoch 117; iter: 0; batch classifier loss: 0.379485; batch adversarial loss: 0.598221\n",
      "epoch 118; iter: 0; batch classifier loss: 0.304442; batch adversarial loss: 0.535046\n",
      "epoch 119; iter: 0; batch classifier loss: 0.317944; batch adversarial loss: 0.526736\n",
      "epoch 120; iter: 0; batch classifier loss: 0.393519; batch adversarial loss: 0.537790\n",
      "epoch 121; iter: 0; batch classifier loss: 0.344015; batch adversarial loss: 0.527087\n",
      "epoch 122; iter: 0; batch classifier loss: 0.310045; batch adversarial loss: 0.545050\n",
      "epoch 123; iter: 0; batch classifier loss: 0.356655; batch adversarial loss: 0.526183\n",
      "epoch 124; iter: 0; batch classifier loss: 0.310105; batch adversarial loss: 0.508466\n",
      "epoch 125; iter: 0; batch classifier loss: 0.354436; batch adversarial loss: 0.501557\n",
      "epoch 126; iter: 0; batch classifier loss: 0.444732; batch adversarial loss: 0.624380\n",
      "epoch 127; iter: 0; batch classifier loss: 0.316544; batch adversarial loss: 0.598464\n",
      "epoch 128; iter: 0; batch classifier loss: 0.401138; batch adversarial loss: 0.587550\n",
      "epoch 129; iter: 0; batch classifier loss: 0.370494; batch adversarial loss: 0.536421\n",
      "epoch 130; iter: 0; batch classifier loss: 0.308175; batch adversarial loss: 0.545437\n",
      "epoch 131; iter: 0; batch classifier loss: 0.365728; batch adversarial loss: 0.535393\n",
      "epoch 132; iter: 0; batch classifier loss: 0.351004; batch adversarial loss: 0.571093\n",
      "epoch 133; iter: 0; batch classifier loss: 0.341303; batch adversarial loss: 0.544393\n",
      "epoch 134; iter: 0; batch classifier loss: 0.357431; batch adversarial loss: 0.569634\n",
      "epoch 135; iter: 0; batch classifier loss: 0.310761; batch adversarial loss: 0.543209\n",
      "epoch 136; iter: 0; batch classifier loss: 0.365437; batch adversarial loss: 0.588353\n",
      "epoch 137; iter: 0; batch classifier loss: 0.352106; batch adversarial loss: 0.598722\n",
      "epoch 138; iter: 0; batch classifier loss: 0.342731; batch adversarial loss: 0.536870\n",
      "epoch 139; iter: 0; batch classifier loss: 0.323411; batch adversarial loss: 0.472356\n",
      "epoch 140; iter: 0; batch classifier loss: 0.327924; batch adversarial loss: 0.589530\n",
      "epoch 141; iter: 0; batch classifier loss: 0.448381; batch adversarial loss: 0.589006\n",
      "epoch 142; iter: 0; batch classifier loss: 0.318624; batch adversarial loss: 0.599054\n",
      "epoch 143; iter: 0; batch classifier loss: 0.326808; batch adversarial loss: 0.489545\n",
      "epoch 144; iter: 0; batch classifier loss: 0.401680; batch adversarial loss: 0.526133\n",
      "epoch 145; iter: 0; batch classifier loss: 0.367022; batch adversarial loss: 0.536176\n",
      "epoch 146; iter: 0; batch classifier loss: 0.316997; batch adversarial loss: 0.481045\n",
      "epoch 147; iter: 0; batch classifier loss: 0.315335; batch adversarial loss: 0.536586\n",
      "epoch 148; iter: 0; batch classifier loss: 0.420894; batch adversarial loss: 0.608082\n",
      "epoch 149; iter: 0; batch classifier loss: 0.278252; batch adversarial loss: 0.553062\n",
      "epoch 150; iter: 0; batch classifier loss: 0.390353; batch adversarial loss: 0.553058\n",
      "epoch 151; iter: 0; batch classifier loss: 0.350653; batch adversarial loss: 0.482183\n",
      "epoch 152; iter: 0; batch classifier loss: 0.309452; batch adversarial loss: 0.624379\n",
      "epoch 153; iter: 0; batch classifier loss: 0.292470; batch adversarial loss: 0.552883\n",
      "epoch 154; iter: 0; batch classifier loss: 0.331104; batch adversarial loss: 0.642735\n",
      "epoch 155; iter: 0; batch classifier loss: 0.384596; batch adversarial loss: 0.580412\n",
      "epoch 156; iter: 0; batch classifier loss: 0.462638; batch adversarial loss: 0.527812\n",
      "epoch 157; iter: 0; batch classifier loss: 0.405055; batch adversarial loss: 0.527433\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 158; iter: 0; batch classifier loss: 0.340042; batch adversarial loss: 0.561194\n",
      "epoch 159; iter: 0; batch classifier loss: 0.444674; batch adversarial loss: 0.544411\n",
      "epoch 160; iter: 0; batch classifier loss: 0.333798; batch adversarial loss: 0.517819\n",
      "epoch 161; iter: 0; batch classifier loss: 0.351623; batch adversarial loss: 0.625418\n",
      "epoch 162; iter: 0; batch classifier loss: 0.385146; batch adversarial loss: 0.588226\n",
      "epoch 163; iter: 0; batch classifier loss: 0.370979; batch adversarial loss: 0.562400\n",
      "epoch 164; iter: 0; batch classifier loss: 0.378034; batch adversarial loss: 0.562692\n",
      "epoch 165; iter: 0; batch classifier loss: 0.320573; batch adversarial loss: 0.623698\n",
      "epoch 166; iter: 0; batch classifier loss: 0.297143; batch adversarial loss: 0.534620\n",
      "epoch 167; iter: 0; batch classifier loss: 0.294548; batch adversarial loss: 0.579810\n",
      "epoch 168; iter: 0; batch classifier loss: 0.285570; batch adversarial loss: 0.527291\n",
      "epoch 169; iter: 0; batch classifier loss: 0.360752; batch adversarial loss: 0.561720\n",
      "epoch 170; iter: 0; batch classifier loss: 0.370425; batch adversarial loss: 0.642206\n",
      "epoch 171; iter: 0; batch classifier loss: 0.395584; batch adversarial loss: 0.500188\n",
      "epoch 172; iter: 0; batch classifier loss: 0.372731; batch adversarial loss: 0.589278\n",
      "epoch 173; iter: 0; batch classifier loss: 0.446237; batch adversarial loss: 0.553590\n",
      "epoch 174; iter: 0; batch classifier loss: 0.388975; batch adversarial loss: 0.516732\n",
      "epoch 175; iter: 0; batch classifier loss: 0.288729; batch adversarial loss: 0.587534\n",
      "epoch 176; iter: 0; batch classifier loss: 0.399914; batch adversarial loss: 0.588049\n",
      "epoch 177; iter: 0; batch classifier loss: 0.334596; batch adversarial loss: 0.571229\n",
      "epoch 178; iter: 0; batch classifier loss: 0.284009; batch adversarial loss: 0.544267\n",
      "epoch 179; iter: 0; batch classifier loss: 0.323122; batch adversarial loss: 0.624941\n",
      "epoch 180; iter: 0; batch classifier loss: 0.370552; batch adversarial loss: 0.561364\n",
      "epoch 181; iter: 0; batch classifier loss: 0.278956; batch adversarial loss: 0.501380\n",
      "epoch 182; iter: 0; batch classifier loss: 0.373859; batch adversarial loss: 0.535876\n",
      "epoch 183; iter: 0; batch classifier loss: 0.284692; batch adversarial loss: 0.518682\n",
      "epoch 184; iter: 0; batch classifier loss: 0.329300; batch adversarial loss: 0.536052\n",
      "epoch 185; iter: 0; batch classifier loss: 0.281912; batch adversarial loss: 0.491575\n",
      "epoch 186; iter: 0; batch classifier loss: 0.387475; batch adversarial loss: 0.624162\n",
      "epoch 187; iter: 0; batch classifier loss: 0.235353; batch adversarial loss: 0.472638\n",
      "epoch 188; iter: 0; batch classifier loss: 0.318149; batch adversarial loss: 0.491318\n",
      "epoch 189; iter: 0; batch classifier loss: 0.341978; batch adversarial loss: 0.552665\n",
      "epoch 190; iter: 0; batch classifier loss: 0.300999; batch adversarial loss: 0.579735\n",
      "epoch 191; iter: 0; batch classifier loss: 0.335083; batch adversarial loss: 0.572731\n",
      "epoch 192; iter: 0; batch classifier loss: 0.329319; batch adversarial loss: 0.580939\n",
      "epoch 193; iter: 0; batch classifier loss: 0.271161; batch adversarial loss: 0.534845\n",
      "epoch 194; iter: 0; batch classifier loss: 0.297583; batch adversarial loss: 0.509180\n",
      "epoch 195; iter: 0; batch classifier loss: 0.309619; batch adversarial loss: 0.598021\n",
      "epoch 196; iter: 0; batch classifier loss: 0.352262; batch adversarial loss: 0.553327\n",
      "epoch 197; iter: 0; batch classifier loss: 0.332398; batch adversarial loss: 0.492083\n",
      "epoch 198; iter: 0; batch classifier loss: 0.369588; batch adversarial loss: 0.596360\n",
      "epoch 199; iter: 0; batch classifier loss: 0.319902; batch adversarial loss: 0.535279\n",
      "epoch 0; iter: 0; batch classifier loss: 0.729340; batch adversarial loss: 0.970765\n",
      "epoch 1; iter: 0; batch classifier loss: 0.915481; batch adversarial loss: 1.123619\n",
      "epoch 2; iter: 0; batch classifier loss: 1.049853; batch adversarial loss: 1.098165\n",
      "epoch 3; iter: 0; batch classifier loss: 1.074551; batch adversarial loss: 1.028664\n",
      "epoch 4; iter: 0; batch classifier loss: 1.175219; batch adversarial loss: 0.945850\n",
      "epoch 5; iter: 0; batch classifier loss: 1.138032; batch adversarial loss: 0.871839\n",
      "epoch 6; iter: 0; batch classifier loss: 1.154445; batch adversarial loss: 0.807069\n",
      "epoch 7; iter: 0; batch classifier loss: 1.143652; batch adversarial loss: 0.745329\n",
      "epoch 8; iter: 0; batch classifier loss: 1.112755; batch adversarial loss: 0.705196\n",
      "epoch 9; iter: 0; batch classifier loss: 0.817257; batch adversarial loss: 0.640616\n",
      "epoch 10; iter: 0; batch classifier loss: 0.807752; batch adversarial loss: 0.638090\n",
      "epoch 11; iter: 0; batch classifier loss: 0.558807; batch adversarial loss: 0.585274\n",
      "epoch 12; iter: 0; batch classifier loss: 0.542826; batch adversarial loss: 0.620231\n",
      "epoch 13; iter: 0; batch classifier loss: 0.528782; batch adversarial loss: 0.559574\n",
      "epoch 14; iter: 0; batch classifier loss: 0.514182; batch adversarial loss: 0.574794\n",
      "epoch 15; iter: 0; batch classifier loss: 0.571112; batch adversarial loss: 0.615451\n",
      "epoch 16; iter: 0; batch classifier loss: 0.473797; batch adversarial loss: 0.588434\n",
      "epoch 17; iter: 0; batch classifier loss: 0.539681; batch adversarial loss: 0.589870\n",
      "epoch 18; iter: 0; batch classifier loss: 0.467953; batch adversarial loss: 0.541711\n",
      "epoch 19; iter: 0; batch classifier loss: 0.519928; batch adversarial loss: 0.589723\n",
      "epoch 20; iter: 0; batch classifier loss: 0.577406; batch adversarial loss: 0.569870\n",
      "epoch 21; iter: 0; batch classifier loss: 0.492036; batch adversarial loss: 0.578354\n",
      "epoch 22; iter: 0; batch classifier loss: 0.573207; batch adversarial loss: 0.558999\n",
      "epoch 23; iter: 0; batch classifier loss: 0.464678; batch adversarial loss: 0.624232\n",
      "epoch 24; iter: 0; batch classifier loss: 0.511908; batch adversarial loss: 0.547348\n",
      "epoch 25; iter: 0; batch classifier loss: 0.473685; batch adversarial loss: 0.596952\n",
      "epoch 26; iter: 0; batch classifier loss: 0.540545; batch adversarial loss: 0.525181\n",
      "epoch 27; iter: 0; batch classifier loss: 0.507453; batch adversarial loss: 0.553307\n",
      "epoch 28; iter: 0; batch classifier loss: 0.477354; batch adversarial loss: 0.576706\n",
      "epoch 29; iter: 0; batch classifier loss: 0.495289; batch adversarial loss: 0.612160\n",
      "epoch 30; iter: 0; batch classifier loss: 0.377507; batch adversarial loss: 0.622626\n",
      "epoch 31; iter: 0; batch classifier loss: 0.439103; batch adversarial loss: 0.529264\n",
      "epoch 32; iter: 0; batch classifier loss: 0.491451; batch adversarial loss: 0.531143\n",
      "epoch 33; iter: 0; batch classifier loss: 0.472397; batch adversarial loss: 0.522279\n",
      "epoch 34; iter: 0; batch classifier loss: 0.384740; batch adversarial loss: 0.520992\n",
      "epoch 35; iter: 0; batch classifier loss: 0.395000; batch adversarial loss: 0.527742\n",
      "epoch 36; iter: 0; batch classifier loss: 0.427263; batch adversarial loss: 0.632129\n",
      "epoch 37; iter: 0; batch classifier loss: 0.399785; batch adversarial loss: 0.550641\n",
      "epoch 38; iter: 0; batch classifier loss: 0.382464; batch adversarial loss: 0.488229\n",
      "epoch 39; iter: 0; batch classifier loss: 0.417757; batch adversarial loss: 0.497505\n",
      "epoch 40; iter: 0; batch classifier loss: 0.502671; batch adversarial loss: 0.569385\n",
      "epoch 41; iter: 0; batch classifier loss: 0.405549; batch adversarial loss: 0.517328\n",
      "epoch 42; iter: 0; batch classifier loss: 0.450947; batch adversarial loss: 0.527468\n",
      "epoch 43; iter: 0; batch classifier loss: 0.393626; batch adversarial loss: 0.560308\n",
      "epoch 44; iter: 0; batch classifier loss: 0.426875; batch adversarial loss: 0.508596\n",
      "epoch 45; iter: 0; batch classifier loss: 0.458776; batch adversarial loss: 0.561533\n",
      "epoch 46; iter: 0; batch classifier loss: 0.482025; batch adversarial loss: 0.545181\n",
      "epoch 47; iter: 0; batch classifier loss: 0.417136; batch adversarial loss: 0.576076\n",
      "epoch 48; iter: 0; batch classifier loss: 0.479730; batch adversarial loss: 0.535803\n",
      "epoch 49; iter: 0; batch classifier loss: 0.300921; batch adversarial loss: 0.520041\n",
      "epoch 50; iter: 0; batch classifier loss: 0.354747; batch adversarial loss: 0.514660\n",
      "epoch 51; iter: 0; batch classifier loss: 0.458982; batch adversarial loss: 0.591244\n",
      "epoch 52; iter: 0; batch classifier loss: 0.309900; batch adversarial loss: 0.517100\n",
      "epoch 53; iter: 0; batch classifier loss: 0.396018; batch adversarial loss: 0.597388\n",
      "epoch 54; iter: 0; batch classifier loss: 0.521199; batch adversarial loss: 0.553984\n",
      "epoch 55; iter: 0; batch classifier loss: 0.333863; batch adversarial loss: 0.536155\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 56; iter: 0; batch classifier loss: 0.362225; batch adversarial loss: 0.553484\n",
      "epoch 57; iter: 0; batch classifier loss: 0.427116; batch adversarial loss: 0.551006\n",
      "epoch 58; iter: 0; batch classifier loss: 0.380385; batch adversarial loss: 0.590939\n",
      "epoch 59; iter: 0; batch classifier loss: 0.392970; batch adversarial loss: 0.541544\n",
      "epoch 60; iter: 0; batch classifier loss: 0.363860; batch adversarial loss: 0.452808\n",
      "epoch 61; iter: 0; batch classifier loss: 0.373871; batch adversarial loss: 0.606361\n",
      "epoch 62; iter: 0; batch classifier loss: 0.379119; batch adversarial loss: 0.584765\n",
      "epoch 63; iter: 0; batch classifier loss: 0.378483; batch adversarial loss: 0.490182\n",
      "epoch 64; iter: 0; batch classifier loss: 0.375843; batch adversarial loss: 0.543934\n",
      "epoch 65; iter: 0; batch classifier loss: 0.469116; batch adversarial loss: 0.557081\n",
      "epoch 66; iter: 0; batch classifier loss: 0.396193; batch adversarial loss: 0.534693\n",
      "epoch 67; iter: 0; batch classifier loss: 0.426716; batch adversarial loss: 0.534241\n",
      "epoch 68; iter: 0; batch classifier loss: 0.421481; batch adversarial loss: 0.497238\n",
      "epoch 69; iter: 0; batch classifier loss: 0.422930; batch adversarial loss: 0.548520\n",
      "epoch 70; iter: 0; batch classifier loss: 0.409038; batch adversarial loss: 0.551404\n",
      "epoch 71; iter: 0; batch classifier loss: 0.369230; batch adversarial loss: 0.564755\n",
      "epoch 72; iter: 0; batch classifier loss: 0.396258; batch adversarial loss: 0.485162\n",
      "epoch 73; iter: 0; batch classifier loss: 0.396336; batch adversarial loss: 0.580630\n",
      "epoch 74; iter: 0; batch classifier loss: 0.295488; batch adversarial loss: 0.498498\n",
      "epoch 75; iter: 0; batch classifier loss: 0.378070; batch adversarial loss: 0.558845\n",
      "epoch 76; iter: 0; batch classifier loss: 0.421128; batch adversarial loss: 0.500704\n",
      "epoch 77; iter: 0; batch classifier loss: 0.342929; batch adversarial loss: 0.638919\n",
      "epoch 78; iter: 0; batch classifier loss: 0.455694; batch adversarial loss: 0.546126\n",
      "epoch 79; iter: 0; batch classifier loss: 0.358335; batch adversarial loss: 0.549799\n",
      "epoch 80; iter: 0; batch classifier loss: 0.345792; batch adversarial loss: 0.604594\n",
      "epoch 81; iter: 0; batch classifier loss: 0.392077; batch adversarial loss: 0.642118\n",
      "epoch 82; iter: 0; batch classifier loss: 0.363188; batch adversarial loss: 0.580278\n",
      "epoch 83; iter: 0; batch classifier loss: 0.335548; batch adversarial loss: 0.553664\n",
      "epoch 84; iter: 0; batch classifier loss: 0.293762; batch adversarial loss: 0.529897\n",
      "epoch 85; iter: 0; batch classifier loss: 0.350728; batch adversarial loss: 0.647023\n",
      "epoch 86; iter: 0; batch classifier loss: 0.401097; batch adversarial loss: 0.527505\n",
      "epoch 87; iter: 0; batch classifier loss: 0.375747; batch adversarial loss: 0.564340\n",
      "epoch 88; iter: 0; batch classifier loss: 0.430704; batch adversarial loss: 0.605191\n",
      "epoch 89; iter: 0; batch classifier loss: 0.302606; batch adversarial loss: 0.501729\n",
      "epoch 90; iter: 0; batch classifier loss: 0.372645; batch adversarial loss: 0.561844\n",
      "epoch 91; iter: 0; batch classifier loss: 0.418619; batch adversarial loss: 0.554112\n",
      "epoch 92; iter: 0; batch classifier loss: 0.341429; batch adversarial loss: 0.615584\n",
      "epoch 93; iter: 0; batch classifier loss: 0.351593; batch adversarial loss: 0.536453\n",
      "epoch 94; iter: 0; batch classifier loss: 0.407284; batch adversarial loss: 0.588657\n",
      "epoch 95; iter: 0; batch classifier loss: 0.347161; batch adversarial loss: 0.580524\n",
      "epoch 96; iter: 0; batch classifier loss: 0.398804; batch adversarial loss: 0.518276\n",
      "epoch 97; iter: 0; batch classifier loss: 0.369144; batch adversarial loss: 0.597587\n",
      "epoch 98; iter: 0; batch classifier loss: 0.337634; batch adversarial loss: 0.570896\n",
      "epoch 99; iter: 0; batch classifier loss: 0.326000; batch adversarial loss: 0.597640\n",
      "epoch 100; iter: 0; batch classifier loss: 0.432552; batch adversarial loss: 0.473507\n",
      "epoch 101; iter: 0; batch classifier loss: 0.362048; batch adversarial loss: 0.580406\n",
      "epoch 102; iter: 0; batch classifier loss: 0.324828; batch adversarial loss: 0.526276\n",
      "epoch 103; iter: 0; batch classifier loss: 0.305466; batch adversarial loss: 0.590503\n",
      "epoch 104; iter: 0; batch classifier loss: 0.325508; batch adversarial loss: 0.501568\n",
      "epoch 105; iter: 0; batch classifier loss: 0.344331; batch adversarial loss: 0.489773\n",
      "epoch 106; iter: 0; batch classifier loss: 0.303530; batch adversarial loss: 0.561563\n",
      "epoch 107; iter: 0; batch classifier loss: 0.357682; batch adversarial loss: 0.542351\n",
      "epoch 108; iter: 0; batch classifier loss: 0.399331; batch adversarial loss: 0.505807\n",
      "epoch 109; iter: 0; batch classifier loss: 0.338732; batch adversarial loss: 0.553230\n",
      "epoch 110; iter: 0; batch classifier loss: 0.373751; batch adversarial loss: 0.563560\n",
      "epoch 111; iter: 0; batch classifier loss: 0.393717; batch adversarial loss: 0.537728\n",
      "epoch 112; iter: 0; batch classifier loss: 0.396782; batch adversarial loss: 0.527954\n",
      "epoch 113; iter: 0; batch classifier loss: 0.362319; batch adversarial loss: 0.606577\n",
      "epoch 114; iter: 0; batch classifier loss: 0.255388; batch adversarial loss: 0.562009\n",
      "epoch 115; iter: 0; batch classifier loss: 0.379768; batch adversarial loss: 0.528348\n",
      "epoch 116; iter: 0; batch classifier loss: 0.355540; batch adversarial loss: 0.523786\n",
      "epoch 117; iter: 0; batch classifier loss: 0.309188; batch adversarial loss: 0.519037\n",
      "epoch 118; iter: 0; batch classifier loss: 0.361705; batch adversarial loss: 0.538488\n",
      "epoch 119; iter: 0; batch classifier loss: 0.370042; batch adversarial loss: 0.547944\n",
      "epoch 120; iter: 0; batch classifier loss: 0.372978; batch adversarial loss: 0.582847\n",
      "epoch 121; iter: 0; batch classifier loss: 0.450284; batch adversarial loss: 0.483499\n",
      "epoch 122; iter: 0; batch classifier loss: 0.330444; batch adversarial loss: 0.518266\n",
      "epoch 123; iter: 0; batch classifier loss: 0.316192; batch adversarial loss: 0.606682\n",
      "epoch 124; iter: 0; batch classifier loss: 0.308000; batch adversarial loss: 0.571310\n",
      "epoch 125; iter: 0; batch classifier loss: 0.357377; batch adversarial loss: 0.509912\n",
      "epoch 126; iter: 0; batch classifier loss: 0.288236; batch adversarial loss: 0.492666\n",
      "epoch 127; iter: 0; batch classifier loss: 0.357999; batch adversarial loss: 0.563483\n",
      "epoch 128; iter: 0; batch classifier loss: 0.331520; batch adversarial loss: 0.573033\n",
      "epoch 129; iter: 0; batch classifier loss: 0.336338; batch adversarial loss: 0.580504\n",
      "epoch 130; iter: 0; batch classifier loss: 0.386055; batch adversarial loss: 0.571292\n",
      "epoch 131; iter: 0; batch classifier loss: 0.310672; batch adversarial loss: 0.527233\n",
      "epoch 132; iter: 0; batch classifier loss: 0.373482; batch adversarial loss: 0.491322\n",
      "epoch 133; iter: 0; batch classifier loss: 0.266478; batch adversarial loss: 0.607330\n",
      "epoch 134; iter: 0; batch classifier loss: 0.346739; batch adversarial loss: 0.660092\n",
      "epoch 135; iter: 0; batch classifier loss: 0.310650; batch adversarial loss: 0.544212\n",
      "epoch 136; iter: 0; batch classifier loss: 0.337203; batch adversarial loss: 0.605192\n",
      "epoch 137; iter: 0; batch classifier loss: 0.400698; batch adversarial loss: 0.570882\n",
      "epoch 138; iter: 0; batch classifier loss: 0.411609; batch adversarial loss: 0.571671\n",
      "epoch 139; iter: 0; batch classifier loss: 0.360137; batch adversarial loss: 0.552704\n",
      "epoch 140; iter: 0; batch classifier loss: 0.289626; batch adversarial loss: 0.570852\n",
      "epoch 141; iter: 0; batch classifier loss: 0.341762; batch adversarial loss: 0.508011\n",
      "epoch 142; iter: 0; batch classifier loss: 0.348688; batch adversarial loss: 0.491765\n",
      "epoch 143; iter: 0; batch classifier loss: 0.396230; batch adversarial loss: 0.570717\n",
      "epoch 144; iter: 0; batch classifier loss: 0.327445; batch adversarial loss: 0.559042\n",
      "epoch 145; iter: 0; batch classifier loss: 0.302500; batch adversarial loss: 0.515804\n",
      "epoch 146; iter: 0; batch classifier loss: 0.316951; batch adversarial loss: 0.552503\n",
      "epoch 147; iter: 0; batch classifier loss: 0.364095; batch adversarial loss: 0.471429\n",
      "epoch 148; iter: 0; batch classifier loss: 0.237875; batch adversarial loss: 0.542742\n",
      "epoch 149; iter: 0; batch classifier loss: 0.391314; batch adversarial loss: 0.578422\n",
      "epoch 150; iter: 0; batch classifier loss: 0.272169; batch adversarial loss: 0.571876\n",
      "epoch 151; iter: 0; batch classifier loss: 0.304880; batch adversarial loss: 0.528377\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 152; iter: 0; batch classifier loss: 0.293237; batch adversarial loss: 0.596293\n",
      "epoch 153; iter: 0; batch classifier loss: 0.383600; batch adversarial loss: 0.535565\n",
      "epoch 154; iter: 0; batch classifier loss: 0.370259; batch adversarial loss: 0.570971\n",
      "epoch 155; iter: 0; batch classifier loss: 0.333577; batch adversarial loss: 0.555400\n",
      "epoch 156; iter: 0; batch classifier loss: 0.333797; batch adversarial loss: 0.534178\n",
      "epoch 157; iter: 0; batch classifier loss: 0.356584; batch adversarial loss: 0.578924\n",
      "epoch 158; iter: 0; batch classifier loss: 0.293031; batch adversarial loss: 0.536837\n",
      "epoch 159; iter: 0; batch classifier loss: 0.300021; batch adversarial loss: 0.534939\n",
      "epoch 160; iter: 0; batch classifier loss: 0.301205; batch adversarial loss: 0.527531\n",
      "epoch 161; iter: 0; batch classifier loss: 0.325271; batch adversarial loss: 0.607046\n",
      "epoch 162; iter: 0; batch classifier loss: 0.299675; batch adversarial loss: 0.562027\n",
      "epoch 163; iter: 0; batch classifier loss: 0.287040; batch adversarial loss: 0.563603\n",
      "epoch 164; iter: 0; batch classifier loss: 0.453337; batch adversarial loss: 0.658390\n",
      "epoch 165; iter: 0; batch classifier loss: 0.380715; batch adversarial loss: 0.527853\n",
      "epoch 166; iter: 0; batch classifier loss: 0.302805; batch adversarial loss: 0.623936\n",
      "epoch 167; iter: 0; batch classifier loss: 0.387983; batch adversarial loss: 0.597357\n",
      "epoch 168; iter: 0; batch classifier loss: 0.324444; batch adversarial loss: 0.553528\n",
      "epoch 169; iter: 0; batch classifier loss: 0.318609; batch adversarial loss: 0.544804\n",
      "epoch 170; iter: 0; batch classifier loss: 0.248554; batch adversarial loss: 0.545003\n",
      "epoch 171; iter: 0; batch classifier loss: 0.321398; batch adversarial loss: 0.527345\n",
      "epoch 172; iter: 0; batch classifier loss: 0.341997; batch adversarial loss: 0.518009\n",
      "epoch 173; iter: 0; batch classifier loss: 0.292062; batch adversarial loss: 0.491569\n",
      "epoch 174; iter: 0; batch classifier loss: 0.303894; batch adversarial loss: 0.580497\n",
      "epoch 175; iter: 0; batch classifier loss: 0.357205; batch adversarial loss: 0.544452\n",
      "epoch 176; iter: 0; batch classifier loss: 0.313166; batch adversarial loss: 0.508272\n",
      "epoch 177; iter: 0; batch classifier loss: 0.319997; batch adversarial loss: 0.510139\n",
      "epoch 178; iter: 0; batch classifier loss: 0.299203; batch adversarial loss: 0.535144\n",
      "epoch 179; iter: 0; batch classifier loss: 0.290973; batch adversarial loss: 0.633701\n",
      "epoch 180; iter: 0; batch classifier loss: 0.257437; batch adversarial loss: 0.640968\n",
      "epoch 181; iter: 0; batch classifier loss: 0.324866; batch adversarial loss: 0.588369\n",
      "epoch 182; iter: 0; batch classifier loss: 0.271953; batch adversarial loss: 0.544629\n",
      "epoch 183; iter: 0; batch classifier loss: 0.249018; batch adversarial loss: 0.589365\n",
      "epoch 184; iter: 0; batch classifier loss: 0.336430; batch adversarial loss: 0.588978\n",
      "epoch 185; iter: 0; batch classifier loss: 0.302580; batch adversarial loss: 0.545499\n",
      "epoch 186; iter: 0; batch classifier loss: 0.343656; batch adversarial loss: 0.525838\n",
      "epoch 187; iter: 0; batch classifier loss: 0.320548; batch adversarial loss: 0.528023\n",
      "epoch 188; iter: 0; batch classifier loss: 0.361486; batch adversarial loss: 0.599358\n",
      "epoch 189; iter: 0; batch classifier loss: 0.266313; batch adversarial loss: 0.491407\n",
      "epoch 190; iter: 0; batch classifier loss: 0.283231; batch adversarial loss: 0.579908\n",
      "epoch 191; iter: 0; batch classifier loss: 0.320148; batch adversarial loss: 0.534739\n",
      "epoch 192; iter: 0; batch classifier loss: 0.299522; batch adversarial loss: 0.545917\n",
      "epoch 193; iter: 0; batch classifier loss: 0.302152; batch adversarial loss: 0.617471\n",
      "epoch 194; iter: 0; batch classifier loss: 0.248601; batch adversarial loss: 0.562468\n",
      "epoch 195; iter: 0; batch classifier loss: 0.364104; batch adversarial loss: 0.535424\n",
      "epoch 196; iter: 0; batch classifier loss: 0.311755; batch adversarial loss: 0.554201\n",
      "epoch 197; iter: 0; batch classifier loss: 0.376945; batch adversarial loss: 0.563053\n",
      "epoch 198; iter: 0; batch classifier loss: 0.304941; batch adversarial loss: 0.571039\n",
      "epoch 199; iter: 0; batch classifier loss: 0.315828; batch adversarial loss: 0.570865\n"
     ]
    }
   ],
   "source": [
    "run_exp_iter_with_inprocessor(data_loader=exp_iter_data_loader,\n",
    "                              experiment_seed=experiment_seed,\n",
    "                              test_set_fraction=TEST_SET_FRACTION,\n",
    "                              db_writer_func=db_writer_func,\n",
    "                              fair_intervention_params_lst=FAIR_INTERVENTION_PARAMS_LST,\n",
    "                              metrics_computation_config=metrics_computation_config,\n",
    "                              custom_table_fields_dct=custom_table_fields_dct,\n",
    "                              dataset_name='ACSPublicCoverageDataset',\n",
    "                              inprocessor_name='AdversarialDebiasing',\n",
    "                              verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb6f653",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
