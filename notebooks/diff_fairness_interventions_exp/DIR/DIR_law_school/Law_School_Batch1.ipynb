{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0af0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -r ./requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb27268a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip uninstall virny -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9094c498",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install using an HTTP link\n",
    "# !pip install git+https://github.com/DataResponsibly/Virny.git@feature/prepare_for_uncertainty_experiments\n",
    "\n",
    "# Install using an SSH link\n",
    "# !pip install git+ssh://git@github.com/DataResponsibly/Virny.git@feature/prepare_for_uncertainty_experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040d8b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85601d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "os.environ[\"PYTHONWARNINGS\"] = \"ignore\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e0651d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_folder_name = os.getcwd().split('/')[-1]\n",
    "if cur_folder_name != \"fairness-variance\":\n",
    "    os.chdir(\"../../../..\")\n",
    "\n",
    "print('Current location: ', os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345b2f8a",
   "metadata": {},
   "source": [
    "## Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae36bf7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "from virny.utils.custom_initializers import create_config_obj\n",
    "from virny.datasets import LawSchoolDataset\n",
    "\n",
    "from configs.constants import TEST_SET_FRACTION, EXPERIMENT_SEEDS\n",
    "from configs.models_config_for_tuning import get_folktables_employment_models_params_for_tuning\n",
    "\n",
    "from source.experiment_interface import run_exp_iter_with_disparate_impact"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a55e611",
   "metadata": {},
   "source": [
    "## Define Input Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414813d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = os.getcwd()\n",
    "EXPERIMENT_NAME = 'DIR_law_school'\n",
    "DB_COLLECTION_NAME = 'one_repair_lvl_many_models'\n",
    "FAIRNESS_INTERVENTION = 'DIR'\n",
    "FAIR_INTERVENTION_PARAMS_LST = [0.6]\n",
    "SAVE_RESULTS_DIR_PATH = os.path.join(ROOT_DIR, 'results', 'diff_fairness_interventions_exp', FAIRNESS_INTERVENTION, EXPERIMENT_NAME)\n",
    "\n",
    "config_yaml_path = os.path.join(ROOT_DIR, 'notebooks', 'diff_fairness_interventions_exp',\n",
    "                                FAIRNESS_INTERVENTION, EXPERIMENT_NAME, 'law_school_config.yaml')\n",
    "metrics_computation_config = create_config_obj(config_yaml_path=config_yaml_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a2072b",
   "metadata": {},
   "source": [
    "## Define a db writer and custom fields to insert into your database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba6d939",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv('./configs/secrets.env')\n",
    "os.getenv(\"DB_NAME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197629de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from source.utils.db_functions import connect_to_mongodb\n",
    "\n",
    "client, collection_obj, db_writer_func = connect_to_mongodb(DB_COLLECTION_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf765f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "custom_table_fields_dct = {\n",
    "#     'session_uuid': str(uuid.uuid4()),\n",
    "    'session_uuid': '336e4621-fef9-4722-a3c1-b2ecca7e7f45',\n",
    "}\n",
    "print('Current session uuid: ', custom_table_fields_dct['session_uuid'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17bd13ba",
   "metadata": {},
   "source": [
    "## Initialize custom objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a804f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = LawSchoolDataset()\n",
    "data_loader.X_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2042867d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader.X_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6aa50ed",
   "metadata": {},
   "source": [
    "## Run experiment iterations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e933f251",
   "metadata": {},
   "source": [
    "### Experiment iteration 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72fe833a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tuned_params_filenames = []\n",
    "# tuned_params_df_paths = [os.path.join(ROOT_DIR, 'results', 'diff_fairness_interventions_exp',\n",
    "#                                       FAIRNESS_INTERVENTION, EXPERIMENT_NAME, tuned_params_filename)\n",
    "#                          for tuned_params_filename in tuned_params_filenames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59e0dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configs for an experiment iteration\n",
    "exp_iter_num = 1\n",
    "experiment_seed = EXPERIMENT_SEEDS[exp_iter_num - 1]\n",
    "custom_table_fields_dct['experiment_iteration'] = f'Exp_iter_{exp_iter_num}'\n",
    "\n",
    "exp_iter_data_loader = copy.deepcopy(data_loader)  # Add deepcopy to avoid data leakage\n",
    "models_params_for_tuning = get_folktables_employment_models_params_for_tuning(experiment_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d429c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_exp_iter_with_disparate_impact(data_loader=exp_iter_data_loader,\n",
    "                                   experiment_seed=experiment_seed,\n",
    "                                   test_set_fraction=TEST_SET_FRACTION,\n",
    "                                   db_writer_func=db_writer_func,\n",
    "                                   fair_intervention_params_lst=FAIR_INTERVENTION_PARAMS_LST,\n",
    "                                   models_params_for_tuning=models_params_for_tuning,\n",
    "                                   metrics_computation_config=metrics_computation_config,\n",
    "                                   custom_table_fields_dct=custom_table_fields_dct,\n",
    "                                   with_tuning=True,\n",
    "                                   # with_tuning=False,\n",
    "                                   # tuned_params_df_paths=tuned_params_df_paths,\n",
    "                                   save_results_dir_path=SAVE_RESULTS_DIR_PATH,\n",
    "                                   dataset_name='LawSchoolDataset',\n",
    "                                   verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc876a4b",
   "metadata": {},
   "source": [
    "### Experiment iteration 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd0259d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configs for an experiment iteration\n",
    "exp_iter_num = 2\n",
    "experiment_seed = EXPERIMENT_SEEDS[exp_iter_num - 1]\n",
    "tuned_params_filenames = [\n",
    "    'tuning_results_Law_School_alpha_0.6_20240106__214045.csv'\n",
    "]\n",
    "tuned_params_df_paths = [os.path.join(ROOT_DIR, 'results', 'diff_fairness_interventions_exp',\n",
    "                                      FAIRNESS_INTERVENTION, EXPERIMENT_NAME, tuned_params_filename)\n",
    "                         for tuned_params_filename in tuned_params_filenames]\n",
    "custom_table_fields_dct['experiment_iteration'] = f'Exp_iter_{exp_iter_num}'\n",
    "\n",
    "exp_iter_data_loader = copy.deepcopy(data_loader)  # Add deepcopy to avoid data leakage\n",
    "models_params_for_tuning = get_folktables_employment_models_params_for_tuning(experiment_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9b9ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_exp_iter_with_disparate_impact(data_loader=exp_iter_data_loader,\n",
    "                                   experiment_seed=experiment_seed,\n",
    "                                   test_set_fraction=TEST_SET_FRACTION,\n",
    "                                   db_writer_func=db_writer_func,\n",
    "                                   fair_intervention_params_lst=FAIR_INTERVENTION_PARAMS_LST,\n",
    "                                   models_params_for_tuning=models_params_for_tuning,\n",
    "                                   metrics_computation_config=metrics_computation_config,\n",
    "                                   custom_table_fields_dct=custom_table_fields_dct,\n",
    "                                   # with_tuning=True,\n",
    "                                   with_tuning=False,\n",
    "                                   tuned_params_df_paths=tuned_params_df_paths,\n",
    "                                   save_results_dir_path=SAVE_RESULTS_DIR_PATH,\n",
    "                                   dataset_name='LawSchoolDataset',\n",
    "                                   verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25dafe12",
   "metadata": {},
   "source": [
    "### Experiment iteration 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663a7eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configs for an experiment iteration\n",
    "exp_iter_num = 3\n",
    "experiment_seed = EXPERIMENT_SEEDS[exp_iter_num - 1]\n",
    "tuned_params_filenames = [\n",
    "    'tuning_results_Law_School_alpha_0.6_20240106__214045.csv'\n",
    "]\n",
    "tuned_params_df_paths = [os.path.join(ROOT_DIR, 'results', 'diff_fairness_interventions_exp',\n",
    "                                      FAIRNESS_INTERVENTION, EXPERIMENT_NAME, tuned_params_filename)\n",
    "                         for tuned_params_filename in tuned_params_filenames]\n",
    "custom_table_fields_dct['experiment_iteration'] = f'Exp_iter_{exp_iter_num}'\n",
    "\n",
    "exp_iter_data_loader = copy.deepcopy(data_loader)  # Add deepcopy to avoid data leakage\n",
    "models_params_for_tuning = get_folktables_employment_models_params_for_tuning(experiment_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39717477",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_exp_iter_with_disparate_impact(data_loader=exp_iter_data_loader,\n",
    "                                   experiment_seed=experiment_seed,\n",
    "                                   test_set_fraction=TEST_SET_FRACTION,\n",
    "                                   db_writer_func=db_writer_func,\n",
    "                                   fair_intervention_params_lst=FAIR_INTERVENTION_PARAMS_LST,\n",
    "                                   models_params_for_tuning=models_params_for_tuning,\n",
    "                                   metrics_computation_config=metrics_computation_config,\n",
    "                                   custom_table_fields_dct=custom_table_fields_dct,\n",
    "                                   # with_tuning=True,\n",
    "                                   with_tuning=False,\n",
    "                                   tuned_params_df_paths=tuned_params_df_paths,\n",
    "                                   save_results_dir_path=SAVE_RESULTS_DIR_PATH,\n",
    "                                   dataset_name='LawSchoolDataset',\n",
    "                                   verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5499e9",
   "metadata": {},
   "source": [
    "### Experiment iteration 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e78a60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configs for an experiment iteration\n",
    "exp_iter_num = 4\n",
    "experiment_seed = EXPERIMENT_SEEDS[exp_iter_num - 1]\n",
    "tuned_params_filenames = [\n",
    "    'tuning_results_Law_School_alpha_0.6_20240106__214045.csv'\n",
    "]\n",
    "tuned_params_df_paths = [os.path.join(ROOT_DIR, 'results', 'diff_fairness_interventions_exp',\n",
    "                                      FAIRNESS_INTERVENTION, EXPERIMENT_NAME, tuned_params_filename)\n",
    "                         for tuned_params_filename in tuned_params_filenames]\n",
    "custom_table_fields_dct['experiment_iteration'] = f'Exp_iter_{exp_iter_num}'\n",
    "\n",
    "exp_iter_data_loader = copy.deepcopy(data_loader)  # Add deepcopy to avoid data leakage\n",
    "models_params_for_tuning = get_folktables_employment_models_params_for_tuning(experiment_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87bbbb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_exp_iter_with_disparate_impact(data_loader=exp_iter_data_loader,\n",
    "                                   experiment_seed=experiment_seed,\n",
    "                                   test_set_fraction=TEST_SET_FRACTION,\n",
    "                                   db_writer_func=db_writer_func,\n",
    "                                   fair_intervention_params_lst=FAIR_INTERVENTION_PARAMS_LST,\n",
    "                                   models_params_for_tuning=models_params_for_tuning,\n",
    "                                   metrics_computation_config=metrics_computation_config,\n",
    "                                   custom_table_fields_dct=custom_table_fields_dct,\n",
    "                                   # with_tuning=True,\n",
    "                                   with_tuning=False,\n",
    "                                   tuned_params_df_paths=tuned_params_df_paths,\n",
    "                                   save_results_dir_path=SAVE_RESULTS_DIR_PATH,\n",
    "                                   dataset_name='LawSchoolDataset',\n",
    "                                   verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f96c80",
   "metadata": {},
   "source": [
    "### Experiment iteration 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e1ff77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configs for an experiment iteration\n",
    "exp_iter_num = 5\n",
    "experiment_seed = EXPERIMENT_SEEDS[exp_iter_num - 1]\n",
    "tuned_params_filenames = [\n",
    "    'tuning_results_Law_School_alpha_0.6_20240106__214045.csv'\n",
    "]\n",
    "tuned_params_df_paths = [os.path.join(ROOT_DIR, 'results', 'diff_fairness_interventions_exp',\n",
    "                                      FAIRNESS_INTERVENTION, EXPERIMENT_NAME, tuned_params_filename)\n",
    "                         for tuned_params_filename in tuned_params_filenames]\n",
    "custom_table_fields_dct['experiment_iteration'] = f'Exp_iter_{exp_iter_num}'\n",
    "\n",
    "exp_iter_data_loader = copy.deepcopy(data_loader)  # Add deepcopy to avoid data leakage\n",
    "models_params_for_tuning = get_folktables_employment_models_params_for_tuning(experiment_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b62d86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_exp_iter_with_disparate_impact(data_loader=exp_iter_data_loader,\n",
    "                                   experiment_seed=experiment_seed,\n",
    "                                   test_set_fraction=TEST_SET_FRACTION,\n",
    "                                   db_writer_func=db_writer_func,\n",
    "                                   fair_intervention_params_lst=FAIR_INTERVENTION_PARAMS_LST,\n",
    "                                   models_params_for_tuning=models_params_for_tuning,\n",
    "                                   metrics_computation_config=metrics_computation_config,\n",
    "                                   custom_table_fields_dct=custom_table_fields_dct,\n",
    "                                   # with_tuning=True,\n",
    "                                   with_tuning=False,\n",
    "                                   tuned_params_df_paths=tuned_params_df_paths,\n",
    "                                   save_results_dir_path=SAVE_RESULTS_DIR_PATH,\n",
    "                                   dataset_name='LawSchoolDataset',\n",
    "                                   verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977e7e5e",
   "metadata": {},
   "source": [
    "### Experiment iteration 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70050088",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configs for an experiment iteration\n",
    "exp_iter_num = 6\n",
    "experiment_seed = EXPERIMENT_SEEDS[exp_iter_num - 1]\n",
    "tuned_params_filenames = [\n",
    "    'tuning_results_Law_School_alpha_0.6_20240106__214045.csv'\n",
    "]\n",
    "tuned_params_df_paths = [os.path.join(ROOT_DIR, 'results', 'diff_fairness_interventions_exp',\n",
    "                                      FAIRNESS_INTERVENTION, EXPERIMENT_NAME, tuned_params_filename)\n",
    "                         for tuned_params_filename in tuned_params_filenames]\n",
    "custom_table_fields_dct['experiment_iteration'] = f'Exp_iter_{exp_iter_num}'\n",
    "\n",
    "exp_iter_data_loader = copy.deepcopy(data_loader)  # Add deepcopy to avoid data leakage\n",
    "models_params_for_tuning = get_folktables_employment_models_params_for_tuning(experiment_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d47024",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_exp_iter_with_disparate_impact(data_loader=exp_iter_data_loader,\n",
    "                                   experiment_seed=experiment_seed,\n",
    "                                   test_set_fraction=TEST_SET_FRACTION,\n",
    "                                   db_writer_func=db_writer_func,\n",
    "                                   fair_intervention_params_lst=FAIR_INTERVENTION_PARAMS_LST,\n",
    "                                   models_params_for_tuning=models_params_for_tuning,\n",
    "                                   metrics_computation_config=metrics_computation_config,\n",
    "                                   custom_table_fields_dct=custom_table_fields_dct,\n",
    "                                   # with_tuning=True,\n",
    "                                   with_tuning=False,\n",
    "                                   tuned_params_df_paths=tuned_params_df_paths,\n",
    "                                   save_results_dir_path=SAVE_RESULTS_DIR_PATH,\n",
    "                                   dataset_name='LawSchoolDataset',\n",
    "                                   verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3aca15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
