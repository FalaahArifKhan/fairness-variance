{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75fe1500",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -r ./requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba455b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip uninstall virny -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52d70e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install using an HTTP link\n",
    "# !pip install git+https://github.com/DataResponsibly/Virny.git@feature/prepare_for_uncertainty_experiments\n",
    "\n",
    "# Install using an SSH link\n",
    "# !pip install git+ssh://git@github.com/DataResponsibly/Virny.git@feature/prepare_for_uncertainty_experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868a36b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffaa58a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "os.environ[\"PYTHONWARNINGS\"] = \"ignore\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125157e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_folder_name = os.getcwd().split('/')[-1]\n",
    "if cur_folder_name != \"fairness-variance\":\n",
    "    os.chdir(\"../../..\")\n",
    "\n",
    "print('Current location: ', os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34541ec9",
   "metadata": {},
   "source": [
    "## Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8095ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "\n",
    "from virny.utils.custom_initializers import create_config_obj\n",
    "from virny.datasets import StudentPerformancePortugueseDataset\n",
    "\n",
    "from configs.constants import TEST_SET_FRACTION, EXPERIMENT_SEEDS\n",
    "from configs.models_config_for_tuning import get_folktables_employment_models_params_for_tuning\n",
    "\n",
    "from source.experiment_interface import run_exp_iter_with_disparate_impact"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6d0128",
   "metadata": {},
   "source": [
    "## Define Input Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b62ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = os.getcwd()\n",
    "EXPERIMENT_NAME = 'DIR_student_performance_por'\n",
    "DB_COLLECTION_NAME = 'one_repair_lvl_many_models'\n",
    "DATASET_NAME = 'StudentPerformancePortugueseDataset'\n",
    "SAVE_RESULTS_DIR_PATH = os.path.join(ROOT_DIR, 'results', 'diff_fairness_interventions_exp', EXPERIMENT_NAME)\n",
    "FAIR_INTERVENTION_PARAMS_LST = [0.7]\n",
    "\n",
    "config_yaml_path = os.path.join(ROOT_DIR, 'notebooks', 'diff_fairness_interventions_exp',\n",
    "                                EXPERIMENT_NAME, 'student_performance_por_config.yaml')\n",
    "metrics_computation_config = create_config_obj(config_yaml_path=config_yaml_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac7ff28",
   "metadata": {},
   "source": [
    "## Define a db writer and custom fields to insert into your database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1cb6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv('./configs/secrets.env')\n",
    "os.getenv(\"DB_NAME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b2fa5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from source.utils.db_functions import connect_to_mongodb\n",
    "\n",
    "client, collection_obj, db_writer_func = connect_to_mongodb(DB_COLLECTION_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc901acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "custom_table_fields_dct = {\n",
    "#     'session_uuid': str(uuid.uuid4()),\n",
    "    'session_uuid': '647daccf-7c14-463c-99ab-ef16972dba80',\n",
    "}\n",
    "print('Current session uuid: ', custom_table_fields_dct['session_uuid'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32c667a",
   "metadata": {},
   "source": [
    "## Initialize custom objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd05e3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = StudentPerformancePortugueseDataset()\n",
    "data_loader.X_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506e8ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader.X_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ce7482",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader.y_data.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ece4971",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader.X_data['sex'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec2becf2",
   "metadata": {},
   "source": [
    "## Run experiment iterations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ecd3026",
   "metadata": {},
   "source": [
    "### Experiment iteration 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4faa2ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tuned_params_filenames = [\n",
    "#     'tuning_results_Law_School_alpha_0.0_20230807__000522.csv',\n",
    "#     'tuning_results_Law_School_alpha_0.6_20230807__000624.csv',\n",
    "# ]\n",
    "# tuned_params_df_paths = [os.path.join(ROOT_DIR, 'results', EXPERIMENT_NAME, tuned_params_filename)\n",
    "#                          for tuned_params_filename in tuned_params_filenames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967c7d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configs for an experiment iteration\n",
    "exp_iter_num = 1\n",
    "experiment_seed = EXPERIMENT_SEEDS[exp_iter_num - 1]\n",
    "custom_table_fields_dct['experiment_iteration'] = f'Exp_iter_{exp_iter_num}'\n",
    "\n",
    "exp_iter_data_loader = copy.deepcopy(data_loader)  # Add deepcopy to avoid data leakage\n",
    "models_params_for_tuning = get_folktables_employment_models_params_for_tuning(experiment_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d633ba64",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_exp_iter_with_disparate_impact(data_loader=exp_iter_data_loader,\n",
    "                                   experiment_seed=experiment_seed,\n",
    "                                   test_set_fraction=TEST_SET_FRACTION,\n",
    "                                   db_writer_func=db_writer_func,\n",
    "                                   fair_intervention_params_lst=FAIR_INTERVENTION_PARAMS_LST,\n",
    "                                   models_params_for_tuning=models_params_for_tuning,\n",
    "                                   metrics_computation_config=metrics_computation_config,\n",
    "                                   custom_table_fields_dct=custom_table_fields_dct,\n",
    "                                   with_tuning=True,\n",
    "                                   # with_tuning=False,\n",
    "                                   # tuned_params_df_paths=tuned_params_df_paths,\n",
    "                                   save_results_dir_path=SAVE_RESULTS_DIR_PATH,\n",
    "                                   verbose=True, \n",
    "                                   dataset_name=DATASET_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cbba8bd",
   "metadata": {},
   "source": [
    "### Experiment iteration 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92458d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configs for an experiment iteration\n",
    "exp_iter_num = 2\n",
    "experiment_seed = EXPERIMENT_SEEDS[exp_iter_num - 1]\n",
    "tuned_params_filenames = [\n",
    "    'tuning_results_Student_Performance_Por_alpha_0.0_20231226__234555.csv',\n",
    "    'tuning_results_Student_Performance_Por_alpha_0.7_20231226__234744.csv',\n",
    "]\n",
    "tuned_params_df_paths = [os.path.join(ROOT_DIR, 'results', 'diff_fairness_interventions_exp', EXPERIMENT_NAME, tuned_params_filename)\n",
    "                         for tuned_params_filename in tuned_params_filenames]\n",
    "custom_table_fields_dct['experiment_iteration'] = f'Exp_iter_{exp_iter_num}'\n",
    "\n",
    "exp_iter_data_loader = copy.deepcopy(data_loader)  # Add deepcopy to avoid data leakage\n",
    "models_params_for_tuning = get_folktables_employment_models_params_for_tuning(experiment_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4eb5e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_exp_iter_with_disparate_impact(data_loader=exp_iter_data_loader,\n",
    "                                   experiment_seed=experiment_seed,\n",
    "                                   test_set_fraction=TEST_SET_FRACTION,\n",
    "                                   db_writer_func=db_writer_func,\n",
    "                                   fair_intervention_params_lst=FAIR_INTERVENTION_PARAMS_LST,\n",
    "                                   models_params_for_tuning=models_params_for_tuning,\n",
    "                                   metrics_computation_config=metrics_computation_config,\n",
    "                                   custom_table_fields_dct=custom_table_fields_dct,\n",
    "#                                    with_tuning=True,\n",
    "                                   with_tuning=False,\n",
    "                                   tuned_params_df_paths=tuned_params_df_paths,\n",
    "                                   save_results_dir_path=SAVE_RESULTS_DIR_PATH,\n",
    "                                   verbose=True, \n",
    "                                   dataset_name=DATASET_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f47f3323",
   "metadata": {},
   "source": [
    "### Experiment iteration 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb7a01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configs for an experiment iteration\n",
    "exp_iter_num = 3\n",
    "experiment_seed = EXPERIMENT_SEEDS[exp_iter_num - 1]\n",
    "tuned_params_filenames = [\n",
    "    'tuning_results_Student_Performance_Por_alpha_0.0_20231226__234555.csv',\n",
    "    'tuning_results_Student_Performance_Por_alpha_0.7_20231226__234744.csv',\n",
    "]\n",
    "tuned_params_df_paths = [os.path.join(ROOT_DIR, 'results', 'diff_fairness_interventions_exp', EXPERIMENT_NAME, tuned_params_filename)\n",
    "                         for tuned_params_filename in tuned_params_filenames]\n",
    "custom_table_fields_dct['experiment_iteration'] = f'Exp_iter_{exp_iter_num}'\n",
    "\n",
    "exp_iter_data_loader = copy.deepcopy(data_loader)  # Add deepcopy to avoid data leakage\n",
    "models_params_for_tuning = get_folktables_employment_models_params_for_tuning(experiment_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea893e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_exp_iter_with_disparate_impact(data_loader=exp_iter_data_loader,\n",
    "                                   experiment_seed=experiment_seed,\n",
    "                                   test_set_fraction=TEST_SET_FRACTION,\n",
    "                                   db_writer_func=db_writer_func,\n",
    "                                   fair_intervention_params_lst=FAIR_INTERVENTION_PARAMS_LST,\n",
    "                                   models_params_for_tuning=models_params_for_tuning,\n",
    "                                   metrics_computation_config=metrics_computation_config,\n",
    "                                   custom_table_fields_dct=custom_table_fields_dct,\n",
    "#                                    with_tuning=True,\n",
    "                                   with_tuning=False,\n",
    "                                   tuned_params_df_paths=tuned_params_df_paths,\n",
    "                                   save_results_dir_path=SAVE_RESULTS_DIR_PATH,\n",
    "                                   verbose=True, \n",
    "                                   dataset_name=DATASET_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76bfe0ff",
   "metadata": {},
   "source": [
    "### Experiment iteration 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d9e853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configs for an experiment iteration\n",
    "exp_iter_num = 4\n",
    "experiment_seed = EXPERIMENT_SEEDS[exp_iter_num - 1]\n",
    "tuned_params_filenames = [\n",
    "    'tuning_results_Student_Performance_Por_alpha_0.0_20231226__234555.csv',\n",
    "    'tuning_results_Student_Performance_Por_alpha_0.7_20231226__234744.csv',\n",
    "]\n",
    "tuned_params_df_paths = [os.path.join(ROOT_DIR, 'results', 'diff_fairness_interventions_exp', EXPERIMENT_NAME, tuned_params_filename)\n",
    "                         for tuned_params_filename in tuned_params_filenames]\n",
    "custom_table_fields_dct['experiment_iteration'] = f'Exp_iter_{exp_iter_num}'\n",
    "\n",
    "exp_iter_data_loader = copy.deepcopy(data_loader)  # Add deepcopy to avoid data leakage\n",
    "models_params_for_tuning = get_folktables_employment_models_params_for_tuning(experiment_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5b57ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_exp_iter_with_disparate_impact(data_loader=exp_iter_data_loader,\n",
    "                                   experiment_seed=experiment_seed,\n",
    "                                   test_set_fraction=TEST_SET_FRACTION,\n",
    "                                   db_writer_func=db_writer_func,\n",
    "                                   fair_intervention_params_lst=FAIR_INTERVENTION_PARAMS_LST,\n",
    "                                   models_params_for_tuning=models_params_for_tuning,\n",
    "                                   metrics_computation_config=metrics_computation_config,\n",
    "                                   custom_table_fields_dct=custom_table_fields_dct,\n",
    "#                                    with_tuning=True,\n",
    "                                   with_tuning=False,\n",
    "                                   tuned_params_df_paths=tuned_params_df_paths,\n",
    "                                   save_results_dir_path=SAVE_RESULTS_DIR_PATH,\n",
    "                                   verbose=True, \n",
    "                                   dataset_name=DATASET_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9481004d",
   "metadata": {},
   "source": [
    "### Experiment iteration 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678825da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configs for an experiment iteration\n",
    "exp_iter_num = 5\n",
    "experiment_seed = EXPERIMENT_SEEDS[exp_iter_num - 1]\n",
    "tuned_params_filenames = [\n",
    "    'tuning_results_Student_Performance_Por_alpha_0.0_20231226__234555.csv',\n",
    "    'tuning_results_Student_Performance_Por_alpha_0.7_20231226__234744.csv',\n",
    "]\n",
    "tuned_params_df_paths = [os.path.join(ROOT_DIR, 'results', 'diff_fairness_interventions_exp', EXPERIMENT_NAME, tuned_params_filename)\n",
    "                         for tuned_params_filename in tuned_params_filenames]\n",
    "custom_table_fields_dct['experiment_iteration'] = f'Exp_iter_{exp_iter_num}'\n",
    "\n",
    "exp_iter_data_loader = copy.deepcopy(data_loader)  # Add deepcopy to avoid data leakage\n",
    "models_params_for_tuning = get_folktables_employment_models_params_for_tuning(experiment_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50651e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_exp_iter_with_disparate_impact(data_loader=exp_iter_data_loader,\n",
    "                                   experiment_seed=experiment_seed,\n",
    "                                   test_set_fraction=TEST_SET_FRACTION,\n",
    "                                   db_writer_func=db_writer_func,\n",
    "                                   fair_intervention_params_lst=FAIR_INTERVENTION_PARAMS_LST,\n",
    "                                   models_params_for_tuning=models_params_for_tuning,\n",
    "                                   metrics_computation_config=metrics_computation_config,\n",
    "                                   custom_table_fields_dct=custom_table_fields_dct,\n",
    "#                                    with_tuning=True,\n",
    "                                   with_tuning=False,\n",
    "                                   tuned_params_df_paths=tuned_params_df_paths,\n",
    "                                   save_results_dir_path=SAVE_RESULTS_DIR_PATH,\n",
    "                                   verbose=True, \n",
    "                                   dataset_name=DATASET_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38926191",
   "metadata": {},
   "source": [
    "### Experiment iteration 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af368cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configs for an experiment iteration\n",
    "exp_iter_num = 6\n",
    "experiment_seed = EXPERIMENT_SEEDS[exp_iter_num - 1]\n",
    "tuned_params_filenames = [\n",
    "    'tuning_results_Student_Performance_Por_alpha_0.0_20231226__234555.csv',\n",
    "    'tuning_results_Student_Performance_Por_alpha_0.7_20231226__234744.csv',\n",
    "]\n",
    "tuned_params_df_paths = [os.path.join(ROOT_DIR, 'results', 'diff_fairness_interventions_exp', EXPERIMENT_NAME, tuned_params_filename)\n",
    "                         for tuned_params_filename in tuned_params_filenames]\n",
    "custom_table_fields_dct['experiment_iteration'] = f'Exp_iter_{exp_iter_num}'\n",
    "\n",
    "exp_iter_data_loader = copy.deepcopy(data_loader)  # Add deepcopy to avoid data leakage\n",
    "models_params_for_tuning = get_folktables_employment_models_params_for_tuning(experiment_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1908f221",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_exp_iter_with_disparate_impact(data_loader=exp_iter_data_loader,\n",
    "                                   experiment_seed=experiment_seed,\n",
    "                                   test_set_fraction=TEST_SET_FRACTION,\n",
    "                                   db_writer_func=db_writer_func,\n",
    "                                   fair_intervention_params_lst=FAIR_INTERVENTION_PARAMS_LST,\n",
    "                                   models_params_for_tuning=models_params_for_tuning,\n",
    "                                   metrics_computation_config=metrics_computation_config,\n",
    "                                   custom_table_fields_dct=custom_table_fields_dct,\n",
    "#                                    with_tuning=True,\n",
    "                                   with_tuning=False,\n",
    "                                   tuned_params_df_paths=tuned_params_df_paths,\n",
    "                                   save_results_dir_path=SAVE_RESULTS_DIR_PATH,\n",
    "                                   verbose=True, \n",
    "                                   dataset_name=DATASET_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29391fd3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
